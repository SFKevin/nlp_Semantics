Train: 2018-07-31T00:37:16.067004: step 1, loss 0.694307.
Train: 2018-07-31T00:37:16.238849: step 2, loss 0.64847.
Train: 2018-07-31T00:37:16.395053: step 3, loss 0.657363.
Train: 2018-07-31T00:37:16.535644: step 4, loss 0.608037.
Train: 2018-07-31T00:37:16.676261: step 5, loss 0.565681.
Train: 2018-07-31T00:37:16.816829: step 6, loss 0.556441.
Train: 2018-07-31T00:37:16.957419: step 7, loss 0.518962.
Train: 2018-07-31T00:37:17.098037: step 8, loss 0.528602.
Train: 2018-07-31T00:37:17.254250: step 9, loss 0.72547.
Train: 2018-07-31T00:37:17.394843: step 10, loss 0.471007.
Test: 2018-07-31T00:37:17.925974: step 10, loss 0.548734.
Train: 2018-07-31T00:37:18.082158: step 11, loss 0.609999.
Train: 2018-07-31T00:37:18.222774: step 12, loss 0.543765.
Train: 2018-07-31T00:37:18.363342: step 13, loss 0.549748.
Train: 2018-07-31T00:37:18.519555: step 14, loss 0.55397.
Train: 2018-07-31T00:37:18.644524: step 15, loss 0.535078.
Train: 2018-07-31T00:37:18.785117: step 16, loss 0.560253.
Train: 2018-07-31T00:37:18.925709: step 17, loss 0.534457.
Train: 2018-07-31T00:37:19.081924: step 18, loss 0.57791.
Train: 2018-07-31T00:37:19.222534: step 19, loss 0.431132.
Train: 2018-07-31T00:37:19.378754: step 20, loss 0.553307.
Test: 2018-07-31T00:37:19.613079: step 20, loss 0.547322.
Train: 2018-07-31T00:37:19.769262: step 21, loss 0.565343.
Train: 2018-07-31T00:37:19.909860: step 22, loss 0.557418.
Train: 2018-07-31T00:37:20.050472: step 23, loss 0.566513.
Train: 2018-07-31T00:37:20.191040: step 24, loss 0.57527.
Train: 2018-07-31T00:37:20.331655: step 25, loss 0.592127.
Train: 2018-07-31T00:37:20.472221: step 26, loss 0.531986.
Train: 2018-07-31T00:37:20.612814: step 27, loss 0.566628.
Train: 2018-07-31T00:37:20.753408: step 28, loss 0.55351.
Train: 2018-07-31T00:37:20.893999: step 29, loss 0.537242.
Train: 2018-07-31T00:37:21.050213: step 30, loss 0.613356.
Test: 2018-07-31T00:37:21.284534: step 30, loss 0.560155.
Train: 2018-07-31T00:37:21.425124: step 31, loss 0.554642.
Train: 2018-07-31T00:37:21.565734: step 32, loss 0.607911.
Train: 2018-07-31T00:37:21.721931: step 33, loss 0.528927.
Train: 2018-07-31T00:37:21.862521: step 34, loss 0.64928.
Train: 2018-07-31T00:37:22.003132: step 35, loss 0.5925.
Train: 2018-07-31T00:37:22.143707: step 36, loss 0.545959.
Train: 2018-07-31T00:37:22.284301: step 37, loss 0.585458.
Train: 2018-07-31T00:37:22.440510: step 38, loss 0.484922.
Train: 2018-07-31T00:37:22.581103: step 39, loss 0.542677.
Train: 2018-07-31T00:37:22.737318: step 40, loss 0.510387.
Test: 2018-07-31T00:37:22.971662: step 40, loss 0.556956.
Train: 2018-07-31T00:37:23.112254: step 41, loss 0.528663.
Train: 2018-07-31T00:37:23.268442: step 42, loss 0.542362.
Train: 2018-07-31T00:37:23.409059: step 43, loss 0.536371.
Train: 2018-07-31T00:37:23.549628: step 44, loss 0.507824.
Train: 2018-07-31T00:37:23.690244: step 45, loss 0.445681.
Train: 2018-07-31T00:37:23.830810: step 46, loss 0.603289.
Train: 2018-07-31T00:37:23.971428: step 47, loss 0.486657.
Train: 2018-07-31T00:37:24.112013: step 48, loss 0.469902.
Train: 2018-07-31T00:37:24.252611: step 49, loss 0.618363.
Train: 2018-07-31T00:37:24.393204: step 50, loss 0.561639.
Test: 2018-07-31T00:37:24.643151: step 50, loss 0.547894.
Train: 2018-07-31T00:37:24.799334: step 51, loss 0.508283.
Train: 2018-07-31T00:37:24.939926: step 52, loss 0.510933.
Train: 2018-07-31T00:37:25.096139: step 53, loss 0.538461.
Train: 2018-07-31T00:37:25.236731: step 54, loss 0.569242.
Train: 2018-07-31T00:37:25.377323: step 55, loss 0.623284.
Train: 2018-07-31T00:37:25.533537: step 56, loss 0.479691.
Train: 2018-07-31T00:37:25.689751: step 57, loss 0.575502.
Train: 2018-07-31T00:37:25.830367: step 58, loss 0.506503.
Train: 2018-07-31T00:37:25.970934: step 59, loss 0.571599.
Train: 2018-07-31T00:37:26.111526: step 60, loss 0.524935.
Test: 2018-07-31T00:37:26.345879: step 60, loss 0.554722.
Train: 2018-07-31T00:37:26.502061: step 61, loss 0.571538.
Train: 2018-07-31T00:37:26.642651: step 62, loss 0.57274.
Train: 2018-07-31T00:37:26.783244: step 63, loss 0.541125.
Train: 2018-07-31T00:37:26.939482: step 64, loss 0.550816.
Train: 2018-07-31T00:37:27.080074: step 65, loss 0.5502.
Train: 2018-07-31T00:37:27.220641: step 66, loss 0.589567.
Train: 2018-07-31T00:37:27.376855: step 67, loss 0.544058.
Train: 2018-07-31T00:37:27.517471: step 68, loss 0.602071.
Train: 2018-07-31T00:37:27.658064: step 69, loss 0.564408.
Train: 2018-07-31T00:37:27.814278: step 70, loss 0.502019.
Test: 2018-07-31T00:37:28.048605: step 70, loss 0.553345.
Train: 2018-07-31T00:37:28.204811: step 71, loss 0.617988.
Train: 2018-07-31T00:37:28.345379: step 72, loss 0.548632.
Train: 2018-07-31T00:37:28.501592: step 73, loss 0.532795.
Train: 2018-07-31T00:37:28.642184: step 74, loss 0.606903.
Train: 2018-07-31T00:37:28.782775: step 75, loss 0.651569.
Train: 2018-07-31T00:37:28.938989: step 76, loss 0.607495.
Train: 2018-07-31T00:37:29.063960: step 77, loss 0.596695.
Train: 2018-07-31T00:37:29.204576: step 78, loss 0.493734.
Train: 2018-07-31T00:37:29.345169: step 79, loss 0.549843.
Train: 2018-07-31T00:37:29.501383: step 80, loss 0.529085.
Test: 2018-07-31T00:37:29.751300: step 80, loss 0.5554.
Train: 2018-07-31T00:37:29.891891: step 81, loss 0.596757.
Train: 2018-07-31T00:37:30.032483: step 82, loss 0.587276.
Train: 2018-07-31T00:37:30.173075: step 83, loss 0.585026.
Train: 2018-07-31T00:37:30.313667: step 84, loss 0.562641.
Train: 2018-07-31T00:37:30.454259: step 85, loss 0.562196.
Train: 2018-07-31T00:37:30.610472: step 86, loss 0.530528.
Train: 2018-07-31T00:37:30.751089: step 87, loss 0.605364.
Train: 2018-07-31T00:37:30.891682: step 88, loss 0.585631.
Train: 2018-07-31T00:37:31.047871: step 89, loss 0.537215.
Train: 2018-07-31T00:37:31.188463: step 90, loss 0.54801.
Test: 2018-07-31T00:37:31.422814: step 90, loss 0.548478.
Train: 2018-07-31T00:37:31.578997: step 91, loss 0.6208.
Train: 2018-07-31T00:37:31.719587: step 92, loss 0.535448.
Train: 2018-07-31T00:37:31.860199: step 93, loss 0.62772.
Train: 2018-07-31T00:37:32.000797: step 94, loss 0.688237.
Train: 2018-07-31T00:37:32.156985: step 95, loss 0.510966.
Train: 2018-07-31T00:37:32.297578: step 96, loss 0.543145.
Train: 2018-07-31T00:37:32.438194: step 97, loss 0.586073.
Train: 2018-07-31T00:37:32.594384: step 98, loss 0.540538.
Train: 2018-07-31T00:37:32.735000: step 99, loss 0.592876.
Train: 2018-07-31T00:37:32.891190: step 100, loss 0.561943.
Test: 2018-07-31T00:37:33.125536: step 100, loss 0.554214.
Train: 2018-07-31T00:37:33.875334: step 101, loss 0.57771.
Train: 2018-07-31T00:37:34.031548: step 102, loss 0.498241.
Train: 2018-07-31T00:37:34.172139: step 103, loss 0.56043.
Train: 2018-07-31T00:37:34.312730: step 104, loss 0.569483.
Train: 2018-07-31T00:37:34.468945: step 105, loss 0.550546.
Train: 2018-07-31T00:37:34.609536: step 106, loss 0.571412.
Train: 2018-07-31T00:37:34.750153: step 107, loss 0.55941.
Train: 2018-07-31T00:37:34.890746: step 108, loss 0.548233.
Train: 2018-07-31T00:37:35.031312: step 109, loss 0.643093.
Train: 2018-07-31T00:37:35.187527: step 110, loss 0.563744.
Test: 2018-07-31T00:37:35.421877: step 110, loss 0.548376.
Train: 2018-07-31T00:37:35.578061: step 111, loss 0.584132.
Train: 2018-07-31T00:37:35.718652: step 112, loss 0.611812.
Train: 2018-07-31T00:37:35.859245: step 113, loss 0.553581.
Train: 2018-07-31T00:37:35.999860: step 114, loss 0.662286.
Train: 2018-07-31T00:37:36.140428: step 115, loss 0.595043.
Train: 2018-07-31T00:37:36.281021: step 116, loss 0.572812.
Train: 2018-07-31T00:37:36.405991: step 117, loss 0.606772.
Train: 2018-07-31T00:37:36.562205: step 118, loss 0.582603.
Train: 2018-07-31T00:37:36.702798: step 119, loss 0.637278.
Train: 2018-07-31T00:37:36.843388: step 120, loss 0.551907.
Test: 2018-07-31T00:37:37.093360: step 120, loss 0.55933.
Train: 2018-07-31T00:37:37.249544: step 121, loss 0.576186.
Train: 2018-07-31T00:37:37.390136: step 122, loss 0.618988.
Train: 2018-07-31T00:37:37.530727: step 123, loss 0.529671.
Train: 2018-07-31T00:37:37.686942: step 124, loss 0.579115.
Train: 2018-07-31T00:37:37.827557: step 125, loss 0.573089.
Train: 2018-07-31T00:37:37.968153: step 126, loss 0.52152.
Train: 2018-07-31T00:37:38.124363: step 127, loss 0.624305.
Train: 2018-07-31T00:37:38.264955: step 128, loss 0.514362.
Train: 2018-07-31T00:37:38.405523: step 129, loss 0.510236.
Train: 2018-07-31T00:37:38.546115: step 130, loss 0.551298.
Test: 2018-07-31T00:37:38.796082: step 130, loss 0.548386.
Train: 2018-07-31T00:37:38.936649: step 131, loss 0.508196.
Train: 2018-07-31T00:37:39.077240: step 132, loss 0.617262.
Train: 2018-07-31T00:37:39.217833: step 133, loss 0.566059.
Train: 2018-07-31T00:37:39.358425: step 134, loss 0.573873.
Train: 2018-07-31T00:37:39.499016: step 135, loss 0.599721.
Train: 2018-07-31T00:37:39.639609: step 136, loss 0.547231.
Train: 2018-07-31T00:37:39.780201: step 137, loss 0.561037.
Train: 2018-07-31T00:37:39.920817: step 138, loss 0.618655.
Train: 2018-07-31T00:37:40.077006: step 139, loss 0.541214.
Train: 2018-07-31T00:37:40.217623: step 140, loss 0.606922.
Test: 2018-07-31T00:37:40.467541: step 140, loss 0.548505.
Train: 2018-07-31T00:37:40.608131: step 141, loss 0.599196.
Train: 2018-07-31T00:37:40.764346: step 142, loss 0.555506.
Train: 2018-07-31T00:37:40.889316: step 143, loss 0.536194.
Train: 2018-07-31T00:37:41.029933: step 144, loss 0.541339.
Train: 2018-07-31T00:37:41.186122: step 145, loss 0.530202.
Train: 2018-07-31T00:37:41.326715: step 146, loss 0.567124.
Train: 2018-07-31T00:37:41.467306: step 147, loss 0.538795.
Train: 2018-07-31T00:37:41.607929: step 148, loss 0.520416.
Train: 2018-07-31T00:37:41.748489: step 149, loss 0.592954.
Train: 2018-07-31T00:37:41.889082: step 150, loss 0.575836.
Test: 2018-07-31T00:37:42.139024: step 150, loss 0.550048.
Train: 2018-07-31T00:37:42.279616: step 151, loss 0.494333.
Train: 2018-07-31T00:37:42.435854: step 152, loss 0.564979.
Train: 2018-07-31T00:37:42.576421: step 153, loss 0.544145.
Train: 2018-07-31T00:37:42.717037: step 154, loss 0.590561.
Train: 2018-07-31T00:37:42.873251: step 155, loss 0.654457.
Train: 2018-07-31T00:37:43.013820: step 156, loss 0.600029.
Train: 2018-07-31T00:37:43.170032: step 157, loss 0.629135.
Train: 2018-07-31T00:37:43.326245: step 158, loss 0.539376.
Train: 2018-07-31T00:37:43.466838: step 159, loss 0.577205.
Train: 2018-07-31T00:37:43.607431: step 160, loss 0.553461.
Test: 2018-07-31T00:37:43.841749: step 160, loss 0.550427.
Train: 2018-07-31T00:37:43.982341: step 161, loss 0.579059.
Train: 2018-07-31T00:37:44.138555: step 162, loss 0.551425.
Train: 2018-07-31T00:37:44.279147: step 163, loss 0.559948.
Train: 2018-07-31T00:37:44.419764: step 164, loss 0.619658.
Train: 2018-07-31T00:37:44.575988: step 165, loss 0.56815.
Train: 2018-07-31T00:37:44.716544: step 166, loss 0.602071.
Train: 2018-07-31T00:37:44.857137: step 167, loss 0.601925.
Train: 2018-07-31T00:37:44.997728: step 168, loss 0.527055.
Train: 2018-07-31T00:37:45.138321: step 169, loss 0.620051.
Train: 2018-07-31T00:37:45.278913: step 170, loss 0.602332.
Test: 2018-07-31T00:37:45.528855: step 170, loss 0.553172.
Train: 2018-07-31T00:37:45.669447: step 171, loss 0.521506.
Train: 2018-07-31T00:37:45.825662: step 172, loss 0.585429.
Train: 2018-07-31T00:37:45.966276: step 173, loss 0.548751.
Train: 2018-07-31T00:37:46.106869: step 174, loss 0.565716.
Train: 2018-07-31T00:37:46.263059: step 175, loss 0.596931.
Train: 2018-07-31T00:37:46.403675: step 176, loss 0.593079.
Train: 2018-07-31T00:37:46.544241: step 177, loss 0.544226.
Train: 2018-07-31T00:37:46.700457: step 178, loss 0.573251.
Train: 2018-07-31T00:37:46.841050: step 179, loss 0.56901.
Train: 2018-07-31T00:37:46.981640: step 180, loss 0.596228.
Test: 2018-07-31T00:37:47.231583: step 180, loss 0.550107.
Train: 2018-07-31T00:37:47.372172: step 181, loss 0.464436.
Train: 2018-07-31T00:37:47.512765: step 182, loss 0.644397.
Train: 2018-07-31T00:37:47.653382: step 183, loss 0.538989.
Train: 2018-07-31T00:37:47.809595: step 184, loss 0.592993.
Train: 2018-07-31T00:37:47.950181: step 185, loss 0.502701.
Train: 2018-07-31T00:37:48.106377: step 186, loss 0.569953.
Train: 2018-07-31T00:37:48.246992: step 187, loss 0.555168.
Train: 2018-07-31T00:37:48.403181: step 188, loss 0.462923.
Train: 2018-07-31T00:37:48.543775: step 189, loss 0.513165.
Train: 2018-07-31T00:37:48.684391: step 190, loss 0.577072.
Test: 2018-07-31T00:37:48.934308: step 190, loss 0.547566.
Train: 2018-07-31T00:37:49.074900: step 191, loss 0.596793.
Train: 2018-07-31T00:37:49.215516: step 192, loss 0.581062.
Train: 2018-07-31T00:37:49.356085: step 193, loss 0.664074.
Train: 2018-07-31T00:37:49.512297: step 194, loss 0.552193.
Train: 2018-07-31T00:37:49.652913: step 195, loss 0.614344.
Train: 2018-07-31T00:37:49.793482: step 196, loss 0.608597.
Train: 2018-07-31T00:37:49.934073: step 197, loss 0.50061.
Train: 2018-07-31T00:37:50.074691: step 198, loss 0.623247.
Train: 2018-07-31T00:37:50.215283: step 199, loss 0.522683.
Train: 2018-07-31T00:37:50.355874: step 200, loss 0.553117.
Test: 2018-07-31T00:37:50.605791: step 200, loss 0.550552.
Train: 2018-07-31T00:37:51.324374: step 201, loss 0.556969.
Train: 2018-07-31T00:37:51.480587: step 202, loss 0.594371.
Train: 2018-07-31T00:37:51.621179: step 203, loss 0.541449.
Train: 2018-07-31T00:37:51.761795: step 204, loss 0.561051.
Train: 2018-07-31T00:37:51.902361: step 205, loss 0.516157.
Train: 2018-07-31T00:37:52.042955: step 206, loss 0.58511.
Train: 2018-07-31T00:37:52.199192: step 207, loss 0.56357.
Train: 2018-07-31T00:37:52.339759: step 208, loss 0.615088.
Train: 2018-07-31T00:37:52.480352: step 209, loss 0.61358.
Train: 2018-07-31T00:37:52.636564: step 210, loss 0.589734.
Test: 2018-07-31T00:37:52.870887: step 210, loss 0.550486.
Train: 2018-07-31T00:37:53.011478: step 211, loss 0.543527.
Train: 2018-07-31T00:37:53.167692: step 212, loss 0.517811.
Train: 2018-07-31T00:37:53.308283: step 213, loss 0.558077.
Train: 2018-07-31T00:37:53.448876: step 214, loss 0.618212.
Train: 2018-07-31T00:37:53.589492: step 215, loss 0.590243.
Train: 2018-07-31T00:37:53.730085: step 216, loss 0.588793.
Train: 2018-07-31T00:37:53.886272: step 217, loss 0.564835.
Train: 2018-07-31T00:37:54.026889: step 218, loss 0.603116.
Train: 2018-07-31T00:37:54.183079: step 219, loss 0.598962.
Train: 2018-07-31T00:37:54.323695: step 220, loss 0.54762.
Test: 2018-07-31T00:37:54.573642: step 220, loss 0.550926.
Train: 2018-07-31T00:37:54.714229: step 221, loss 0.546336.
Train: 2018-07-31T00:37:54.854795: step 222, loss 0.554817.
Train: 2018-07-31T00:37:54.995412: step 223, loss 0.613336.
Train: 2018-07-31T00:37:55.151601: step 224, loss 0.588285.
Train: 2018-07-31T00:37:55.292193: step 225, loss 0.563816.
Train: 2018-07-31T00:37:55.432822: step 226, loss 0.529705.
Train: 2018-07-31T00:37:55.573378: step 227, loss 0.59226.
Train: 2018-07-31T00:37:55.713988: step 228, loss 0.515104.
Train: 2018-07-31T00:37:55.854563: step 229, loss 0.565512.
Train: 2018-07-31T00:37:55.995154: step 230, loss 0.567309.
Test: 2018-07-31T00:37:56.245097: step 230, loss 0.549599.
Train: 2018-07-31T00:37:56.385687: step 231, loss 0.577882.
Train: 2018-07-31T00:37:56.526280: step 232, loss 0.521313.
Train: 2018-07-31T00:37:56.666870: step 233, loss 0.552441.
Train: 2018-07-31T00:37:56.807462: step 234, loss 0.599759.
Train: 2018-07-31T00:37:56.948055: step 235, loss 0.58849.
Train: 2018-07-31T00:37:57.088647: step 236, loss 0.567733.
Train: 2018-07-31T00:37:57.244861: step 237, loss 0.533353.
Train: 2018-07-31T00:37:57.385452: step 238, loss 0.576144.
Train: 2018-07-31T00:37:57.526046: step 239, loss 0.614137.
Train: 2018-07-31T00:37:57.666662: step 240, loss 0.527587.
Test: 2018-07-31T00:37:57.916631: step 240, loss 0.548728.
Train: 2018-07-31T00:37:58.057172: step 241, loss 0.610189.
Train: 2018-07-31T00:37:58.197780: step 242, loss 0.565263.
Train: 2018-07-31T00:37:58.338380: step 243, loss 0.507382.
Train: 2018-07-31T00:37:58.494570: step 244, loss 0.588941.
Train: 2018-07-31T00:37:58.635161: step 245, loss 0.586263.
Train: 2018-07-31T00:37:58.791374: step 246, loss 0.634624.
Train: 2018-07-31T00:37:58.931991: step 247, loss 0.565862.
Train: 2018-07-31T00:37:59.072558: step 248, loss 0.592185.
Train: 2018-07-31T00:37:59.213151: step 249, loss 0.551721.
Train: 2018-07-31T00:37:59.353743: step 250, loss 0.574241.
Test: 2018-07-31T00:37:59.603685: step 250, loss 0.551253.
Train: 2018-07-31T00:37:59.744328: step 251, loss 0.585879.
Train: 2018-07-31T00:37:59.900491: step 252, loss 0.527194.
Train: 2018-07-31T00:38:00.041105: step 253, loss 0.535753.
Train: 2018-07-31T00:38:00.181698: step 254, loss 0.525311.
Train: 2018-07-31T00:38:00.322283: step 255, loss 0.589395.
Train: 2018-07-31T00:38:00.478479: step 256, loss 0.503922.
Train: 2018-07-31T00:38:00.619097: step 257, loss 0.491866.
Train: 2018-07-31T00:38:00.775285: step 258, loss 0.572048.
Train: 2018-07-31T00:38:00.915876: step 259, loss 0.524145.
Train: 2018-07-31T00:38:01.072091: step 260, loss 0.606603.
Test: 2018-07-31T00:38:01.306412: step 260, loss 0.548071.
Train: 2018-07-31T00:38:01.462624: step 261, loss 0.545957.
Train: 2018-07-31T00:38:01.603239: step 262, loss 0.50522.
Train: 2018-07-31T00:38:01.759429: step 263, loss 0.509383.
Train: 2018-07-31T00:38:01.900021: step 264, loss 0.584893.
Train: 2018-07-31T00:38:02.040631: step 265, loss 0.552122.
Train: 2018-07-31T00:38:02.181205: step 266, loss 0.611402.
Train: 2018-07-31T00:38:02.321797: step 267, loss 0.524767.
Train: 2018-07-31T00:38:02.478012: step 268, loss 0.527466.
Train: 2018-07-31T00:38:02.618627: step 269, loss 0.566846.
Train: 2018-07-31T00:38:02.759223: step 270, loss 0.553463.
Test: 2018-07-31T00:38:03.009137: step 270, loss 0.547499.
Train: 2018-07-31T00:38:03.149752: step 271, loss 0.592212.
Train: 2018-07-31T00:38:03.290344: step 272, loss 0.585676.
Train: 2018-07-31T00:38:03.430913: step 273, loss 0.482343.
Train: 2018-07-31T00:38:03.571505: step 274, loss 0.572001.
Train: 2018-07-31T00:38:03.727718: step 275, loss 0.588752.
Train: 2018-07-31T00:38:03.868310: step 276, loss 0.507776.
Train: 2018-07-31T00:38:04.008902: step 277, loss 0.552558.
Train: 2018-07-31T00:38:04.149493: step 278, loss 0.566013.
Train: 2018-07-31T00:38:04.290099: step 279, loss 0.536183.
Train: 2018-07-31T00:38:04.446300: step 280, loss 0.552068.
Test: 2018-07-31T00:38:04.680649: step 280, loss 0.548355.
Train: 2018-07-31T00:38:04.836849: step 281, loss 0.53958.
Train: 2018-07-31T00:38:04.993048: step 282, loss 0.570377.
Train: 2018-07-31T00:38:05.133639: step 283, loss 0.540573.
Train: 2018-07-31T00:38:05.274248: step 284, loss 0.495629.
Train: 2018-07-31T00:38:05.414823: step 285, loss 0.554746.
Train: 2018-07-31T00:38:05.555414: step 286, loss 0.499255.
Train: 2018-07-31T00:38:05.696007: step 287, loss 0.593103.
Train: 2018-07-31T00:38:05.852220: step 288, loss 0.467027.
Train: 2018-07-31T00:38:05.992812: step 289, loss 0.571534.
Train: 2018-07-31T00:38:06.133404: step 290, loss 0.557299.
Test: 2018-07-31T00:38:06.383347: step 290, loss 0.547603.
Train: 2018-07-31T00:38:06.523964: step 291, loss 0.553072.
Train: 2018-07-31T00:38:06.664558: step 292, loss 0.565243.
Train: 2018-07-31T00:38:06.805122: step 293, loss 0.577089.
Train: 2018-07-31T00:38:06.961336: step 294, loss 0.607706.
Train: 2018-07-31T00:38:07.086331: step 295, loss 0.531353.
Train: 2018-07-31T00:38:07.242520: step 296, loss 0.522029.
Train: 2018-07-31T00:38:07.383111: step 297, loss 0.53029.
Train: 2018-07-31T00:38:07.523704: step 298, loss 0.545284.
Train: 2018-07-31T00:38:07.664320: step 299, loss 0.53597.
Train: 2018-07-31T00:38:07.804889: step 300, loss 0.554907.
Test: 2018-07-31T00:38:08.054831: step 300, loss 0.547814.
Train: 2018-07-31T00:38:08.742169: step 301, loss 0.520331.
Train: 2018-07-31T00:38:08.882762: step 302, loss 0.528807.
Train: 2018-07-31T00:38:09.023357: step 303, loss 0.55737.
Train: 2018-07-31T00:38:09.179567: step 304, loss 0.666924.
Train: 2018-07-31T00:38:09.320158: step 305, loss 0.551864.
Train: 2018-07-31T00:38:09.460752: step 306, loss 0.557639.
Train: 2018-07-31T00:38:09.601368: step 307, loss 0.623305.
Train: 2018-07-31T00:38:09.757557: step 308, loss 0.53759.
Train: 2018-07-31T00:38:09.898154: step 309, loss 0.537668.
Train: 2018-07-31T00:38:10.038765: step 310, loss 0.479631.
Test: 2018-07-31T00:38:10.288713: step 310, loss 0.54871.
Train: 2018-07-31T00:38:10.444896: step 311, loss 0.650415.
Train: 2018-07-31T00:38:10.601108: step 312, loss 0.54259.
Train: 2018-07-31T00:38:10.741709: step 313, loss 0.551919.
Train: 2018-07-31T00:38:10.882317: step 314, loss 0.542799.
Train: 2018-07-31T00:38:11.038505: step 315, loss 0.518305.
Train: 2018-07-31T00:38:11.194744: step 316, loss 0.556794.
Train: 2018-07-31T00:38:11.335312: step 317, loss 0.551003.
Train: 2018-07-31T00:38:11.475905: step 318, loss 0.555706.
Train: 2018-07-31T00:38:11.616520: step 319, loss 0.656314.
Train: 2018-07-31T00:38:11.772710: step 320, loss 0.524171.
Test: 2018-07-31T00:38:12.007029: step 320, loss 0.548838.
Train: 2018-07-31T00:38:12.163244: step 321, loss 0.597789.
Train: 2018-07-31T00:38:12.303859: step 322, loss 0.553703.
Train: 2018-07-31T00:38:12.444451: step 323, loss 0.598698.
Train: 2018-07-31T00:38:12.585043: step 324, loss 0.498149.
Train: 2018-07-31T00:38:12.741233: step 325, loss 0.501209.
Train: 2018-07-31T00:38:12.881824: step 326, loss 0.534101.
Train: 2018-07-31T00:38:13.038039: step 327, loss 0.548485.
Train: 2018-07-31T00:38:13.194251: step 328, loss 0.586668.
Train: 2018-07-31T00:38:13.334844: step 329, loss 0.601172.
Train: 2018-07-31T00:38:13.475459: step 330, loss 0.564875.
Test: 2018-07-31T00:38:13.725376: step 330, loss 0.548292.
Train: 2018-07-31T00:38:13.865993: step 331, loss 0.609613.
Train: 2018-07-31T00:38:14.022183: step 332, loss 0.521998.
Train: 2018-07-31T00:38:14.162799: step 333, loss 0.575931.
Train: 2018-07-31T00:38:14.303391: step 334, loss 0.593131.
Train: 2018-07-31T00:38:14.443957: step 335, loss 0.566465.
Train: 2018-07-31T00:38:14.600172: step 336, loss 0.574038.
Train: 2018-07-31T00:38:14.725143: step 337, loss 0.484227.
Train: 2018-07-31T00:38:14.865759: step 338, loss 0.5026.
Train: 2018-07-31T00:38:15.021948: step 339, loss 0.571954.
Train: 2018-07-31T00:38:15.162540: step 340, loss 0.57045.
Test: 2018-07-31T00:38:15.411933: step 340, loss 0.548707.
Train: 2018-07-31T00:38:15.552524: step 341, loss 0.527062.
Train: 2018-07-31T00:38:15.708763: step 342, loss 0.506958.
Train: 2018-07-31T00:38:15.849331: step 343, loss 0.553321.
Train: 2018-07-31T00:38:15.989921: step 344, loss 0.573082.
Train: 2018-07-31T00:38:16.130514: step 345, loss 0.572921.
Train: 2018-07-31T00:38:16.271124: step 346, loss 0.568038.
Train: 2018-07-31T00:38:16.411698: step 347, loss 0.557401.
Train: 2018-07-31T00:38:16.552290: step 348, loss 0.524602.
Train: 2018-07-31T00:38:16.692882: step 349, loss 0.547371.
Train: 2018-07-31T00:38:16.849097: step 350, loss 0.508891.
Test: 2018-07-31T00:38:17.083415: step 350, loss 0.54774.
Train: 2018-07-31T00:38:17.239629: step 351, loss 0.549238.
Train: 2018-07-31T00:38:17.380223: step 352, loss 0.556001.
Train: 2018-07-31T00:38:17.520814: step 353, loss 0.576977.
Train: 2018-07-31T00:38:17.661430: step 354, loss 0.560468.
Train: 2018-07-31T00:38:17.801997: step 355, loss 0.575688.
Train: 2018-07-31T00:38:17.942589: step 356, loss 0.492312.
Train: 2018-07-31T00:38:18.083206: step 357, loss 0.52537.
Train: 2018-07-31T00:38:18.239396: step 358, loss 0.544483.
Train: 2018-07-31T00:38:18.380015: step 359, loss 0.543101.
Train: 2018-07-31T00:38:18.520584: step 360, loss 0.524338.
Test: 2018-07-31T00:38:18.770521: step 360, loss 0.547558.
Train: 2018-07-31T00:38:18.911113: step 361, loss 0.603506.
Train: 2018-07-31T00:38:19.051731: step 362, loss 0.591796.
Train: 2018-07-31T00:38:19.192321: step 363, loss 0.601506.
Train: 2018-07-31T00:38:19.348538: step 364, loss 0.603386.
Train: 2018-07-31T00:38:19.489102: step 365, loss 0.567187.
Train: 2018-07-31T00:38:19.629696: step 366, loss 0.591362.
Train: 2018-07-31T00:38:19.770334: step 367, loss 0.551308.
Train: 2018-07-31T00:38:19.910878: step 368, loss 0.569812.
Train: 2018-07-31T00:38:20.051495: step 369, loss 0.606117.
Train: 2018-07-31T00:38:20.192063: step 370, loss 0.576593.
Test: 2018-07-31T00:38:20.442035: step 370, loss 0.549703.
Train: 2018-07-31T00:38:20.598219: step 371, loss 0.583025.
Train: 2018-07-31T00:38:20.738827: step 372, loss 0.548379.
Train: 2018-07-31T00:38:20.879401: step 373, loss 0.541046.
Train: 2018-07-31T00:38:21.020019: step 374, loss 0.572796.
Train: 2018-07-31T00:38:21.160612: step 375, loss 0.539386.
Train: 2018-07-31T00:38:21.301177: step 376, loss 0.519101.
Train: 2018-07-31T00:38:21.441788: step 377, loss 0.563394.
Train: 2018-07-31T00:38:21.582362: step 378, loss 0.627261.
Train: 2018-07-31T00:38:21.722954: step 379, loss 0.548572.
Train: 2018-07-31T00:38:21.863546: step 380, loss 0.610952.
Test: 2018-07-31T00:38:22.113518: step 380, loss 0.550726.
Train: 2018-07-31T00:38:22.254081: step 381, loss 0.525474.
Train: 2018-07-31T00:38:22.394697: step 382, loss 0.64511.
Train: 2018-07-31T00:38:22.550887: step 383, loss 0.55255.
Train: 2018-07-31T00:38:22.691479: step 384, loss 0.571316.
Train: 2018-07-31T00:38:22.832095: step 385, loss 0.533942.
Train: 2018-07-31T00:38:22.988308: step 386, loss 0.543306.
Train: 2018-07-31T00:38:23.128875: step 387, loss 0.567758.
Train: 2018-07-31T00:38:23.269467: step 388, loss 0.595237.
Train: 2018-07-31T00:38:23.425680: step 389, loss 0.655561.
Train: 2018-07-31T00:38:23.566272: step 390, loss 0.556263.
Test: 2018-07-31T00:38:23.800595: step 390, loss 0.550532.
Train: 2018-07-31T00:38:23.956823: step 391, loss 0.571388.
Train: 2018-07-31T00:38:24.097423: step 392, loss 0.591186.
Train: 2018-07-31T00:38:24.237990: step 393, loss 0.560325.
Train: 2018-07-31T00:38:24.394212: step 394, loss 0.534986.
Train: 2018-07-31T00:38:24.534796: step 395, loss 0.524814.
Train: 2018-07-31T00:38:24.691010: step 396, loss 0.562923.
Train: 2018-07-31T00:38:24.831601: step 397, loss 0.57723.
Train: 2018-07-31T00:38:24.972218: step 398, loss 0.57153.
Train: 2018-07-31T00:38:25.112787: step 399, loss 0.563519.
Train: 2018-07-31T00:38:25.253411: step 400, loss 0.618801.
Test: 2018-07-31T00:38:25.503344: step 400, loss 0.549726.
Train: 2018-07-31T00:38:26.221932: step 401, loss 0.507187.
Train: 2018-07-31T00:38:26.362492: step 402, loss 0.559139.
Train: 2018-07-31T00:38:26.503085: step 403, loss 0.587222.
Train: 2018-07-31T00:38:26.643676: step 404, loss 0.577962.
Train: 2018-07-31T00:38:26.784269: step 405, loss 0.56326.
Train: 2018-07-31T00:38:26.924885: step 406, loss 0.490814.
Train: 2018-07-31T00:38:27.065478: step 407, loss 0.531829.
Train: 2018-07-31T00:38:27.221666: step 408, loss 0.602607.
Train: 2018-07-31T00:38:27.362259: step 409, loss 0.54198.
Train: 2018-07-31T00:38:27.518474: step 410, loss 0.554675.
Test: 2018-07-31T00:38:27.752823: step 410, loss 0.548212.
Train: 2018-07-31T00:38:27.909006: step 411, loss 0.545694.
Train: 2018-07-31T00:38:28.049597: step 412, loss 0.512331.
Train: 2018-07-31T00:38:28.205812: step 413, loss 0.575631.
Train: 2018-07-31T00:38:28.346403: step 414, loss 0.50806.
Train: 2018-07-31T00:38:28.486996: step 415, loss 0.618885.
Train: 2018-07-31T00:38:28.627589: step 416, loss 0.54275.
Train: 2018-07-31T00:38:28.768179: step 417, loss 0.605346.
Train: 2018-07-31T00:38:28.908772: step 418, loss 0.656416.
Train: 2018-07-31T00:38:29.049363: step 419, loss 0.54314.
Train: 2018-07-31T00:38:29.205577: step 420, loss 0.498346.
Test: 2018-07-31T00:38:29.455549: step 420, loss 0.548008.
Train: 2018-07-31T00:38:29.596112: step 421, loss 0.592225.
Train: 2018-07-31T00:38:29.736702: step 422, loss 0.610189.
Train: 2018-07-31T00:38:29.892916: step 423, loss 0.560862.
Train: 2018-07-31T00:38:30.033509: step 424, loss 0.548259.
Train: 2018-07-31T00:38:30.174124: step 425, loss 0.585981.
Train: 2018-07-31T00:38:30.330315: step 426, loss 0.532187.
Train: 2018-07-31T00:38:30.470907: step 427, loss 0.545362.
Train: 2018-07-31T00:38:30.611499: step 428, loss 0.548053.
Train: 2018-07-31T00:38:30.752091: step 429, loss 0.556073.
Train: 2018-07-31T00:38:30.892681: step 430, loss 0.646508.
Test: 2018-07-31T00:38:31.142654: step 430, loss 0.549867.
Train: 2018-07-31T00:38:31.283216: step 431, loss 0.590793.
Train: 2018-07-31T00:38:31.423825: step 432, loss 0.558148.
Train: 2018-07-31T00:38:31.580021: step 433, loss 0.511451.
Train: 2018-07-31T00:38:31.720613: step 434, loss 0.582292.
Train: 2018-07-31T00:38:31.861206: step 435, loss 0.531525.
Train: 2018-07-31T00:38:32.001797: step 436, loss 0.640579.
Train: 2018-07-31T00:38:32.142390: step 437, loss 0.596624.
Train: 2018-07-31T00:38:32.298604: step 438, loss 0.486362.
Train: 2018-07-31T00:38:32.423599: step 439, loss 0.546806.
Train: 2018-07-31T00:38:32.579811: step 440, loss 0.615684.
Test: 2018-07-31T00:38:32.829730: step 440, loss 0.550621.
Train: 2018-07-31T00:38:32.970345: step 441, loss 0.559439.
Train: 2018-07-31T00:38:33.126534: step 442, loss 0.61652.
Train: 2018-07-31T00:38:33.267126: step 443, loss 0.577522.
Train: 2018-07-31T00:38:33.407719: step 444, loss 0.5184.
Train: 2018-07-31T00:38:33.548335: step 445, loss 0.550471.
Train: 2018-07-31T00:38:33.688903: step 446, loss 0.548197.
Train: 2018-07-31T00:38:33.829497: step 447, loss 0.582805.
Train: 2018-07-31T00:38:33.970086: step 448, loss 0.539529.
Train: 2018-07-31T00:38:34.110703: step 449, loss 0.569776.
Train: 2018-07-31T00:38:34.266892: step 450, loss 0.484782.
Test: 2018-07-31T00:38:34.501213: step 450, loss 0.54931.
Train: 2018-07-31T00:38:34.641805: step 451, loss 0.565459.
Train: 2018-07-31T00:38:34.798019: step 452, loss 0.572472.
Train: 2018-07-31T00:38:34.923012: step 453, loss 0.648039.
Train: 2018-07-31T00:38:35.063579: step 454, loss 0.517348.
Train: 2018-07-31T00:38:35.219795: step 455, loss 0.528131.
Train: 2018-07-31T00:38:35.360386: step 456, loss 0.575567.
Train: 2018-07-31T00:38:35.501003: step 457, loss 0.543492.
Train: 2018-07-31T00:38:35.641569: step 458, loss 0.652124.
Train: 2018-07-31T00:38:35.782162: step 459, loss 0.527745.
Train: 2018-07-31T00:38:35.922754: step 460, loss 0.604309.
Test: 2018-07-31T00:38:36.172726: step 460, loss 0.548523.
Train: 2018-07-31T00:38:36.313287: step 461, loss 0.557423.
Train: 2018-07-31T00:38:36.469519: step 462, loss 0.505865.
Train: 2018-07-31T00:38:36.610107: step 463, loss 0.545387.
Train: 2018-07-31T00:38:36.750686: step 464, loss 0.544263.
Train: 2018-07-31T00:38:36.891277: step 465, loss 0.645501.
Train: 2018-07-31T00:38:37.031894: step 466, loss 0.53034.
Train: 2018-07-31T00:38:37.172462: step 467, loss 0.53702.
Train: 2018-07-31T00:38:37.313052: step 468, loss 0.4877.
Train: 2018-07-31T00:38:37.469268: step 469, loss 0.547826.
Train: 2018-07-31T00:38:37.609884: step 470, loss 0.564947.
Test: 2018-07-31T00:38:37.859800: step 470, loss 0.548294.
Train: 2018-07-31T00:38:38.000417: step 471, loss 0.555232.
Train: 2018-07-31T00:38:38.156606: step 472, loss 0.543503.
Train: 2018-07-31T00:38:38.297198: step 473, loss 0.530465.
Train: 2018-07-31T00:38:38.437798: step 474, loss 0.565515.
Train: 2018-07-31T00:38:38.578383: step 475, loss 0.57371.
Train: 2018-07-31T00:38:38.718974: step 476, loss 0.556097.
Train: 2018-07-31T00:38:38.859567: step 477, loss 0.5547.
Train: 2018-07-31T00:38:39.015798: step 478, loss 0.570941.
Train: 2018-07-31T00:38:39.156376: step 479, loss 0.512048.
Train: 2018-07-31T00:38:39.312586: step 480, loss 0.468738.
Test: 2018-07-31T00:38:39.546931: step 480, loss 0.547798.
Train: 2018-07-31T00:38:39.703118: step 481, loss 0.510236.
Train: 2018-07-31T00:38:39.843711: step 482, loss 0.503589.
Train: 2018-07-31T00:38:39.984303: step 483, loss 0.533614.
Train: 2018-07-31T00:38:40.124894: step 484, loss 0.59865.
Train: 2018-07-31T00:38:40.265487: step 485, loss 0.582455.
Train: 2018-07-31T00:38:40.406079: step 486, loss 0.566112.
Train: 2018-07-31T00:38:40.546671: step 487, loss 0.543408.
Train: 2018-07-31T00:38:40.702886: step 488, loss 0.556314.
Train: 2018-07-31T00:38:40.843478: step 489, loss 0.672179.
Train: 2018-07-31T00:38:40.984070: step 490, loss 0.554859.
Test: 2018-07-31T00:38:41.234012: step 490, loss 0.547656.
Train: 2018-07-31T00:38:41.374627: step 491, loss 0.577271.
Train: 2018-07-31T00:38:41.515194: step 492, loss 0.581571.
Train: 2018-07-31T00:38:41.671409: step 493, loss 0.545648.
Train: 2018-07-31T00:38:41.812001: step 494, loss 0.556491.
Train: 2018-07-31T00:38:41.952593: step 495, loss 0.60338.
Train: 2018-07-31T00:38:42.093186: step 496, loss 0.523367.
Train: 2018-07-31T00:38:42.249422: step 497, loss 0.643123.
Train: 2018-07-31T00:38:42.389989: step 498, loss 0.557517.
Train: 2018-07-31T00:38:42.530609: step 499, loss 0.54114.
Train: 2018-07-31T00:38:42.686820: step 500, loss 0.538732.
Test: 2018-07-31T00:38:42.936738: step 500, loss 0.550424.
Train: 2018-07-31T00:38:43.670948: step 501, loss 0.533971.
Train: 2018-07-31T00:38:43.827154: step 502, loss 0.610331.
Train: 2018-07-31T00:38:43.967746: step 503, loss 0.612205.
Train: 2018-07-31T00:38:44.108337: step 504, loss 0.554731.
Train: 2018-07-31T00:38:44.248947: step 505, loss 0.572698.
Train: 2018-07-31T00:38:44.389546: step 506, loss 0.585662.
Train: 2018-07-31T00:38:44.545735: step 507, loss 0.589898.
Train: 2018-07-31T00:38:44.686329: step 508, loss 0.578462.
Train: 2018-07-31T00:38:44.826920: step 509, loss 0.608282.
Train: 2018-07-31T00:38:44.967510: step 510, loss 0.563472.
Test: 2018-07-31T00:38:45.217483: step 510, loss 0.552164.
Train: 2018-07-31T00:38:45.358045: step 511, loss 0.542331.
Train: 2018-07-31T00:38:45.514282: step 512, loss 0.547478.
Train: 2018-07-31T00:38:45.654851: step 513, loss 0.512857.
Train: 2018-07-31T00:38:45.795442: step 514, loss 0.571947.
Train: 2018-07-31T00:38:45.936033: step 515, loss 0.544317.
Train: 2018-07-31T00:38:46.076654: step 516, loss 0.488417.
Train: 2018-07-31T00:38:46.232842: step 517, loss 0.517728.
Train: 2018-07-31T00:38:46.373433: step 518, loss 0.584653.
Train: 2018-07-31T00:38:46.514025: step 519, loss 0.523772.
Train: 2018-07-31T00:38:46.654617: step 520, loss 0.544407.
Test: 2018-07-31T00:38:46.888962: step 520, loss 0.548996.
Train: 2018-07-31T00:38:47.045150: step 521, loss 0.545526.
Train: 2018-07-31T00:38:47.185741: step 522, loss 0.518264.
Train: 2018-07-31T00:38:47.341956: step 523, loss 0.607291.
Train: 2018-07-31T00:38:47.482547: step 524, loss 0.497942.
Train: 2018-07-31T00:38:47.623139: step 525, loss 0.588377.
Train: 2018-07-31T00:38:47.763731: step 526, loss 0.571824.
Train: 2018-07-31T00:38:47.904348: step 527, loss 0.474014.
Train: 2018-07-31T00:38:48.060556: step 528, loss 0.548972.
Train: 2018-07-31T00:38:48.201154: step 529, loss 0.6128.
Train: 2018-07-31T00:38:48.341746: step 530, loss 0.640388.
Test: 2018-07-31T00:38:48.591663: step 530, loss 0.547562.
Train: 2018-07-31T00:38:48.732256: step 531, loss 0.494969.
Train: 2018-07-31T00:38:48.872861: step 532, loss 0.545344.
Train: 2018-07-31T00:38:49.013464: step 533, loss 0.534594.
Train: 2018-07-31T00:38:49.154055: step 534, loss 0.546646.
Train: 2018-07-31T00:38:49.310244: step 535, loss 0.519604.
Train: 2018-07-31T00:38:49.466493: step 536, loss 0.645401.
Train: 2018-07-31T00:38:49.607074: step 537, loss 0.581168.
Train: 2018-07-31T00:38:49.747647: step 538, loss 0.521451.
Train: 2018-07-31T00:38:49.888251: step 539, loss 0.622288.
Train: 2018-07-31T00:38:50.044449: step 540, loss 0.601622.
Test: 2018-07-31T00:38:50.278769: step 540, loss 0.548118.
Train: 2018-07-31T00:38:50.419377: step 541, loss 0.537011.
Train: 2018-07-31T00:38:50.559978: step 542, loss 0.514766.
Train: 2018-07-31T00:38:50.700544: step 543, loss 0.511091.
Train: 2018-07-31T00:38:50.841136: step 544, loss 0.554196.
Train: 2018-07-31T00:38:50.981728: step 545, loss 0.61034.
Train: 2018-07-31T00:38:51.122320: step 546, loss 0.57871.
Train: 2018-07-31T00:38:51.278534: step 547, loss 0.609878.
Train: 2018-07-31T00:38:51.419126: step 548, loss 0.569727.
Train: 2018-07-31T00:38:51.559716: step 549, loss 0.594667.
Train: 2018-07-31T00:38:51.715956: step 550, loss 0.605761.
Test: 2018-07-31T00:38:51.950282: step 550, loss 0.549727.
Train: 2018-07-31T00:38:52.106465: step 551, loss 0.490781.
Train: 2018-07-31T00:38:52.247056: step 552, loss 0.612621.
Train: 2018-07-31T00:38:52.387673: step 553, loss 0.533342.
Train: 2018-07-31T00:38:52.528265: step 554, loss 0.579218.
Train: 2018-07-31T00:38:52.684454: step 555, loss 0.570959.
Train: 2018-07-31T00:38:52.825071: step 556, loss 0.610022.
Train: 2018-07-31T00:38:52.965662: step 557, loss 0.547086.
Train: 2018-07-31T00:38:53.106229: step 558, loss 0.581148.
Train: 2018-07-31T00:38:53.262444: step 559, loss 0.587348.
Train: 2018-07-31T00:38:53.403037: step 560, loss 0.601462.
Test: 2018-07-31T00:38:53.637387: step 560, loss 0.551016.
Train: 2018-07-31T00:38:53.793569: step 561, loss 0.579569.
Train: 2018-07-31T00:38:53.934161: step 562, loss 0.549366.
Train: 2018-07-31T00:38:54.074753: step 563, loss 0.510029.
Train: 2018-07-31T00:38:54.230967: step 564, loss 0.556366.
Train: 2018-07-31T00:38:54.371560: step 565, loss 0.595362.
Train: 2018-07-31T00:38:54.512152: step 566, loss 0.558285.
Train: 2018-07-31T00:38:54.652767: step 567, loss 0.593856.
Train: 2018-07-31T00:38:54.793360: step 568, loss 0.594236.
Train: 2018-07-31T00:38:54.933927: step 569, loss 0.562724.
Train: 2018-07-31T00:38:55.074519: step 570, loss 0.541157.
Test: 2018-07-31T00:38:55.324462: step 570, loss 0.550822.
Train: 2018-07-31T00:38:55.465052: step 571, loss 0.603157.
Train: 2018-07-31T00:38:55.621290: step 572, loss 0.543565.
Train: 2018-07-31T00:38:55.746263: step 573, loss 0.581042.
Train: 2018-07-31T00:38:55.902451: step 574, loss 0.548825.
Train: 2018-07-31T00:38:56.043042: step 575, loss 0.586593.
Train: 2018-07-31T00:38:56.183658: step 576, loss 0.508753.
Train: 2018-07-31T00:38:56.339849: step 577, loss 0.537368.
Train: 2018-07-31T00:38:56.480440: step 578, loss 0.57187.
Train: 2018-07-31T00:38:56.621033: step 579, loss 0.570053.
Train: 2018-07-31T00:38:56.761623: step 580, loss 0.508299.
Test: 2018-07-31T00:38:57.011567: step 580, loss 0.549564.
Train: 2018-07-31T00:38:57.152170: step 581, loss 0.547162.
Train: 2018-07-31T00:38:57.292751: step 582, loss 0.505598.
Train: 2018-07-31T00:38:57.433341: step 583, loss 0.577323.
Train: 2018-07-31T00:38:57.573933: step 584, loss 0.515822.
Train: 2018-07-31T00:38:57.714525: step 585, loss 0.53956.
Train: 2018-07-31T00:38:57.855143: step 586, loss 0.620157.
Train: 2018-07-31T00:38:57.995711: step 587, loss 0.561834.
Train: 2018-07-31T00:38:58.136302: step 588, loss 0.586372.
Train: 2018-07-31T00:38:58.276915: step 589, loss 0.628817.
Train: 2018-07-31T00:38:58.433108: step 590, loss 0.520586.
Test: 2018-07-31T00:38:58.667428: step 590, loss 0.54811.
Train: 2018-07-31T00:38:58.808045: step 591, loss 0.604448.
Train: 2018-07-31T00:38:58.964234: step 592, loss 0.596283.
Train: 2018-07-31T00:38:59.104826: step 593, loss 0.619852.
Train: 2018-07-31T00:38:59.245418: step 594, loss 0.593973.
Train: 2018-07-31T00:38:59.386034: step 595, loss 0.553595.
Train: 2018-07-31T00:38:59.526601: step 596, loss 0.579553.
Train: 2018-07-31T00:38:59.667194: step 597, loss 0.545781.
Train: 2018-07-31T00:38:59.807785: step 598, loss 0.661689.
Train: 2018-07-31T00:38:59.964025: step 599, loss 0.603473.
Train: 2018-07-31T00:39:00.104591: step 600, loss 0.595936.
Test: 2018-07-31T00:39:00.354564: step 600, loss 0.54983.
Train: 2018-07-31T00:39:01.073116: step 601, loss 0.507668.
Train: 2018-07-31T00:39:01.213732: step 602, loss 0.58473.
Train: 2018-07-31T00:39:01.354323: step 603, loss 0.548648.
Train: 2018-07-31T00:39:01.494891: step 604, loss 0.5989.
Train: 2018-07-31T00:39:01.635485: step 605, loss 0.627375.
Train: 2018-07-31T00:39:01.776099: step 606, loss 0.583614.
Train: 2018-07-31T00:39:01.932314: step 607, loss 0.578039.
Train: 2018-07-31T00:39:02.072882: step 608, loss 0.54256.
Train: 2018-07-31T00:39:02.213485: step 609, loss 0.607628.
Train: 2018-07-31T00:39:02.369686: step 610, loss 0.527013.
Test: 2018-07-31T00:39:02.604033: step 610, loss 0.551823.
Train: 2018-07-31T00:39:02.760220: step 611, loss 0.594906.
Train: 2018-07-31T00:39:02.900831: step 612, loss 0.609406.
Train: 2018-07-31T00:39:03.041427: step 613, loss 0.599007.
Train: 2018-07-31T00:39:03.182020: step 614, loss 0.593744.
Train: 2018-07-31T00:39:03.322613: step 615, loss 0.565118.
Train: 2018-07-31T00:39:03.463204: step 616, loss 0.571974.
Train: 2018-07-31T00:39:03.603796: step 617, loss 0.609036.
Train: 2018-07-31T00:39:03.744364: step 618, loss 0.609217.
Train: 2018-07-31T00:39:03.900578: step 619, loss 0.543479.
Train: 2018-07-31T00:39:04.041169: step 620, loss 0.499935.
Test: 2018-07-31T00:39:04.275495: step 620, loss 0.552542.
Train: 2018-07-31T00:39:04.416082: step 621, loss 0.513783.
Train: 2018-07-31T00:39:04.556698: step 622, loss 0.578587.
Train: 2018-07-31T00:39:04.697291: step 623, loss 0.549813.
Train: 2018-07-31T00:39:04.853481: step 624, loss 0.617695.
Train: 2018-07-31T00:39:04.994096: step 625, loss 0.571382.
Train: 2018-07-31T00:39:05.134664: step 626, loss 0.526142.
Train: 2018-07-31T00:39:05.290878: step 627, loss 0.564318.
Train: 2018-07-31T00:39:05.431468: step 628, loss 0.540981.
Train: 2018-07-31T00:39:05.572076: step 629, loss 0.524999.
Train: 2018-07-31T00:39:05.728276: step 630, loss 0.547343.
Test: 2018-07-31T00:39:05.962597: step 630, loss 0.550082.
Train: 2018-07-31T00:39:06.118808: step 631, loss 0.549923.
Train: 2018-07-31T00:39:06.259401: step 632, loss 0.587621.
Train: 2018-07-31T00:39:06.415614: step 633, loss 0.562437.
Train: 2018-07-31T00:39:06.556206: step 634, loss 0.548577.
Train: 2018-07-31T00:39:06.712454: step 635, loss 0.555442.
Train: 2018-07-31T00:39:06.853036: step 636, loss 0.571816.
Train: 2018-07-31T00:39:06.993604: step 637, loss 0.456776.
Train: 2018-07-31T00:39:07.134196: step 638, loss 0.465099.
Train: 2018-07-31T00:39:07.306030: step 639, loss 0.445086.
Train: 2018-07-31T00:39:07.446622: step 640, loss 0.511672.
Test: 2018-07-31T00:39:07.696564: step 640, loss 0.547818.
Train: 2018-07-31T00:39:07.884044: step 641, loss 0.649637.
Train: 2018-07-31T00:39:08.024636: step 642, loss 0.580517.
Train: 2018-07-31T00:39:08.165228: step 643, loss 0.546427.
Train: 2018-07-31T00:39:08.305821: step 644, loss 0.550142.
Train: 2018-07-31T00:39:08.462010: step 645, loss 0.621051.
Train: 2018-07-31T00:39:08.618248: step 646, loss 0.510881.
Train: 2018-07-31T00:39:08.758814: step 647, loss 0.534754.
Train: 2018-07-31T00:39:08.899408: step 648, loss 0.552657.
Train: 2018-07-31T00:39:09.055621: step 649, loss 0.535465.
Train: 2018-07-31T00:39:09.196238: step 650, loss 0.670681.
Test: 2018-07-31T00:39:09.446156: step 650, loss 0.547545.
Train: 2018-07-31T00:39:09.586746: step 651, loss 0.536083.
Train: 2018-07-31T00:39:09.727338: step 652, loss 0.544814.
Train: 2018-07-31T00:39:09.867930: step 653, loss 0.609338.
Train: 2018-07-31T00:39:10.008522: step 654, loss 0.606548.
Train: 2018-07-31T00:39:10.149114: step 655, loss 0.570363.
Train: 2018-07-31T00:39:10.289705: step 656, loss 0.597304.
Train: 2018-07-31T00:39:10.430299: step 657, loss 0.52049.
Train: 2018-07-31T00:39:10.570890: step 658, loss 0.501544.
Train: 2018-07-31T00:39:10.727104: step 659, loss 0.612196.
Train: 2018-07-31T00:39:10.867697: step 660, loss 0.536642.
Test: 2018-07-31T00:39:11.117637: step 660, loss 0.548451.
Train: 2018-07-31T00:39:11.273851: step 661, loss 0.619292.
Train: 2018-07-31T00:39:11.414443: step 662, loss 0.513558.
Train: 2018-07-31T00:39:11.555035: step 663, loss 0.537548.
Train: 2018-07-31T00:39:11.711275: step 664, loss 0.49082.
Train: 2018-07-31T00:39:11.851841: step 665, loss 0.595802.
Train: 2018-07-31T00:39:12.008055: step 666, loss 0.482284.
Train: 2018-07-31T00:39:12.148648: step 667, loss 0.57021.
Train: 2018-07-31T00:39:12.304860: step 668, loss 0.554508.
Train: 2018-07-31T00:39:12.445477: step 669, loss 0.52953.
Train: 2018-07-31T00:39:12.586045: step 670, loss 0.70449.
Test: 2018-07-31T00:39:12.835988: step 670, loss 0.548676.
Train: 2018-07-31T00:39:12.992199: step 671, loss 0.606371.
Train: 2018-07-31T00:39:13.132792: step 672, loss 0.586818.
Train: 2018-07-31T00:39:13.273407: step 673, loss 0.547274.
Train: 2018-07-31T00:39:13.413975: step 674, loss 0.546587.
Train: 2018-07-31T00:39:13.554568: step 675, loss 0.594233.
Train: 2018-07-31T00:39:13.695159: step 676, loss 0.516539.
Train: 2018-07-31T00:39:13.835776: step 677, loss 0.548103.
Train: 2018-07-31T00:39:13.976368: step 678, loss 0.627218.
Train: 2018-07-31T00:39:14.132582: step 679, loss 0.539755.
Train: 2018-07-31T00:39:14.273148: step 680, loss 0.563115.
Test: 2018-07-31T00:39:14.523091: step 680, loss 0.549712.
Train: 2018-07-31T00:39:14.663707: step 681, loss 0.531873.
Train: 2018-07-31T00:39:14.819920: step 682, loss 0.563577.
Train: 2018-07-31T00:39:14.960512: step 683, loss 0.507188.
Train: 2018-07-31T00:39:15.116725: step 684, loss 0.516139.
Train: 2018-07-31T00:39:15.257294: step 685, loss 0.531382.
Train: 2018-07-31T00:39:15.397886: step 686, loss 0.537118.
Train: 2018-07-31T00:39:15.554123: step 687, loss 0.612152.
Train: 2018-07-31T00:39:15.694715: step 688, loss 0.555771.
Train: 2018-07-31T00:39:15.835283: step 689, loss 0.562571.
Train: 2018-07-31T00:39:15.991521: step 690, loss 0.611097.
Test: 2018-07-31T00:39:16.241462: step 690, loss 0.548981.
Train: 2018-07-31T00:39:16.397675: step 691, loss 0.490145.
Train: 2018-07-31T00:39:16.538243: step 692, loss 0.522119.
Train: 2018-07-31T00:39:16.678859: step 693, loss 0.553361.
Train: 2018-07-31T00:39:16.835049: step 694, loss 0.579344.
Train: 2018-07-31T00:39:16.991262: step 695, loss 0.552781.
Train: 2018-07-31T00:39:17.131854: step 696, loss 0.536824.
Train: 2018-07-31T00:39:17.272446: step 697, loss 0.594436.
Train: 2018-07-31T00:39:17.428660: step 698, loss 0.536921.
Train: 2018-07-31T00:39:17.569253: step 699, loss 0.570828.
Train: 2018-07-31T00:39:17.725466: step 700, loss 0.552954.
Test: 2018-07-31T00:39:17.975437: step 700, loss 0.548207.
Train: 2018-07-31T00:39:18.725232: step 701, loss 0.604809.
Train: 2018-07-31T00:39:18.865873: step 702, loss 0.553841.
Train: 2018-07-31T00:39:19.006439: step 703, loss 0.604918.
Train: 2018-07-31T00:39:19.162630: step 704, loss 0.528033.
Train: 2018-07-31T00:39:19.303221: step 705, loss 0.553756.
Train: 2018-07-31T00:39:19.443812: step 706, loss 0.52929.
Train: 2018-07-31T00:39:19.584405: step 707, loss 0.552423.
Train: 2018-07-31T00:39:19.724997: step 708, loss 0.479985.
Train: 2018-07-31T00:39:19.865590: step 709, loss 0.597828.
Train: 2018-07-31T00:39:20.006223: step 710, loss 0.605693.
Test: 2018-07-31T00:39:20.256122: step 710, loss 0.548152.
Train: 2018-07-31T00:39:20.412337: step 711, loss 0.486.
Train: 2018-07-31T00:39:20.552929: step 712, loss 0.545861.
Train: 2018-07-31T00:39:20.693545: step 713, loss 0.546046.
Train: 2018-07-31T00:39:20.834136: step 714, loss 0.64918.
Train: 2018-07-31T00:39:20.974704: step 715, loss 0.571419.
Train: 2018-07-31T00:39:21.130919: step 716, loss 0.5876.
Train: 2018-07-31T00:39:21.271512: step 717, loss 0.537329.
Train: 2018-07-31T00:39:21.412103: step 718, loss 0.628539.
Train: 2018-07-31T00:39:21.552718: step 719, loss 0.596905.
Train: 2018-07-31T00:39:21.693285: step 720, loss 0.520423.
Test: 2018-07-31T00:39:21.943229: step 720, loss 0.548662.
Train: 2018-07-31T00:39:22.099441: step 721, loss 0.521381.
Train: 2018-07-31T00:39:22.240033: step 722, loss 0.578768.
Train: 2018-07-31T00:39:22.380643: step 723, loss 0.612251.
Train: 2018-07-31T00:39:22.521244: step 724, loss 0.522071.
Train: 2018-07-31T00:39:22.661834: step 725, loss 0.522084.
Train: 2018-07-31T00:39:22.802426: step 726, loss 0.595167.
Train: 2018-07-31T00:39:22.958615: step 727, loss 0.620348.
Train: 2018-07-31T00:39:23.099231: step 728, loss 0.513514.
Train: 2018-07-31T00:39:23.239798: step 729, loss 0.618429.
Train: 2018-07-31T00:39:23.396036: step 730, loss 0.522842.
Test: 2018-07-31T00:39:23.630333: step 730, loss 0.549308.
Train: 2018-07-31T00:39:23.786547: step 731, loss 0.586664.
Train: 2018-07-31T00:39:23.927138: step 732, loss 0.635958.
Train: 2018-07-31T00:39:24.067755: step 733, loss 0.554744.
Train: 2018-07-31T00:39:24.223942: step 734, loss 0.579231.
Train: 2018-07-31T00:39:24.364537: step 735, loss 0.546244.
Train: 2018-07-31T00:39:24.520749: step 736, loss 0.562754.
Train: 2018-07-31T00:39:24.661365: step 737, loss 0.618461.
Train: 2018-07-31T00:39:24.817554: step 738, loss 0.625062.
Train: 2018-07-31T00:39:24.958148: step 739, loss 0.570928.
Train: 2018-07-31T00:39:25.098739: step 740, loss 0.581239.
Test: 2018-07-31T00:39:25.333060: step 740, loss 0.550345.
Train: 2018-07-31T00:39:25.473675: step 741, loss 0.555999.
Train: 2018-07-31T00:39:25.629890: step 742, loss 0.532715.
Train: 2018-07-31T00:39:25.786079: step 743, loss 0.563677.
Train: 2018-07-31T00:39:25.926670: step 744, loss 0.540592.
Train: 2018-07-31T00:39:26.067261: step 745, loss 0.555753.
Train: 2018-07-31T00:39:26.207879: step 746, loss 0.587514.
Train: 2018-07-31T00:39:26.364092: step 747, loss 0.594314.
Train: 2018-07-31T00:39:26.520281: step 748, loss 0.578265.
Train: 2018-07-31T00:39:26.645276: step 749, loss 0.571717.
Train: 2018-07-31T00:39:26.801489: step 750, loss 0.463118.
Test: 2018-07-31T00:39:27.051425: step 750, loss 0.550496.
Train: 2018-07-31T00:39:27.192023: step 751, loss 0.60228.
Train: 2018-07-31T00:39:27.348223: step 752, loss 0.556022.
Train: 2018-07-31T00:39:27.504425: step 753, loss 0.594596.
Train: 2018-07-31T00:39:27.660640: step 754, loss 0.554949.
Train: 2018-07-31T00:39:27.801255: step 755, loss 0.497463.
Train: 2018-07-31T00:39:27.941823: step 756, loss 0.555303.
Train: 2018-07-31T00:39:28.082414: step 757, loss 0.508141.
Train: 2018-07-31T00:39:28.223006: step 758, loss 0.603075.
Train: 2018-07-31T00:39:28.379245: step 759, loss 0.507043.
Train: 2018-07-31T00:39:28.519838: step 760, loss 0.619756.
Test: 2018-07-31T00:39:28.769765: step 760, loss 0.549321.
Train: 2018-07-31T00:39:28.910345: step 761, loss 0.587364.
Train: 2018-07-31T00:39:29.066561: step 762, loss 0.595034.
Train: 2018-07-31T00:39:29.207151: step 763, loss 0.57141.
Train: 2018-07-31T00:39:29.363365: step 764, loss 0.554746.
Train: 2018-07-31T00:39:29.488336: step 765, loss 0.569961.
Train: 2018-07-31T00:39:29.628928: step 766, loss 0.562149.
Train: 2018-07-31T00:39:29.769520: step 767, loss 0.530879.
Train: 2018-07-31T00:39:29.925734: step 768, loss 0.644005.
Train: 2018-07-31T00:39:30.066325: step 769, loss 0.51407.
Train: 2018-07-31T00:39:30.206942: step 770, loss 0.513987.
Test: 2018-07-31T00:39:30.456859: step 770, loss 0.549104.
Train: 2018-07-31T00:39:30.597475: step 771, loss 0.505375.
Train: 2018-07-31T00:39:30.753665: step 772, loss 0.545494.
Train: 2018-07-31T00:39:30.894255: step 773, loss 0.611404.
Train: 2018-07-31T00:39:31.034850: step 774, loss 0.521697.
Train: 2018-07-31T00:39:31.175441: step 775, loss 0.571158.
Train: 2018-07-31T00:39:31.316034: step 776, loss 0.539415.
Train: 2018-07-31T00:39:31.456649: step 777, loss 0.587777.
Train: 2018-07-31T00:39:31.597241: step 778, loss 0.579201.
Train: 2018-07-31T00:39:31.737808: step 779, loss 0.612319.
Train: 2018-07-31T00:39:31.878420: step 780, loss 0.511875.
Test: 2018-07-31T00:39:32.128343: step 780, loss 0.548558.
Train: 2018-07-31T00:39:32.268935: step 781, loss 0.579559.
Train: 2018-07-31T00:39:32.409526: step 782, loss 0.55445.
Train: 2018-07-31T00:39:32.565741: step 783, loss 0.55461.
Train: 2018-07-31T00:39:32.706334: step 784, loss 0.48762.
Train: 2018-07-31T00:39:32.846925: step 785, loss 0.628598.
Train: 2018-07-31T00:39:32.987535: step 786, loss 0.604444.
Train: 2018-07-31T00:39:33.143757: step 787, loss 0.454315.
Train: 2018-07-31T00:39:33.284321: step 788, loss 0.62103.
Train: 2018-07-31T00:39:33.424920: step 789, loss 0.553816.
Train: 2018-07-31T00:39:33.565507: step 790, loss 0.554214.
Test: 2018-07-31T00:39:33.799857: step 790, loss 0.548519.
Train: 2018-07-31T00:39:33.956040: step 791, loss 0.570057.
Train: 2018-07-31T00:39:34.096632: step 792, loss 0.487961.
Train: 2018-07-31T00:39:34.237223: step 793, loss 0.545451.
Train: 2018-07-31T00:39:34.393438: step 794, loss 0.512201.
Train: 2018-07-31T00:39:34.549650: step 795, loss 0.570103.
Train: 2018-07-31T00:39:34.690267: step 796, loss 0.503893.
Train: 2018-07-31T00:39:34.830834: step 797, loss 0.604657.
Train: 2018-07-31T00:39:34.971426: step 798, loss 0.587686.
Train: 2018-07-31T00:39:35.127639: step 799, loss 0.612698.
Train: 2018-07-31T00:39:35.268232: step 800, loss 0.596988.
Test: 2018-07-31T00:39:35.502554: step 800, loss 0.548197.
Train: 2018-07-31T00:39:36.346129: step 801, loss 0.545352.
Train: 2018-07-31T00:39:36.486721: step 802, loss 0.614262.
Train: 2018-07-31T00:39:36.642911: step 803, loss 0.536111.
Train: 2018-07-31T00:39:36.783503: step 804, loss 0.554663.
Train: 2018-07-31T00:39:36.924094: step 805, loss 0.604336.
Train: 2018-07-31T00:39:37.095953: step 806, loss 0.521831.
Train: 2018-07-31T00:39:37.236520: step 807, loss 0.504756.
Train: 2018-07-31T00:39:37.377138: step 808, loss 0.528721.
Train: 2018-07-31T00:39:37.517730: step 809, loss 0.487149.
Train: 2018-07-31T00:39:37.658297: step 810, loss 0.537974.
Test: 2018-07-31T00:39:37.908239: step 810, loss 0.548405.
Train: 2018-07-31T00:39:38.048831: step 811, loss 0.587749.
Train: 2018-07-31T00:39:38.189425: step 812, loss 0.663872.
Train: 2018-07-31T00:39:38.345636: step 813, loss 0.562632.
Train: 2018-07-31T00:39:38.486254: step 814, loss 0.537709.
Train: 2018-07-31T00:39:38.642443: step 815, loss 0.571123.
Train: 2018-07-31T00:39:38.783059: step 816, loss 0.50377.
Train: 2018-07-31T00:39:38.923625: step 817, loss 0.645822.
Train: 2018-07-31T00:39:39.064218: step 818, loss 0.554129.
Train: 2018-07-31T00:39:39.220447: step 819, loss 0.596396.
Train: 2018-07-31T00:39:39.376644: step 820, loss 0.562531.
Test: 2018-07-31T00:39:39.610996: step 820, loss 0.548741.
Train: 2018-07-31T00:39:39.767178: step 821, loss 0.528906.
Train: 2018-07-31T00:39:39.907796: step 822, loss 0.603681.
Train: 2018-07-31T00:39:40.048363: step 823, loss 0.562391.
Train: 2018-07-31T00:39:40.188979: step 824, loss 0.513293.
Train: 2018-07-31T00:39:40.345169: step 825, loss 0.554216.
Train: 2018-07-31T00:39:40.485762: step 826, loss 0.571084.
Train: 2018-07-31T00:39:40.626353: step 827, loss 0.530854.
Train: 2018-07-31T00:39:40.766945: step 828, loss 0.529751.
Train: 2018-07-31T00:39:40.923182: step 829, loss 0.554216.
Train: 2018-07-31T00:39:41.079371: step 830, loss 0.538182.
Test: 2018-07-31T00:39:41.313692: step 830, loss 0.548794.
Train: 2018-07-31T00:39:41.469905: step 831, loss 0.538043.
Train: 2018-07-31T00:39:41.610521: step 832, loss 0.546144.
Train: 2018-07-31T00:39:41.751089: step 833, loss 0.619764.
Train: 2018-07-31T00:39:41.891705: step 834, loss 0.553979.
Train: 2018-07-31T00:39:42.032273: step 835, loss 0.562335.
Train: 2018-07-31T00:39:42.172865: step 836, loss 0.646233.
Train: 2018-07-31T00:39:42.329079: step 837, loss 0.55401.
Train: 2018-07-31T00:39:42.469672: step 838, loss 0.562294.
Train: 2018-07-31T00:39:42.610264: step 839, loss 0.505016.
Train: 2018-07-31T00:39:42.750855: step 840, loss 0.545791.
Test: 2018-07-31T00:39:43.000798: step 840, loss 0.548715.
Train: 2018-07-31T00:39:43.141389: step 841, loss 0.555234.
Train: 2018-07-31T00:39:43.297603: step 842, loss 0.513435.
Train: 2018-07-31T00:39:43.438195: step 843, loss 0.536772.
Train: 2018-07-31T00:39:43.578786: step 844, loss 0.619601.
Train: 2018-07-31T00:39:43.735000: step 845, loss 0.521093.
Train: 2018-07-31T00:39:43.875616: step 846, loss 0.620404.
Train: 2018-07-31T00:39:44.016183: step 847, loss 0.562967.
Train: 2018-07-31T00:39:44.172422: step 848, loss 0.529872.
Train: 2018-07-31T00:39:44.313014: step 849, loss 0.579619.
Train: 2018-07-31T00:39:44.453581: step 850, loss 0.59649.
Test: 2018-07-31T00:39:44.703541: step 850, loss 0.548588.
Train: 2018-07-31T00:39:44.844114: step 851, loss 0.545498.
Train: 2018-07-31T00:39:44.984732: step 852, loss 0.554522.
Train: 2018-07-31T00:39:45.125323: step 853, loss 0.653744.
Train: 2018-07-31T00:39:45.281511: step 854, loss 0.595333.
Train: 2018-07-31T00:39:45.422104: step 855, loss 0.5467.
Train: 2018-07-31T00:39:45.562697: step 856, loss 0.546888.
Train: 2018-07-31T00:39:45.718910: step 857, loss 0.530167.
Train: 2018-07-31T00:39:45.859503: step 858, loss 0.546526.
Train: 2018-07-31T00:39:46.015716: step 859, loss 0.521439.
Train: 2018-07-31T00:39:46.156307: step 860, loss 0.546652.
Test: 2018-07-31T00:39:46.406249: step 860, loss 0.549006.
Train: 2018-07-31T00:39:46.546865: step 861, loss 0.579314.
Train: 2018-07-31T00:39:46.687457: step 862, loss 0.554865.
Train: 2018-07-31T00:39:46.828038: step 863, loss 0.537835.
Train: 2018-07-31T00:39:46.968617: step 864, loss 0.537961.
Train: 2018-07-31T00:39:47.109208: step 865, loss 0.596098.
Train: 2018-07-31T00:39:47.249818: step 866, loss 0.481425.
Train: 2018-07-31T00:39:47.390419: step 867, loss 0.538471.
Train: 2018-07-31T00:39:47.530986: step 868, loss 0.620665.
Train: 2018-07-31T00:39:47.671606: step 869, loss 0.58648.
Train: 2018-07-31T00:39:47.827792: step 870, loss 0.636302.
Test: 2018-07-31T00:39:48.062142: step 870, loss 0.548778.
Train: 2018-07-31T00:39:48.218324: step 871, loss 0.563032.
Train: 2018-07-31T00:39:48.358916: step 872, loss 0.554096.
Train: 2018-07-31T00:39:48.499508: step 873, loss 0.587463.
Train: 2018-07-31T00:39:48.655722: step 874, loss 0.553646.
Train: 2018-07-31T00:39:48.796315: step 875, loss 0.530414.
Train: 2018-07-31T00:39:48.952528: step 876, loss 0.562734.
Train: 2018-07-31T00:39:49.093144: step 877, loss 0.635615.
Train: 2018-07-31T00:39:49.233712: step 878, loss 0.611722.
Train: 2018-07-31T00:39:49.374329: step 879, loss 0.538114.
Train: 2018-07-31T00:39:49.530519: step 880, loss 0.578531.
Test: 2018-07-31T00:39:49.764863: step 880, loss 0.549269.
Train: 2018-07-31T00:39:49.921075: step 881, loss 0.58645.
Train: 2018-07-31T00:39:50.077265: step 882, loss 0.563136.
Train: 2018-07-31T00:39:50.233502: step 883, loss 0.546872.
Train: 2018-07-31T00:39:50.389716: step 884, loss 0.5468.
Train: 2018-07-31T00:39:50.530307: step 885, loss 0.610664.
Train: 2018-07-31T00:39:50.702119: step 886, loss 0.483221.
Train: 2018-07-31T00:39:50.842709: step 887, loss 0.602124.
Train: 2018-07-31T00:39:50.983301: step 888, loss 0.522791.
Train: 2018-07-31T00:39:51.108298: step 889, loss 0.523885.
Train: 2018-07-31T00:39:51.264486: step 890, loss 0.474138.
Test: 2018-07-31T00:39:51.514458: step 890, loss 0.5493.
Train: 2018-07-31T00:39:51.655052: step 891, loss 0.570449.
Train: 2018-07-31T00:39:51.811257: step 892, loss 0.659634.
Train: 2018-07-31T00:39:51.967490: step 893, loss 0.570689.
Train: 2018-07-31T00:39:52.123685: step 894, loss 0.554075.
Train: 2018-07-31T00:39:52.264272: step 895, loss 0.546076.
Train: 2018-07-31T00:39:52.404869: step 896, loss 0.611667.
Train: 2018-07-31T00:39:52.561057: step 897, loss 0.595301.
Train: 2018-07-31T00:39:52.701650: step 898, loss 0.538552.
Train: 2018-07-31T00:39:52.842241: step 899, loss 0.603267.
Train: 2018-07-31T00:39:52.982834: step 900, loss 0.643687.
Test: 2018-07-31T00:39:53.232775: step 900, loss 0.54921.
Train: 2018-07-31T00:39:54.045103: step 901, loss 0.530045.
Train: 2018-07-31T00:39:54.185701: step 902, loss 0.538674.
Train: 2018-07-31T00:39:54.326276: step 903, loss 0.585635.
Train: 2018-07-31T00:39:54.482484: step 904, loss 0.571405.
Train: 2018-07-31T00:39:54.623099: step 905, loss 0.578668.
Train: 2018-07-31T00:39:54.763691: step 906, loss 0.426432.
Train: 2018-07-31T00:39:54.904276: step 907, loss 0.546912.
Train: 2018-07-31T00:39:55.044853: step 908, loss 0.570285.
Train: 2018-07-31T00:39:55.201065: step 909, loss 0.602811.
Train: 2018-07-31T00:39:55.341655: step 910, loss 0.587136.
Test: 2018-07-31T00:39:55.576007: step 910, loss 0.549124.
Train: 2018-07-31T00:39:55.732190: step 911, loss 0.505758.
Train: 2018-07-31T00:39:55.872806: step 912, loss 0.562207.
Train: 2018-07-31T00:39:56.029020: step 913, loss 0.546547.
Train: 2018-07-31T00:39:56.169612: step 914, loss 0.652225.
Train: 2018-07-31T00:39:56.325810: step 915, loss 0.571245.
Train: 2018-07-31T00:39:56.466392: step 916, loss 0.538414.
Train: 2018-07-31T00:39:56.622606: step 917, loss 0.505865.
Train: 2018-07-31T00:39:56.763198: step 918, loss 0.578666.
Train: 2018-07-31T00:39:56.919412: step 919, loss 0.537743.
Train: 2018-07-31T00:39:57.060005: step 920, loss 0.505815.
Test: 2018-07-31T00:39:57.294355: step 920, loss 0.548742.
Train: 2018-07-31T00:39:57.450538: step 921, loss 0.562611.
Train: 2018-07-31T00:39:57.591154: step 922, loss 0.603079.
Train: 2018-07-31T00:39:57.731722: step 923, loss 0.503809.
Train: 2018-07-31T00:39:57.872313: step 924, loss 0.579741.
Train: 2018-07-31T00:39:58.028527: step 925, loss 0.51186.
Train: 2018-07-31T00:39:58.169118: step 926, loss 0.60401.
Train: 2018-07-31T00:39:58.309729: step 927, loss 0.58762.
Train: 2018-07-31T00:39:58.450328: step 928, loss 0.536447.
Train: 2018-07-31T00:39:58.590919: step 929, loss 0.536765.
Train: 2018-07-31T00:39:58.731513: step 930, loss 0.503585.
Test: 2018-07-31T00:39:58.981459: step 930, loss 0.547919.
Train: 2018-07-31T00:39:59.122039: step 931, loss 0.58951.
Train: 2018-07-31T00:39:59.278236: step 932, loss 0.606287.
Train: 2018-07-31T00:39:59.418855: step 933, loss 0.493416.
Train: 2018-07-31T00:39:59.559418: step 934, loss 0.552685.
Train: 2018-07-31T00:39:59.715656: step 935, loss 0.545491.
Train: 2018-07-31T00:39:59.856249: step 936, loss 0.519837.
Train: 2018-07-31T00:39:59.996816: step 937, loss 0.537275.
Train: 2018-07-31T00:40:00.137433: step 938, loss 0.519643.
Train: 2018-07-31T00:40:00.309244: step 939, loss 0.645602.
Train: 2018-07-31T00:40:00.449836: step 940, loss 0.603736.
Test: 2018-07-31T00:40:00.684155: step 940, loss 0.547057.
Train: 2018-07-31T00:40:00.824747: step 941, loss 0.552811.
Train: 2018-07-31T00:40:00.965340: step 942, loss 0.53795.
Train: 2018-07-31T00:40:01.105931: step 943, loss 0.660188.
Train: 2018-07-31T00:40:01.246523: step 944, loss 0.577986.
Train: 2018-07-31T00:40:01.387141: step 945, loss 0.561574.
Train: 2018-07-31T00:40:01.543330: step 946, loss 0.544321.
Train: 2018-07-31T00:40:01.668300: step 947, loss 0.584403.
Train: 2018-07-31T00:40:01.808892: step 948, loss 0.66139.
Train: 2018-07-31T00:40:01.949483: step 949, loss 0.546137.
Train: 2018-07-31T00:40:02.090075: step 950, loss 0.610159.
Test: 2018-07-31T00:40:02.340026: step 950, loss 0.548916.
Train: 2018-07-31T00:40:02.480611: step 951, loss 0.495384.
Train: 2018-07-31T00:40:02.621202: step 952, loss 0.512325.
Train: 2018-07-31T00:40:02.761795: step 953, loss 0.537905.
Train: 2018-07-31T00:40:02.902387: step 954, loss 0.588185.
Train: 2018-07-31T00:40:03.042985: step 955, loss 0.547048.
Train: 2018-07-31T00:40:03.183570: step 956, loss 0.587744.
Train: 2018-07-31T00:40:03.324189: step 957, loss 0.521199.
Train: 2018-07-31T00:40:03.464754: step 958, loss 0.603513.
Train: 2018-07-31T00:40:03.620969: step 959, loss 0.572306.
Train: 2018-07-31T00:40:03.761560: step 960, loss 0.495579.
Test: 2018-07-31T00:40:03.995910: step 960, loss 0.548378.
Train: 2018-07-31T00:40:04.136471: step 961, loss 0.588059.
Train: 2018-07-31T00:40:04.292685: step 962, loss 0.496369.
Train: 2018-07-31T00:40:04.433302: step 963, loss 0.602594.
Train: 2018-07-31T00:40:04.573877: step 964, loss 0.521927.
Train: 2018-07-31T00:40:04.714462: step 965, loss 0.61209.
Train: 2018-07-31T00:40:04.870674: step 966, loss 0.635354.
Train: 2018-07-31T00:40:05.011267: step 967, loss 0.555334.
Train: 2018-07-31T00:40:05.167482: step 968, loss 0.595769.
Train: 2018-07-31T00:40:05.308072: step 969, loss 0.505286.
Train: 2018-07-31T00:40:05.464285: step 970, loss 0.576129.
Test: 2018-07-31T00:40:05.714227: step 970, loss 0.549026.
Train: 2018-07-31T00:40:05.854819: step 971, loss 0.577943.
Train: 2018-07-31T00:40:05.995411: step 972, loss 0.512495.
Train: 2018-07-31T00:40:06.136028: step 973, loss 0.530851.
Train: 2018-07-31T00:40:06.292219: step 974, loss 0.588225.
Train: 2018-07-31T00:40:06.432809: step 975, loss 0.538328.
Train: 2018-07-31T00:40:06.573401: step 976, loss 0.562748.
Train: 2018-07-31T00:40:06.729639: step 977, loss 0.546483.
Train: 2018-07-31T00:40:06.870231: step 978, loss 0.571383.
Train: 2018-07-31T00:40:07.010799: step 979, loss 0.51251.
Train: 2018-07-31T00:40:07.167014: step 980, loss 0.587805.
Test: 2018-07-31T00:40:07.401334: step 980, loss 0.5487.
Train: 2018-07-31T00:40:07.557569: step 981, loss 0.571029.
Train: 2018-07-31T00:40:07.698137: step 982, loss 0.504984.
Train: 2018-07-31T00:40:07.838729: step 983, loss 0.545653.
Train: 2018-07-31T00:40:07.979323: step 984, loss 0.504982.
Train: 2018-07-31T00:40:08.119913: step 985, loss 0.640164.
Train: 2018-07-31T00:40:08.260506: step 986, loss 0.622046.
Train: 2018-07-31T00:40:08.401100: step 987, loss 0.587675.
Train: 2018-07-31T00:40:08.541690: step 988, loss 0.527447.
Train: 2018-07-31T00:40:08.682282: step 989, loss 0.504709.
Train: 2018-07-31T00:40:08.822874: step 990, loss 0.646448.
Test: 2018-07-31T00:40:09.072845: step 990, loss 0.54865.
Train: 2018-07-31T00:40:09.213421: step 991, loss 0.595273.
Train: 2018-07-31T00:40:09.354001: step 992, loss 0.561223.
Train: 2018-07-31T00:40:09.494593: step 993, loss 0.547793.
Train: 2018-07-31T00:40:09.635185: step 994, loss 0.571136.
Train: 2018-07-31T00:40:09.775776: step 995, loss 0.538875.
Train: 2018-07-31T00:40:09.931990: step 996, loss 0.546459.
Train: 2018-07-31T00:40:10.072582: step 997, loss 0.481653.
Train: 2018-07-31T00:40:10.213174: step 998, loss 0.529196.
Train: 2018-07-31T00:40:10.353766: step 999, loss 0.547026.
Train: 2018-07-31T00:40:10.494357: step 1000, loss 0.60348.
Test: 2018-07-31T00:40:10.744300: step 1000, loss 0.548681.
Train: 2018-07-31T00:40:11.462906: step 1001, loss 0.602455.
Train: 2018-07-31T00:40:11.603498: step 1002, loss 0.570891.
Train: 2018-07-31T00:40:11.744089: step 1003, loss 0.562501.
Train: 2018-07-31T00:40:11.900279: step 1004, loss 0.555436.
Train: 2018-07-31T00:40:12.040870: step 1005, loss 0.660367.
Train: 2018-07-31T00:40:12.197085: step 1006, loss 0.555135.
Train: 2018-07-31T00:40:12.337678: step 1007, loss 0.497794.
Train: 2018-07-31T00:40:12.478299: step 1008, loss 0.572325.
Train: 2018-07-31T00:40:12.618885: step 1009, loss 0.522588.
Train: 2018-07-31T00:40:12.759477: step 1010, loss 0.497791.
Test: 2018-07-31T00:40:13.009395: step 1010, loss 0.548929.
Train: 2018-07-31T00:40:13.165633: step 1011, loss 0.570533.
Train: 2018-07-31T00:40:13.306200: step 1012, loss 0.538055.
Train: 2018-07-31T00:40:13.446791: step 1013, loss 0.529098.
Train: 2018-07-31T00:40:13.587409: step 1014, loss 0.552948.
Train: 2018-07-31T00:40:13.728000: step 1015, loss 0.497051.
Train: 2018-07-31T00:40:13.868568: step 1016, loss 0.5538.
Train: 2018-07-31T00:40:14.009184: step 1017, loss 0.529484.
Train: 2018-07-31T00:40:14.149752: step 1018, loss 0.629697.
Train: 2018-07-31T00:40:14.290346: step 1019, loss 0.546933.
Train: 2018-07-31T00:40:14.430936: step 1020, loss 0.487368.
Test: 2018-07-31T00:40:14.680908: step 1020, loss 0.548151.
Train: 2018-07-31T00:40:14.837092: step 1021, loss 0.604838.
Train: 2018-07-31T00:40:14.977707: step 1022, loss 0.654531.
Train: 2018-07-31T00:40:15.118300: step 1023, loss 0.570762.
Train: 2018-07-31T00:40:15.274513: step 1024, loss 0.528559.
Train: 2018-07-31T00:40:15.430703: step 1025, loss 0.553024.
Train: 2018-07-31T00:40:15.571296: step 1026, loss 0.562169.
Train: 2018-07-31T00:40:15.711910: step 1027, loss 0.50286.
Train: 2018-07-31T00:40:15.852503: step 1028, loss 0.554175.
Train: 2018-07-31T00:40:16.008691: step 1029, loss 0.553051.
Train: 2018-07-31T00:40:16.149283: step 1030, loss 0.613716.
Test: 2018-07-31T00:40:16.383632: step 1030, loss 0.548199.
Train: 2018-07-31T00:40:16.539818: step 1031, loss 0.554586.
Train: 2018-07-31T00:40:16.696030: step 1032, loss 0.563432.
Train: 2018-07-31T00:40:16.836647: step 1033, loss 0.562811.
Train: 2018-07-31T00:40:16.992837: step 1034, loss 0.587557.
Train: 2018-07-31T00:40:17.133430: step 1035, loss 0.603686.
Train: 2018-07-31T00:40:17.274046: step 1036, loss 0.595223.
Train: 2018-07-31T00:40:17.445857: step 1037, loss 0.554359.
Train: 2018-07-31T00:40:17.586447: step 1038, loss 0.471095.
Train: 2018-07-31T00:40:17.742685: step 1039, loss 0.628502.
Train: 2018-07-31T00:40:17.883277: step 1040, loss 0.594618.
Test: 2018-07-31T00:40:18.133227: step 1040, loss 0.548703.
Train: 2018-07-31T00:40:18.273811: step 1041, loss 0.586927.
Train: 2018-07-31T00:40:18.430030: step 1042, loss 0.521784.
Train: 2018-07-31T00:40:18.570593: step 1043, loss 0.594631.
Train: 2018-07-31T00:40:18.711208: step 1044, loss 0.572176.
Train: 2018-07-31T00:40:18.867398: step 1045, loss 0.554513.
Train: 2018-07-31T00:40:19.008013: step 1046, loss 0.579026.
Train: 2018-07-31T00:40:19.148580: step 1047, loss 0.513985.
Train: 2018-07-31T00:40:19.304794: step 1048, loss 0.595791.
Train: 2018-07-31T00:40:19.461043: step 1049, loss 0.603451.
Train: 2018-07-31T00:40:19.601612: step 1050, loss 0.611057.
Test: 2018-07-31T00:40:19.835952: step 1050, loss 0.549391.
Train: 2018-07-31T00:40:19.992135: step 1051, loss 0.554331.
Train: 2018-07-31T00:40:20.132751: step 1052, loss 0.562177.
Train: 2018-07-31T00:40:20.273335: step 1053, loss 0.572393.
Train: 2018-07-31T00:40:20.429532: step 1054, loss 0.571063.
Train: 2018-07-31T00:40:20.585746: step 1055, loss 0.602866.
Train: 2018-07-31T00:40:20.726338: step 1056, loss 0.56327.
Train: 2018-07-31T00:40:20.882575: step 1057, loss 0.496512.
Train: 2018-07-31T00:40:21.038789: step 1058, loss 0.539441.
Train: 2018-07-31T00:40:21.195013: step 1059, loss 0.570701.
Train: 2018-07-31T00:40:21.335586: step 1060, loss 0.539042.
Test: 2018-07-31T00:40:21.569891: step 1060, loss 0.549845.
Train: 2018-07-31T00:40:21.726107: step 1061, loss 0.618357.
Train: 2018-07-31T00:40:21.882342: step 1062, loss 0.515224.
Train: 2018-07-31T00:40:22.022908: step 1063, loss 0.515142.
Train: 2018-07-31T00:40:22.179146: step 1064, loss 0.539161.
Train: 2018-07-31T00:40:22.335365: step 1065, loss 0.531334.
Train: 2018-07-31T00:40:22.475929: step 1066, loss 0.546933.
Train: 2018-07-31T00:40:22.616520: step 1067, loss 0.522977.
Train: 2018-07-31T00:40:22.757111: step 1068, loss 0.521414.
Train: 2018-07-31T00:40:22.897730: step 1069, loss 0.505078.
Train: 2018-07-31T00:40:23.053918: step 1070, loss 0.579186.
Test: 2018-07-31T00:40:23.288237: step 1070, loss 0.548371.
Train: 2018-07-31T00:40:23.428854: step 1071, loss 0.520354.
Train: 2018-07-31T00:40:23.585067: step 1072, loss 0.655816.
Train: 2018-07-31T00:40:23.725660: step 1073, loss 0.648451.
Train: 2018-07-31T00:40:23.866229: step 1074, loss 0.630961.
Train: 2018-07-31T00:40:24.006844: step 1075, loss 0.537802.
Train: 2018-07-31T00:40:24.163033: step 1076, loss 0.554133.
Train: 2018-07-31T00:40:24.288027: step 1077, loss 0.512755.
Train: 2018-07-31T00:40:24.444240: step 1078, loss 0.603685.
Train: 2018-07-31T00:40:24.584809: step 1079, loss 0.513059.
Train: 2018-07-31T00:40:24.725425: step 1080, loss 0.512794.
Test: 2018-07-31T00:40:24.959720: step 1080, loss 0.548582.
Train: 2018-07-31T00:40:25.115959: step 1081, loss 0.604162.
Train: 2018-07-31T00:40:25.272183: step 1082, loss 0.554516.
Train: 2018-07-31T00:40:25.412741: step 1083, loss 0.562413.
Train: 2018-07-31T00:40:25.553331: step 1084, loss 0.570514.
Train: 2018-07-31T00:40:25.709572: step 1085, loss 0.6785.
Train: 2018-07-31T00:40:25.865760: step 1086, loss 0.530213.
Train: 2018-07-31T00:40:25.990754: step 1087, loss 0.587734.
Train: 2018-07-31T00:40:26.146943: step 1088, loss 0.513493.
Train: 2018-07-31T00:40:26.287535: step 1089, loss 0.538808.
Train: 2018-07-31T00:40:26.443749: step 1090, loss 0.611136.
Test: 2018-07-31T00:40:26.678098: step 1090, loss 0.549101.
Train: 2018-07-31T00:40:26.818684: step 1091, loss 0.539059.
Train: 2018-07-31T00:40:26.974874: step 1092, loss 0.489709.
Train: 2018-07-31T00:40:27.131112: step 1093, loss 0.513514.
Train: 2018-07-31T00:40:27.287301: step 1094, loss 0.505987.
Train: 2018-07-31T00:40:27.427893: step 1095, loss 0.603516.
Train: 2018-07-31T00:40:27.568502: step 1096, loss 0.505443.
Train: 2018-07-31T00:40:27.709101: step 1097, loss 0.602987.
Train: 2018-07-31T00:40:27.865314: step 1098, loss 0.595127.
Train: 2018-07-31T00:40:28.005907: step 1099, loss 0.603519.
Train: 2018-07-31T00:40:28.146475: step 1100, loss 0.538157.
Test: 2018-07-31T00:40:28.396417: step 1100, loss 0.548701.
Train: 2018-07-31T00:40:29.130619: step 1101, loss 0.562363.
Train: 2018-07-31T00:40:29.271212: step 1102, loss 0.553589.
Train: 2018-07-31T00:40:29.411828: step 1103, loss 0.678396.
Train: 2018-07-31T00:40:29.568018: step 1104, loss 0.620568.
Train: 2018-07-31T00:40:29.708609: step 1105, loss 0.604312.
Train: 2018-07-31T00:40:29.849226: step 1106, loss 0.594861.
Train: 2018-07-31T00:40:29.989798: step 1107, loss 0.538605.
Train: 2018-07-31T00:40:30.130409: step 1108, loss 0.538514.
Train: 2018-07-31T00:40:30.271002: step 1109, loss 0.587155.
Train: 2018-07-31T00:40:30.411587: step 1110, loss 0.586914.
Test: 2018-07-31T00:40:30.645896: step 1110, loss 0.549566.
Train: 2018-07-31T00:40:30.802127: step 1111, loss 0.546737.
Train: 2018-07-31T00:40:30.942712: step 1112, loss 0.56247.
Train: 2018-07-31T00:40:31.083286: step 1113, loss 0.547617.
Train: 2018-07-31T00:40:31.239501: step 1114, loss 0.562677.
Train: 2018-07-31T00:40:31.380117: step 1115, loss 0.634521.
Train: 2018-07-31T00:40:31.520694: step 1116, loss 0.507572.
Train: 2018-07-31T00:40:31.661275: step 1117, loss 0.618242.
Train: 2018-07-31T00:40:31.817491: step 1118, loss 0.555076.
Train: 2018-07-31T00:40:31.973704: step 1119, loss 0.539922.
Train: 2018-07-31T00:40:32.129917: step 1120, loss 0.555363.
Test: 2018-07-31T00:40:32.364256: step 1120, loss 0.549978.
Train: 2018-07-31T00:40:32.504828: step 1121, loss 0.57916.
Train: 2018-07-31T00:40:32.661042: step 1122, loss 0.524231.
Train: 2018-07-31T00:40:32.801634: step 1123, loss 0.555132.
Train: 2018-07-31T00:40:32.942226: step 1124, loss 0.586506.
Train: 2018-07-31T00:40:33.082843: step 1125, loss 0.578853.
Train: 2018-07-31T00:40:33.223410: step 1126, loss 0.5628.
Train: 2018-07-31T00:40:33.364002: step 1127, loss 0.563354.
Train: 2018-07-31T00:40:33.520215: step 1128, loss 0.618825.
Train: 2018-07-31T00:40:33.660833: step 1129, loss 0.570791.
Train: 2018-07-31T00:40:33.817046: step 1130, loss 0.62639.
Test: 2018-07-31T00:40:34.051343: step 1130, loss 0.549905.
Train: 2018-07-31T00:40:34.191934: step 1131, loss 0.555029.
Train: 2018-07-31T00:40:34.348148: step 1132, loss 0.515792.
Train: 2018-07-31T00:40:34.488740: step 1133, loss 0.617967.
Train: 2018-07-31T00:40:34.629355: step 1134, loss 0.547228.
Train: 2018-07-31T00:40:34.769923: step 1135, loss 0.516384.
Train: 2018-07-31T00:40:34.910540: step 1136, loss 0.602564.
Train: 2018-07-31T00:40:35.066730: step 1137, loss 0.64118.
Train: 2018-07-31T00:40:35.222942: step 1138, loss 0.578594.
Train: 2018-07-31T00:40:35.379180: step 1139, loss 0.555131.
Train: 2018-07-31T00:40:35.519747: step 1140, loss 0.562616.
Test: 2018-07-31T00:40:35.754068: step 1140, loss 0.550092.
Train: 2018-07-31T00:40:35.910306: step 1141, loss 0.626545.
Train: 2018-07-31T00:40:36.050873: step 1142, loss 0.602389.
Train: 2018-07-31T00:40:36.207111: step 1143, loss 0.4696.
Train: 2018-07-31T00:40:36.347679: step 1144, loss 0.508585.
Train: 2018-07-31T00:40:36.503894: step 1145, loss 0.547466.
Train: 2018-07-31T00:40:36.644509: step 1146, loss 0.579054.
Train: 2018-07-31T00:40:36.785114: step 1147, loss 0.577988.
Train: 2018-07-31T00:40:36.925715: step 1148, loss 0.547129.
Train: 2018-07-31T00:40:37.066285: step 1149, loss 0.634265.
Train: 2018-07-31T00:40:37.206852: step 1150, loss 0.499232.
Test: 2018-07-31T00:40:37.456825: step 1150, loss 0.549735.
Train: 2018-07-31T00:40:37.597387: step 1151, loss 0.570517.
Train: 2018-07-31T00:40:37.753600: step 1152, loss 0.586264.
Train: 2018-07-31T00:40:37.894192: step 1153, loss 0.569974.
Train: 2018-07-31T00:40:38.034808: step 1154, loss 0.586617.
Train: 2018-07-31T00:40:38.175376: step 1155, loss 0.649771.
Train: 2018-07-31T00:40:38.315992: step 1156, loss 0.570876.
Train: 2018-07-31T00:40:38.472181: step 1157, loss 0.539414.
Train: 2018-07-31T00:40:38.628394: step 1158, loss 0.554604.
Train: 2018-07-31T00:40:38.768987: step 1159, loss 0.531371.
Train: 2018-07-31T00:40:38.925199: step 1160, loss 0.547053.
Test: 2018-07-31T00:40:39.159551: step 1160, loss 0.54944.
Train: 2018-07-31T00:40:39.300111: step 1161, loss 0.635386.
Train: 2018-07-31T00:40:39.456325: step 1162, loss 0.546342.
Train: 2018-07-31T00:40:39.596920: step 1163, loss 0.55524.
Train: 2018-07-31T00:40:39.737510: step 1164, loss 0.515923.
Train: 2018-07-31T00:40:39.893748: step 1165, loss 0.547828.
Train: 2018-07-31T00:40:40.034329: step 1166, loss 0.530275.
Train: 2018-07-31T00:40:40.174907: step 1167, loss 0.553246.
Train: 2018-07-31T00:40:40.315500: step 1168, loss 0.529159.
Train: 2018-07-31T00:40:40.456116: step 1169, loss 0.488408.
Train: 2018-07-31T00:40:40.596684: step 1170, loss 0.62606.
Test: 2018-07-31T00:40:40.846626: step 1170, loss 0.548644.
Train: 2018-07-31T00:40:40.987261: step 1171, loss 0.581142.
Train: 2018-07-31T00:40:41.127834: step 1172, loss 0.646618.
Train: 2018-07-31T00:40:41.268418: step 1173, loss 0.529219.
Train: 2018-07-31T00:40:41.409018: step 1174, loss 0.529924.
Train: 2018-07-31T00:40:41.549610: step 1175, loss 0.554549.
Train: 2018-07-31T00:40:41.705798: step 1176, loss 0.538656.
Train: 2018-07-31T00:40:41.846391: step 1177, loss 0.529538.
Train: 2018-07-31T00:40:41.986984: step 1178, loss 0.554474.
Train: 2018-07-31T00:40:42.127576: step 1179, loss 0.589655.
Train: 2018-07-31T00:40:42.268167: step 1180, loss 0.568046.
Test: 2018-07-31T00:40:42.518139: step 1180, loss 0.548322.
Train: 2018-07-31T00:40:42.658729: step 1181, loss 0.544964.
Train: 2018-07-31T00:40:42.799320: step 1182, loss 0.554551.
Train: 2018-07-31T00:40:42.955507: step 1183, loss 0.521722.
Train: 2018-07-31T00:40:43.096098: step 1184, loss 0.599087.
Train: 2018-07-31T00:40:43.236690: step 1185, loss 0.601919.
Train: 2018-07-31T00:40:43.392904: step 1186, loss 0.511743.
Train: 2018-07-31T00:40:43.533498: step 1187, loss 0.544761.
Train: 2018-07-31T00:40:43.674088: step 1188, loss 0.57978.
Train: 2018-07-31T00:40:43.830326: step 1189, loss 0.511593.
Train: 2018-07-31T00:40:43.986516: step 1190, loss 0.545924.
Test: 2018-07-31T00:40:44.220836: step 1190, loss 0.548054.
Train: 2018-07-31T00:40:44.377073: step 1191, loss 0.527176.
Train: 2018-07-31T00:40:44.517641: step 1192, loss 0.554145.
Train: 2018-07-31T00:40:44.673878: step 1193, loss 0.529159.
Train: 2018-07-31T00:40:44.814471: step 1194, loss 0.591027.
Train: 2018-07-31T00:40:44.955038: step 1195, loss 0.562876.
Train: 2018-07-31T00:40:45.111253: step 1196, loss 0.476277.
Train: 2018-07-31T00:40:45.251872: step 1197, loss 0.614377.
Train: 2018-07-31T00:40:45.392460: step 1198, loss 0.52131.
Train: 2018-07-31T00:40:45.548648: step 1199, loss 0.577889.
Train: 2018-07-31T00:40:45.689241: step 1200, loss 0.579355.
Test: 2018-07-31T00:40:45.923599: step 1200, loss 0.548072.
Train: 2018-07-31T00:40:46.657789: step 1201, loss 0.528437.
Train: 2018-07-31T00:40:46.814003: step 1202, loss 0.586973.
Train: 2018-07-31T00:40:46.954570: step 1203, loss 0.51287.
Train: 2018-07-31T00:40:47.095189: step 1204, loss 0.570464.
Train: 2018-07-31T00:40:47.235779: step 1205, loss 0.535908.
Train: 2018-07-31T00:40:47.407590: step 1206, loss 0.537828.
Train: 2018-07-31T00:40:47.548180: step 1207, loss 0.596456.
Train: 2018-07-31T00:40:47.688773: step 1208, loss 0.471673.
Train: 2018-07-31T00:40:47.844987: step 1209, loss 0.53655.
Train: 2018-07-31T00:40:47.985579: step 1210, loss 0.622131.
Test: 2018-07-31T00:40:48.235521: step 1210, loss 0.548137.
Train: 2018-07-31T00:40:48.391734: step 1211, loss 0.526435.
Train: 2018-07-31T00:40:48.547947: step 1212, loss 0.59876.
Train: 2018-07-31T00:40:48.704160: step 1213, loss 0.528385.
Train: 2018-07-31T00:40:48.844752: step 1214, loss 0.536057.
Train: 2018-07-31T00:40:48.985344: step 1215, loss 0.553022.
Train: 2018-07-31T00:40:49.125936: step 1216, loss 0.512756.
Train: 2018-07-31T00:40:49.286669: step 1217, loss 0.572371.
Train: 2018-07-31T00:40:49.442883: step 1218, loss 0.571742.
Train: 2018-07-31T00:40:49.583499: step 1219, loss 0.605423.
Train: 2018-07-31T00:40:49.724093: step 1220, loss 0.5962.
Test: 2018-07-31T00:40:49.974016: step 1220, loss 0.548299.
Train: 2018-07-31T00:40:50.130246: step 1221, loss 0.57957.
Train: 2018-07-31T00:40:50.286463: step 1222, loss 0.545686.
Train: 2018-07-31T00:40:50.442649: step 1223, loss 0.512495.
Train: 2018-07-31T00:40:50.583270: step 1224, loss 0.562194.
Train: 2018-07-31T00:40:50.723832: step 1225, loss 0.622052.
Train: 2018-07-31T00:40:50.880070: step 1226, loss 0.604289.
Train: 2018-07-31T00:40:51.020665: step 1227, loss 0.595643.
Train: 2018-07-31T00:40:51.176851: step 1228, loss 0.537518.
Train: 2018-07-31T00:40:51.317443: step 1229, loss 0.586745.
Train: 2018-07-31T00:40:51.458036: step 1230, loss 0.514953.
Test: 2018-07-31T00:40:51.707987: step 1230, loss 0.549019.
Train: 2018-07-31T00:40:51.864214: step 1231, loss 0.603544.
Train: 2018-07-31T00:40:52.004783: step 1232, loss 0.47355.
Train: 2018-07-31T00:40:52.145374: step 1233, loss 0.546264.
Train: 2018-07-31T00:40:52.285990: step 1234, loss 0.594919.
Train: 2018-07-31T00:40:52.442204: step 1235, loss 0.514397.
Train: 2018-07-31T00:40:52.582798: step 1236, loss 0.571365.
Train: 2018-07-31T00:40:52.723363: step 1237, loss 0.448451.
Train: 2018-07-31T00:40:52.863958: step 1238, loss 0.521741.
Train: 2018-07-31T00:40:53.004573: step 1239, loss 0.521751.
Train: 2018-07-31T00:40:53.145165: step 1240, loss 0.545259.
Test: 2018-07-31T00:40:53.395083: step 1240, loss 0.54849.
Train: 2018-07-31T00:40:53.535675: step 1241, loss 0.553686.
Train: 2018-07-31T00:40:53.676268: step 1242, loss 0.612766.
Train: 2018-07-31T00:40:53.816859: step 1243, loss 0.461285.
Train: 2018-07-31T00:40:53.957451: step 1244, loss 0.612953.
Train: 2018-07-31T00:40:54.098042: step 1245, loss 0.528334.
Train: 2018-07-31T00:40:54.254255: step 1246, loss 0.537007.
Train: 2018-07-31T00:40:54.394847: step 1247, loss 0.57935.
Train: 2018-07-31T00:40:54.551062: step 1248, loss 0.528282.
Train: 2018-07-31T00:40:54.691653: step 1249, loss 0.613078.
Train: 2018-07-31T00:40:54.847868: step 1250, loss 0.48615.
Test: 2018-07-31T00:40:55.082218: step 1250, loss 0.547955.
Train: 2018-07-31T00:40:55.222834: step 1251, loss 0.589199.
Train: 2018-07-31T00:40:55.378994: step 1252, loss 0.606186.
Train: 2018-07-31T00:40:55.519585: step 1253, loss 0.528202.
Train: 2018-07-31T00:40:55.660204: step 1254, loss 0.518277.
Train: 2018-07-31T00:40:55.800767: step 1255, loss 0.58664.
Train: 2018-07-31T00:40:55.941361: step 1256, loss 0.562122.
Train: 2018-07-31T00:40:56.081977: step 1257, loss 0.527599.
Train: 2018-07-31T00:40:56.238167: step 1258, loss 0.589095.
Train: 2018-07-31T00:40:56.378758: step 1259, loss 0.623101.
Train: 2018-07-31T00:40:56.519350: step 1260, loss 0.623366.
Test: 2018-07-31T00:40:56.753703: step 1260, loss 0.548062.
Train: 2018-07-31T00:40:56.909885: step 1261, loss 0.511519.
Train: 2018-07-31T00:40:57.066097: step 1262, loss 0.621774.
Train: 2018-07-31T00:40:57.206713: step 1263, loss 0.622954.
Train: 2018-07-31T00:40:57.347281: step 1264, loss 0.545536.
Train: 2018-07-31T00:40:57.519149: step 1265, loss 0.537985.
Train: 2018-07-31T00:40:57.659733: step 1266, loss 0.562812.
Train: 2018-07-31T00:40:57.815946: step 1267, loss 0.562881.
Train: 2018-07-31T00:40:57.956513: step 1268, loss 0.595615.
Train: 2018-07-31T00:40:58.112726: step 1269, loss 0.587066.
Train: 2018-07-31T00:40:58.253336: step 1270, loss 0.497058.
Test: 2018-07-31T00:40:58.487670: step 1270, loss 0.549034.
Train: 2018-07-31T00:40:58.643854: step 1271, loss 0.546587.
Train: 2018-07-31T00:40:58.784444: step 1272, loss 0.611156.
Train: 2018-07-31T00:40:58.925062: step 1273, loss 0.56256.
Train: 2018-07-31T00:40:59.081251: step 1274, loss 0.482348.
Train: 2018-07-31T00:40:59.221843: step 1275, loss 0.595264.
Train: 2018-07-31T00:40:59.362436: step 1276, loss 0.538176.
Train: 2018-07-31T00:40:59.503027: step 1277, loss 0.554849.
Train: 2018-07-31T00:40:59.643644: step 1278, loss 0.522161.
Train: 2018-07-31T00:40:59.799832: step 1279, loss 0.506237.
Train: 2018-07-31T00:40:59.940424: step 1280, loss 0.506295.
Test: 2018-07-31T00:41:00.190395: step 1280, loss 0.548999.
Train: 2018-07-31T00:41:00.330982: step 1281, loss 0.53009.
Train: 2018-07-31T00:41:00.471575: step 1282, loss 0.611644.
Train: 2018-07-31T00:41:00.627764: step 1283, loss 0.562563.
Train: 2018-07-31T00:41:00.768383: step 1284, loss 0.538224.
Train: 2018-07-31T00:41:00.908971: step 1285, loss 0.586919.
Train: 2018-07-31T00:41:01.065185: step 1286, loss 0.644716.
Train: 2018-07-31T00:41:01.205781: step 1287, loss 0.57937.
Train: 2018-07-31T00:41:01.361990: step 1288, loss 0.554286.
Train: 2018-07-31T00:41:01.518212: step 1289, loss 0.578687.
Train: 2018-07-31T00:41:01.674417: step 1290, loss 0.660731.
Test: 2018-07-31T00:41:01.908721: step 1290, loss 0.548832.
Train: 2018-07-31T00:41:02.049360: step 1291, loss 0.579103.
Train: 2018-07-31T00:41:02.205519: step 1292, loss 0.554102.
Train: 2018-07-31T00:41:02.346135: step 1293, loss 0.611629.
Train: 2018-07-31T00:41:02.486702: step 1294, loss 0.554558.
Train: 2018-07-31T00:41:02.642941: step 1295, loss 0.530184.
Train: 2018-07-31T00:41:02.783533: step 1296, loss 0.594872.
Train: 2018-07-31T00:41:02.939746: step 1297, loss 0.571208.
Train: 2018-07-31T00:41:03.080348: step 1298, loss 0.570842.
Train: 2018-07-31T00:41:03.252150: step 1299, loss 0.602793.
Train: 2018-07-31T00:41:03.392742: step 1300, loss 0.5628.
Test: 2018-07-31T00:41:03.642683: step 1300, loss 0.549608.
Train: 2018-07-31T00:41:04.408167: step 1301, loss 0.570892.
Train: 2018-07-31T00:41:04.548719: step 1302, loss 0.531103.
Train: 2018-07-31T00:41:04.689339: step 1303, loss 0.491276.
Train: 2018-07-31T00:41:04.845527: step 1304, loss 0.594788.
Train: 2018-07-31T00:41:04.986142: step 1305, loss 0.602749.
Train: 2018-07-31T00:41:05.126734: step 1306, loss 0.586327.
Train: 2018-07-31T00:41:05.267326: step 1307, loss 0.555171.
Train: 2018-07-31T00:41:05.423540: step 1308, loss 0.58709.
Train: 2018-07-31T00:41:05.579729: step 1309, loss 0.570521.
Train: 2018-07-31T00:41:05.720345: step 1310, loss 0.610891.
Test: 2018-07-31T00:41:05.954671: step 1310, loss 0.549837.
Train: 2018-07-31T00:41:06.110879: step 1311, loss 0.546951.
Train: 2018-07-31T00:41:06.282714: step 1312, loss 0.507557.
Train: 2018-07-31T00:41:06.423298: step 1313, loss 0.531722.
Train: 2018-07-31T00:41:06.563897: step 1314, loss 0.523165.
Train: 2018-07-31T00:41:06.720086: step 1315, loss 0.578267.
Train: 2018-07-31T00:41:06.860680: step 1316, loss 0.475581.
Train: 2018-07-31T00:41:07.016916: step 1317, loss 0.547317.
Train: 2018-07-31T00:41:07.157483: step 1318, loss 0.587117.
Train: 2018-07-31T00:41:07.407450: step 1319, loss 0.570683.
Train: 2018-07-31T00:41:07.548042: step 1320, loss 0.587416.
Test: 2018-07-31T00:41:07.797983: step 1320, loss 0.549116.
Train: 2018-07-31T00:41:07.985440: step 1321, loss 0.530264.
Train: 2018-07-31T00:41:08.141652: step 1322, loss 0.505733.
Train: 2018-07-31T00:41:08.282232: step 1323, loss 0.570489.
Train: 2018-07-31T00:41:08.438434: step 1324, loss 0.603688.
Train: 2018-07-31T00:41:08.579026: step 1325, loss 0.513554.
Train: 2018-07-31T00:41:08.735240: step 1326, loss 0.636478.
Train: 2018-07-31T00:41:08.875832: step 1327, loss 0.660904.
Train: 2018-07-31T00:41:09.016424: step 1328, loss 0.57101.
Train: 2018-07-31T00:41:09.157040: step 1329, loss 0.562855.
Train: 2018-07-31T00:41:09.297607: step 1330, loss 0.545772.
Test: 2018-07-31T00:41:09.547549: step 1330, loss 0.548886.
Train: 2018-07-31T00:41:09.688168: step 1331, loss 0.563219.
Train: 2018-07-31T00:41:09.844354: step 1332, loss 0.480247.
Train: 2018-07-31T00:41:09.984946: step 1333, loss 0.578998.
Train: 2018-07-31T00:41:10.125538: step 1334, loss 0.604375.
Train: 2018-07-31T00:41:10.266131: step 1335, loss 0.619822.
Train: 2018-07-31T00:41:10.437990: step 1336, loss 0.537601.
Train: 2018-07-31T00:41:10.578559: step 1337, loss 0.563219.
Train: 2018-07-31T00:41:10.719151: step 1338, loss 0.570568.
Train: 2018-07-31T00:41:10.859766: step 1339, loss 0.530433.
Train: 2018-07-31T00:41:11.000334: step 1340, loss 0.586962.
Test: 2018-07-31T00:41:11.250309: step 1340, loss 0.549075.
Train: 2018-07-31T00:41:11.406488: step 1341, loss 0.578699.
Train: 2018-07-31T00:41:11.547106: step 1342, loss 0.538342.
Train: 2018-07-31T00:41:11.703294: step 1343, loss 0.538482.
Train: 2018-07-31T00:41:11.843886: step 1344, loss 0.619427.
Train: 2018-07-31T00:41:12.000099: step 1345, loss 0.60354.
Train: 2018-07-31T00:41:12.156314: step 1346, loss 0.586686.
Train: 2018-07-31T00:41:12.296906: step 1347, loss 0.571255.
Train: 2018-07-31T00:41:12.437522: step 1348, loss 0.546396.
Train: 2018-07-31T00:41:12.578090: step 1349, loss 0.547117.
Train: 2018-07-31T00:41:12.734304: step 1350, loss 0.602972.
Test: 2018-07-31T00:41:12.968654: step 1350, loss 0.54947.
Train: 2018-07-31T00:41:13.124860: step 1351, loss 0.474459.
Train: 2018-07-31T00:41:13.281067: step 1352, loss 0.51496.
Train: 2018-07-31T00:41:13.421642: step 1353, loss 0.514371.
Train: 2018-07-31T00:41:13.562251: step 1354, loss 0.530287.
Train: 2018-07-31T00:41:13.702827: step 1355, loss 0.547357.
Train: 2018-07-31T00:41:13.859046: step 1356, loss 0.611921.
Train: 2018-07-31T00:41:13.999631: step 1357, loss 0.57084.
Train: 2018-07-31T00:41:14.140249: step 1358, loss 0.587512.
Train: 2018-07-31T00:41:14.296461: step 1359, loss 0.579737.
Train: 2018-07-31T00:41:14.452650: step 1360, loss 0.538139.
Test: 2018-07-31T00:41:14.686971: step 1360, loss 0.548947.
Train: 2018-07-31T00:41:14.827587: step 1361, loss 0.555073.
Train: 2018-07-31T00:41:14.968154: step 1362, loss 0.505825.
Train: 2018-07-31T00:41:15.139990: step 1363, loss 0.627781.
Train: 2018-07-31T00:41:15.280582: step 1364, loss 0.537713.
Train: 2018-07-31T00:41:15.405552: step 1365, loss 0.530225.
Train: 2018-07-31T00:41:15.546144: step 1366, loss 0.587077.
Train: 2018-07-31T00:41:15.717980: step 1367, loss 0.505424.
Train: 2018-07-31T00:41:15.858578: step 1368, loss 0.628449.
Train: 2018-07-31T00:41:15.999163: step 1369, loss 0.546596.
Train: 2018-07-31T00:41:16.155377: step 1370, loss 0.488187.
Test: 2018-07-31T00:41:16.389726: step 1370, loss 0.548682.
Train: 2018-07-31T00:41:16.545911: step 1371, loss 0.520673.
Train: 2018-07-31T00:41:16.686542: step 1372, loss 0.57903.
Train: 2018-07-31T00:41:16.842717: step 1373, loss 0.553228.
Train: 2018-07-31T00:41:16.998955: step 1374, loss 0.546399.
Train: 2018-07-31T00:41:17.155143: step 1375, loss 0.503875.
Train: 2018-07-31T00:41:17.295734: step 1376, loss 0.578909.
Train: 2018-07-31T00:41:17.436327: step 1377, loss 0.544961.
Train: 2018-07-31T00:41:17.592540: step 1378, loss 0.512219.
Train: 2018-07-31T00:41:17.733134: step 1379, loss 0.529061.
Train: 2018-07-31T00:41:17.873750: step 1380, loss 0.578901.
Test: 2018-07-31T00:41:18.108075: step 1380, loss 0.548025.
Train: 2018-07-31T00:41:18.264260: step 1381, loss 0.579074.
Train: 2018-07-31T00:41:18.404875: step 1382, loss 0.519294.
Train: 2018-07-31T00:41:18.561062: step 1383, loss 0.580347.
Train: 2018-07-31T00:41:18.717301: step 1384, loss 0.492963.
Train: 2018-07-31T00:41:18.873529: step 1385, loss 0.640086.
Train: 2018-07-31T00:41:19.014107: step 1386, loss 0.485248.
Train: 2018-07-31T00:41:19.170320: step 1387, loss 0.502474.
Train: 2018-07-31T00:41:19.326510: step 1388, loss 0.586964.
Train: 2018-07-31T00:41:19.467102: step 1389, loss 0.476304.
Train: 2018-07-31T00:41:19.607718: step 1390, loss 0.626506.
Test: 2018-07-31T00:41:19.842013: step 1390, loss 0.547626.
Train: 2018-07-31T00:41:19.998228: step 1391, loss 0.591945.
Train: 2018-07-31T00:41:20.138819: step 1392, loss 0.57104.
Train: 2018-07-31T00:41:20.279411: step 1393, loss 0.554065.
Train: 2018-07-31T00:41:20.435624: step 1394, loss 0.528115.
Train: 2018-07-31T00:41:20.576217: step 1395, loss 0.588529.
Train: 2018-07-31T00:41:20.716837: step 1396, loss 0.561711.
Train: 2018-07-31T00:41:20.857435: step 1397, loss 0.622156.
Train: 2018-07-31T00:41:20.997992: step 1398, loss 0.477549.
Train: 2018-07-31T00:41:21.154207: step 1399, loss 0.67288.
Train: 2018-07-31T00:41:21.294799: step 1400, loss 0.578957.
Test: 2018-07-31T00:41:21.529118: step 1400, loss 0.548256.
Train: 2018-07-31T00:41:22.247701: step 1401, loss 0.561974.
Train: 2018-07-31T00:41:22.388313: step 1402, loss 0.570272.
Train: 2018-07-31T00:41:22.528908: step 1403, loss 0.578918.
Train: 2018-07-31T00:41:22.685097: step 1404, loss 0.537329.
Train: 2018-07-31T00:41:22.825690: step 1405, loss 0.587289.
Train: 2018-07-31T00:41:22.966281: step 1406, loss 0.65319.
Train: 2018-07-31T00:41:23.106873: step 1407, loss 0.554174.
Train: 2018-07-31T00:41:23.278709: step 1408, loss 0.619505.
Train: 2018-07-31T00:41:23.434948: step 1409, loss 0.513416.
Train: 2018-07-31T00:41:23.575515: step 1410, loss 0.562463.
Test: 2018-07-31T00:41:23.809836: step 1410, loss 0.549103.
Train: 2018-07-31T00:41:23.966073: step 1411, loss 0.539079.
Train: 2018-07-31T00:41:24.122263: step 1412, loss 0.627438.
Train: 2018-07-31T00:41:24.262855: step 1413, loss 0.562601.
Train: 2018-07-31T00:41:24.403447: step 1414, loss 0.530866.
Train: 2018-07-31T00:41:24.544037: step 1415, loss 0.58665.
Train: 2018-07-31T00:41:24.684631: step 1416, loss 0.562916.
Train: 2018-07-31T00:41:24.809600: step 1417, loss 0.562031.
Train: 2018-07-31T00:41:24.965815: step 1418, loss 0.546803.
Train: 2018-07-31T00:41:25.106434: step 1419, loss 0.554799.
Train: 2018-07-31T00:41:25.247022: step 1420, loss 0.618984.
Test: 2018-07-31T00:41:25.496969: step 1420, loss 0.54965.
Train: 2018-07-31T00:41:25.637532: step 1421, loss 0.539158.
Train: 2018-07-31T00:41:25.778123: step 1422, loss 0.523748.
Train: 2018-07-31T00:41:25.918716: step 1423, loss 0.562571.
Train: 2018-07-31T00:41:26.059332: step 1424, loss 0.602332.
Train: 2018-07-31T00:41:26.215546: step 1425, loss 0.578461.
Train: 2018-07-31T00:41:26.356159: step 1426, loss 0.547309.
Train: 2018-07-31T00:41:26.496729: step 1427, loss 0.555481.
Train: 2018-07-31T00:41:26.637322: step 1428, loss 0.658344.
Train: 2018-07-31T00:41:26.777914: step 1429, loss 0.491376.
Train: 2018-07-31T00:41:26.934102: step 1430, loss 0.578333.
Test: 2018-07-31T00:41:27.168449: step 1430, loss 0.549688.
Train: 2018-07-31T00:41:27.324660: step 1431, loss 0.587155.
Train: 2018-07-31T00:41:27.465254: step 1432, loss 0.531141.
Train: 2018-07-31T00:41:27.605820: step 1433, loss 0.618652.
Train: 2018-07-31T00:41:27.762035: step 1434, loss 0.530988.
Train: 2018-07-31T00:41:27.902626: step 1435, loss 0.570641.
Train: 2018-07-31T00:41:28.058839: step 1436, loss 0.570948.
Train: 2018-07-31T00:41:28.199432: step 1437, loss 0.56357.
Train: 2018-07-31T00:41:28.340024: step 1438, loss 0.625887.
Train: 2018-07-31T00:41:28.496239: step 1439, loss 0.61809.
Train: 2018-07-31T00:41:28.636853: step 1440, loss 0.57876.
Test: 2018-07-31T00:41:28.871179: step 1440, loss 0.549848.
Train: 2018-07-31T00:41:29.027387: step 1441, loss 0.555272.
Train: 2018-07-31T00:41:29.167989: step 1442, loss 0.524451.
Train: 2018-07-31T00:41:29.308547: step 1443, loss 0.619429.
Train: 2018-07-31T00:41:29.464760: step 1444, loss 0.532149.
Train: 2018-07-31T00:41:29.605352: step 1445, loss 0.602205.
Train: 2018-07-31T00:41:29.745949: step 1446, loss 0.548074.
Train: 2018-07-31T00:41:29.886561: step 1447, loss 0.571338.
Train: 2018-07-31T00:41:30.042774: step 1448, loss 0.571154.
Train: 2018-07-31T00:41:30.183367: step 1449, loss 0.54723.
Train: 2018-07-31T00:41:30.323959: step 1450, loss 0.539927.
Test: 2018-07-31T00:41:30.558256: step 1450, loss 0.550126.
Train: 2018-07-31T00:41:30.714467: step 1451, loss 0.618169.
Train: 2018-07-31T00:41:30.855060: step 1452, loss 0.586886.
Train: 2018-07-31T00:41:30.995652: step 1453, loss 0.586346.
Train: 2018-07-31T00:41:31.151889: step 1454, loss 0.563398.
Train: 2018-07-31T00:41:31.292458: step 1455, loss 0.57105.
Train: 2018-07-31T00:41:31.433049: step 1456, loss 0.547869.
Train: 2018-07-31T00:41:31.573641: step 1457, loss 0.547601.
Train: 2018-07-31T00:41:31.729880: step 1458, loss 0.524041.
Train: 2018-07-31T00:41:31.870447: step 1459, loss 0.540344.
Train: 2018-07-31T00:41:32.026660: step 1460, loss 0.539822.
Test: 2018-07-31T00:41:32.276636: step 1460, loss 0.549986.
Train: 2018-07-31T00:41:32.417229: step 1461, loss 0.500391.
Train: 2018-07-31T00:41:32.557796: step 1462, loss 0.539861.
Train: 2018-07-31T00:41:32.713999: step 1463, loss 0.539003.
Train: 2018-07-31T00:41:32.854592: step 1464, loss 0.530935.
Train: 2018-07-31T00:41:33.010804: step 1465, loss 0.466283.
Train: 2018-07-31T00:41:33.151421: step 1466, loss 0.522002.
Train: 2018-07-31T00:41:33.291988: step 1467, loss 0.563071.
Train: 2018-07-31T00:41:33.448202: step 1468, loss 0.554462.
Train: 2018-07-31T00:41:33.588821: step 1469, loss 0.528926.
Train: 2018-07-31T00:41:33.729403: step 1470, loss 0.545492.
Test: 2018-07-31T00:41:33.963710: step 1470, loss 0.548393.
Train: 2018-07-31T00:41:34.119921: step 1471, loss 0.554017.
Train: 2018-07-31T00:41:34.260511: step 1472, loss 0.561861.
Train: 2018-07-31T00:41:34.401103: step 1473, loss 0.569823.
Train: 2018-07-31T00:41:34.557318: step 1474, loss 0.56212.
Train: 2018-07-31T00:41:34.697910: step 1475, loss 0.578755.
Train: 2018-07-31T00:41:34.838503: step 1476, loss 0.519395.
Train: 2018-07-31T00:41:34.979092: step 1477, loss 0.518866.
Train: 2018-07-31T00:41:35.135307: step 1478, loss 0.520311.
Train: 2018-07-31T00:41:35.275901: step 1479, loss 0.535445.
Train: 2018-07-31T00:41:35.416516: step 1480, loss 0.579176.
Test: 2018-07-31T00:41:35.666434: step 1480, loss 0.547723.
Train: 2018-07-31T00:41:35.807024: step 1481, loss 0.572165.
Train: 2018-07-31T00:41:35.963239: step 1482, loss 0.578648.
Train: 2018-07-31T00:41:36.088235: step 1483, loss 0.606678.
Train: 2018-07-31T00:41:36.244424: step 1484, loss 0.562976.
Train: 2018-07-31T00:41:36.400635: step 1485, loss 0.536359.
Train: 2018-07-31T00:41:36.556850: step 1486, loss 0.542908.
Train: 2018-07-31T00:41:36.697466: step 1487, loss 0.59691.
Train: 2018-07-31T00:41:36.838059: step 1488, loss 0.572393.
Train: 2018-07-31T00:41:36.978627: step 1489, loss 0.579336.
Train: 2018-07-31T00:41:37.119217: step 1490, loss 0.56365.
Test: 2018-07-31T00:41:37.369184: step 1490, loss 0.547856.
Train: 2018-07-31T00:41:37.509750: step 1491, loss 0.511508.
Train: 2018-07-31T00:41:37.665966: step 1492, loss 0.579027.
Train: 2018-07-31T00:41:37.806575: step 1493, loss 0.587059.
Train: 2018-07-31T00:41:37.978392: step 1494, loss 0.527723.
Train: 2018-07-31T00:41:38.118982: step 1495, loss 0.545467.
Train: 2018-07-31T00:41:38.275215: step 1496, loss 0.570248.
Train: 2018-07-31T00:41:38.415788: step 1497, loss 0.630715.
Train: 2018-07-31T00:41:38.556380: step 1498, loss 0.528846.
Train: 2018-07-31T00:41:38.696973: step 1499, loss 0.554265.
Train: 2018-07-31T00:41:38.837565: step 1500, loss 0.603705.
Test: 2018-07-31T00:41:39.071916: step 1500, loss 0.548286.
Train: 2018-07-31T00:41:39.852977: step 1501, loss 0.537097.
Train: 2018-07-31T00:41:40.009166: step 1502, loss 0.588237.
Train: 2018-07-31T00:41:40.165379: step 1503, loss 0.662851.
Train: 2018-07-31T00:41:40.305972: step 1504, loss 0.620558.
Train: 2018-07-31T00:41:40.462185: step 1505, loss 0.546788.
Train: 2018-07-31T00:41:40.602776: step 1506, loss 0.52932.
Train: 2018-07-31T00:41:40.759014: step 1507, loss 0.553952.
Train: 2018-07-31T00:41:40.899581: step 1508, loss 0.586962.
Train: 2018-07-31T00:41:41.040174: step 1509, loss 0.627038.
Train: 2018-07-31T00:41:41.180766: step 1510, loss 0.597345.
Test: 2018-07-31T00:41:41.415117: step 1510, loss 0.549379.
Train: 2018-07-31T00:41:41.571301: step 1511, loss 0.586383.
Train: 2018-07-31T00:41:41.711916: step 1512, loss 0.531203.
Train: 2018-07-31T00:41:41.852509: step 1513, loss 0.563239.
Train: 2018-07-31T00:41:41.993116: step 1514, loss 0.515888.
Train: 2018-07-31T00:41:42.149290: step 1515, loss 0.546638.
Train: 2018-07-31T00:41:42.289882: step 1516, loss 0.571063.
Train: 2018-07-31T00:41:42.430498: step 1517, loss 0.578981.
Train: 2018-07-31T00:41:42.571090: step 1518, loss 0.642106.
Train: 2018-07-31T00:41:42.711657: step 1519, loss 0.539516.
Train: 2018-07-31T00:41:42.852275: step 1520, loss 0.602807.
Test: 2018-07-31T00:41:43.102207: step 1520, loss 0.550088.
Train: 2018-07-31T00:41:43.242783: step 1521, loss 0.594458.
Train: 2018-07-31T00:41:43.398997: step 1522, loss 0.539885.
Train: 2018-07-31T00:41:43.539590: step 1523, loss 0.515907.
Train: 2018-07-31T00:41:43.680205: step 1524, loss 0.516473.
Train: 2018-07-31T00:41:43.836419: step 1525, loss 0.516274.
Train: 2018-07-31T00:41:43.976986: step 1526, loss 0.563535.
Train: 2018-07-31T00:41:44.117602: step 1527, loss 0.61047.
Train: 2018-07-31T00:41:44.258170: step 1528, loss 0.523637.
Train: 2018-07-31T00:41:44.398763: step 1529, loss 0.578716.
Train: 2018-07-31T00:41:44.539366: step 1530, loss 0.531589.
Test: 2018-07-31T00:41:44.773710: step 1530, loss 0.54971.
Train: 2018-07-31T00:41:44.914291: step 1531, loss 0.571035.
Train: 2018-07-31T00:41:45.054877: step 1532, loss 0.587311.
Train: 2018-07-31T00:41:45.211072: step 1533, loss 0.610741.
Train: 2018-07-31T00:41:45.351664: step 1534, loss 0.539183.
Train: 2018-07-31T00:41:45.492282: step 1535, loss 0.594955.
Train: 2018-07-31T00:41:45.648471: step 1536, loss 0.538401.
Train: 2018-07-31T00:41:45.789080: step 1537, loss 0.587344.
Train: 2018-07-31T00:41:45.929679: step 1538, loss 0.587149.
Train: 2018-07-31T00:41:46.085868: step 1539, loss 0.546938.
Train: 2018-07-31T00:41:46.226459: step 1540, loss 0.60289.
Test: 2018-07-31T00:41:46.460810: step 1540, loss 0.549529.
Train: 2018-07-31T00:41:46.601373: step 1541, loss 0.571081.
Train: 2018-07-31T00:41:46.757585: step 1542, loss 0.539141.
Train: 2018-07-31T00:41:46.898203: step 1543, loss 0.546909.
Train: 2018-07-31T00:41:47.038795: step 1544, loss 0.531143.
Train: 2018-07-31T00:41:47.179387: step 1545, loss 0.555114.
Train: 2018-07-31T00:41:47.335576: step 1546, loss 0.586633.
Train: 2018-07-31T00:41:47.491790: step 1547, loss 0.56275.
Train: 2018-07-31T00:41:47.632380: step 1548, loss 0.570535.
Train: 2018-07-31T00:41:47.757351: step 1549, loss 0.626622.
Train: 2018-07-31T00:41:47.897958: step 1550, loss 0.506749.
Test: 2018-07-31T00:41:48.132266: step 1550, loss 0.549402.
Train: 2018-07-31T00:41:48.288477: step 1551, loss 0.555105.
Train: 2018-07-31T00:41:48.444691: step 1552, loss 0.530557.
Train: 2018-07-31T00:41:48.585307: step 1553, loss 0.506437.
Train: 2018-07-31T00:41:48.725874: step 1554, loss 0.522307.
Train: 2018-07-31T00:41:48.866491: step 1555, loss 0.562842.
Train: 2018-07-31T00:41:49.022680: step 1556, loss 0.497623.
Train: 2018-07-31T00:41:49.163272: step 1557, loss 0.554548.
Train: 2018-07-31T00:41:49.319485: step 1558, loss 0.537861.
Train: 2018-07-31T00:41:49.444456: step 1559, loss 0.57927.
Train: 2018-07-31T00:41:49.600669: step 1560, loss 0.596219.
Test: 2018-07-31T00:41:49.835020: step 1560, loss 0.548579.
Train: 2018-07-31T00:41:49.975607: step 1561, loss 0.579219.
Train: 2018-07-31T00:41:50.116173: step 1562, loss 0.579299.
Train: 2018-07-31T00:41:50.256765: step 1563, loss 0.537533.
Train: 2018-07-31T00:41:50.397358: step 1564, loss 0.537632.
Train: 2018-07-31T00:41:50.537950: step 1565, loss 0.579338.
Train: 2018-07-31T00:41:50.678567: step 1566, loss 0.603993.
Train: 2018-07-31T00:41:50.834780: step 1567, loss 0.58725.
Train: 2018-07-31T00:41:50.975372: step 1568, loss 0.496118.
Train: 2018-07-31T00:41:51.115952: step 1569, loss 0.521019.
Train: 2018-07-31T00:41:51.272153: step 1570, loss 0.520376.
Test: 2018-07-31T00:41:51.522096: step 1570, loss 0.548417.
Train: 2018-07-31T00:41:51.693961: step 1571, loss 0.545668.
Train: 2018-07-31T00:41:51.834522: step 1572, loss 0.621241.
Train: 2018-07-31T00:41:51.975113: step 1573, loss 0.512271.
Train: 2018-07-31T00:41:52.131327: step 1574, loss 0.629506.
Train: 2018-07-31T00:41:52.287565: step 1575, loss 0.562452.
Train: 2018-07-31T00:41:52.443753: step 1576, loss 0.579189.
Train: 2018-07-31T00:41:52.599966: step 1577, loss 0.604313.
Train: 2018-07-31T00:41:52.756182: step 1578, loss 0.462189.
Train: 2018-07-31T00:41:52.896798: step 1579, loss 0.578937.
Train: 2018-07-31T00:41:53.037364: step 1580, loss 0.570682.
Test: 2018-07-31T00:41:53.271714: step 1580, loss 0.548438.
Train: 2018-07-31T00:41:53.427898: step 1581, loss 0.545856.
Train: 2018-07-31T00:41:53.568490: step 1582, loss 0.51229.
Train: 2018-07-31T00:41:53.709083: step 1583, loss 0.570401.
Train: 2018-07-31T00:41:53.849680: step 1584, loss 0.562542.
Train: 2018-07-31T00:41:53.990268: step 1585, loss 0.562702.
Train: 2018-07-31T00:41:54.130883: step 1586, loss 0.637702.
Train: 2018-07-31T00:41:54.271475: step 1587, loss 0.545701.
Train: 2018-07-31T00:41:54.427665: step 1588, loss 0.554004.
Train: 2018-07-31T00:41:54.568282: step 1589, loss 0.545914.
Train: 2018-07-31T00:41:54.724470: step 1590, loss 0.529058.
Test: 2018-07-31T00:41:54.958802: step 1590, loss 0.548503.
Train: 2018-07-31T00:41:55.099381: step 1591, loss 0.587468.
Train: 2018-07-31T00:41:55.255597: step 1592, loss 0.587446.
Train: 2018-07-31T00:41:55.396212: step 1593, loss 0.520943.
Train: 2018-07-31T00:41:55.552401: step 1594, loss 0.545953.
Train: 2018-07-31T00:41:55.693021: step 1595, loss 0.554251.
Train: 2018-07-31T00:41:55.833585: step 1596, loss 0.637371.
Train: 2018-07-31T00:41:55.989799: step 1597, loss 0.562283.
Train: 2018-07-31T00:41:56.130390: step 1598, loss 0.620451.
Train: 2018-07-31T00:41:56.286628: step 1599, loss 0.636717.
Train: 2018-07-31T00:41:56.427197: step 1600, loss 0.488604.
Test: 2018-07-31T00:41:56.677168: step 1600, loss 0.548846.
Train: 2018-07-31T00:41:57.426962: step 1601, loss 0.538108.
Train: 2018-07-31T00:41:57.567579: step 1602, loss 0.505385.
Train: 2018-07-31T00:41:57.708172: step 1603, loss 0.636253.
Train: 2018-07-31T00:41:57.864384: step 1604, loss 0.538104.
Train: 2018-07-31T00:41:58.004998: step 1605, loss 0.578898.
Train: 2018-07-31T00:41:58.145569: step 1606, loss 0.53832.
Train: 2018-07-31T00:41:58.286161: step 1607, loss 0.530152.
Train: 2018-07-31T00:41:58.426727: step 1608, loss 0.47307.
Train: 2018-07-31T00:41:58.598563: step 1609, loss 0.489147.
Train: 2018-07-31T00:41:58.739155: step 1610, loss 0.562635.
Test: 2018-07-31T00:41:58.973501: step 1610, loss 0.54866.
Train: 2018-07-31T00:41:59.114066: step 1611, loss 0.54593.
Train: 2018-07-31T00:41:59.270281: step 1612, loss 0.603603.
Train: 2018-07-31T00:41:59.410872: step 1613, loss 0.520725.
Train: 2018-07-31T00:41:59.535868: step 1614, loss 0.57097.
Train: 2018-07-31T00:41:59.676442: step 1615, loss 0.579321.
Train: 2018-07-31T00:41:59.817027: step 1616, loss 0.494064.
Train: 2018-07-31T00:41:59.973242: step 1617, loss 0.537326.
Train: 2018-07-31T00:42:00.113857: step 1618, loss 0.612927.
Train: 2018-07-31T00:42:00.254424: step 1619, loss 0.60778.
Train: 2018-07-31T00:42:00.410639: step 1620, loss 0.526546.
Test: 2018-07-31T00:42:00.644993: step 1620, loss 0.548035.
Train: 2018-07-31T00:42:00.785549: step 1621, loss 0.50272.
Train: 2018-07-31T00:42:00.941765: step 1622, loss 0.571789.
Train: 2018-07-31T00:42:01.082381: step 1623, loss 0.604126.
Train: 2018-07-31T00:42:01.238570: step 1624, loss 0.518587.
Train: 2018-07-31T00:42:01.379162: step 1625, loss 0.596987.
Train: 2018-07-31T00:42:01.519754: step 1626, loss 0.470033.
Train: 2018-07-31T00:42:01.660346: step 1627, loss 0.529127.
Train: 2018-07-31T00:42:01.816570: step 1628, loss 0.596104.
Train: 2018-07-31T00:42:01.957152: step 1629, loss 0.546589.
Train: 2018-07-31T00:42:02.097742: step 1630, loss 0.519727.
Test: 2018-07-31T00:42:02.347685: step 1630, loss 0.548149.
Train: 2018-07-31T00:42:02.488276: step 1631, loss 0.604026.
Train: 2018-07-31T00:42:02.644515: step 1632, loss 0.529303.
Train: 2018-07-31T00:42:02.785100: step 1633, loss 0.570239.
Train: 2018-07-31T00:42:02.925673: step 1634, loss 0.554464.
Train: 2018-07-31T00:42:03.081889: step 1635, loss 0.57097.
Train: 2018-07-31T00:42:03.222482: step 1636, loss 0.537082.
Train: 2018-07-31T00:42:03.363072: step 1637, loss 0.621301.
Train: 2018-07-31T00:42:03.503664: step 1638, loss 0.528767.
Train: 2018-07-31T00:42:03.644257: step 1639, loss 0.63782.
Train: 2018-07-31T00:42:03.784849: step 1640, loss 0.570796.
Test: 2018-07-31T00:42:04.019170: step 1640, loss 0.548454.
Train: 2018-07-31T00:42:04.175383: step 1641, loss 0.587454.
Train: 2018-07-31T00:42:04.331596: step 1642, loss 0.529165.
Train: 2018-07-31T00:42:04.472188: step 1643, loss 0.595651.
Train: 2018-07-31T00:42:04.612779: step 1644, loss 0.545894.
Train: 2018-07-31T00:42:04.753370: step 1645, loss 0.562483.
Train: 2018-07-31T00:42:04.909586: step 1646, loss 0.595523.
Train: 2018-07-31T00:42:05.050176: step 1647, loss 0.587189.
Train: 2018-07-31T00:42:05.190793: step 1648, loss 0.562573.
Train: 2018-07-31T00:42:05.347000: step 1649, loss 0.628013.
Train: 2018-07-31T00:42:05.487588: step 1650, loss 0.578938.
Test: 2018-07-31T00:42:05.721932: step 1650, loss 0.54908.
Train: 2018-07-31T00:42:05.878133: step 1651, loss 0.611352.
Train: 2018-07-31T00:42:06.018724: step 1652, loss 0.55469.
Train: 2018-07-31T00:42:06.159293: step 1653, loss 0.611056.
Train: 2018-07-31T00:42:06.315532: step 1654, loss 0.546838.
Train: 2018-07-31T00:42:06.456098: step 1655, loss 0.507014.
Train: 2018-07-31T00:42:06.596714: step 1656, loss 0.554951.
Train: 2018-07-31T00:42:06.752903: step 1657, loss 0.594781.
Train: 2018-07-31T00:42:06.893495: step 1658, loss 0.570893.
Train: 2018-07-31T00:42:07.034112: step 1659, loss 0.634325.
Train: 2018-07-31T00:42:07.190327: step 1660, loss 0.61838.
Test: 2018-07-31T00:42:07.440267: step 1660, loss 0.549955.
Train: 2018-07-31T00:42:07.580834: step 1661, loss 0.579921.
Train: 2018-07-31T00:42:07.721451: step 1662, loss 0.657259.
Train: 2018-07-31T00:42:07.862019: step 1663, loss 0.60228.
Train: 2018-07-31T00:42:08.002611: step 1664, loss 0.532441.
Train: 2018-07-31T00:42:08.143204: step 1665, loss 0.532664.
Train: 2018-07-31T00:42:08.283795: step 1666, loss 0.617443.
Train: 2018-07-31T00:42:08.424388: step 1667, loss 0.479326.
Train: 2018-07-31T00:42:08.565003: step 1668, loss 0.586653.
Train: 2018-07-31T00:42:08.705595: step 1669, loss 0.548389.
Train: 2018-07-31T00:42:08.846181: step 1670, loss 0.579005.
Test: 2018-07-31T00:42:09.096105: step 1670, loss 0.55088.
Train: 2018-07-31T00:42:09.252318: step 1671, loss 0.586641.
Train: 2018-07-31T00:42:09.392911: step 1672, loss 0.609601.
Train: 2018-07-31T00:42:09.533526: step 1673, loss 0.548449.
Train: 2018-07-31T00:42:09.689740: step 1674, loss 0.556115.
Train: 2018-07-31T00:42:09.845953: step 1675, loss 0.47206.
Train: 2018-07-31T00:42:10.002142: step 1676, loss 0.571324.
Train: 2018-07-31T00:42:10.127138: step 1677, loss 0.594337.
Train: 2018-07-31T00:42:10.283350: step 1678, loss 0.578958.
Train: 2018-07-31T00:42:10.439564: step 1679, loss 0.555807.
Train: 2018-07-31T00:42:10.595777: step 1680, loss 0.56348.
Test: 2018-07-31T00:42:10.830104: step 1680, loss 0.550459.
Train: 2018-07-31T00:42:10.986288: step 1681, loss 0.51694.
Train: 2018-07-31T00:42:11.126880: step 1682, loss 0.571163.
Train: 2018-07-31T00:42:11.283117: step 1683, loss 0.586754.
Train: 2018-07-31T00:42:11.423685: step 1684, loss 0.539798.
Train: 2018-07-31T00:42:11.564276: step 1685, loss 0.531836.
Train: 2018-07-31T00:42:11.720490: step 1686, loss 0.571011.
Train: 2018-07-31T00:42:11.876703: step 1687, loss 0.642056.
Train: 2018-07-31T00:42:12.017296: step 1688, loss 0.555144.
Train: 2018-07-31T00:42:12.173534: step 1689, loss 0.547219.
Train: 2018-07-31T00:42:12.314103: step 1690, loss 0.586782.
Test: 2018-07-31T00:42:12.548447: step 1690, loss 0.549708.
Train: 2018-07-31T00:42:12.689014: step 1691, loss 0.547121.
Train: 2018-07-31T00:42:12.845226: step 1692, loss 0.507342.
Train: 2018-07-31T00:42:12.985820: step 1693, loss 0.483236.
Train: 2018-07-31T00:42:13.126412: step 1694, loss 0.514815.
Train: 2018-07-31T00:42:13.267004: step 1695, loss 0.635257.
Train: 2018-07-31T00:42:13.423241: step 1696, loss 0.578869.
Train: 2018-07-31T00:42:13.563832: step 1697, loss 0.522211.
Train: 2018-07-31T00:42:13.720023: step 1698, loss 0.424567.
Train: 2018-07-31T00:42:13.860615: step 1699, loss 0.578926.
Train: 2018-07-31T00:42:14.016828: step 1700, loss 0.644826.
Test: 2018-07-31T00:42:14.251178: step 1700, loss 0.54872.
Train: 2018-07-31T00:42:15.000996: step 1701, loss 0.513077.
Train: 2018-07-31T00:42:15.141565: step 1702, loss 0.545931.
Train: 2018-07-31T00:42:15.297778: step 1703, loss 0.54583.
Train: 2018-07-31T00:42:15.438369: step 1704, loss 0.587431.
Train: 2018-07-31T00:42:15.578962: step 1705, loss 0.562452.
Train: 2018-07-31T00:42:15.719553: step 1706, loss 0.595894.
Train: 2018-07-31T00:42:15.875791: step 1707, loss 0.595896.
Train: 2018-07-31T00:42:16.016359: step 1708, loss 0.612583.
Train: 2018-07-31T00:42:16.156953: step 1709, loss 0.570794.
Train: 2018-07-31T00:42:16.281922: step 1710, loss 0.537418.
Test: 2018-07-31T00:42:16.531902: step 1710, loss 0.548477.
Train: 2018-07-31T00:42:16.672480: step 1711, loss 0.57083.
Train: 2018-07-31T00:42:16.828669: step 1712, loss 0.554106.
Train: 2018-07-31T00:42:16.969260: step 1713, loss 0.612351.
Train: 2018-07-31T00:42:17.109852: step 1714, loss 0.520964.
Train: 2018-07-31T00:42:17.250445: step 1715, loss 0.537555.
Train: 2018-07-31T00:42:17.391037: step 1716, loss 0.562482.
Train: 2018-07-31T00:42:17.531628: step 1717, loss 0.554195.
Train: 2018-07-31T00:42:17.672221: step 1718, loss 0.504486.
Train: 2018-07-31T00:42:17.812813: step 1719, loss 0.579065.
Train: 2018-07-31T00:42:17.969053: step 1720, loss 0.595677.
Test: 2018-07-31T00:42:18.203347: step 1720, loss 0.54858.
Train: 2018-07-31T00:42:18.343939: step 1721, loss 0.537568.
Train: 2018-07-31T00:42:18.484556: step 1722, loss 0.562483.
Train: 2018-07-31T00:42:18.625147: step 1723, loss 0.603918.
Train: 2018-07-31T00:42:18.765740: step 1724, loss 0.529349.
Train: 2018-07-31T00:42:18.921929: step 1725, loss 0.496259.
Train: 2018-07-31T00:42:19.062545: step 1726, loss 0.628771.
Train: 2018-07-31T00:42:19.203112: step 1727, loss 0.529341.
Train: 2018-07-31T00:42:19.359326: step 1728, loss 0.587297.
Train: 2018-07-31T00:42:19.515571: step 1729, loss 0.496207.
Train: 2018-07-31T00:42:19.671753: step 1730, loss 0.595638.
Test: 2018-07-31T00:42:19.906099: step 1730, loss 0.548579.
Train: 2018-07-31T00:42:20.046665: step 1731, loss 0.562438.
Train: 2018-07-31T00:42:20.202880: step 1732, loss 0.612207.
Train: 2018-07-31T00:42:20.343470: step 1733, loss 0.628728.
Train: 2018-07-31T00:42:20.484063: step 1734, loss 0.529513.
Train: 2018-07-31T00:42:20.609034: step 1735, loss 0.628465.
Train: 2018-07-31T00:42:20.780869: step 1736, loss 0.513246.
Train: 2018-07-31T00:42:20.921461: step 1737, loss 0.587163.
Train: 2018-07-31T00:42:21.062078: step 1738, loss 0.554407.
Train: 2018-07-31T00:42:21.218265: step 1739, loss 0.554435.
Train: 2018-07-31T00:42:21.358858: step 1740, loss 0.587113.
Test: 2018-07-31T00:42:21.593209: step 1740, loss 0.548986.
Train: 2018-07-31T00:42:21.749393: step 1741, loss 0.603383.
Train: 2018-07-31T00:42:21.889984: step 1742, loss 0.505782.
Train: 2018-07-31T00:42:22.014953: step 1743, loss 0.570772.
Train: 2018-07-31T00:42:22.155547: step 1744, loss 0.595104.
Train: 2018-07-31T00:42:22.296163: step 1745, loss 0.643682.
Train: 2018-07-31T00:42:22.452376: step 1746, loss 0.554696.
Train: 2018-07-31T00:42:22.592944: step 1747, loss 0.530614.
Train: 2018-07-31T00:42:22.749158: step 1748, loss 0.562815.
Train: 2018-07-31T00:42:22.889750: step 1749, loss 0.651043.
Train: 2018-07-31T00:42:23.030341: step 1750, loss 0.68277.
Test: 2018-07-31T00:42:23.264689: step 1750, loss 0.549655.
Train: 2018-07-31T00:42:23.420876: step 1751, loss 0.467601.
Train: 2018-07-31T00:42:23.561499: step 1752, loss 0.602637.
Train: 2018-07-31T00:42:23.717720: step 1753, loss 0.53147.
Train: 2018-07-31T00:42:23.858274: step 1754, loss 0.555218.
Train: 2018-07-31T00:42:24.014511: step 1755, loss 0.555253.
Train: 2018-07-31T00:42:24.155104: step 1756, loss 0.515958.
Train: 2018-07-31T00:42:24.295697: step 1757, loss 0.602466.
Train: 2018-07-31T00:42:24.436287: step 1758, loss 0.51595.
Train: 2018-07-31T00:42:24.576878: step 1759, loss 0.539507.
Train: 2018-07-31T00:42:24.733068: step 1760, loss 0.578865.
Test: 2018-07-31T00:42:24.967388: step 1760, loss 0.549845.
Train: 2018-07-31T00:42:25.123601: step 1761, loss 0.547274.
Train: 2018-07-31T00:42:25.279814: step 1762, loss 0.491856.
Train: 2018-07-31T00:42:25.420406: step 1763, loss 0.491548.
Train: 2018-07-31T00:42:25.545377: step 1764, loss 0.626716.
Train: 2018-07-31T00:42:25.701626: step 1765, loss 0.578875.
Train: 2018-07-31T00:42:25.842184: step 1766, loss 0.562824.
Train: 2018-07-31T00:42:25.982802: step 1767, loss 0.538648.
Train: 2018-07-31T00:42:26.138989: step 1768, loss 0.570841.
Train: 2018-07-31T00:42:26.263984: step 1769, loss 0.586991.
Train: 2018-07-31T00:42:26.404577: step 1770, loss 0.530378.
Test: 2018-07-31T00:42:26.654523: step 1770, loss 0.549101.
Train: 2018-07-31T00:42:26.795085: step 1771, loss 0.554632.
Train: 2018-07-31T00:42:26.935676: step 1772, loss 0.57079.
Train: 2018-07-31T00:42:27.076270: step 1773, loss 0.62775.
Train: 2018-07-31T00:42:27.216862: step 1774, loss 0.595185.
Train: 2018-07-31T00:42:27.357478: step 1775, loss 0.497596.
Train: 2018-07-31T00:42:27.513705: step 1776, loss 0.513812.
Train: 2018-07-31T00:42:27.654289: step 1777, loss 0.587083.
Train: 2018-07-31T00:42:27.794875: step 1778, loss 0.578941.
Train: 2018-07-31T00:42:27.951064: step 1779, loss 0.578935.
Train: 2018-07-31T00:42:28.091681: step 1780, loss 0.505397.
Test: 2018-07-31T00:42:28.341628: step 1780, loss 0.548874.
Train: 2018-07-31T00:42:28.482200: step 1781, loss 0.628053.
Train: 2018-07-31T00:42:28.622781: step 1782, loss 0.521666.
Train: 2018-07-31T00:42:28.779019: step 1783, loss 0.619902.
Train: 2018-07-31T00:42:28.935209: step 1784, loss 0.58714.
Train: 2018-07-31T00:42:29.075801: step 1785, loss 0.529893.
Train: 2018-07-31T00:42:29.216394: step 1786, loss 0.570773.
Train: 2018-07-31T00:42:29.356985: step 1787, loss 0.497252.
Train: 2018-07-31T00:42:29.497576: step 1788, loss 0.529876.
Train: 2018-07-31T00:42:29.638170: step 1789, loss 0.554384.
Train: 2018-07-31T00:42:29.778780: step 1790, loss 0.587169.
Test: 2018-07-31T00:42:30.028733: step 1790, loss 0.548794.
Train: 2018-07-31T00:42:30.169343: step 1791, loss 0.537912.
Train: 2018-07-31T00:42:30.309911: step 1792, loss 0.562531.
Train: 2018-07-31T00:42:30.450477: step 1793, loss 0.595459.
Train: 2018-07-31T00:42:30.606716: step 1794, loss 0.620166.
Train: 2018-07-31T00:42:30.747284: step 1795, loss 0.554307.
Train: 2018-07-31T00:42:30.887876: step 1796, loss 0.570759.
Train: 2018-07-31T00:42:31.028469: step 1797, loss 0.554336.
Train: 2018-07-31T00:42:31.169074: step 1798, loss 0.546133.
Train: 2018-07-31T00:42:31.309678: step 1799, loss 0.537943.
Train: 2018-07-31T00:42:31.465866: step 1800, loss 0.619998.
Test: 2018-07-31T00:42:31.700218: step 1800, loss 0.548829.
Train: 2018-07-31T00:42:32.465633: step 1801, loss 0.570802.
Train: 2018-07-31T00:42:32.621846: step 1802, loss 0.587133.
Train: 2018-07-31T00:42:32.762438: step 1803, loss 0.497201.
Train: 2018-07-31T00:42:32.903054: step 1804, loss 0.513528.
Train: 2018-07-31T00:42:33.043622: step 1805, loss 0.497089.
Train: 2018-07-31T00:42:33.184215: step 1806, loss 0.54603.
Train: 2018-07-31T00:42:33.340428: step 1807, loss 0.636866.
Train: 2018-07-31T00:42:33.481044: step 1808, loss 0.521349.
Train: 2018-07-31T00:42:33.621612: step 1809, loss 0.554157.
Train: 2018-07-31T00:42:33.762202: step 1810, loss 0.520977.
Test: 2018-07-31T00:42:34.012146: step 1810, loss 0.54856.
Train: 2018-07-31T00:42:34.152736: step 1811, loss 0.56264.
Train: 2018-07-31T00:42:34.293329: step 1812, loss 0.562484.
Train: 2018-07-31T00:42:34.433922: step 1813, loss 0.587598.
Train: 2018-07-31T00:42:34.574512: step 1814, loss 0.479422.
Train: 2018-07-31T00:42:34.715130: step 1815, loss 0.479105.
Train: 2018-07-31T00:42:34.871318: step 1816, loss 0.570725.
Train: 2018-07-31T00:42:35.027567: step 1817, loss 0.562469.
Train: 2018-07-31T00:42:35.168125: step 1818, loss 0.503531.
Train: 2018-07-31T00:42:35.324338: step 1819, loss 0.587899.
Train: 2018-07-31T00:42:35.464953: step 1820, loss 0.528528.
Test: 2018-07-31T00:42:35.699250: step 1820, loss 0.548141.
Train: 2018-07-31T00:42:35.839842: step 1821, loss 0.57078.
Train: 2018-07-31T00:42:35.996056: step 1822, loss 0.570838.
Train: 2018-07-31T00:42:36.136649: step 1823, loss 0.553902.
Train: 2018-07-31T00:42:36.292885: step 1824, loss 0.56237.
Train: 2018-07-31T00:42:36.449098: step 1825, loss 0.630491.
Train: 2018-07-31T00:42:36.589691: step 1826, loss 0.596331.
Train: 2018-07-31T00:42:36.730282: step 1827, loss 0.562386.
Train: 2018-07-31T00:42:36.886472: step 1828, loss 0.545385.
Train: 2018-07-31T00:42:37.027081: step 1829, loss 0.59623.
Train: 2018-07-31T00:42:37.167655: step 1830, loss 0.528567.
Test: 2018-07-31T00:42:37.417627: step 1830, loss 0.548235.
Train: 2018-07-31T00:42:37.558190: step 1831, loss 0.579238.
Train: 2018-07-31T00:42:37.698781: step 1832, loss 0.604488.
Train: 2018-07-31T00:42:37.839373: step 1833, loss 0.511993.
Train: 2018-07-31T00:42:37.979967: step 1834, loss 0.595925.
Train: 2018-07-31T00:42:38.104936: step 1835, loss 0.579152.
Train: 2018-07-31T00:42:38.245528: step 1836, loss 0.554072.
Train: 2018-07-31T00:42:38.386145: step 1837, loss 0.570765.
Train: 2018-07-31T00:42:38.526714: step 1838, loss 0.595685.
Train: 2018-07-31T00:42:38.667330: step 1839, loss 0.562465.
Train: 2018-07-31T00:42:38.807921: step 1840, loss 0.636879.
Test: 2018-07-31T00:42:39.057838: step 1840, loss 0.548737.
Train: 2018-07-31T00:42:39.198442: step 1841, loss 0.513124.
Train: 2018-07-31T00:42:39.339040: step 1842, loss 0.537917.
Train: 2018-07-31T00:42:39.479615: step 1843, loss 0.562563.
Train: 2018-07-31T00:42:39.620208: step 1844, loss 0.587154.
Train: 2018-07-31T00:42:39.776444: step 1845, loss 0.562619.
Train: 2018-07-31T00:42:39.917012: step 1846, loss 0.570787.
Train: 2018-07-31T00:42:40.073225: step 1847, loss 0.562648.
Train: 2018-07-31T00:42:40.213819: step 1848, loss 0.595144.
Train: 2018-07-31T00:42:40.354409: step 1849, loss 0.562696.
Train: 2018-07-31T00:42:40.495001: step 1850, loss 0.489977.
Test: 2018-07-31T00:42:40.744984: step 1850, loss 0.549188.
Train: 2018-07-31T00:42:40.885535: step 1851, loss 0.586971.
Train: 2018-07-31T00:42:41.026127: step 1852, loss 0.570809.
Train: 2018-07-31T00:42:41.166744: step 1853, loss 0.506238.
Train: 2018-07-31T00:42:41.307312: step 1854, loss 0.570805.
Train: 2018-07-31T00:42:41.447927: step 1855, loss 0.554636.
Train: 2018-07-31T00:42:41.604117: step 1856, loss 0.611241.
Train: 2018-07-31T00:42:41.729088: step 1857, loss 0.595057.
Train: 2018-07-31T00:42:41.869679: step 1858, loss 0.570817.
Train: 2018-07-31T00:42:42.010272: step 1859, loss 0.595025.
Train: 2018-07-31T00:42:42.150863: step 1860, loss 0.570824.
Test: 2018-07-31T00:42:42.400807: step 1860, loss 0.549322.
Train: 2018-07-31T00:42:42.541399: step 1861, loss 0.586909.
Train: 2018-07-31T00:42:42.681990: step 1862, loss 0.562808.
Train: 2018-07-31T00:42:42.822605: step 1863, loss 0.57085.
Train: 2018-07-31T00:42:42.963198: step 1864, loss 0.530851.
Train: 2018-07-31T00:42:43.103783: step 1865, loss 0.610833.
Train: 2018-07-31T00:42:43.244358: step 1866, loss 0.538968.
Train: 2018-07-31T00:42:43.400572: step 1867, loss 0.499061.
Train: 2018-07-31T00:42:43.541164: step 1868, loss 0.538956.
Train: 2018-07-31T00:42:43.681755: step 1869, loss 0.570908.
Train: 2018-07-31T00:42:43.822347: step 1870, loss 0.538862.
Test: 2018-07-31T00:42:44.056669: step 1870, loss 0.549353.
Train: 2018-07-31T00:42:44.212881: step 1871, loss 0.586873.
Train: 2018-07-31T00:42:44.353473: step 1872, loss 0.538753.
Train: 2018-07-31T00:42:44.478445: step 1873, loss 0.570693.
Train: 2018-07-31T00:42:44.634657: step 1874, loss 0.538495.
Train: 2018-07-31T00:42:44.775250: step 1875, loss 0.554839.
Train: 2018-07-31T00:42:44.931503: step 1876, loss 0.538593.
Train: 2018-07-31T00:42:45.072080: step 1877, loss 0.51401.
Train: 2018-07-31T00:42:45.212646: step 1878, loss 0.554725.
Train: 2018-07-31T00:42:45.353239: step 1879, loss 0.505457.
Train: 2018-07-31T00:42:45.493831: step 1880, loss 0.537884.
Test: 2018-07-31T00:42:45.728151: step 1880, loss 0.548679.
Train: 2018-07-31T00:42:45.868747: step 1881, loss 0.579129.
Train: 2018-07-31T00:42:46.024957: step 1882, loss 0.570531.
Train: 2018-07-31T00:42:46.149927: step 1883, loss 0.512523.
Train: 2018-07-31T00:42:46.306142: step 1884, loss 0.537192.
Train: 2018-07-31T00:42:46.446757: step 1885, loss 0.527672.
Train: 2018-07-31T00:42:46.587325: step 1886, loss 0.493872.
Train: 2018-07-31T00:42:46.727917: step 1887, loss 0.580594.
Train: 2018-07-31T00:42:46.884130: step 1888, loss 0.536769.
Train: 2018-07-31T00:42:47.024723: step 1889, loss 0.592516.
Train: 2018-07-31T00:42:47.165316: step 1890, loss 0.564048.
Test: 2018-07-31T00:42:47.415257: step 1890, loss 0.547701.
Train: 2018-07-31T00:42:47.555847: step 1891, loss 0.482039.
Train: 2018-07-31T00:42:47.712062: step 1892, loss 0.578865.
Train: 2018-07-31T00:42:47.852678: step 1893, loss 0.606735.
Train: 2018-07-31T00:42:48.008892: step 1894, loss 0.491448.
Train: 2018-07-31T00:42:48.149459: step 1895, loss 0.665966.
Train: 2018-07-31T00:42:48.290052: step 1896, loss 0.519407.
Train: 2018-07-31T00:42:48.430668: step 1897, loss 0.519451.
Train: 2018-07-31T00:42:48.571262: step 1898, loss 0.528414.
Train: 2018-07-31T00:42:48.711827: step 1899, loss 0.562382.
Train: 2018-07-31T00:42:48.868042: step 1900, loss 0.622211.
Test: 2018-07-31T00:42:49.102394: step 1900, loss 0.547942.
Train: 2018-07-31T00:42:49.899048: step 1901, loss 0.528168.
Train: 2018-07-31T00:42:50.055263: step 1902, loss 0.639692.
Train: 2018-07-31T00:42:50.195882: step 1903, loss 0.604573.
Train: 2018-07-31T00:42:50.352070: step 1904, loss 0.596208.
Train: 2018-07-31T00:42:50.492660: step 1905, loss 0.545206.
Train: 2018-07-31T00:42:50.633252: step 1906, loss 0.528947.
Train: 2018-07-31T00:42:50.773844: step 1907, loss 0.612516.
Train: 2018-07-31T00:42:50.914436: step 1908, loss 0.554124.
Train: 2018-07-31T00:42:51.055030: step 1909, loss 0.579067.
Train: 2018-07-31T00:42:51.211266: step 1910, loss 0.595583.
Test: 2018-07-31T00:42:51.445593: step 1910, loss 0.548724.
Train: 2018-07-31T00:42:51.601777: step 1911, loss 0.570732.
Train: 2018-07-31T00:42:51.742368: step 1912, loss 0.562554.
Train: 2018-07-31T00:42:51.882959: step 1913, loss 0.505346.
Train: 2018-07-31T00:42:52.023553: step 1914, loss 0.5871.
Train: 2018-07-31T00:42:52.164145: step 1915, loss 0.546337.
Train: 2018-07-31T00:42:52.304735: step 1916, loss 0.578919.
Train: 2018-07-31T00:42:52.460950: step 1917, loss 0.62762.
Train: 2018-07-31T00:42:52.617187: step 1918, loss 0.497944.
Train: 2018-07-31T00:42:52.757755: step 1919, loss 0.554629.
Train: 2018-07-31T00:42:52.898346: step 1920, loss 0.59504.
Test: 2018-07-31T00:42:53.148314: step 1920, loss 0.549239.
Train: 2018-07-31T00:42:53.288905: step 1921, loss 0.586947.
Train: 2018-07-31T00:42:53.445119: step 1922, loss 0.554722.
Train: 2018-07-31T00:42:53.601345: step 1923, loss 0.522584.
Train: 2018-07-31T00:42:53.741899: step 1924, loss 0.514567.
Train: 2018-07-31T00:42:53.882491: step 1925, loss 0.570834.
Train: 2018-07-31T00:42:54.023110: step 1926, loss 0.562777.
Train: 2018-07-31T00:42:54.163690: step 1927, loss 0.603055.
Train: 2018-07-31T00:42:54.319920: step 1928, loss 0.554708.
Train: 2018-07-31T00:42:54.460499: step 1929, loss 0.538587.
Train: 2018-07-31T00:42:54.616719: step 1930, loss 0.595009.
Test: 2018-07-31T00:42:54.851048: step 1930, loss 0.549252.
Train: 2018-07-31T00:42:55.007252: step 1931, loss 0.538561.
Train: 2018-07-31T00:42:55.147820: step 1932, loss 0.554679.
Train: 2018-07-31T00:42:55.288412: step 1933, loss 0.595036.
Train: 2018-07-31T00:42:55.444626: step 1934, loss 0.562747.
Train: 2018-07-31T00:42:55.585219: step 1935, loss 0.578885.
Train: 2018-07-31T00:42:55.725834: step 1936, loss 0.586955.
Train: 2018-07-31T00:42:55.866427: step 1937, loss 0.538568.
Train: 2018-07-31T00:42:56.006994: step 1938, loss 0.570822.
Train: 2018-07-31T00:42:56.163232: step 1939, loss 0.627253.
Train: 2018-07-31T00:42:56.303799: step 1940, loss 0.522544.
Test: 2018-07-31T00:42:56.553741: step 1940, loss 0.549312.
Train: 2018-07-31T00:42:56.694334: step 1941, loss 0.586917.
Train: 2018-07-31T00:42:56.850555: step 1942, loss 0.546717.
Train: 2018-07-31T00:42:56.991139: step 1943, loss 0.514593.
Train: 2018-07-31T00:42:57.131730: step 1944, loss 0.635178.
Train: 2018-07-31T00:42:57.287968: step 1945, loss 0.57084.
Train: 2018-07-31T00:42:57.444166: step 1946, loss 0.594927.
Train: 2018-07-31T00:42:57.600371: step 1947, loss 0.570853.
Train: 2018-07-31T00:42:57.740962: step 1948, loss 0.578859.
Train: 2018-07-31T00:42:57.881580: step 1949, loss 0.55489.
Train: 2018-07-31T00:42:58.037768: step 1950, loss 0.522997.
Test: 2018-07-31T00:42:58.272120: step 1950, loss 0.549531.
Train: 2018-07-31T00:42:58.412706: step 1951, loss 0.538954.
Train: 2018-07-31T00:42:58.553298: step 1952, loss 0.514961.
Train: 2018-07-31T00:42:58.709511: step 1953, loss 0.506838.
Train: 2018-07-31T00:42:58.865700: step 1954, loss 0.59492.
Train: 2018-07-31T00:42:59.006292: step 1955, loss 0.611061.
Train: 2018-07-31T00:42:59.162505: step 1956, loss 0.530542.
Train: 2018-07-31T00:42:59.303110: step 1957, loss 0.554665.
Train: 2018-07-31T00:42:59.443704: step 1958, loss 0.62743.
Train: 2018-07-31T00:42:59.599903: step 1959, loss 0.530367.
Train: 2018-07-31T00:42:59.740496: step 1960, loss 0.586987.
Test: 2018-07-31T00:42:59.990464: step 1960, loss 0.549158.
Train: 2018-07-31T00:43:00.131027: step 1961, loss 0.554625.
Train: 2018-07-31T00:43:00.287243: step 1962, loss 0.546521.
Train: 2018-07-31T00:43:00.427858: step 1963, loss 0.631801.
Train: 2018-07-31T00:43:00.568450: step 1964, loss 0.50603.
Train: 2018-07-31T00:43:00.724640: step 1965, loss 0.587038.
Train: 2018-07-31T00:43:00.865255: step 1966, loss 0.554595.
Train: 2018-07-31T00:43:01.005840: step 1967, loss 0.546456.
Train: 2018-07-31T00:43:01.146432: step 1968, loss 0.570787.
Train: 2018-07-31T00:43:01.302629: step 1969, loss 0.514001.
Train: 2018-07-31T00:43:01.443221: step 1970, loss 0.586962.
Test: 2018-07-31T00:43:01.693164: step 1970, loss 0.549019.
Train: 2018-07-31T00:43:01.833773: step 1971, loss 0.595157.
Train: 2018-07-31T00:43:01.974347: step 1972, loss 0.546367.
Train: 2018-07-31T00:43:02.114938: step 1973, loss 0.578724.
Train: 2018-07-31T00:43:02.255531: step 1974, loss 0.538476.
Train: 2018-07-31T00:43:02.396122: step 1975, loss 0.57928.
Train: 2018-07-31T00:43:02.536714: step 1976, loss 0.529957.
Train: 2018-07-31T00:43:02.677307: step 1977, loss 0.554272.
Train: 2018-07-31T00:43:02.833545: step 1978, loss 0.554249.
Train: 2018-07-31T00:43:02.989758: step 1979, loss 0.570699.
Train: 2018-07-31T00:43:03.130350: step 1980, loss 0.529914.
Test: 2018-07-31T00:43:03.364675: step 1980, loss 0.548777.
Train: 2018-07-31T00:43:03.520861: step 1981, loss 0.538061.
Train: 2018-07-31T00:43:03.661453: step 1982, loss 0.471523.
Train: 2018-07-31T00:43:03.817666: step 1983, loss 0.553803.
Train: 2018-07-31T00:43:03.958257: step 1984, loss 0.604207.
Train: 2018-07-31T00:43:04.098900: step 1985, loss 0.545565.
Train: 2018-07-31T00:43:04.255062: step 1986, loss 0.570117.
Train: 2018-07-31T00:43:04.395655: step 1987, loss 0.639764.
Train: 2018-07-31T00:43:04.536248: step 1988, loss 0.528237.
Train: 2018-07-31T00:43:04.676863: step 1989, loss 0.605705.
Train: 2018-07-31T00:43:04.817431: step 1990, loss 0.595148.
Test: 2018-07-31T00:43:05.051752: step 1990, loss 0.548299.
Train: 2018-07-31T00:43:05.192344: step 1991, loss 0.604026.
Train: 2018-07-31T00:43:05.332959: step 1992, loss 0.52858.
Train: 2018-07-31T00:43:05.489150: step 1993, loss 0.562835.
Train: 2018-07-31T00:43:05.645363: step 1994, loss 0.612165.
Train: 2018-07-31T00:43:05.785955: step 1995, loss 0.570397.
Train: 2018-07-31T00:43:05.926546: step 1996, loss 0.538192.
Train: 2018-07-31T00:43:06.082784: step 1997, loss 0.538044.
Train: 2018-07-31T00:43:06.223376: step 1998, loss 0.562664.
Train: 2018-07-31T00:43:06.363961: step 1999, loss 0.570745.
Train: 2018-07-31T00:43:06.520183: step 2000, loss 0.538346.
Test: 2018-07-31T00:43:06.770118: step 2000, loss 0.549069.
Train: 2018-07-31T00:43:07.504326: step 2001, loss 0.514028.
Train: 2018-07-31T00:43:07.676136: step 2002, loss 0.530085.
Train: 2018-07-31T00:43:07.832375: step 2003, loss 0.570829.
Train: 2018-07-31T00:43:07.972967: step 2004, loss 0.562544.
Train: 2018-07-31T00:43:08.129179: step 2005, loss 0.554051.
Train: 2018-07-31T00:43:08.269747: step 2006, loss 0.619588.
Train: 2018-07-31T00:43:08.410340: step 2007, loss 0.529926.
Train: 2018-07-31T00:43:08.550933: step 2008, loss 0.554514.
Train: 2018-07-31T00:43:08.707145: step 2009, loss 0.554677.
Train: 2018-07-31T00:43:08.847762: step 2010, loss 0.538038.
Test: 2018-07-31T00:43:09.097680: step 2010, loss 0.548762.
Train: 2018-07-31T00:43:09.269537: step 2011, loss 0.56298.
Train: 2018-07-31T00:43:09.410130: step 2012, loss 0.619973.
Train: 2018-07-31T00:43:09.566320: step 2013, loss 0.546288.
Train: 2018-07-31T00:43:09.706911: step 2014, loss 0.562784.
Train: 2018-07-31T00:43:09.847528: step 2015, loss 0.611743.
Train: 2018-07-31T00:43:10.003744: step 2016, loss 0.545955.
Train: 2018-07-31T00:43:10.144333: step 2017, loss 0.54629.
Train: 2018-07-31T00:43:10.284905: step 2018, loss 0.505305.
Train: 2018-07-31T00:43:10.425492: step 2019, loss 0.546048.
Train: 2018-07-31T00:43:10.566114: step 2020, loss 0.63643.
Test: 2018-07-31T00:43:10.800418: step 2020, loss 0.548871.
Train: 2018-07-31T00:43:10.956619: step 2021, loss 0.619793.
Train: 2018-07-31T00:43:11.097234: step 2022, loss 0.538205.
Train: 2018-07-31T00:43:11.237802: step 2023, loss 0.52185.
Train: 2018-07-31T00:43:11.394016: step 2024, loss 0.59532.
Train: 2018-07-31T00:43:11.534632: step 2025, loss 0.570673.
Train: 2018-07-31T00:43:11.675225: step 2026, loss 0.627623.
Train: 2018-07-31T00:43:11.815817: step 2027, loss 0.538364.
Train: 2018-07-31T00:43:11.972006: step 2028, loss 0.473455.
Train: 2018-07-31T00:43:12.112597: step 2029, loss 0.473575.
Train: 2018-07-31T00:43:12.268835: step 2030, loss 0.570819.
Test: 2018-07-31T00:43:12.518782: step 2030, loss 0.548944.
Train: 2018-07-31T00:43:12.659371: step 2031, loss 0.522066.
Train: 2018-07-31T00:43:12.799937: step 2032, loss 0.521714.
Train: 2018-07-31T00:43:12.956149: step 2033, loss 0.579013.
Train: 2018-07-31T00:43:13.096741: step 2034, loss 0.513267.
Train: 2018-07-31T00:43:13.237364: step 2035, loss 0.56256.
Train: 2018-07-31T00:43:13.377926: step 2036, loss 0.537406.
Train: 2018-07-31T00:43:13.518519: step 2037, loss 0.537365.
Train: 2018-07-31T00:43:13.674737: step 2038, loss 0.545697.
Train: 2018-07-31T00:43:13.815324: step 2039, loss 0.562552.
Train: 2018-07-31T00:43:13.971538: step 2040, loss 0.495307.
Test: 2018-07-31T00:43:14.205883: step 2040, loss 0.5482.
Train: 2018-07-31T00:43:14.346474: step 2041, loss 0.579296.
Train: 2018-07-31T00:43:14.502688: step 2042, loss 0.545337.
Train: 2018-07-31T00:43:14.643254: step 2043, loss 0.579257.
Train: 2018-07-31T00:43:14.799468: step 2044, loss 0.485911.
Train: 2018-07-31T00:43:14.940060: step 2045, loss 0.510788.
Train: 2018-07-31T00:43:15.080652: step 2046, loss 0.553902.
Train: 2018-07-31T00:43:15.221270: step 2047, loss 0.536406.
Train: 2018-07-31T00:43:15.361863: step 2048, loss 0.605897.
Train: 2018-07-31T00:43:15.502453: step 2049, loss 0.553816.
Train: 2018-07-31T00:43:15.643020: step 2050, loss 0.553682.
Test: 2018-07-31T00:43:15.877366: step 2050, loss 0.547817.
Train: 2018-07-31T00:43:16.033555: step 2051, loss 0.649212.
Train: 2018-07-31T00:43:16.174147: step 2052, loss 0.579747.
Train: 2018-07-31T00:43:16.330384: step 2053, loss 0.631258.
Train: 2018-07-31T00:43:16.470976: step 2054, loss 0.605284.
Train: 2018-07-31T00:43:16.611569: step 2055, loss 0.579463.
Train: 2018-07-31T00:43:16.752163: step 2056, loss 0.579351.
Train: 2018-07-31T00:43:16.892729: step 2057, loss 0.714815.
Train: 2018-07-31T00:43:17.033345: step 2058, loss 0.612812.
Train: 2018-07-31T00:43:17.173930: step 2059, loss 0.579087.
Train: 2018-07-31T00:43:17.330126: step 2060, loss 0.628641.
Test: 2018-07-31T00:43:17.564448: step 2060, loss 0.548829.
Train: 2018-07-31T00:43:17.720658: step 2061, loss 0.529803.
Train: 2018-07-31T00:43:17.876897: step 2062, loss 0.5219.
Train: 2018-07-31T00:43:18.017464: step 2063, loss 0.603164.
Train: 2018-07-31T00:43:18.158058: step 2064, loss 0.554736.
Train: 2018-07-31T00:43:18.298648: step 2065, loss 0.610887.
Train: 2018-07-31T00:43:18.439241: step 2066, loss 0.5231.
Train: 2018-07-31T00:43:18.579858: step 2067, loss 0.539203.
Train: 2018-07-31T00:43:18.736047: step 2068, loss 0.539319.
Train: 2018-07-31T00:43:18.876663: step 2069, loss 0.484131.
Train: 2018-07-31T00:43:19.017230: step 2070, loss 0.523601.
Test: 2018-07-31T00:43:19.267203: step 2070, loss 0.549796.
Train: 2018-07-31T00:43:19.407764: step 2071, loss 0.586763.
Train: 2018-07-31T00:43:19.548381: step 2072, loss 0.578834.
Train: 2018-07-31T00:43:19.688949: step 2073, loss 0.555117.
Train: 2018-07-31T00:43:19.845161: step 2074, loss 0.594726.
Train: 2018-07-31T00:43:20.001375: step 2075, loss 0.602642.
Train: 2018-07-31T00:43:20.126346: step 2076, loss 0.602635.
Train: 2018-07-31T00:43:20.282559: step 2077, loss 0.618415.
Train: 2018-07-31T00:43:20.423151: step 2078, loss 0.555166.
Train: 2018-07-31T00:43:20.579365: step 2079, loss 0.594624.
Train: 2018-07-31T00:43:20.735577: step 2080, loss 0.531692.
Test: 2018-07-31T00:43:20.969899: step 2080, loss 0.550013.
Train: 2018-07-31T00:43:21.126111: step 2081, loss 0.633838.
Train: 2018-07-31T00:43:21.266705: step 2082, loss 0.477059.
Train: 2018-07-31T00:43:21.407321: step 2083, loss 0.52402.
Train: 2018-07-31T00:43:21.547912: step 2084, loss 0.539666.
Train: 2018-07-31T00:43:21.688480: step 2085, loss 0.563143.
Train: 2018-07-31T00:43:21.844702: step 2086, loss 0.578871.
Train: 2018-07-31T00:43:21.985285: step 2087, loss 0.586762.
Train: 2018-07-31T00:43:22.125902: step 2088, loss 0.578849.
Train: 2018-07-31T00:43:22.282092: step 2089, loss 0.515663.
Train: 2018-07-31T00:43:22.422708: step 2090, loss 0.594678.
Test: 2018-07-31T00:43:22.657004: step 2090, loss 0.549741.
Train: 2018-07-31T00:43:22.813216: step 2091, loss 0.586799.
Train: 2018-07-31T00:43:22.969459: step 2092, loss 0.578887.
Train: 2018-07-31T00:43:23.110022: step 2093, loss 0.475767.
Train: 2018-07-31T00:43:23.250615: step 2094, loss 0.610651.
Train: 2018-07-31T00:43:23.391206: step 2095, loss 0.547017.
Train: 2018-07-31T00:43:23.531798: step 2096, loss 0.554895.
Train: 2018-07-31T00:43:23.672415: step 2097, loss 0.570855.
Train: 2018-07-31T00:43:23.812991: step 2098, loss 0.546906.
Train: 2018-07-31T00:43:23.953575: step 2099, loss 0.562668.
Train: 2018-07-31T00:43:24.094167: step 2100, loss 0.603165.
Test: 2018-07-31T00:43:24.344141: step 2100, loss 0.549189.
Train: 2018-07-31T00:43:25.109555: step 2101, loss 0.546872.
Train: 2018-07-31T00:43:25.250145: step 2102, loss 0.635655.
Train: 2018-07-31T00:43:25.390738: step 2103, loss 0.538563.
Train: 2018-07-31T00:43:25.531330: step 2104, loss 0.538653.
Train: 2018-07-31T00:43:25.687568: step 2105, loss 0.58695.
Train: 2018-07-31T00:43:25.843757: step 2106, loss 0.498457.
Train: 2018-07-31T00:43:25.984377: step 2107, loss 0.627196.
Train: 2018-07-31T00:43:26.124942: step 2108, loss 0.466098.
Train: 2018-07-31T00:43:26.265534: step 2109, loss 0.530371.
Train: 2018-07-31T00:43:26.406126: step 2110, loss 0.570813.
Test: 2018-07-31T00:43:26.656068: step 2110, loss 0.549021.
Train: 2018-07-31T00:43:26.796659: step 2111, loss 0.586954.
Train: 2018-07-31T00:43:26.937275: step 2112, loss 0.554609.
Train: 2018-07-31T00:43:27.077868: step 2113, loss 0.587171.
Train: 2018-07-31T00:43:27.234081: step 2114, loss 0.597425.
Train: 2018-07-31T00:43:27.374648: step 2115, loss 0.530117.
Train: 2018-07-31T00:43:27.530863: step 2116, loss 0.530044.
Train: 2018-07-31T00:43:27.671455: step 2117, loss 0.52986.
Train: 2018-07-31T00:43:27.812045: step 2118, loss 0.554365.
Train: 2018-07-31T00:43:27.952662: step 2119, loss 0.521507.
Train: 2018-07-31T00:43:28.108852: step 2120, loss 0.537911.
Test: 2018-07-31T00:43:28.343172: step 2120, loss 0.548681.
Train: 2018-07-31T00:43:28.483789: step 2121, loss 0.512924.
Train: 2018-07-31T00:43:28.624355: step 2122, loss 0.562467.
Train: 2018-07-31T00:43:28.764947: step 2123, loss 0.620601.
Train: 2018-07-31T00:43:28.921186: step 2124, loss 0.495749.
Train: 2018-07-31T00:43:29.061752: step 2125, loss 0.595966.
Train: 2018-07-31T00:43:29.217968: step 2126, loss 0.554038.
Train: 2018-07-31T00:43:29.374181: step 2127, loss 0.570773.
Train: 2018-07-31T00:43:29.514771: step 2128, loss 0.520389.
Train: 2018-07-31T00:43:29.655365: step 2129, loss 0.553963.
Train: 2018-07-31T00:43:29.795958: step 2130, loss 0.5879.
Test: 2018-07-31T00:43:30.030289: step 2130, loss 0.548242.
Train: 2018-07-31T00:43:30.186491: step 2131, loss 0.587712.
Train: 2018-07-31T00:43:30.342728: step 2132, loss 0.5877.
Train: 2018-07-31T00:43:30.483295: step 2133, loss 0.587508.
Train: 2018-07-31T00:43:30.639533: step 2134, loss 0.520382.
Train: 2018-07-31T00:43:30.780101: step 2135, loss 0.587564.
Train: 2018-07-31T00:43:30.936339: step 2136, loss 0.56227.
Train: 2018-07-31T00:43:31.076931: step 2137, loss 0.637693.
Train: 2018-07-31T00:43:31.233121: step 2138, loss 0.554041.
Train: 2018-07-31T00:43:31.373737: step 2139, loss 0.53745.
Train: 2018-07-31T00:43:31.529956: step 2140, loss 0.6288.
Test: 2018-07-31T00:43:31.764247: step 2140, loss 0.548644.
Train: 2018-07-31T00:43:31.920459: step 2141, loss 0.562609.
Train: 2018-07-31T00:43:32.061076: step 2142, loss 0.570847.
Train: 2018-07-31T00:43:32.201669: step 2143, loss 0.505181.
Train: 2018-07-31T00:43:32.342236: step 2144, loss 0.611787.
Train: 2018-07-31T00:43:32.498448: step 2145, loss 0.497114.
Train: 2018-07-31T00:43:32.639096: step 2146, loss 0.49712.
Train: 2018-07-31T00:43:32.779632: step 2147, loss 0.587172.
Train: 2018-07-31T00:43:32.920225: step 2148, loss 0.521612.
Train: 2018-07-31T00:43:33.076450: step 2149, loss 0.562558.
Train: 2018-07-31T00:43:33.217054: step 2150, loss 0.595346.
Test: 2018-07-31T00:43:33.466972: step 2150, loss 0.548808.
Train: 2018-07-31T00:43:33.607563: step 2151, loss 0.546143.
Train: 2018-07-31T00:43:33.763776: step 2152, loss 0.587224.
Train: 2018-07-31T00:43:33.919991: step 2153, loss 0.529745.
Train: 2018-07-31T00:43:34.060601: step 2154, loss 0.587189.
Train: 2018-07-31T00:43:34.201188: step 2155, loss 0.554343.
Train: 2018-07-31T00:43:34.341803: step 2156, loss 0.570746.
Train: 2018-07-31T00:43:34.482359: step 2157, loss 0.546154.
Train: 2018-07-31T00:43:34.622951: step 2158, loss 0.595399.
Train: 2018-07-31T00:43:34.763568: step 2159, loss 0.546144.
Train: 2018-07-31T00:43:34.935379: step 2160, loss 0.562569.
Test: 2018-07-31T00:43:35.169698: step 2160, loss 0.548828.
Train: 2018-07-31T00:43:35.325913: step 2161, loss 0.496952.
Train: 2018-07-31T00:43:35.466503: step 2162, loss 0.513281.
Train: 2018-07-31T00:43:35.622718: step 2163, loss 0.603676.
Train: 2018-07-31T00:43:35.778929: step 2164, loss 0.57077.
Train: 2018-07-31T00:43:35.935169: step 2165, loss 0.537781.
Train: 2018-07-31T00:43:36.075761: step 2166, loss 0.678038.
Train: 2018-07-31T00:43:36.216327: step 2167, loss 0.636662.
Train: 2018-07-31T00:43:36.356920: step 2168, loss 0.546118.
Train: 2018-07-31T00:43:36.497519: step 2169, loss 0.595343.
Train: 2018-07-31T00:43:36.638104: step 2170, loss 0.611595.
Test: 2018-07-31T00:43:36.872466: step 2170, loss 0.549032.
Train: 2018-07-31T00:43:37.028639: step 2171, loss 0.538253.
Train: 2018-07-31T00:43:37.169231: step 2172, loss 0.546472.
Train: 2018-07-31T00:43:37.294226: step 2173, loss 0.627419.
Train: 2018-07-31T00:43:37.450440: step 2174, loss 0.595006.
Train: 2018-07-31T00:43:37.591006: step 2175, loss 0.498591.
Train: 2018-07-31T00:43:37.747219: step 2176, loss 0.530791.
Train: 2018-07-31T00:43:37.887812: step 2177, loss 0.530823.
Train: 2018-07-31T00:43:38.028404: step 2178, loss 0.546841.
Train: 2018-07-31T00:43:38.168996: step 2179, loss 0.586876.
Train: 2018-07-31T00:43:38.309589: step 2180, loss 0.538808.
Test: 2018-07-31T00:43:38.543941: step 2180, loss 0.549408.
Train: 2018-07-31T00:43:38.700121: step 2181, loss 0.59489.
Train: 2018-07-31T00:43:38.840713: step 2182, loss 0.546802.
Train: 2018-07-31T00:43:38.996927: step 2183, loss 0.586888.
Train: 2018-07-31T00:43:39.137536: step 2184, loss 0.522737.
Train: 2018-07-31T00:43:39.278137: step 2185, loss 0.635042.
Train: 2018-07-31T00:43:39.434350: step 2186, loss 0.522737.
Train: 2018-07-31T00:43:39.574942: step 2187, loss 0.498643.
Train: 2018-07-31T00:43:39.731130: step 2188, loss 0.586897.
Train: 2018-07-31T00:43:39.887369: step 2189, loss 0.570823.
Train: 2018-07-31T00:43:40.027936: step 2190, loss 0.546634.
Test: 2018-07-31T00:43:40.262257: step 2190, loss 0.54924.
Train: 2018-07-31T00:43:40.418493: step 2191, loss 0.554683.
Train: 2018-07-31T00:43:40.574700: step 2192, loss 0.481944.
Train: 2018-07-31T00:43:40.715299: step 2193, loss 0.50596.
Train: 2018-07-31T00:43:40.871516: step 2194, loss 0.611471.
Train: 2018-07-31T00:43:41.012083: step 2195, loss 0.505477.
Train: 2018-07-31T00:43:41.152673: step 2196, loss 0.59534.
Train: 2018-07-31T00:43:41.293264: step 2197, loss 0.529668.
Train: 2018-07-31T00:43:41.433857: step 2198, loss 0.513097.
Train: 2018-07-31T00:43:41.574448: step 2199, loss 0.620405.
Train: 2018-07-31T00:43:41.715066: step 2200, loss 0.579023.
Test: 2018-07-31T00:43:41.965015: step 2200, loss 0.54856.
Train: 2018-07-31T00:43:42.683563: step 2201, loss 0.529292.
Train: 2018-07-31T00:43:42.839803: step 2202, loss 0.529215.
Train: 2018-07-31T00:43:42.980368: step 2203, loss 0.587419.
Train: 2018-07-31T00:43:43.120961: step 2204, loss 0.579112.
Train: 2018-07-31T00:43:43.277173: step 2205, loss 0.620833.
Train: 2018-07-31T00:43:43.433412: step 2206, loss 0.554099.
Train: 2018-07-31T00:43:43.589601: step 2207, loss 0.545735.
Train: 2018-07-31T00:43:43.730218: step 2208, loss 0.612427.
Train: 2018-07-31T00:43:43.870810: step 2209, loss 0.537507.
Train: 2018-07-31T00:43:44.026999: step 2210, loss 0.562401.
Test: 2018-07-31T00:43:44.261319: step 2210, loss 0.548523.
Train: 2018-07-31T00:43:44.417557: step 2211, loss 0.579076.
Train: 2018-07-31T00:43:44.573794: step 2212, loss 0.479451.
Train: 2018-07-31T00:43:44.714338: step 2213, loss 0.520927.
Train: 2018-07-31T00:43:44.854955: step 2214, loss 0.56245.
Train: 2018-07-31T00:43:45.011144: step 2215, loss 0.47913.
Train: 2018-07-31T00:43:45.151735: step 2216, loss 0.587459.
Train: 2018-07-31T00:43:45.307948: step 2217, loss 0.503835.
Train: 2018-07-31T00:43:45.464187: step 2218, loss 0.537191.
Train: 2018-07-31T00:43:45.604789: step 2219, loss 0.612863.
Train: 2018-07-31T00:43:45.760967: step 2220, loss 0.570813.
Test: 2018-07-31T00:43:45.995290: step 2220, loss 0.548237.
Train: 2018-07-31T00:43:46.151527: step 2221, loss 0.579252.
Train: 2018-07-31T00:43:46.292094: step 2222, loss 0.528627.
Train: 2018-07-31T00:43:46.432687: step 2223, loss 0.503287.
Train: 2018-07-31T00:43:46.573302: step 2224, loss 0.629987.
Train: 2018-07-31T00:43:46.713895: step 2225, loss 0.503166.
Train: 2018-07-31T00:43:46.854461: step 2226, loss 0.520072.
Train: 2018-07-31T00:43:47.010675: step 2227, loss 0.570855.
Train: 2018-07-31T00:43:47.151269: step 2228, loss 0.545365.
Train: 2018-07-31T00:43:47.291859: step 2229, loss 0.553856.
Train: 2018-07-31T00:43:47.448073: step 2230, loss 0.511279.
Test: 2018-07-31T00:43:47.682424: step 2230, loss 0.548057.
Train: 2018-07-31T00:43:47.822985: step 2231, loss 0.613481.
Train: 2018-07-31T00:43:47.979199: step 2232, loss 0.647651.
Train: 2018-07-31T00:43:48.135436: step 2233, loss 0.519781.
Train: 2018-07-31T00:43:48.291626: step 2234, loss 0.587858.
Train: 2018-07-31T00:43:48.432245: step 2235, loss 0.570849.
Train: 2018-07-31T00:43:48.572834: step 2236, loss 0.502999.
Train: 2018-07-31T00:43:48.729023: step 2237, loss 0.604738.
Train: 2018-07-31T00:43:48.869614: step 2238, loss 0.536973.
Train: 2018-07-31T00:43:49.025827: step 2239, loss 0.562367.
Train: 2018-07-31T00:43:49.182043: step 2240, loss 0.579282.
Test: 2018-07-31T00:43:49.416363: step 2240, loss 0.54826.
Train: 2018-07-31T00:43:49.556954: step 2241, loss 0.570783.
Train: 2018-07-31T00:43:49.709140: step 2242, loss 0.587583.
Train: 2018-07-31T00:43:49.849707: step 2243, loss 0.629541.
Train: 2018-07-31T00:43:50.005921: step 2244, loss 0.579139.
Train: 2018-07-31T00:43:50.162134: step 2245, loss 0.570747.
Train: 2018-07-31T00:43:50.302750: step 2246, loss 0.570739.
Train: 2018-07-31T00:43:50.443343: step 2247, loss 0.55424.
Train: 2018-07-31T00:43:50.583911: step 2248, loss 0.578993.
Train: 2018-07-31T00:43:50.724502: step 2249, loss 0.570759.
Train: 2018-07-31T00:43:50.865094: step 2250, loss 0.562573.
Test: 2018-07-31T00:43:51.115037: step 2250, loss 0.548937.
Train: 2018-07-31T00:43:51.255628: step 2251, loss 0.595263.
Train: 2018-07-31T00:43:51.411865: step 2252, loss 0.554507.
Train: 2018-07-31T00:43:51.552458: step 2253, loss 0.57891.
Train: 2018-07-31T00:43:51.693050: step 2254, loss 0.562713.
Train: 2018-07-31T00:43:51.849264: step 2255, loss 0.64341.
Train: 2018-07-31T00:43:51.989831: step 2256, loss 0.602974.
Train: 2018-07-31T00:43:52.130422: step 2257, loss 0.618831.
Train: 2018-07-31T00:43:52.271014: step 2258, loss 0.499348.
Train: 2018-07-31T00:43:52.411631: step 2259, loss 0.547165.
Train: 2018-07-31T00:43:52.567822: step 2260, loss 0.586757.
Test: 2018-07-31T00:43:52.802172: step 2260, loss 0.54989.
Train: 2018-07-31T00:43:52.942732: step 2261, loss 0.563093.
Train: 2018-07-31T00:43:53.083326: step 2262, loss 0.594604.
Train: 2018-07-31T00:43:53.223918: step 2263, loss 0.555334.
Train: 2018-07-31T00:43:53.380131: step 2264, loss 0.56321.
Train: 2018-07-31T00:43:53.520746: step 2265, loss 0.529869.
Train: 2018-07-31T00:43:53.676960: step 2266, loss 0.547615.
Train: 2018-07-31T00:43:53.817527: step 2267, loss 0.563243.
Train: 2018-07-31T00:43:53.958146: step 2268, loss 0.62583.
Train: 2018-07-31T00:43:54.098719: step 2269, loss 0.56324.
Train: 2018-07-31T00:43:54.239303: step 2270, loss 0.50856.
Test: 2018-07-31T00:43:54.489278: step 2270, loss 0.550138.
Train: 2018-07-31T00:43:54.629855: step 2271, loss 0.602347.
Train: 2018-07-31T00:43:54.786051: step 2272, loss 0.547587.
Train: 2018-07-31T00:43:54.926650: step 2273, loss 0.531893.
Train: 2018-07-31T00:43:55.082858: step 2274, loss 0.539654.
Train: 2018-07-31T00:43:55.223448: step 2275, loss 0.547411.
Train: 2018-07-31T00:43:55.364057: step 2276, loss 0.570958.
Train: 2018-07-31T00:43:55.504657: step 2277, loss 0.53145.
Train: 2018-07-31T00:43:55.660871: step 2278, loss 0.594701.
Train: 2018-07-31T00:43:55.801463: step 2279, loss 0.523221.
Train: 2018-07-31T00:43:55.942052: step 2280, loss 0.56293.
Test: 2018-07-31T00:43:56.192004: step 2280, loss 0.549489.
Train: 2018-07-31T00:43:56.348185: step 2281, loss 0.570862.
Train: 2018-07-31T00:43:56.488802: step 2282, loss 0.594881.
Train: 2018-07-31T00:43:56.613747: step 2283, loss 0.530705.
Train: 2018-07-31T00:43:56.769962: step 2284, loss 0.586888.
Train: 2018-07-31T00:43:56.894933: step 2285, loss 0.578903.
Train: 2018-07-31T00:43:57.066767: step 2286, loss 0.546648.
Train: 2018-07-31T00:43:57.223005: step 2287, loss 0.594956.
Train: 2018-07-31T00:43:57.379193: step 2288, loss 0.514226.
Train: 2018-07-31T00:43:57.519787: step 2289, loss 0.497915.
Train: 2018-07-31T00:43:57.676024: step 2290, loss 0.562635.
Test: 2018-07-31T00:43:57.910320: step 2290, loss 0.548992.
Train: 2018-07-31T00:43:58.066534: step 2291, loss 0.652267.
Train: 2018-07-31T00:43:58.207150: step 2292, loss 0.513761.
Train: 2018-07-31T00:43:58.347717: step 2293, loss 0.562626.
Train: 2018-07-31T00:43:58.488311: step 2294, loss 0.562637.
Train: 2018-07-31T00:43:58.628900: step 2295, loss 0.497121.
Train: 2018-07-31T00:43:58.769492: step 2296, loss 0.620066.
Train: 2018-07-31T00:43:58.925721: step 2297, loss 0.521582.
Train: 2018-07-31T00:43:59.081920: step 2298, loss 0.496731.
Train: 2018-07-31T00:43:59.222513: step 2299, loss 0.579018.
Train: 2018-07-31T00:43:59.363104: step 2300, loss 0.512814.
Test: 2018-07-31T00:43:59.597426: step 2300, loss 0.548568.
Train: 2018-07-31T00:44:00.316030: step 2301, loss 0.587286.
Train: 2018-07-31T00:44:00.472221: step 2302, loss 0.678869.
Train: 2018-07-31T00:44:00.612829: step 2303, loss 0.595666.
Train: 2018-07-31T00:44:00.753404: step 2304, loss 0.496167.
Train: 2018-07-31T00:44:00.894020: step 2305, loss 0.529317.
Train: 2018-07-31T00:44:01.050234: step 2306, loss 0.595614.
Train: 2018-07-31T00:44:01.190801: step 2307, loss 0.504437.
Train: 2018-07-31T00:44:01.331393: step 2308, loss 0.595706.
Train: 2018-07-31T00:44:01.471985: step 2309, loss 0.554177.
Train: 2018-07-31T00:44:01.628198: step 2310, loss 0.537459.
Test: 2018-07-31T00:44:01.862547: step 2310, loss 0.548528.
Train: 2018-07-31T00:44:02.018732: step 2311, loss 0.537453.
Train: 2018-07-31T00:44:02.159326: step 2312, loss 0.470935.
Train: 2018-07-31T00:44:02.315538: step 2313, loss 0.495636.
Train: 2018-07-31T00:44:02.456129: step 2314, loss 0.545676.
Train: 2018-07-31T00:44:02.596722: step 2315, loss 0.553942.
Train: 2018-07-31T00:44:02.737313: step 2316, loss 0.553752.
Train: 2018-07-31T00:44:02.877930: step 2317, loss 0.553791.
Train: 2018-07-31T00:44:03.018498: step 2318, loss 0.613373.
Train: 2018-07-31T00:44:03.159115: step 2319, loss 0.664221.
Train: 2018-07-31T00:44:03.299708: step 2320, loss 0.553794.
Test: 2018-07-31T00:44:03.534049: step 2320, loss 0.548143.
Train: 2018-07-31T00:44:03.690240: step 2321, loss 0.570778.
Train: 2018-07-31T00:44:03.830809: step 2322, loss 0.536961.
Train: 2018-07-31T00:44:03.971399: step 2323, loss 0.613119.
Train: 2018-07-31T00:44:04.111991: step 2324, loss 0.520135.
Train: 2018-07-31T00:44:04.268205: step 2325, loss 0.562575.
Train: 2018-07-31T00:44:04.424419: step 2326, loss 0.570832.
Train: 2018-07-31T00:44:04.565011: step 2327, loss 0.511897.
Train: 2018-07-31T00:44:04.705603: step 2328, loss 0.49516.
Train: 2018-07-31T00:44:04.861816: step 2329, loss 0.478074.
Train: 2018-07-31T00:44:05.002410: step 2330, loss 0.562378.
Test: 2018-07-31T00:44:05.252381: step 2330, loss 0.54819.
Train: 2018-07-31T00:44:05.392966: step 2331, loss 0.562482.
Train: 2018-07-31T00:44:05.549157: step 2332, loss 0.604653.
Train: 2018-07-31T00:44:05.705370: step 2333, loss 0.570959.
Train: 2018-07-31T00:44:05.845962: step 2334, loss 0.503003.
Train: 2018-07-31T00:44:05.986552: step 2335, loss 0.511625.
Train: 2018-07-31T00:44:06.127144: step 2336, loss 0.511373.
Train: 2018-07-31T00:44:06.267752: step 2337, loss 0.545467.
Train: 2018-07-31T00:44:06.439573: step 2338, loss 0.485359.
Train: 2018-07-31T00:44:06.580189: step 2339, loss 0.562375.
Train: 2018-07-31T00:44:06.705135: step 2340, loss 0.553733.
Test: 2018-07-31T00:44:06.955127: step 2340, loss 0.547892.
Train: 2018-07-31T00:44:07.111290: step 2341, loss 0.588347.
Train: 2018-07-31T00:44:07.251883: step 2342, loss 0.605592.
Train: 2018-07-31T00:44:07.392474: step 2343, loss 0.579687.
Train: 2018-07-31T00:44:07.533067: step 2344, loss 0.570905.
Train: 2018-07-31T00:44:07.673659: step 2345, loss 0.622631.
Train: 2018-07-31T00:44:07.814249: step 2346, loss 0.622345.
Train: 2018-07-31T00:44:07.970462: step 2347, loss 0.562427.
Train: 2018-07-31T00:44:08.111056: step 2348, loss 0.596474.
Train: 2018-07-31T00:44:08.251648: step 2349, loss 0.5198.
Train: 2018-07-31T00:44:08.407860: step 2350, loss 0.638555.
Test: 2018-07-31T00:44:08.642225: step 2350, loss 0.548248.
Train: 2018-07-31T00:44:08.798412: step 2351, loss 0.562342.
Train: 2018-07-31T00:44:08.938986: step 2352, loss 0.562443.
Train: 2018-07-31T00:44:09.095200: step 2353, loss 0.579173.
Train: 2018-07-31T00:44:09.235816: step 2354, loss 0.570767.
Train: 2018-07-31T00:44:09.392012: step 2355, loss 0.4381.
Train: 2018-07-31T00:44:09.532616: step 2356, loss 0.587306.
Train: 2018-07-31T00:44:09.688836: step 2357, loss 0.562475.
Train: 2018-07-31T00:44:09.829404: step 2358, loss 0.587283.
Train: 2018-07-31T00:44:09.969997: step 2359, loss 0.620255.
Train: 2018-07-31T00:44:10.126233: step 2360, loss 0.537908.
Test: 2018-07-31T00:44:10.360562: step 2360, loss 0.548836.
Train: 2018-07-31T00:44:10.516742: step 2361, loss 0.56258.
Train: 2018-07-31T00:44:10.657358: step 2362, loss 0.505322.
Train: 2018-07-31T00:44:10.797926: step 2363, loss 0.587124.
Train: 2018-07-31T00:44:10.938543: step 2364, loss 0.505437.
Train: 2018-07-31T00:44:11.079111: step 2365, loss 0.554413.
Train: 2018-07-31T00:44:11.235349: step 2366, loss 0.505386.
Train: 2018-07-31T00:44:11.375917: step 2367, loss 0.669001.
Train: 2018-07-31T00:44:11.532130: step 2368, loss 0.619841.
Train: 2018-07-31T00:44:11.657102: step 2369, loss 0.570769.
Train: 2018-07-31T00:44:11.797692: step 2370, loss 0.587068.
Test: 2018-07-31T00:44:12.047635: step 2370, loss 0.549054.
Train: 2018-07-31T00:44:12.203848: step 2371, loss 0.530159.
Train: 2018-07-31T00:44:12.328818: step 2372, loss 0.570803.
Train: 2018-07-31T00:44:12.485047: step 2373, loss 0.619406.
Train: 2018-07-31T00:44:12.641246: step 2374, loss 0.506168.
Train: 2018-07-31T00:44:12.781861: step 2375, loss 0.619243.
Train: 2018-07-31T00:44:12.922454: step 2376, loss 0.56277.
Train: 2018-07-31T00:44:13.063046: step 2377, loss 0.578872.
Train: 2018-07-31T00:44:13.203613: step 2378, loss 0.675139.
Train: 2018-07-31T00:44:13.344204: step 2379, loss 0.562892.
Train: 2018-07-31T00:44:13.484797: step 2380, loss 0.531126.
Test: 2018-07-31T00:44:13.734772: step 2380, loss 0.549699.
Train: 2018-07-31T00:44:13.875355: step 2381, loss 0.578857.
Train: 2018-07-31T00:44:14.031544: step 2382, loss 0.586774.
Train: 2018-07-31T00:44:14.172136: step 2383, loss 0.594646.
Train: 2018-07-31T00:44:14.312727: step 2384, loss 0.547399.
Train: 2018-07-31T00:44:14.453321: step 2385, loss 0.586722.
Train: 2018-07-31T00:44:14.593914: step 2386, loss 0.555383.
Train: 2018-07-31T00:44:14.734505: step 2387, loss 0.586701.
Train: 2018-07-31T00:44:14.875121: step 2388, loss 0.547679.
Train: 2018-07-31T00:44:15.015689: step 2389, loss 0.524341.
Train: 2018-07-31T00:44:15.171903: step 2390, loss 0.532121.
Test: 2018-07-31T00:44:15.406254: step 2390, loss 0.55021.
Train: 2018-07-31T00:44:15.562435: step 2391, loss 0.563279.
Train: 2018-07-31T00:44:15.703060: step 2392, loss 0.578885.
Train: 2018-07-31T00:44:15.843620: step 2393, loss 0.594528.
Train: 2018-07-31T00:44:15.999834: step 2394, loss 0.531927.
Train: 2018-07-31T00:44:16.124803: step 2395, loss 0.524028.
Train: 2018-07-31T00:44:16.281018: step 2396, loss 0.625997.
Train: 2018-07-31T00:44:16.421609: step 2397, loss 0.610309.
Train: 2018-07-31T00:44:16.562202: step 2398, loss 0.492435.
Train: 2018-07-31T00:44:16.702794: step 2399, loss 0.578864.
Train: 2018-07-31T00:44:16.843386: step 2400, loss 0.578863.
Test: 2018-07-31T00:44:17.093352: step 2400, loss 0.549873.
Train: 2018-07-31T00:44:17.843152: step 2401, loss 0.547308.
Train: 2018-07-31T00:44:17.999389: step 2402, loss 0.578863.
Train: 2018-07-31T00:44:18.139956: step 2403, loss 0.626314.
Train: 2018-07-31T00:44:18.280551: step 2404, loss 0.547242.
Train: 2018-07-31T00:44:18.436763: step 2405, loss 0.618388.
Train: 2018-07-31T00:44:18.577379: step 2406, loss 0.547268.
Train: 2018-07-31T00:44:18.717966: step 2407, loss 0.563077.
Train: 2018-07-31T00:44:18.858563: step 2408, loss 0.618326.
Train: 2018-07-31T00:44:18.999155: step 2409, loss 0.586748.
Train: 2018-07-31T00:44:19.155345: step 2410, loss 0.594603.
Test: 2018-07-31T00:44:19.389691: step 2410, loss 0.550013.
Train: 2018-07-31T00:44:19.545926: step 2411, loss 0.539606.
Train: 2018-07-31T00:44:19.686495: step 2412, loss 0.500426.
Train: 2018-07-31T00:44:19.827062: step 2413, loss 0.531767.
Train: 2018-07-31T00:44:19.967679: step 2414, loss 0.539552.
Train: 2018-07-31T00:44:20.123867: step 2415, loss 0.57886.
Train: 2018-07-31T00:44:20.280106: step 2416, loss 0.495681.
Train: 2018-07-31T00:44:20.451941: step 2417, loss 0.531312.
Train: 2018-07-31T00:44:20.592508: step 2418, loss 0.586817.
Train: 2018-07-31T00:44:20.717503: step 2419, loss 0.570882.
Train: 2018-07-31T00:44:20.873716: step 2420, loss 0.634898.
Test: 2018-07-31T00:44:21.123633: step 2420, loss 0.549427.
Train: 2018-07-31T00:44:21.264250: step 2421, loss 0.634937.
Train: 2018-07-31T00:44:21.420441: step 2422, loss 0.586871.
Train: 2018-07-31T00:44:21.545436: step 2423, loss 0.506914.
Train: 2018-07-31T00:44:21.686002: step 2424, loss 0.586858.
Train: 2018-07-31T00:44:21.842233: step 2425, loss 0.586862.
Train: 2018-07-31T00:44:21.998429: step 2426, loss 0.594839.
Train: 2018-07-31T00:44:22.139020: step 2427, loss 0.53098.
Train: 2018-07-31T00:44:22.279612: step 2428, loss 0.554923.
Train: 2018-07-31T00:44:22.435826: step 2429, loss 0.642688.
Train: 2018-07-31T00:44:22.576442: step 2430, loss 0.610718.
Test: 2018-07-31T00:44:22.826376: step 2430, loss 0.549666.
Train: 2018-07-31T00:44:22.966951: step 2431, loss 0.539136.
Train: 2018-07-31T00:44:23.107544: step 2432, loss 0.594715.
Train: 2018-07-31T00:44:23.248136: step 2433, loss 0.475968.
Train: 2018-07-31T00:44:23.388729: step 2434, loss 0.634291.
Train: 2018-07-31T00:44:23.529319: step 2435, loss 0.586775.
Train: 2018-07-31T00:44:23.669930: step 2436, loss 0.539384.
Train: 2018-07-31T00:44:23.826125: step 2437, loss 0.547296.
Train: 2018-07-31T00:44:23.966741: step 2438, loss 0.641992.
Train: 2018-07-31T00:44:24.122932: step 2439, loss 0.649761.
Train: 2018-07-31T00:44:24.263548: step 2440, loss 0.539637.
Test: 2018-07-31T00:44:24.497860: step 2440, loss 0.550108.
Train: 2018-07-31T00:44:24.654082: step 2441, loss 0.531905.
Train: 2018-07-31T00:44:24.794648: step 2442, loss 0.539784.
Train: 2018-07-31T00:44:24.950862: step 2443, loss 0.657066.
Train: 2018-07-31T00:44:25.091454: step 2444, loss 0.477506.
Train: 2018-07-31T00:44:25.247669: step 2445, loss 0.610096.
Train: 2018-07-31T00:44:25.388260: step 2446, loss 0.555506.
Train: 2018-07-31T00:44:25.528851: step 2447, loss 0.5711.
Train: 2018-07-31T00:44:25.685066: step 2448, loss 0.563312.
Train: 2018-07-31T00:44:25.825659: step 2449, loss 0.524342.
Train: 2018-07-31T00:44:25.966250: step 2450, loss 0.508659.
Test: 2018-07-31T00:44:26.200569: step 2450, loss 0.550126.
Train: 2018-07-31T00:44:26.372405: step 2451, loss 0.484983.
Train: 2018-07-31T00:44:26.513021: step 2452, loss 0.531702.
Train: 2018-07-31T00:44:26.669209: step 2453, loss 0.531453.
Train: 2018-07-31T00:44:26.825447: step 2454, loss 0.570913.
Train: 2018-07-31T00:44:26.966017: step 2455, loss 0.475075.
Train: 2018-07-31T00:44:27.122236: step 2456, loss 0.586908.
Train: 2018-07-31T00:44:27.262838: step 2457, loss 0.578887.
Train: 2018-07-31T00:44:27.403412: step 2458, loss 0.530214.
Train: 2018-07-31T00:44:27.544031: step 2459, loss 0.603391.
Train: 2018-07-31T00:44:27.700243: step 2460, loss 0.529858.
Test: 2018-07-31T00:44:27.950193: step 2460, loss 0.548795.
Train: 2018-07-31T00:44:28.090751: step 2461, loss 0.537911.
Train: 2018-07-31T00:44:28.231343: step 2462, loss 0.496563.
Train: 2018-07-31T00:44:28.371961: step 2463, loss 0.529336.
Train: 2018-07-31T00:44:28.528149: step 2464, loss 0.554111.
Train: 2018-07-31T00:44:28.668767: step 2465, loss 0.620957.
Train: 2018-07-31T00:44:28.809334: step 2466, loss 0.520461.
Train: 2018-07-31T00:44:28.949926: step 2467, loss 0.537139.
Train: 2018-07-31T00:44:29.106163: step 2468, loss 0.520162.
Train: 2018-07-31T00:44:29.246732: step 2469, loss 0.545408.
Train: 2018-07-31T00:44:29.387349: step 2470, loss 0.477335.
Test: 2018-07-31T00:44:29.621646: step 2470, loss 0.548034.
Train: 2018-07-31T00:44:29.777857: step 2471, loss 0.570879.
Train: 2018-07-31T00:44:29.918473: step 2472, loss 0.528041.
Train: 2018-07-31T00:44:30.059058: step 2473, loss 0.493487.
Train: 2018-07-31T00:44:30.215279: step 2474, loss 0.579638.
Train: 2018-07-31T00:44:30.355847: step 2475, loss 0.518971.
Train: 2018-07-31T00:44:30.496438: step 2476, loss 0.553647.
Train: 2018-07-31T00:44:30.637031: step 2477, loss 0.475004.
Train: 2018-07-31T00:44:30.777624: step 2478, loss 0.536076.
Train: 2018-07-31T00:44:30.918215: step 2479, loss 0.60646.
Train: 2018-07-31T00:44:31.058808: step 2480, loss 0.527109.
Test: 2018-07-31T00:44:31.293128: step 2480, loss 0.547621.
Train: 2018-07-31T00:44:31.449340: step 2481, loss 0.597846.
Train: 2018-07-31T00:44:31.589932: step 2482, loss 0.589033.
Train: 2018-07-31T00:44:31.730524: step 2483, loss 0.659934.
Train: 2018-07-31T00:44:31.871117: step 2484, loss 0.518229.
Train: 2018-07-31T00:44:32.027332: step 2485, loss 0.544763.
Train: 2018-07-31T00:44:32.167948: step 2486, loss 0.52715.
Train: 2018-07-31T00:44:32.308514: step 2487, loss 0.562417.
Train: 2018-07-31T00:44:32.449107: step 2488, loss 0.553597.
Train: 2018-07-31T00:44:32.605320: step 2489, loss 0.544817.
Train: 2018-07-31T00:44:32.761557: step 2490, loss 0.588746.
Test: 2018-07-31T00:44:33.011474: step 2490, loss 0.547712.
Train: 2018-07-31T00:44:33.167689: step 2491, loss 0.56239.
Train: 2018-07-31T00:44:33.308281: step 2492, loss 0.606074.
Train: 2018-07-31T00:44:33.448873: step 2493, loss 0.501373.
Train: 2018-07-31T00:44:33.589464: step 2494, loss 0.614533.
Train: 2018-07-31T00:44:33.730055: step 2495, loss 0.545007.
Train: 2018-07-31T00:44:33.870648: step 2496, loss 0.588279.
Train: 2018-07-31T00:44:34.011265: step 2497, loss 0.588191.
Train: 2018-07-31T00:44:34.151832: step 2498, loss 0.527991.
Train: 2018-07-31T00:44:34.292449: step 2499, loss 0.528092.
Train: 2018-07-31T00:44:34.448637: step 2500, loss 0.545252.
Test: 2018-07-31T00:44:34.698609: step 2500, loss 0.548059.
Train: 2018-07-31T00:44:35.448428: step 2501, loss 0.596447.
Train: 2018-07-31T00:44:35.604616: step 2502, loss 0.553839.
Train: 2018-07-31T00:44:35.745234: step 2503, loss 0.57932.
Train: 2018-07-31T00:44:35.885801: step 2504, loss 0.503121.
Train: 2018-07-31T00:44:36.026393: step 2505, loss 0.62997.
Train: 2018-07-31T00:44:36.166985: step 2506, loss 0.570799.
Train: 2018-07-31T00:44:36.323199: step 2507, loss 0.503565.
Train: 2018-07-31T00:44:36.463816: step 2508, loss 0.637905.
Train: 2018-07-31T00:44:36.620005: step 2509, loss 0.587502.
Train: 2018-07-31T00:44:36.776242: step 2510, loss 0.5791.
Test: 2018-07-31T00:44:37.026189: step 2510, loss 0.548546.
Train: 2018-07-31T00:44:37.166765: step 2511, loss 0.603979.
Train: 2018-07-31T00:44:37.307344: step 2512, loss 0.512871.
Train: 2018-07-31T00:44:37.447936: step 2513, loss 0.562512.
Train: 2018-07-31T00:44:37.588529: step 2514, loss 0.537859.
Train: 2018-07-31T00:44:37.729120: step 2515, loss 0.587183.
Train: 2018-07-31T00:44:37.869712: step 2516, loss 0.505236.
Train: 2018-07-31T00:44:38.025953: step 2517, loss 0.529837.
Train: 2018-07-31T00:44:38.166517: step 2518, loss 0.562583.
Train: 2018-07-31T00:44:38.307110: step 2519, loss 0.578955.
Train: 2018-07-31T00:44:38.463323: step 2520, loss 0.578946.
Test: 2018-07-31T00:44:38.713265: step 2520, loss 0.548897.
Train: 2018-07-31T00:44:38.853858: step 2521, loss 0.538064.
Train: 2018-07-31T00:44:38.994474: step 2522, loss 0.505363.
Train: 2018-07-31T00:44:39.150686: step 2523, loss 0.619876.
Train: 2018-07-31T00:44:39.306900: step 2524, loss 0.603496.
Train: 2018-07-31T00:44:39.447468: step 2525, loss 0.513551.
Train: 2018-07-31T00:44:39.588060: step 2526, loss 0.570774.
Train: 2018-07-31T00:44:39.728676: step 2527, loss 0.611634.
Train: 2018-07-31T00:44:39.869245: step 2528, loss 0.538123.
Train: 2018-07-31T00:44:40.009836: step 2529, loss 0.636033.
Train: 2018-07-31T00:44:40.150428: step 2530, loss 0.505666.
Test: 2018-07-31T00:44:40.384749: step 2530, loss 0.549026.
Train: 2018-07-31T00:44:40.525341: step 2531, loss 0.562647.
Train: 2018-07-31T00:44:40.681554: step 2532, loss 0.497624.
Train: 2018-07-31T00:44:40.822145: step 2533, loss 0.595191.
Train: 2018-07-31T00:44:40.962738: step 2534, loss 0.619607.
Train: 2018-07-31T00:44:41.118952: step 2535, loss 0.627682.
Train: 2018-07-31T00:44:41.259544: step 2536, loss 0.522146.
Train: 2018-07-31T00:44:41.400136: step 2537, loss 0.546507.
Train: 2018-07-31T00:44:41.556349: step 2538, loss 0.55462.
Train: 2018-07-31T00:44:41.696942: step 2539, loss 0.570804.
Train: 2018-07-31T00:44:41.837558: step 2540, loss 0.570806.
Test: 2018-07-31T00:44:42.071855: step 2540, loss 0.549206.
Train: 2018-07-31T00:44:42.228068: step 2541, loss 0.530425.
Train: 2018-07-31T00:44:42.368660: step 2542, loss 0.603123.
Train: 2018-07-31T00:44:42.509252: step 2543, loss 0.578885.
Train: 2018-07-31T00:44:42.649843: step 2544, loss 0.578881.
Train: 2018-07-31T00:44:42.790459: step 2545, loss 0.603044.
Train: 2018-07-31T00:44:42.931026: step 2546, loss 0.498477.
Train: 2018-07-31T00:44:43.087240: step 2547, loss 0.54672.
Train: 2018-07-31T00:44:43.227857: step 2548, loss 0.562792.
Train: 2018-07-31T00:44:43.368449: step 2549, loss 0.675393.
Train: 2018-07-31T00:44:43.509016: step 2550, loss 0.635043.
Test: 2018-07-31T00:44:43.758958: step 2550, loss 0.549481.
Train: 2018-07-31T00:44:43.915173: step 2551, loss 0.602849.
Train: 2018-07-31T00:44:44.055764: step 2552, loss 0.61867.
Train: 2018-07-31T00:44:44.196354: step 2553, loss 0.563014.
Train: 2018-07-31T00:44:44.352569: step 2554, loss 0.484207.
Train: 2018-07-31T00:44:44.493160: step 2555, loss 0.570993.
Train: 2018-07-31T00:44:44.633752: step 2556, loss 0.563149.
Train: 2018-07-31T00:44:44.789991: step 2557, loss 0.523922.
Train: 2018-07-31T00:44:44.930583: step 2558, loss 0.547473.
Train: 2018-07-31T00:44:45.071152: step 2559, loss 0.571017.
Train: 2018-07-31T00:44:45.211743: step 2560, loss 0.539578.
Test: 2018-07-31T00:44:45.446064: step 2560, loss 0.549954.
Train: 2018-07-31T00:44:45.586655: step 2561, loss 0.578869.
Train: 2018-07-31T00:44:45.727265: step 2562, loss 0.578868.
Train: 2018-07-31T00:44:45.883461: step 2563, loss 0.515826.
Train: 2018-07-31T00:44:46.024051: step 2564, loss 0.570967.
Train: 2018-07-31T00:44:46.164673: step 2565, loss 0.491875.
Train: 2018-07-31T00:44:46.305237: step 2566, loss 0.57886.
Train: 2018-07-31T00:44:46.445829: step 2567, loss 0.61387.
Train: 2018-07-31T00:44:46.586420: step 2568, loss 0.53902.
Train: 2018-07-31T00:44:46.727037: step 2569, loss 0.475077.
Train: 2018-07-31T00:44:46.883226: step 2570, loss 0.618941.
Test: 2018-07-31T00:44:47.117547: step 2570, loss 0.54935.
Train: 2018-07-31T00:44:47.273761: step 2571, loss 0.611004.
Train: 2018-07-31T00:44:47.414377: step 2572, loss 0.586915.
Train: 2018-07-31T00:44:47.554945: step 2573, loss 0.53865.
Train: 2018-07-31T00:44:47.711182: step 2574, loss 0.58693.
Train: 2018-07-31T00:44:47.867372: step 2575, loss 0.603047.
Train: 2018-07-31T00:44:48.007988: step 2576, loss 0.578877.
Train: 2018-07-31T00:44:48.148581: step 2577, loss 0.538646.
Train: 2018-07-31T00:44:48.304793: step 2578, loss 0.474288.
Train: 2018-07-31T00:44:48.445385: step 2579, loss 0.546633.
Train: 2018-07-31T00:44:48.601598: step 2580, loss 0.554646.
Test: 2018-07-31T00:44:48.835923: step 2580, loss 0.549134.
Train: 2018-07-31T00:44:48.992108: step 2581, loss 0.586995.
Train: 2018-07-31T00:44:49.148322: step 2582, loss 0.56268.
Train: 2018-07-31T00:44:49.288913: step 2583, loss 0.505803.
Train: 2018-07-31T00:44:49.429529: step 2584, loss 0.546346.
Train: 2018-07-31T00:44:49.585742: step 2585, loss 0.644265.
Train: 2018-07-31T00:44:49.741933: step 2586, loss 0.538086.
Train: 2018-07-31T00:44:49.882524: step 2587, loss 0.578946.
Train: 2018-07-31T00:44:50.023115: step 2588, loss 0.546214.
Train: 2018-07-31T00:44:50.179330: step 2589, loss 0.538.
Train: 2018-07-31T00:44:50.319947: step 2590, loss 0.521552.
Test: 2018-07-31T00:44:50.569863: step 2590, loss 0.548776.
Train: 2018-07-31T00:44:50.710455: step 2591, loss 0.521448.
Train: 2018-07-31T00:44:50.866693: step 2592, loss 0.570757.
Train: 2018-07-31T00:44:51.007260: step 2593, loss 0.620313.
Train: 2018-07-31T00:44:51.147853: step 2594, loss 0.570756.
Train: 2018-07-31T00:44:51.288445: step 2595, loss 0.512884.
Train: 2018-07-31T00:44:51.429062: step 2596, loss 0.595592.
Train: 2018-07-31T00:44:51.569629: step 2597, loss 0.521067.
Train: 2018-07-31T00:44:51.710222: step 2598, loss 0.521009.
Train: 2018-07-31T00:44:51.835192: step 2599, loss 0.562452.
Train: 2018-07-31T00:44:51.991406: step 2600, loss 0.470914.
Test: 2018-07-31T00:44:52.225753: step 2600, loss 0.548438.
Train: 2018-07-31T00:44:52.991195: step 2601, loss 0.570768.
Train: 2018-07-31T00:44:53.131762: step 2602, loss 0.53729.
Train: 2018-07-31T00:44:53.287976: step 2603, loss 0.579179.
Train: 2018-07-31T00:44:53.444213: step 2604, loss 0.579204.
Train: 2018-07-31T00:44:53.584799: step 2605, loss 0.570797.
Train: 2018-07-31T00:44:53.725375: step 2606, loss 0.63825.
Train: 2018-07-31T00:44:53.881611: step 2607, loss 0.629754.
Train: 2018-07-31T00:44:54.022204: step 2608, loss 0.520382.
Train: 2018-07-31T00:44:54.162772: step 2609, loss 0.44496.
Train: 2018-07-31T00:44:54.318985: step 2610, loss 0.512008.
Test: 2018-07-31T00:44:54.553306: step 2610, loss 0.548291.
Train: 2018-07-31T00:44:54.709520: step 2611, loss 0.545555.
Train: 2018-07-31T00:44:54.850111: step 2612, loss 0.537088.
Train: 2018-07-31T00:44:54.990702: step 2613, loss 0.5877.
Train: 2018-07-31T00:44:55.146916: step 2614, loss 0.638456.
Train: 2018-07-31T00:44:55.303165: step 2615, loss 0.477876.
Train: 2018-07-31T00:44:55.443739: step 2616, loss 0.56236.
Train: 2018-07-31T00:44:55.584313: step 2617, loss 0.672365.
Train: 2018-07-31T00:44:55.724931: step 2618, loss 0.621486.
Train: 2018-07-31T00:44:55.865497: step 2619, loss 0.511859.
Train: 2018-07-31T00:44:56.021710: step 2620, loss 0.520368.
Test: 2018-07-31T00:44:56.256033: step 2620, loss 0.548329.
Train: 2018-07-31T00:44:56.412271: step 2621, loss 0.59597.
Train: 2018-07-31T00:44:56.552836: step 2622, loss 0.570779.
Train: 2018-07-31T00:44:56.693430: step 2623, loss 0.570773.
Train: 2018-07-31T00:44:56.849642: step 2624, loss 0.545724.
Train: 2018-07-31T00:44:56.990259: step 2625, loss 0.51242.
Train: 2018-07-31T00:44:57.130851: step 2626, loss 0.562433.
Train: 2018-07-31T00:44:57.271418: step 2627, loss 0.5208.
Train: 2018-07-31T00:44:57.412047: step 2628, loss 0.529113.
Train: 2018-07-31T00:44:57.552603: step 2629, loss 0.495723.
Train: 2018-07-31T00:44:57.693195: step 2630, loss 0.587483.
Test: 2018-07-31T00:44:57.943141: step 2630, loss 0.548394.
Train: 2018-07-31T00:44:58.083752: step 2631, loss 0.679546.
Train: 2018-07-31T00:44:58.239968: step 2632, loss 0.579125.
Train: 2018-07-31T00:44:58.380534: step 2633, loss 0.545747.
Train: 2018-07-31T00:44:58.536770: step 2634, loss 0.579091.
Train: 2018-07-31T00:44:58.677364: step 2635, loss 0.537506.
Train: 2018-07-31T00:44:58.833553: step 2636, loss 0.562455.
Train: 2018-07-31T00:44:58.974144: step 2637, loss 0.545871.
Train: 2018-07-31T00:44:59.114736: step 2638, loss 0.612207.
Train: 2018-07-31T00:44:59.255329: step 2639, loss 0.562482.
Train: 2018-07-31T00:44:59.395921: step 2640, loss 0.554234.
Test: 2018-07-31T00:44:59.645899: step 2640, loss 0.548692.
Train: 2018-07-31T00:44:59.786455: step 2641, loss 0.595504.
Train: 2018-07-31T00:44:59.927046: step 2642, loss 0.537829.
Train: 2018-07-31T00:45:00.083259: step 2643, loss 0.529653.
Train: 2018-07-31T00:45:00.223890: step 2644, loss 0.488592.
Train: 2018-07-31T00:45:00.380066: step 2645, loss 0.537854.
Train: 2018-07-31T00:45:00.520657: step 2646, loss 0.661381.
Train: 2018-07-31T00:45:00.676872: step 2647, loss 0.546063.
Train: 2018-07-31T00:45:00.817512: step 2648, loss 0.595441.
Train: 2018-07-31T00:45:00.989334: step 2649, loss 0.546106.
Train: 2018-07-31T00:45:01.129890: step 2650, loss 0.537914.
Test: 2018-07-31T00:45:01.364236: step 2650, loss 0.5488.
Train: 2018-07-31T00:45:01.520425: step 2651, loss 0.603601.
Train: 2018-07-31T00:45:01.661040: step 2652, loss 0.505152.
Train: 2018-07-31T00:45:01.817253: step 2653, loss 0.562558.
Train: 2018-07-31T00:45:01.957823: step 2654, loss 0.570761.
Train: 2018-07-31T00:45:02.098413: step 2655, loss 0.554351.
Train: 2018-07-31T00:45:02.239030: step 2656, loss 0.537937.
Train: 2018-07-31T00:45:02.379597: step 2657, loss 0.595394.
Train: 2018-07-31T00:45:02.520189: step 2658, loss 0.496874.
Train: 2018-07-31T00:45:02.660780: step 2659, loss 0.521439.
Train: 2018-07-31T00:45:02.801373: step 2660, loss 0.620176.
Test: 2018-07-31T00:45:03.035706: step 2660, loss 0.548716.
Train: 2018-07-31T00:45:03.191931: step 2661, loss 0.521315.
Train: 2018-07-31T00:45:03.348121: step 2662, loss 0.554254.
Train: 2018-07-31T00:45:03.488730: step 2663, loss 0.53771.
Train: 2018-07-31T00:45:03.629304: step 2664, loss 0.521106.
Train: 2018-07-31T00:45:03.769896: step 2665, loss 0.587346.
Train: 2018-07-31T00:45:03.926135: step 2666, loss 0.61229.
Train: 2018-07-31T00:45:04.066704: step 2667, loss 0.595681.
Train: 2018-07-31T00:45:04.207293: step 2668, loss 0.520952.
Train: 2018-07-31T00:45:04.347911: step 2669, loss 0.612272.
Train: 2018-07-31T00:45:04.504100: step 2670, loss 0.520993.
Test: 2018-07-31T00:45:04.738451: step 2670, loss 0.548575.
Train: 2018-07-31T00:45:04.894633: step 2671, loss 0.587344.
Train: 2018-07-31T00:45:05.035245: step 2672, loss 0.512746.
Train: 2018-07-31T00:45:05.175819: step 2673, loss 0.562467.
Train: 2018-07-31T00:45:05.316409: step 2674, loss 0.562465.
Train: 2018-07-31T00:45:05.457022: step 2675, loss 0.562464.
Train: 2018-07-31T00:45:05.597593: step 2676, loss 0.537582.
Train: 2018-07-31T00:45:05.738185: step 2677, loss 0.537566.
Train: 2018-07-31T00:45:05.894401: step 2678, loss 0.545842.
Train: 2018-07-31T00:45:06.034991: step 2679, loss 0.58739.
Train: 2018-07-31T00:45:06.191229: step 2680, loss 0.570761.
Test: 2018-07-31T00:45:06.441178: step 2680, loss 0.548513.
Train: 2018-07-31T00:45:06.597359: step 2681, loss 0.628986.
Train: 2018-07-31T00:45:06.737976: step 2682, loss 0.520929.
Train: 2018-07-31T00:45:06.878543: step 2683, loss 0.58736.
Train: 2018-07-31T00:45:07.019136: step 2684, loss 0.579049.
Train: 2018-07-31T00:45:07.159746: step 2685, loss 0.61215.
Train: 2018-07-31T00:45:07.315942: step 2686, loss 0.562498.
Train: 2018-07-31T00:45:07.456558: step 2687, loss 0.496608.
Train: 2018-07-31T00:45:07.612748: step 2688, loss 0.546058.
Train: 2018-07-31T00:45:07.784581: step 2689, loss 0.603681.
Train: 2018-07-31T00:45:07.925173: step 2690, loss 0.611862.
Test: 2018-07-31T00:45:08.175145: step 2690, loss 0.548823.
Train: 2018-07-31T00:45:08.315706: step 2691, loss 0.587166.
Train: 2018-07-31T00:45:08.456324: step 2692, loss 0.595308.
Train: 2018-07-31T00:45:08.612514: step 2693, loss 0.554463.
Train: 2018-07-31T00:45:08.753122: step 2694, loss 0.513845.
Train: 2018-07-31T00:45:08.893747: step 2695, loss 0.595157.
Train: 2018-07-31T00:45:09.049910: step 2696, loss 0.595118.
Train: 2018-07-31T00:45:09.190503: step 2697, loss 0.586981.
Train: 2018-07-31T00:45:09.331122: step 2698, loss 0.58695.
Train: 2018-07-31T00:45:09.471711: step 2699, loss 0.586918.
Train: 2018-07-31T00:45:09.612317: step 2700, loss 0.56283.
Test: 2018-07-31T00:45:09.862251: step 2700, loss 0.549477.
Train: 2018-07-31T00:45:10.612070: step 2701, loss 0.578863.
Train: 2018-07-31T00:45:10.768259: step 2702, loss 0.586834.
Train: 2018-07-31T00:45:10.908874: step 2703, loss 0.610662.
Train: 2018-07-31T00:45:11.049467: step 2704, loss 0.586781.
Train: 2018-07-31T00:45:11.190060: step 2705, loss 0.586755.
Train: 2018-07-31T00:45:11.346247: step 2706, loss 0.523836.
Train: 2018-07-31T00:45:11.486841: step 2707, loss 0.555343.
Train: 2018-07-31T00:45:11.643053: step 2708, loss 0.578879.
Train: 2018-07-31T00:45:11.783669: step 2709, loss 0.571067.
Train: 2018-07-31T00:45:11.924261: step 2710, loss 0.555471.
Test: 2018-07-31T00:45:12.174179: step 2710, loss 0.550233.
Train: 2018-07-31T00:45:12.346034: step 2711, loss 0.500903.
Train: 2018-07-31T00:45:12.470984: step 2712, loss 0.547663.
Train: 2018-07-31T00:45:12.611577: step 2713, loss 0.617975.
Train: 2018-07-31T00:45:12.767789: step 2714, loss 0.610162.
Train: 2018-07-31T00:45:12.908381: step 2715, loss 0.532005.
Train: 2018-07-31T00:45:13.064595: step 2716, loss 0.594517.
Train: 2018-07-31T00:45:13.205186: step 2717, loss 0.555445.
Train: 2018-07-31T00:45:13.361401: step 2718, loss 0.429882.
Train: 2018-07-31T00:45:13.501994: step 2719, loss 0.52397.
Train: 2018-07-31T00:45:13.658207: step 2720, loss 0.657651.
Test: 2018-07-31T00:45:13.892526: step 2720, loss 0.549857.
Train: 2018-07-31T00:45:14.033118: step 2721, loss 0.484144.
Train: 2018-07-31T00:45:14.189332: step 2722, loss 0.539245.
Train: 2018-07-31T00:45:14.329924: step 2723, loss 0.531128.
Train: 2018-07-31T00:45:14.470515: step 2724, loss 0.610828.
Train: 2018-07-31T00:45:14.642352: step 2725, loss 0.570851.
Train: 2018-07-31T00:45:14.782942: step 2726, loss 0.586909.
Train: 2018-07-31T00:45:14.939180: step 2727, loss 0.490309.
Train: 2018-07-31T00:45:15.079773: step 2728, loss 0.490016.
Train: 2018-07-31T00:45:15.235986: step 2729, loss 0.562669.
Train: 2018-07-31T00:45:15.392199: step 2730, loss 0.456629.
Test: 2018-07-31T00:45:15.642147: step 2730, loss 0.548815.
Train: 2018-07-31T00:45:15.782739: step 2731, loss 0.554354.
Train: 2018-07-31T00:45:15.938965: step 2732, loss 0.48823.
Train: 2018-07-31T00:45:16.079531: step 2733, loss 0.537545.
Train: 2018-07-31T00:45:16.220130: step 2734, loss 0.579139.
Train: 2018-07-31T00:45:16.376321: step 2735, loss 0.596031.
Train: 2018-07-31T00:45:16.516913: step 2736, loss 0.562372.
Train: 2018-07-31T00:45:16.657505: step 2737, loss 0.520026.
Train: 2018-07-31T00:45:16.798121: step 2738, loss 0.562347.
Train: 2018-07-31T00:45:16.938713: step 2739, loss 0.545292.
Train: 2018-07-31T00:45:17.079281: step 2740, loss 0.605089.
Test: 2018-07-31T00:45:17.329251: step 2740, loss 0.547998.
Train: 2018-07-31T00:45:17.469838: step 2741, loss 0.553776.
Train: 2018-07-31T00:45:17.626027: step 2742, loss 0.562335.
Train: 2018-07-31T00:45:17.766643: step 2743, loss 0.519438.
Train: 2018-07-31T00:45:17.907212: step 2744, loss 0.553743.
Train: 2018-07-31T00:45:18.047802: step 2745, loss 0.579541.
Train: 2018-07-31T00:45:18.188396: step 2746, loss 0.510693.
Train: 2018-07-31T00:45:18.329012: step 2747, loss 0.536483.
Train: 2018-07-31T00:45:18.469603: step 2748, loss 0.579598.
Train: 2018-07-31T00:45:18.625794: step 2749, loss 0.588244.
Train: 2018-07-31T00:45:18.766410: step 2750, loss 0.53644.
Test: 2018-07-31T00:45:19.000736: step 2750, loss 0.54788.
Train: 2018-07-31T00:45:19.156943: step 2751, loss 0.527806.
Train: 2018-07-31T00:45:19.297510: step 2752, loss 0.493242.
Train: 2018-07-31T00:45:19.453725: step 2753, loss 0.562342.
Train: 2018-07-31T00:45:19.609939: step 2754, loss 0.605644.
Train: 2018-07-31T00:45:19.750530: step 2755, loss 0.579661.
Train: 2018-07-31T00:45:19.891121: step 2756, loss 0.493128.
Train: 2018-07-31T00:45:20.047335: step 2757, loss 0.501754.
Train: 2018-07-31T00:45:20.203549: step 2758, loss 0.623023.
Train: 2018-07-31T00:45:20.344141: step 2759, loss 0.510359.
Train: 2018-07-31T00:45:20.484757: step 2760, loss 0.492999.
Test: 2018-07-31T00:45:20.734675: step 2760, loss 0.547809.
Train: 2018-07-31T00:45:20.875290: step 2761, loss 0.640499.
Train: 2018-07-31T00:45:21.031504: step 2762, loss 0.623088.
Train: 2018-07-31T00:45:21.172096: step 2763, loss 0.596975.
Train: 2018-07-31T00:45:21.312688: step 2764, loss 0.510533.
Train: 2018-07-31T00:45:21.453256: step 2765, loss 0.501999.
Train: 2018-07-31T00:45:21.593848: step 2766, loss 0.553719.
Train: 2018-07-31T00:45:21.750085: step 2767, loss 0.519286.
Train: 2018-07-31T00:45:21.906275: step 2768, loss 0.536503.
Train: 2018-07-31T00:45:22.046867: step 2769, loss 0.588193.
Train: 2018-07-31T00:45:22.187471: step 2770, loss 0.613997.
Test: 2018-07-31T00:45:22.437431: step 2770, loss 0.547941.
Train: 2018-07-31T00:45:22.578017: step 2771, loss 0.570915.
Train: 2018-07-31T00:45:22.718610: step 2772, loss 0.510872.
Train: 2018-07-31T00:45:22.859201: step 2773, loss 0.613754.
Train: 2018-07-31T00:45:23.015414: step 2774, loss 0.596524.
Train: 2018-07-31T00:45:23.156006: step 2775, loss 0.570861.
Train: 2018-07-31T00:45:23.312195: step 2776, loss 0.477391.
Train: 2018-07-31T00:45:23.452815: step 2777, loss 0.664177.
Train: 2018-07-31T00:45:23.609001: step 2778, loss 0.58773.
Train: 2018-07-31T00:45:23.749592: step 2779, loss 0.528674.
Train: 2018-07-31T00:45:23.890210: step 2780, loss 0.604393.
Test: 2018-07-31T00:45:24.140127: step 2780, loss 0.548384.
Train: 2018-07-31T00:45:24.280719: step 2781, loss 0.53729.
Train: 2018-07-31T00:45:24.421335: step 2782, loss 0.537372.
Train: 2018-07-31T00:45:24.561945: step 2783, loss 0.562414.
Train: 2018-07-31T00:45:24.702495: step 2784, loss 0.570755.
Train: 2018-07-31T00:45:24.858709: step 2785, loss 0.58741.
Train: 2018-07-31T00:45:24.999301: step 2786, loss 0.603867.
Train: 2018-07-31T00:45:25.139893: step 2787, loss 0.537759.
Train: 2018-07-31T00:45:25.280508: step 2788, loss 0.570749.
Train: 2018-07-31T00:45:25.436699: step 2789, loss 0.546145.
Train: 2018-07-31T00:45:25.577290: step 2790, loss 0.537982.
Test: 2018-07-31T00:45:25.811610: step 2790, loss 0.548874.
Train: 2018-07-31T00:45:25.967824: step 2791, loss 0.57078.
Train: 2018-07-31T00:45:26.124038: step 2792, loss 0.529883.
Train: 2018-07-31T00:45:26.264653: step 2793, loss 0.603468.
Train: 2018-07-31T00:45:26.420871: step 2794, loss 0.587097.
Train: 2018-07-31T00:45:26.561459: step 2795, loss 0.578948.
Train: 2018-07-31T00:45:26.702052: step 2796, loss 0.627676.
Train: 2018-07-31T00:45:26.858276: step 2797, loss 0.578904.
Train: 2018-07-31T00:45:26.998834: step 2798, loss 0.586966.
Train: 2018-07-31T00:45:27.139426: step 2799, loss 0.562788.
Train: 2018-07-31T00:45:27.280040: step 2800, loss 0.530736.
Test: 2018-07-31T00:45:27.529958: step 2800, loss 0.549442.
Train: 2018-07-31T00:45:28.295405: step 2801, loss 0.594878.
Train: 2018-07-31T00:45:28.451642: step 2802, loss 0.546911.
Train: 2018-07-31T00:45:28.592208: step 2803, loss 0.531014.
Train: 2018-07-31T00:45:28.748424: step 2804, loss 0.531043.
Train: 2018-07-31T00:45:28.873419: step 2805, loss 0.594803.
Train: 2018-07-31T00:45:29.029608: step 2806, loss 0.443387.
Train: 2018-07-31T00:45:29.154577: step 2807, loss 0.570872.
Train: 2018-07-31T00:45:29.310791: step 2808, loss 0.562849.
Train: 2018-07-31T00:45:29.451382: step 2809, loss 0.554793.
Train: 2018-07-31T00:45:29.607597: step 2810, loss 0.59496.
Test: 2018-07-31T00:45:29.857568: step 2810, loss 0.549284.
Train: 2018-07-31T00:45:30.013751: step 2811, loss 0.466132.
Train: 2018-07-31T00:45:30.154368: step 2812, loss 0.627377.
Train: 2018-07-31T00:45:30.294937: step 2813, loss 0.603176.
Train: 2018-07-31T00:45:30.451174: step 2814, loss 0.611295.
Train: 2018-07-31T00:45:30.591766: step 2815, loss 0.603179.
Train: 2018-07-31T00:45:30.747954: step 2816, loss 0.595056.
Train: 2018-07-31T00:45:30.888546: step 2817, loss 0.58695.
Train: 2018-07-31T00:45:31.029162: step 2818, loss 0.570828.
Train: 2018-07-31T00:45:31.169731: step 2819, loss 0.562811.
Train: 2018-07-31T00:45:31.325944: step 2820, loss 0.634998.
Test: 2018-07-31T00:45:31.560297: step 2820, loss 0.549499.
Train: 2018-07-31T00:45:31.700881: step 2821, loss 0.57087.
Train: 2018-07-31T00:45:31.857069: step 2822, loss 0.578859.
Train: 2018-07-31T00:45:32.013282: step 2823, loss 0.578858.
Train: 2018-07-31T00:45:32.153875: step 2824, loss 0.491764.
Train: 2018-07-31T00:45:32.294476: step 2825, loss 0.586771.
Train: 2018-07-31T00:45:32.450679: step 2826, loss 0.602568.
Train: 2018-07-31T00:45:32.591288: step 2827, loss 0.531538.
Train: 2018-07-31T00:45:32.731889: step 2828, loss 0.531574.
Train: 2018-07-31T00:45:32.888103: step 2829, loss 0.594633.
Train: 2018-07-31T00:45:33.044305: step 2830, loss 0.578865.
Test: 2018-07-31T00:45:33.278612: step 2830, loss 0.549918.
Train: 2018-07-31T00:45:33.419229: step 2831, loss 0.570988.
Train: 2018-07-31T00:45:33.575443: step 2832, loss 0.515877.
Train: 2018-07-31T00:45:33.731655: step 2833, loss 0.594627.
Train: 2018-07-31T00:45:33.887845: step 2834, loss 0.555217.
Train: 2018-07-31T00:45:34.028437: step 2835, loss 0.515767.
Train: 2018-07-31T00:45:34.169028: step 2836, loss 0.515648.
Train: 2018-07-31T00:45:34.309620: step 2837, loss 0.634337.
Train: 2018-07-31T00:45:34.465834: step 2838, loss 0.523318.
Train: 2018-07-31T00:45:34.606427: step 2839, loss 0.570906.
Train: 2018-07-31T00:45:34.747017: step 2840, loss 0.547001.
Test: 2018-07-31T00:45:34.981340: step 2840, loss 0.549523.
Train: 2018-07-31T00:45:35.137551: step 2841, loss 0.522969.
Train: 2018-07-31T00:45:35.278168: step 2842, loss 0.562848.
Train: 2018-07-31T00:45:35.418760: step 2843, loss 0.578901.
Train: 2018-07-31T00:45:35.559326: step 2844, loss 0.570741.
Train: 2018-07-31T00:45:35.715542: step 2845, loss 0.490186.
Train: 2018-07-31T00:45:35.856134: step 2846, loss 0.530231.
Train: 2018-07-31T00:45:35.996725: step 2847, loss 0.546091.
Train: 2018-07-31T00:45:36.152938: step 2848, loss 0.587973.
Train: 2018-07-31T00:45:36.309152: step 2849, loss 0.579166.
Train: 2018-07-31T00:45:36.449745: step 2850, loss 0.570962.
Test: 2018-07-31T00:45:36.684081: step 2850, loss 0.548739.
Train: 2018-07-31T00:45:36.809034: step 2851, loss 0.537857.
Train: 2018-07-31T00:45:36.965248: step 2852, loss 0.56243.
Train: 2018-07-31T00:45:37.105840: step 2853, loss 0.587192.
Train: 2018-07-31T00:45:37.262053: step 2854, loss 0.579015.
Train: 2018-07-31T00:45:37.402664: step 2855, loss 0.628448.
Train: 2018-07-31T00:45:37.543237: step 2856, loss 0.52136.
Train: 2018-07-31T00:45:37.683854: step 2857, loss 0.546069.
Train: 2018-07-31T00:45:37.840044: step 2858, loss 0.570758.
Train: 2018-07-31T00:45:37.996256: step 2859, loss 0.628368.
Train: 2018-07-31T00:45:38.136848: step 2860, loss 0.570758.
Test: 2018-07-31T00:45:38.386792: step 2860, loss 0.54882.
Train: 2018-07-31T00:45:38.527383: step 2861, loss 0.570762.
Train: 2018-07-31T00:45:38.667992: step 2862, loss 0.538008.
Train: 2018-07-31T00:45:38.808567: step 2863, loss 0.587128.
Train: 2018-07-31T00:45:38.949160: step 2864, loss 0.554432.
Train: 2018-07-31T00:45:39.105397: step 2865, loss 0.529975.
Train: 2018-07-31T00:45:39.245964: step 2866, loss 0.627872.
Train: 2018-07-31T00:45:39.386581: step 2867, loss 0.611491.
Train: 2018-07-31T00:45:39.527148: step 2868, loss 0.651993.
Train: 2018-07-31T00:45:39.667739: step 2869, loss 0.545474.
Train: 2018-07-31T00:45:39.823986: step 2870, loss 0.570823.
Test: 2018-07-31T00:45:40.058275: step 2870, loss 0.549368.
Train: 2018-07-31T00:45:40.198884: step 2871, loss 0.57887.
Train: 2018-07-31T00:45:40.339458: step 2872, loss 0.61887.
Train: 2018-07-31T00:45:40.495670: step 2873, loss 0.507155.
Train: 2018-07-31T00:45:40.636289: step 2874, loss 0.562962.
Train: 2018-07-31T00:45:40.776857: step 2875, loss 0.54713.
Train: 2018-07-31T00:45:40.917477: step 2876, loss 0.610547.
Train: 2018-07-31T00:45:41.058064: step 2877, loss 0.570956.
Train: 2018-07-31T00:45:41.214277: step 2878, loss 0.547308.
Train: 2018-07-31T00:45:41.370467: step 2879, loss 0.547349.
Train: 2018-07-31T00:45:41.511058: step 2880, loss 0.563116.
Test: 2018-07-31T00:45:41.745378: step 2880, loss 0.549937.
Train: 2018-07-31T00:45:41.885987: step 2881, loss 0.50014.
Train: 2018-07-31T00:45:42.042185: step 2882, loss 0.56309.
Train: 2018-07-31T00:45:42.182778: step 2883, loss 0.555159.
Train: 2018-07-31T00:45:42.323393: step 2884, loss 0.555185.
Train: 2018-07-31T00:45:42.463960: step 2885, loss 0.53127.
Train: 2018-07-31T00:45:42.620175: step 2886, loss 0.499348.
Train: 2018-07-31T00:45:42.760765: step 2887, loss 0.538895.
Train: 2018-07-31T00:45:42.901357: step 2888, loss 0.611158.
Train: 2018-07-31T00:45:43.041975: step 2889, loss 0.570803.
Train: 2018-07-31T00:45:43.182560: step 2890, loss 0.506073.
Test: 2018-07-31T00:45:43.432485: step 2890, loss 0.549069.
Train: 2018-07-31T00:45:43.573076: step 2891, loss 0.579024.
Train: 2018-07-31T00:45:43.713692: step 2892, loss 0.538233.
Train: 2018-07-31T00:45:43.869899: step 2893, loss 0.530053.
Train: 2018-07-31T00:45:44.010498: step 2894, loss 0.586812.
Train: 2018-07-31T00:45:44.151090: step 2895, loss 0.54662.
Train: 2018-07-31T00:45:44.307278: step 2896, loss 0.538116.
Train: 2018-07-31T00:45:44.447871: step 2897, loss 0.57166.
Train: 2018-07-31T00:45:44.588464: step 2898, loss 0.520847.
Train: 2018-07-31T00:45:44.729055: step 2899, loss 0.496201.
Train: 2018-07-31T00:45:44.885270: step 2900, loss 0.595973.
Test: 2018-07-31T00:45:45.119620: step 2900, loss 0.548318.
Train: 2018-07-31T00:45:45.869413: step 2901, loss 0.519618.
Train: 2018-07-31T00:45:46.010030: step 2902, loss 0.538075.
Train: 2018-07-31T00:45:46.150596: step 2903, loss 0.563263.
Train: 2018-07-31T00:45:46.291215: step 2904, loss 0.536612.
Train: 2018-07-31T00:45:46.431799: step 2905, loss 0.60396.
Train: 2018-07-31T00:45:46.587997: step 2906, loss 0.493621.
Train: 2018-07-31T00:45:46.744209: step 2907, loss 0.570277.
Train: 2018-07-31T00:45:46.869181: step 2908, loss 0.526486.
Train: 2018-07-31T00:45:47.025417: step 2909, loss 0.581241.
Train: 2018-07-31T00:45:47.181605: step 2910, loss 0.52587.
Test: 2018-07-31T00:45:47.415952: step 2910, loss 0.547638.
Train: 2018-07-31T00:45:47.556560: step 2911, loss 0.475736.
Train: 2018-07-31T00:45:47.759626: step 2912, loss 0.526286.
Train: 2018-07-31T00:45:47.900213: step 2913, loss 0.598296.
Train: 2018-07-31T00:45:48.040804: step 2914, loss 0.571366.
Train: 2018-07-31T00:45:48.196994: step 2915, loss 0.6065.
Train: 2018-07-31T00:45:48.337586: step 2916, loss 0.605584.
Train: 2018-07-31T00:45:48.478176: step 2917, loss 0.582543.
Train: 2018-07-31T00:45:48.634391: step 2918, loss 0.606866.
Train: 2018-07-31T00:45:48.774985: step 2919, loss 0.570759.
Train: 2018-07-31T00:45:48.915574: step 2920, loss 0.502835.
Test: 2018-07-31T00:45:49.149895: step 2920, loss 0.548117.
Train: 2018-07-31T00:45:49.290486: step 2921, loss 0.587216.
Train: 2018-07-31T00:45:49.446702: step 2922, loss 0.613316.
Train: 2018-07-31T00:45:49.587318: step 2923, loss 0.595666.
Train: 2018-07-31T00:45:49.727910: step 2924, loss 0.512564.
Train: 2018-07-31T00:45:49.868502: step 2925, loss 0.504489.
Train: 2018-07-31T00:45:50.024691: step 2926, loss 0.537697.
Train: 2018-07-31T00:45:50.165306: step 2927, loss 0.58727.
Train: 2018-07-31T00:45:50.305873: step 2928, loss 0.554267.
Train: 2018-07-31T00:45:50.446493: step 2929, loss 0.546051.
Train: 2018-07-31T00:45:50.602704: step 2930, loss 0.53784.
Test: 2018-07-31T00:45:50.837007: step 2930, loss 0.548749.
Train: 2018-07-31T00:45:50.977617: step 2931, loss 0.56253.
Train: 2018-07-31T00:45:51.133807: step 2932, loss 0.554305.
Train: 2018-07-31T00:45:51.274398: step 2933, loss 0.570758.
Train: 2018-07-31T00:45:51.414989: step 2934, loss 0.595433.
Train: 2018-07-31T00:45:51.555580: step 2935, loss 0.562544.
Train: 2018-07-31T00:45:51.696174: step 2936, loss 0.63643.
Train: 2018-07-31T00:45:51.836766: step 2937, loss 0.636264.
Train: 2018-07-31T00:45:51.977358: step 2938, loss 0.538157.
Train: 2018-07-31T00:45:52.117967: step 2939, loss 0.595172.
Train: 2018-07-31T00:45:52.258543: step 2940, loss 0.562695.
Test: 2018-07-31T00:45:52.492893: step 2940, loss 0.549211.
Train: 2018-07-31T00:45:52.649076: step 2941, loss 0.586962.
Train: 2018-07-31T00:45:52.789698: step 2942, loss 0.570827.
Train: 2018-07-31T00:45:52.930285: step 2943, loss 0.562822.
Train: 2018-07-31T00:45:53.070852: step 2944, loss 0.610872.
Train: 2018-07-31T00:45:53.227065: step 2945, loss 0.594811.
Train: 2018-07-31T00:45:53.383304: step 2946, loss 0.539137.
Train: 2018-07-31T00:45:53.523872: step 2947, loss 0.594702.
Train: 2018-07-31T00:45:53.664462: step 2948, loss 0.578842.
Train: 2018-07-31T00:45:53.805055: step 2949, loss 0.547372.
Train: 2018-07-31T00:45:53.945664: step 2950, loss 0.563161.
Test: 2018-07-31T00:45:54.195621: step 2950, loss 0.550044.
Train: 2018-07-31T00:45:54.351826: step 2951, loss 0.516135.
Train: 2018-07-31T00:45:54.508041: step 2952, loss 0.555337.
Train: 2018-07-31T00:45:54.648625: step 2953, loss 0.531803.
Train: 2018-07-31T00:45:54.789198: step 2954, loss 0.515932.
Train: 2018-07-31T00:45:54.929792: step 2955, loss 0.51587.
Train: 2018-07-31T00:45:55.070382: step 2956, loss 0.579039.
Train: 2018-07-31T00:45:55.211001: step 2957, loss 0.570844.
Train: 2018-07-31T00:45:55.351568: step 2958, loss 0.586897.
Train: 2018-07-31T00:45:55.492184: step 2959, loss 0.626999.
Train: 2018-07-31T00:45:55.632752: step 2960, loss 0.578841.
Test: 2018-07-31T00:45:55.882706: step 2960, loss 0.549577.
Train: 2018-07-31T00:45:56.023309: step 2961, loss 0.531079.
Train: 2018-07-31T00:45:56.163902: step 2962, loss 0.586872.
Train: 2018-07-31T00:45:56.320091: step 2963, loss 0.539004.
Train: 2018-07-31T00:45:56.460685: step 2964, loss 0.546951.
Train: 2018-07-31T00:45:56.601276: step 2965, loss 0.60282.
Train: 2018-07-31T00:45:56.741892: step 2966, loss 0.562896.
Train: 2018-07-31T00:45:56.882483: step 2967, loss 0.506979.
Train: 2018-07-31T00:45:57.023069: step 2968, loss 0.602868.
Train: 2018-07-31T00:45:57.163668: step 2969, loss 0.56285.
Train: 2018-07-31T00:45:57.304235: step 2970, loss 0.522768.
Test: 2018-07-31T00:45:57.554207: step 2970, loss 0.549369.
Train: 2018-07-31T00:45:57.710390: step 2971, loss 0.498587.
Train: 2018-07-31T00:45:57.850983: step 2972, loss 0.570824.
Train: 2018-07-31T00:45:57.991575: step 2973, loss 0.603114.
Train: 2018-07-31T00:45:58.132191: step 2974, loss 0.538448.
Train: 2018-07-31T00:45:58.272758: step 2975, loss 0.595109.
Train: 2018-07-31T00:45:58.428989: step 2976, loss 0.578905.
Train: 2018-07-31T00:45:58.569578: step 2977, loss 0.578908.
Train: 2018-07-31T00:45:58.725777: step 2978, loss 0.522047.
Train: 2018-07-31T00:45:58.866370: step 2979, loss 0.530129.
Train: 2018-07-31T00:45:59.006962: step 2980, loss 0.448487.
Test: 2018-07-31T00:45:59.256934: step 2980, loss 0.548826.
Train: 2018-07-31T00:45:59.413118: step 2981, loss 0.603717.
Train: 2018-07-31T00:45:59.553708: step 2982, loss 0.570855.
Train: 2018-07-31T00:45:59.709922: step 2983, loss 0.463715.
Train: 2018-07-31T00:45:59.866136: step 2984, loss 0.554235.
Train: 2018-07-31T00:46:00.006753: step 2985, loss 0.595697.
Train: 2018-07-31T00:46:00.147321: step 2986, loss 0.579211.
Train: 2018-07-31T00:46:00.287911: step 2987, loss 0.637376.
Train: 2018-07-31T00:46:00.428522: step 2988, loss 0.612401.
Train: 2018-07-31T00:46:00.584756: step 2989, loss 0.545811.
Train: 2018-07-31T00:46:00.725335: step 2990, loss 0.587375.
Test: 2018-07-31T00:46:00.959663: step 2990, loss 0.548555.
Train: 2018-07-31T00:46:01.115844: step 2991, loss 0.504361.
Train: 2018-07-31T00:46:01.256450: step 2992, loss 0.52927.
Train: 2018-07-31T00:46:01.397051: step 2993, loss 0.612282.
Train: 2018-07-31T00:46:01.537644: step 2994, loss 0.603953.
Train: 2018-07-31T00:46:01.693837: step 2995, loss 0.537603.
Train: 2018-07-31T00:46:01.834449: step 2996, loss 0.603885.
Train: 2018-07-31T00:46:01.975041: step 2997, loss 0.512926.
Train: 2018-07-31T00:46:02.146875: step 2998, loss 0.603794.
Train: 2018-07-31T00:46:02.287445: step 2999, loss 0.529538.
Train: 2018-07-31T00:46:02.428061: step 3000, loss 0.546052.
Test: 2018-07-31T00:46:02.662358: step 3000, loss 0.54873.
Train: 2018-07-31T00:46:03.412206: step 3001, loss 0.529581.
Train: 2018-07-31T00:46:03.552796: step 3002, loss 0.570752.
Train: 2018-07-31T00:46:03.708986: step 3003, loss 0.603708.
Train: 2018-07-31T00:46:03.849579: step 3004, loss 0.578986.
Train: 2018-07-31T00:46:03.974548: step 3005, loss 0.570755.
Train: 2018-07-31T00:46:04.146382: step 3006, loss 0.546131.
Train: 2018-07-31T00:46:04.286975: step 3007, loss 0.529743.
Train: 2018-07-31T00:46:04.427567: step 3008, loss 0.619981.
Train: 2018-07-31T00:46:04.568184: step 3009, loss 0.554387.
Train: 2018-07-31T00:46:04.724396: step 3010, loss 0.628042.
Test: 2018-07-31T00:46:04.958694: step 3010, loss 0.548938.
Train: 2018-07-31T00:46:05.099285: step 3011, loss 0.554443.
Train: 2018-07-31T00:46:05.286742: step 3012, loss 0.644094.
Train: 2018-07-31T00:46:05.442956: step 3013, loss 0.578899.
Train: 2018-07-31T00:46:05.583546: step 3014, loss 0.643578.
Train: 2018-07-31T00:46:05.724138: step 3015, loss 0.570831.
Train: 2018-07-31T00:46:05.864731: step 3016, loss 0.54685.
Train: 2018-07-31T00:46:06.005323: step 3017, loss 0.531029.
Train: 2018-07-31T00:46:06.145916: step 3018, loss 0.570908.
Train: 2018-07-31T00:46:06.302129: step 3019, loss 0.555065.
Train: 2018-07-31T00:46:06.442720: step 3020, loss 0.52925.
Test: 2018-07-31T00:46:06.677042: step 3020, loss 0.54979.
Train: 2018-07-31T00:46:06.833256: step 3021, loss 0.515574.
Train: 2018-07-31T00:46:06.973871: step 3022, loss 0.570943.
Train: 2018-07-31T00:46:07.130083: step 3023, loss 0.578859.
Train: 2018-07-31T00:46:07.270651: step 3024, loss 0.515474.
Train: 2018-07-31T00:46:07.411243: step 3025, loss 0.547117.
Train: 2018-07-31T00:46:07.567482: step 3026, loss 0.602714.
Train: 2018-07-31T00:46:07.708074: step 3027, loss 0.523154.
Train: 2018-07-31T00:46:07.848666: step 3028, loss 0.554942.
Train: 2018-07-31T00:46:07.989258: step 3029, loss 0.618807.
Train: 2018-07-31T00:46:08.145471: step 3030, loss 0.554881.
Test: 2018-07-31T00:46:08.395419: step 3030, loss 0.549464.
Train: 2018-07-31T00:46:08.536003: step 3031, loss 0.650867.
Train: 2018-07-31T00:46:08.676573: step 3032, loss 0.530922.
Train: 2018-07-31T00:46:08.817189: step 3033, loss 0.642763.
Train: 2018-07-31T00:46:08.957757: step 3034, loss 0.467264.
Train: 2018-07-31T00:46:09.113970: step 3035, loss 0.594811.
Train: 2018-07-31T00:46:09.270183: step 3036, loss 0.594809.
Train: 2018-07-31T00:46:09.410776: step 3037, loss 0.531051.
Train: 2018-07-31T00:46:09.551367: step 3038, loss 0.515103.
Train: 2018-07-31T00:46:09.691961: step 3039, loss 0.530975.
Train: 2018-07-31T00:46:09.832551: step 3040, loss 0.586861.
Test: 2018-07-31T00:46:10.066897: step 3040, loss 0.549431.
Train: 2018-07-31T00:46:10.207464: step 3041, loss 0.570855.
Train: 2018-07-31T00:46:10.348075: step 3042, loss 0.538769.
Train: 2018-07-31T00:46:10.488673: step 3043, loss 0.562804.
Train: 2018-07-31T00:46:10.644886: step 3044, loss 0.611063.
Train: 2018-07-31T00:46:10.785496: step 3045, loss 0.594977.
Train: 2018-07-31T00:46:10.941667: step 3046, loss 0.554732.
Train: 2018-07-31T00:46:11.082258: step 3047, loss 0.586923.
Train: 2018-07-31T00:46:11.222851: step 3048, loss 0.554745.
Train: 2018-07-31T00:46:11.363468: step 3049, loss 0.538667.
Train: 2018-07-31T00:46:11.504036: step 3050, loss 0.55474.
Test: 2018-07-31T00:46:11.754001: step 3050, loss 0.549293.
Train: 2018-07-31T00:46:11.894593: step 3051, loss 0.651327.
Train: 2018-07-31T00:46:12.050806: step 3052, loss 0.586911.
Train: 2018-07-31T00:46:12.191391: step 3053, loss 0.602941.
Train: 2018-07-31T00:46:12.347612: step 3054, loss 0.618885.
Train: 2018-07-31T00:46:12.503800: step 3055, loss 0.507073.
Train: 2018-07-31T00:46:12.644392: step 3056, loss 0.594785.
Train: 2018-07-31T00:46:12.784985: step 3057, loss 0.539131.
Train: 2018-07-31T00:46:12.925576: step 3058, loss 0.531245.
Train: 2018-07-31T00:46:13.066169: step 3059, loss 0.515387.
Train: 2018-07-31T00:46:13.206761: step 3060, loss 0.562973.
Test: 2018-07-31T00:46:13.441110: step 3060, loss 0.549637.
Train: 2018-07-31T00:46:13.597319: step 3061, loss 0.5391.
Train: 2018-07-31T00:46:13.753533: step 3062, loss 0.578859.
Train: 2018-07-31T00:46:13.909758: step 3063, loss 0.515053.
Train: 2018-07-31T00:46:14.050315: step 3064, loss 0.586857.
Train: 2018-07-31T00:46:14.175284: step 3065, loss 0.586875.
Train: 2018-07-31T00:46:14.315876: step 3066, loss 0.546797.
Train: 2018-07-31T00:46:14.456468: step 3067, loss 0.522666.
Train: 2018-07-31T00:46:14.612707: step 3068, loss 0.594974.
Train: 2018-07-31T00:46:14.753299: step 3069, loss 0.538586.
Train: 2018-07-31T00:46:14.893866: step 3070, loss 0.627324.
Test: 2018-07-31T00:46:15.128217: step 3070, loss 0.549207.
Train: 2018-07-31T00:46:15.284424: step 3071, loss 0.554662.
Train: 2018-07-31T00:46:15.440614: step 3072, loss 0.546575.
Train: 2018-07-31T00:46:15.581206: step 3073, loss 0.570803.
Train: 2018-07-31T00:46:15.737418: step 3074, loss 0.578892.
Train: 2018-07-31T00:46:15.878010: step 3075, loss 0.554618.
Train: 2018-07-31T00:46:16.018602: step 3076, loss 0.514131.
Train: 2018-07-31T00:46:16.174829: step 3077, loss 0.514041.
Train: 2018-07-31T00:46:16.315410: step 3078, loss 0.554518.
Train: 2018-07-31T00:46:16.456050: step 3079, loss 0.587133.
Train: 2018-07-31T00:46:16.612214: step 3080, loss 0.578909.
Test: 2018-07-31T00:46:16.846534: step 3080, loss 0.548903.
Train: 2018-07-31T00:46:16.987144: step 3081, loss 0.521706.
Train: 2018-07-31T00:46:17.127718: step 3082, loss 0.537955.
Train: 2018-07-31T00:46:17.283932: step 3083, loss 0.521381.
Train: 2018-07-31T00:46:17.424548: step 3084, loss 0.504446.
Train: 2018-07-31T00:46:17.565140: step 3085, loss 0.59601.
Train: 2018-07-31T00:46:17.705732: step 3086, loss 0.612341.
Train: 2018-07-31T00:46:17.861945: step 3087, loss 0.520389.
Train: 2018-07-31T00:46:18.018134: step 3088, loss 0.494934.
Train: 2018-07-31T00:46:18.158751: step 3089, loss 0.552976.
Train: 2018-07-31T00:46:18.299319: step 3090, loss 0.449342.
Test: 2018-07-31T00:46:18.549261: step 3090, loss 0.54767.
Train: 2018-07-31T00:46:18.689877: step 3091, loss 0.545165.
Train: 2018-07-31T00:46:18.830469: step 3092, loss 0.575592.
Train: 2018-07-31T00:46:18.986660: step 3093, loss 0.658246.
Train: 2018-07-31T00:46:19.127275: step 3094, loss 0.53471.
Train: 2018-07-31T00:46:19.267842: step 3095, loss 0.517275.
Train: 2018-07-31T00:46:19.408434: step 3096, loss 0.561591.
Train: 2018-07-31T00:46:19.549026: step 3097, loss 0.556781.
Train: 2018-07-31T00:46:19.689618: step 3098, loss 0.563375.
Train: 2018-07-31T00:46:19.830211: step 3099, loss 0.527907.
Train: 2018-07-31T00:46:19.970803: step 3100, loss 0.527594.
Test: 2018-07-31T00:46:20.220745: step 3100, loss 0.547958.
Train: 2018-07-31T00:46:20.986191: step 3101, loss 0.545749.
Train: 2018-07-31T00:46:21.126807: step 3102, loss 0.519256.
Train: 2018-07-31T00:46:21.267398: step 3103, loss 0.527356.
Train: 2018-07-31T00:46:21.423586: step 3104, loss 0.536601.
Train: 2018-07-31T00:46:21.564178: step 3105, loss 0.562517.
Train: 2018-07-31T00:46:21.704772: step 3106, loss 0.553779.
Train: 2018-07-31T00:46:21.845363: step 3107, loss 0.519358.
Train: 2018-07-31T00:46:21.985980: step 3108, loss 0.579281.
Train: 2018-07-31T00:46:22.126572: step 3109, loss 0.578993.
Train: 2018-07-31T00:46:22.267140: step 3110, loss 0.588088.
Test: 2018-07-31T00:46:22.517082: step 3110, loss 0.547921.
Train: 2018-07-31T00:46:22.673320: step 3111, loss 0.588094.
Train: 2018-07-31T00:46:22.813886: step 3112, loss 0.622287.
Train: 2018-07-31T00:46:22.954491: step 3113, loss 0.52808.
Train: 2018-07-31T00:46:23.110693: step 3114, loss 0.536564.
Train: 2018-07-31T00:46:23.251284: step 3115, loss 0.511265.
Train: 2018-07-31T00:46:23.391876: step 3116, loss 0.553722.
Train: 2018-07-31T00:46:23.548089: step 3117, loss 0.511142.
Train: 2018-07-31T00:46:23.688681: step 3118, loss 0.494023.
Train: 2018-07-31T00:46:23.829298: step 3119, loss 0.596622.
Train: 2018-07-31T00:46:23.969866: step 3120, loss 0.648114.
Test: 2018-07-31T00:46:24.219813: step 3120, loss 0.548022.
Train: 2018-07-31T00:46:24.360424: step 3121, loss 0.53655.
Train: 2018-07-31T00:46:24.500993: step 3122, loss 0.562125.
Train: 2018-07-31T00:46:24.641608: step 3123, loss 0.528027.
Train: 2018-07-31T00:46:24.797798: step 3124, loss 0.562972.
Train: 2018-07-31T00:46:24.938420: step 3125, loss 0.621588.
Train: 2018-07-31T00:46:25.078980: step 3126, loss 0.621414.
Train: 2018-07-31T00:46:25.219574: step 3127, loss 0.562235.
Train: 2018-07-31T00:46:25.360166: step 3128, loss 0.588247.
Train: 2018-07-31T00:46:25.500758: step 3129, loss 0.58736.
Train: 2018-07-31T00:46:25.641375: step 3130, loss 0.503957.
Test: 2018-07-31T00:46:25.875670: step 3130, loss 0.548477.
Train: 2018-07-31T00:46:26.047543: step 3131, loss 0.62065.
Train: 2018-07-31T00:46:26.188105: step 3132, loss 0.570844.
Train: 2018-07-31T00:46:26.328689: step 3133, loss 0.61229.
Train: 2018-07-31T00:46:26.469280: step 3134, loss 0.537755.
Train: 2018-07-31T00:46:26.609873: step 3135, loss 0.554466.
Train: 2018-07-31T00:46:26.766086: step 3136, loss 0.587164.
Train: 2018-07-31T00:46:26.906690: step 3137, loss 0.513837.
Train: 2018-07-31T00:46:27.047287: step 3138, loss 0.546378.
Train: 2018-07-31T00:46:27.187864: step 3139, loss 0.60325.
Train: 2018-07-31T00:46:27.328479: step 3140, loss 0.562723.
Test: 2018-07-31T00:46:27.578396: step 3140, loss 0.549209.
Train: 2018-07-31T00:46:27.718988: step 3141, loss 0.570799.
Train: 2018-07-31T00:46:27.875203: step 3142, loss 0.60305.
Train: 2018-07-31T00:46:28.015819: step 3143, loss 0.562794.
Train: 2018-07-31T00:46:28.156411: step 3144, loss 0.578872.
Train: 2018-07-31T00:46:28.297002: step 3145, loss 0.578865.
Train: 2018-07-31T00:46:28.437570: step 3146, loss 0.602817.
Train: 2018-07-31T00:46:28.578186: step 3147, loss 0.483312.
Train: 2018-07-31T00:46:28.734375: step 3148, loss 0.523157.
Train: 2018-07-31T00:46:28.874968: step 3149, loss 0.53905.
Train: 2018-07-31T00:46:29.031182: step 3150, loss 0.554945.
Test: 2018-07-31T00:46:29.265527: step 3150, loss 0.549527.
Train: 2018-07-31T00:46:29.421714: step 3151, loss 0.554913.
Train: 2018-07-31T00:46:29.562311: step 3152, loss 0.562872.
Train: 2018-07-31T00:46:29.702897: step 3153, loss 0.554843.
Train: 2018-07-31T00:46:29.843515: step 3154, loss 0.514703.
Train: 2018-07-31T00:46:29.999704: step 3155, loss 0.675385.
Train: 2018-07-31T00:46:30.140320: step 3156, loss 0.586918.
Train: 2018-07-31T00:46:30.296534: step 3157, loss 0.627083.
Train: 2018-07-31T00:46:30.437126: step 3158, loss 0.578867.
Train: 2018-07-31T00:46:30.577720: step 3159, loss 0.570862.
Train: 2018-07-31T00:46:30.733906: step 3160, loss 0.618786.
Test: 2018-07-31T00:46:30.968258: step 3160, loss 0.549606.
Train: 2018-07-31T00:46:31.124465: step 3161, loss 0.507215.
Train: 2018-07-31T00:46:31.265033: step 3162, loss 0.578858.
Train: 2018-07-31T00:46:31.421247: step 3163, loss 0.578858.
Train: 2018-07-31T00:46:31.561839: step 3164, loss 0.5313.
Train: 2018-07-31T00:46:31.702454: step 3165, loss 0.539245.
Train: 2018-07-31T00:46:31.874266: step 3166, loss 0.602635.
Train: 2018-07-31T00:46:32.014858: step 3167, loss 0.578859.
Train: 2018-07-31T00:46:32.171081: step 3168, loss 0.586775.
Train: 2018-07-31T00:46:32.311664: step 3169, loss 0.539326.
Train: 2018-07-31T00:46:32.452280: step 3170, loss 0.570956.
Test: 2018-07-31T00:46:32.702229: step 3170, loss 0.549818.
Train: 2018-07-31T00:46:32.842813: step 3171, loss 0.613636.
Train: 2018-07-31T00:46:32.999026: step 3172, loss 0.594649.
Train: 2018-07-31T00:46:33.170861: step 3173, loss 0.523713.
Train: 2018-07-31T00:46:33.311429: step 3174, loss 0.618243.
Train: 2018-07-31T00:46:33.452021: step 3175, loss 0.50024.
Train: 2018-07-31T00:46:33.592612: step 3176, loss 0.555272.
Train: 2018-07-31T00:46:33.764446: step 3177, loss 0.60248.
Train: 2018-07-31T00:46:33.905064: step 3178, loss 0.586737.
Train: 2018-07-31T00:46:34.045665: step 3179, loss 0.492354.
Train: 2018-07-31T00:46:34.201849: step 3180, loss 0.547359.
Test: 2018-07-31T00:46:34.436193: step 3180, loss 0.549864.
Train: 2018-07-31T00:46:34.592379: step 3181, loss 0.51573.
Train: 2018-07-31T00:46:34.732971: step 3182, loss 0.586775.
Train: 2018-07-31T00:46:34.873564: step 3183, loss 0.531256.
Train: 2018-07-31T00:46:35.014156: step 3184, loss 0.586809.
Train: 2018-07-31T00:46:35.170387: step 3185, loss 0.546956.
Train: 2018-07-31T00:46:35.310960: step 3186, loss 0.522872.
Train: 2018-07-31T00:46:35.467198: step 3187, loss 0.530685.
Train: 2018-07-31T00:46:35.607765: step 3188, loss 0.603105.
Train: 2018-07-31T00:46:35.748358: step 3189, loss 0.473775.
Train: 2018-07-31T00:46:35.888949: step 3190, loss 0.562751.
Test: 2018-07-31T00:46:36.123272: step 3190, loss 0.548917.
Train: 2018-07-31T00:46:36.279484: step 3191, loss 0.611514.
Train: 2018-07-31T00:46:36.435698: step 3192, loss 0.595308.
Train: 2018-07-31T00:46:36.576288: step 3193, loss 0.513302.
Train: 2018-07-31T00:46:36.732503: step 3194, loss 0.644765.
Train: 2018-07-31T00:46:36.873119: step 3195, loss 0.537683.
Train: 2018-07-31T00:46:37.029308: step 3196, loss 0.628407.
Train: 2018-07-31T00:46:37.154303: step 3197, loss 0.521668.
Train: 2018-07-31T00:46:37.310493: step 3198, loss 0.480504.
Train: 2018-07-31T00:46:37.451108: step 3199, loss 0.620067.
Train: 2018-07-31T00:46:37.607296: step 3200, loss 0.521451.
Test: 2018-07-31T00:46:37.857271: step 3200, loss 0.548735.
Train: 2018-07-31T00:46:38.607063: step 3201, loss 0.545971.
Train: 2018-07-31T00:46:38.747680: step 3202, loss 0.57076.
Train: 2018-07-31T00:46:38.888273: step 3203, loss 0.661574.
Train: 2018-07-31T00:46:39.028840: step 3204, loss 0.54608.
Train: 2018-07-31T00:46:39.185078: step 3205, loss 0.496714.
Train: 2018-07-31T00:46:39.325646: step 3206, loss 0.595394.
Train: 2018-07-31T00:46:39.466236: step 3207, loss 0.603702.
Train: 2018-07-31T00:46:39.622451: step 3208, loss 0.58718.
Train: 2018-07-31T00:46:39.763044: step 3209, loss 0.546169.
Train: 2018-07-31T00:46:39.903635: step 3210, loss 0.587144.
Test: 2018-07-31T00:46:40.137956: step 3210, loss 0.5489.
Train: 2018-07-31T00:46:40.309789: step 3211, loss 0.611643.
Train: 2018-07-31T00:46:40.450383: step 3212, loss 0.530006.
Train: 2018-07-31T00:46:40.590975: step 3213, loss 0.456811.
Train: 2018-07-31T00:46:40.731591: step 3214, loss 0.521883.
Train: 2018-07-31T00:46:40.872183: step 3215, loss 0.595263.
Train: 2018-07-31T00:46:41.028373: step 3216, loss 0.554426.
Train: 2018-07-31T00:46:41.168987: step 3217, loss 0.513511.
Train: 2018-07-31T00:46:41.340797: step 3218, loss 0.619937.
Train: 2018-07-31T00:46:41.481391: step 3219, loss 0.521565.
Train: 2018-07-31T00:46:41.637604: step 3220, loss 0.578971.
Test: 2018-07-31T00:46:41.871926: step 3220, loss 0.548781.
Train: 2018-07-31T00:46:42.028138: step 3221, loss 0.587193.
Train: 2018-07-31T00:46:42.168753: step 3222, loss 0.546106.
Train: 2018-07-31T00:46:42.309321: step 3223, loss 0.620085.
Train: 2018-07-31T00:46:42.465537: step 3224, loss 0.537907.
Train: 2018-07-31T00:46:42.606141: step 3225, loss 0.57076.
Train: 2018-07-31T00:46:42.746719: step 3226, loss 0.52973.
Train: 2018-07-31T00:46:42.902932: step 3227, loss 0.505094.
Train: 2018-07-31T00:46:43.043524: step 3228, loss 0.546098.
Train: 2018-07-31T00:46:43.184117: step 3229, loss 0.546038.
Train: 2018-07-31T00:46:43.324710: step 3230, loss 0.545979.
Test: 2018-07-31T00:46:43.559028: step 3230, loss 0.548607.
Train: 2018-07-31T00:46:43.715267: step 3231, loss 0.545891.
Train: 2018-07-31T00:46:43.855859: step 3232, loss 0.637455.
Train: 2018-07-31T00:46:44.012084: step 3233, loss 0.570661.
Train: 2018-07-31T00:46:44.152639: step 3234, loss 0.520995.
Train: 2018-07-31T00:46:44.293232: step 3235, loss 0.570741.
Train: 2018-07-31T00:46:44.433824: step 3236, loss 0.529325.
Train: 2018-07-31T00:46:44.574416: step 3237, loss 0.653779.
Train: 2018-07-31T00:46:44.730628: step 3238, loss 0.521035.
Train: 2018-07-31T00:46:44.886867: step 3239, loss 0.554192.
Train: 2018-07-31T00:46:45.027460: step 3240, loss 0.537641.
Test: 2018-07-31T00:46:45.277407: step 3240, loss 0.548599.
Train: 2018-07-31T00:46:45.417968: step 3241, loss 0.620462.
Train: 2018-07-31T00:46:45.574206: step 3242, loss 0.463178.
Train: 2018-07-31T00:46:45.714775: step 3243, loss 0.554185.
Train: 2018-07-31T00:46:45.855366: step 3244, loss 0.554169.
Train: 2018-07-31T00:46:45.995957: step 3245, loss 0.562449.
Train: 2018-07-31T00:46:46.136550: step 3246, loss 0.595694.
Train: 2018-07-31T00:46:46.277167: step 3247, loss 0.587409.
Train: 2018-07-31T00:46:46.433380: step 3248, loss 0.562448.
Train: 2018-07-31T00:46:46.589570: step 3249, loss 0.587371.
Train: 2018-07-31T00:46:46.730162: step 3250, loss 0.537591.
Test: 2018-07-31T00:46:46.964512: step 3250, loss 0.548597.
Train: 2018-07-31T00:46:47.120719: step 3251, loss 0.5459.
Train: 2018-07-31T00:46:47.276910: step 3252, loss 0.54591.
Train: 2018-07-31T00:46:47.417500: step 3253, loss 0.587323.
Train: 2018-07-31T00:46:47.558117: step 3254, loss 0.537649.
Train: 2018-07-31T00:46:47.698692: step 3255, loss 0.554203.
Train: 2018-07-31T00:46:47.839276: step 3256, loss 0.487989.
Train: 2018-07-31T00:46:47.995514: step 3257, loss 0.595629.
Train: 2018-07-31T00:46:48.151728: step 3258, loss 0.603941.
Train: 2018-07-31T00:46:48.307917: step 3259, loss 0.554174.
Train: 2018-07-31T00:46:48.448530: step 3260, loss 0.554176.
Test: 2018-07-31T00:46:48.682863: step 3260, loss 0.548587.
Train: 2018-07-31T00:46:48.839068: step 3261, loss 0.612199.
Train: 2018-07-31T00:46:48.995280: step 3262, loss 0.554192.
Train: 2018-07-31T00:46:49.135886: step 3263, loss 0.595572.
Train: 2018-07-31T00:46:49.292085: step 3264, loss 0.521219.
Train: 2018-07-31T00:46:49.432654: step 3265, loss 0.529502.
Train: 2018-07-31T00:46:49.588866: step 3266, loss 0.521209.
Train: 2018-07-31T00:46:49.729460: step 3267, loss 0.496389.
Train: 2018-07-31T00:46:49.885696: step 3268, loss 0.595928.
Train: 2018-07-31T00:46:50.026263: step 3269, loss 0.579143.
Train: 2018-07-31T00:46:50.166252: step 3270, loss 0.512734.
Test: 2018-07-31T00:46:50.416225: step 3270, loss 0.54854.
Train: 2018-07-31T00:46:50.556811: step 3271, loss 0.512577.
Train: 2018-07-31T00:46:50.713001: step 3272, loss 0.570764.
Train: 2018-07-31T00:46:50.853617: step 3273, loss 0.570774.
Train: 2018-07-31T00:46:50.994185: step 3274, loss 0.529021.
Train: 2018-07-31T00:46:51.134776: step 3275, loss 0.487139.
Train: 2018-07-31T00:46:51.290990: step 3276, loss 0.570787.
Train: 2018-07-31T00:46:51.431606: step 3277, loss 0.58762.
Train: 2018-07-31T00:46:51.587819: step 3278, loss 0.596069.
Train: 2018-07-31T00:46:51.728388: step 3279, loss 0.520235.
Train: 2018-07-31T00:46:51.869004: step 3280, loss 0.562367.
Test: 2018-07-31T00:46:52.118921: step 3280, loss 0.54822.
Train: 2018-07-31T00:46:52.259537: step 3281, loss 0.562364.
Train: 2018-07-31T00:46:52.415728: step 3282, loss 0.54546.
Train: 2018-07-31T00:46:52.556319: step 3283, loss 0.579274.
Train: 2018-07-31T00:46:52.696914: step 3284, loss 0.638487.
Train: 2018-07-31T00:46:52.837527: step 3285, loss 0.596142.
Train: 2018-07-31T00:46:52.993717: step 3286, loss 0.55395.
Train: 2018-07-31T00:46:53.134332: step 3287, loss 0.52876.
Train: 2018-07-31T00:46:53.306142: step 3288, loss 0.579178.
Train: 2018-07-31T00:46:53.446735: step 3289, loss 0.579158.
Train: 2018-07-31T00:46:53.587351: step 3290, loss 0.604221.
Test: 2018-07-31T00:46:53.821647: step 3290, loss 0.548464.
Train: 2018-07-31T00:46:53.977860: step 3291, loss 0.579103.
Train: 2018-07-31T00:46:54.134075: step 3292, loss 0.51258.
Train: 2018-07-31T00:46:54.259069: step 3293, loss 0.612241.
Train: 2018-07-31T00:46:54.415258: step 3294, loss 0.603848.
Train: 2018-07-31T00:46:54.555897: step 3295, loss 0.570757.
Train: 2018-07-31T00:46:54.696466: step 3296, loss 0.513254.
Train: 2018-07-31T00:46:54.837084: step 3297, loss 0.496978.
Train: 2018-07-31T00:46:54.993249: step 3298, loss 0.546177.
Train: 2018-07-31T00:46:55.133865: step 3299, loss 0.636328.
Train: 2018-07-31T00:46:55.290054: step 3300, loss 0.554403.
Test: 2018-07-31T00:46:55.524405: step 3300, loss 0.548914.
Train: 2018-07-31T00:46:56.242980: step 3301, loss 0.58711.
Train: 2018-07-31T00:46:56.383573: step 3302, loss 0.562617.
Train: 2018-07-31T00:46:56.524164: step 3303, loss 0.54635.
Train: 2018-07-31T00:46:56.680354: step 3304, loss 0.50571.
Train: 2018-07-31T00:46:56.820943: step 3305, loss 0.603328.
Train: 2018-07-31T00:46:56.992779: step 3306, loss 0.60331.
Train: 2018-07-31T00:46:57.133372: step 3307, loss 0.692587.
Train: 2018-07-31T00:46:57.273965: step 3308, loss 0.627398.
Train: 2018-07-31T00:46:57.414556: step 3309, loss 0.546709.
Train: 2018-07-31T00:46:57.570793: step 3310, loss 0.570859.
Test: 2018-07-31T00:46:57.820722: step 3310, loss 0.549562.
Train: 2018-07-31T00:46:57.961304: step 3311, loss 0.586832.
Train: 2018-07-31T00:46:58.117515: step 3312, loss 0.515342.
Train: 2018-07-31T00:46:58.258109: step 3313, loss 0.578859.
Train: 2018-07-31T00:46:58.398700: step 3314, loss 0.531459.
Train: 2018-07-31T00:46:58.539319: step 3315, loss 0.578863.
Train: 2018-07-31T00:46:58.679909: step 3316, loss 0.602504.
Train: 2018-07-31T00:46:58.820475: step 3317, loss 0.571006.
Train: 2018-07-31T00:46:58.976717: step 3318, loss 0.531779.
Train: 2018-07-31T00:46:59.117306: step 3319, loss 0.586719.
Train: 2018-07-31T00:46:59.257875: step 3320, loss 0.547533.
Test: 2018-07-31T00:46:59.492225: step 3320, loss 0.550091.
Train: 2018-07-31T00:46:59.648407: step 3321, loss 0.563211.
Train: 2018-07-31T00:46:59.804645: step 3322, loss 0.596634.
Train: 2018-07-31T00:46:59.976456: step 3323, loss 0.5006.
Train: 2018-07-31T00:47:00.117073: step 3324, loss 0.555365.
Train: 2018-07-31T00:47:00.257640: step 3325, loss 0.484688.
Train: 2018-07-31T00:47:00.398233: step 3326, loss 0.53161.
Train: 2018-07-31T00:47:00.554470: step 3327, loss 0.594677.
Train: 2018-07-31T00:47:00.710683: step 3328, loss 0.570926.
Train: 2018-07-31T00:47:00.851251: step 3329, loss 0.594766.
Train: 2018-07-31T00:47:00.991842: step 3330, loss 0.499185.
Test: 2018-07-31T00:47:01.226195: step 3330, loss 0.549489.
Train: 2018-07-31T00:47:01.366755: step 3331, loss 0.530902.
Train: 2018-07-31T00:47:01.507347: step 3332, loss 0.570845.
Train: 2018-07-31T00:47:01.647939: step 3333, loss 0.578876.
Train: 2018-07-31T00:47:01.819774: step 3334, loss 0.675737.
Train: 2018-07-31T00:47:01.960392: step 3335, loss 0.546607.
Train: 2018-07-31T00:47:02.116581: step 3336, loss 0.578884.
Train: 2018-07-31T00:47:02.257172: step 3337, loss 0.586953.
Train: 2018-07-31T00:47:02.397788: step 3338, loss 0.578881.
Train: 2018-07-31T00:47:02.553978: step 3339, loss 0.60305.
Train: 2018-07-31T00:47:02.694587: step 3340, loss 0.578874.
Test: 2018-07-31T00:47:02.928915: step 3340, loss 0.549367.
Train: 2018-07-31T00:47:03.069482: step 3341, loss 0.498586.
Train: 2018-07-31T00:47:03.225695: step 3342, loss 0.594925.
Train: 2018-07-31T00:47:03.366316: step 3343, loss 0.578868.
Train: 2018-07-31T00:47:03.522499: step 3344, loss 0.634966.
Train: 2018-07-31T00:47:03.663130: step 3345, loss 0.55488.
Train: 2018-07-31T00:47:03.803684: step 3346, loss 0.554925.
Train: 2018-07-31T00:47:03.944301: step 3347, loss 0.515126.
Train: 2018-07-31T00:47:04.100508: step 3348, loss 0.570893.
Train: 2018-07-31T00:47:04.256728: step 3349, loss 0.59479.
Train: 2018-07-31T00:47:04.397295: step 3350, loss 0.55498.
Test: 2018-07-31T00:47:04.647246: step 3350, loss 0.54962.
Train: 2018-07-31T00:47:04.803463: step 3351, loss 0.618642.
Train: 2018-07-31T00:47:04.928445: step 3352, loss 0.539137.
Train: 2018-07-31T00:47:05.084636: step 3353, loss 0.515347.
Train: 2018-07-31T00:47:05.225227: step 3354, loss 0.610636.
Train: 2018-07-31T00:47:05.365820: step 3355, loss 0.499447.
Train: 2018-07-31T00:47:05.506411: step 3356, loss 0.602713.
Train: 2018-07-31T00:47:05.647028: step 3357, loss 0.578859.
Train: 2018-07-31T00:47:05.787619: step 3358, loss 0.610678.
Train: 2018-07-31T00:47:05.928186: step 3359, loss 0.610647.
Train: 2018-07-31T00:47:06.068779: step 3360, loss 0.523335.
Test: 2018-07-31T00:47:06.303132: step 3360, loss 0.549729.
Train: 2018-07-31T00:47:06.474934: step 3361, loss 0.531296.
Train: 2018-07-31T00:47:06.615526: step 3362, loss 0.531278.
Train: 2018-07-31T00:47:06.756142: step 3363, loss 0.547098.
Train: 2018-07-31T00:47:06.912332: step 3364, loss 0.531139.
Train: 2018-07-31T00:47:07.037328: step 3365, loss 0.594804.
Train: 2018-07-31T00:47:07.193516: step 3366, loss 0.546924.
Train: 2018-07-31T00:47:07.334107: step 3367, loss 0.586862.
Train: 2018-07-31T00:47:07.474700: step 3368, loss 0.538824.
Train: 2018-07-31T00:47:07.615292: step 3369, loss 0.522714.
Train: 2018-07-31T00:47:07.802748: step 3370, loss 0.530617.
Test: 2018-07-31T00:47:08.052690: step 3370, loss 0.549234.
Train: 2018-07-31T00:47:08.193283: step 3371, loss 0.586951.
Train: 2018-07-31T00:47:08.349499: step 3372, loss 0.611239.
Train: 2018-07-31T00:47:08.490112: step 3373, loss 0.546514.
Train: 2018-07-31T00:47:08.630680: step 3374, loss 0.570794.
Train: 2018-07-31T00:47:08.771271: step 3375, loss 0.578904.
Train: 2018-07-31T00:47:08.927502: step 3376, loss 0.530197.
Train: 2018-07-31T00:47:09.068076: step 3377, loss 0.578912.
Train: 2018-07-31T00:47:09.224314: step 3378, loss 0.652132.
Train: 2018-07-31T00:47:09.364901: step 3379, loss 0.595158.
Train: 2018-07-31T00:47:09.505499: step 3380, loss 0.489713.
Test: 2018-07-31T00:47:09.755446: step 3380, loss 0.549107.
Train: 2018-07-31T00:47:09.896032: step 3381, loss 0.554578.
Train: 2018-07-31T00:47:10.052249: step 3382, loss 0.538355.
Train: 2018-07-31T00:47:10.208435: step 3383, loss 0.530212.
Train: 2018-07-31T00:47:10.364648: step 3384, loss 0.603294.
Train: 2018-07-31T00:47:10.505265: step 3385, loss 0.513868.
Train: 2018-07-31T00:47:10.645850: step 3386, loss 0.456778.
Train: 2018-07-31T00:47:10.802065: step 3387, loss 0.529899.
Train: 2018-07-31T00:47:10.942637: step 3388, loss 0.603592.
Train: 2018-07-31T00:47:11.083285: step 3389, loss 0.537836.
Train: 2018-07-31T00:47:11.223821: step 3390, loss 0.562501.
Test: 2018-07-31T00:47:11.473770: step 3390, loss 0.548619.
Train: 2018-07-31T00:47:11.661219: step 3391, loss 0.570757.
Train: 2018-07-31T00:47:11.801813: step 3392, loss 0.545876.
Train: 2018-07-31T00:47:11.942403: step 3393, loss 0.47933.
Train: 2018-07-31T00:47:12.098618: step 3394, loss 0.512369.
Train: 2018-07-31T00:47:12.239227: step 3395, loss 0.545642.
Train: 2018-07-31T00:47:12.379802: step 3396, loss 0.587618.
Train: 2018-07-31T00:47:12.520393: step 3397, loss 0.579243.
Train: 2018-07-31T00:47:12.692228: step 3398, loss 0.545449.
Train: 2018-07-31T00:47:12.817201: step 3399, loss 0.596246.
Train: 2018-07-31T00:47:12.973411: step 3400, loss 0.562351.
Test: 2018-07-31T00:47:13.192111: step 3400, loss 0.548135.
Train: 2018-07-31T00:47:13.910693: step 3401, loss 0.519914.
Train: 2018-07-31T00:47:14.066906: step 3402, loss 0.485863.
Train: 2018-07-31T00:47:14.207498: step 3403, loss 0.494179.
Train: 2018-07-31T00:47:14.363712: step 3404, loss 0.60509.
Train: 2018-07-31T00:47:14.504303: step 3405, loss 0.562335.
Train: 2018-07-31T00:47:14.644905: step 3406, loss 0.528007.
Train: 2018-07-31T00:47:14.785489: step 3407, loss 0.58813.
Train: 2018-07-31T00:47:14.926104: step 3408, loss 0.588155.
Train: 2018-07-31T00:47:15.066671: step 3409, loss 0.570942.
Train: 2018-07-31T00:47:15.222910: step 3410, loss 0.502116.
Test: 2018-07-31T00:47:15.457240: step 3410, loss 0.547919.
Train: 2018-07-31T00:47:15.613420: step 3411, loss 0.596768.
Train: 2018-07-31T00:47:15.754011: step 3412, loss 0.527918.
Train: 2018-07-31T00:47:15.894627: step 3413, loss 0.562336.
Train: 2018-07-31T00:47:16.050818: step 3414, loss 0.502114.
Train: 2018-07-31T00:47:16.207031: step 3415, loss 0.467626.
Train: 2018-07-31T00:47:16.347623: step 3416, loss 0.614123.
Train: 2018-07-31T00:47:16.488214: step 3417, loss 0.605529.
Train: 2018-07-31T00:47:16.628807: step 3418, loss 0.536436.
Train: 2018-07-31T00:47:16.769423: step 3419, loss 0.553706.
Train: 2018-07-31T00:47:16.925613: step 3420, loss 0.553707.
Test: 2018-07-31T00:47:17.159962: step 3420, loss 0.547887.
Train: 2018-07-31T00:47:17.300525: step 3421, loss 0.605481.
Train: 2018-07-31T00:47:17.441116: step 3422, loss 0.605417.
Train: 2018-07-31T00:47:17.597331: step 3423, loss 0.613904.
Train: 2018-07-31T00:47:17.753544: step 3424, loss 0.639415.
Train: 2018-07-31T00:47:17.878538: step 3425, loss 0.587904.
Train: 2018-07-31T00:47:18.034726: step 3426, loss 0.494548.
Train: 2018-07-31T00:47:18.175344: step 3427, loss 0.528583.
Train: 2018-07-31T00:47:18.315911: step 3428, loss 0.57922.
Train: 2018-07-31T00:47:18.472125: step 3429, loss 0.587582.
Train: 2018-07-31T00:47:18.612717: step 3430, loss 0.595885.
Test: 2018-07-31T00:47:18.862688: step 3430, loss 0.548465.
Train: 2018-07-31T00:47:19.003251: step 3431, loss 0.554091.
Train: 2018-07-31T00:47:19.159465: step 3432, loss 0.545834.
Train: 2018-07-31T00:47:19.300080: step 3433, loss 0.529332.
Train: 2018-07-31T00:47:19.440667: step 3434, loss 0.587295.
Train: 2018-07-31T00:47:19.581264: step 3435, loss 0.587256.
Train: 2018-07-31T00:47:19.753110: step 3436, loss 0.546075.
Train: 2018-07-31T00:47:19.878070: step 3437, loss 0.58718.
Train: 2018-07-31T00:47:20.034259: step 3438, loss 0.521629.
Train: 2018-07-31T00:47:20.174851: step 3439, loss 0.538055.
Train: 2018-07-31T00:47:20.331088: step 3440, loss 0.611631.
Test: 2018-07-31T00:47:20.565386: step 3440, loss 0.548951.
Train: 2018-07-31T00:47:20.721596: step 3441, loss 0.595247.
Train: 2018-07-31T00:47:20.862215: step 3442, loss 0.587058.
Train: 2018-07-31T00:47:21.002782: step 3443, loss 0.587023.
Train: 2018-07-31T00:47:21.143375: step 3444, loss 0.554613.
Train: 2018-07-31T00:47:21.283965: step 3445, loss 0.586959.
Train: 2018-07-31T00:47:21.424559: step 3446, loss 0.611083.
Train: 2018-07-31T00:47:21.565150: step 3447, loss 0.538753.
Train: 2018-07-31T00:47:21.705741: step 3448, loss 0.618877.
Train: 2018-07-31T00:47:21.861955: step 3449, loss 0.538988.
Train: 2018-07-31T00:47:22.002572: step 3450, loss 0.515224.
Test: 2018-07-31T00:47:22.252490: step 3450, loss 0.549656.
Train: 2018-07-31T00:47:22.393105: step 3451, loss 0.555019.
Train: 2018-07-31T00:47:22.533697: step 3452, loss 0.539147.
Train: 2018-07-31T00:47:22.674291: step 3453, loss 0.602691.
Train: 2018-07-31T00:47:22.830479: step 3454, loss 0.531223.
Train: 2018-07-31T00:47:22.971071: step 3455, loss 0.618568.
Train: 2018-07-31T00:47:23.111664: step 3456, loss 0.586793.
Train: 2018-07-31T00:47:23.252279: step 3457, loss 0.491686.
Train: 2018-07-31T00:47:23.392873: step 3458, loss 0.626444.
Train: 2018-07-31T00:47:23.533463: step 3459, loss 0.586784.
Train: 2018-07-31T00:47:23.689654: step 3460, loss 0.594693.
Test: 2018-07-31T00:47:23.923975: step 3460, loss 0.549816.
Train: 2018-07-31T00:47:24.064564: step 3461, loss 0.531438.
Train: 2018-07-31T00:47:24.220803: step 3462, loss 0.657862.
Train: 2018-07-31T00:47:24.361370: step 3463, loss 0.555228.
Train: 2018-07-31T00:47:24.501963: step 3464, loss 0.563142.
Train: 2018-07-31T00:47:24.658177: step 3465, loss 0.563171.
Train: 2018-07-31T00:47:24.798768: step 3466, loss 0.508306.
Train: 2018-07-31T00:47:24.923738: step 3467, loss 0.57103.
Train: 2018-07-31T00:47:25.079978: step 3468, loss 0.51609.
Train: 2018-07-31T00:47:25.236166: step 3469, loss 0.633902.
Train: 2018-07-31T00:47:25.376757: step 3470, loss 0.515975.
Test: 2018-07-31T00:47:25.626730: step 3470, loss 0.549937.
Train: 2018-07-31T00:47:25.767301: step 3471, loss 0.555249.
Train: 2018-07-31T00:47:25.907883: step 3472, loss 0.523668.
Train: 2018-07-31T00:47:26.048475: step 3473, loss 0.563049.
Train: 2018-07-31T00:47:26.189092: step 3474, loss 0.634337.
Train: 2018-07-31T00:47:26.329684: step 3475, loss 0.578859.
Train: 2018-07-31T00:47:26.485872: step 3476, loss 0.50746.
Train: 2018-07-31T00:47:26.610868: step 3477, loss 0.547069.
Train: 2018-07-31T00:47:26.767086: step 3478, loss 0.570895.
Train: 2018-07-31T00:47:26.923272: step 3479, loss 0.570881.
Train: 2018-07-31T00:47:27.063863: step 3480, loss 0.546895.
Test: 2018-07-31T00:47:27.298183: step 3480, loss 0.54944.
Train: 2018-07-31T00:47:27.438799: step 3481, loss 0.538829.
Train: 2018-07-31T00:47:27.579367: step 3482, loss 0.514659.
Train: 2018-07-31T00:47:27.735581: step 3483, loss 0.570824.
Train: 2018-07-31T00:47:27.876172: step 3484, loss 0.465811.
Train: 2018-07-31T00:47:28.016765: step 3485, loss 0.595139.
Train: 2018-07-31T00:47:28.157357: step 3486, loss 0.570777.
Train: 2018-07-31T00:47:28.313571: step 3487, loss 0.570769.
Train: 2018-07-31T00:47:28.454163: step 3488, loss 0.51341.
Train: 2018-07-31T00:47:28.594781: step 3489, loss 0.644752.
Train: 2018-07-31T00:47:28.750969: step 3490, loss 0.603682.
Test: 2018-07-31T00:47:28.985321: step 3490, loss 0.54874.
Train: 2018-07-31T00:47:29.125880: step 3491, loss 0.570758.
Train: 2018-07-31T00:47:29.282118: step 3492, loss 0.496686.
Train: 2018-07-31T00:47:29.422684: step 3493, loss 0.587238.
Train: 2018-07-31T00:47:29.578899: step 3494, loss 0.554266.
Train: 2018-07-31T00:47:29.703869: step 3495, loss 0.546005.
Train: 2018-07-31T00:47:29.875705: step 3496, loss 0.537726.
Train: 2018-07-31T00:47:30.016296: step 3497, loss 0.512878.
Train: 2018-07-31T00:47:30.156906: step 3498, loss 0.595617.
Train: 2018-07-31T00:47:30.297504: step 3499, loss 0.529278.
Train: 2018-07-31T00:47:30.438090: step 3500, loss 0.57076.
Test: 2018-07-31T00:47:30.672425: step 3500, loss 0.548507.
Train: 2018-07-31T00:47:31.422241: step 3501, loss 0.51252.
Train: 2018-07-31T00:47:31.578430: step 3502, loss 0.562428.
Train: 2018-07-31T00:47:31.719023: step 3503, loss 0.529005.
Train: 2018-07-31T00:47:31.859615: step 3504, loss 0.528918.
Train: 2018-07-31T00:47:32.015828: step 3505, loss 0.51203.
Train: 2018-07-31T00:47:32.156420: step 3506, loss 0.596059.
Train: 2018-07-31T00:47:32.297037: step 3507, loss 0.587682.
Train: 2018-07-31T00:47:32.437605: step 3508, loss 0.596155.
Train: 2018-07-31T00:47:32.578221: step 3509, loss 0.646852.
Train: 2018-07-31T00:47:32.734417: step 3510, loss 0.596101.
Test: 2018-07-31T00:47:32.968755: step 3510, loss 0.548294.
Train: 2018-07-31T00:47:33.109346: step 3511, loss 0.570791.
Train: 2018-07-31T00:47:33.265536: step 3512, loss 0.520452.
Train: 2018-07-31T00:47:33.406127: step 3513, loss 0.52053.
Train: 2018-07-31T00:47:33.562365: step 3514, loss 0.570774.
Train: 2018-07-31T00:47:33.702932: step 3515, loss 0.654377.
Train: 2018-07-31T00:47:33.859147: step 3516, loss 0.487411.
Train: 2018-07-31T00:47:33.999756: step 3517, loss 0.462529.
Train: 2018-07-31T00:47:34.140354: step 3518, loss 0.554096.
Train: 2018-07-31T00:47:34.280923: step 3519, loss 0.570767.
Train: 2018-07-31T00:47:34.437135: step 3520, loss 0.537375.
Test: 2018-07-31T00:47:34.671486: step 3520, loss 0.548418.
Train: 2018-07-31T00:47:34.827669: step 3521, loss 0.604198.
Train: 2018-07-31T00:47:34.983884: step 3522, loss 0.520637.
Train: 2018-07-31T00:47:35.124475: step 3523, loss 0.595855.
Train: 2018-07-31T00:47:35.265068: step 3524, loss 0.587489.
Train: 2018-07-31T00:47:35.405659: step 3525, loss 0.520661.
Train: 2018-07-31T00:47:35.561872: step 3526, loss 0.562418.
Train: 2018-07-31T00:47:35.702465: step 3527, loss 0.562419.
Train: 2018-07-31T00:47:35.858679: step 3528, loss 0.620856.
Train: 2018-07-31T00:47:35.999295: step 3529, loss 0.495755.
Train: 2018-07-31T00:47:36.139862: step 3530, loss 0.529097.
Test: 2018-07-31T00:47:36.389835: step 3530, loss 0.548463.
Train: 2018-07-31T00:47:36.530395: step 3531, loss 0.579104.
Train: 2018-07-31T00:47:36.670988: step 3532, loss 0.537413.
Train: 2018-07-31T00:47:36.811581: step 3533, loss 0.579108.
Train: 2018-07-31T00:47:36.952171: step 3534, loss 0.554084.
Train: 2018-07-31T00:47:37.092788: step 3535, loss 0.595789.
Train: 2018-07-31T00:47:37.233356: step 3536, loss 0.562431.
Train: 2018-07-31T00:47:37.389570: step 3537, loss 0.637375.
Train: 2018-07-31T00:47:37.530163: step 3538, loss 0.60398.
Train: 2018-07-31T00:47:37.655157: step 3539, loss 0.463149.
Train: 2018-07-31T00:47:37.811370: step 3540, loss 0.562486.
Test: 2018-07-31T00:47:38.061286: step 3540, loss 0.548653.
Train: 2018-07-31T00:47:38.201881: step 3541, loss 0.595547.
Train: 2018-07-31T00:47:38.342472: step 3542, loss 0.537754.
Train: 2018-07-31T00:47:38.483088: step 3543, loss 0.488326.
Train: 2018-07-31T00:47:38.639301: step 3544, loss 0.546007.
Train: 2018-07-31T00:47:38.779894: step 3545, loss 0.570756.
Train: 2018-07-31T00:47:38.936106: step 3546, loss 0.545965.
Train: 2018-07-31T00:47:39.076674: step 3547, loss 0.512857.
Train: 2018-07-31T00:47:39.217267: step 3548, loss 0.545897.
Train: 2018-07-31T00:47:39.357859: step 3549, loss 0.579062.
Train: 2018-07-31T00:47:39.498450: step 3550, loss 0.487622.
Test: 2018-07-31T00:47:39.748392: step 3550, loss 0.548467.
Train: 2018-07-31T00:47:39.904619: step 3551, loss 0.495735.
Train: 2018-07-31T00:47:40.045197: step 3552, loss 0.637723.
Train: 2018-07-31T00:47:40.201412: step 3553, loss 0.579162.
Train: 2018-07-31T00:47:40.342021: step 3554, loss 0.579173.
Train: 2018-07-31T00:47:40.482623: step 3555, loss 0.646324.
Train: 2018-07-31T00:47:40.638810: step 3556, loss 0.554019.
Train: 2018-07-31T00:47:40.779401: step 3557, loss 0.604244.
Train: 2018-07-31T00:47:40.919993: step 3558, loss 0.60416.
Train: 2018-07-31T00:47:41.060586: step 3559, loss 0.537475.
Train: 2018-07-31T00:47:41.216800: step 3560, loss 0.612268.
Test: 2018-07-31T00:47:41.451118: step 3560, loss 0.548625.
Train: 2018-07-31T00:47:41.591735: step 3561, loss 0.620401.
Train: 2018-07-31T00:47:41.747925: step 3562, loss 0.529569.
Train: 2018-07-31T00:47:41.888542: step 3563, loss 0.537918.
Train: 2018-07-31T00:47:42.044730: step 3564, loss 0.570764.
Train: 2018-07-31T00:47:42.200943: step 3565, loss 0.497232.
Train: 2018-07-31T00:47:42.341534: step 3566, loss 0.55444.
Train: 2018-07-31T00:47:42.482126: step 3567, loss 0.644228.
Train: 2018-07-31T00:47:42.638339: step 3568, loss 0.587064.
Train: 2018-07-31T00:47:42.778943: step 3569, loss 0.570787.
Train: 2018-07-31T00:47:42.919524: step 3570, loss 0.6032.
Test: 2018-07-31T00:47:43.169497: step 3570, loss 0.549211.
Train: 2018-07-31T00:47:43.310058: step 3571, loss 0.570809.
Train: 2018-07-31T00:47:43.481929: step 3572, loss 0.594977.
Train: 2018-07-31T00:47:43.622509: step 3573, loss 0.50668.
Train: 2018-07-31T00:47:43.778700: step 3574, loss 0.562845.
Train: 2018-07-31T00:47:43.934936: step 3575, loss 0.658851.
Train: 2018-07-31T00:47:44.091124: step 3576, loss 0.602773.
Train: 2018-07-31T00:47:44.247340: step 3577, loss 0.55504.
Train: 2018-07-31T00:47:44.387948: step 3578, loss 0.6026.
Train: 2018-07-31T00:47:44.528521: step 3579, loss 0.539446.
Train: 2018-07-31T00:47:44.684762: step 3580, loss 0.492377.
Test: 2018-07-31T00:47:44.934706: step 3580, loss 0.549988.
Train: 2018-07-31T00:47:45.075269: step 3581, loss 0.555292.
Train: 2018-07-31T00:47:45.215861: step 3582, loss 0.602448.
Train: 2018-07-31T00:47:45.340833: step 3583, loss 0.555312.
Train: 2018-07-31T00:47:45.497071: step 3584, loss 0.461112.
Train: 2018-07-31T00:47:45.653294: step 3585, loss 0.563128.
Train: 2018-07-31T00:47:45.793892: step 3586, loss 0.555198.
Train: 2018-07-31T00:47:45.934468: step 3587, loss 0.539328.
Train: 2018-07-31T00:47:46.075035: step 3588, loss 0.562995.
Train: 2018-07-31T00:47:46.215652: step 3589, loss 0.594767.
Train: 2018-07-31T00:47:46.356246: step 3590, loss 0.507136.
Test: 2018-07-31T00:47:46.606164: step 3590, loss 0.549485.
Train: 2018-07-31T00:47:46.746778: step 3591, loss 0.53889.
Train: 2018-07-31T00:47:46.902968: step 3592, loss 0.578868.
Train: 2018-07-31T00:47:47.043560: step 3593, loss 0.554738.
Train: 2018-07-31T00:47:47.184159: step 3594, loss 0.611155.
Train: 2018-07-31T00:47:47.324772: step 3595, loss 0.627366.
Train: 2018-07-31T00:47:47.465336: step 3596, loss 0.578887.
Train: 2018-07-31T00:47:47.605927: step 3597, loss 0.562736.
Train: 2018-07-31T00:47:47.762164: step 3598, loss 0.562741.
Train: 2018-07-31T00:47:47.902734: step 3599, loss 0.60309.
Train: 2018-07-31T00:47:48.043325: step 3600, loss 0.498284.
Test: 2018-07-31T00:47:48.293267: step 3600, loss 0.549249.
Train: 2018-07-31T00:47:49.043091: step 3601, loss 0.57888.
Train: 2018-07-31T00:47:49.199305: step 3602, loss 0.465979.
Train: 2018-07-31T00:47:49.339895: step 3603, loss 0.506124.
Train: 2018-07-31T00:47:49.480513: step 3604, loss 0.587018.
Train: 2018-07-31T00:47:49.621105: step 3605, loss 0.497559.
Train: 2018-07-31T00:47:49.761671: step 3606, loss 0.63611.
Train: 2018-07-31T00:47:49.917886: step 3607, loss 0.58713.
Train: 2018-07-31T00:47:50.074125: step 3608, loss 0.554382.
Train: 2018-07-31T00:47:50.214715: step 3609, loss 0.644562.
Train: 2018-07-31T00:47:50.370930: step 3610, loss 0.537993.
Test: 2018-07-31T00:47:50.620847: step 3610, loss 0.548856.
Train: 2018-07-31T00:47:50.761469: step 3611, loss 0.538002.
Train: 2018-07-31T00:47:50.902031: step 3612, loss 0.529799.
Train: 2018-07-31T00:47:51.042647: step 3613, loss 0.603566.
Train: 2018-07-31T00:47:51.198836: step 3614, loss 0.603564.
Train: 2018-07-31T00:47:51.339429: step 3615, loss 0.546187.
Train: 2018-07-31T00:47:51.480020: step 3616, loss 0.578952.
Train: 2018-07-31T00:47:51.620611: step 3617, loss 0.488968.
Train: 2018-07-31T00:47:51.761205: step 3618, loss 0.570765.
Train: 2018-07-31T00:47:51.901814: step 3619, loss 0.603529.
Train: 2018-07-31T00:47:52.058036: step 3620, loss 0.603515.
Test: 2018-07-31T00:47:52.307952: step 3620, loss 0.548898.
Train: 2018-07-31T00:47:52.464165: step 3621, loss 0.58712.
Train: 2018-07-31T00:47:52.604756: step 3622, loss 0.56261.
Train: 2018-07-31T00:47:52.760971: step 3623, loss 0.513738.
Train: 2018-07-31T00:47:52.885965: step 3624, loss 0.580009.
Train: 2018-07-31T00:47:53.042155: step 3625, loss 0.53008.
Train: 2018-07-31T00:47:53.198375: step 3626, loss 0.521934.
Train: 2018-07-31T00:47:53.338985: step 3627, loss 0.595224.
Train: 2018-07-31T00:47:53.479552: step 3628, loss 0.562624.
Train: 2018-07-31T00:47:53.620169: step 3629, loss 0.530012.
Train: 2018-07-31T00:47:53.760736: step 3630, loss 0.538132.
Test: 2018-07-31T00:47:53.995059: step 3630, loss 0.548912.
Train: 2018-07-31T00:47:54.135649: step 3631, loss 0.570769.
Train: 2018-07-31T00:47:54.276265: step 3632, loss 0.546229.
Train: 2018-07-31T00:47:54.432478: step 3633, loss 0.505242.
Train: 2018-07-31T00:47:54.588696: step 3634, loss 0.652868.
Train: 2018-07-31T00:47:54.729259: step 3635, loss 0.562549.
Train: 2018-07-31T00:47:54.869876: step 3636, loss 0.587184.
Train: 2018-07-31T00:47:55.010444: step 3637, loss 0.570761.
Train: 2018-07-31T00:47:55.166657: step 3638, loss 0.60357.
Train: 2018-07-31T00:47:55.307249: step 3639, loss 0.660843.
Train: 2018-07-31T00:47:55.447842: step 3640, loss 0.513661.
Test: 2018-07-31T00:47:55.682160: step 3640, loss 0.549004.
Train: 2018-07-31T00:47:55.838399: step 3641, loss 0.570779.
Train: 2018-07-31T00:47:55.978966: step 3642, loss 0.522047.
Train: 2018-07-31T00:47:56.135182: step 3643, loss 0.603249.
Train: 2018-07-31T00:47:56.275773: step 3644, loss 0.497895.
Train: 2018-07-31T00:47:56.416365: step 3645, loss 0.578896.
Train: 2018-07-31T00:47:56.556957: step 3646, loss 0.465553.
Train: 2018-07-31T00:47:56.713171: step 3647, loss 0.570791.
Train: 2018-07-31T00:47:56.853761: step 3648, loss 0.513919.
Train: 2018-07-31T00:47:56.994394: step 3649, loss 0.521911.
Train: 2018-07-31T00:47:57.150568: step 3650, loss 0.554428.
Test: 2018-07-31T00:47:57.384913: step 3650, loss 0.548841.
Train: 2018-07-31T00:47:57.541101: step 3651, loss 0.554372.
Train: 2018-07-31T00:47:57.681694: step 3652, loss 0.587197.
Train: 2018-07-31T00:47:57.822284: step 3653, loss 0.554285.
Train: 2018-07-31T00:47:57.978498: step 3654, loss 0.570754.
Train: 2018-07-31T00:47:58.119090: step 3655, loss 0.620346.
Train: 2018-07-31T00:47:58.275303: step 3656, loss 0.579024.
Train: 2018-07-31T00:47:58.400275: step 3657, loss 0.587278.
Train: 2018-07-31T00:47:58.556488: step 3658, loss 0.537747.
Train: 2018-07-31T00:47:58.697097: step 3659, loss 0.603751.
Train: 2018-07-31T00:47:58.853295: step 3660, loss 0.570757.
Test: 2018-07-31T00:47:59.087614: step 3660, loss 0.548757.
Train: 2018-07-31T00:47:59.228207: step 3661, loss 0.562533.
Train: 2018-07-31T00:47:59.368798: step 3662, loss 0.57076.
Train: 2018-07-31T00:47:59.509414: step 3663, loss 0.537953.
Train: 2018-07-31T00:47:59.650006: step 3664, loss 0.488806.
Train: 2018-07-31T00:47:59.806196: step 3665, loss 0.603575.
Train: 2018-07-31T00:47:59.946811: step 3666, loss 0.595369.
Train: 2018-07-31T00:48:00.087404: step 3667, loss 0.554372.
Train: 2018-07-31T00:48:00.243593: step 3668, loss 0.538003.
Train: 2018-07-31T00:48:00.384184: step 3669, loss 0.603524.
Train: 2018-07-31T00:48:00.524776: step 3670, loss 0.603494.
Test: 2018-07-31T00:48:00.774749: step 3670, loss 0.548925.
Train: 2018-07-31T00:48:00.915310: step 3671, loss 0.595271.
Train: 2018-07-31T00:48:01.071562: step 3672, loss 0.562627.
Train: 2018-07-31T00:48:01.196519: step 3673, loss 0.554525.
Train: 2018-07-31T00:48:01.352708: step 3674, loss 0.554559.
Train: 2018-07-31T00:48:01.493325: step 3675, loss 0.546484.
Train: 2018-07-31T00:48:01.633892: step 3676, loss 0.505996.
Train: 2018-07-31T00:48:01.805729: step 3677, loss 0.546491.
Train: 2018-07-31T00:48:01.946319: step 3678, loss 0.587114.
Train: 2018-07-31T00:48:02.086936: step 3679, loss 0.570715.
Train: 2018-07-31T00:48:02.243125: step 3680, loss 0.57891.
Test: 2018-07-31T00:48:02.477446: step 3680, loss 0.549066.
Train: 2018-07-31T00:48:02.618061: step 3681, loss 0.570719.
Train: 2018-07-31T00:48:02.774250: step 3682, loss 0.570877.
Train: 2018-07-31T00:48:02.914842: step 3683, loss 0.530087.
Train: 2018-07-31T00:48:03.055452: step 3684, loss 0.58707.
Train: 2018-07-31T00:48:03.211649: step 3685, loss 0.522159.
Train: 2018-07-31T00:48:03.352262: step 3686, loss 0.554701.
Train: 2018-07-31T00:48:03.492857: step 3687, loss 0.546318.
Train: 2018-07-31T00:48:03.649045: step 3688, loss 0.464875.
Train: 2018-07-31T00:48:03.805259: step 3689, loss 0.570957.
Train: 2018-07-31T00:48:03.961481: step 3690, loss 0.562644.
Test: 2018-07-31T00:48:04.195826: step 3690, loss 0.548746.
Train: 2018-07-31T00:48:04.336408: step 3691, loss 0.603931.
Train: 2018-07-31T00:48:04.476977: step 3692, loss 0.554382.
Train: 2018-07-31T00:48:04.633189: step 3693, loss 0.496781.
Train: 2018-07-31T00:48:04.773799: step 3694, loss 0.562517.
Train: 2018-07-31T00:48:04.929996: step 3695, loss 0.603773.
Train: 2018-07-31T00:48:05.070587: step 3696, loss 0.55423.
Train: 2018-07-31T00:48:05.211179: step 3697, loss 0.620386.
Train: 2018-07-31T00:48:05.351779: step 3698, loss 0.6369.
Train: 2018-07-31T00:48:05.507986: step 3699, loss 0.504754.
Train: 2018-07-31T00:48:05.648578: step 3700, loss 0.537778.
Test: 2018-07-31T00:48:05.882922: step 3700, loss 0.548707.
Train: 2018-07-31T00:48:06.601505: step 3701, loss 0.587244.
Train: 2018-07-31T00:48:06.742096: step 3702, loss 0.595471.
Train: 2018-07-31T00:48:06.898285: step 3703, loss 0.570758.
Train: 2018-07-31T00:48:07.054522: step 3704, loss 0.480412.
Train: 2018-07-31T00:48:07.210735: step 3705, loss 0.578976.
Train: 2018-07-31T00:48:07.351321: step 3706, loss 0.59541.
Train: 2018-07-31T00:48:07.491920: step 3707, loss 0.595392.
Train: 2018-07-31T00:48:07.632513: step 3708, loss 0.587159.
Train: 2018-07-31T00:48:07.773105: step 3709, loss 0.628043.
Train: 2018-07-31T00:48:07.913696: step 3710, loss 0.546306.
Test: 2018-07-31T00:48:08.163626: step 3710, loss 0.549023.
Train: 2018-07-31T00:48:08.304222: step 3711, loss 0.587051.
Train: 2018-07-31T00:48:08.460419: step 3712, loss 0.587014.
Train: 2018-07-31T00:48:08.601041: step 3713, loss 0.667835.
Train: 2018-07-31T00:48:08.741604: step 3714, loss 0.643222.
Train: 2018-07-31T00:48:08.882195: step 3715, loss 0.546899.
Train: 2018-07-31T00:48:09.022786: step 3716, loss 0.54707.
Train: 2018-07-31T00:48:09.163378: step 3717, loss 0.5393.
Train: 2018-07-31T00:48:09.303971: step 3718, loss 0.547317.
Train: 2018-07-31T00:48:09.444589: step 3719, loss 0.578856.
Train: 2018-07-31T00:48:09.585180: step 3720, loss 0.547468.
Test: 2018-07-31T00:48:09.835100: step 3720, loss 0.550062.
Train: 2018-07-31T00:48:09.991310: step 3721, loss 0.547518.
Train: 2018-07-31T00:48:10.131927: step 3722, loss 0.524033.
Train: 2018-07-31T00:48:10.272495: step 3723, loss 0.523836.
Train: 2018-07-31T00:48:10.413085: step 3724, loss 0.547263.
Train: 2018-07-31T00:48:10.553703: step 3725, loss 0.578537.
Train: 2018-07-31T00:48:10.709893: step 3726, loss 0.617995.
Train: 2018-07-31T00:48:10.850509: step 3727, loss 0.537564.
Train: 2018-07-31T00:48:10.991077: step 3728, loss 0.520482.
Train: 2018-07-31T00:48:11.147289: step 3729, loss 0.515687.
Train: 2018-07-31T00:48:11.287882: step 3730, loss 0.598558.
Test: 2018-07-31T00:48:11.522201: step 3730, loss 0.548182.
Train: 2018-07-31T00:48:11.662797: step 3731, loss 0.546911.
Train: 2018-07-31T00:48:11.803385: step 3732, loss 0.593498.
Train: 2018-07-31T00:48:11.943977: step 3733, loss 0.516436.
Train: 2018-07-31T00:48:12.100191: step 3734, loss 0.556994.
Train: 2018-07-31T00:48:12.240784: step 3735, loss 0.54998.
Train: 2018-07-31T00:48:12.381400: step 3736, loss 0.540153.
Train: 2018-07-31T00:48:12.521967: step 3737, loss 0.571111.
Train: 2018-07-31T00:48:12.662586: step 3738, loss 0.639797.
Train: 2018-07-31T00:48:12.803153: step 3739, loss 0.579708.
Train: 2018-07-31T00:48:12.959366: step 3740, loss 0.560784.
Test: 2018-07-31T00:48:13.193685: step 3740, loss 0.548497.
Train: 2018-07-31T00:48:13.349899: step 3741, loss 0.54584.
Train: 2018-07-31T00:48:13.474868: step 3742, loss 0.536975.
Train: 2018-07-31T00:48:13.615461: step 3743, loss 0.472116.
Train: 2018-07-31T00:48:13.756053: step 3744, loss 0.580968.
Train: 2018-07-31T00:48:13.896645: step 3745, loss 0.571033.
Train: 2018-07-31T00:48:14.037237: step 3746, loss 0.58536.
Train: 2018-07-31T00:48:14.177830: step 3747, loss 0.642299.
Train: 2018-07-31T00:48:14.318447: step 3748, loss 0.554519.
Train: 2018-07-31T00:48:14.459013: step 3749, loss 0.546845.
Train: 2018-07-31T00:48:14.630850: step 3750, loss 0.561568.
Test: 2018-07-31T00:48:14.865200: step 3750, loss 0.549032.
Train: 2018-07-31T00:48:15.005778: step 3751, loss 0.498643.
Train: 2018-07-31T00:48:15.177595: step 3752, loss 0.587238.
Train: 2018-07-31T00:48:15.318187: step 3753, loss 0.547611.
Train: 2018-07-31T00:48:15.458798: step 3754, loss 0.514369.
Train: 2018-07-31T00:48:15.599397: step 3755, loss 0.583986.
Train: 2018-07-31T00:48:15.739964: step 3756, loss 0.570542.
Train: 2018-07-31T00:48:15.880557: step 3757, loss 0.553777.
Train: 2018-07-31T00:48:16.021148: step 3758, loss 0.50479.
Train: 2018-07-31T00:48:16.161764: step 3759, loss 0.537116.
Train: 2018-07-31T00:48:16.302369: step 3760, loss 0.489438.
Test: 2018-07-31T00:48:16.552274: step 3760, loss 0.54831.
Train: 2018-07-31T00:48:16.692866: step 3761, loss 0.572737.
Train: 2018-07-31T00:48:16.833482: step 3762, loss 0.546616.
Train: 2018-07-31T00:48:16.974068: step 3763, loss 0.594736.
Train: 2018-07-31T00:48:17.114641: step 3764, loss 0.545503.
Train: 2018-07-31T00:48:17.270882: step 3765, loss 0.619926.
Train: 2018-07-31T00:48:17.411446: step 3766, loss 0.56282.
Train: 2018-07-31T00:48:17.552040: step 3767, loss 0.530023.
Train: 2018-07-31T00:48:17.692656: step 3768, loss 0.563691.
Train: 2018-07-31T00:48:17.833249: step 3769, loss 0.630892.
Train: 2018-07-31T00:48:17.973816: step 3770, loss 0.552774.
Test: 2018-07-31T00:48:18.223758: step 3770, loss 0.548792.
Train: 2018-07-31T00:48:18.364373: step 3771, loss 0.471284.
Train: 2018-07-31T00:48:18.504966: step 3772, loss 0.586958.
Train: 2018-07-31T00:48:18.645533: step 3773, loss 0.579908.
Train: 2018-07-31T00:48:18.786150: step 3774, loss 0.521909.
Train: 2018-07-31T00:48:18.926744: step 3775, loss 0.632382.
Train: 2018-07-31T00:48:19.067334: step 3776, loss 0.58686.
Train: 2018-07-31T00:48:19.207926: step 3777, loss 0.55434.
Train: 2018-07-31T00:48:19.348518: step 3778, loss 0.571026.
Train: 2018-07-31T00:48:19.489111: step 3779, loss 0.538429.
Train: 2018-07-31T00:48:19.645299: step 3780, loss 0.546838.
Test: 2018-07-31T00:48:19.879651: step 3780, loss 0.549282.
Train: 2018-07-31T00:48:20.035857: step 3781, loss 0.594902.
Train: 2018-07-31T00:48:20.176449: step 3782, loss 0.610969.
Train: 2018-07-31T00:48:20.317018: step 3783, loss 0.586924.
Train: 2018-07-31T00:48:20.473229: step 3784, loss 0.578759.
Train: 2018-07-31T00:48:20.613847: step 3785, loss 0.578766.
Train: 2018-07-31T00:48:20.785658: step 3786, loss 0.602819.
Train: 2018-07-31T00:48:20.926250: step 3787, loss 0.602758.
Train: 2018-07-31T00:48:21.066841: step 3788, loss 0.602656.
Train: 2018-07-31T00:48:21.207435: step 3789, loss 0.634094.
Train: 2018-07-31T00:48:21.348054: step 3790, loss 0.594571.
Test: 2018-07-31T00:48:21.582362: step 3790, loss 0.550187.
Train: 2018-07-31T00:48:21.738560: step 3791, loss 0.516417.
Train: 2018-07-31T00:48:21.879151: step 3792, loss 0.58668.
Train: 2018-07-31T00:48:22.035390: step 3793, loss 0.594432.
Train: 2018-07-31T00:48:22.175957: step 3794, loss 0.602123.
Train: 2018-07-31T00:48:22.316573: step 3795, loss 0.555852.
Train: 2018-07-31T00:48:22.472761: step 3796, loss 0.479173.
Train: 2018-07-31T00:48:22.613374: step 3797, loss 0.502219.
Train: 2018-07-31T00:48:22.753946: step 3798, loss 0.586653.
Train: 2018-07-31T00:48:22.894563: step 3799, loss 0.594354.
Train: 2018-07-31T00:48:23.050752: step 3800, loss 0.532726.
Test: 2018-07-31T00:48:23.285099: step 3800, loss 0.550581.
Train: 2018-07-31T00:48:24.034896: step 3801, loss 0.478612.
Train: 2018-07-31T00:48:24.191135: step 3802, loss 0.586671.
Train: 2018-07-31T00:48:24.331726: step 3803, loss 0.532271.
Train: 2018-07-31T00:48:24.472294: step 3804, loss 0.524252.
Train: 2018-07-31T00:48:24.612885: step 3805, loss 0.58672.
Train: 2018-07-31T00:48:24.769101: step 3806, loss 0.500136.
Train: 2018-07-31T00:48:24.909709: step 3807, loss 0.507622.
Train: 2018-07-31T00:48:25.050308: step 3808, loss 0.554967.
Train: 2018-07-31T00:48:25.190900: step 3809, loss 0.626993.
Train: 2018-07-31T00:48:25.331495: step 3810, loss 0.554737.
Test: 2018-07-31T00:48:25.581410: step 3810, loss 0.54919.
Train: 2018-07-31T00:48:25.722000: step 3811, loss 0.586935.
Train: 2018-07-31T00:48:25.862593: step 3812, loss 0.505943.
Train: 2018-07-31T00:48:26.034429: step 3813, loss 0.480871.
Train: 2018-07-31T00:48:26.175019: step 3814, loss 0.55444.
Train: 2018-07-31T00:48:26.315615: step 3815, loss 0.586436.
Train: 2018-07-31T00:48:26.471826: step 3816, loss 0.510775.
Train: 2018-07-31T00:48:26.612418: step 3817, loss 0.500338.
Train: 2018-07-31T00:48:26.753010: step 3818, loss 0.535844.
Train: 2018-07-31T00:48:26.893601: step 3819, loss 0.611824.
Train: 2018-07-31T00:48:27.049815: step 3820, loss 0.503386.
Test: 2018-07-31T00:48:27.284170: step 3820, loss 0.547574.
Train: 2018-07-31T00:48:27.440376: step 3821, loss 0.522718.
Train: 2018-07-31T00:48:27.596561: step 3822, loss 0.485718.
Train: 2018-07-31T00:48:27.737155: step 3823, loss 0.56862.
Train: 2018-07-31T00:48:27.877771: step 3824, loss 0.546536.
Train: 2018-07-31T00:48:28.018375: step 3825, loss 0.610624.
Train: 2018-07-31T00:48:28.174552: step 3826, loss 0.576038.
Train: 2018-07-31T00:48:28.315144: step 3827, loss 0.569659.
Train: 2018-07-31T00:48:28.455735: step 3828, loss 0.546395.
Train: 2018-07-31T00:48:28.611949: step 3829, loss 0.517712.
Train: 2018-07-31T00:48:28.752541: step 3830, loss 0.533136.
Test: 2018-07-31T00:48:29.002514: step 3830, loss 0.547806.
Train: 2018-07-31T00:48:29.143100: step 3831, loss 0.543684.
Train: 2018-07-31T00:48:29.283691: step 3832, loss 0.534619.
Train: 2018-07-31T00:48:29.439880: step 3833, loss 0.545092.
Train: 2018-07-31T00:48:29.596094: step 3834, loss 0.554293.
Train: 2018-07-31T00:48:29.736686: step 3835, loss 0.527387.
Train: 2018-07-31T00:48:29.877277: step 3836, loss 0.554069.
Train: 2018-07-31T00:48:30.017869: step 3837, loss 0.5194.
Train: 2018-07-31T00:48:30.174108: step 3838, loss 0.596948.
Train: 2018-07-31T00:48:30.345947: step 3839, loss 0.587289.
Train: 2018-07-31T00:48:30.486511: step 3840, loss 0.56195.
Test: 2018-07-31T00:48:30.720861: step 3840, loss 0.54813.
Train: 2018-07-31T00:48:30.861422: step 3841, loss 0.562478.
Train: 2018-07-31T00:48:31.033257: step 3842, loss 0.603528.
Train: 2018-07-31T00:48:31.173850: step 3843, loss 0.579175.
Train: 2018-07-31T00:48:31.330063: step 3844, loss 0.621761.
Train: 2018-07-31T00:48:31.470654: step 3845, loss 0.545814.
Train: 2018-07-31T00:48:31.626893: step 3846, loss 0.53722.
Train: 2018-07-31T00:48:31.767484: step 3847, loss 0.495757.
Train: 2018-07-31T00:48:31.923675: step 3848, loss 0.645304.
Train: 2018-07-31T00:48:32.064291: step 3849, loss 0.496599.
Train: 2018-07-31T00:48:32.204884: step 3850, loss 0.56224.
Test: 2018-07-31T00:48:32.454801: step 3850, loss 0.548639.
Train: 2018-07-31T00:48:32.595392: step 3851, loss 0.595837.
Train: 2018-07-31T00:48:32.735997: step 3852, loss 0.59606.
Train: 2018-07-31T00:48:32.876576: step 3853, loss 0.472174.
Train: 2018-07-31T00:48:33.032814: step 3854, loss 0.636363.
Train: 2018-07-31T00:48:33.173432: step 3855, loss 0.570664.
Train: 2018-07-31T00:48:33.313991: step 3856, loss 0.497431.
Train: 2018-07-31T00:48:33.454590: step 3857, loss 0.603754.
Train: 2018-07-31T00:48:33.610779: step 3858, loss 0.554331.
Train: 2018-07-31T00:48:33.751372: step 3859, loss 0.529957.
Train: 2018-07-31T00:48:33.891987: step 3860, loss 0.570783.
Test: 2018-07-31T00:48:34.141905: step 3860, loss 0.548991.
Train: 2018-07-31T00:48:34.282522: step 3861, loss 0.578965.
Train: 2018-07-31T00:48:34.438710: step 3862, loss 0.546394.
Train: 2018-07-31T00:48:34.579327: step 3863, loss 0.611435.
Train: 2018-07-31T00:48:34.719919: step 3864, loss 0.595191.
Train: 2018-07-31T00:48:34.876107: step 3865, loss 0.497818.
Train: 2018-07-31T00:48:35.016699: step 3866, loss 0.595168.
Train: 2018-07-31T00:48:35.157316: step 3867, loss 0.57889.
Train: 2018-07-31T00:48:35.297887: step 3868, loss 0.56268.
Train: 2018-07-31T00:48:35.438500: step 3869, loss 0.530409.
Train: 2018-07-31T00:48:35.594689: step 3870, loss 0.578848.
Test: 2018-07-31T00:48:35.844662: step 3870, loss 0.549197.
Train: 2018-07-31T00:48:35.985223: step 3871, loss 0.53041.
Train: 2018-07-31T00:48:36.141437: step 3872, loss 0.546546.
Train: 2018-07-31T00:48:36.282028: step 3873, loss 0.554595.
Train: 2018-07-31T00:48:36.422620: step 3874, loss 0.562644.
Train: 2018-07-31T00:48:36.578834: step 3875, loss 0.651882.
Train: 2018-07-31T00:48:36.735072: step 3876, loss 0.546476.
Train: 2018-07-31T00:48:36.875664: step 3877, loss 0.497918.
Train: 2018-07-31T00:48:37.016255: step 3878, loss 0.570788.
Train: 2018-07-31T00:48:37.172446: step 3879, loss 0.619671.
Train: 2018-07-31T00:48:37.313037: step 3880, loss 0.627524.
Test: 2018-07-31T00:48:37.547387: step 3880, loss 0.549149.
Train: 2018-07-31T00:48:37.703571: step 3881, loss 0.473708.
Train: 2018-07-31T00:48:37.844164: step 3882, loss 0.530355.
Train: 2018-07-31T00:48:37.984756: step 3883, loss 0.594983.
Train: 2018-07-31T00:48:38.125346: step 3884, loss 0.514014.
Train: 2018-07-31T00:48:38.265939: step 3885, loss 0.538256.
Train: 2018-07-31T00:48:38.422152: step 3886, loss 0.53006.
Train: 2018-07-31T00:48:38.562744: step 3887, loss 0.538224.
Train: 2018-07-31T00:48:38.703336: step 3888, loss 0.603403.
Train: 2018-07-31T00:48:38.843952: step 3889, loss 0.62031.
Train: 2018-07-31T00:48:39.000141: step 3890, loss 0.628627.
Test: 2018-07-31T00:48:39.234464: step 3890, loss 0.548849.
Train: 2018-07-31T00:48:39.390674: step 3891, loss 0.619571.
Train: 2018-07-31T00:48:39.546889: step 3892, loss 0.595328.
Train: 2018-07-31T00:48:39.687481: step 3893, loss 0.627694.
Train: 2018-07-31T00:48:39.828074: step 3894, loss 0.530465.
Train: 2018-07-31T00:48:39.968665: step 3895, loss 0.586905.
Train: 2018-07-31T00:48:40.109296: step 3896, loss 0.562843.
Train: 2018-07-31T00:48:40.249874: step 3897, loss 0.562886.
Train: 2018-07-31T00:48:40.406088: step 3898, loss 0.562925.
Train: 2018-07-31T00:48:40.562276: step 3899, loss 0.610654.
Train: 2018-07-31T00:48:40.702869: step 3900, loss 0.515461.
Test: 2018-07-31T00:48:40.937188: step 3900, loss 0.549779.
Train: 2018-07-31T00:48:41.749522: step 3901, loss 0.555119.
Train: 2018-07-31T00:48:41.890089: step 3902, loss 0.507705.
Train: 2018-07-31T00:48:42.030706: step 3903, loss 0.507656.
Train: 2018-07-31T00:48:42.186920: step 3904, loss 0.531289.
Train: 2018-07-31T00:48:42.327513: step 3905, loss 0.602711.
Train: 2018-07-31T00:48:42.468079: step 3906, loss 0.578859.
Train: 2018-07-31T00:48:42.624293: step 3907, loss 0.570886.
Train: 2018-07-31T00:48:42.764910: step 3908, loss 0.546929.
Train: 2018-07-31T00:48:42.905503: step 3909, loss 0.602845.
Train: 2018-07-31T00:48:43.061690: step 3910, loss 0.546871.
Test: 2018-07-31T00:48:43.296062: step 3910, loss 0.549448.
Train: 2018-07-31T00:48:43.436628: step 3911, loss 0.682928.
Train: 2018-07-31T00:48:43.592817: step 3912, loss 0.586851.
Train: 2018-07-31T00:48:43.749040: step 3913, loss 0.546975.
Train: 2018-07-31T00:48:43.889646: step 3914, loss 0.586818.
Train: 2018-07-31T00:48:44.045855: step 3915, loss 0.50736.
Train: 2018-07-31T00:48:44.202049: step 3916, loss 0.547087.
Train: 2018-07-31T00:48:44.358262: step 3917, loss 0.531183.
Train: 2018-07-31T00:48:44.498853: step 3918, loss 0.531125.
Train: 2018-07-31T00:48:44.639446: step 3919, loss 0.507115.
Train: 2018-07-31T00:48:44.780039: step 3920, loss 0.714823.
Test: 2018-07-31T00:48:45.029981: step 3920, loss 0.54949.
Train: 2018-07-31T00:48:45.170596: step 3921, loss 0.570869.
Train: 2018-07-31T00:48:45.311164: step 3922, loss 0.586849.
Train: 2018-07-31T00:48:45.451756: step 3923, loss 0.602799.
Train: 2018-07-31T00:48:45.607982: step 3924, loss 0.49124.
Train: 2018-07-31T00:48:45.748563: step 3925, loss 0.531055.
Train: 2018-07-31T00:48:45.873532: step 3926, loss 0.562905.
Train: 2018-07-31T00:48:46.014150: step 3927, loss 0.602818.
Train: 2018-07-31T00:48:46.170339: step 3928, loss 0.546914.
Train: 2018-07-31T00:48:46.310931: step 3929, loss 0.570865.
Train: 2018-07-31T00:48:46.451546: step 3930, loss 0.618869.
Test: 2018-07-31T00:48:46.685842: step 3930, loss 0.549499.
Train: 2018-07-31T00:48:46.842056: step 3931, loss 0.538912.
Train: 2018-07-31T00:48:46.982647: step 3932, loss 0.634795.
Train: 2018-07-31T00:48:47.123239: step 3933, loss 0.578866.
Train: 2018-07-31T00:48:47.263831: step 3934, loss 0.570901.
Train: 2018-07-31T00:48:47.404424: step 3935, loss 0.515277.
Train: 2018-07-31T00:48:47.545016: step 3936, loss 0.634473.
Train: 2018-07-31T00:48:47.685609: step 3937, loss 0.562996.
Train: 2018-07-31T00:48:47.826241: step 3938, loss 0.56302.
Train: 2018-07-31T00:48:47.966792: step 3939, loss 0.570951.
Train: 2018-07-31T00:48:48.123029: step 3940, loss 0.491944.
Test: 2018-07-31T00:48:48.357325: step 3940, loss 0.549798.
Train: 2018-07-31T00:48:48.513539: step 3941, loss 0.539316.
Train: 2018-07-31T00:48:48.669753: step 3942, loss 0.491728.
Train: 2018-07-31T00:48:48.810344: step 3943, loss 0.562965.
Train: 2018-07-31T00:48:48.950936: step 3944, loss 0.586831.
Train: 2018-07-31T00:48:49.091553: step 3945, loss 0.546903.
Train: 2018-07-31T00:48:49.247743: step 3946, loss 0.602895.
Train: 2018-07-31T00:48:49.388335: step 3947, loss 0.586889.
Train: 2018-07-31T00:48:49.528926: step 3948, loss 0.570842.
Train: 2018-07-31T00:48:49.669518: step 3949, loss 0.514609.
Train: 2018-07-31T00:48:49.810135: step 3950, loss 0.594969.
Test: 2018-07-31T00:48:50.044433: step 3950, loss 0.549281.
Train: 2018-07-31T00:48:50.185023: step 3951, loss 0.554715.
Train: 2018-07-31T00:48:50.341236: step 3952, loss 0.627256.
Train: 2018-07-31T00:48:50.481830: step 3953, loss 0.52247.
Train: 2018-07-31T00:48:50.622445: step 3954, loss 0.586944.
Train: 2018-07-31T00:48:50.778647: step 3955, loss 0.570818.
Train: 2018-07-31T00:48:50.919263: step 3956, loss 0.514387.
Train: 2018-07-31T00:48:51.059852: step 3957, loss 0.514322.
Train: 2018-07-31T00:48:51.216030: step 3958, loss 0.603153.
Train: 2018-07-31T00:48:51.356623: step 3959, loss 0.586991.
Train: 2018-07-31T00:48:51.497240: step 3960, loss 0.514105.
Test: 2018-07-31T00:48:51.747157: step 3960, loss 0.549096.
Train: 2018-07-31T00:48:51.887750: step 3961, loss 0.578902.
Train: 2018-07-31T00:48:52.028342: step 3962, loss 0.595146.
Train: 2018-07-31T00:48:52.168939: step 3963, loss 0.570787.
Train: 2018-07-31T00:48:52.309553: step 3964, loss 0.546425.
Train: 2018-07-31T00:48:52.465740: step 3965, loss 0.587034.
Train: 2018-07-31T00:48:52.606332: step 3966, loss 0.473317.
Train: 2018-07-31T00:48:52.746941: step 3967, loss 0.53009.
Train: 2018-07-31T00:48:52.903137: step 3968, loss 0.521824.
Train: 2018-07-31T00:48:53.043753: step 3969, loss 0.578949.
Train: 2018-07-31T00:48:53.184345: step 3970, loss 0.578965.
Test: 2018-07-31T00:48:53.434295: step 3970, loss 0.548777.
Train: 2018-07-31T00:48:53.574853: step 3971, loss 0.603633.
Train: 2018-07-31T00:48:53.731092: step 3972, loss 0.537863.
Train: 2018-07-31T00:48:53.871684: step 3973, loss 0.521362.
Train: 2018-07-31T00:48:54.012277: step 3974, loss 0.579004.
Train: 2018-07-31T00:48:54.152843: step 3975, loss 0.537724.
Train: 2018-07-31T00:48:54.293434: step 3976, loss 0.545942.
Train: 2018-07-31T00:48:54.434035: step 3977, loss 0.587329.
Train: 2018-07-31T00:48:54.590241: step 3978, loss 0.637109.
Train: 2018-07-31T00:48:54.730833: step 3979, loss 0.512755.
Train: 2018-07-31T00:48:54.871450: step 3980, loss 0.562469.
Test: 2018-07-31T00:48:55.105771: step 3980, loss 0.548587.
Train: 2018-07-31T00:48:55.261960: step 3981, loss 0.529314.
Train: 2018-07-31T00:48:55.402552: step 3982, loss 0.587348.
Train: 2018-07-31T00:48:55.527521: step 3983, loss 0.562463.
Train: 2018-07-31T00:48:55.683735: step 3984, loss 0.554169.
Train: 2018-07-31T00:48:55.824328: step 3985, loss 0.620529.
Train: 2018-07-31T00:48:55.964919: step 3986, loss 0.603894.
Train: 2018-07-31T00:48:56.105513: step 3987, loss 0.587288.
Train: 2018-07-31T00:48:56.246103: step 3988, loss 0.513046.
Train: 2018-07-31T00:48:56.402318: step 3989, loss 0.562524.
Train: 2018-07-31T00:48:56.542933: step 3990, loss 0.578982.
Test: 2018-07-31T00:48:56.777231: step 3990, loss 0.548796.
Train: 2018-07-31T00:48:56.933442: step 3991, loss 0.521491.
Train: 2018-07-31T00:48:57.074058: step 3992, loss 0.521501.
Train: 2018-07-31T00:48:57.230272: step 3993, loss 0.611839.
Train: 2018-07-31T00:48:57.386461: step 3994, loss 0.603596.
Train: 2018-07-31T00:48:57.527053: step 3995, loss 0.595372.
Train: 2018-07-31T00:48:57.667646: step 3996, loss 0.619807.
Train: 2018-07-31T00:48:57.808238: step 3997, loss 0.554543.
Train: 2018-07-31T00:48:57.948830: step 3998, loss 0.546415.
Train: 2018-07-31T00:48:58.089421: step 3999, loss 0.546476.
Train: 2018-07-31T00:48:58.230039: step 4000, loss 0.578894.
Test: 2018-07-31T00:48:58.479986: step 4000, loss 0.549196.
Train: 2018-07-31T00:48:59.214157: step 4001, loss 0.619286.
Train: 2018-07-31T00:48:59.354750: step 4002, loss 0.546651.
Train: 2018-07-31T00:48:59.510964: step 4003, loss 0.611032.
Train: 2018-07-31T00:48:59.651556: step 4004, loss 0.47466.
Train: 2018-07-31T00:48:59.807770: step 4005, loss 0.522782.
Train: 2018-07-31T00:48:59.948387: step 4006, loss 0.5468.
Train: 2018-07-31T00:49:00.104576: step 4007, loss 0.586893.
Train: 2018-07-31T00:49:00.245191: step 4008, loss 0.643094.
Train: 2018-07-31T00:49:00.401381: step 4009, loss 0.554817.
Train: 2018-07-31T00:49:00.557619: step 4010, loss 0.562848.
Test: 2018-07-31T00:49:00.791942: step 4010, loss 0.54946.
Train: 2018-07-31T00:49:00.932531: step 4011, loss 0.546858.
Train: 2018-07-31T00:49:01.088720: step 4012, loss 0.530864.
Train: 2018-07-31T00:49:01.229336: step 4013, loss 0.54682.
Train: 2018-07-31T00:49:01.385549: step 4014, loss 0.594896.
Train: 2018-07-31T00:49:01.526117: step 4015, loss 0.611001.
Train: 2018-07-31T00:49:01.666710: step 4016, loss 0.586861.
Train: 2018-07-31T00:49:01.822923: step 4017, loss 0.482849.
Train: 2018-07-31T00:49:01.963514: step 4018, loss 0.586924.
Train: 2018-07-31T00:49:02.104131: step 4019, loss 0.578881.
Train: 2018-07-31T00:49:02.244723: step 4020, loss 0.610991.
Test: 2018-07-31T00:49:02.494670: step 4020, loss 0.549451.
Train: 2018-07-31T00:49:02.650866: step 4021, loss 0.618833.
Train: 2018-07-31T00:49:02.791470: step 4022, loss 0.507028.
Train: 2018-07-31T00:49:02.932062: step 4023, loss 0.538975.
Train: 2018-07-31T00:49:03.072650: step 4024, loss 0.57886.
Train: 2018-07-31T00:49:03.228867: step 4025, loss 0.562904.
Train: 2018-07-31T00:49:03.369439: step 4026, loss 0.530991.
Train: 2018-07-31T00:49:03.525648: step 4027, loss 0.538934.
Train: 2018-07-31T00:49:03.666240: step 4028, loss 0.498887.
Train: 2018-07-31T00:49:03.822454: step 4029, loss 0.578869.
Train: 2018-07-31T00:49:03.963047: step 4030, loss 0.554754.
Test: 2018-07-31T00:49:04.197366: step 4030, loss 0.549258.
Train: 2018-07-31T00:49:04.353580: step 4031, loss 0.506329.
Train: 2018-07-31T00:49:04.509795: step 4032, loss 0.586995.
Train: 2018-07-31T00:49:04.650385: step 4033, loss 0.489643.
Train: 2018-07-31T00:49:04.791002: step 4034, loss 0.603401.
Train: 2018-07-31T00:49:04.931569: step 4035, loss 0.546226.
Train: 2018-07-31T00:49:05.072162: step 4036, loss 0.529787.
Train: 2018-07-31T00:49:05.212753: step 4037, loss 0.603671.
Train: 2018-07-31T00:49:05.353345: step 4038, loss 0.529513.
Train: 2018-07-31T00:49:05.493939: step 4039, loss 0.587153.
Train: 2018-07-31T00:49:05.634548: step 4040, loss 0.579311.
Test: 2018-07-31T00:49:05.868856: step 4040, loss 0.548577.
Train: 2018-07-31T00:49:06.025063: step 4041, loss 0.612181.
Train: 2018-07-31T00:49:06.165682: step 4042, loss 0.60381.
Train: 2018-07-31T00:49:06.321893: step 4043, loss 0.521272.
Train: 2018-07-31T00:49:06.462485: step 4044, loss 0.52132.
Train: 2018-07-31T00:49:06.603089: step 4045, loss 0.603744.
Train: 2018-07-31T00:49:06.743673: step 4046, loss 0.611919.
Train: 2018-07-31T00:49:06.884262: step 4047, loss 0.59552.
Train: 2018-07-31T00:49:07.040452: step 4048, loss 0.55443.
Train: 2018-07-31T00:49:07.181047: step 4049, loss 0.529789.
Train: 2018-07-31T00:49:07.321636: step 4050, loss 0.505246.
Test: 2018-07-31T00:49:07.555989: step 4050, loss 0.54882.
Train: 2018-07-31T00:49:07.712193: step 4051, loss 0.578966.
Train: 2018-07-31T00:49:07.884002: step 4052, loss 0.578967.
Train: 2018-07-31T00:49:08.024595: step 4053, loss 0.611768.
Train: 2018-07-31T00:49:08.180810: step 4054, loss 0.619897.
Train: 2018-07-31T00:49:08.321424: step 4055, loss 0.52177.
Train: 2018-07-31T00:49:08.461991: step 4056, loss 0.481077.
Train: 2018-07-31T00:49:08.618207: step 4057, loss 0.546297.
Train: 2018-07-31T00:49:08.758803: step 4058, loss 0.587101.
Train: 2018-07-31T00:49:08.899415: step 4059, loss 0.562603.
Train: 2018-07-31T00:49:09.039981: step 4060, loss 0.513592.
Test: 2018-07-31T00:49:09.289952: step 4060, loss 0.548891.
Train: 2018-07-31T00:49:09.430515: step 4061, loss 0.513516.
Train: 2018-07-31T00:49:09.571108: step 4062, loss 0.603553.
Train: 2018-07-31T00:49:09.711700: step 4063, loss 0.529732.
Train: 2018-07-31T00:49:09.883559: step 4064, loss 0.521414.
Train: 2018-07-31T00:49:10.024126: step 4065, loss 0.653239.
Train: 2018-07-31T00:49:10.164718: step 4066, loss 0.529515.
Train: 2018-07-31T00:49:10.305311: step 4067, loss 0.562518.
Train: 2018-07-31T00:49:10.445903: step 4068, loss 0.545971.
Train: 2018-07-31T00:49:10.586495: step 4069, loss 0.545968.
Train: 2018-07-31T00:49:10.727087: step 4070, loss 0.504604.
Test: 2018-07-31T00:49:10.977030: step 4070, loss 0.54857.
Train: 2018-07-31T00:49:11.117621: step 4071, loss 0.537572.
Train: 2018-07-31T00:49:11.258238: step 4072, loss 0.570876.
Train: 2018-07-31T00:49:11.414427: step 4073, loss 0.529062.
Train: 2018-07-31T00:49:11.555042: step 4074, loss 0.512296.
Train: 2018-07-31T00:49:11.695610: step 4075, loss 0.537273.
Train: 2018-07-31T00:49:11.836202: step 4076, loss 0.562458.
Train: 2018-07-31T00:49:11.976794: step 4077, loss 0.634493.
Train: 2018-07-31T00:49:12.117386: step 4078, loss 0.537026.
Train: 2018-07-31T00:49:12.258025: step 4079, loss 0.528628.
Train: 2018-07-31T00:49:12.414194: step 4080, loss 0.604684.
Test: 2018-07-31T00:49:12.648546: step 4080, loss 0.548216.
Train: 2018-07-31T00:49:12.835969: step 4081, loss 0.553864.
Train: 2018-07-31T00:49:12.976560: step 4082, loss 0.579275.
Train: 2018-07-31T00:49:13.132774: step 4083, loss 0.511725.
Train: 2018-07-31T00:49:13.257771: step 4084, loss 0.545477.
Train: 2018-07-31T00:49:13.429579: step 4085, loss 0.570812.
Train: 2018-07-31T00:49:13.570196: step 4086, loss 0.528553.
Train: 2018-07-31T00:49:13.726409: step 4087, loss 0.587735.
Train: 2018-07-31T00:49:13.866977: step 4088, loss 0.587735.
Train: 2018-07-31T00:49:14.007569: step 4089, loss 0.579267.
Train: 2018-07-31T00:49:14.179404: step 4090, loss 0.646792.
Test: 2018-07-31T00:49:14.413753: step 4090, loss 0.548281.
Train: 2018-07-31T00:49:14.569936: step 4091, loss 0.520294.
Train: 2018-07-31T00:49:14.710528: step 4092, loss 0.478388.
Train: 2018-07-31T00:49:14.851120: step 4093, loss 0.579185.
Train: 2018-07-31T00:49:14.991714: step 4094, loss 0.646323.
Train: 2018-07-31T00:49:15.132306: step 4095, loss 0.528916.
Train: 2018-07-31T00:49:15.272897: step 4096, loss 0.53734.
Train: 2018-07-31T00:49:15.413490: step 4097, loss 0.587466.
Train: 2018-07-31T00:49:15.554106: step 4098, loss 0.637443.
Train: 2018-07-31T00:49:15.694673: step 4099, loss 0.612298.
Train: 2018-07-31T00:49:15.835291: step 4100, loss 0.562483.
Test: 2018-07-31T00:49:16.085260: step 4100, loss 0.548712.
Train: 2018-07-31T00:49:16.850681: step 4101, loss 0.595482.
Train: 2018-07-31T00:49:17.022489: step 4102, loss 0.595381.
Train: 2018-07-31T00:49:17.163081: step 4103, loss 0.497249.
Train: 2018-07-31T00:49:17.303673: step 4104, loss 0.562629.
Train: 2018-07-31T00:49:17.444264: step 4105, loss 0.473255.
Train: 2018-07-31T00:49:17.584856: step 4106, loss 0.603291.
Train: 2018-07-31T00:49:17.725473: step 4107, loss 0.522077.
Train: 2018-07-31T00:49:17.866064: step 4108, loss 0.562667.
Train: 2018-07-31T00:49:18.006650: step 4109, loss 0.595147.
Train: 2018-07-31T00:49:18.162847: step 4110, loss 0.587021.
Test: 2018-07-31T00:49:18.397173: step 4110, loss 0.549114.
Train: 2018-07-31T00:49:18.553380: step 4111, loss 0.595105.
Train: 2018-07-31T00:49:18.693971: step 4112, loss 0.611257.
Train: 2018-07-31T00:49:18.834563: step 4113, loss 0.546605.
Train: 2018-07-31T00:49:18.975155: step 4114, loss 0.619148.
Train: 2018-07-31T00:49:19.115748: step 4115, loss 0.570841.
Train: 2018-07-31T00:49:19.271987: step 4116, loss 0.586867.
Train: 2018-07-31T00:49:19.412554: step 4117, loss 0.602807.
Train: 2018-07-31T00:49:19.553145: step 4118, loss 0.523192.
Train: 2018-07-31T00:49:19.709359: step 4119, loss 0.475703.
Train: 2018-07-31T00:49:19.834330: step 4120, loss 0.562985.
Test: 2018-07-31T00:49:20.084271: step 4120, loss 0.549678.
Train: 2018-07-31T00:49:20.224888: step 4121, loss 0.578857.
Train: 2018-07-31T00:49:20.365455: step 4122, loss 0.515323.
Train: 2018-07-31T00:49:20.506049: step 4123, loss 0.602719.
Train: 2018-07-31T00:49:20.646639: step 4124, loss 0.562945.
Train: 2018-07-31T00:49:20.787231: step 4125, loss 0.547014.
Train: 2018-07-31T00:49:20.943448: step 4126, loss 0.562916.
Train: 2018-07-31T00:49:21.084038: step 4127, loss 0.546942.
Train: 2018-07-31T00:49:21.224629: step 4128, loss 0.506954.
Train: 2018-07-31T00:49:21.365246: step 4129, loss 0.538855.
Train: 2018-07-31T00:49:21.521436: step 4130, loss 0.61899.
Test: 2018-07-31T00:49:21.755755: step 4130, loss 0.549277.
Train: 2018-07-31T00:49:21.896346: step 4131, loss 0.562804.
Train: 2018-07-31T00:49:22.052561: step 4132, loss 0.538586.
Train: 2018-07-31T00:49:22.193152: step 4133, loss 0.586968.
Train: 2018-07-31T00:49:22.333744: step 4134, loss 0.58698.
Train: 2018-07-31T00:49:22.474354: step 4135, loss 0.586965.
Train: 2018-07-31T00:49:22.630549: step 4136, loss 0.603269.
Train: 2018-07-31T00:49:22.771142: step 4137, loss 0.514221.
Train: 2018-07-31T00:49:22.911735: step 4138, loss 0.546542.
Train: 2018-07-31T00:49:23.067947: step 4139, loss 0.55463.
Train: 2018-07-31T00:49:23.224162: step 4140, loss 0.570796.
Test: 2018-07-31T00:49:23.458510: step 4140, loss 0.549132.
Train: 2018-07-31T00:49:23.599074: step 4141, loss 0.595111.
Train: 2018-07-31T00:49:23.770909: step 4142, loss 0.5951.
Train: 2018-07-31T00:49:23.911525: step 4143, loss 0.554626.
Train: 2018-07-31T00:49:24.067737: step 4144, loss 0.530383.
Train: 2018-07-31T00:49:24.208305: step 4145, loss 0.578891.
Train: 2018-07-31T00:49:24.348922: step 4146, loss 0.546546.
Train: 2018-07-31T00:49:24.489488: step 4147, loss 0.473733.
Train: 2018-07-31T00:49:24.630106: step 4148, loss 0.562683.
Train: 2018-07-31T00:49:24.786320: step 4149, loss 0.505767.
Train: 2018-07-31T00:49:24.942508: step 4150, loss 0.554465.
Test: 2018-07-31T00:49:25.176830: step 4150, loss 0.548886.
Train: 2018-07-31T00:49:25.333043: step 4151, loss 0.587127.
Train: 2018-07-31T00:49:25.473635: step 4152, loss 0.570762.
Train: 2018-07-31T00:49:25.614244: step 4153, loss 0.587188.
Train: 2018-07-31T00:49:25.754817: step 4154, loss 0.595426.
Train: 2018-07-31T00:49:25.911031: step 4155, loss 0.546087.
Train: 2018-07-31T00:49:26.051622: step 4156, loss 0.611897.
Train: 2018-07-31T00:49:26.192216: step 4157, loss 0.537872.
Train: 2018-07-31T00:49:26.348431: step 4158, loss 0.562538.
Train: 2018-07-31T00:49:26.489020: step 4159, loss 0.554321.
Train: 2018-07-31T00:49:26.629616: step 4160, loss 0.587196.
Test: 2018-07-31T00:49:26.879584: step 4160, loss 0.548794.
Train: 2018-07-31T00:49:27.020190: step 4161, loss 0.521479.
Train: 2018-07-31T00:49:27.176361: step 4162, loss 0.521459.
Train: 2018-07-31T00:49:27.316952: step 4163, loss 0.521398.
Train: 2018-07-31T00:49:27.457545: step 4164, loss 0.562514.
Train: 2018-07-31T00:49:27.598137: step 4165, loss 0.537728.
Train: 2018-07-31T00:49:27.738728: step 4166, loss 0.570756.
Train: 2018-07-31T00:49:27.894967: step 4167, loss 0.603905.
Train: 2018-07-31T00:49:28.035559: step 4168, loss 0.579048.
Train: 2018-07-31T00:49:28.191746: step 4169, loss 0.628786.
Train: 2018-07-31T00:49:28.332341: step 4170, loss 0.554204.
Test: 2018-07-31T00:49:28.582281: step 4170, loss 0.54865.
Train: 2018-07-31T00:49:28.722874: step 4171, loss 0.48811.
Train: 2018-07-31T00:49:28.863483: step 4172, loss 0.645166.
Train: 2018-07-31T00:49:29.004056: step 4173, loss 0.512974.
Train: 2018-07-31T00:49:29.160288: step 4174, loss 0.504746.
Train: 2018-07-31T00:49:29.300887: step 4175, loss 0.562498.
Train: 2018-07-31T00:49:29.457113: step 4176, loss 0.554225.
Train: 2018-07-31T00:49:29.597693: step 4177, loss 0.488042.
Train: 2018-07-31T00:49:29.738285: step 4178, loss 0.562465.
Train: 2018-07-31T00:49:29.894498: step 4179, loss 0.587373.
Train: 2018-07-31T00:49:30.050687: step 4180, loss 0.579075.
Test: 2018-07-31T00:49:30.285035: step 4180, loss 0.548501.
Train: 2018-07-31T00:49:30.456846: step 4181, loss 0.587399.
Train: 2018-07-31T00:49:30.597435: step 4182, loss 0.529145.
Train: 2018-07-31T00:49:30.738040: step 4183, loss 0.604074.
Train: 2018-07-31T00:49:30.878643: step 4184, loss 0.554111.
Train: 2018-07-31T00:49:31.019235: step 4185, loss 0.520866.
Train: 2018-07-31T00:49:31.175425: step 4186, loss 0.46259.
Train: 2018-07-31T00:49:31.316015: step 4187, loss 0.620851.
Train: 2018-07-31T00:49:31.472230: step 4188, loss 0.587409.
Train: 2018-07-31T00:49:31.612822: step 4189, loss 0.545756.
Train: 2018-07-31T00:49:31.753413: step 4190, loss 0.462153.
Test: 2018-07-31T00:49:32.003355: step 4190, loss 0.548368.
Train: 2018-07-31T00:49:32.159568: step 4191, loss 0.554039.
Train: 2018-07-31T00:49:32.300178: step 4192, loss 0.503627.
Train: 2018-07-31T00:49:32.456374: step 4193, loss 0.486523.
Train: 2018-07-31T00:49:32.612623: step 4194, loss 0.570574.
Train: 2018-07-31T00:49:32.753179: step 4195, loss 0.545206.
Train: 2018-07-31T00:49:32.893770: step 4196, loss 0.605364.
Train: 2018-07-31T00:49:33.034380: step 4197, loss 0.562737.
Train: 2018-07-31T00:49:33.174956: step 4198, loss 0.588089.
Train: 2018-07-31T00:49:33.331194: step 4199, loss 0.56184.
Train: 2018-07-31T00:49:33.471786: step 4200, loss 0.587443.
Test: 2018-07-31T00:49:33.706082: step 4200, loss 0.547951.
Train: 2018-07-31T00:49:34.440286: step 4201, loss 0.587958.
Train: 2018-07-31T00:49:34.580876: step 4202, loss 0.579204.
Train: 2018-07-31T00:49:34.737090: step 4203, loss 0.588838.
Train: 2018-07-31T00:49:34.877681: step 4204, loss 0.511182.
Train: 2018-07-31T00:49:35.018283: step 4205, loss 0.536477.
Train: 2018-07-31T00:49:35.174488: step 4206, loss 0.604672.
Train: 2018-07-31T00:49:35.299459: step 4207, loss 0.528444.
Train: 2018-07-31T00:49:35.455672: step 4208, loss 0.630201.
Train: 2018-07-31T00:49:35.596288: step 4209, loss 0.638585.
Train: 2018-07-31T00:49:35.752478: step 4210, loss 0.562055.
Test: 2018-07-31T00:49:35.986828: step 4210, loss 0.548407.
Train: 2018-07-31T00:49:36.143010: step 4211, loss 0.487032.
Train: 2018-07-31T00:49:36.283621: step 4212, loss 0.637506.
Train: 2018-07-31T00:49:36.439816: step 4213, loss 0.512603.
Train: 2018-07-31T00:49:36.580409: step 4214, loss 0.537505.
Train: 2018-07-31T00:49:36.721024: step 4215, loss 0.545862.
Train: 2018-07-31T00:49:36.861617: step 4216, loss 0.579179.
Train: 2018-07-31T00:49:37.002209: step 4217, loss 0.537832.
Train: 2018-07-31T00:49:37.142802: step 4218, loss 0.51289.
Train: 2018-07-31T00:49:37.298991: step 4219, loss 0.56229.
Train: 2018-07-31T00:49:37.439581: step 4220, loss 0.6453.
Test: 2018-07-31T00:49:37.673932: step 4220, loss 0.548694.
Train: 2018-07-31T00:49:37.830140: step 4221, loss 0.571224.
Train: 2018-07-31T00:49:37.970732: step 4222, loss 0.521627.
Train: 2018-07-31T00:49:38.111311: step 4223, loss 0.505144.
Train: 2018-07-31T00:49:38.267512: step 4224, loss 0.57076.
Train: 2018-07-31T00:49:38.408129: step 4225, loss 0.570784.
Train: 2018-07-31T00:49:38.548696: step 4226, loss 0.603573.
Train: 2018-07-31T00:49:38.689300: step 4227, loss 0.619944.
Train: 2018-07-31T00:49:38.829882: step 4228, loss 0.580036.
Train: 2018-07-31T00:49:38.970491: step 4229, loss 0.578932.
Train: 2018-07-31T00:49:39.126686: step 4230, loss 0.578919.
Test: 2018-07-31T00:49:39.361009: step 4230, loss 0.549076.
Train: 2018-07-31T00:49:39.517245: step 4231, loss 0.489611.
Train: 2018-07-31T00:49:39.657813: step 4232, loss 0.522116.
Train: 2018-07-31T00:49:39.798404: step 4233, loss 0.522096.
Train: 2018-07-31T00:49:39.938997: step 4234, loss 0.530153.
Train: 2018-07-31T00:49:40.095235: step 4235, loss 0.611489.
Train: 2018-07-31T00:49:40.251424: step 4236, loss 0.513746.
Train: 2018-07-31T00:49:40.376419: step 4237, loss 0.611578.
Train: 2018-07-31T00:49:40.532609: step 4238, loss 0.603428.
Train: 2018-07-31T00:49:40.673200: step 4239, loss 0.513655.
Train: 2018-07-31T00:49:40.813816: step 4240, loss 0.505455.
Test: 2018-07-31T00:49:41.048146: step 4240, loss 0.548888.
Train: 2018-07-31T00:49:41.188726: step 4241, loss 0.554408.
Train: 2018-07-31T00:49:41.329320: step 4242, loss 0.570763.
Train: 2018-07-31T00:49:41.469887: step 4243, loss 0.537936.
Train: 2018-07-31T00:49:41.610480: step 4244, loss 0.562538.
Train: 2018-07-31T00:49:41.751073: step 4245, loss 0.521353.
Train: 2018-07-31T00:49:41.907285: step 4246, loss 0.562503.
Train: 2018-07-31T00:49:42.063499: step 4247, loss 0.529408.
Train: 2018-07-31T00:49:42.204090: step 4248, loss 0.570758.
Train: 2018-07-31T00:49:42.344708: step 4249, loss 0.612292.
Train: 2018-07-31T00:49:42.485274: step 4250, loss 0.604005.
Test: 2018-07-31T00:49:42.735217: step 4250, loss 0.548541.
Train: 2018-07-31T00:49:42.891455: step 4251, loss 0.587373.
Train: 2018-07-31T00:49:43.032047: step 4252, loss 0.579056.
Train: 2018-07-31T00:49:43.188237: step 4253, loss 0.570757.
Train: 2018-07-31T00:49:43.328828: step 4254, loss 0.628662.
Train: 2018-07-31T00:49:43.469419: step 4255, loss 0.513024.
Train: 2018-07-31T00:49:43.641254: step 4256, loss 0.578991.
Train: 2018-07-31T00:49:43.781846: step 4257, loss 0.537885.
Train: 2018-07-31T00:49:43.938060: step 4258, loss 0.554343.
Train: 2018-07-31T00:49:44.078651: step 4259, loss 0.546159.
Train: 2018-07-31T00:49:44.219244: step 4260, loss 0.611752.
Test: 2018-07-31T00:49:44.469221: step 4260, loss 0.548875.
Train: 2018-07-31T00:49:44.609778: step 4261, loss 0.49711.
Train: 2018-07-31T00:49:44.750370: step 4262, loss 0.603503.
Train: 2018-07-31T00:49:44.890962: step 4263, loss 0.505351.
Train: 2018-07-31T00:49:45.031554: step 4264, loss 0.578947.
Train: 2018-07-31T00:49:45.172146: step 4265, loss 0.570765.
Train: 2018-07-31T00:49:45.312737: step 4266, loss 0.595307.
Train: 2018-07-31T00:49:45.453330: step 4267, loss 0.570766.
Train: 2018-07-31T00:49:45.609544: step 4268, loss 0.529951.
Train: 2018-07-31T00:49:45.750137: step 4269, loss 0.611585.
Train: 2018-07-31T00:49:45.890729: step 4270, loss 0.595231.
Test: 2018-07-31T00:49:46.125049: step 4270, loss 0.549016.
Train: 2018-07-31T00:49:46.265665: step 4271, loss 0.562644.
Train: 2018-07-31T00:49:46.421854: step 4272, loss 0.562662.
Train: 2018-07-31T00:49:46.578066: step 4273, loss 0.514023.
Train: 2018-07-31T00:49:46.718661: step 4274, loss 0.5789.
Train: 2018-07-31T00:49:46.874873: step 4275, loss 0.595103.
Train: 2018-07-31T00:49:47.015463: step 4276, loss 0.514142.
Train: 2018-07-31T00:49:47.156074: step 4277, loss 0.586993.
Train: 2018-07-31T00:49:47.312270: step 4278, loss 0.5627.
Train: 2018-07-31T00:49:47.452886: step 4279, loss 0.635516.
Train: 2018-07-31T00:49:47.609076: step 4280, loss 0.55467.
Test: 2018-07-31T00:49:47.843397: step 4280, loss 0.549261.
Train: 2018-07-31T00:49:47.983988: step 4281, loss 0.570819.
Train: 2018-07-31T00:49:48.140201: step 4282, loss 0.570829.
Train: 2018-07-31T00:49:48.280819: step 4283, loss 0.570843.
Train: 2018-07-31T00:49:48.421386: step 4284, loss 0.49864.
Train: 2018-07-31T00:49:48.562002: step 4285, loss 0.554806.
Train: 2018-07-31T00:49:48.718190: step 4286, loss 0.538722.
Train: 2018-07-31T00:49:48.858783: step 4287, loss 0.538674.
Train: 2018-07-31T00:49:48.999374: step 4288, loss 0.586931.
Train: 2018-07-31T00:49:49.139991: step 4289, loss 0.522465.
Train: 2018-07-31T00:49:49.280583: step 4290, loss 0.522366.
Test: 2018-07-31T00:49:49.514880: step 4290, loss 0.549139.
Train: 2018-07-31T00:49:49.671110: step 4291, loss 0.562691.
Train: 2018-07-31T00:49:49.811710: step 4292, loss 0.522085.
Train: 2018-07-31T00:49:49.952302: step 4293, loss 0.530066.
Train: 2018-07-31T00:49:50.108491: step 4294, loss 0.529892.
Train: 2018-07-31T00:49:50.249082: step 4295, loss 0.587178.
Train: 2018-07-31T00:49:50.389674: step 4296, loss 0.611945.
Train: 2018-07-31T00:49:50.561510: step 4297, loss 0.504796.
Train: 2018-07-31T00:49:50.698029: step 4298, loss 0.570749.
Train: 2018-07-31T00:49:50.854217: step 4299, loss 0.587328.
Train: 2018-07-31T00:49:51.010469: step 4300, loss 0.504419.
Test: 2018-07-31T00:49:51.244779: step 4300, loss 0.548523.
Train: 2018-07-31T00:49:52.041464: step 4301, loss 0.620649.
Train: 2018-07-31T00:49:52.182056: step 4302, loss 0.604022.
Train: 2018-07-31T00:49:52.338263: step 4303, loss 0.520868.
Train: 2018-07-31T00:49:52.478862: step 4304, loss 0.554142.
Train: 2018-07-31T00:49:52.619455: step 4305, loss 0.587418.
Train: 2018-07-31T00:49:52.775666: step 4306, loss 0.520839.
Train: 2018-07-31T00:49:52.931857: step 4307, loss 0.495822.
Train: 2018-07-31T00:49:53.088069: step 4308, loss 0.545741.
Train: 2018-07-31T00:49:53.228661: step 4309, loss 0.487166.
Train: 2018-07-31T00:49:53.384882: step 4310, loss 0.537237.
Test: 2018-07-31T00:49:53.634818: step 4310, loss 0.54828.
Train: 2018-07-31T00:49:53.775433: step 4311, loss 0.553993.
Train: 2018-07-31T00:49:53.916026: step 4312, loss 0.58765.
Train: 2018-07-31T00:49:54.072215: step 4313, loss 0.494658.
Train: 2018-07-31T00:49:54.212806: step 4314, loss 0.579356.
Train: 2018-07-31T00:49:54.353416: step 4315, loss 0.587909.
Train: 2018-07-31T00:49:54.493990: step 4316, loss 0.596402.
Train: 2018-07-31T00:49:54.650227: step 4317, loss 0.519754.
Train: 2018-07-31T00:49:54.790796: step 4318, loss 0.519698.
Train: 2018-07-31T00:49:54.931387: step 4319, loss 0.519658.
Train: 2018-07-31T00:49:55.087602: step 4320, loss 0.553815.
Test: 2018-07-31T00:49:55.321953: step 4320, loss 0.547978.
Train: 2018-07-31T00:49:55.478152: step 4321, loss 0.648065.
Train: 2018-07-31T00:49:55.634349: step 4322, loss 0.605189.
Train: 2018-07-31T00:49:55.774998: step 4323, loss 0.545242.
Train: 2018-07-31T00:49:55.931155: step 4324, loss 0.656232.
Train: 2018-07-31T00:49:56.071745: step 4325, loss 0.570848.
Train: 2018-07-31T00:49:56.212337: step 4326, loss 0.613214.
Train: 2018-07-31T00:49:56.352930: step 4327, loss 0.579245.
Train: 2018-07-31T00:49:56.493523: step 4328, loss 0.587589.
Train: 2018-07-31T00:49:56.634143: step 4329, loss 0.629296.
Train: 2018-07-31T00:49:56.790328: step 4330, loss 0.545827.
Test: 2018-07-31T00:49:57.024675: step 4330, loss 0.54864.
Train: 2018-07-31T00:49:57.165240: step 4331, loss 0.512876.
Train: 2018-07-31T00:49:57.305832: step 4332, loss 0.587235.
Train: 2018-07-31T00:49:57.462045: step 4333, loss 0.578968.
Train: 2018-07-31T00:49:57.618260: step 4334, loss 0.521713.
Train: 2018-07-31T00:49:57.758851: step 4335, loss 0.578929.
Train: 2018-07-31T00:49:57.899461: step 4336, loss 0.538251.
Train: 2018-07-31T00:49:58.040035: step 4337, loss 0.505847.
Train: 2018-07-31T00:49:58.180651: step 4338, loss 0.578904.
Train: 2018-07-31T00:49:58.321244: step 4339, loss 0.62756.
Train: 2018-07-31T00:49:58.461812: step 4340, loss 0.530334.
Test: 2018-07-31T00:49:58.711753: step 4340, loss 0.54918.
Train: 2018-07-31T00:49:58.852369: step 4341, loss 0.473792.
Train: 2018-07-31T00:49:59.008558: step 4342, loss 0.522232.
Train: 2018-07-31T00:49:59.164772: step 4343, loss 0.530235.
Train: 2018-07-31T00:49:59.305363: step 4344, loss 0.562634.
Train: 2018-07-31T00:49:59.445971: step 4345, loss 0.554417.
Train: 2018-07-31T00:49:59.586572: step 4346, loss 0.554421.
Train: 2018-07-31T00:49:59.742761: step 4347, loss 0.529523.
Train: 2018-07-31T00:49:59.883378: step 4348, loss 0.62891.
Train: 2018-07-31T00:50:00.023945: step 4349, loss 0.603172.
Train: 2018-07-31T00:50:00.180158: step 4350, loss 0.562173.
Test: 2018-07-31T00:50:00.414479: step 4350, loss 0.548575.
Train: 2018-07-31T00:50:00.586338: step 4351, loss 0.579452.
Train: 2018-07-31T00:50:00.742527: step 4352, loss 0.620654.
Train: 2018-07-31T00:50:00.883141: step 4353, loss 0.636641.
Train: 2018-07-31T00:50:01.023711: step 4354, loss 0.570842.
Train: 2018-07-31T00:50:01.195547: step 4355, loss 0.521866.
Train: 2018-07-31T00:50:01.351760: step 4356, loss 0.538305.
Train: 2018-07-31T00:50:01.476729: step 4357, loss 0.546477.
Train: 2018-07-31T00:50:01.617322: step 4358, loss 0.530301.
Train: 2018-07-31T00:50:01.773560: step 4359, loss 0.554597.
Train: 2018-07-31T00:50:01.914127: step 4360, loss 0.603204.
Test: 2018-07-31T00:50:02.164115: step 4360, loss 0.549141.
Train: 2018-07-31T00:50:02.304685: step 4361, loss 0.586992.
Train: 2018-07-31T00:50:02.460875: step 4362, loss 0.61933.
Train: 2018-07-31T00:50:02.601491: step 4363, loss 0.586952.
Train: 2018-07-31T00:50:02.742058: step 4364, loss 0.619116.
Train: 2018-07-31T00:50:02.882651: step 4365, loss 0.530755.
Train: 2018-07-31T00:50:03.038889: step 4366, loss 0.578865.
Train: 2018-07-31T00:50:03.179456: step 4367, loss 0.554921.
Train: 2018-07-31T00:50:03.320047: step 4368, loss 0.523106.
Train: 2018-07-31T00:50:03.460656: step 4369, loss 0.642537.
Train: 2018-07-31T00:50:03.601232: step 4370, loss 0.570917.
Test: 2018-07-31T00:50:03.835554: step 4370, loss 0.549744.
Train: 2018-07-31T00:50:03.991767: step 4371, loss 0.578859.
Train: 2018-07-31T00:50:04.132359: step 4372, loss 0.555145.
Train: 2018-07-31T00:50:04.288596: step 4373, loss 0.53151.
Train: 2018-07-31T00:50:04.429164: step 4374, loss 0.602529.
Train: 2018-07-31T00:50:04.585377: step 4375, loss 0.539472.
Train: 2018-07-31T00:50:04.725969: step 4376, loss 0.539472.
Train: 2018-07-31T00:50:04.866562: step 4377, loss 0.507943.
Train: 2018-07-31T00:50:05.007153: step 4378, loss 0.578852.
Train: 2018-07-31T00:50:05.147746: step 4379, loss 0.613537.
Train: 2018-07-31T00:50:05.288337: step 4380, loss 0.539189.
Test: 2018-07-31T00:50:05.538280: step 4380, loss 0.549599.
Train: 2018-07-31T00:50:05.678896: step 4381, loss 0.554787.
Train: 2018-07-31T00:50:05.819489: step 4382, loss 0.506837.
Train: 2018-07-31T00:50:05.975677: step 4383, loss 0.530112.
Train: 2018-07-31T00:50:06.116270: step 4384, loss 0.569282.
Train: 2018-07-31T00:50:06.256880: step 4385, loss 0.589013.
Train: 2018-07-31T00:50:06.397478: step 4386, loss 0.521984.
Train: 2018-07-31T00:50:06.538070: step 4387, loss 0.51361.
Train: 2018-07-31T00:50:06.678661: step 4388, loss 0.59647.
Train: 2018-07-31T00:50:06.819229: step 4389, loss 0.579223.
Train: 2018-07-31T00:50:06.975443: step 4390, loss 0.445209.
Test: 2018-07-31T00:50:07.209765: step 4390, loss 0.548164.
Train: 2018-07-31T00:50:07.350373: step 4391, loss 0.556808.
Train: 2018-07-31T00:50:07.490971: step 4392, loss 0.45084.
Train: 2018-07-31T00:50:07.631563: step 4393, loss 0.521028.
Train: 2018-07-31T00:50:07.787752: step 4394, loss 0.526844.
Train: 2018-07-31T00:50:07.943965: step 4395, loss 0.680761.
Train: 2018-07-31T00:50:08.084559: step 4396, loss 0.517578.
Train: 2018-07-31T00:50:08.225151: step 4397, loss 0.582399.
Train: 2018-07-31T00:50:08.365742: step 4398, loss 0.590012.
Train: 2018-07-31T00:50:08.506358: step 4399, loss 0.633609.
Train: 2018-07-31T00:50:08.662572: step 4400, loss 0.519136.
Test: 2018-07-31T00:50:08.896896: step 4400, loss 0.54804.
Train: 2018-07-31T00:50:09.740419: step 4401, loss 0.536869.
Train: 2018-07-31T00:50:09.881011: step 4402, loss 0.586948.
Train: 2018-07-31T00:50:10.021604: step 4403, loss 0.494572.
Train: 2018-07-31T00:50:10.162197: step 4404, loss 0.604164.
Train: 2018-07-31T00:50:10.302790: step 4405, loss 0.595913.
Train: 2018-07-31T00:50:10.443382: step 4406, loss 0.603823.
Train: 2018-07-31T00:50:10.583973: step 4407, loss 0.54643.
Train: 2018-07-31T00:50:10.724582: step 4408, loss 0.529679.
Train: 2018-07-31T00:50:10.880795: step 4409, loss 0.620076.
Train: 2018-07-31T00:50:11.021401: step 4410, loss 0.513593.
Test: 2018-07-31T00:50:11.271347: step 4410, loss 0.548874.
Train: 2018-07-31T00:50:11.427524: step 4411, loss 0.627938.
Train: 2018-07-31T00:50:11.568117: step 4412, loss 0.570813.
Train: 2018-07-31T00:50:11.708709: step 4413, loss 0.570797.
Train: 2018-07-31T00:50:11.864923: step 4414, loss 0.538373.
Train: 2018-07-31T00:50:12.005516: step 4415, loss 0.578887.
Train: 2018-07-31T00:50:12.146107: step 4416, loss 0.595026.
Train: 2018-07-31T00:50:12.302320: step 4417, loss 0.586927.
Train: 2018-07-31T00:50:12.442937: step 4418, loss 0.619006.
Train: 2018-07-31T00:50:12.583503: step 4419, loss 0.594861.
Train: 2018-07-31T00:50:12.755338: step 4420, loss 0.562923.
Test: 2018-07-31T00:50:12.989689: step 4420, loss 0.549676.
Train: 2018-07-31T00:50:13.130269: step 4421, loss 0.555036.
Train: 2018-07-31T00:50:13.286464: step 4422, loss 0.594699.
Train: 2018-07-31T00:50:13.427057: step 4423, loss 0.492009.
Train: 2018-07-31T00:50:13.567648: step 4424, loss 0.563085.
Train: 2018-07-31T00:50:13.708241: step 4425, loss 0.523672.
Train: 2018-07-31T00:50:13.848857: step 4426, loss 0.531528.
Train: 2018-07-31T00:50:13.989426: step 4427, loss 0.499836.
Train: 2018-07-31T00:50:14.130018: step 4428, loss 0.594722.
Train: 2018-07-31T00:50:14.270610: step 4429, loss 0.570928.
Train: 2018-07-31T00:50:14.426822: step 4430, loss 0.547036.
Test: 2018-07-31T00:50:14.661167: step 4430, loss 0.54955.
Train: 2018-07-31T00:50:14.817355: step 4431, loss 0.562895.
Train: 2018-07-31T00:50:14.957948: step 4432, loss 0.466917.
Train: 2018-07-31T00:50:15.098566: step 4433, loss 0.619027.
Train: 2018-07-31T00:50:15.239149: step 4434, loss 0.514241.
Train: 2018-07-31T00:50:15.395347: step 4435, loss 0.522078.
Train: 2018-07-31T00:50:15.535938: step 4436, loss 0.496545.
Train: 2018-07-31T00:50:15.692153: step 4437, loss 0.556627.
Train: 2018-07-31T00:50:15.848388: step 4438, loss 0.536934.
Train: 2018-07-31T00:50:16.004579: step 4439, loss 0.605044.
Train: 2018-07-31T00:50:16.145194: step 4440, loss 0.586966.
Test: 2018-07-31T00:50:16.395135: step 4440, loss 0.548154.
Train: 2018-07-31T00:50:16.551325: step 4441, loss 0.527809.
Train: 2018-07-31T00:50:16.691916: step 4442, loss 0.647824.
Train: 2018-07-31T00:50:16.832534: step 4443, loss 0.503675.
Train: 2018-07-31T00:50:16.988724: step 4444, loss 0.537234.
Train: 2018-07-31T00:50:17.129315: step 4445, loss 0.537249.
Train: 2018-07-31T00:50:17.269932: step 4446, loss 0.462233.
Train: 2018-07-31T00:50:17.426119: step 4447, loss 0.51092.
Train: 2018-07-31T00:50:17.566729: step 4448, loss 0.595676.
Train: 2018-07-31T00:50:17.707331: step 4449, loss 0.613331.
Train: 2018-07-31T00:50:17.847896: step 4450, loss 0.58909.
Test: 2018-07-31T00:50:18.097839: step 4450, loss 0.548042.
Train: 2018-07-31T00:50:18.238441: step 4451, loss 0.501962.
Train: 2018-07-31T00:50:18.379023: step 4452, loss 0.587874.
Train: 2018-07-31T00:50:18.519614: step 4453, loss 0.578196.
Train: 2018-07-31T00:50:18.675829: step 4454, loss 0.502711.
Train: 2018-07-31T00:50:18.816421: step 4455, loss 0.613127.
Train: 2018-07-31T00:50:18.957027: step 4456, loss 0.664081.
Train: 2018-07-31T00:50:19.113249: step 4457, loss 0.57019.
Train: 2018-07-31T00:50:19.253818: step 4458, loss 0.57954.
Train: 2018-07-31T00:50:19.394409: step 4459, loss 0.587661.
Train: 2018-07-31T00:50:19.535001: step 4460, loss 0.621193.
Test: 2018-07-31T00:50:19.769353: step 4460, loss 0.548402.
Train: 2018-07-31T00:50:19.925536: step 4461, loss 0.562764.
Train: 2018-07-31T00:50:20.066127: step 4462, loss 0.604351.
Train: 2018-07-31T00:50:20.206719: step 4463, loss 0.57103.
Train: 2018-07-31T00:50:20.347311: step 4464, loss 0.570968.
Train: 2018-07-31T00:50:20.487927: step 4465, loss 0.595207.
Train: 2018-07-31T00:50:20.628497: step 4466, loss 0.595051.
Train: 2018-07-31T00:50:20.769111: step 4467, loss 0.627036.
Train: 2018-07-31T00:50:20.925300: step 4468, loss 0.610776.
Train: 2018-07-31T00:50:21.081539: step 4469, loss 0.547152.
Train: 2018-07-31T00:50:21.237729: step 4470, loss 0.570981.
Test: 2018-07-31T00:50:21.472079: step 4470, loss 0.550044.
Train: 2018-07-31T00:50:21.612640: step 4471, loss 0.523957.
Train: 2018-07-31T00:50:21.784475: step 4472, loss 0.555424.
Train: 2018-07-31T00:50:21.925091: step 4473, loss 0.610092.
Train: 2018-07-31T00:50:22.065660: step 4474, loss 0.516705.
Train: 2018-07-31T00:50:22.206262: step 4475, loss 0.571147.
Train: 2018-07-31T00:50:22.346843: step 4476, loss 0.586675.
Train: 2018-07-31T00:50:22.503056: step 4477, loss 0.532471.
Train: 2018-07-31T00:50:22.643650: step 4478, loss 0.547964.
Train: 2018-07-31T00:50:22.784241: step 4479, loss 0.509221.
Train: 2018-07-31T00:50:22.940456: step 4480, loss 0.516833.
Test: 2018-07-31T00:50:23.174810: step 4480, loss 0.550278.
Train: 2018-07-31T00:50:23.330987: step 4481, loss 0.563328.
Train: 2018-07-31T00:50:23.471604: step 4482, loss 0.578902.
Train: 2018-07-31T00:50:23.612196: step 4483, loss 0.571093.
Train: 2018-07-31T00:50:23.752763: step 4484, loss 0.547448.
Train: 2018-07-31T00:50:23.908977: step 4485, loss 0.570997.
Train: 2018-07-31T00:50:24.049571: step 4486, loss 0.53149.
Train: 2018-07-31T00:50:24.190160: step 4487, loss 0.539273.
Train: 2018-07-31T00:50:24.330753: step 4488, loss 0.547064.
Train: 2018-07-31T00:50:24.471380: step 4489, loss 0.578854.
Train: 2018-07-31T00:50:24.611936: step 4490, loss 0.650921.
Test: 2018-07-31T00:50:24.861880: step 4490, loss 0.549422.
Train: 2018-07-31T00:50:25.002472: step 4491, loss 0.538749.
Train: 2018-07-31T00:50:25.143088: step 4492, loss 0.570835.
Train: 2018-07-31T00:50:25.283679: step 4493, loss 0.570834.
Train: 2018-07-31T00:50:25.439869: step 4494, loss 0.514523.
Train: 2018-07-31T00:50:25.580485: step 4495, loss 0.546731.
Train: 2018-07-31T00:50:25.736699: step 4496, loss 0.562623.
Train: 2018-07-31T00:50:25.861644: step 4497, loss 0.5545.
Train: 2018-07-31T00:50:26.017859: step 4498, loss 0.505389.
Train: 2018-07-31T00:50:26.174072: step 4499, loss 0.595314.
Train: 2018-07-31T00:50:26.314665: step 4500, loss 0.571358.
Test: 2018-07-31T00:50:26.549011: step 4500, loss 0.548609.
Train: 2018-07-31T00:50:27.330050: step 4501, loss 0.60372.
Train: 2018-07-31T00:50:27.486265: step 4502, loss 0.489364.
Train: 2018-07-31T00:50:27.626858: step 4503, loss 0.528829.
Train: 2018-07-31T00:50:27.767473: step 4504, loss 0.546056.
Train: 2018-07-31T00:50:27.923686: step 4505, loss 0.562619.
Train: 2018-07-31T00:50:28.079900: step 4506, loss 0.562676.
Train: 2018-07-31T00:50:28.236090: step 4507, loss 0.612905.
Train: 2018-07-31T00:50:28.376682: step 4508, loss 0.587904.
Train: 2018-07-31T00:50:28.517297: step 4509, loss 0.512888.
Train: 2018-07-31T00:50:28.657882: step 4510, loss 0.570849.
Test: 2018-07-31T00:50:28.907806: step 4510, loss 0.548646.
Train: 2018-07-31T00:50:29.048399: step 4511, loss 0.529388.
Train: 2018-07-31T00:50:29.188991: step 4512, loss 0.595606.
Train: 2018-07-31T00:50:29.329581: step 4513, loss 0.620354.
Train: 2018-07-31T00:50:29.485796: step 4514, loss 0.562499.
Train: 2018-07-31T00:50:29.626415: step 4515, loss 0.570753.
Train: 2018-07-31T00:50:29.782603: step 4516, loss 0.53781.
Train: 2018-07-31T00:50:29.923194: step 4517, loss 0.529616.
Train: 2018-07-31T00:50:30.063785: step 4518, loss 0.562525.
Train: 2018-07-31T00:50:30.220000: step 4519, loss 0.620141.
Train: 2018-07-31T00:50:30.376250: step 4520, loss 0.562529.
Test: 2018-07-31T00:50:30.610533: step 4520, loss 0.548797.
Train: 2018-07-31T00:50:30.766748: step 4521, loss 0.562548.
Train: 2018-07-31T00:50:30.907338: step 4522, loss 0.595372.
Train: 2018-07-31T00:50:31.047931: step 4523, loss 0.562581.
Train: 2018-07-31T00:50:31.188522: step 4524, loss 0.521721.
Train: 2018-07-31T00:50:31.329138: step 4525, loss 0.603427.
Train: 2018-07-31T00:50:31.485329: step 4526, loss 0.603416.
Train: 2018-07-31T00:50:31.625921: step 4527, loss 0.562652.
Train: 2018-07-31T00:50:31.766537: step 4528, loss 0.587052.
Train: 2018-07-31T00:50:31.922749: step 4529, loss 0.58699.
Train: 2018-07-31T00:50:32.063342: step 4530, loss 0.57996.
Test: 2018-07-31T00:50:32.313283: step 4530, loss 0.549269.
Train: 2018-07-31T00:50:32.453852: step 4531, loss 0.530524.
Train: 2018-07-31T00:50:32.594442: step 4532, loss 0.627137.
Train: 2018-07-31T00:50:32.750657: step 4533, loss 0.578864.
Train: 2018-07-31T00:50:32.891288: step 4534, loss 0.4989.
Train: 2018-07-31T00:50:33.047486: step 4535, loss 0.570885.
Train: 2018-07-31T00:50:33.203676: step 4536, loss 0.491084.
Train: 2018-07-31T00:50:33.344268: step 4537, loss 0.538931.
Train: 2018-07-31T00:50:33.469264: step 4538, loss 0.498869.
Train: 2018-07-31T00:50:33.609830: step 4539, loss 0.562818.
Train: 2018-07-31T00:50:33.766043: step 4540, loss 0.546685.
Test: 2018-07-31T00:50:34.000391: step 4540, loss 0.549228.
Train: 2018-07-31T00:50:34.140980: step 4541, loss 0.595022.
Train: 2018-07-31T00:50:34.297196: step 4542, loss 0.554626.
Train: 2018-07-31T00:50:34.422165: step 4543, loss 0.595058.
Train: 2018-07-31T00:50:34.562756: step 4544, loss 0.578953.
Train: 2018-07-31T00:50:34.718946: step 4545, loss 0.595113.
Train: 2018-07-31T00:50:34.859583: step 4546, loss 0.55457.
Train: 2018-07-31T00:50:35.000129: step 4547, loss 0.554545.
Train: 2018-07-31T00:50:35.140722: step 4548, loss 0.635794.
Train: 2018-07-31T00:50:35.281354: step 4549, loss 0.570807.
Train: 2018-07-31T00:50:35.437529: step 4550, loss 0.587019.
Test: 2018-07-31T00:50:35.671878: step 4550, loss 0.549205.
Train: 2018-07-31T00:50:35.812441: step 4551, loss 0.57888.
Train: 2018-07-31T00:50:35.984274: step 4552, loss 0.498276.
Train: 2018-07-31T00:50:36.109270: step 4553, loss 0.538572.
Train: 2018-07-31T00:50:36.265459: step 4554, loss 0.586934.
Train: 2018-07-31T00:50:36.406051: step 4555, loss 0.554712.
Train: 2018-07-31T00:50:36.546643: step 4556, loss 0.578877.
Train: 2018-07-31T00:50:36.687234: step 4557, loss 0.546656.
Train: 2018-07-31T00:50:36.827826: step 4558, loss 0.522461.
Train: 2018-07-31T00:50:36.984041: step 4559, loss 0.546598.
Train: 2018-07-31T00:50:37.124658: step 4560, loss 0.611228.
Test: 2018-07-31T00:50:37.374574: step 4560, loss 0.549176.
Train: 2018-07-31T00:50:37.515183: step 4561, loss 0.619309.
Train: 2018-07-31T00:50:37.655783: step 4562, loss 0.586966.
Train: 2018-07-31T00:50:37.796349: step 4563, loss 0.635335.
Train: 2018-07-31T00:50:37.952564: step 4564, loss 0.546709.
Train: 2018-07-31T00:50:38.093200: step 4565, loss 0.53073.
Train: 2018-07-31T00:50:38.233772: step 4566, loss 0.570858.
Train: 2018-07-31T00:50:38.374339: step 4567, loss 0.602862.
Train: 2018-07-31T00:50:38.530577: step 4568, loss 0.522948.
Train: 2018-07-31T00:50:38.686767: step 4569, loss 0.546921.
Train: 2018-07-31T00:50:38.827358: step 4570, loss 0.570879.
Test: 2018-07-31T00:50:39.061678: step 4570, loss 0.549529.
Train: 2018-07-31T00:50:39.202270: step 4571, loss 0.515012.
Train: 2018-07-31T00:50:39.358484: step 4572, loss 0.626805.
Train: 2018-07-31T00:50:39.499085: step 4573, loss 0.650741.
Train: 2018-07-31T00:50:39.639669: step 4574, loss 0.586833.
Train: 2018-07-31T00:50:39.780285: step 4575, loss 0.586812.
Train: 2018-07-31T00:50:39.936473: step 4576, loss 0.539231.
Train: 2018-07-31T00:50:40.077065: step 4577, loss 0.523492.
Train: 2018-07-31T00:50:40.233279: step 4578, loss 0.618399.
Train: 2018-07-31T00:50:40.358277: step 4579, loss 0.547289.
Train: 2018-07-31T00:50:40.514463: step 4580, loss 0.570976.
Test: 2018-07-31T00:50:40.764406: step 4580, loss 0.549912.
Train: 2018-07-31T00:50:40.904998: step 4581, loss 0.570986.
Train: 2018-07-31T00:50:41.045591: step 4582, loss 0.578867.
Train: 2018-07-31T00:50:41.186181: step 4583, loss 0.571004.
Train: 2018-07-31T00:50:41.326774: step 4584, loss 0.563152.
Train: 2018-07-31T00:50:41.467364: step 4585, loss 0.578872.
Train: 2018-07-31T00:50:41.607957: step 4586, loss 0.555327.
Train: 2018-07-31T00:50:41.748574: step 4587, loss 0.523943.
Train: 2018-07-31T00:50:41.904763: step 4588, loss 0.476759.
Train: 2018-07-31T00:50:42.029758: step 4589, loss 0.547344.
Train: 2018-07-31T00:50:42.185947: step 4590, loss 0.54723.
Test: 2018-07-31T00:50:42.435888: step 4590, loss 0.549693.
Train: 2018-07-31T00:50:42.576482: step 4591, loss 0.547112.
Train: 2018-07-31T00:50:42.732695: step 4592, loss 0.570891.
Train: 2018-07-31T00:50:42.873287: step 4593, loss 0.562876.
Train: 2018-07-31T00:50:43.013902: step 4594, loss 0.586885.
Train: 2018-07-31T00:50:43.170092: step 4595, loss 0.546723.
Train: 2018-07-31T00:50:43.310684: step 4596, loss 0.522472.
Train: 2018-07-31T00:50:43.451277: step 4597, loss 0.570794.
Train: 2018-07-31T00:50:43.591869: step 4598, loss 0.522138.
Train: 2018-07-31T00:50:43.732461: step 4599, loss 0.538236.
Train: 2018-07-31T00:50:43.873052: step 4600, loss 0.488993.
Test: 2018-07-31T00:50:44.107404: step 4600, loss 0.548727.
Train: 2018-07-31T00:50:44.872836: step 4601, loss 0.595555.
Train: 2018-07-31T00:50:45.013410: step 4602, loss 0.521365.
Train: 2018-07-31T00:50:45.154002: step 4603, loss 0.529302.
Train: 2018-07-31T00:50:45.310216: step 4604, loss 0.595805.
Train: 2018-07-31T00:50:45.450808: step 4605, loss 0.520602.
Train: 2018-07-31T00:50:45.591400: step 4606, loss 0.554097.
Train: 2018-07-31T00:50:45.731991: step 4607, loss 0.587487.
Train: 2018-07-31T00:50:45.872583: step 4608, loss 0.604489.
Train: 2018-07-31T00:50:46.028797: step 4609, loss 0.570822.
Train: 2018-07-31T00:50:46.169389: step 4610, loss 0.520195.
Test: 2018-07-31T00:50:46.419330: step 4610, loss 0.548233.
Train: 2018-07-31T00:50:46.559922: step 4611, loss 0.570794.
Train: 2018-07-31T00:50:46.700515: step 4612, loss 0.596154.
Train: 2018-07-31T00:50:46.841105: step 4613, loss 0.613063.
Train: 2018-07-31T00:50:46.981723: step 4614, loss 0.663445.
Train: 2018-07-31T00:50:47.137914: step 4615, loss 0.570782.
Train: 2018-07-31T00:50:47.278504: step 4616, loss 0.537335.
Train: 2018-07-31T00:50:47.434718: step 4617, loss 0.554095.
Train: 2018-07-31T00:50:47.575311: step 4618, loss 0.554133.
Train: 2018-07-31T00:50:47.731524: step 4619, loss 0.496105.
Train: 2018-07-31T00:50:47.872139: step 4620, loss 0.579048.
Test: 2018-07-31T00:50:48.122058: step 4620, loss 0.548606.
Train: 2018-07-31T00:50:48.278295: step 4621, loss 0.545912.
Train: 2018-07-31T00:50:48.434493: step 4622, loss 0.612139.
Train: 2018-07-31T00:50:48.575077: step 4623, loss 0.521184.
Train: 2018-07-31T00:50:48.715669: step 4624, loss 0.545988.
Train: 2018-07-31T00:50:48.856261: step 4625, loss 0.51298.
Train: 2018-07-31T00:50:48.996877: step 4626, loss 0.579018.
Train: 2018-07-31T00:50:49.137454: step 4627, loss 0.554229.
Train: 2018-07-31T00:50:49.293659: step 4628, loss 0.612082.
Train: 2018-07-31T00:50:49.434251: step 4629, loss 0.595531.
Train: 2018-07-31T00:50:49.574868: step 4630, loss 0.603734.
Test: 2018-07-31T00:50:49.824814: step 4630, loss 0.548761.
Train: 2018-07-31T00:50:49.981021: step 4631, loss 0.554309.
Train: 2018-07-31T00:50:50.121613: step 4632, loss 0.546137.
Train: 2018-07-31T00:50:50.262180: step 4633, loss 0.628125.
Train: 2018-07-31T00:50:50.402772: step 4634, loss 0.595257.
Train: 2018-07-31T00:50:50.543365: step 4635, loss 0.546312.
Train: 2018-07-31T00:50:50.699580: step 4636, loss 0.587009.
Train: 2018-07-31T00:50:50.840170: step 4637, loss 0.562974.
Train: 2018-07-31T00:50:50.980763: step 4638, loss 0.578992.
Train: 2018-07-31T00:50:51.121356: step 4639, loss 0.498339.
Train: 2018-07-31T00:50:51.261947: step 4640, loss 0.562764.
Test: 2018-07-31T00:50:51.511887: step 4640, loss 0.549306.
Train: 2018-07-31T00:50:51.652479: step 4641, loss 0.578884.
Train: 2018-07-31T00:50:51.808693: step 4642, loss 0.506528.
Train: 2018-07-31T00:50:51.949287: step 4643, loss 0.586918.
Train: 2018-07-31T00:50:52.105499: step 4644, loss 0.562773.
Train: 2018-07-31T00:50:52.246093: step 4645, loss 0.522548.
Train: 2018-07-31T00:50:52.386684: step 4646, loss 0.675578.
Train: 2018-07-31T00:50:52.527275: step 4647, loss 0.554754.
Train: 2018-07-31T00:50:52.683509: step 4648, loss 0.546705.
Train: 2018-07-31T00:50:52.824105: step 4649, loss 0.578835.
Train: 2018-07-31T00:50:52.964691: step 4650, loss 0.635033.
Test: 2018-07-31T00:50:53.214614: step 4650, loss 0.549454.
Train: 2018-07-31T00:50:53.355206: step 4651, loss 0.522833.
Train: 2018-07-31T00:50:53.511420: step 4652, loss 0.570938.
Train: 2018-07-31T00:50:53.636390: step 4653, loss 0.602749.
Train: 2018-07-31T00:50:53.792605: step 4654, loss 0.610727.
Train: 2018-07-31T00:50:53.933222: step 4655, loss 0.523223.
Train: 2018-07-31T00:50:54.089409: step 4656, loss 0.578878.
Train: 2018-07-31T00:50:54.230001: step 4657, loss 0.555038.
Train: 2018-07-31T00:50:54.370618: step 4658, loss 0.578907.
Train: 2018-07-31T00:50:54.511204: step 4659, loss 0.547166.
Train: 2018-07-31T00:50:54.651777: step 4660, loss 0.499681.
Test: 2018-07-31T00:50:54.901749: step 4660, loss 0.549704.
Train: 2018-07-31T00:50:55.042325: step 4661, loss 0.547091.
Train: 2018-07-31T00:50:55.198549: step 4662, loss 0.562909.
Train: 2018-07-31T00:50:55.339141: step 4663, loss 0.571223.
Train: 2018-07-31T00:50:55.479727: step 4664, loss 0.587297.
Train: 2018-07-31T00:50:55.620301: step 4665, loss 0.618596.
Train: 2018-07-31T00:50:55.760892: step 4666, loss 0.490622.
Train: 2018-07-31T00:50:55.901484: step 4667, loss 0.538473.
Train: 2018-07-31T00:50:56.057723: step 4668, loss 0.554785.
Train: 2018-07-31T00:50:56.213913: step 4669, loss 0.539311.
Train: 2018-07-31T00:50:56.354529: step 4670, loss 0.521552.
Test: 2018-07-31T00:50:56.588856: step 4670, loss 0.548832.
Train: 2018-07-31T00:50:56.745038: step 4671, loss 0.547769.
Train: 2018-07-31T00:50:56.885629: step 4672, loss 0.554491.
Train: 2018-07-31T00:50:57.041844: step 4673, loss 0.529263.
Train: 2018-07-31T00:50:57.182448: step 4674, loss 0.537804.
Train: 2018-07-31T00:50:57.323028: step 4675, loss 0.528897.
Train: 2018-07-31T00:50:57.479241: step 4676, loss 0.588075.
Train: 2018-07-31T00:50:57.619833: step 4677, loss 0.511541.
Train: 2018-07-31T00:50:57.776047: step 4678, loss 0.552434.
Train: 2018-07-31T00:50:57.916663: step 4679, loss 0.579666.
Train: 2018-07-31T00:50:58.072853: step 4680, loss 0.52912.
Test: 2018-07-31T00:50:58.307203: step 4680, loss 0.547858.
Train: 2018-07-31T00:50:58.447789: step 4681, loss 0.473809.
Train: 2018-07-31T00:50:58.588356: step 4682, loss 0.579695.
Train: 2018-07-31T00:50:58.744569: step 4683, loss 0.65142.
Train: 2018-07-31T00:50:58.900784: step 4684, loss 0.626367.
Train: 2018-07-31T00:50:59.041375: step 4685, loss 0.572123.
Train: 2018-07-31T00:50:59.181992: step 4686, loss 0.545563.
Train: 2018-07-31T00:50:59.338206: step 4687, loss 0.554084.
Train: 2018-07-31T00:50:59.494394: step 4688, loss 0.50438.
Train: 2018-07-31T00:50:59.619365: step 4689, loss 0.520946.
Train: 2018-07-31T00:50:59.775577: step 4690, loss 0.537531.
Test: 2018-07-31T00:51:00.025521: step 4690, loss 0.548505.
Train: 2018-07-31T00:51:00.166158: step 4691, loss 0.637351.
Train: 2018-07-31T00:51:00.306728: step 4692, loss 0.562404.
Train: 2018-07-31T00:51:00.462917: step 4693, loss 0.562409.
Train: 2018-07-31T00:51:00.603533: step 4694, loss 0.595765.
Train: 2018-07-31T00:51:00.744100: step 4695, loss 0.562385.
Train: 2018-07-31T00:51:00.884694: step 4696, loss 0.554209.
Train: 2018-07-31T00:51:01.025306: step 4697, loss 0.578959.
Train: 2018-07-31T00:51:01.181500: step 4698, loss 0.579193.
Train: 2018-07-31T00:51:01.322092: step 4699, loss 0.545956.
Train: 2018-07-31T00:51:01.462682: step 4700, loss 0.513018.
Test: 2018-07-31T00:51:01.712644: step 4700, loss 0.548698.
Train: 2018-07-31T00:51:02.493709: step 4701, loss 0.504767.
Train: 2018-07-31T00:51:02.634284: step 4702, loss 0.554146.
Train: 2018-07-31T00:51:02.774900: step 4703, loss 0.496331.
Train: 2018-07-31T00:51:02.915469: step 4704, loss 0.537273.
Train: 2018-07-31T00:51:03.056060: step 4705, loss 0.521515.
Train: 2018-07-31T00:51:03.227897: step 4706, loss 0.562386.
Train: 2018-07-31T00:51:03.368503: step 4707, loss 0.545594.
Train: 2018-07-31T00:51:03.509078: step 4708, loss 0.579161.
Train: 2018-07-31T00:51:03.649670: step 4709, loss 0.528822.
Train: 2018-07-31T00:51:03.790263: step 4710, loss 0.571419.
Test: 2018-07-31T00:51:04.024618: step 4710, loss 0.548163.
Train: 2018-07-31T00:51:04.165175: step 4711, loss 0.570722.
Train: 2018-07-31T00:51:04.321390: step 4712, loss 0.57916.
Train: 2018-07-31T00:51:04.461981: step 4713, loss 0.579331.
Train: 2018-07-31T00:51:04.602597: step 4714, loss 0.604545.
Train: 2018-07-31T00:51:04.758786: step 4715, loss 0.553948.
Train: 2018-07-31T00:51:04.899378: step 4716, loss 0.587608.
Train: 2018-07-31T00:51:05.039970: step 4717, loss 0.587572.
Train: 2018-07-31T00:51:05.180587: step 4718, loss 0.562406.
Train: 2018-07-31T00:51:05.336777: step 4719, loss 0.528987.
Train: 2018-07-31T00:51:05.477369: step 4720, loss 0.562421.
Test: 2018-07-31T00:51:05.727310: step 4720, loss 0.548474.
Train: 2018-07-31T00:51:05.867901: step 4721, loss 0.637435.
Train: 2018-07-31T00:51:06.008518: step 4722, loss 0.529225.
Train: 2018-07-31T00:51:06.149086: step 4723, loss 0.645385.
Train: 2018-07-31T00:51:06.305298: step 4724, loss 0.537716.
Train: 2018-07-31T00:51:06.445891: step 4725, loss 0.653122.
Train: 2018-07-31T00:51:06.602106: step 4726, loss 0.537974.
Train: 2018-07-31T00:51:06.758318: step 4727, loss 0.513607.
Train: 2018-07-31T00:51:06.898910: step 4728, loss 0.61151.
Train: 2018-07-31T00:51:07.039503: step 4729, loss 0.554538.
Train: 2018-07-31T00:51:07.180093: step 4730, loss 0.570801.
Test: 2018-07-31T00:51:07.414445: step 4730, loss 0.549185.
Train: 2018-07-31T00:51:07.570627: step 4731, loss 0.53041.
Train: 2018-07-31T00:51:07.711244: step 4732, loss 0.578902.
Train: 2018-07-31T00:51:07.851812: step 4733, loss 0.55471.
Train: 2018-07-31T00:51:08.070545: step 4734, loss 0.522551.
Train: 2018-07-31T00:51:08.211103: step 4735, loss 0.611136.
Train: 2018-07-31T00:51:08.351695: step 4736, loss 0.602974.
Train: 2018-07-31T00:51:08.492286: step 4737, loss 0.626968.
Train: 2018-07-31T00:51:08.632880: step 4738, loss 0.506949.
Train: 2018-07-31T00:51:08.773471: step 4739, loss 0.618754.
Train: 2018-07-31T00:51:08.914065: step 4740, loss 0.5709.
Test: 2018-07-31T00:51:09.164035: step 4740, loss 0.549682.
Train: 2018-07-31T00:51:09.304597: step 4741, loss 0.626497.
Train: 2018-07-31T00:51:09.460810: step 4742, loss 0.555127.
Train: 2018-07-31T00:51:09.585805: step 4743, loss 0.499974.
Train: 2018-07-31T00:51:09.726398: step 4744, loss 0.539446.
Train: 2018-07-31T00:51:09.882587: step 4745, loss 0.515781.
Train: 2018-07-31T00:51:10.023179: step 4746, loss 0.515692.
Train: 2018-07-31T00:51:10.163790: step 4747, loss 0.563036.
Train: 2018-07-31T00:51:10.304386: step 4748, loss 0.570942.
Train: 2018-07-31T00:51:10.444955: step 4749, loss 0.570889.
Train: 2018-07-31T00:51:10.601178: step 4750, loss 0.555031.
Test: 2018-07-31T00:51:10.835488: step 4750, loss 0.549473.
Train: 2018-07-31T00:51:10.991703: step 4751, loss 0.602841.
Train: 2018-07-31T00:51:11.132318: step 4752, loss 0.490867.
Train: 2018-07-31T00:51:11.272885: step 4753, loss 0.610996.
Train: 2018-07-31T00:51:11.429099: step 4754, loss 0.586789.
Train: 2018-07-31T00:51:11.569716: step 4755, loss 0.546605.
Train: 2018-07-31T00:51:11.710307: step 4756, loss 0.554559.
Train: 2018-07-31T00:51:11.866498: step 4757, loss 0.579048.
Train: 2018-07-31T00:51:12.007113: step 4758, loss 0.57077.
Train: 2018-07-31T00:51:12.147682: step 4759, loss 0.6112.
Train: 2018-07-31T00:51:12.288273: step 4760, loss 0.570962.
Test: 2018-07-31T00:51:12.522627: step 4760, loss 0.549184.
Train: 2018-07-31T00:51:12.678824: step 4761, loss 0.587027.
Train: 2018-07-31T00:51:12.819400: step 4762, loss 0.562802.
Train: 2018-07-31T00:51:12.960026: step 4763, loss 0.514539.
Train: 2018-07-31T00:51:13.100584: step 4764, loss 0.594861.
Train: 2018-07-31T00:51:13.241174: step 4765, loss 0.546668.
Train: 2018-07-31T00:51:13.397389: step 4766, loss 0.570719.
Train: 2018-07-31T00:51:13.537981: step 4767, loss 0.522402.
Train: 2018-07-31T00:51:13.678572: step 4768, loss 0.538456.
Train: 2018-07-31T00:51:13.834785: step 4769, loss 0.546736.
Train: 2018-07-31T00:51:13.959757: step 4770, loss 0.545715.
Test: 2018-07-31T00:51:14.209699: step 4770, loss 0.548867.
Train: 2018-07-31T00:51:14.381533: step 4771, loss 0.529398.
Train: 2018-07-31T00:51:14.522124: step 4772, loss 0.57061.
Train: 2018-07-31T00:51:14.662734: step 4773, loss 0.521904.
Train: 2018-07-31T00:51:14.818930: step 4774, loss 0.596937.
Train: 2018-07-31T00:51:14.959522: step 4775, loss 0.615769.
Train: 2018-07-31T00:51:15.115761: step 4776, loss 0.562405.
Train: 2018-07-31T00:51:15.256328: step 4777, loss 0.561646.
Train: 2018-07-31T00:51:15.396921: step 4778, loss 0.471102.
Train: 2018-07-31T00:51:15.537512: step 4779, loss 0.512073.
Train: 2018-07-31T00:51:15.693725: step 4780, loss 0.529941.
Test: 2018-07-31T00:51:15.928076: step 4780, loss 0.54833.
Train: 2018-07-31T00:51:16.084259: step 4781, loss 0.595114.
Train: 2018-07-31T00:51:16.224852: step 4782, loss 0.562083.
Train: 2018-07-31T00:51:16.365444: step 4783, loss 0.604649.
Train: 2018-07-31T00:51:16.506059: step 4784, loss 0.511708.
Train: 2018-07-31T00:51:16.662248: step 4785, loss 0.604183.
Train: 2018-07-31T00:51:16.802866: step 4786, loss 0.536305.
Train: 2018-07-31T00:51:16.943432: step 4787, loss 0.614702.
Train: 2018-07-31T00:51:17.084053: step 4788, loss 0.470234.
Train: 2018-07-31T00:51:17.224618: step 4789, loss 0.520706.
Train: 2018-07-31T00:51:17.380855: step 4790, loss 0.57936.
Test: 2018-07-31T00:51:17.630772: step 4790, loss 0.548238.
Train: 2018-07-31T00:51:17.771388: step 4791, loss 0.588013.
Train: 2018-07-31T00:51:17.911980: step 4792, loss 0.578533.
Train: 2018-07-31T00:51:18.052565: step 4793, loss 0.51277.
Train: 2018-07-31T00:51:18.193165: step 4794, loss 0.629897.
Train: 2018-07-31T00:51:18.349378: step 4795, loss 0.537125.
Train: 2018-07-31T00:51:18.489947: step 4796, loss 0.562674.
Train: 2018-07-31T00:51:18.646159: step 4797, loss 0.521036.
Train: 2018-07-31T00:51:18.786775: step 4798, loss 0.562524.
Train: 2018-07-31T00:51:18.942982: step 4799, loss 0.595442.
Train: 2018-07-31T00:51:19.083556: step 4800, loss 0.529602.
Test: 2018-07-31T00:51:19.333529: step 4800, loss 0.54861.
Train: 2018-07-31T00:51:20.052080: step 4801, loss 0.521123.
Train: 2018-07-31T00:51:20.208294: step 4802, loss 0.529431.
Train: 2018-07-31T00:51:20.348910: step 4803, loss 0.545709.
Train: 2018-07-31T00:51:20.505099: step 4804, loss 0.612129.
Train: 2018-07-31T00:51:20.630100: step 4805, loss 0.512484.
Train: 2018-07-31T00:51:20.801905: step 4806, loss 0.570579.
Train: 2018-07-31T00:51:20.926900: step 4807, loss 0.571054.
Train: 2018-07-31T00:51:21.067466: step 4808, loss 0.587077.
Train: 2018-07-31T00:51:21.223679: step 4809, loss 0.56245.
Train: 2018-07-31T00:51:21.364273: step 4810, loss 0.53738.
Test: 2018-07-31T00:51:21.614215: step 4810, loss 0.548441.
Train: 2018-07-31T00:51:21.754806: step 4811, loss 0.537877.
Train: 2018-07-31T00:51:21.895398: step 4812, loss 0.587429.
Train: 2018-07-31T00:51:22.035991: step 4813, loss 0.612555.
Train: 2018-07-31T00:51:22.192205: step 4814, loss 0.545911.
Train: 2018-07-31T00:51:22.332795: step 4815, loss 0.545706.
Train: 2018-07-31T00:51:22.473414: step 4816, loss 0.520933.
Train: 2018-07-31T00:51:22.614005: step 4817, loss 0.57064.
Train: 2018-07-31T00:51:22.754597: step 4818, loss 0.620695.
Train: 2018-07-31T00:51:22.910831: step 4819, loss 0.546073.
Train: 2018-07-31T00:51:23.066999: step 4820, loss 0.496225.
Test: 2018-07-31T00:51:23.316968: step 4820, loss 0.54858.
Train: 2018-07-31T00:51:23.457533: step 4821, loss 0.562234.
Train: 2018-07-31T00:51:23.613746: step 4822, loss 0.578738.
Train: 2018-07-31T00:51:23.754362: step 4823, loss 0.546089.
Train: 2018-07-31T00:51:23.910558: step 4824, loss 0.545717.
Train: 2018-07-31T00:51:24.051143: step 4825, loss 0.554495.
Train: 2018-07-31T00:51:24.191735: step 4826, loss 0.5373.
Train: 2018-07-31T00:51:24.332327: step 4827, loss 0.604283.
Train: 2018-07-31T00:51:24.488558: step 4828, loss 0.562155.
Train: 2018-07-31T00:51:24.629132: step 4829, loss 0.645622.
Train: 2018-07-31T00:51:24.769726: step 4830, loss 0.5126.
Test: 2018-07-31T00:51:25.004074: step 4830, loss 0.548596.
Train: 2018-07-31T00:51:25.144636: step 4831, loss 0.546033.
Train: 2018-07-31T00:51:25.300875: step 4832, loss 0.668544.
Train: 2018-07-31T00:51:25.441442: step 4833, loss 0.537575.
Train: 2018-07-31T00:51:25.582034: step 4834, loss 0.504931.
Train: 2018-07-31T00:51:25.738248: step 4835, loss 0.57081.
Train: 2018-07-31T00:51:25.878840: step 4836, loss 0.472077.
Train: 2018-07-31T00:51:26.019432: step 4837, loss 0.652741.
Train: 2018-07-31T00:51:26.160027: step 4838, loss 0.513154.
Train: 2018-07-31T00:51:26.316239: step 4839, loss 0.570867.
Train: 2018-07-31T00:51:26.472451: step 4840, loss 0.504639.
Test: 2018-07-31T00:51:26.706802: step 4840, loss 0.548696.
Train: 2018-07-31T00:51:26.862985: step 4841, loss 0.603726.
Train: 2018-07-31T00:51:27.003601: step 4842, loss 0.521434.
Train: 2018-07-31T00:51:27.144170: step 4843, loss 0.56249.
Train: 2018-07-31T00:51:27.284785: step 4844, loss 0.529017.
Train: 2018-07-31T00:51:27.425397: step 4845, loss 0.570245.
Train: 2018-07-31T00:51:27.581566: step 4846, loss 0.586333.
Train: 2018-07-31T00:51:27.722157: step 4847, loss 0.562889.
Train: 2018-07-31T00:51:27.862751: step 4848, loss 0.562718.
Train: 2018-07-31T00:51:28.018965: step 4849, loss 0.595213.
Train: 2018-07-31T00:51:28.159580: step 4850, loss 0.545954.
Test: 2018-07-31T00:51:28.409497: step 4850, loss 0.548462.
Train: 2018-07-31T00:51:28.550089: step 4851, loss 0.637584.
Train: 2018-07-31T00:51:28.706304: step 4852, loss 0.52952.
Train: 2018-07-31T00:51:28.846896: step 4853, loss 0.604486.
Train: 2018-07-31T00:51:28.987513: step 4854, loss 0.531236.
Train: 2018-07-31T00:51:29.143701: step 4855, loss 0.546668.
Train: 2018-07-31T00:51:29.284293: step 4856, loss 0.562327.
Train: 2018-07-31T00:51:29.424909: step 4857, loss 0.513124.
Train: 2018-07-31T00:51:29.581098: step 4858, loss 0.620548.
Train: 2018-07-31T00:51:29.721716: step 4859, loss 0.579544.
Train: 2018-07-31T00:51:29.862283: step 4860, loss 0.537977.
Test: 2018-07-31T00:51:30.112225: step 4860, loss 0.548849.
Train: 2018-07-31T00:51:30.252816: step 4861, loss 0.627739.
Train: 2018-07-31T00:51:30.409030: step 4862, loss 0.571211.
Train: 2018-07-31T00:51:30.549623: step 4863, loss 0.521697.
Train: 2018-07-31T00:51:30.690238: step 4864, loss 0.530065.
Train: 2018-07-31T00:51:30.830830: step 4865, loss 0.570589.
Train: 2018-07-31T00:51:30.971423: step 4866, loss 0.505933.
Train: 2018-07-31T00:51:31.111990: step 4867, loss 0.513955.
Train: 2018-07-31T00:51:31.252607: step 4868, loss 0.586869.
Train: 2018-07-31T00:51:31.393173: step 4869, loss 0.571067.
Train: 2018-07-31T00:51:31.549388: step 4870, loss 0.570867.
Test: 2018-07-31T00:51:31.783738: step 4870, loss 0.548896.
Train: 2018-07-31T00:51:31.924299: step 4871, loss 0.578688.
Train: 2018-07-31T00:51:32.080514: step 4872, loss 0.570547.
Train: 2018-07-31T00:51:32.221106: step 4873, loss 0.521804.
Train: 2018-07-31T00:51:32.361722: step 4874, loss 0.546178.
Train: 2018-07-31T00:51:32.502316: step 4875, loss 0.595662.
Train: 2018-07-31T00:51:32.642881: step 4876, loss 0.578986.
Train: 2018-07-31T00:51:32.783472: step 4877, loss 0.652859.
Train: 2018-07-31T00:51:32.939688: step 4878, loss 0.570846.
Train: 2018-07-31T00:51:33.080278: step 4879, loss 0.554663.
Train: 2018-07-31T00:51:33.236493: step 4880, loss 0.521893.
Test: 2018-07-31T00:51:33.470842: step 4880, loss 0.549053.
Train: 2018-07-31T00:51:33.611405: step 4881, loss 0.530166.
Train: 2018-07-31T00:51:33.767617: step 4882, loss 0.55453.
Train: 2018-07-31T00:51:33.908234: step 4883, loss 0.513817.
Train: 2018-07-31T00:51:34.048718: step 4884, loss 0.562801.
Train: 2018-07-31T00:51:34.204930: step 4885, loss 0.513697.
Train: 2018-07-31T00:51:34.345523: step 4886, loss 0.505533.
Train: 2018-07-31T00:51:34.501737: step 4887, loss 0.562593.
Train: 2018-07-31T00:51:34.642329: step 4888, loss 0.57889.
Train: 2018-07-31T00:51:34.782946: step 4889, loss 0.537797.
Train: 2018-07-31T00:51:34.923513: step 4890, loss 0.570794.
Test: 2018-07-31T00:51:35.157834: step 4890, loss 0.548558.
Train: 2018-07-31T00:51:35.314047: step 4891, loss 0.57886.
Train: 2018-07-31T00:51:35.470284: step 4892, loss 0.628948.
Train: 2018-07-31T00:51:35.610878: step 4893, loss 0.670405.
Train: 2018-07-31T00:51:35.751443: step 4894, loss 0.487977.
Train: 2018-07-31T00:51:35.907682: step 4895, loss 0.529281.
Train: 2018-07-31T00:51:36.063871: step 4896, loss 0.578697.
Train: 2018-07-31T00:51:36.204464: step 4897, loss 0.55421.
Train: 2018-07-31T00:51:36.345080: step 4898, loss 0.620284.
Train: 2018-07-31T00:51:36.485671: step 4899, loss 0.570715.
Train: 2018-07-31T00:51:36.641862: step 4900, loss 0.586915.
Test: 2018-07-31T00:51:36.876214: step 4900, loss 0.548671.
Train: 2018-07-31T00:51:37.610384: step 4901, loss 0.554062.
Train: 2018-07-31T00:51:37.782219: step 4902, loss 0.512509.
Train: 2018-07-31T00:51:37.938432: step 4903, loss 0.596377.
Train: 2018-07-31T00:51:38.079025: step 4904, loss 0.60361.
Train: 2018-07-31T00:51:38.219634: step 4905, loss 0.562774.
Train: 2018-07-31T00:51:38.375830: step 4906, loss 0.562433.
Train: 2018-07-31T00:51:38.532067: step 4907, loss 0.603798.
Train: 2018-07-31T00:51:38.672661: step 4908, loss 0.595417.
Train: 2018-07-31T00:51:38.828850: step 4909, loss 0.578831.
Train: 2018-07-31T00:51:38.969440: step 4910, loss 0.546478.
Test: 2018-07-31T00:51:39.219413: step 4910, loss 0.549376.
Train: 2018-07-31T00:51:39.359975: step 4911, loss 0.55468.
Train: 2018-07-31T00:51:39.516212: step 4912, loss 0.578787.
Train: 2018-07-31T00:51:39.656804: step 4913, loss 0.546937.
Train: 2018-07-31T00:51:39.812993: step 4914, loss 0.554981.
Train: 2018-07-31T00:51:39.953585: step 4915, loss 0.467247.
Train: 2018-07-31T00:51:40.094207: step 4916, loss 0.514687.
Train: 2018-07-31T00:51:40.234794: step 4917, loss 0.5303.
Train: 2018-07-31T00:51:40.375361: step 4918, loss 0.570808.
Train: 2018-07-31T00:51:40.515978: step 4919, loss 0.587632.
Train: 2018-07-31T00:51:40.656545: step 4920, loss 0.47772.
Test: 2018-07-31T00:51:40.906517: step 4920, loss 0.547981.
Train: 2018-07-31T00:51:41.047096: step 4921, loss 0.56349.
Train: 2018-07-31T00:51:41.187688: step 4922, loss 0.559919.
Train: 2018-07-31T00:51:41.343884: step 4923, loss 0.540308.
Train: 2018-07-31T00:51:41.484501: step 4924, loss 0.613135.
Train: 2018-07-31T00:51:41.625070: step 4925, loss 0.556856.
Train: 2018-07-31T00:51:41.765661: step 4926, loss 0.572488.
Train: 2018-07-31T00:51:41.906253: step 4927, loss 0.587135.
Train: 2018-07-31T00:51:42.046846: step 4928, loss 0.537993.
Train: 2018-07-31T00:51:42.187462: step 4929, loss 0.570464.
Train: 2018-07-31T00:51:42.343651: step 4930, loss 0.545639.
Test: 2018-07-31T00:51:42.578001: step 4930, loss 0.548717.
Train: 2018-07-31T00:51:42.718562: step 4931, loss 0.578946.
Train: 2018-07-31T00:51:42.874800: step 4932, loss 0.595845.
Train: 2018-07-31T00:51:43.015369: step 4933, loss 0.56245.
Train: 2018-07-31T00:51:43.156000: step 4934, loss 0.562837.
Train: 2018-07-31T00:51:43.312173: step 4935, loss 0.538184.
Train: 2018-07-31T00:51:43.468388: step 4936, loss 0.529996.
Train: 2018-07-31T00:51:43.608995: step 4937, loss 0.5383.
Train: 2018-07-31T00:51:43.765193: step 4938, loss 0.546073.
Train: 2018-07-31T00:51:43.905783: step 4939, loss 0.529793.
Train: 2018-07-31T00:51:44.077619: step 4940, loss 0.603668.
Test: 2018-07-31T00:51:44.311940: step 4940, loss 0.548839.
Train: 2018-07-31T00:51:44.452533: step 4941, loss 0.603012.
Train: 2018-07-31T00:51:44.593147: step 4942, loss 0.553975.
Train: 2018-07-31T00:51:44.733739: step 4943, loss 0.522386.
Train: 2018-07-31T00:51:44.874307: step 4944, loss 0.562618.
Train: 2018-07-31T00:51:45.030522: step 4945, loss 0.562894.
Train: 2018-07-31T00:51:45.186759: step 4946, loss 0.554306.
Train: 2018-07-31T00:51:45.327346: step 4947, loss 0.644717.
Train: 2018-07-31T00:51:45.483540: step 4948, loss 0.586384.
Train: 2018-07-31T00:51:45.624156: step 4949, loss 0.594938.
Train: 2018-07-31T00:51:45.764741: step 4950, loss 0.55499.
Test: 2018-07-31T00:51:46.014699: step 4950, loss 0.548956.
Train: 2018-07-31T00:51:46.155258: step 4951, loss 0.554541.
Train: 2018-07-31T00:51:46.311471: step 4952, loss 0.545792.
Train: 2018-07-31T00:51:46.452065: step 4953, loss 0.490129.
Train: 2018-07-31T00:51:46.592660: step 4954, loss 0.545443.
Train: 2018-07-31T00:51:46.733272: step 4955, loss 0.570523.
Train: 2018-07-31T00:51:46.873864: step 4956, loss 0.488716.
Train: 2018-07-31T00:51:47.014433: step 4957, loss 0.54551.
Train: 2018-07-31T00:51:47.170645: step 4958, loss 0.604255.
Train: 2018-07-31T00:51:47.311238: step 4959, loss 0.555192.
Train: 2018-07-31T00:51:47.467475: step 4960, loss 0.587117.
Test: 2018-07-31T00:51:47.701801: step 4960, loss 0.548386.
Train: 2018-07-31T00:51:47.857985: step 4961, loss 0.595864.
Train: 2018-07-31T00:51:48.014222: step 4962, loss 0.603678.
Train: 2018-07-31T00:51:48.154795: step 4963, loss 0.586424.
Train: 2018-07-31T00:51:48.311004: step 4964, loss 0.587011.
Train: 2018-07-31T00:51:48.451620: step 4965, loss 0.596138.
Train: 2018-07-31T00:51:48.592187: step 4966, loss 0.604459.
Train: 2018-07-31T00:51:48.748400: step 4967, loss 0.57063.
Train: 2018-07-31T00:51:48.888992: step 4968, loss 0.595423.
Train: 2018-07-31T00:51:49.029621: step 4969, loss 0.538997.
Train: 2018-07-31T00:51:49.189826: step 4970, loss 0.634647.
Test: 2018-07-31T00:51:49.439771: step 4970, loss 0.549789.
Train: 2018-07-31T00:51:49.596015: step 4971, loss 0.507519.
Train: 2018-07-31T00:51:49.720954: step 4972, loss 0.578792.
Train: 2018-07-31T00:51:49.877193: step 4973, loss 0.53169.
Train: 2018-07-31T00:51:50.017760: step 4974, loss 0.57102.
Train: 2018-07-31T00:51:50.173998: step 4975, loss 0.500472.
Train: 2018-07-31T00:51:50.314590: step 4976, loss 0.547484.
Train: 2018-07-31T00:51:50.455182: step 4977, loss 0.57101.
Train: 2018-07-31T00:51:50.611372: step 4978, loss 0.523786.
Train: 2018-07-31T00:51:50.767586: step 4979, loss 0.586755.
Train: 2018-07-31T00:51:50.908202: step 4980, loss 0.594669.
Test: 2018-07-31T00:51:51.142526: step 4980, loss 0.549797.
Train: 2018-07-31T00:51:51.283088: step 4981, loss 0.555136.
Train: 2018-07-31T00:51:51.439327: step 4982, loss 0.578852.
Train: 2018-07-31T00:51:51.579920: step 4983, loss 0.579893.
Train: 2018-07-31T00:51:51.751759: step 4984, loss 0.586791.
Train: 2018-07-31T00:51:51.892321: step 4985, loss 0.586782.
Train: 2018-07-31T00:51:52.032938: step 4986, loss 0.53925.
Train: 2018-07-31T00:51:52.173510: step 4987, loss 0.507506.
Train: 2018-07-31T00:51:52.314097: step 4988, loss 0.523224.
Train: 2018-07-31T00:51:52.454715: step 4989, loss 0.570851.
Train: 2018-07-31T00:51:52.595307: step 4990, loss 0.554928.
Test: 2018-07-31T00:51:52.845223: step 4990, loss 0.549431.
Train: 2018-07-31T00:51:52.985815: step 4991, loss 0.578862.
Train: 2018-07-31T00:51:53.126432: step 4992, loss 0.675134.
Train: 2018-07-31T00:51:53.282645: step 4993, loss 0.490671.
Train: 2018-07-31T00:51:53.423212: step 4994, loss 0.619028.
Train: 2018-07-31T00:51:53.579451: step 4995, loss 0.546784.
Train: 2018-07-31T00:51:53.720020: step 4996, loss 0.602965.
Train: 2018-07-31T00:51:53.860610: step 4997, loss 0.61907.
Train: 2018-07-31T00:51:54.016835: step 4998, loss 0.546867.
Train: 2018-07-31T00:51:54.141794: step 4999, loss 0.570839.
Train: 2018-07-31T00:51:54.298009: step 5000, loss 0.546954.
Test: 2018-07-31T00:51:54.532358: step 5000, loss 0.549565.
Train: 2018-07-31T00:51:55.329017: step 5001, loss 0.602818.
Train: 2018-07-31T00:51:55.469610: step 5002, loss 0.578836.
Train: 2018-07-31T00:51:55.610200: step 5003, loss 0.531174.
Train: 2018-07-31T00:51:55.766414: step 5004, loss 0.56299.
Train: 2018-07-31T00:51:55.891386: step 5005, loss 0.562999.
Train: 2018-07-31T00:51:56.047598: step 5006, loss 0.562994.
Train: 2018-07-31T00:51:56.188214: step 5007, loss 0.586795.
Train: 2018-07-31T00:51:56.344405: step 5008, loss 0.499534.
Train: 2018-07-31T00:51:56.484995: step 5009, loss 0.507371.
Train: 2018-07-31T00:51:56.625588: step 5010, loss 0.515139.
Test: 2018-07-31T00:51:56.875545: step 5010, loss 0.549482.
Train: 2018-07-31T00:51:57.016146: step 5011, loss 0.570867.
Train: 2018-07-31T00:51:57.156714: step 5012, loss 0.578868.
Train: 2018-07-31T00:51:57.297305: step 5013, loss 0.522573.
Train: 2018-07-31T00:51:57.453519: step 5014, loss 0.53046.
Train: 2018-07-31T00:51:57.594112: step 5015, loss 0.562693.
Train: 2018-07-31T00:51:57.734728: step 5016, loss 0.497602.
Train: 2018-07-31T00:51:57.875321: step 5017, loss 0.652468.
Train: 2018-07-31T00:51:58.031509: step 5018, loss 0.570765.
Train: 2018-07-31T00:51:58.156504: step 5019, loss 0.570762.
Train: 2018-07-31T00:51:58.312718: step 5020, loss 0.488643.
Test: 2018-07-31T00:51:58.547014: step 5020, loss 0.548731.
Train: 2018-07-31T00:51:58.703227: step 5021, loss 0.546052.
Train: 2018-07-31T00:51:58.843843: step 5022, loss 0.636828.
Train: 2018-07-31T00:51:58.984410: step 5023, loss 0.529428.
Train: 2018-07-31T00:51:59.125027: step 5024, loss 0.521092.
Train: 2018-07-31T00:51:59.265594: step 5025, loss 0.570758.
Train: 2018-07-31T00:51:59.406186: step 5026, loss 0.603995.
Train: 2018-07-31T00:51:59.546780: step 5027, loss 0.537511.
Train: 2018-07-31T00:51:59.702993: step 5028, loss 0.529162.
Train: 2018-07-31T00:51:59.843585: step 5029, loss 0.454118.
Train: 2018-07-31T00:51:59.984176: step 5030, loss 0.55405.
Test: 2018-07-31T00:52:00.218527: step 5030, loss 0.548342.
Train: 2018-07-31T00:52:00.374710: step 5031, loss 0.64629.
Train: 2018-07-31T00:52:00.515302: step 5032, loss 0.520404.
Train: 2018-07-31T00:52:00.655902: step 5033, loss 0.570792.
Train: 2018-07-31T00:52:00.812109: step 5034, loss 0.562376.
Train: 2018-07-31T00:52:00.952699: step 5035, loss 0.494945.
Train: 2018-07-31T00:52:01.108937: step 5036, loss 0.545472.
Train: 2018-07-31T00:52:01.249504: step 5037, loss 0.57082.
Train: 2018-07-31T00:52:01.390097: step 5038, loss 0.553878.
Train: 2018-07-31T00:52:01.546335: step 5039, loss 0.519912.
Train: 2018-07-31T00:52:01.686902: step 5040, loss 0.562346.
Test: 2018-07-31T00:52:01.921253: step 5040, loss 0.548079.
Train: 2018-07-31T00:52:02.093081: step 5041, loss 0.570861.
Train: 2018-07-31T00:52:02.233649: step 5042, loss 0.596439.
Train: 2018-07-31T00:52:02.374269: step 5043, loss 0.656097.
Train: 2018-07-31T00:52:02.530457: step 5044, loss 0.536835.
Train: 2018-07-31T00:52:02.655426: step 5045, loss 0.604791.
Train: 2018-07-31T00:52:02.811640: step 5046, loss 0.62161.
Train: 2018-07-31T00:52:02.936609: step 5047, loss 0.537078.
Train: 2018-07-31T00:52:03.077202: step 5048, loss 0.469942.
Train: 2018-07-31T00:52:03.233422: step 5049, loss 0.579186.
Train: 2018-07-31T00:52:03.374031: step 5050, loss 0.537245.
Test: 2018-07-31T00:52:03.608358: step 5050, loss 0.54837.
Train: 2018-07-31T00:52:03.764565: step 5051, loss 0.570778.
Train: 2018-07-31T00:52:03.905157: step 5052, loss 0.654458.
Train: 2018-07-31T00:52:04.061371: step 5053, loss 0.554083.
Train: 2018-07-31T00:52:04.201964: step 5054, loss 0.537487.
Train: 2018-07-31T00:52:04.358201: step 5055, loss 0.545855.
Train: 2018-07-31T00:52:04.498743: step 5056, loss 0.545892.
Train: 2018-07-31T00:52:04.639361: step 5057, loss 0.545919.
Train: 2018-07-31T00:52:04.779928: step 5058, loss 0.545937.
Train: 2018-07-31T00:52:04.936157: step 5059, loss 0.570756.
Train: 2018-07-31T00:52:05.076734: step 5060, loss 0.587288.
Test: 2018-07-31T00:52:05.326710: step 5060, loss 0.548671.
Train: 2018-07-31T00:52:05.467292: step 5061, loss 0.512963.
Train: 2018-07-31T00:52:05.607859: step 5062, loss 0.636809.
Train: 2018-07-31T00:52:05.748451: step 5063, loss 0.636695.
Train: 2018-07-31T00:52:05.904665: step 5064, loss 0.537901.
Train: 2018-07-31T00:52:06.045258: step 5065, loss 0.49701.
Train: 2018-07-31T00:52:06.185849: step 5066, loss 0.562574.
Train: 2018-07-31T00:52:06.342062: step 5067, loss 0.488887.
Train: 2018-07-31T00:52:06.482689: step 5068, loss 0.570798.
Train: 2018-07-31T00:52:06.638869: step 5069, loss 0.603689.
Train: 2018-07-31T00:52:06.779485: step 5070, loss 0.562625.
Test: 2018-07-31T00:52:07.029433: step 5070, loss 0.548841.
Train: 2018-07-31T00:52:07.185617: step 5071, loss 0.652743.
Train: 2018-07-31T00:52:07.326233: step 5072, loss 0.578941.
Train: 2018-07-31T00:52:07.466799: step 5073, loss 0.562623.
Train: 2018-07-31T00:52:07.623012: step 5074, loss 0.53825.
Train: 2018-07-31T00:52:07.763629: step 5075, loss 0.522062.
Train: 2018-07-31T00:52:07.919842: step 5076, loss 0.530199.
Train: 2018-07-31T00:52:08.060410: step 5077, loss 0.611395.
Train: 2018-07-31T00:52:08.216648: step 5078, loss 0.546442.
Train: 2018-07-31T00:52:08.357233: step 5079, loss 0.603245.
Train: 2018-07-31T00:52:08.513453: step 5080, loss 0.538377.
Test: 2018-07-31T00:52:08.763401: step 5080, loss 0.549128.
Train: 2018-07-31T00:52:08.903988: step 5081, loss 0.619402.
Train: 2018-07-31T00:52:09.060176: step 5082, loss 0.6355.
Train: 2018-07-31T00:52:09.200768: step 5083, loss 0.562758.
Train: 2018-07-31T00:52:09.341384: step 5084, loss 0.554759.
Train: 2018-07-31T00:52:09.497574: step 5085, loss 0.602925.
Train: 2018-07-31T00:52:09.638167: step 5086, loss 0.546882.
Train: 2018-07-31T00:52:09.763137: step 5087, loss 0.570882.
Train: 2018-07-31T00:52:09.919351: step 5088, loss 0.578858.
Train: 2018-07-31T00:52:10.059943: step 5089, loss 0.634461.
Train: 2018-07-31T00:52:10.200534: step 5090, loss 0.539236.
Test: 2018-07-31T00:52:10.450476: step 5090, loss 0.54977.
Train: 2018-07-31T00:52:10.591068: step 5091, loss 0.618387.
Train: 2018-07-31T00:52:10.731659: step 5092, loss 0.563075.
Train: 2018-07-31T00:52:10.872253: step 5093, loss 0.602566.
Train: 2018-07-31T00:52:11.012845: step 5094, loss 0.555372.
Train: 2018-07-31T00:52:11.153463: step 5095, loss 0.625806.
Train: 2018-07-31T00:52:11.294053: step 5096, loss 0.52449.
Train: 2018-07-31T00:52:11.434644: step 5097, loss 0.594431.
Train: 2018-07-31T00:52:11.575237: step 5098, loss 0.54028.
Train: 2018-07-31T00:52:11.731426: step 5099, loss 0.609802.
Train: 2018-07-31T00:52:11.872017: step 5100, loss 0.540461.
Test: 2018-07-31T00:52:12.121960: step 5100, loss 0.550673.
Train: 2018-07-31T00:52:12.903025: step 5101, loss 0.525078.
Train: 2018-07-31T00:52:13.043642: step 5102, loss 0.509587.
Train: 2018-07-31T00:52:13.199832: step 5103, loss 0.586803.
Train: 2018-07-31T00:52:13.356046: step 5104, loss 0.586651.
Train: 2018-07-31T00:52:13.512259: step 5105, loss 0.555864.
Train: 2018-07-31T00:52:13.652851: step 5106, loss 0.516751.
Train: 2018-07-31T00:52:13.793442: step 5107, loss 0.571269.
Train: 2018-07-31T00:52:13.949699: step 5108, loss 0.516338.
Train: 2018-07-31T00:52:14.090248: step 5109, loss 0.53178.
Train: 2018-07-31T00:52:14.230839: step 5110, loss 0.539421.
Test: 2018-07-31T00:52:14.480812: step 5110, loss 0.549589.
Train: 2018-07-31T00:52:14.621374: step 5111, loss 0.515137.
Train: 2018-07-31T00:52:14.761965: step 5112, loss 0.498287.
Train: 2018-07-31T00:52:14.902559: step 5113, loss 0.629968.
Train: 2018-07-31T00:52:15.058770: step 5114, loss 0.523182.
Train: 2018-07-31T00:52:15.199364: step 5115, loss 0.610584.
Train: 2018-07-31T00:52:15.339956: step 5116, loss 0.520795.
Train: 2018-07-31T00:52:15.496168: step 5117, loss 0.571548.
Train: 2018-07-31T00:52:15.636761: step 5118, loss 0.530551.
Train: 2018-07-31T00:52:15.777370: step 5119, loss 0.579383.
Train: 2018-07-31T00:52:15.933565: step 5120, loss 0.471593.
Test: 2018-07-31T00:52:16.167920: step 5120, loss 0.548514.
Train: 2018-07-31T00:52:16.324100: step 5121, loss 0.562798.
Train: 2018-07-31T00:52:16.464692: step 5122, loss 0.570672.
Train: 2018-07-31T00:52:16.620905: step 5123, loss 0.621103.
Train: 2018-07-31T00:52:16.761497: step 5124, loss 0.554397.
Train: 2018-07-31T00:52:16.917712: step 5125, loss 0.537548.
Train: 2018-07-31T00:52:17.058302: step 5126, loss 0.57075.
Train: 2018-07-31T00:52:17.198895: step 5127, loss 0.570781.
Train: 2018-07-31T00:52:17.339487: step 5128, loss 0.570758.
Train: 2018-07-31T00:52:17.495701: step 5129, loss 0.54579.
Train: 2018-07-31T00:52:17.636292: step 5130, loss 0.554089.
Test: 2018-07-31T00:52:17.870614: step 5130, loss 0.548462.
Train: 2018-07-31T00:52:18.026827: step 5131, loss 0.520749.
Train: 2018-07-31T00:52:18.167419: step 5132, loss 0.595856.
Train: 2018-07-31T00:52:18.308011: step 5133, loss 0.587447.
Train: 2018-07-31T00:52:18.448603: step 5134, loss 0.509005.
Train: 2018-07-31T00:52:18.589219: step 5135, loss 0.48723.
Train: 2018-07-31T00:52:18.729787: step 5136, loss 0.520537.
Train: 2018-07-31T00:52:18.870379: step 5137, loss 0.587586.
Train: 2018-07-31T00:52:19.026594: step 5138, loss 0.537099.
Train: 2018-07-31T00:52:19.167185: step 5139, loss 0.528553.
Train: 2018-07-31T00:52:19.307800: step 5140, loss 0.67248.
Test: 2018-07-31T00:52:19.557748: step 5140, loss 0.548194.
Train: 2018-07-31T00:52:19.698310: step 5141, loss 0.553952.
Train: 2018-07-31T00:52:19.838926: step 5142, loss 0.511587.
Train: 2018-07-31T00:52:19.979495: step 5143, loss 0.520114.
Train: 2018-07-31T00:52:20.120087: step 5144, loss 0.579388.
Train: 2018-07-31T00:52:20.276300: step 5145, loss 0.604684.
Train: 2018-07-31T00:52:20.416915: step 5146, loss 0.596176.
Train: 2018-07-31T00:52:20.557509: step 5147, loss 0.604571.
Train: 2018-07-31T00:52:20.713722: step 5148, loss 0.520278.
Train: 2018-07-31T00:52:20.869935: step 5149, loss 0.587606.
Train: 2018-07-31T00:52:21.010502: step 5150, loss 0.520438.
Test: 2018-07-31T00:52:21.244852: step 5150, loss 0.548357.
Train: 2018-07-31T00:52:21.401054: step 5151, loss 0.570779.
Train: 2018-07-31T00:52:21.541628: step 5152, loss 0.579147.
Train: 2018-07-31T00:52:21.682221: step 5153, loss 0.570771.
Train: 2018-07-31T00:52:21.838435: step 5154, loss 0.612483.
Train: 2018-07-31T00:52:21.963405: step 5155, loss 0.562442.
Train: 2018-07-31T00:52:22.103998: step 5156, loss 0.53757.
Train: 2018-07-31T00:52:22.244613: step 5157, loss 0.603881.
Train: 2018-07-31T00:52:22.385181: step 5158, loss 0.570756.
Train: 2018-07-31T00:52:22.510150: step 5159, loss 0.537817.
Train: 2018-07-31T00:52:22.666365: step 5160, loss 0.628291.
Test: 2018-07-31T00:52:22.900713: step 5160, loss 0.548853.
Train: 2018-07-31T00:52:23.041277: step 5161, loss 0.521616.
Train: 2018-07-31T00:52:23.181869: step 5162, loss 0.578942.
Train: 2018-07-31T00:52:23.322485: step 5163, loss 0.538152.
Train: 2018-07-31T00:52:23.478675: step 5164, loss 0.595208.
Train: 2018-07-31T00:52:23.619267: step 5165, loss 0.530153.
Train: 2018-07-31T00:52:23.775480: step 5166, loss 0.587023.
Train: 2018-07-31T00:52:23.916096: step 5167, loss 0.587003.
Train: 2018-07-31T00:52:24.056665: step 5168, loss 0.522269.
Train: 2018-07-31T00:52:24.197269: step 5169, loss 0.619309.
Train: 2018-07-31T00:52:24.337847: step 5170, loss 0.570818.
Test: 2018-07-31T00:52:24.587790: step 5170, loss 0.549288.
Train: 2018-07-31T00:52:24.728394: step 5171, loss 0.546668.
Train: 2018-07-31T00:52:24.884619: step 5172, loss 0.554745.
Train: 2018-07-31T00:52:25.025188: step 5173, loss 0.619043.
Train: 2018-07-31T00:52:25.165779: step 5174, loss 0.586881.
Train: 2018-07-31T00:52:25.290749: step 5175, loss 0.506876.
Train: 2018-07-31T00:52:25.431342: step 5176, loss 0.586865.
Train: 2018-07-31T00:52:25.571935: step 5177, loss 0.53894.
Train: 2018-07-31T00:52:25.728148: step 5178, loss 0.491052.
Train: 2018-07-31T00:52:25.868758: step 5179, loss 0.530889.
Train: 2018-07-31T00:52:26.009357: step 5180, loss 0.554809.
Test: 2018-07-31T00:52:26.243677: step 5180, loss 0.549341.
Train: 2018-07-31T00:52:26.399890: step 5181, loss 0.530656.
Train: 2018-07-31T00:52:26.540457: step 5182, loss 0.546645.
Train: 2018-07-31T00:52:26.696673: step 5183, loss 0.506053.
Train: 2018-07-31T00:52:26.837264: step 5184, loss 0.570806.
Train: 2018-07-31T00:52:26.977890: step 5185, loss 0.619881.
Train: 2018-07-31T00:52:27.118448: step 5186, loss 0.578981.
Train: 2018-07-31T00:52:27.243419: step 5187, loss 0.488925.
Train: 2018-07-31T00:52:27.384010: step 5188, loss 0.505056.
Train: 2018-07-31T00:52:27.524627: step 5189, loss 0.546065.
Train: 2018-07-31T00:52:27.680815: step 5190, loss 0.603786.
Test: 2018-07-31T00:52:27.930758: step 5190, loss 0.548564.
Train: 2018-07-31T00:52:28.086972: step 5191, loss 0.520944.
Train: 2018-07-31T00:52:28.227562: step 5192, loss 0.587524.
Train: 2018-07-31T00:52:28.368179: step 5193, loss 0.587208.
Train: 2018-07-31T00:52:28.508747: step 5194, loss 0.554016.
Train: 2018-07-31T00:52:28.649344: step 5195, loss 0.495288.
Train: 2018-07-31T00:52:28.805552: step 5196, loss 0.579563.
Train: 2018-07-31T00:52:28.946143: step 5197, loss 0.562514.
Train: 2018-07-31T00:52:29.086737: step 5198, loss 0.486304.
Train: 2018-07-31T00:52:29.227328: step 5199, loss 0.570809.
Train: 2018-07-31T00:52:29.367945: step 5200, loss 0.554094.
Test: 2018-07-31T00:52:29.602242: step 5200, loss 0.548055.
Train: 2018-07-31T00:52:30.398929: step 5201, loss 0.494066.
Train: 2018-07-31T00:52:30.539546: step 5202, loss 0.502433.
Train: 2018-07-31T00:52:30.680112: step 5203, loss 0.510767.
Train: 2018-07-31T00:52:30.820705: step 5204, loss 0.560815.
Train: 2018-07-31T00:52:30.961298: step 5205, loss 0.683717.
Train: 2018-07-31T00:52:31.101890: step 5206, loss 0.543499.
Train: 2018-07-31T00:52:31.242482: step 5207, loss 0.510162.
Train: 2018-07-31T00:52:31.383099: step 5208, loss 0.524583.
Train: 2018-07-31T00:52:31.523690: step 5209, loss 0.577741.
Train: 2018-07-31T00:52:31.679878: step 5210, loss 0.587291.
Test: 2018-07-31T00:52:31.914199: step 5210, loss 0.547402.
Train: 2018-07-31T00:52:32.070413: step 5211, loss 0.646019.
Train: 2018-07-31T00:52:32.211022: step 5212, loss 0.663145.
Train: 2018-07-31T00:52:32.351597: step 5213, loss 0.552672.
Train: 2018-07-31T00:52:32.492189: step 5214, loss 0.58744.
Train: 2018-07-31T00:52:32.632805: step 5215, loss 0.604963.
Train: 2018-07-31T00:52:32.789019: step 5216, loss 0.578379.
Train: 2018-07-31T00:52:32.945207: step 5217, loss 0.562653.
Train: 2018-07-31T00:52:33.101452: step 5218, loss 0.504811.
Train: 2018-07-31T00:52:33.242014: step 5219, loss 0.554319.
Train: 2018-07-31T00:52:33.382606: step 5220, loss 0.513415.
Test: 2018-07-31T00:52:33.616956: step 5220, loss 0.548887.
Train: 2018-07-31T00:52:33.773139: step 5221, loss 0.619832.
Train: 2018-07-31T00:52:33.929352: step 5222, loss 0.513711.
Train: 2018-07-31T00:52:34.054347: step 5223, loss 0.554501.
Train: 2018-07-31T00:52:34.210537: step 5224, loss 0.619561.
Train: 2018-07-31T00:52:34.351127: step 5225, loss 0.587012.
Train: 2018-07-31T00:52:34.507344: step 5226, loss 0.562715.
Train: 2018-07-31T00:52:34.632338: step 5227, loss 0.53854.
Train: 2018-07-31T00:52:34.788550: step 5228, loss 0.538598.
Train: 2018-07-31T00:52:34.944740: step 5229, loss 0.627176.
Train: 2018-07-31T00:52:35.085357: step 5230, loss 0.562805.
Test: 2018-07-31T00:52:35.319686: step 5230, loss 0.549414.
Train: 2018-07-31T00:52:35.475865: step 5231, loss 0.570849.
Train: 2018-07-31T00:52:35.632103: step 5232, loss 0.546851.
Train: 2018-07-31T00:52:35.772671: step 5233, loss 0.546885.
Train: 2018-07-31T00:52:35.913262: step 5234, loss 0.538911.
Train: 2018-07-31T00:52:36.053872: step 5235, loss 0.57087.
Train: 2018-07-31T00:52:36.210092: step 5236, loss 0.578862.
Train: 2018-07-31T00:52:36.366282: step 5237, loss 0.506939.
Train: 2018-07-31T00:52:36.506898: step 5238, loss 0.546856.
Train: 2018-07-31T00:52:36.647490: step 5239, loss 0.602912.
Train: 2018-07-31T00:52:36.788058: step 5240, loss 0.651049.
Test: 2018-07-31T00:52:37.038030: step 5240, loss 0.549437.
Train: 2018-07-31T00:52:37.178591: step 5241, loss 0.55484.
Train: 2018-07-31T00:52:37.334831: step 5242, loss 0.474869.
Train: 2018-07-31T00:52:37.491019: step 5243, loss 0.514786.
Train: 2018-07-31T00:52:37.631610: step 5244, loss 0.522664.
Train: 2018-07-31T00:52:37.772202: step 5245, loss 0.586932.
Train: 2018-07-31T00:52:37.928416: step 5246, loss 0.659632.
Train: 2018-07-31T00:52:38.069009: step 5247, loss 0.530445.
Train: 2018-07-31T00:52:38.209599: step 5248, loss 0.554653.
Train: 2018-07-31T00:52:38.350191: step 5249, loss 0.538458.
Train: 2018-07-31T00:52:38.490784: step 5250, loss 0.530312.
Test: 2018-07-31T00:52:38.740726: step 5250, loss 0.549086.
Train: 2018-07-31T00:52:38.881318: step 5251, loss 0.578902.
Train: 2018-07-31T00:52:39.021935: step 5252, loss 0.603289.
Train: 2018-07-31T00:52:39.162527: step 5253, loss 0.546389.
Train: 2018-07-31T00:52:39.318715: step 5254, loss 0.481279.
Train: 2018-07-31T00:52:39.443685: step 5255, loss 0.554449.
Train: 2018-07-31T00:52:39.599899: step 5256, loss 0.595296.
Train: 2018-07-31T00:52:39.740492: step 5257, loss 0.521574.
Train: 2018-07-31T00:52:39.881083: step 5258, loss 0.611882.
Train: 2018-07-31T00:52:40.021676: step 5259, loss 0.562569.
Train: 2018-07-31T00:52:40.177888: step 5260, loss 0.504907.
Test: 2018-07-31T00:52:40.412212: step 5260, loss 0.548701.
Train: 2018-07-31T00:52:40.568423: step 5261, loss 0.603718.
Train: 2018-07-31T00:52:40.709040: step 5262, loss 0.587327.
Train: 2018-07-31T00:52:40.849624: step 5263, loss 0.595471.
Train: 2018-07-31T00:52:40.990223: step 5264, loss 0.504809.
Train: 2018-07-31T00:52:41.130790: step 5265, loss 0.587258.
Train: 2018-07-31T00:52:41.271383: step 5266, loss 0.554267.
Train: 2018-07-31T00:52:41.411975: step 5267, loss 0.562553.
Train: 2018-07-31T00:52:41.552566: step 5268, loss 0.537777.
Train: 2018-07-31T00:52:41.693160: step 5269, loss 0.562506.
Train: 2018-07-31T00:52:41.833752: step 5270, loss 0.537754.
Test: 2018-07-31T00:52:42.083693: step 5270, loss 0.548671.
Train: 2018-07-31T00:52:42.239907: step 5271, loss 0.554244.
Train: 2018-07-31T00:52:42.380523: step 5272, loss 0.562492.
Train: 2018-07-31T00:52:42.521091: step 5273, loss 0.628644.
Train: 2018-07-31T00:52:42.661681: step 5274, loss 0.595543.
Train: 2018-07-31T00:52:42.802274: step 5275, loss 0.579005.
Train: 2018-07-31T00:52:42.942866: step 5276, loss 0.529604.
Train: 2018-07-31T00:52:43.083458: step 5277, loss 0.595426.
Train: 2018-07-31T00:52:43.224050: step 5278, loss 0.6118.
Train: 2018-07-31T00:52:43.364668: step 5279, loss 0.611692.
Train: 2018-07-31T00:52:43.505247: step 5280, loss 0.554463.
Test: 2018-07-31T00:52:43.739581: step 5280, loss 0.549037.
Train: 2018-07-31T00:52:43.895793: step 5281, loss 0.538262.
Train: 2018-07-31T00:52:44.036361: step 5282, loss 0.578903.
Train: 2018-07-31T00:52:44.176954: step 5283, loss 0.619359.
Train: 2018-07-31T00:52:44.317544: step 5284, loss 0.522424.
Train: 2018-07-31T00:52:44.458137: step 5285, loss 0.545608.
Train: 2018-07-31T00:52:44.614350: step 5286, loss 0.498498.
Train: 2018-07-31T00:52:44.754966: step 5287, loss 0.602995.
Train: 2018-07-31T00:52:44.895559: step 5288, loss 0.530656.
Train: 2018-07-31T00:52:45.051749: step 5289, loss 0.45025.
Train: 2018-07-31T00:52:45.192341: step 5290, loss 0.530498.
Test: 2018-07-31T00:52:45.426661: step 5290, loss 0.549151.
Train: 2018-07-31T00:52:45.582898: step 5291, loss 0.659825.
Train: 2018-07-31T00:52:45.723466: step 5292, loss 0.627503.
Train: 2018-07-31T00:52:45.864058: step 5293, loss 0.538416.
Train: 2018-07-31T00:52:46.004649: step 5294, loss 0.538413.
Train: 2018-07-31T00:52:46.145272: step 5295, loss 0.554593.
Train: 2018-07-31T00:52:46.285858: step 5296, loss 0.570792.
Train: 2018-07-31T00:52:46.426426: step 5297, loss 0.603241.
Train: 2018-07-31T00:52:46.582640: step 5298, loss 0.562685.
Train: 2018-07-31T00:52:46.707635: step 5299, loss 0.611326.
Train: 2018-07-31T00:52:46.848227: step 5300, loss 0.538421.
Test: 2018-07-31T00:52:47.098145: step 5300, loss 0.549165.
Train: 2018-07-31T00:52:47.832346: step 5301, loss 0.578891.
Train: 2018-07-31T00:52:47.972938: step 5302, loss 0.595051.
Train: 2018-07-31T00:52:48.129153: step 5303, loss 0.546608.
Train: 2018-07-31T00:52:48.269762: step 5304, loss 0.522455.
Train: 2018-07-31T00:52:48.410335: step 5305, loss 0.546633.
Train: 2018-07-31T00:52:48.566549: step 5306, loss 0.554682.
Train: 2018-07-31T00:52:48.707159: step 5307, loss 0.562738.
Train: 2018-07-31T00:52:48.847758: step 5308, loss 0.61928.
Train: 2018-07-31T00:52:49.003946: step 5309, loss 0.611179.
Train: 2018-07-31T00:52:49.160161: step 5310, loss 0.578882.
Test: 2018-07-31T00:52:49.394506: step 5310, loss 0.549311.
Train: 2018-07-31T00:52:49.550693: step 5311, loss 0.546697.
Train: 2018-07-31T00:52:49.706908: step 5312, loss 0.619048.
Train: 2018-07-31T00:52:49.831903: step 5313, loss 0.578866.
Train: 2018-07-31T00:52:49.988093: step 5314, loss 0.578862.
Train: 2018-07-31T00:52:50.128709: step 5315, loss 0.594814.
Train: 2018-07-31T00:52:50.284896: step 5316, loss 0.523185.
Train: 2018-07-31T00:52:50.425491: step 5317, loss 0.586799.
Train: 2018-07-31T00:52:50.566081: step 5318, loss 0.523371.
Train: 2018-07-31T00:52:50.706673: step 5319, loss 0.563013.
Train: 2018-07-31T00:52:50.862886: step 5320, loss 0.563019.
Test: 2018-07-31T00:52:51.112830: step 5320, loss 0.549758.
Train: 2018-07-31T00:52:51.253420: step 5321, loss 0.483825.
Train: 2018-07-31T00:52:51.394013: step 5322, loss 0.555052.
Train: 2018-07-31T00:52:51.534629: step 5323, loss 0.578859.
Train: 2018-07-31T00:52:51.690818: step 5324, loss 0.610723.
Train: 2018-07-31T00:52:51.831410: step 5325, loss 0.562921.
Train: 2018-07-31T00:52:51.972027: step 5326, loss 0.538991.
Train: 2018-07-31T00:52:52.112618: step 5327, loss 0.546928.
Train: 2018-07-31T00:52:52.253211: step 5328, loss 0.570867.
Train: 2018-07-31T00:52:52.393778: step 5329, loss 0.546841.
Train: 2018-07-31T00:52:52.534371: step 5330, loss 0.506692.
Test: 2018-07-31T00:52:52.768722: step 5330, loss 0.549323.
Train: 2018-07-31T00:52:52.924904: step 5331, loss 0.554745.
Train: 2018-07-31T00:52:53.065509: step 5332, loss 0.506282.
Train: 2018-07-31T00:52:53.206088: step 5333, loss 0.514104.
Train: 2018-07-31T00:52:53.362326: step 5334, loss 0.619609.
Train: 2018-07-31T00:52:53.502944: step 5335, loss 0.546285.
Train: 2018-07-31T00:52:53.643485: step 5336, loss 0.578952.
Train: 2018-07-31T00:52:53.784102: step 5337, loss 0.603585.
Train: 2018-07-31T00:52:53.940292: step 5338, loss 0.628265.
Train: 2018-07-31T00:52:54.080909: step 5339, loss 0.537919.
Train: 2018-07-31T00:52:54.237123: step 5340, loss 0.546129.
Test: 2018-07-31T00:52:54.471417: step 5340, loss 0.54879.
Train: 2018-07-31T00:52:54.627631: step 5341, loss 0.537906.
Train: 2018-07-31T00:52:54.768246: step 5342, loss 0.677626.
Train: 2018-07-31T00:52:54.908815: step 5343, loss 0.529737.
Train: 2018-07-31T00:52:55.049406: step 5344, loss 0.636334.
Train: 2018-07-31T00:52:55.190025: step 5345, loss 0.529894.
Train: 2018-07-31T00:52:55.330615: step 5346, loss 0.538126.
Train: 2018-07-31T00:52:55.486829: step 5347, loss 0.554466.
Train: 2018-07-31T00:52:55.643043: step 5348, loss 0.578925.
Train: 2018-07-31T00:52:55.783633: step 5349, loss 0.554496.
Train: 2018-07-31T00:52:55.939823: step 5350, loss 0.465013.
Test: 2018-07-31T00:52:56.174145: step 5350, loss 0.548976.
Train: 2018-07-31T00:52:56.314746: step 5351, loss 0.595225.
Train: 2018-07-31T00:52:56.455352: step 5352, loss 0.538147.
Train: 2018-07-31T00:52:56.611542: step 5353, loss 0.521768.
Train: 2018-07-31T00:52:56.752133: step 5354, loss 0.587136.
Train: 2018-07-31T00:52:56.892750: step 5355, loss 0.546179.
Train: 2018-07-31T00:52:57.033316: step 5356, loss 0.521518.
Train: 2018-07-31T00:52:57.173934: step 5357, loss 0.578991.
Train: 2018-07-31T00:52:57.330148: step 5358, loss 0.578996.
Train: 2018-07-31T00:52:57.470715: step 5359, loss 0.554257.
Train: 2018-07-31T00:52:57.626929: step 5360, loss 0.53773.
Test: 2018-07-31T00:52:57.861291: step 5360, loss 0.548637.
Train: 2018-07-31T00:52:58.017460: step 5361, loss 0.587293.
Train: 2018-07-31T00:52:58.158079: step 5362, loss 0.653498.
Train: 2018-07-31T00:52:58.298672: step 5363, loss 0.554231.
Train: 2018-07-31T00:52:58.439263: step 5364, loss 0.546003.
Train: 2018-07-31T00:52:58.579854: step 5365, loss 0.570753.
Train: 2018-07-31T00:52:58.720421: step 5366, loss 0.55429.
Train: 2018-07-31T00:52:58.861039: step 5367, loss 0.504924.
Train: 2018-07-31T00:52:59.001630: step 5368, loss 0.546049.
Train: 2018-07-31T00:52:59.157819: step 5369, loss 0.554264.
Train: 2018-07-31T00:52:59.298437: step 5370, loss 0.57076.
Test: 2018-07-31T00:52:59.532733: step 5370, loss 0.548675.
Train: 2018-07-31T00:52:59.688945: step 5371, loss 0.570776.
Train: 2018-07-31T00:52:59.845160: step 5372, loss 0.595529.
Train: 2018-07-31T00:52:59.985751: step 5373, loss 0.612028.
Train: 2018-07-31T00:53:00.126341: step 5374, loss 0.529571.
Train: 2018-07-31T00:53:00.266962: step 5375, loss 0.52961.
Train: 2018-07-31T00:53:00.407552: step 5376, loss 0.587216.
Train: 2018-07-31T00:53:00.563741: step 5377, loss 0.546089.
Train: 2018-07-31T00:53:00.704331: step 5378, loss 0.521433.
Train: 2018-07-31T00:53:00.844924: step 5379, loss 0.603664.
Train: 2018-07-31T00:53:00.985518: step 5380, loss 0.546089.
Test: 2018-07-31T00:53:01.219837: step 5380, loss 0.548764.
Train: 2018-07-31T00:53:01.376050: step 5381, loss 0.562535.
Train: 2018-07-31T00:53:01.516643: step 5382, loss 0.513199.
Train: 2018-07-31T00:53:01.657251: step 5383, loss 0.471981.
Train: 2018-07-31T00:53:01.797851: step 5384, loss 0.587271.
Train: 2018-07-31T00:53:01.938417: step 5385, loss 0.620391.
Train: 2018-07-31T00:53:02.079034: step 5386, loss 0.529378.
Train: 2018-07-31T00:53:02.219602: step 5387, loss 0.554181.
Train: 2018-07-31T00:53:02.360195: step 5388, loss 0.471215.
Train: 2018-07-31T00:53:02.500812: step 5389, loss 0.562445.
Train: 2018-07-31T00:53:02.641380: step 5390, loss 0.504043.
Test: 2018-07-31T00:53:02.891351: step 5390, loss 0.548375.
Train: 2018-07-31T00:53:03.031912: step 5391, loss 0.579162.
Train: 2018-07-31T00:53:03.172504: step 5392, loss 0.587562.
Train: 2018-07-31T00:53:03.313114: step 5393, loss 0.537168.
Train: 2018-07-31T00:53:03.469311: step 5394, loss 0.612908.
Train: 2018-07-31T00:53:03.609907: step 5395, loss 0.52867.
Train: 2018-07-31T00:53:03.750494: step 5396, loss 0.562361.
Train: 2018-07-31T00:53:03.891110: step 5397, loss 0.545493.
Train: 2018-07-31T00:53:04.047301: step 5398, loss 0.621472.
Train: 2018-07-31T00:53:04.187893: step 5399, loss 0.53705.
Train: 2018-07-31T00:53:04.328484: step 5400, loss 0.520203.
Test: 2018-07-31T00:53:04.562829: step 5400, loss 0.548232.
Train: 2018-07-31T00:53:05.343896: step 5401, loss 0.638321.
Train: 2018-07-31T00:53:05.484463: step 5402, loss 0.587654.
Train: 2018-07-31T00:53:05.625056: step 5403, loss 0.570791.
Train: 2018-07-31T00:53:05.765646: step 5404, loss 0.579175.
Train: 2018-07-31T00:53:05.906241: step 5405, loss 0.554032.
Train: 2018-07-31T00:53:06.046856: step 5406, loss 0.529002.
Train: 2018-07-31T00:53:06.187452: step 5407, loss 0.57911.
Train: 2018-07-31T00:53:06.343662: step 5408, loss 0.537449.
Train: 2018-07-31T00:53:06.484229: step 5409, loss 0.529163.
Train: 2018-07-31T00:53:06.624846: step 5410, loss 0.60403.
Test: 2018-07-31T00:53:06.859172: step 5410, loss 0.548542.
Train: 2018-07-31T00:53:06.999733: step 5411, loss 0.554147.
Train: 2018-07-31T00:53:07.155971: step 5412, loss 0.579055.
Train: 2018-07-31T00:53:07.296540: step 5413, loss 0.521046.
Train: 2018-07-31T00:53:07.437158: step 5414, loss 0.612164.
Train: 2018-07-31T00:53:07.577723: step 5415, loss 0.587293.
Train: 2018-07-31T00:53:07.718339: step 5416, loss 0.537753.
Train: 2018-07-31T00:53:07.858931: step 5417, loss 0.603714.
Train: 2018-07-31T00:53:08.077605: step 5418, loss 0.587201.
Train: 2018-07-31T00:53:08.218197: step 5419, loss 0.603562.
Train: 2018-07-31T00:53:08.374412: step 5420, loss 0.570768.
Test: 2018-07-31T00:53:08.608762: step 5420, loss 0.548992.
Train: 2018-07-31T00:53:08.764969: step 5421, loss 0.554487.
Train: 2018-07-31T00:53:08.905538: step 5422, loss 0.570786.
Train: 2018-07-31T00:53:09.046128: step 5423, loss 0.5951.
Train: 2018-07-31T00:53:09.186745: step 5424, loss 0.490053.
Train: 2018-07-31T00:53:09.327337: step 5425, loss 0.570815.
Train: 2018-07-31T00:53:09.483551: step 5426, loss 0.522467.
Train: 2018-07-31T00:53:09.639741: step 5427, loss 0.522459.
Train: 2018-07-31T00:53:09.780356: step 5428, loss 0.586956.
Train: 2018-07-31T00:53:09.920924: step 5429, loss 0.595027.
Train: 2018-07-31T00:53:10.061516: step 5430, loss 0.562735.
Test: 2018-07-31T00:53:10.311458: step 5430, loss 0.549229.
Train: 2018-07-31T00:53:10.452049: step 5431, loss 0.586951.
Train: 2018-07-31T00:53:10.592666: step 5432, loss 0.586921.
Train: 2018-07-31T00:53:10.748856: step 5433, loss 0.619144.
Train: 2018-07-31T00:53:10.889447: step 5434, loss 0.514555.
Train: 2018-07-31T00:53:11.045686: step 5435, loss 0.514541.
Train: 2018-07-31T00:53:11.186253: step 5436, loss 0.528261.
Train: 2018-07-31T00:53:11.326846: step 5437, loss 0.586983.
Train: 2018-07-31T00:53:11.467437: step 5438, loss 0.561866.
Train: 2018-07-31T00:53:11.608054: step 5439, loss 0.54523.
Train: 2018-07-31T00:53:11.748621: step 5440, loss 0.511449.
Test: 2018-07-31T00:53:11.982942: step 5440, loss 0.548117.
Train: 2018-07-31T00:53:12.139155: step 5441, loss 0.55476.
Train: 2018-07-31T00:53:12.279747: step 5442, loss 0.555013.
Train: 2018-07-31T00:53:12.420339: step 5443, loss 0.564937.
Train: 2018-07-31T00:53:12.576553: step 5444, loss 0.546107.
Train: 2018-07-31T00:53:12.717144: step 5445, loss 0.64606.
Train: 2018-07-31T00:53:12.857736: step 5446, loss 0.601299.
Train: 2018-07-31T00:53:12.998352: step 5447, loss 0.493587.
Train: 2018-07-31T00:53:13.154541: step 5448, loss 0.536974.
Train: 2018-07-31T00:53:13.295134: step 5449, loss 0.513458.
Train: 2018-07-31T00:53:13.435743: step 5450, loss 0.586407.
Test: 2018-07-31T00:53:13.670074: step 5450, loss 0.548615.
Train: 2018-07-31T00:53:13.841880: step 5451, loss 0.51969.
Train: 2018-07-31T00:53:13.982472: step 5452, loss 0.538267.
Train: 2018-07-31T00:53:14.138687: step 5453, loss 0.613006.
Train: 2018-07-31T00:53:14.263659: step 5454, loss 0.545551.
Train: 2018-07-31T00:53:14.419871: step 5455, loss 0.562466.
Train: 2018-07-31T00:53:14.560462: step 5456, loss 0.562445.
Train: 2018-07-31T00:53:14.701055: step 5457, loss 0.593928.
Train: 2018-07-31T00:53:14.841647: step 5458, loss 0.49565.
Train: 2018-07-31T00:53:14.997861: step 5459, loss 0.536635.
Train: 2018-07-31T00:53:15.138452: step 5460, loss 0.586259.
Test: 2018-07-31T00:53:15.388394: step 5460, loss 0.548426.
Train: 2018-07-31T00:53:15.575849: step 5461, loss 0.6059.
Train: 2018-07-31T00:53:15.716441: step 5462, loss 0.520181.
Train: 2018-07-31T00:53:15.872680: step 5463, loss 0.560702.
Train: 2018-07-31T00:53:16.013273: step 5464, loss 0.587176.
Train: 2018-07-31T00:53:16.153840: step 5465, loss 0.639372.
Train: 2018-07-31T00:53:16.310077: step 5466, loss 0.620484.
Train: 2018-07-31T00:53:16.450669: step 5467, loss 0.659964.
Train: 2018-07-31T00:53:16.591261: step 5468, loss 0.611616.
Train: 2018-07-31T00:53:16.747481: step 5469, loss 0.618993.
Train: 2018-07-31T00:53:16.903663: step 5470, loss 0.58685.
Test: 2018-07-31T00:53:17.138011: step 5470, loss 0.54952.
Train: 2018-07-31T00:53:17.294197: step 5471, loss 0.523977.
Train: 2018-07-31T00:53:17.434790: step 5472, loss 0.626616.
Train: 2018-07-31T00:53:17.575405: step 5473, loss 0.516461.
Train: 2018-07-31T00:53:17.715973: step 5474, loss 0.524494.
Train: 2018-07-31T00:53:17.856567: step 5475, loss 0.547862.
Train: 2018-07-31T00:53:17.997157: step 5476, loss 0.602161.
Train: 2018-07-31T00:53:18.153371: step 5477, loss 0.578854.
Train: 2018-07-31T00:53:18.293963: step 5478, loss 0.532766.
Train: 2018-07-31T00:53:18.434555: step 5479, loss 0.479262.
Train: 2018-07-31T00:53:18.575148: step 5480, loss 0.548135.
Test: 2018-07-31T00:53:18.809468: step 5480, loss 0.550625.
Train: 2018-07-31T00:53:18.965680: step 5481, loss 0.501834.
Train: 2018-07-31T00:53:19.106272: step 5482, loss 0.571145.
Train: 2018-07-31T00:53:19.262488: step 5483, loss 0.602213.
Train: 2018-07-31T00:53:19.403079: step 5484, loss 0.578774.
Train: 2018-07-31T00:53:19.559293: step 5485, loss 0.58664.
Train: 2018-07-31T00:53:19.699885: step 5486, loss 0.610245.
Train: 2018-07-31T00:53:19.840476: step 5487, loss 0.531647.
Train: 2018-07-31T00:53:19.981068: step 5488, loss 0.618073.
Train: 2018-07-31T00:53:20.121678: step 5489, loss 0.571106.
Train: 2018-07-31T00:53:20.262277: step 5490, loss 0.602628.
Test: 2018-07-31T00:53:20.512221: step 5490, loss 0.550053.
Train: 2018-07-31T00:53:20.652785: step 5491, loss 0.492534.
Train: 2018-07-31T00:53:20.793377: step 5492, loss 0.578915.
Train: 2018-07-31T00:53:20.933970: step 5493, loss 0.563067.
Train: 2018-07-31T00:53:21.074561: step 5494, loss 0.563102.
Train: 2018-07-31T00:53:21.215153: step 5495, loss 0.523709.
Train: 2018-07-31T00:53:21.371367: step 5496, loss 0.586592.
Train: 2018-07-31T00:53:21.511960: step 5497, loss 0.531568.
Train: 2018-07-31T00:53:21.652552: step 5498, loss 0.562962.
Train: 2018-07-31T00:53:21.793144: step 5499, loss 0.538775.
Train: 2018-07-31T00:53:21.949383: step 5500, loss 0.562932.
Test: 2018-07-31T00:53:22.183680: step 5500, loss 0.549288.
Train: 2018-07-31T00:53:22.933502: step 5501, loss 0.538286.
Train: 2018-07-31T00:53:23.089739: step 5502, loss 0.52263.
Train: 2018-07-31T00:53:23.245929: step 5503, loss 0.587189.
Train: 2018-07-31T00:53:23.386546: step 5504, loss 0.626489.
Train: 2018-07-31T00:53:23.527112: step 5505, loss 0.571856.
Train: 2018-07-31T00:53:23.667704: step 5506, loss 0.528873.
Train: 2018-07-31T00:53:23.823917: step 5507, loss 0.510897.
Train: 2018-07-31T00:53:23.964535: step 5508, loss 0.511842.
Train: 2018-07-31T00:53:24.105103: step 5509, loss 0.58241.
Train: 2018-07-31T00:53:24.245696: step 5510, loss 0.526993.
Test: 2018-07-31T00:53:24.480016: step 5510, loss 0.547873.
Train: 2018-07-31T00:53:24.620607: step 5511, loss 0.54349.
Train: 2018-07-31T00:53:24.761200: step 5512, loss 0.49673.
Train: 2018-07-31T00:53:24.917413: step 5513, loss 0.514574.
Train: 2018-07-31T00:53:25.058029: step 5514, loss 0.535286.
Train: 2018-07-31T00:53:25.198633: step 5515, loss 0.571631.
Train: 2018-07-31T00:53:25.354810: step 5516, loss 0.599342.
Train: 2018-07-31T00:53:25.495402: step 5517, loss 0.6347.
Train: 2018-07-31T00:53:25.635998: step 5518, loss 0.584131.
Train: 2018-07-31T00:53:25.792232: step 5519, loss 0.542284.
Train: 2018-07-31T00:53:25.932800: step 5520, loss 0.553485.
Test: 2018-07-31T00:53:26.167121: step 5520, loss 0.547686.
Train: 2018-07-31T00:53:26.307712: step 5521, loss 0.545312.
Train: 2018-07-31T00:53:26.448313: step 5522, loss 0.669135.
Train: 2018-07-31T00:53:26.604518: step 5523, loss 0.485937.
Train: 2018-07-31T00:53:26.745134: step 5524, loss 0.574927.
Train: 2018-07-31T00:53:26.885701: step 5525, loss 0.595723.
Train: 2018-07-31T00:53:27.041915: step 5526, loss 0.587524.
Train: 2018-07-31T00:53:27.182507: step 5527, loss 0.563592.
Train: 2018-07-31T00:53:27.323100: step 5528, loss 0.620424.
Train: 2018-07-31T00:53:27.463716: step 5529, loss 0.498316.
Train: 2018-07-31T00:53:27.604283: step 5530, loss 0.596326.
Test: 2018-07-31T00:53:27.854225: step 5530, loss 0.549289.
Train: 2018-07-31T00:53:27.994841: step 5531, loss 0.571578.
Train: 2018-07-31T00:53:28.151047: step 5532, loss 0.547122.
Train: 2018-07-31T00:53:28.291621: step 5533, loss 0.54757.
Train: 2018-07-31T00:53:28.432239: step 5534, loss 0.563096.
Train: 2018-07-31T00:53:28.572830: step 5535, loss 0.539282.
Train: 2018-07-31T00:53:28.729056: step 5536, loss 0.523489.
Train: 2018-07-31T00:53:28.869613: step 5537, loss 0.507968.
Train: 2018-07-31T00:53:29.010203: step 5538, loss 0.539219.
Train: 2018-07-31T00:53:29.150797: step 5539, loss 0.539111.
Train: 2018-07-31T00:53:29.291388: step 5540, loss 0.562156.
Test: 2018-07-31T00:53:29.525741: step 5540, loss 0.548823.
Train: 2018-07-31T00:53:29.666324: step 5541, loss 0.661514.
Train: 2018-07-31T00:53:29.822515: step 5542, loss 0.595508.
Train: 2018-07-31T00:53:29.963107: step 5543, loss 0.603498.
Train: 2018-07-31T00:53:30.103699: step 5544, loss 0.602352.
Train: 2018-07-31T00:53:30.244289: step 5545, loss 0.538814.
Train: 2018-07-31T00:53:30.400528: step 5546, loss 0.539242.
Train: 2018-07-31T00:53:30.556751: step 5547, loss 0.515514.
Train: 2018-07-31T00:53:30.697308: step 5548, loss 0.570938.
Train: 2018-07-31T00:53:30.837931: step 5549, loss 0.531262.
Train: 2018-07-31T00:53:30.994115: step 5550, loss 0.578838.
Test: 2018-07-31T00:53:31.228465: step 5550, loss 0.549634.
Train: 2018-07-31T00:53:31.384648: step 5551, loss 0.523159.
Train: 2018-07-31T00:53:31.525240: step 5552, loss 0.570924.
Train: 2018-07-31T00:53:31.665856: step 5553, loss 0.52297.
Train: 2018-07-31T00:53:31.806424: step 5554, loss 0.522819.
Train: 2018-07-31T00:53:31.947040: step 5555, loss 0.53063.
Train: 2018-07-31T00:53:32.103230: step 5556, loss 0.538509.
Train: 2018-07-31T00:53:32.243821: step 5557, loss 0.514009.
Train: 2018-07-31T00:53:32.384438: step 5558, loss 0.497363.
Train: 2018-07-31T00:53:32.540652: step 5559, loss 0.513302.
Train: 2018-07-31T00:53:32.681219: step 5560, loss 0.529312.
Test: 2018-07-31T00:53:32.931190: step 5560, loss 0.548433.
Train: 2018-07-31T00:53:33.071752: step 5561, loss 0.620257.
Train: 2018-07-31T00:53:33.212344: step 5562, loss 0.596036.
Train: 2018-07-31T00:53:33.352961: step 5563, loss 0.512038.
Train: 2018-07-31T00:53:33.493529: step 5564, loss 0.613139.
Train: 2018-07-31T00:53:33.649743: step 5565, loss 0.578941.
Train: 2018-07-31T00:53:33.790334: step 5566, loss 0.614165.
Train: 2018-07-31T00:53:33.930927: step 5567, loss 0.537361.
Train: 2018-07-31T00:53:34.087141: step 5568, loss 0.579367.
Train: 2018-07-31T00:53:34.227733: step 5569, loss 0.570544.
Train: 2018-07-31T00:53:34.368325: step 5570, loss 0.545456.
Test: 2018-07-31T00:53:34.602675: step 5570, loss 0.548267.
Train: 2018-07-31T00:53:34.758882: step 5571, loss 0.638015.
Train: 2018-07-31T00:53:34.899451: step 5572, loss 0.511988.
Train: 2018-07-31T00:53:35.040043: step 5573, loss 0.587604.
Train: 2018-07-31T00:53:35.180635: step 5574, loss 0.612608.
Train: 2018-07-31T00:53:35.321250: step 5575, loss 0.545747.
Train: 2018-07-31T00:53:35.461842: step 5576, loss 0.604015.
Train: 2018-07-31T00:53:35.602439: step 5577, loss 0.529327.
Train: 2018-07-31T00:53:35.758625: step 5578, loss 0.562488.
Train: 2018-07-31T00:53:35.899217: step 5579, loss 0.579009.
Train: 2018-07-31T00:53:36.039808: step 5580, loss 0.578991.
Test: 2018-07-31T00:53:36.289750: step 5580, loss 0.548789.
Train: 2018-07-31T00:53:36.430340: step 5581, loss 0.521475.
Train: 2018-07-31T00:53:36.586556: step 5582, loss 0.554353.
Train: 2018-07-31T00:53:36.727145: step 5583, loss 0.570764.
Train: 2018-07-31T00:53:36.867765: step 5584, loss 0.587138.
Train: 2018-07-31T00:53:37.023971: step 5585, loss 0.570769.
Train: 2018-07-31T00:53:37.164569: step 5586, loss 0.529974.
Train: 2018-07-31T00:53:37.305160: step 5587, loss 0.632201.
Train: 2018-07-31T00:53:37.445728: step 5588, loss 0.554512.
Train: 2018-07-31T00:53:37.586338: step 5589, loss 0.570787.
Train: 2018-07-31T00:53:37.726913: step 5590, loss 0.489743.
Test: 2018-07-31T00:53:37.961263: step 5590, loss 0.549113.
Train: 2018-07-31T00:53:38.117471: step 5591, loss 0.595111.
Train: 2018-07-31T00:53:38.273672: step 5592, loss 0.578897.
Train: 2018-07-31T00:53:38.414252: step 5593, loss 0.546521.
Train: 2018-07-31T00:53:38.554843: step 5594, loss 0.522264.
Train: 2018-07-31T00:53:38.695460: step 5595, loss 0.489851.
Train: 2018-07-31T00:53:38.851650: step 5596, loss 0.587018.
Train: 2018-07-31T00:53:38.992242: step 5597, loss 0.62767.
Train: 2018-07-31T00:53:39.132833: step 5598, loss 0.546408.
Train: 2018-07-31T00:53:39.273435: step 5599, loss 0.570785.
Train: 2018-07-31T00:53:39.414017: step 5600, loss 0.562652.
Test: 2018-07-31T00:53:39.648339: step 5600, loss 0.549039.
Train: 2018-07-31T00:53:40.398162: step 5601, loss 0.554524.
Train: 2018-07-31T00:53:40.554375: step 5602, loss 0.521989.
Train: 2018-07-31T00:53:40.694968: step 5603, loss 0.619636.
Train: 2018-07-31T00:53:40.851182: step 5604, loss 0.521931.
Train: 2018-07-31T00:53:40.991798: step 5605, loss 0.595216.
Train: 2018-07-31T00:53:41.147986: step 5606, loss 0.570776.
Train: 2018-07-31T00:53:41.288578: step 5607, loss 0.58707.
Train: 2018-07-31T00:53:41.429176: step 5608, loss 0.53007.
Train: 2018-07-31T00:53:41.585408: step 5609, loss 0.538206.
Train: 2018-07-31T00:53:41.741598: step 5610, loss 0.5708.
Test: 2018-07-31T00:53:41.975948: step 5610, loss 0.548969.
Train: 2018-07-31T00:53:42.132132: step 5611, loss 0.529985.
Train: 2018-07-31T00:53:42.272723: step 5612, loss 0.578886.
Train: 2018-07-31T00:53:42.413362: step 5613, loss 0.505386.
Train: 2018-07-31T00:53:42.569528: step 5614, loss 0.562533.
Train: 2018-07-31T00:53:42.710159: step 5615, loss 0.505143.
Train: 2018-07-31T00:53:42.850713: step 5616, loss 0.512577.
Train: 2018-07-31T00:53:42.991329: step 5617, loss 0.462039.
Train: 2018-07-31T00:53:43.131922: step 5618, loss 0.519155.
Train: 2018-07-31T00:53:43.272513: step 5619, loss 0.59613.
Train: 2018-07-31T00:53:43.428703: step 5620, loss 0.606369.
Test: 2018-07-31T00:53:43.678678: step 5620, loss 0.547635.
Train: 2018-07-31T00:53:43.834882: step 5621, loss 0.597849.
Train: 2018-07-31T00:53:43.975450: step 5622, loss 0.56397.
Train: 2018-07-31T00:53:44.131687: step 5623, loss 0.545407.
Train: 2018-07-31T00:53:44.272272: step 5624, loss 0.553642.
Train: 2018-07-31T00:53:44.412848: step 5625, loss 0.537101.
Train: 2018-07-31T00:53:44.553463: step 5626, loss 0.552076.
Train: 2018-07-31T00:53:44.709651: step 5627, loss 0.543567.
Train: 2018-07-31T00:53:44.850269: step 5628, loss 0.535959.
Train: 2018-07-31T00:53:44.990860: step 5629, loss 0.527495.
Train: 2018-07-31T00:53:45.131453: step 5630, loss 0.614563.
Test: 2018-07-31T00:53:45.381371: step 5630, loss 0.547833.
Train: 2018-07-31T00:53:45.521963: step 5631, loss 0.63127.
Train: 2018-07-31T00:53:45.678176: step 5632, loss 0.492875.
Train: 2018-07-31T00:53:45.818792: step 5633, loss 0.563501.
Train: 2018-07-31T00:53:45.959406: step 5634, loss 0.511239.
Train: 2018-07-31T00:53:46.115574: step 5635, loss 0.545889.
Train: 2018-07-31T00:53:46.256190: step 5636, loss 0.528168.
Train: 2018-07-31T00:53:46.396756: step 5637, loss 0.477376.
Train: 2018-07-31T00:53:46.537373: step 5638, loss 0.69144.
Train: 2018-07-31T00:53:46.677942: step 5639, loss 0.578198.
Train: 2018-07-31T00:53:46.834154: step 5640, loss 0.640459.
Test: 2018-07-31T00:53:47.068475: step 5640, loss 0.548207.
Train: 2018-07-31T00:53:47.224688: step 5641, loss 0.553025.
Train: 2018-07-31T00:53:47.365281: step 5642, loss 0.570773.
Train: 2018-07-31T00:53:47.490276: step 5643, loss 0.529059.
Train: 2018-07-31T00:53:47.646466: step 5644, loss 0.512315.
Train: 2018-07-31T00:53:47.787057: step 5645, loss 0.57082.
Train: 2018-07-31T00:53:47.927649: step 5646, loss 0.620479.
Train: 2018-07-31T00:53:48.068266: step 5647, loss 0.579156.
Train: 2018-07-31T00:53:48.208857: step 5648, loss 0.587219.
Train: 2018-07-31T00:53:48.349425: step 5649, loss 0.562597.
Train: 2018-07-31T00:53:48.505664: step 5650, loss 0.537999.
Test: 2018-07-31T00:53:48.739989: step 5650, loss 0.548903.
Train: 2018-07-31T00:53:48.896172: step 5651, loss 0.570768.
Train: 2018-07-31T00:53:49.036789: step 5652, loss 0.562615.
Train: 2018-07-31T00:53:49.192978: step 5653, loss 0.530068.
Train: 2018-07-31T00:53:49.333570: step 5654, loss 0.513835.
Train: 2018-07-31T00:53:49.474162: step 5655, loss 0.619612.
Train: 2018-07-31T00:53:49.614754: step 5656, loss 0.595176.
Train: 2018-07-31T00:53:49.755370: step 5657, loss 0.546434.
Train: 2018-07-31T00:53:49.895937: step 5658, loss 0.546463.
Train: 2018-07-31T00:53:50.052151: step 5659, loss 0.546478.
Train: 2018-07-31T00:53:50.192743: step 5660, loss 0.562689.
Test: 2018-07-31T00:53:50.442686: step 5660, loss 0.549115.
Train: 2018-07-31T00:53:50.583301: step 5661, loss 0.570794.
Train: 2018-07-31T00:53:50.739491: step 5662, loss 0.578899.
Train: 2018-07-31T00:53:50.880084: step 5663, loss 0.514102.
Train: 2018-07-31T00:53:51.020676: step 5664, loss 0.489741.
Train: 2018-07-31T00:53:51.145671: step 5665, loss 0.53016.
Train: 2018-07-31T00:53:51.317479: step 5666, loss 0.554478.
Train: 2018-07-31T00:53:51.458097: step 5667, loss 0.570768.
Train: 2018-07-31T00:53:51.614286: step 5668, loss 0.513422.
Train: 2018-07-31T00:53:51.754902: step 5669, loss 0.546104.
Train: 2018-07-31T00:53:51.895469: step 5670, loss 0.496552.
Test: 2018-07-31T00:53:52.145415: step 5670, loss 0.548607.
Train: 2018-07-31T00:53:52.286030: step 5671, loss 0.579038.
Train: 2018-07-31T00:53:52.442218: step 5672, loss 0.55414.
Train: 2018-07-31T00:53:52.567188: step 5673, loss 0.562429.
Train: 2018-07-31T00:53:52.723425: step 5674, loss 0.604209.
Train: 2018-07-31T00:53:52.863994: step 5675, loss 0.554033.
Train: 2018-07-31T00:53:53.004609: step 5676, loss 0.545632.
Train: 2018-07-31T00:53:53.160831: step 5677, loss 0.612755.
Train: 2018-07-31T00:53:53.301416: step 5678, loss 0.520419.
Train: 2018-07-31T00:53:53.441982: step 5679, loss 0.705202.
Train: 2018-07-31T00:53:53.582599: step 5680, loss 0.562399.
Test: 2018-07-31T00:53:53.816921: step 5680, loss 0.548414.
Train: 2018-07-31T00:53:53.973109: step 5681, loss 0.645996.
Train: 2018-07-31T00:53:54.129320: step 5682, loss 0.53747.
Train: 2018-07-31T00:53:54.285559: step 5683, loss 0.562463.
Train: 2018-07-31T00:53:54.426151: step 5684, loss 0.521141.
Train: 2018-07-31T00:53:54.582365: step 5685, loss 0.636781.
Train: 2018-07-31T00:53:54.738555: step 5686, loss 0.546086.
Train: 2018-07-31T00:53:54.879148: step 5687, loss 0.603565.
Train: 2018-07-31T00:53:55.019763: step 5688, loss 0.562597.
Train: 2018-07-31T00:53:55.160330: step 5689, loss 0.562632.
Train: 2018-07-31T00:53:55.300921: step 5690, loss 0.570786.
Test: 2018-07-31T00:53:55.550898: step 5690, loss 0.549133.
Train: 2018-07-31T00:53:55.691456: step 5691, loss 0.578897.
Train: 2018-07-31T00:53:55.832073: step 5692, loss 0.546581.
Train: 2018-07-31T00:53:55.972664: step 5693, loss 0.522468.
Train: 2018-07-31T00:53:56.113256: step 5694, loss 0.586928.
Train: 2018-07-31T00:53:56.253825: step 5695, loss 0.611035.
Train: 2018-07-31T00:53:56.394443: step 5696, loss 0.522713.
Train: 2018-07-31T00:53:56.550630: step 5697, loss 0.562838.
Train: 2018-07-31T00:53:56.691221: step 5698, loss 0.546835.
Train: 2018-07-31T00:53:56.831823: step 5699, loss 0.522826.
Train: 2018-07-31T00:53:56.972431: step 5700, loss 0.610915.
Test: 2018-07-31T00:53:57.206726: step 5700, loss 0.549431.
Train: 2018-07-31T00:53:57.956551: step 5701, loss 0.530806.
Train: 2018-07-31T00:53:58.097142: step 5702, loss 0.530779.
Train: 2018-07-31T00:53:58.253357: step 5703, loss 0.618996.
Train: 2018-07-31T00:53:58.378327: step 5704, loss 0.602951.
Train: 2018-07-31T00:53:58.518918: step 5705, loss 0.530759.
Train: 2018-07-31T00:53:58.675133: step 5706, loss 0.57085.
Train: 2018-07-31T00:53:58.815725: step 5707, loss 0.554817.
Train: 2018-07-31T00:53:58.956341: step 5708, loss 0.602926.
Train: 2018-07-31T00:53:59.096908: step 5709, loss 0.586881.
Train: 2018-07-31T00:53:59.253121: step 5710, loss 0.538838.
Test: 2018-07-31T00:53:59.487467: step 5710, loss 0.549456.
Train: 2018-07-31T00:53:59.643679: step 5711, loss 0.578864.
Train: 2018-07-31T00:53:59.799870: step 5712, loss 0.562867.
Train: 2018-07-31T00:53:59.924839: step 5713, loss 0.602846.
Train: 2018-07-31T00:54:00.081053: step 5714, loss 0.674675.
Train: 2018-07-31T00:54:00.221646: step 5715, loss 0.570904.
Train: 2018-07-31T00:54:00.362262: step 5716, loss 0.499589.
Train: 2018-07-31T00:54:00.518451: step 5717, loss 0.626355.
Train: 2018-07-31T00:54:00.659059: step 5718, loss 0.523599.
Train: 2018-07-31T00:54:00.799659: step 5719, loss 0.484246.
Train: 2018-07-31T00:54:00.940251: step 5720, loss 0.681471.
Test: 2018-07-31T00:54:01.190195: step 5720, loss 0.549916.
Train: 2018-07-31T00:54:01.330785: step 5721, loss 0.555231.
Train: 2018-07-31T00:54:01.471377: step 5722, loss 0.563132.
Train: 2018-07-31T00:54:01.611944: step 5723, loss 0.610311.
Train: 2018-07-31T00:54:01.752536: step 5724, loss 0.563183.
Train: 2018-07-31T00:54:01.893127: step 5725, loss 0.547543.
Train: 2018-07-31T00:54:02.033721: step 5726, loss 0.547568.
Train: 2018-07-31T00:54:02.174337: step 5727, loss 0.563225.
Train: 2018-07-31T00:54:02.314905: step 5728, loss 0.610197.
Train: 2018-07-31T00:54:02.455521: step 5729, loss 0.586705.
Train: 2018-07-31T00:54:02.596090: step 5730, loss 0.571072.
Test: 2018-07-31T00:54:02.846030: step 5730, loss 0.550209.
Train: 2018-07-31T00:54:02.986647: step 5731, loss 0.571083.
Train: 2018-07-31T00:54:03.127214: step 5732, loss 0.516494.
Train: 2018-07-31T00:54:03.267806: step 5733, loss 0.555475.
Train: 2018-07-31T00:54:03.408423: step 5734, loss 0.547634.
Train: 2018-07-31T00:54:03.549008: step 5735, loss 0.571056.
Train: 2018-07-31T00:54:03.705229: step 5736, loss 0.524022.
Train: 2018-07-31T00:54:03.845798: step 5737, loss 0.586727.
Train: 2018-07-31T00:54:03.986413: step 5738, loss 0.512757.
Train: 2018-07-31T00:54:04.127011: step 5739, loss 0.531494.
Train: 2018-07-31T00:54:04.267571: step 5740, loss 0.539238.
Test: 2018-07-31T00:54:04.517538: step 5740, loss 0.549619.
Train: 2018-07-31T00:54:04.658130: step 5741, loss 0.570902.
Train: 2018-07-31T00:54:04.798726: step 5742, loss 0.570877.
Train: 2018-07-31T00:54:04.939314: step 5743, loss 0.538809.
Train: 2018-07-31T00:54:05.079882: step 5744, loss 0.546713.
Train: 2018-07-31T00:54:05.236120: step 5745, loss 0.595005.
Train: 2018-07-31T00:54:05.376715: step 5746, loss 0.578884.
Train: 2018-07-31T00:54:05.517304: step 5747, loss 0.513975.
Train: 2018-07-31T00:54:05.657871: step 5748, loss 0.603119.
Train: 2018-07-31T00:54:05.814085: step 5749, loss 0.546351.
Train: 2018-07-31T00:54:05.954702: step 5750, loss 0.588001.
Test: 2018-07-31T00:54:06.204649: step 5750, loss 0.548714.
Train: 2018-07-31T00:54:06.345210: step 5751, loss 0.480196.
Train: 2018-07-31T00:54:06.485827: step 5752, loss 0.537507.
Train: 2018-07-31T00:54:06.626413: step 5753, loss 0.537591.
Train: 2018-07-31T00:54:06.782609: step 5754, loss 0.51168.
Train: 2018-07-31T00:54:06.923201: step 5755, loss 0.561275.
Train: 2018-07-31T00:54:07.063818: step 5756, loss 0.554166.
Train: 2018-07-31T00:54:07.204385: step 5757, loss 0.588413.
Train: 2018-07-31T00:54:07.345001: step 5758, loss 0.605817.
Train: 2018-07-31T00:54:07.485593: step 5759, loss 0.573617.
Train: 2018-07-31T00:54:07.641782: step 5760, loss 0.622979.
Test: 2018-07-31T00:54:07.876102: step 5760, loss 0.548143.
Train: 2018-07-31T00:54:08.032315: step 5761, loss 0.510912.
Train: 2018-07-31T00:54:08.172907: step 5762, loss 0.61361.
Train: 2018-07-31T00:54:08.313526: step 5763, loss 0.554112.
Train: 2018-07-31T00:54:08.454116: step 5764, loss 0.595553.
Train: 2018-07-31T00:54:08.594683: step 5765, loss 0.64523.
Train: 2018-07-31T00:54:08.750933: step 5766, loss 0.554291.
Train: 2018-07-31T00:54:08.891490: step 5767, loss 0.472346.
Train: 2018-07-31T00:54:09.032083: step 5768, loss 0.546187.
Train: 2018-07-31T00:54:09.172675: step 5769, loss 0.546205.
Train: 2018-07-31T00:54:09.313267: step 5770, loss 0.546211.
Test: 2018-07-31T00:54:09.547586: step 5770, loss 0.54887.
Train: 2018-07-31T00:54:09.688195: step 5771, loss 0.562579.
Train: 2018-07-31T00:54:09.844393: step 5772, loss 0.636258.
Train: 2018-07-31T00:54:09.984984: step 5773, loss 0.538074.
Train: 2018-07-31T00:54:10.141197: step 5774, loss 0.57077.
Train: 2018-07-31T00:54:10.281789: step 5775, loss 0.5463.
Train: 2018-07-31T00:54:10.422382: step 5776, loss 0.587082.
Train: 2018-07-31T00:54:10.562973: step 5777, loss 0.505622.
Train: 2018-07-31T00:54:10.703566: step 5778, loss 0.59522.
Train: 2018-07-31T00:54:10.844182: step 5779, loss 0.570777.
Train: 2018-07-31T00:54:10.984749: step 5780, loss 0.587059.
Test: 2018-07-31T00:54:11.234691: step 5780, loss 0.549034.
Train: 2018-07-31T00:54:11.375284: step 5781, loss 0.562652.
Train: 2018-07-31T00:54:11.515899: step 5782, loss 0.619526.
Train: 2018-07-31T00:54:11.656468: step 5783, loss 0.595111.
Train: 2018-07-31T00:54:11.812681: step 5784, loss 0.522301.
Train: 2018-07-31T00:54:11.953273: step 5785, loss 0.522378.
Train: 2018-07-31T00:54:12.093866: step 5786, loss 0.562743.
Train: 2018-07-31T00:54:12.234474: step 5787, loss 0.586952.
Train: 2018-07-31T00:54:12.375050: step 5788, loss 0.530502.
Train: 2018-07-31T00:54:12.500045: step 5789, loss 0.570816.
Train: 2018-07-31T00:54:12.640611: step 5790, loss 0.586945.
Test: 2018-07-31T00:54:12.890553: step 5790, loss 0.549257.
Train: 2018-07-31T00:54:13.031145: step 5791, loss 0.570818.
Train: 2018-07-31T00:54:13.187359: step 5792, loss 0.562766.
Train: 2018-07-31T00:54:13.327951: step 5793, loss 0.546666.
Train: 2018-07-31T00:54:13.468567: step 5794, loss 0.53861.
Train: 2018-07-31T00:54:13.609169: step 5795, loss 0.586936.
Train: 2018-07-31T00:54:13.765349: step 5796, loss 0.522458.
Train: 2018-07-31T00:54:13.921562: step 5797, loss 0.50626.
Train: 2018-07-31T00:54:14.062153: step 5798, loss 0.522271.
Train: 2018-07-31T00:54:14.187124: step 5799, loss 0.587016.
Train: 2018-07-31T00:54:14.343338: step 5800, loss 0.489446.
Test: 2018-07-31T00:54:14.593280: step 5800, loss 0.548933.
Train: 2018-07-31T00:54:15.327484: step 5801, loss 0.521784.
Train: 2018-07-31T00:54:15.468092: step 5802, loss 0.521558.
Train: 2018-07-31T00:54:15.608691: step 5803, loss 0.603723.
Train: 2018-07-31T00:54:15.749258: step 5804, loss 0.579028.
Train: 2018-07-31T00:54:15.889883: step 5805, loss 0.554176.
Train: 2018-07-31T00:54:16.046064: step 5806, loss 0.520907.
Train: 2018-07-31T00:54:16.202276: step 5807, loss 0.612436.
Train: 2018-07-31T00:54:16.342895: step 5808, loss 0.503999.
Train: 2018-07-31T00:54:16.483462: step 5809, loss 0.612607.
Train: 2018-07-31T00:54:16.624078: step 5810, loss 0.528909.
Test: 2018-07-31T00:54:16.873996: step 5810, loss 0.548344.
Train: 2018-07-31T00:54:17.014587: step 5811, loss 0.554025.
Train: 2018-07-31T00:54:17.155179: step 5812, loss 0.570792.
Train: 2018-07-31T00:54:17.295772: step 5813, loss 0.528733.
Train: 2018-07-31T00:54:17.436389: step 5814, loss 0.48659.
Train: 2018-07-31T00:54:17.592577: step 5815, loss 0.562386.
Train: 2018-07-31T00:54:17.748789: step 5816, loss 0.587749.
Train: 2018-07-31T00:54:17.889399: step 5817, loss 0.55387.
Train: 2018-07-31T00:54:18.045597: step 5818, loss 0.502937.
Train: 2018-07-31T00:54:18.186188: step 5819, loss 0.587879.
Train: 2018-07-31T00:54:18.311159: step 5820, loss 0.596387.
Test: 2018-07-31T00:54:18.561100: step 5820, loss 0.548082.
Train: 2018-07-31T00:54:18.717314: step 5821, loss 0.579363.
Train: 2018-07-31T00:54:18.873551: step 5822, loss 0.553815.
Train: 2018-07-31T00:54:19.014119: step 5823, loss 0.579372.
Train: 2018-07-31T00:54:19.154710: step 5824, loss 0.57085.
Train: 2018-07-31T00:54:19.310926: step 5825, loss 0.562313.
Train: 2018-07-31T00:54:19.451516: step 5826, loss 0.536942.
Train: 2018-07-31T00:54:19.592133: step 5827, loss 0.553875.
Train: 2018-07-31T00:54:19.732737: step 5828, loss 0.570789.
Train: 2018-07-31T00:54:19.873293: step 5829, loss 0.520078.
Train: 2018-07-31T00:54:20.013913: step 5830, loss 0.621489.
Test: 2018-07-31T00:54:20.263827: step 5830, loss 0.548237.
Train: 2018-07-31T00:54:20.404419: step 5831, loss 0.536993.
Train: 2018-07-31T00:54:20.545010: step 5832, loss 0.612933.
Train: 2018-07-31T00:54:20.701249: step 5833, loss 0.520338.
Train: 2018-07-31T00:54:20.841832: step 5834, loss 0.511942.
Train: 2018-07-31T00:54:20.982433: step 5835, loss 0.612852.
Train: 2018-07-31T00:54:21.138622: step 5836, loss 0.587533.
Train: 2018-07-31T00:54:21.279213: step 5837, loss 0.679746.
Train: 2018-07-31T00:54:21.419823: step 5838, loss 0.470874.
Train: 2018-07-31T00:54:21.560398: step 5839, loss 0.537541.
Train: 2018-07-31T00:54:21.701007: step 5840, loss 0.562506.
Test: 2018-07-31T00:54:21.950962: step 5840, loss 0.548599.
Train: 2018-07-31T00:54:22.091548: step 5841, loss 0.529331.
Train: 2018-07-31T00:54:22.232115: step 5842, loss 0.545923.
Train: 2018-07-31T00:54:22.372708: step 5843, loss 0.521103.
Train: 2018-07-31T00:54:22.513326: step 5844, loss 0.554187.
Train: 2018-07-31T00:54:22.653891: step 5845, loss 0.537605.
Train: 2018-07-31T00:54:22.810129: step 5846, loss 0.537544.
Train: 2018-07-31T00:54:22.950697: step 5847, loss 0.62064.
Train: 2018-07-31T00:54:23.106912: step 5848, loss 0.620598.
Train: 2018-07-31T00:54:23.247502: step 5849, loss 0.504397.
Train: 2018-07-31T00:54:23.403740: step 5850, loss 0.554214.
Test: 2018-07-31T00:54:23.638070: step 5850, loss 0.548572.
Train: 2018-07-31T00:54:23.794251: step 5851, loss 0.545897.
Train: 2018-07-31T00:54:23.934842: step 5852, loss 0.529321.
Train: 2018-07-31T00:54:24.059837: step 5853, loss 0.587335.
Train: 2018-07-31T00:54:24.216025: step 5854, loss 0.603944.
Train: 2018-07-31T00:54:24.356618: step 5855, loss 0.587366.
Train: 2018-07-31T00:54:24.497209: step 5856, loss 0.612137.
Train: 2018-07-31T00:54:24.637821: step 5857, loss 0.579021.
Train: 2018-07-31T00:54:24.778394: step 5858, loss 0.562527.
Train: 2018-07-31T00:54:24.919010: step 5859, loss 0.562556.
Train: 2018-07-31T00:54:25.075200: step 5860, loss 0.570771.
Test: 2018-07-31T00:54:25.309519: step 5860, loss 0.548888.
Train: 2018-07-31T00:54:25.450129: step 5861, loss 0.513511.
Train: 2018-07-31T00:54:25.590729: step 5862, loss 0.619801.
Train: 2018-07-31T00:54:25.746919: step 5863, loss 0.635996.
Train: 2018-07-31T00:54:25.887510: step 5864, loss 0.562664.
Train: 2018-07-31T00:54:26.043723: step 5865, loss 0.58699.
Train: 2018-07-31T00:54:26.184339: step 5866, loss 0.578882.
Train: 2018-07-31T00:54:26.324906: step 5867, loss 0.619061.
Train: 2018-07-31T00:54:26.481119: step 5868, loss 0.56286.
Train: 2018-07-31T00:54:26.621713: step 5869, loss 0.53104.
Train: 2018-07-31T00:54:26.762305: step 5870, loss 0.547064.
Test: 2018-07-31T00:54:27.012246: step 5870, loss 0.549704.
Train: 2018-07-31T00:54:27.152839: step 5871, loss 0.523323.
Train: 2018-07-31T00:54:27.293431: step 5872, loss 0.578859.
Train: 2018-07-31T00:54:27.449643: step 5873, loss 0.578859.
Train: 2018-07-31T00:54:27.590235: step 5874, loss 0.555112.
Train: 2018-07-31T00:54:27.746450: step 5875, loss 0.563036.
Train: 2018-07-31T00:54:27.887067: step 5876, loss 0.54722.
Train: 2018-07-31T00:54:28.043255: step 5877, loss 0.586773.
Train: 2018-07-31T00:54:28.183848: step 5878, loss 0.594683.
Train: 2018-07-31T00:54:28.324439: step 5879, loss 0.618387.
Train: 2018-07-31T00:54:28.480653: step 5880, loss 0.618313.
Test: 2018-07-31T00:54:28.714974: step 5880, loss 0.54996.
Train: 2018-07-31T00:54:28.855582: step 5881, loss 0.571002.
Train: 2018-07-31T00:54:29.011778: step 5882, loss 0.516109.
Train: 2018-07-31T00:54:29.136774: step 5883, loss 0.594552.
Train: 2018-07-31T00:54:29.277367: step 5884, loss 0.508446.
Train: 2018-07-31T00:54:29.433555: step 5885, loss 0.547567.
Train: 2018-07-31T00:54:29.589792: step 5886, loss 0.563207.
Train: 2018-07-31T00:54:29.745981: step 5887, loss 0.523974.
Train: 2018-07-31T00:54:29.886597: step 5888, loss 0.57887.
Train: 2018-07-31T00:54:30.027164: step 5889, loss 0.579916.
Train: 2018-07-31T00:54:30.167782: step 5890, loss 0.507917.
Test: 2018-07-31T00:54:30.402106: step 5890, loss 0.549814.
Train: 2018-07-31T00:54:30.558292: step 5891, loss 0.578861.
Train: 2018-07-31T00:54:30.698883: step 5892, loss 0.515482.
Train: 2018-07-31T00:54:30.839499: step 5893, loss 0.507321.
Train: 2018-07-31T00:54:30.995689: step 5894, loss 0.618783.
Train: 2018-07-31T00:54:31.136324: step 5895, loss 0.618897.
Train: 2018-07-31T00:54:31.292494: step 5896, loss 0.610932.
Train: 2018-07-31T00:54:31.433088: step 5897, loss 0.578867.
Train: 2018-07-31T00:54:31.589301: step 5898, loss 0.562838.
Train: 2018-07-31T00:54:31.729891: step 5899, loss 0.586878.
Train: 2018-07-31T00:54:31.870485: step 5900, loss 0.570857.
Test: 2018-07-31T00:54:32.120455: step 5900, loss 0.549459.
Train: 2018-07-31T00:54:32.839032: step 5901, loss 0.594867.
Train: 2018-07-31T00:54:32.995221: step 5902, loss 0.530915.
Train: 2018-07-31T00:54:33.135813: step 5903, loss 0.594839.
Train: 2018-07-31T00:54:33.276406: step 5904, loss 0.46712.
Train: 2018-07-31T00:54:33.416996: step 5905, loss 0.546884.
Train: 2018-07-31T00:54:33.557613: step 5906, loss 0.610906.
Train: 2018-07-31T00:54:33.698204: step 5907, loss 0.578866.
Train: 2018-07-31T00:54:33.854394: step 5908, loss 0.538776.
Train: 2018-07-31T00:54:33.995003: step 5909, loss 0.530714.
Train: 2018-07-31T00:54:34.151200: step 5910, loss 0.602992.
Test: 2018-07-31T00:54:34.401142: step 5910, loss 0.549311.
Train: 2018-07-31T00:54:34.541757: step 5911, loss 0.52256.
Train: 2018-07-31T00:54:34.682349: step 5912, loss 0.562763.
Train: 2018-07-31T00:54:34.822941: step 5913, loss 0.530461.
Train: 2018-07-31T00:54:34.963534: step 5914, loss 0.562715.
Train: 2018-07-31T00:54:35.119747: step 5915, loss 0.538376.
Train: 2018-07-31T00:54:35.260332: step 5916, loss 0.52204.
Train: 2018-07-31T00:54:35.400931: step 5917, loss 0.562625.
Train: 2018-07-31T00:54:35.541500: step 5918, loss 0.546248.
Train: 2018-07-31T00:54:35.682115: step 5919, loss 0.529776.
Train: 2018-07-31T00:54:35.838328: step 5920, loss 0.578983.
Test: 2018-07-31T00:54:36.072627: step 5920, loss 0.548699.
Train: 2018-07-31T00:54:36.228837: step 5921, loss 0.56251.
Train: 2018-07-31T00:54:36.369454: step 5922, loss 0.5129.
Train: 2018-07-31T00:54:36.510047: step 5923, loss 0.554176.
Train: 2018-07-31T00:54:36.666260: step 5924, loss 0.57076.
Train: 2018-07-31T00:54:36.806852: step 5925, loss 0.545762.
Train: 2018-07-31T00:54:36.963041: step 5926, loss 0.545708.
Train: 2018-07-31T00:54:37.103658: step 5927, loss 0.562403.
Train: 2018-07-31T00:54:37.259848: step 5928, loss 0.537221.
Train: 2018-07-31T00:54:37.400463: step 5929, loss 0.562382.
Train: 2018-07-31T00:54:37.541055: step 5930, loss 0.520255.
Test: 2018-07-31T00:54:37.790997: step 5930, loss 0.548222.
Train: 2018-07-31T00:54:37.931589: step 5931, loss 0.55392.
Train: 2018-07-31T00:54:38.072157: step 5932, loss 0.562358.
Train: 2018-07-31T00:54:38.212758: step 5933, loss 0.57083.
Train: 2018-07-31T00:54:38.353341: step 5934, loss 0.570835.
Train: 2018-07-31T00:54:38.493934: step 5935, loss 0.579335.
Train: 2018-07-31T00:54:38.634525: step 5936, loss 0.528373.
Train: 2018-07-31T00:54:38.775116: step 5937, loss 0.613339.
Train: 2018-07-31T00:54:38.931330: step 5938, loss 0.528382.
Train: 2018-07-31T00:54:39.071922: step 5939, loss 0.655736.
Train: 2018-07-31T00:54:39.228135: step 5940, loss 0.562355.
Test: 2018-07-31T00:54:39.462455: step 5940, loss 0.548213.
Train: 2018-07-31T00:54:39.618669: step 5941, loss 0.528567.
Train: 2018-07-31T00:54:39.774882: step 5942, loss 0.528627.
Train: 2018-07-31T00:54:39.915499: step 5943, loss 0.579228.
Train: 2018-07-31T00:54:40.056066: step 5944, loss 0.537126.
Train: 2018-07-31T00:54:40.196658: step 5945, loss 0.520329.
Train: 2018-07-31T00:54:40.337249: step 5946, loss 0.511914.
Train: 2018-07-31T00:54:40.493465: step 5947, loss 0.579216.
Train: 2018-07-31T00:54:40.618435: step 5948, loss 0.562374.
Train: 2018-07-31T00:54:40.759027: step 5949, loss 0.612922.
Train: 2018-07-31T00:54:40.899619: step 5950, loss 0.579209.
Test: 2018-07-31T00:54:41.149591: step 5950, loss 0.548314.
Train: 2018-07-31T00:54:41.290153: step 5951, loss 0.511973.
Train: 2018-07-31T00:54:41.446401: step 5952, loss 0.537192.
Train: 2018-07-31T00:54:41.586982: step 5953, loss 0.511995.
Train: 2018-07-31T00:54:41.743173: step 5954, loss 0.553975.
Train: 2018-07-31T00:54:41.883764: step 5955, loss 0.562378.
Train: 2018-07-31T00:54:42.039977: step 5956, loss 0.621322.
Train: 2018-07-31T00:54:42.180569: step 5957, loss 0.596033.
Train: 2018-07-31T00:54:42.321163: step 5958, loss 0.595984.
Train: 2018-07-31T00:54:42.446133: step 5959, loss 0.503748.
Train: 2018-07-31T00:54:42.617968: step 5960, loss 0.612626.
Test: 2018-07-31T00:54:42.852317: step 5960, loss 0.54843.
Train: 2018-07-31T00:54:43.008501: step 5961, loss 0.595825.
Train: 2018-07-31T00:54:43.149097: step 5962, loss 0.604075.
Train: 2018-07-31T00:54:43.289709: step 5963, loss 0.52927.
Train: 2018-07-31T00:54:43.445898: step 5964, loss 0.545928.
Train: 2018-07-31T00:54:43.602111: step 5965, loss 0.479907.
Train: 2018-07-31T00:54:43.758362: step 5966, loss 0.612051.
Train: 2018-07-31T00:54:43.898917: step 5967, loss 0.529512.
Train: 2018-07-31T00:54:44.039534: step 5968, loss 0.628477.
Train: 2018-07-31T00:54:44.195722: step 5969, loss 0.554298.
Train: 2018-07-31T00:54:44.351971: step 5970, loss 0.505027.
Test: 2018-07-31T00:54:44.586287: step 5970, loss 0.548785.
Train: 2018-07-31T00:54:44.726872: step 5971, loss 0.562544.
Train: 2018-07-31T00:54:44.883060: step 5972, loss 0.52969.
Train: 2018-07-31T00:54:45.023652: step 5973, loss 0.554321.
Train: 2018-07-31T00:54:45.179891: step 5974, loss 0.537861.
Train: 2018-07-31T00:54:45.336081: step 5975, loss 0.578991.
Train: 2018-07-31T00:54:45.476696: step 5976, loss 0.61195.
Train: 2018-07-31T00:54:45.617265: step 5977, loss 0.513126.
Train: 2018-07-31T00:54:45.773479: step 5978, loss 0.611942.
Train: 2018-07-31T00:54:45.914069: step 5979, loss 0.59545.
Train: 2018-07-31T00:54:46.054663: step 5980, loss 0.521449.
Test: 2018-07-31T00:54:46.289016: step 5980, loss 0.548787.
Train: 2018-07-31T00:54:46.445196: step 5981, loss 0.57076.
Train: 2018-07-31T00:54:46.585788: step 5982, loss 0.620018.
Train: 2018-07-31T00:54:46.726380: step 5983, loss 0.546182.
Train: 2018-07-31T00:54:46.866973: step 5984, loss 0.603495.
Train: 2018-07-31T00:54:47.007588: step 5985, loss 0.562607.
Train: 2018-07-31T00:54:47.148155: step 5986, loss 0.570776.
Train: 2018-07-31T00:54:47.304393: step 5987, loss 0.587044.
Train: 2018-07-31T00:54:47.460584: step 5988, loss 0.62757.
Train: 2018-07-31T00:54:47.616823: step 5989, loss 0.578888.
Train: 2018-07-31T00:54:47.773034: step 5990, loss 0.619134.
Test: 2018-07-31T00:54:48.007363: step 5990, loss 0.549416.
Train: 2018-07-31T00:54:48.163569: step 5991, loss 0.562838.
Train: 2018-07-31T00:54:48.304135: step 5992, loss 0.562898.
Train: 2018-07-31T00:54:48.444780: step 5993, loss 0.547048.
Train: 2018-07-31T00:54:48.585343: step 5994, loss 0.578859.
Train: 2018-07-31T00:54:48.741557: step 5995, loss 0.531404.
Train: 2018-07-31T00:54:48.882125: step 5996, loss 0.531475.
Train: 2018-07-31T00:54:49.038339: step 5997, loss 0.594652.
Train: 2018-07-31T00:54:49.178955: step 5998, loss 0.594639.
Train: 2018-07-31T00:54:49.319541: step 5999, loss 0.578866.
Train: 2018-07-31T00:54:49.460139: step 6000, loss 0.586733.
Test: 2018-07-31T00:54:49.705958: step 6000, loss 0.550028.
Train: 2018-07-31T00:54:50.502670: step 6001, loss 0.633819.
Train: 2018-07-31T00:54:50.658859: step 6002, loss 0.563234.
Train: 2018-07-31T00:54:50.815097: step 6003, loss 0.586694.
Train: 2018-07-31T00:54:50.955689: step 6004, loss 0.454408.
Train: 2018-07-31T00:54:51.111877: step 6005, loss 0.547758.
Train: 2018-07-31T00:54:51.252470: step 6006, loss 0.602278.
Train: 2018-07-31T00:54:51.408683: step 6007, loss 0.461943.
Train: 2018-07-31T00:54:51.549276: step 6008, loss 0.563241.
Train: 2018-07-31T00:54:51.705489: step 6009, loss 0.531805.
Train: 2018-07-31T00:54:51.846081: step 6010, loss 0.507998.
Test: 2018-07-31T00:54:52.080431: step 6010, loss 0.549781.
Train: 2018-07-31T00:54:52.236655: step 6011, loss 0.555121.
Train: 2018-07-31T00:54:52.377206: step 6012, loss 0.570907.
Train: 2018-07-31T00:54:52.533420: step 6013, loss 0.626769.
Train: 2018-07-31T00:54:52.674013: step 6014, loss 0.522842.
Train: 2018-07-31T00:54:52.814621: step 6015, loss 0.570841.
Train: 2018-07-31T00:54:52.970841: step 6016, loss 0.578876.
Train: 2018-07-31T00:54:53.111435: step 6017, loss 0.578882.
Train: 2018-07-31T00:54:53.267653: step 6018, loss 0.570807.
Train: 2018-07-31T00:54:53.408214: step 6019, loss 0.538441.
Train: 2018-07-31T00:54:53.548806: step 6020, loss 0.611318.
Test: 2018-07-31T00:54:53.783127: step 6020, loss 0.549105.
Train: 2018-07-31T00:54:53.939340: step 6021, loss 0.53836.
Train: 2018-07-31T00:54:54.079932: step 6022, loss 0.554556.
Train: 2018-07-31T00:54:54.220524: step 6023, loss 0.513905.
Train: 2018-07-31T00:54:54.376739: step 6024, loss 0.570778.
Train: 2018-07-31T00:54:54.517354: step 6025, loss 0.62788.
Train: 2018-07-31T00:54:54.673544: step 6026, loss 0.58709.
Train: 2018-07-31T00:54:54.814154: step 6027, loss 0.521848.
Train: 2018-07-31T00:54:54.970348: step 6028, loss 0.595248.
Train: 2018-07-31T00:54:55.110942: step 6029, loss 0.562618.
Train: 2018-07-31T00:54:55.251557: step 6030, loss 0.562621.
Test: 2018-07-31T00:54:55.501475: step 6030, loss 0.548974.
Train: 2018-07-31T00:54:55.657712: step 6031, loss 0.603378.
Train: 2018-07-31T00:54:55.798279: step 6032, loss 0.530074.
Train: 2018-07-31T00:54:55.938874: step 6033, loss 0.578918.
Train: 2018-07-31T00:54:56.079490: step 6034, loss 0.546383.
Train: 2018-07-31T00:54:56.220081: step 6035, loss 0.55452.
Train: 2018-07-31T00:54:56.360648: step 6036, loss 0.554519.
Train: 2018-07-31T00:54:56.501240: step 6037, loss 0.554514.
Train: 2018-07-31T00:54:56.657454: step 6038, loss 0.562643.
Train: 2018-07-31T00:54:56.798070: step 6039, loss 0.546358.
Train: 2018-07-31T00:54:56.938638: step 6040, loss 0.545251.
Test: 2018-07-31T00:54:57.188610: step 6040, loss 0.548959.
Train: 2018-07-31T00:54:57.329196: step 6041, loss 0.603396.
Train: 2018-07-31T00:54:57.469788: step 6042, loss 0.529995.
Train: 2018-07-31T00:54:57.610355: step 6043, loss 0.505474.
Train: 2018-07-31T00:54:57.750948: step 6044, loss 0.554409.
Train: 2018-07-31T00:54:57.907179: step 6045, loss 0.554371.
Train: 2018-07-31T00:54:58.047753: step 6046, loss 0.5297.
Train: 2018-07-31T00:54:58.203966: step 6047, loss 0.57899.
Train: 2018-07-31T00:54:58.360204: step 6048, loss 0.529516.
Train: 2018-07-31T00:54:58.500772: step 6049, loss 0.570756.
Train: 2018-07-31T00:54:58.641364: step 6050, loss 0.512777.
Test: 2018-07-31T00:54:58.891305: step 6050, loss 0.548544.
Train: 2018-07-31T00:54:59.031899: step 6051, loss 0.562454.
Train: 2018-07-31T00:54:59.172489: step 6052, loss 0.595738.
Train: 2018-07-31T00:54:59.328704: step 6053, loss 0.595772.
Train: 2018-07-31T00:54:59.469295: step 6054, loss 0.512402.
Train: 2018-07-31T00:54:59.609912: step 6055, loss 0.587464.
Train: 2018-07-31T00:54:59.750506: step 6056, loss 0.579121.
Train: 2018-07-31T00:54:59.906693: step 6057, loss 0.487262.
Train: 2018-07-31T00:55:00.062907: step 6058, loss 0.528957.
Train: 2018-07-31T00:55:00.203498: step 6059, loss 0.528881.
Train: 2018-07-31T00:55:00.344115: step 6060, loss 0.545588.
Test: 2018-07-31T00:55:00.594033: step 6060, loss 0.548276.
Train: 2018-07-31T00:55:00.734625: step 6061, loss 0.545537.
Train: 2018-07-31T00:55:00.875218: step 6062, loss 0.587684.
Train: 2018-07-31T00:55:01.015833: step 6063, loss 0.562362.
Train: 2018-07-31T00:55:01.156426: step 6064, loss 0.54544.
Train: 2018-07-31T00:55:01.296992: step 6065, loss 0.59623.
Train: 2018-07-31T00:55:01.437628: step 6066, loss 0.613171.
Train: 2018-07-31T00:55:01.578175: step 6067, loss 0.545442.
Train: 2018-07-31T00:55:01.718768: step 6068, loss 0.553912.
Train: 2018-07-31T00:55:01.859360: step 6069, loss 0.570808.
Train: 2018-07-31T00:55:01.999952: step 6070, loss 0.570803.
Test: 2018-07-31T00:55:02.249927: step 6070, loss 0.548271.
Train: 2018-07-31T00:55:02.390489: step 6071, loss 0.612905.
Train: 2018-07-31T00:55:02.546724: step 6072, loss 0.595986.
Train: 2018-07-31T00:55:02.687316: step 6073, loss 0.604267.
Train: 2018-07-31T00:55:02.843504: step 6074, loss 0.579105.
Train: 2018-07-31T00:55:02.984098: step 6075, loss 0.587369.
Train: 2018-07-31T00:55:03.124714: step 6076, loss 0.529415.
Train: 2018-07-31T00:55:03.265282: step 6077, loss 0.554274.
Train: 2018-07-31T00:55:03.405898: step 6078, loss 0.513234.
Train: 2018-07-31T00:55:03.562088: step 6079, loss 0.587173.
Train: 2018-07-31T00:55:03.702679: step 6080, loss 0.521621.
Test: 2018-07-31T00:55:03.937030: step 6080, loss 0.548874.
Train: 2018-07-31T00:55:04.093212: step 6081, loss 0.529844.
Train: 2018-07-31T00:55:04.233821: step 6082, loss 0.52984.
Train: 2018-07-31T00:55:04.390019: step 6083, loss 0.578955.
Train: 2018-07-31T00:55:04.530634: step 6084, loss 0.521596.
Train: 2018-07-31T00:55:04.671226: step 6085, loss 0.587171.
Train: 2018-07-31T00:55:04.827440: step 6086, loss 0.513298.
Train: 2018-07-31T00:55:04.968009: step 6087, loss 0.546093.
Train: 2018-07-31T00:55:05.124220: step 6088, loss 0.529574.
Train: 2018-07-31T00:55:05.264837: step 6089, loss 0.562501.
Train: 2018-07-31T00:55:05.405405: step 6090, loss 0.595573.
Test: 2018-07-31T00:55:05.655347: step 6090, loss 0.548609.
Train: 2018-07-31T00:55:05.795938: step 6091, loss 0.570757.
Train: 2018-07-31T00:55:05.936531: step 6092, loss 0.587328.
Train: 2018-07-31T00:55:06.077147: step 6093, loss 0.537621.
Train: 2018-07-31T00:55:06.217740: step 6094, loss 0.595619.
Train: 2018-07-31T00:55:06.373928: step 6095, loss 0.587323.
Train: 2018-07-31T00:55:06.530143: step 6096, loss 0.570756.
Train: 2018-07-31T00:55:06.686380: step 6097, loss 0.537705.
Train: 2018-07-31T00:55:06.826972: step 6098, loss 0.554241.
Train: 2018-07-31T00:55:06.967565: step 6099, loss 0.521234.
Train: 2018-07-31T00:55:07.123753: step 6100, loss 0.479921.
Test: 2018-07-31T00:55:07.358074: step 6100, loss 0.548618.
Train: 2018-07-31T00:55:08.107915: step 6101, loss 0.58731.
Train: 2018-07-31T00:55:08.279765: step 6102, loss 0.603912.
Train: 2018-07-31T00:55:08.435945: step 6103, loss 0.620501.
Train: 2018-07-31T00:55:08.576564: step 6104, loss 0.496234.
Train: 2018-07-31T00:55:08.717130: step 6105, loss 0.620457.
Train: 2018-07-31T00:55:08.873344: step 6106, loss 0.579031.
Train: 2018-07-31T00:55:08.998315: step 6107, loss 0.603803.
Train: 2018-07-31T00:55:09.154529: step 6108, loss 0.521304.
Train: 2018-07-31T00:55:09.295128: step 6109, loss 0.488436.
Train: 2018-07-31T00:55:09.435739: step 6110, loss 0.620179.
Test: 2018-07-31T00:55:09.685683: step 6110, loss 0.548745.
Train: 2018-07-31T00:55:09.826245: step 6111, loss 0.521379.
Train: 2018-07-31T00:55:09.966849: step 6112, loss 0.513141.
Train: 2018-07-31T00:55:10.107453: step 6113, loss 0.570757.
Train: 2018-07-31T00:55:10.263642: step 6114, loss 0.636743.
Train: 2018-07-31T00:55:10.419881: step 6115, loss 0.578997.
Train: 2018-07-31T00:55:10.576070: step 6116, loss 0.570758.
Train: 2018-07-31T00:55:10.716662: step 6117, loss 0.554326.
Train: 2018-07-31T00:55:10.872876: step 6118, loss 0.513314.
Train: 2018-07-31T00:55:11.013467: step 6119, loss 0.636419.
Train: 2018-07-31T00:55:11.154061: step 6120, loss 0.554377.
Test: 2018-07-31T00:55:11.388409: step 6120, loss 0.548881.
Train: 2018-07-31T00:55:11.544598: step 6121, loss 0.554402.
Train: 2018-07-31T00:55:11.685186: step 6122, loss 0.603461.
Train: 2018-07-31T00:55:11.825801: step 6123, loss 0.546302.
Train: 2018-07-31T00:55:11.966393: step 6124, loss 0.587069.
Train: 2018-07-31T00:55:12.122583: step 6125, loss 0.578914.
Train: 2018-07-31T00:55:12.263199: step 6126, loss 0.554561.
Train: 2018-07-31T00:55:12.403791: step 6127, loss 0.546491.
Train: 2018-07-31T00:55:12.560006: step 6128, loss 0.578894.
Train: 2018-07-31T00:55:12.700572: step 6129, loss 0.603138.
Train: 2018-07-31T00:55:12.841164: step 6130, loss 0.595014.
Test: 2018-07-31T00:55:13.091106: step 6130, loss 0.549311.
Train: 2018-07-31T00:55:13.231722: step 6131, loss 0.594964.
Train: 2018-07-31T00:55:13.372304: step 6132, loss 0.578867.
Train: 2018-07-31T00:55:13.512883: step 6133, loss 0.554877.
Train: 2018-07-31T00:55:13.653474: step 6134, loss 0.546959.
Train: 2018-07-31T00:55:13.809688: step 6135, loss 0.53109.
Train: 2018-07-31T00:55:13.965900: step 6136, loss 0.562946.
Train: 2018-07-31T00:55:14.106494: step 6137, loss 0.586812.
Train: 2018-07-31T00:55:14.247086: step 6138, loss 0.578858.
Train: 2018-07-31T00:55:14.387677: step 6139, loss 0.642362.
Train: 2018-07-31T00:55:14.543890: step 6140, loss 0.594691.
Test: 2018-07-31T00:55:14.793864: step 6140, loss 0.549868.
Train: 2018-07-31T00:55:14.934453: step 6141, loss 0.555192.
Train: 2018-07-31T00:55:15.075015: step 6142, loss 0.563126.
Train: 2018-07-31T00:55:15.215607: step 6143, loss 0.563163.
Train: 2018-07-31T00:55:15.356226: step 6144, loss 0.586717.
Train: 2018-07-31T00:55:15.496817: step 6145, loss 0.571054.
Train: 2018-07-31T00:55:15.637410: step 6146, loss 0.555446.
Train: 2018-07-31T00:55:15.778000: step 6147, loss 0.53206.
Train: 2018-07-31T00:55:15.934191: step 6148, loss 0.539861.
Train: 2018-07-31T00:55:16.074783: step 6149, loss 0.571073.
Train: 2018-07-31T00:55:16.215399: step 6150, loss 0.625803.
Test: 2018-07-31T00:55:16.465340: step 6150, loss 0.550167.
Train: 2018-07-31T00:55:16.652796: step 6151, loss 0.500735.
Train: 2018-07-31T00:55:16.808986: step 6152, loss 0.516278.
Train: 2018-07-31T00:55:16.949607: step 6153, loss 0.58672.
Train: 2018-07-31T00:55:17.090168: step 6154, loss 0.5317.
Train: 2018-07-31T00:55:17.230761: step 6155, loss 0.563098.
Train: 2018-07-31T00:55:17.371355: step 6156, loss 0.578861.
Train: 2018-07-31T00:55:17.511944: step 6157, loss 0.531328.
Train: 2018-07-31T00:55:17.652555: step 6158, loss 0.578858.
Train: 2018-07-31T00:55:17.793129: step 6159, loss 0.586823.
Train: 2018-07-31T00:55:17.949343: step 6160, loss 0.562906.
Test: 2018-07-31T00:55:18.199304: step 6160, loss 0.549501.
Train: 2018-07-31T00:55:18.339901: step 6161, loss 0.538913.
Train: 2018-07-31T00:55:18.480494: step 6162, loss 0.570858.
Train: 2018-07-31T00:55:18.621061: step 6163, loss 0.514695.
Train: 2018-07-31T00:55:18.777275: step 6164, loss 0.578875.
Train: 2018-07-31T00:55:18.917867: step 6165, loss 0.546626.
Train: 2018-07-31T00:55:19.074079: step 6166, loss 0.441458.
Train: 2018-07-31T00:55:19.230294: step 6167, loss 0.587038.
Train: 2018-07-31T00:55:19.370911: step 6168, loss 0.529967.
Train: 2018-07-31T00:55:19.511525: step 6169, loss 0.488784.
Train: 2018-07-31T00:55:19.652095: step 6170, loss 0.51304.
Test: 2018-07-31T00:55:19.886391: step 6170, loss 0.548565.
Train: 2018-07-31T00:55:20.058223: step 6171, loss 0.545867.
Train: 2018-07-31T00:55:20.198818: step 6172, loss 0.537382.
Train: 2018-07-31T00:55:20.339409: step 6173, loss 0.595968.
Train: 2018-07-31T00:55:20.480001: step 6174, loss 0.621379.
Train: 2018-07-31T00:55:20.620592: step 6175, loss 0.579261.
Train: 2018-07-31T00:55:20.776805: step 6176, loss 0.553896.
Train: 2018-07-31T00:55:20.917397: step 6177, loss 0.562354.
Train: 2018-07-31T00:55:21.073612: step 6178, loss 0.638681.
Train: 2018-07-31T00:55:21.214205: step 6179, loss 0.570826.
Train: 2018-07-31T00:55:21.354820: step 6180, loss 0.545435.
Test: 2018-07-31T00:55:21.589150: step 6180, loss 0.548204.
Train: 2018-07-31T00:55:21.745353: step 6181, loss 0.553908.
Train: 2018-07-31T00:55:21.885939: step 6182, loss 0.528581.
Train: 2018-07-31T00:55:22.026531: step 6183, loss 0.503258.
Train: 2018-07-31T00:55:22.167106: step 6184, loss 0.46939.
Train: 2018-07-31T00:55:22.323319: step 6185, loss 0.562353.
Train: 2018-07-31T00:55:22.463935: step 6186, loss 0.562347.
Train: 2018-07-31T00:55:22.604503: step 6187, loss 0.613404.
Train: 2018-07-31T00:55:22.745094: step 6188, loss 0.570855.
Train: 2018-07-31T00:55:22.885687: step 6189, loss 0.6049.
Train: 2018-07-31T00:55:23.026307: step 6190, loss 0.66435.
Test: 2018-07-31T00:55:23.276258: step 6190, loss 0.548171.
Train: 2018-07-31T00:55:23.416837: step 6191, loss 0.634627.
Train: 2018-07-31T00:55:23.573050: step 6192, loss 0.596078.
Train: 2018-07-31T00:55:23.713643: step 6193, loss 0.53726.
Train: 2018-07-31T00:55:23.869856: step 6194, loss 0.562425.
Train: 2018-07-31T00:55:24.010448: step 6195, loss 0.620593.
Train: 2018-07-31T00:55:24.166662: step 6196, loss 0.570756.
Train: 2018-07-31T00:55:24.322851: step 6197, loss 0.570759.
Train: 2018-07-31T00:55:24.463467: step 6198, loss 0.570766.
Train: 2018-07-31T00:55:24.604035: step 6199, loss 0.538206.
Train: 2018-07-31T00:55:24.744626: step 6200, loss 0.538334.
Test: 2018-07-31T00:55:24.994598: step 6200, loss 0.549153.
Train: 2018-07-31T00:55:25.744392: step 6201, loss 0.586987.
Train: 2018-07-31T00:55:25.900630: step 6202, loss 0.546604.
Train: 2018-07-31T00:55:26.041198: step 6203, loss 0.65135.
Train: 2018-07-31T00:55:26.213032: step 6204, loss 0.498668.
Train: 2018-07-31T00:55:26.338004: step 6205, loss 0.514831.
Train: 2018-07-31T00:55:26.478594: step 6206, loss 0.642866.
Train: 2018-07-31T00:55:26.634808: step 6207, loss 0.594824.
Train: 2018-07-31T00:55:26.775426: step 6208, loss 0.55498.
Train: 2018-07-31T00:55:26.915993: step 6209, loss 0.594743.
Train: 2018-07-31T00:55:27.072206: step 6210, loss 0.618465.
Test: 2018-07-31T00:55:27.306528: step 6210, loss 0.54986.
Train: 2018-07-31T00:55:27.462739: step 6211, loss 0.578863.
Train: 2018-07-31T00:55:27.603331: step 6212, loss 0.610328.
Train: 2018-07-31T00:55:27.743924: step 6213, loss 0.610206.
Train: 2018-07-31T00:55:27.884516: step 6214, loss 0.563306.
Train: 2018-07-31T00:55:28.040730: step 6215, loss 0.516813.
Train: 2018-07-31T00:55:28.181321: step 6216, loss 0.555686.
Train: 2018-07-31T00:55:28.321915: step 6217, loss 0.563462.
Train: 2018-07-31T00:55:28.462531: step 6218, loss 0.53258.
Train: 2018-07-31T00:55:28.603099: step 6219, loss 0.463026.
Train: 2018-07-31T00:55:28.743691: step 6220, loss 0.602173.
Test: 2018-07-31T00:55:28.993662: step 6220, loss 0.550365.
Train: 2018-07-31T00:55:29.149845: step 6221, loss 0.602212.
Train: 2018-07-31T00:55:29.290437: step 6222, loss 0.555576.
Train: 2018-07-31T00:55:29.446650: step 6223, loss 0.66456.
Train: 2018-07-31T00:55:29.587242: step 6224, loss 0.53223.
Train: 2018-07-31T00:55:29.727835: step 6225, loss 0.547784.
Train: 2018-07-31T00:55:29.868427: step 6226, loss 0.61004.
Train: 2018-07-31T00:55:30.009043: step 6227, loss 0.524421.
Train: 2018-07-31T00:55:30.165232: step 6228, loss 0.539943.
Train: 2018-07-31T00:55:30.305824: step 6229, loss 0.586694.
Train: 2018-07-31T00:55:30.446442: step 6230, loss 0.610141.
Test: 2018-07-31T00:55:30.696388: step 6230, loss 0.550169.
Train: 2018-07-31T00:55:30.836949: step 6231, loss 0.516369.
Train: 2018-07-31T00:55:30.977541: step 6232, loss 0.484962.
Train: 2018-07-31T00:55:31.118134: step 6233, loss 0.594581.
Train: 2018-07-31T00:55:31.258726: step 6234, loss 0.578866.
Train: 2018-07-31T00:55:31.399317: step 6235, loss 0.57097.
Train: 2018-07-31T00:55:31.539911: step 6236, loss 0.555136.
Train: 2018-07-31T00:55:31.680501: step 6237, loss 0.531311.
Train: 2018-07-31T00:55:31.821094: step 6238, loss 0.578858.
Train: 2018-07-31T00:55:31.961686: step 6239, loss 0.546998.
Train: 2018-07-31T00:55:32.102279: step 6240, loss 0.546918.
Test: 2018-07-31T00:55:32.352221: step 6240, loss 0.549436.
Train: 2018-07-31T00:55:32.492811: step 6241, loss 0.50679.
Train: 2018-07-31T00:55:32.633404: step 6242, loss 0.562792.
Train: 2018-07-31T00:55:32.789643: step 6243, loss 0.522392.
Train: 2018-07-31T00:55:32.930210: step 6244, loss 0.530268.
Train: 2018-07-31T00:55:33.070819: step 6245, loss 0.562634.
Train: 2018-07-31T00:55:33.211394: step 6246, loss 0.5217.
Train: 2018-07-31T00:55:33.352011: step 6247, loss 0.521459.
Train: 2018-07-31T00:55:33.508224: step 6248, loss 0.562497.
Train: 2018-07-31T00:55:33.648816: step 6249, loss 0.570758.
Train: 2018-07-31T00:55:33.805006: step 6250, loss 0.629065.
Test: 2018-07-31T00:55:34.039358: step 6250, loss 0.54845.
Train: 2018-07-31T00:55:34.195539: step 6251, loss 0.537393.
Train: 2018-07-31T00:55:34.336156: step 6252, loss 0.55405.
Train: 2018-07-31T00:55:34.476747: step 6253, loss 0.5624.
Train: 2018-07-31T00:55:34.632961: step 6254, loss 0.512053.
Train: 2018-07-31T00:55:34.773553: step 6255, loss 0.528742.
Train: 2018-07-31T00:55:34.929742: step 6256, loss 0.562373.
Train: 2018-07-31T00:55:35.070358: step 6257, loss 0.477833.
Train: 2018-07-31T00:55:35.210950: step 6258, loss 0.519929.
Train: 2018-07-31T00:55:35.367163: step 6259, loss 0.604941.
Train: 2018-07-31T00:55:35.523359: step 6260, loss 0.562338.
Test: 2018-07-31T00:55:35.757703: step 6260, loss 0.548003.
Train: 2018-07-31T00:55:35.913924: step 6261, loss 0.605126.
Train: 2018-07-31T00:55:36.054479: step 6262, loss 0.613717.
Train: 2018-07-31T00:55:36.195071: step 6263, loss 0.622234.
Train: 2018-07-31T00:55:36.335687: step 6264, loss 0.587951.
Train: 2018-07-31T00:55:36.491877: step 6265, loss 0.545316.
Train: 2018-07-31T00:55:36.632469: step 6266, loss 0.494404.
Train: 2018-07-31T00:55:36.773084: step 6267, loss 0.596291.
Train: 2018-07-31T00:55:36.913652: step 6268, loss 0.562354.
Train: 2018-07-31T00:55:37.054269: step 6269, loss 0.50317.
Train: 2018-07-31T00:55:37.210469: step 6270, loss 0.545458.
Test: 2018-07-31T00:55:37.444809: step 6270, loss 0.548211.
Train: 2018-07-31T00:55:37.585370: step 6271, loss 0.621511.
Train: 2018-07-31T00:55:37.741584: step 6272, loss 0.545497.
Train: 2018-07-31T00:55:37.882215: step 6273, loss 0.621343.
Train: 2018-07-31T00:55:38.038414: step 6274, loss 0.545583.
Train: 2018-07-31T00:55:38.179006: step 6275, loss 0.461799.
Train: 2018-07-31T00:55:38.319597: step 6276, loss 0.528854.
Train: 2018-07-31T00:55:38.460165: step 6277, loss 0.554017.
Train: 2018-07-31T00:55:38.600772: step 6278, loss 0.579188.
Train: 2018-07-31T00:55:38.741348: step 6279, loss 0.537194.
Train: 2018-07-31T00:55:38.881941: step 6280, loss 0.503573.
Test: 2018-07-31T00:55:39.116291: step 6280, loss 0.548284.
Train: 2018-07-31T00:55:39.272476: step 6281, loss 0.537132.
Train: 2018-07-31T00:55:39.413092: step 6282, loss 0.444335.
Train: 2018-07-31T00:55:39.553684: step 6283, loss 0.613152.
Train: 2018-07-31T00:55:39.694250: step 6284, loss 0.579322.
Train: 2018-07-31T00:55:39.834868: step 6285, loss 0.613343.
Train: 2018-07-31T00:55:39.991058: step 6286, loss 0.494343.
Train: 2018-07-31T00:55:40.131648: step 6287, loss 0.570854.
Train: 2018-07-31T00:55:40.272253: step 6288, loss 0.528267.
Train: 2018-07-31T00:55:40.412856: step 6289, loss 0.604986.
Train: 2018-07-31T00:55:40.553449: step 6290, loss 0.545282.
Test: 2018-07-31T00:55:40.787744: step 6290, loss 0.548054.
Train: 2018-07-31T00:55:40.943983: step 6291, loss 0.579399.
Train: 2018-07-31T00:55:41.100173: step 6292, loss 0.570866.
Train: 2018-07-31T00:55:41.240763: step 6293, loss 0.528268.
Train: 2018-07-31T00:55:41.381355: step 6294, loss 0.553826.
Train: 2018-07-31T00:55:41.537569: step 6295, loss 0.604911.
Train: 2018-07-31T00:55:41.678160: step 6296, loss 0.562345.
Train: 2018-07-31T00:55:41.818777: step 6297, loss 0.519901.
Train: 2018-07-31T00:55:41.959371: step 6298, loss 0.604772.
Train: 2018-07-31T00:55:42.099937: step 6299, loss 0.511534.
Train: 2018-07-31T00:55:42.240528: step 6300, loss 0.570821.
Test: 2018-07-31T00:55:42.474852: step 6300, loss 0.548195.
Train: 2018-07-31T00:55:43.224675: step 6301, loss 0.477783.
Train: 2018-07-31T00:55:43.380889: step 6302, loss 0.613146.
Train: 2018-07-31T00:55:43.521505: step 6303, loss 0.486213.
Train: 2018-07-31T00:55:43.693316: step 6304, loss 0.61317.
Train: 2018-07-31T00:55:43.833931: step 6305, loss 0.520027.
Train: 2018-07-31T00:55:43.990121: step 6306, loss 0.570824.
Train: 2018-07-31T00:55:44.130737: step 6307, loss 0.553886.
Train: 2018-07-31T00:55:44.286950: step 6308, loss 0.562355.
Train: 2018-07-31T00:55:44.427518: step 6309, loss 0.647021.
Train: 2018-07-31T00:55:44.568134: step 6310, loss 0.613047.
Test: 2018-07-31T00:55:44.802460: step 6310, loss 0.548277.
Train: 2018-07-31T00:55:44.958643: step 6311, loss 0.537119.
Train: 2018-07-31T00:55:45.099235: step 6312, loss 0.570785.
Train: 2018-07-31T00:55:45.255473: step 6313, loss 0.545654.
Train: 2018-07-31T00:55:45.396040: step 6314, loss 0.537348.
Train: 2018-07-31T00:55:45.552272: step 6315, loss 0.729279.
Train: 2018-07-31T00:55:45.692892: step 6316, loss 0.537564.
Train: 2018-07-31T00:55:45.833438: step 6317, loss 0.537704.
Train: 2018-07-31T00:55:45.989650: step 6318, loss 0.603698.
Train: 2018-07-31T00:55:46.145865: step 6319, loss 0.546156.
Train: 2018-07-31T00:55:46.286458: step 6320, loss 0.546244.
Test: 2018-07-31T00:55:46.520778: step 6320, loss 0.548967.
Train: 2018-07-31T00:55:46.676992: step 6321, loss 0.627846.
Train: 2018-07-31T00:55:46.817582: step 6322, loss 0.554544.
Train: 2018-07-31T00:55:46.958176: step 6323, loss 0.578894.
Train: 2018-07-31T00:55:47.114389: step 6324, loss 0.58695.
Train: 2018-07-31T00:55:47.254981: step 6325, loss 0.643181.
Train: 2018-07-31T00:55:47.395573: step 6326, loss 0.546872.
Train: 2018-07-31T00:55:47.536165: step 6327, loss 0.602753.
Train: 2018-07-31T00:55:47.692378: step 6328, loss 0.578859.
Train: 2018-07-31T00:55:47.832971: step 6329, loss 0.539395.
Train: 2018-07-31T00:55:47.973575: step 6330, loss 0.500185.
Test: 2018-07-31T00:55:48.207913: step 6330, loss 0.549987.
Train: 2018-07-31T00:55:48.364095: step 6331, loss 0.531712.
Train: 2018-07-31T00:55:48.504688: step 6332, loss 0.531711.
Train: 2018-07-31T00:55:48.645281: step 6333, loss 0.602472.
Train: 2018-07-31T00:55:48.785871: step 6334, loss 0.586736.
Train: 2018-07-31T00:55:48.926463: step 6335, loss 0.586735.
Train: 2018-07-31T00:55:49.067056: step 6336, loss 0.633894.
Train: 2018-07-31T00:55:49.223269: step 6337, loss 0.523973.
Train: 2018-07-31T00:55:49.363861: step 6338, loss 0.516182.
Train: 2018-07-31T00:55:49.520099: step 6339, loss 0.500452.
Train: 2018-07-31T00:55:49.660667: step 6340, loss 0.531701.
Test: 2018-07-31T00:55:49.894988: step 6340, loss 0.549883.
Train: 2018-07-31T00:55:50.051201: step 6341, loss 0.594637.
Train: 2018-07-31T00:55:50.176171: step 6342, loss 0.546191.
Train: 2018-07-31T00:55:50.316788: step 6343, loss 0.54716.
Train: 2018-07-31T00:55:50.472977: step 6344, loss 0.570911.
Train: 2018-07-31T00:55:50.613593: step 6345, loss 0.539021.
Train: 2018-07-31T00:55:50.754193: step 6346, loss 0.578862.
Train: 2018-07-31T00:55:50.910374: step 6347, loss 0.578865.
Train: 2018-07-31T00:55:51.050967: step 6348, loss 0.61097.
Train: 2018-07-31T00:55:51.191586: step 6349, loss 0.49857.
Train: 2018-07-31T00:55:51.332175: step 6350, loss 0.514496.
Test: 2018-07-31T00:55:51.582123: step 6350, loss 0.549218.
Train: 2018-07-31T00:55:51.738306: step 6351, loss 0.570811.
Train: 2018-07-31T00:55:51.878899: step 6352, loss 0.570795.
Train: 2018-07-31T00:55:52.019489: step 6353, loss 0.481527.
Train: 2018-07-31T00:55:52.175705: step 6354, loss 0.619667.
Train: 2018-07-31T00:55:52.316296: step 6355, loss 0.603418.
Train: 2018-07-31T00:55:52.456887: step 6356, loss 0.505325.
Train: 2018-07-31T00:55:52.597479: step 6357, loss 0.546097.
Train: 2018-07-31T00:55:52.738071: step 6358, loss 0.521082.
Train: 2018-07-31T00:55:52.894309: step 6359, loss 0.587313.
Train: 2018-07-31T00:55:53.050522: step 6360, loss 0.47853.
Test: 2018-07-31T00:55:53.284846: step 6360, loss 0.548102.
Train: 2018-07-31T00:55:53.441033: step 6361, loss 0.552476.
Train: 2018-07-31T00:55:53.581633: step 6362, loss 0.554945.
Train: 2018-07-31T00:55:53.722233: step 6363, loss 0.615177.
Train: 2018-07-31T00:55:53.862808: step 6364, loss 0.564914.
Train: 2018-07-31T00:55:54.003399: step 6365, loss 0.485272.
Train: 2018-07-31T00:55:54.159614: step 6366, loss 0.674352.
Train: 2018-07-31T00:55:54.300205: step 6367, loss 0.586721.
Train: 2018-07-31T00:55:54.440822: step 6368, loss 0.537107.
Train: 2018-07-31T00:55:54.597010: step 6369, loss 0.578997.
Train: 2018-07-31T00:55:54.737603: step 6370, loss 0.613083.
Test: 2018-07-31T00:55:54.987545: step 6370, loss 0.548498.
Train: 2018-07-31T00:55:55.128161: step 6371, loss 0.579153.
Train: 2018-07-31T00:55:55.284374: step 6372, loss 0.595645.
Train: 2018-07-31T00:55:55.424941: step 6373, loss 0.595488.
Train: 2018-07-31T00:55:55.565559: step 6374, loss 0.488685.
Train: 2018-07-31T00:55:55.706151: step 6375, loss 0.578956.
Train: 2018-07-31T00:55:55.846743: step 6376, loss 0.538068.
Train: 2018-07-31T00:55:55.987335: step 6377, loss 0.562607.
Train: 2018-07-31T00:55:56.143534: step 6378, loss 0.50554.
Train: 2018-07-31T00:55:56.299738: step 6379, loss 0.587086.
Train: 2018-07-31T00:55:56.440329: step 6380, loss 0.587081.
Test: 2018-07-31T00:55:56.674680: step 6380, loss 0.548988.
Train: 2018-07-31T00:55:56.830864: step 6381, loss 0.530046.
Train: 2018-07-31T00:55:56.971454: step 6382, loss 0.546339.
Train: 2018-07-31T00:55:57.112047: step 6383, loss 0.521882.
Train: 2018-07-31T00:55:57.268261: step 6384, loss 0.489177.
Train: 2018-07-31T00:55:57.424474: step 6385, loss 0.677145.
Train: 2018-07-31T00:55:57.565086: step 6386, loss 0.538037.
Train: 2018-07-31T00:55:57.705682: step 6387, loss 0.562579.
Train: 2018-07-31T00:55:57.846251: step 6388, loss 0.595332.
Train: 2018-07-31T00:55:57.986841: step 6389, loss 0.578951.
Train: 2018-07-31T00:55:58.127434: step 6390, loss 0.554408.
Test: 2018-07-31T00:55:58.377377: step 6390, loss 0.548902.
Train: 2018-07-31T00:55:58.517992: step 6391, loss 0.595292.
Train: 2018-07-31T00:55:58.658585: step 6392, loss 0.562606.
Train: 2018-07-31T00:55:58.814772: step 6393, loss 0.587084.
Train: 2018-07-31T00:55:58.970987: step 6394, loss 0.57892.
Train: 2018-07-31T00:55:59.111603: step 6395, loss 0.505768.
Train: 2018-07-31T00:55:59.267817: step 6396, loss 0.554536.
Train: 2018-07-31T00:55:59.408423: step 6397, loss 0.562661.
Train: 2018-07-31T00:55:59.548975: step 6398, loss 0.554537.
Train: 2018-07-31T00:55:59.705191: step 6399, loss 0.52203.
Train: 2018-07-31T00:55:59.861428: step 6400, loss 0.546375.
Test: 2018-07-31T00:56:00.095755: step 6400, loss 0.548986.
Train: 2018-07-31T00:56:00.876814: step 6401, loss 0.538189.
Train: 2018-07-31T00:56:01.017381: step 6402, loss 0.521798.
Train: 2018-07-31T00:56:01.157975: step 6403, loss 0.595317.
Train: 2018-07-31T00:56:01.298567: step 6404, loss 0.546173.
Train: 2018-07-31T00:56:01.439158: step 6405, loss 0.546126.
Train: 2018-07-31T00:56:01.579750: step 6406, loss 0.529622.
Train: 2018-07-31T00:56:01.720343: step 6407, loss 0.587251.
Train: 2018-07-31T00:56:01.860935: step 6408, loss 0.554235.
Train: 2018-07-31T00:56:02.032770: step 6409, loss 0.562483.
Train: 2018-07-31T00:56:02.173362: step 6410, loss 0.570757.
Test: 2018-07-31T00:56:02.423305: step 6410, loss 0.548579.
Train: 2018-07-31T00:56:02.563896: step 6411, loss 0.603925.
Train: 2018-07-31T00:56:02.704487: step 6412, loss 0.562468.
Train: 2018-07-31T00:56:02.845104: step 6413, loss 0.620483.
Train: 2018-07-31T00:56:03.001294: step 6414, loss 0.562482.
Train: 2018-07-31T00:56:03.141885: step 6415, loss 0.537714.
Train: 2018-07-31T00:56:03.282502: step 6416, loss 0.545997.
Train: 2018-07-31T00:56:03.423087: step 6417, loss 0.570757.
Train: 2018-07-31T00:56:03.563686: step 6418, loss 0.529532.
Train: 2018-07-31T00:56:03.719875: step 6419, loss 0.529529.
Train: 2018-07-31T00:56:03.860492: step 6420, loss 0.587264.
Test: 2018-07-31T00:56:04.110409: step 6420, loss 0.548683.
Train: 2018-07-31T00:56:04.251000: step 6421, loss 0.587259.
Train: 2018-07-31T00:56:04.391592: step 6422, loss 0.603734.
Train: 2018-07-31T00:56:04.547806: step 6423, loss 0.595437.
Train: 2018-07-31T00:56:04.688423: step 6424, loss 0.537886.
Train: 2018-07-31T00:56:04.829014: step 6425, loss 0.496894.
Train: 2018-07-31T00:56:04.969607: step 6426, loss 0.537908.
Train: 2018-07-31T00:56:05.110175: step 6427, loss 0.570754.
Train: 2018-07-31T00:56:05.250791: step 6428, loss 0.620058.
Train: 2018-07-31T00:56:05.391358: step 6429, loss 0.587213.
Train: 2018-07-31T00:56:05.531950: step 6430, loss 0.562492.
Test: 2018-07-31T00:56:05.781893: step 6430, loss 0.54885.
Train: 2018-07-31T00:56:05.922508: step 6431, loss 0.521665.
Train: 2018-07-31T00:56:06.078699: step 6432, loss 0.546151.
Train: 2018-07-31T00:56:06.203668: step 6433, loss 0.537873.
Train: 2018-07-31T00:56:06.344262: step 6434, loss 0.6117.
Train: 2018-07-31T00:56:06.484852: step 6435, loss 0.513302.
Train: 2018-07-31T00:56:06.625444: step 6436, loss 0.59549.
Train: 2018-07-31T00:56:06.781689: step 6437, loss 0.554165.
Train: 2018-07-31T00:56:06.922251: step 6438, loss 0.603606.
Train: 2018-07-31T00:56:07.062867: step 6439, loss 0.604078.
Train: 2018-07-31T00:56:07.203459: step 6440, loss 0.57881.
Test: 2018-07-31T00:56:07.453376: step 6440, loss 0.548921.
Train: 2018-07-31T00:56:07.593992: step 6441, loss 0.562458.
Train: 2018-07-31T00:56:07.750205: step 6442, loss 0.554346.
Train: 2018-07-31T00:56:07.890774: step 6443, loss 0.554617.
Train: 2018-07-31T00:56:08.031389: step 6444, loss 0.538351.
Train: 2018-07-31T00:56:08.187579: step 6445, loss 0.546401.
Train: 2018-07-31T00:56:08.343793: step 6446, loss 0.603265.
Train: 2018-07-31T00:56:08.484406: step 6447, loss 0.570612.
Train: 2018-07-31T00:56:08.624977: step 6448, loss 0.570579.
Train: 2018-07-31T00:56:08.781190: step 6449, loss 0.611249.
Train: 2018-07-31T00:56:08.921806: step 6450, loss 0.481938.
Test: 2018-07-31T00:56:09.156102: step 6450, loss 0.549163.
Train: 2018-07-31T00:56:09.296694: step 6451, loss 0.521869.
Train: 2018-07-31T00:56:09.452907: step 6452, loss 0.578744.
Train: 2018-07-31T00:56:09.593525: step 6453, loss 0.563205.
Train: 2018-07-31T00:56:09.749713: step 6454, loss 0.538224.
Train: 2018-07-31T00:56:09.890329: step 6455, loss 0.488963.
Train: 2018-07-31T00:56:10.062140: step 6456, loss 0.489489.
Train: 2018-07-31T00:56:10.202755: step 6457, loss 0.611833.
Train: 2018-07-31T00:56:10.343323: step 6458, loss 0.654727.
Train: 2018-07-31T00:56:10.499536: step 6459, loss 0.604164.
Train: 2018-07-31T00:56:10.640165: step 6460, loss 0.537409.
Test: 2018-07-31T00:56:10.874483: step 6460, loss 0.548732.
Train: 2018-07-31T00:56:11.030663: step 6461, loss 0.66163.
Train: 2018-07-31T00:56:11.186877: step 6462, loss 0.513624.
Train: 2018-07-31T00:56:11.327469: step 6463, loss 0.603298.
Train: 2018-07-31T00:56:11.483682: step 6464, loss 0.481363.
Train: 2018-07-31T00:56:11.624273: step 6465, loss 0.538477.
Train: 2018-07-31T00:56:11.764890: step 6466, loss 0.554589.
Train: 2018-07-31T00:56:11.905507: step 6467, loss 0.554606.
Train: 2018-07-31T00:56:12.046074: step 6468, loss 0.578811.
Train: 2018-07-31T00:56:12.186676: step 6469, loss 0.554451.
Train: 2018-07-31T00:56:12.342855: step 6470, loss 0.570734.
Test: 2018-07-31T00:56:12.561584: step 6470, loss 0.549032.
Train: 2018-07-31T00:56:12.702146: step 6471, loss 0.595216.
Train: 2018-07-31T00:56:12.858384: step 6472, loss 0.57075.
Train: 2018-07-31T00:56:12.998953: step 6473, loss 0.627666.
Train: 2018-07-31T00:56:13.155176: step 6474, loss 0.554584.
Train: 2018-07-31T00:56:13.295756: step 6475, loss 0.538437.
Train: 2018-07-31T00:56:13.436373: step 6476, loss 0.619333.
Train: 2018-07-31T00:56:13.576954: step 6477, loss 0.586955.
Train: 2018-07-31T00:56:13.717533: step 6478, loss 0.522562.
Train: 2018-07-31T00:56:13.873747: step 6479, loss 0.602979.
Train: 2018-07-31T00:56:14.014363: step 6480, loss 0.514706.
Test: 2018-07-31T00:56:14.248659: step 6480, loss 0.549407.
Train: 2018-07-31T00:56:14.389250: step 6481, loss 0.586883.
Train: 2018-07-31T00:56:14.529868: step 6482, loss 0.514789.
Train: 2018-07-31T00:56:14.686056: step 6483, loss 0.522773.
Train: 2018-07-31T00:56:14.842270: step 6484, loss 0.554793.
Train: 2018-07-31T00:56:14.967241: step 6485, loss 0.602987.
Train: 2018-07-31T00:56:15.107833: step 6486, loss 0.53866.
Train: 2018-07-31T00:56:15.264048: step 6487, loss 0.554721.
Train: 2018-07-31T00:56:15.404662: step 6488, loss 0.538568.
Train: 2018-07-31T00:56:15.560852: step 6489, loss 0.562732.
Train: 2018-07-31T00:56:15.701468: step 6490, loss 0.611256.
Test: 2018-07-31T00:56:15.935767: step 6490, loss 0.54915.
Train: 2018-07-31T00:56:16.091978: step 6491, loss 0.5708.
Train: 2018-07-31T00:56:16.232570: step 6492, loss 0.522225.
Train: 2018-07-31T00:56:16.373161: step 6493, loss 0.57998.
Train: 2018-07-31T00:56:16.513755: step 6494, loss 0.578903.
Train: 2018-07-31T00:56:16.654345: step 6495, loss 0.530227.
Train: 2018-07-31T00:56:16.794962: step 6496, loss 0.562666.
Train: 2018-07-31T00:56:16.951151: step 6497, loss 0.627685.
Train: 2018-07-31T00:56:17.091768: step 6498, loss 0.522046.
Train: 2018-07-31T00:56:17.232360: step 6499, loss 0.530152.
Train: 2018-07-31T00:56:17.372927: step 6500, loss 0.505693.
Test: 2018-07-31T00:56:17.622899: step 6500, loss 0.548962.
Train: 2018-07-31T00:56:18.372717: step 6501, loss 0.529965.
Train: 2018-07-31T00:56:18.528931: step 6502, loss 0.54625.
Train: 2018-07-31T00:56:18.685120: step 6503, loss 0.521479.
Train: 2018-07-31T00:56:18.825711: step 6504, loss 0.529441.
Train: 2018-07-31T00:56:18.966350: step 6505, loss 0.545692.
Train: 2018-07-31T00:56:19.138149: step 6506, loss 0.51212.
Train: 2018-07-31T00:56:19.278755: step 6507, loss 0.537221.
Train: 2018-07-31T00:56:19.419324: step 6508, loss 0.560735.
Train: 2018-07-31T00:56:19.575537: step 6509, loss 0.556053.
Train: 2018-07-31T00:56:19.716130: step 6510, loss 0.548739.
Test: 2018-07-31T00:56:19.950479: step 6510, loss 0.547729.
Train: 2018-07-31T00:56:20.106686: step 6511, loss 0.640481.
Train: 2018-07-31T00:56:20.247254: step 6512, loss 0.570449.
Train: 2018-07-31T00:56:20.403468: step 6513, loss 0.553712.
Train: 2018-07-31T00:56:20.544061: step 6514, loss 0.587404.
Train: 2018-07-31T00:56:20.684651: step 6515, loss 0.579432.
Train: 2018-07-31T00:56:20.825268: step 6516, loss 0.494624.
Train: 2018-07-31T00:56:20.965836: step 6517, loss 0.52858.
Train: 2018-07-31T00:56:21.122050: step 6518, loss 0.570767.
Train: 2018-07-31T00:56:21.262667: step 6519, loss 0.604572.
Train: 2018-07-31T00:56:21.403258: step 6520, loss 0.562375.
Test: 2018-07-31T00:56:21.637582: step 6520, loss 0.548284.
Train: 2018-07-31T00:56:21.793768: step 6521, loss 0.621298.
Train: 2018-07-31T00:56:21.934360: step 6522, loss 0.545594.
Train: 2018-07-31T00:56:22.090597: step 6523, loss 0.562398.
Train: 2018-07-31T00:56:22.231165: step 6524, loss 0.595867.
Train: 2018-07-31T00:56:22.371768: step 6525, loss 0.587453.
Train: 2018-07-31T00:56:22.512349: step 6526, loss 0.512538.
Train: 2018-07-31T00:56:22.652940: step 6527, loss 0.545849.
Train: 2018-07-31T00:56:22.809155: step 6528, loss 0.595637.
Train: 2018-07-31T00:56:22.949755: step 6529, loss 0.56248.
Train: 2018-07-31T00:56:23.090364: step 6530, loss 0.562495.
Test: 2018-07-31T00:56:23.324660: step 6530, loss 0.548698.
Train: 2018-07-31T00:56:23.480872: step 6531, loss 0.636731.
Train: 2018-07-31T00:56:23.621474: step 6532, loss 0.496787.
Train: 2018-07-31T00:56:23.762057: step 6533, loss 0.636414.
Train: 2018-07-31T00:56:23.902650: step 6534, loss 0.546224.
Train: 2018-07-31T00:56:24.058897: step 6535, loss 0.562611.
Train: 2018-07-31T00:56:24.199478: step 6536, loss 0.587063.
Train: 2018-07-31T00:56:24.340073: step 6537, loss 0.619513.
Train: 2018-07-31T00:56:24.480638: step 6538, loss 0.554619.
Train: 2018-07-31T00:56:24.621230: step 6539, loss 0.522419.
Train: 2018-07-31T00:56:24.761822: step 6540, loss 0.546669.
Test: 2018-07-31T00:56:24.996143: step 6540, loss 0.54932.
Train: 2018-07-31T00:56:25.136734: step 6541, loss 0.562788.
Train: 2018-07-31T00:56:25.292948: step 6542, loss 0.562801.
Train: 2018-07-31T00:56:25.449198: step 6543, loss 0.530694.
Train: 2018-07-31T00:56:25.589755: step 6544, loss 0.57887.
Train: 2018-07-31T00:56:25.730346: step 6545, loss 0.594929.
Train: 2018-07-31T00:56:25.870938: step 6546, loss 0.570845.
Train: 2018-07-31T00:56:26.011551: step 6547, loss 0.586882.
Train: 2018-07-31T00:56:26.152122: step 6548, loss 0.578865.
Train: 2018-07-31T00:56:26.308352: step 6549, loss 0.586856.
Train: 2018-07-31T00:56:26.448927: step 6550, loss 0.507047.
Test: 2018-07-31T00:56:26.698869: step 6550, loss 0.549542.
Train: 2018-07-31T00:56:26.855106: step 6551, loss 0.546947.
Train: 2018-07-31T00:56:26.995675: step 6552, loss 0.52299.
Train: 2018-07-31T00:56:27.136265: step 6553, loss 0.530903.
Train: 2018-07-31T00:56:27.276858: step 6554, loss 0.562843.
Train: 2018-07-31T00:56:27.417450: step 6555, loss 0.619009.
Train: 2018-07-31T00:56:27.558067: step 6556, loss 0.522643.
Train: 2018-07-31T00:56:27.698659: step 6557, loss 0.530603.
Train: 2018-07-31T00:56:27.854849: step 6558, loss 0.522434.
Train: 2018-07-31T00:56:27.995464: step 6559, loss 0.586979.
Train: 2018-07-31T00:56:28.151654: step 6560, loss 0.562684.
Test: 2018-07-31T00:56:28.385976: step 6560, loss 0.549056.
Train: 2018-07-31T00:56:28.526564: step 6561, loss 0.587038.
Train: 2018-07-31T00:56:28.667158: step 6562, loss 0.603331.
Train: 2018-07-31T00:56:28.823371: step 6563, loss 0.538236.
Train: 2018-07-31T00:56:28.963964: step 6564, loss 0.58706.
Train: 2018-07-31T00:56:29.104580: step 6565, loss 0.570779.
Train: 2018-07-31T00:56:29.229550: step 6566, loss 0.61963.
Train: 2018-07-31T00:56:29.385740: step 6567, loss 0.562653.
Train: 2018-07-31T00:56:29.526332: step 6568, loss 0.562668.
Train: 2018-07-31T00:56:29.666922: step 6569, loss 0.530244.
Train: 2018-07-31T00:56:29.807517: step 6570, loss 0.595117.
Test: 2018-07-31T00:56:30.057458: step 6570, loss 0.549127.
Train: 2018-07-31T00:56:30.198048: step 6571, loss 0.619397.
Train: 2018-07-31T00:56:30.354264: step 6572, loss 0.586971.
Train: 2018-07-31T00:56:30.479232: step 6573, loss 0.578879.
Train: 2018-07-31T00:56:30.619825: step 6574, loss 0.554751.
Train: 2018-07-31T00:56:30.776038: step 6575, loss 0.594916.
Train: 2018-07-31T00:56:30.916630: step 6576, loss 0.538847.
Train: 2018-07-31T00:56:31.057266: step 6577, loss 0.578859.
Train: 2018-07-31T00:56:31.197839: step 6578, loss 0.570881.
Train: 2018-07-31T00:56:31.338407: step 6579, loss 0.554958.
Train: 2018-07-31T00:56:31.494620: step 6580, loss 0.435607.
Test: 2018-07-31T00:56:31.744563: step 6580, loss 0.549433.
Train: 2018-07-31T00:56:31.885155: step 6581, loss 0.522982.
Train: 2018-07-31T00:56:32.025747: step 6582, loss 0.586771.
Train: 2018-07-31T00:56:32.166338: step 6583, loss 0.521789.
Train: 2018-07-31T00:56:32.322551: step 6584, loss 0.555735.
Train: 2018-07-31T00:56:32.463168: step 6585, loss 0.528773.
Train: 2018-07-31T00:56:32.603761: step 6586, loss 0.620487.
Train: 2018-07-31T00:56:32.744352: step 6587, loss 0.562433.
Train: 2018-07-31T00:56:32.884944: step 6588, loss 0.486392.
Train: 2018-07-31T00:56:33.025542: step 6589, loss 0.562206.
Train: 2018-07-31T00:56:33.181726: step 6590, loss 0.554553.
Test: 2018-07-31T00:56:33.416045: step 6590, loss 0.547937.
Train: 2018-07-31T00:56:33.572259: step 6591, loss 0.586692.
Train: 2018-07-31T00:56:33.712876: step 6592, loss 0.544639.
Train: 2018-07-31T00:56:33.853443: step 6593, loss 0.588872.
Train: 2018-07-31T00:56:33.994034: step 6594, loss 0.578361.
Train: 2018-07-31T00:56:34.150248: step 6595, loss 0.559797.
Train: 2018-07-31T00:56:34.290840: step 6596, loss 0.587467.
Train: 2018-07-31T00:56:34.447055: step 6597, loss 0.519165.
Train: 2018-07-31T00:56:34.587647: step 6598, loss 0.470673.
Train: 2018-07-31T00:56:34.728239: step 6599, loss 0.595502.
Train: 2018-07-31T00:56:34.868854: step 6600, loss 0.546893.
Test: 2018-07-31T00:56:35.103151: step 6600, loss 0.547924.
Train: 2018-07-31T00:56:35.821757: step 6601, loss 0.57117.
Train: 2018-07-31T00:56:35.977970: step 6602, loss 0.537647.
Train: 2018-07-31T00:56:36.134159: step 6603, loss 0.539461.
Train: 2018-07-31T00:56:36.274752: step 6604, loss 0.486149.
Train: 2018-07-31T00:56:36.415343: step 6605, loss 0.603692.
Train: 2018-07-31T00:56:36.571581: step 6606, loss 0.519387.
Train: 2018-07-31T00:56:36.712173: step 6607, loss 0.503691.
Train: 2018-07-31T00:56:36.852765: step 6608, loss 0.569947.
Train: 2018-07-31T00:56:36.993334: step 6609, loss 0.50868.
Train: 2018-07-31T00:56:37.133950: step 6610, loss 0.621177.
Test: 2018-07-31T00:56:37.383870: step 6610, loss 0.547871.
Train: 2018-07-31T00:56:37.524483: step 6611, loss 0.503176.
Train: 2018-07-31T00:56:37.680672: step 6612, loss 0.498559.
Train: 2018-07-31T00:56:37.821288: step 6613, loss 0.585223.
Train: 2018-07-31T00:56:37.977501: step 6614, loss 0.589436.
Train: 2018-07-31T00:56:38.118068: step 6615, loss 0.619865.
Train: 2018-07-31T00:56:38.274307: step 6616, loss 0.572614.
Train: 2018-07-31T00:56:38.430495: step 6617, loss 0.584224.
Train: 2018-07-31T00:56:38.571090: step 6618, loss 0.551197.
Train: 2018-07-31T00:56:38.711698: step 6619, loss 0.63651.
Train: 2018-07-31T00:56:38.852274: step 6620, loss 0.651132.
Test: 2018-07-31T00:56:39.086617: step 6620, loss 0.54816.
Train: 2018-07-31T00:56:39.227209: step 6621, loss 0.521833.
Train: 2018-07-31T00:56:39.367776: step 6622, loss 0.596497.
Train: 2018-07-31T00:56:39.508393: step 6623, loss 0.610343.
Train: 2018-07-31T00:56:39.664583: step 6624, loss 0.570524.
Train: 2018-07-31T00:56:39.805174: step 6625, loss 0.619563.
Train: 2018-07-31T00:56:39.961423: step 6626, loss 0.555184.
Train: 2018-07-31T00:56:40.086378: step 6627, loss 0.570949.
Train: 2018-07-31T00:56:40.242571: step 6628, loss 0.610329.
Train: 2018-07-31T00:56:40.383188: step 6629, loss 0.547604.
Train: 2018-07-31T00:56:40.523781: step 6630, loss 0.508877.
Test: 2018-07-31T00:56:40.773697: step 6630, loss 0.550384.
Train: 2018-07-31T00:56:40.929936: step 6631, loss 0.563385.
Train: 2018-07-31T00:56:41.086125: step 6632, loss 0.57117.
Train: 2018-07-31T00:56:41.226717: step 6633, loss 0.586665.
Train: 2018-07-31T00:56:41.367310: step 6634, loss 0.509416.
Train: 2018-07-31T00:56:41.507901: step 6635, loss 0.571209.
Train: 2018-07-31T00:56:41.632896: step 6636, loss 0.50938.
Train: 2018-07-31T00:56:41.789086: step 6637, loss 0.509232.
Train: 2018-07-31T00:56:41.929676: step 6638, loss 0.571137.
Train: 2018-07-31T00:56:42.070294: step 6639, loss 0.547714.
Train: 2018-07-31T00:56:42.210886: step 6640, loss 0.57106.
Test: 2018-07-31T00:56:42.445183: step 6640, loss 0.550036.
Train: 2018-07-31T00:56:42.601395: step 6641, loss 0.563179.
Train: 2018-07-31T00:56:42.741987: step 6642, loss 0.641838.
Train: 2018-07-31T00:56:42.882603: step 6643, loss 0.594623.
Train: 2018-07-31T00:56:43.023172: step 6644, loss 0.613537.
Train: 2018-07-31T00:56:43.163763: step 6645, loss 0.555248.
Train: 2018-07-31T00:56:43.304355: step 6646, loss 0.54739.
Train: 2018-07-31T00:56:43.444948: step 6647, loss 0.515899.
Train: 2018-07-31T00:56:43.585539: step 6648, loss 0.507914.
Train: 2018-07-31T00:56:43.726130: step 6649, loss 0.594675.
Train: 2018-07-31T00:56:43.866723: step 6650, loss 0.6264.
Test: 2018-07-31T00:56:44.116694: step 6650, loss 0.549731.
Train: 2018-07-31T00:56:44.257281: step 6651, loss 0.531299.
Train: 2018-07-31T00:56:44.397849: step 6652, loss 0.594733.
Train: 2018-07-31T00:56:44.538440: step 6653, loss 0.570917.
Train: 2018-07-31T00:56:44.694654: step 6654, loss 0.602692.
Train: 2018-07-31T00:56:44.835246: step 6655, loss 0.547095.
Train: 2018-07-31T00:56:44.991460: step 6656, loss 0.594742.
Train: 2018-07-31T00:56:45.147674: step 6657, loss 0.570921.
Train: 2018-07-31T00:56:45.288290: step 6658, loss 0.642321.
Train: 2018-07-31T00:56:45.428857: step 6659, loss 0.563032.
Train: 2018-07-31T00:56:45.569474: step 6660, loss 0.563065.
Test: 2018-07-31T00:56:45.819392: step 6660, loss 0.549885.
Train: 2018-07-31T00:56:45.959983: step 6661, loss 0.54732.
Train: 2018-07-31T00:56:46.100574: step 6662, loss 0.570986.
Train: 2018-07-31T00:56:46.256789: step 6663, loss 0.602486.
Train: 2018-07-31T00:56:46.397380: step 6664, loss 0.626035.
Train: 2018-07-31T00:56:46.537972: step 6665, loss 0.531843.
Train: 2018-07-31T00:56:46.678565: step 6666, loss 0.578881.
Train: 2018-07-31T00:56:46.819158: step 6667, loss 0.602331.
Train: 2018-07-31T00:56:46.959773: step 6668, loss 0.539902.
Train: 2018-07-31T00:56:47.115964: step 6669, loss 0.547739.
Train: 2018-07-31T00:56:47.256555: step 6670, loss 0.555537.
Test: 2018-07-31T00:56:47.490874: step 6670, loss 0.550278.
Train: 2018-07-31T00:56:47.647088: step 6671, loss 0.532169.
Train: 2018-07-31T00:56:47.787679: step 6672, loss 0.539906.
Train: 2018-07-31T00:56:47.928273: step 6673, loss 0.571074.
Train: 2018-07-31T00:56:48.068864: step 6674, loss 0.547575.
Train: 2018-07-31T00:56:48.225102: step 6675, loss 0.484749.
Train: 2018-07-31T00:56:48.365680: step 6676, loss 0.555235.
Train: 2018-07-31T00:56:48.521896: step 6677, loss 0.586771.
Train: 2018-07-31T00:56:48.662474: step 6678, loss 0.507436.
Train: 2018-07-31T00:56:48.818687: step 6679, loss 0.554944.
Train: 2018-07-31T00:56:48.974926: step 6680, loss 0.554845.
Test: 2018-07-31T00:56:49.209253: step 6680, loss 0.549327.
Train: 2018-07-31T00:56:49.349814: step 6681, loss 0.578875.
Train: 2018-07-31T00:56:49.490431: step 6682, loss 0.546611.
Train: 2018-07-31T00:56:49.631023: step 6683, loss 0.611282.
Train: 2018-07-31T00:56:49.787212: step 6684, loss 0.578904.
Train: 2018-07-31T00:56:49.927828: step 6685, loss 0.595159.
Train: 2018-07-31T00:56:50.068414: step 6686, loss 0.554525.
Train: 2018-07-31T00:56:50.209007: step 6687, loss 0.538242.
Train: 2018-07-31T00:56:50.349580: step 6688, loss 0.587067.
Train: 2018-07-31T00:56:50.505795: step 6689, loss 0.570776.
Train: 2018-07-31T00:56:50.662006: step 6690, loss 0.611533.
Test: 2018-07-31T00:56:50.896360: step 6690, loss 0.548994.
Train: 2018-07-31T00:56:51.052540: step 6691, loss 0.603354.
Train: 2018-07-31T00:56:51.193132: step 6692, loss 0.513876.
Train: 2018-07-31T00:56:51.333725: step 6693, loss 0.570785.
Train: 2018-07-31T00:56:51.474349: step 6694, loss 0.505814.
Train: 2018-07-31T00:56:51.630532: step 6695, loss 0.578912.
Train: 2018-07-31T00:56:51.771123: step 6696, loss 0.611443.
Train: 2018-07-31T00:56:51.927337: step 6697, loss 0.546407.
Train: 2018-07-31T00:56:52.067929: step 6698, loss 0.505798.
Train: 2018-07-31T00:56:52.208521: step 6699, loss 0.603313.
Train: 2018-07-31T00:56:52.349136: step 6700, loss 0.51385.
Test: 2018-07-31T00:56:52.599054: step 6700, loss 0.548997.
Train: 2018-07-31T00:56:53.317659: step 6701, loss 0.595207.
Train: 2018-07-31T00:56:53.458253: step 6702, loss 0.554485.
Train: 2018-07-31T00:56:53.598844: step 6703, loss 0.562626.
Train: 2018-07-31T00:56:53.739436: step 6704, loss 0.578928.
Train: 2018-07-31T00:56:53.895649: step 6705, loss 0.603389.
Train: 2018-07-31T00:56:54.067460: step 6706, loss 0.595215.
Train: 2018-07-31T00:56:54.208053: step 6707, loss 0.587047.
Train: 2018-07-31T00:56:54.348668: step 6708, loss 0.587022.
Train: 2018-07-31T00:56:54.489235: step 6709, loss 0.635568.
Train: 2018-07-31T00:56:54.645450: step 6710, loss 0.546623.
Test: 2018-07-31T00:56:54.879799: step 6710, loss 0.549329.
Train: 2018-07-31T00:56:55.036007: step 6711, loss 0.602992.
Train: 2018-07-31T00:56:55.176600: step 6712, loss 0.554836.
Train: 2018-07-31T00:56:55.332788: step 6713, loss 0.554905.
Train: 2018-07-31T00:56:55.489001: step 6714, loss 0.578859.
Train: 2018-07-31T00:56:55.629593: step 6715, loss 0.523235.
Train: 2018-07-31T00:56:55.785808: step 6716, loss 0.515359.
Train: 2018-07-31T00:56:55.926424: step 6717, loss 0.523276.
Train: 2018-07-31T00:56:56.067016: step 6718, loss 0.531146.
Train: 2018-07-31T00:56:56.223206: step 6719, loss 0.523069.
Train: 2018-07-31T00:56:56.363821: step 6720, loss 0.538886.
Test: 2018-07-31T00:56:56.598123: step 6720, loss 0.549381.
Train: 2018-07-31T00:56:56.738709: step 6721, loss 0.554798.
Train: 2018-07-31T00:56:56.879301: step 6722, loss 0.578876.
Train: 2018-07-31T00:56:57.019894: step 6723, loss 0.54659.
Train: 2018-07-31T00:56:57.176107: step 6724, loss 0.578895.
Train: 2018-07-31T00:56:57.332322: step 6725, loss 0.643832.
Train: 2018-07-31T00:56:57.472937: step 6726, loss 0.587022.
Train: 2018-07-31T00:56:57.613530: step 6727, loss 0.554565.
Train: 2018-07-31T00:56:57.754114: step 6728, loss 0.546458.
Train: 2018-07-31T00:56:57.910335: step 6729, loss 0.587016.
Train: 2018-07-31T00:56:58.050926: step 6730, loss 0.595123.
Test: 2018-07-31T00:56:58.300844: step 6730, loss 0.549126.
Train: 2018-07-31T00:56:58.441434: step 6731, loss 0.659915.
Train: 2018-07-31T00:56:58.597649: step 6732, loss 0.546585.
Train: 2018-07-31T00:56:58.753862: step 6733, loss 0.603041.
Train: 2018-07-31T00:56:58.894455: step 6734, loss 0.514639.
Train: 2018-07-31T00:56:59.035046: step 6735, loss 0.57085.
Train: 2018-07-31T00:56:59.175663: step 6736, loss 0.586867.
Train: 2018-07-31T00:56:59.316255: step 6737, loss 0.610814.
Train: 2018-07-31T00:56:59.456847: step 6738, loss 0.59479.
Train: 2018-07-31T00:56:59.597414: step 6739, loss 0.515338.
Train: 2018-07-31T00:56:59.738006: step 6740, loss 0.515438.
Test: 2018-07-31T00:56:59.972357: step 6740, loss 0.549728.
Train: 2018-07-31T00:57:00.128541: step 6741, loss 0.539222.
Train: 2018-07-31T00:57:00.269133: step 6742, loss 0.523327.
Train: 2018-07-31T00:57:00.409724: step 6743, loss 0.562964.
Train: 2018-07-31T00:57:00.550317: step 6744, loss 0.539053.
Train: 2018-07-31T00:57:00.690909: step 6745, loss 0.554921.
Train: 2018-07-31T00:57:00.831500: step 6746, loss 0.53087.
Train: 2018-07-31T00:57:00.972094: step 6747, loss 0.506659.
Train: 2018-07-31T00:57:01.112684: step 6748, loss 0.603049.
Train: 2018-07-31T00:57:01.268899: step 6749, loss 0.562727.
Train: 2018-07-31T00:57:01.425112: step 6750, loss 0.595101.
Test: 2018-07-31T00:57:01.659462: step 6750, loss 0.549082.
Train: 2018-07-31T00:57:01.800024: step 6751, loss 0.489651.
Train: 2018-07-31T00:57:01.956237: step 6752, loss 0.652179.
Train: 2018-07-31T00:57:02.112450: step 6753, loss 0.562631.
Train: 2018-07-31T00:57:02.268665: step 6754, loss 0.530018.
Train: 2018-07-31T00:57:02.409256: step 6755, loss 0.529958.
Train: 2018-07-31T00:57:02.549849: step 6756, loss 0.554408.
Train: 2018-07-31T00:57:02.706089: step 6757, loss 0.578958.
Train: 2018-07-31T00:57:02.862276: step 6758, loss 0.611795.
Train: 2018-07-31T00:57:03.002866: step 6759, loss 0.529725.
Train: 2018-07-31T00:57:03.143483: step 6760, loss 0.603614.
Test: 2018-07-31T00:57:03.393432: step 6760, loss 0.548794.
Train: 2018-07-31T00:57:03.533993: step 6761, loss 0.546127.
Train: 2018-07-31T00:57:03.674610: step 6762, loss 0.513279.
Train: 2018-07-31T00:57:03.815201: step 6763, loss 0.554317.
Train: 2018-07-31T00:57:03.955769: step 6764, loss 0.570757.
Train: 2018-07-31T00:57:04.111982: step 6765, loss 0.562519.
Train: 2018-07-31T00:57:04.252574: step 6766, loss 0.579001.
Train: 2018-07-31T00:57:04.408812: step 6767, loss 0.554265.
Train: 2018-07-31T00:57:04.565002: step 6768, loss 0.529513.
Train: 2018-07-31T00:57:04.705618: step 6769, loss 0.554243.
Train: 2018-07-31T00:57:04.846212: step 6770, loss 0.587287.
Test: 2018-07-31T00:57:05.096126: step 6770, loss 0.548643.
Train: 2018-07-31T00:57:05.236719: step 6771, loss 0.545954.
Train: 2018-07-31T00:57:05.377312: step 6772, loss 0.537668.
Train: 2018-07-31T00:57:05.533525: step 6773, loss 0.562476.
Train: 2018-07-31T00:57:05.674141: step 6774, loss 0.521034.
Train: 2018-07-31T00:57:05.830330: step 6775, loss 0.496052.
Train: 2018-07-31T00:57:05.970923: step 6776, loss 0.529139.
Train: 2018-07-31T00:57:06.111515: step 6777, loss 0.595825.
Train: 2018-07-31T00:57:06.252105: step 6778, loss 0.545665.
Train: 2018-07-31T00:57:06.392699: step 6779, loss 0.554009.
Train: 2018-07-31T00:57:06.533291: step 6780, loss 0.587592.
Test: 2018-07-31T00:57:06.767612: step 6780, loss 0.548293.
Train: 2018-07-31T00:57:06.908203: step 6781, loss 0.503498.
Train: 2018-07-31T00:57:07.048795: step 6782, loss 0.553946.
Train: 2018-07-31T00:57:07.205009: step 6783, loss 0.553923.
Train: 2018-07-31T00:57:07.345601: step 6784, loss 0.587723.
Train: 2018-07-31T00:57:07.486193: step 6785, loss 0.604701.
Train: 2018-07-31T00:57:07.626783: step 6786, loss 0.579275.
Train: 2018-07-31T00:57:07.767401: step 6787, loss 0.536993.
Train: 2018-07-31T00:57:07.923590: step 6788, loss 0.520101.
Train: 2018-07-31T00:57:08.048575: step 6789, loss 0.545477.
Train: 2018-07-31T00:57:08.220430: step 6790, loss 0.503165.
Test: 2018-07-31T00:57:08.501580: step 6790, loss 0.548163.
Train: 2018-07-31T00:57:08.642172: step 6791, loss 0.553876.
Train: 2018-07-31T00:57:08.798386: step 6792, loss 0.553883.
Train: 2018-07-31T00:57:08.938978: step 6793, loss 0.553805.
Train: 2018-07-31T00:57:09.079586: step 6794, loss 0.545308.
Train: 2018-07-31T00:57:09.220163: step 6795, loss 0.562433.
Train: 2018-07-31T00:57:09.360777: step 6796, loss 0.545301.
Train: 2018-07-31T00:57:09.501370: step 6797, loss 0.553755.
Train: 2018-07-31T00:57:09.641937: step 6798, loss 0.61365.
Train: 2018-07-31T00:57:09.782529: step 6799, loss 0.604972.
Train: 2018-07-31T00:57:09.923146: step 6800, loss 0.630458.
Test: 2018-07-31T00:57:10.173064: step 6800, loss 0.548151.
Train: 2018-07-31T00:57:10.907265: step 6801, loss 0.587789.
Train: 2018-07-31T00:57:11.047884: step 6802, loss 0.537024.
Train: 2018-07-31T00:57:11.188450: step 6803, loss 0.553955.
Train: 2018-07-31T00:57:11.329042: step 6804, loss 0.436425.
Train: 2018-07-31T00:57:11.469633: step 6805, loss 0.520389.
Train: 2018-07-31T00:57:11.610225: step 6806, loss 0.57079.
Train: 2018-07-31T00:57:11.750818: step 6807, loss 0.587618.
Train: 2018-07-31T00:57:11.907033: step 6808, loss 0.587613.
Train: 2018-07-31T00:57:12.047625: step 6809, loss 0.562385.
Train: 2018-07-31T00:57:12.188217: step 6810, loss 0.612757.
Test: 2018-07-31T00:57:12.422566: step 6810, loss 0.548373.
Train: 2018-07-31T00:57:12.578750: step 6811, loss 0.562401.
Train: 2018-07-31T00:57:12.719341: step 6812, loss 0.604204.
Train: 2018-07-31T00:57:12.859958: step 6813, loss 0.579098.
Train: 2018-07-31T00:57:13.000544: step 6814, loss 0.504308.
Train: 2018-07-31T00:57:13.141117: step 6815, loss 0.521002.
Train: 2018-07-31T00:57:13.297368: step 6816, loss 0.56247.
Train: 2018-07-31T00:57:13.453566: step 6817, loss 0.562474.
Train: 2018-07-31T00:57:13.609757: step 6818, loss 0.570757.
Train: 2018-07-31T00:57:13.750351: step 6819, loss 0.612106.
Train: 2018-07-31T00:57:13.890976: step 6820, loss 0.595516.
Test: 2018-07-31T00:57:14.140885: step 6820, loss 0.54874.
Train: 2018-07-31T00:57:14.281500: step 6821, loss 0.603684.
Train: 2018-07-31T00:57:14.437692: step 6822, loss 0.505128.
Train: 2018-07-31T00:57:14.578306: step 6823, loss 0.603517.
Train: 2018-07-31T00:57:14.734495: step 6824, loss 0.497242.
Train: 2018-07-31T00:57:14.890708: step 6825, loss 0.538094.
Train: 2018-07-31T00:57:15.031334: step 6826, loss 0.546221.
Train: 2018-07-31T00:57:15.187513: step 6827, loss 0.554422.
Train: 2018-07-31T00:57:15.328106: step 6828, loss 0.612082.
Train: 2018-07-31T00:57:15.484319: step 6829, loss 0.521691.
Train: 2018-07-31T00:57:15.640533: step 6830, loss 0.579053.
Test: 2018-07-31T00:57:15.874886: step 6830, loss 0.548927.
Train: 2018-07-31T00:57:16.015444: step 6831, loss 0.562704.
Train: 2018-07-31T00:57:16.171659: step 6832, loss 0.636048.
Train: 2018-07-31T00:57:16.312251: step 6833, loss 0.505639.
Train: 2018-07-31T00:57:16.452867: step 6834, loss 0.578919.
Train: 2018-07-31T00:57:16.593436: step 6835, loss 0.530113.
Train: 2018-07-31T00:57:16.749647: step 6836, loss 0.554511.
Train: 2018-07-31T00:57:16.890258: step 6837, loss 0.546366.
Train: 2018-07-31T00:57:17.030856: step 6838, loss 0.521915.
Train: 2018-07-31T00:57:17.171449: step 6839, loss 0.513673.
Train: 2018-07-31T00:57:17.327661: step 6840, loss 0.47262.
Test: 2018-07-31T00:57:17.577580: step 6840, loss 0.548784.
Train: 2018-07-31T00:57:17.765035: step 6841, loss 0.620054.
Train: 2018-07-31T00:57:17.905627: step 6842, loss 0.562519.
Train: 2018-07-31T00:57:18.046219: step 6843, loss 0.545986.
Train: 2018-07-31T00:57:18.186811: step 6844, loss 0.579033.
Train: 2018-07-31T00:57:18.327404: step 6845, loss 0.587339.
Train: 2018-07-31T00:57:18.467995: step 6846, loss 0.545865.
Train: 2018-07-31T00:57:18.608588: step 6847, loss 0.637211.
Train: 2018-07-31T00:57:18.749179: step 6848, loss 0.512664.
Train: 2018-07-31T00:57:18.889772: step 6849, loss 0.595663.
Train: 2018-07-31T00:57:19.030364: step 6850, loss 0.545869.
Test: 2018-07-31T00:57:19.264716: step 6850, loss 0.548573.
Train: 2018-07-31T00:57:19.420897: step 6851, loss 0.487816.
Train: 2018-07-31T00:57:19.561488: step 6852, loss 0.52923.
Train: 2018-07-31T00:57:19.702081: step 6853, loss 0.56244.
Train: 2018-07-31T00:57:19.842674: step 6854, loss 0.579101.
Train: 2018-07-31T00:57:20.014509: step 6855, loss 0.554079.
Train: 2018-07-31T00:57:20.170722: step 6856, loss 0.512306.
Train: 2018-07-31T00:57:20.311315: step 6857, loss 0.612617.
Train: 2018-07-31T00:57:20.451931: step 6858, loss 0.654511.
Train: 2018-07-31T00:57:20.592497: step 6859, loss 0.545694.
Train: 2018-07-31T00:57:20.748711: step 6860, loss 0.60415.
Test: 2018-07-31T00:57:20.998678: step 6860, loss 0.548496.
Train: 2018-07-31T00:57:21.139245: step 6861, loss 0.520795.
Train: 2018-07-31T00:57:21.279862: step 6862, loss 0.587382.
Train: 2018-07-31T00:57:21.420454: step 6863, loss 0.603958.
Train: 2018-07-31T00:57:21.561046: step 6864, loss 0.554188.
Train: 2018-07-31T00:57:21.701638: step 6865, loss 0.587256.
Train: 2018-07-31T00:57:21.842205: step 6866, loss 0.504849.
Train: 2018-07-31T00:57:21.998419: step 6867, loss 0.496701.
Train: 2018-07-31T00:57:22.139011: step 6868, loss 0.562502.
Train: 2018-07-31T00:57:22.279602: step 6869, loss 0.579106.
Train: 2018-07-31T00:57:22.435827: step 6870, loss 0.570856.
Test: 2018-07-31T00:57:22.670162: step 6870, loss 0.548718.
Train: 2018-07-31T00:57:22.810729: step 6871, loss 0.587249.
Train: 2018-07-31T00:57:22.951321: step 6872, loss 0.546019.
Train: 2018-07-31T00:57:23.107535: step 6873, loss 0.570639.
Train: 2018-07-31T00:57:23.248126: step 6874, loss 0.579055.
Train: 2018-07-31T00:57:23.388717: step 6875, loss 0.472222.
Train: 2018-07-31T00:57:23.529310: step 6876, loss 0.505028.
Train: 2018-07-31T00:57:23.669902: step 6877, loss 0.579107.
Train: 2018-07-31T00:57:23.810494: step 6878, loss 0.587199.
Train: 2018-07-31T00:57:23.951087: step 6879, loss 0.537802.
Train: 2018-07-31T00:57:24.091679: step 6880, loss 0.570784.
Test: 2018-07-31T00:57:24.341621: step 6880, loss 0.548589.
Train: 2018-07-31T00:57:24.482236: step 6881, loss 0.504307.
Train: 2018-07-31T00:57:24.622803: step 6882, loss 0.437613.
Train: 2018-07-31T00:57:24.779018: step 6883, loss 0.57926.
Train: 2018-07-31T00:57:24.919638: step 6884, loss 0.528383.
Train: 2018-07-31T00:57:25.060201: step 6885, loss 0.494937.
Train: 2018-07-31T00:57:25.216416: step 6886, loss 0.647105.
Train: 2018-07-31T00:57:25.357031: step 6887, loss 0.529672.
Train: 2018-07-31T00:57:25.513221: step 6888, loss 0.605249.
Train: 2018-07-31T00:57:25.653824: step 6889, loss 0.553051.
Train: 2018-07-31T00:57:25.794430: step 6890, loss 0.554492.
Test: 2018-07-31T00:57:26.044377: step 6890, loss 0.547953.
Train: 2018-07-31T00:57:26.184938: step 6891, loss 0.562631.
Train: 2018-07-31T00:57:26.325530: step 6892, loss 0.604568.
Train: 2018-07-31T00:57:26.466123: step 6893, loss 0.562509.
Train: 2018-07-31T00:57:26.606714: step 6894, loss 0.553911.
Train: 2018-07-31T00:57:26.762927: step 6895, loss 0.570743.
Train: 2018-07-31T00:57:26.903520: step 6896, loss 0.587603.
Train: 2018-07-31T00:57:27.059734: step 6897, loss 0.528642.
Train: 2018-07-31T00:57:27.200344: step 6898, loss 0.503419.
Train: 2018-07-31T00:57:27.340942: step 6899, loss 0.612926.
Train: 2018-07-31T00:57:27.497131: step 6900, loss 0.495127.
Test: 2018-07-31T00:57:27.731452: step 6900, loss 0.548301.
Train: 2018-07-31T00:57:28.481276: step 6901, loss 0.537146.
Train: 2018-07-31T00:57:28.621867: step 6902, loss 0.680163.
Train: 2018-07-31T00:57:28.762460: step 6903, loss 0.579177.
Train: 2018-07-31T00:57:28.903052: step 6904, loss 0.637754.
Train: 2018-07-31T00:57:29.043643: step 6905, loss 0.479051.
Train: 2018-07-31T00:57:29.184236: step 6906, loss 0.512511.
Train: 2018-07-31T00:57:29.324829: step 6907, loss 0.587392.
Train: 2018-07-31T00:57:29.465420: step 6908, loss 0.55415.
Train: 2018-07-31T00:57:29.621658: step 6909, loss 0.570758.
Train: 2018-07-31T00:57:29.762242: step 6910, loss 0.570757.
Test: 2018-07-31T00:57:29.996548: step 6910, loss 0.548627.
Train: 2018-07-31T00:57:30.152760: step 6911, loss 0.545936.
Train: 2018-07-31T00:57:30.293376: step 6912, loss 0.645145.
Train: 2018-07-31T00:57:30.449565: step 6913, loss 0.58724.
Train: 2018-07-31T00:57:30.590158: step 6914, loss 0.562544.
Train: 2018-07-31T00:57:30.746370: step 6915, loss 0.587146.
Train: 2018-07-31T00:57:30.886987: step 6916, loss 0.480963.
Train: 2018-07-31T00:57:31.027554: step 6917, loss 0.529993.
Train: 2018-07-31T00:57:31.168147: step 6918, loss 0.538153.
Train: 2018-07-31T00:57:31.308740: step 6919, loss 0.570772.
Train: 2018-07-31T00:57:31.449331: step 6920, loss 0.619736.
Test: 2018-07-31T00:57:31.699273: step 6920, loss 0.548973.
Train: 2018-07-31T00:57:31.839865: step 6921, loss 0.538171.
Train: 2018-07-31T00:57:31.980462: step 6922, loss 0.554482.
Train: 2018-07-31T00:57:32.136670: step 6923, loss 0.587068.
Train: 2018-07-31T00:57:32.277286: step 6924, loss 0.513805.
Train: 2018-07-31T00:57:32.417868: step 6925, loss 0.562635.
Train: 2018-07-31T00:57:32.558446: step 6926, loss 0.48931.
Train: 2018-07-31T00:57:32.714659: step 6927, loss 0.546278.
Train: 2018-07-31T00:57:32.855251: step 6928, loss 0.562583.
Train: 2018-07-31T00:57:33.011466: step 6929, loss 0.505162.
Train: 2018-07-31T00:57:33.167677: step 6930, loss 0.58721.
Test: 2018-07-31T00:57:33.402025: step 6930, loss 0.548705.
Train: 2018-07-31T00:57:33.558213: step 6931, loss 0.59549.
Train: 2018-07-31T00:57:33.698828: step 6932, loss 0.587264.
Train: 2018-07-31T00:57:33.823774: step 6933, loss 0.645072.
Train: 2018-07-31T00:57:33.964367: step 6934, loss 0.537781.
Train: 2018-07-31T00:57:34.120605: step 6935, loss 0.603702.
Train: 2018-07-31T00:57:34.261173: step 6936, loss 0.57898.
Train: 2018-07-31T00:57:34.417386: step 6937, loss 0.570761.
Train: 2018-07-31T00:57:34.557977: step 6938, loss 0.570765.
Train: 2018-07-31T00:57:34.698594: step 6939, loss 0.603444.
Train: 2018-07-31T00:57:34.839204: step 6940, loss 0.635939.
Test: 2018-07-31T00:57:35.089104: step 6940, loss 0.549101.
Train: 2018-07-31T00:57:35.229696: step 6941, loss 0.538354.
Train: 2018-07-31T00:57:35.370287: step 6942, loss 0.627384.
Train: 2018-07-31T00:57:35.510881: step 6943, loss 0.570828.
Train: 2018-07-31T00:57:35.667093: step 6944, loss 0.570854.
Train: 2018-07-31T00:57:35.807686: step 6945, loss 0.538959.
Train: 2018-07-31T00:57:35.948277: step 6946, loss 0.512014.
Train: 2018-07-31T00:57:36.088895: step 6947, loss 0.586807.
Train: 2018-07-31T00:57:36.245084: step 6948, loss 0.594732.
Train: 2018-07-31T00:57:36.385676: step 6949, loss 0.563017.
Train: 2018-07-31T00:57:36.526267: step 6950, loss 0.507692.
Test: 2018-07-31T00:57:36.760619: step 6950, loss 0.549799.
Train: 2018-07-31T00:57:36.916801: step 6951, loss 0.586768.
Train: 2018-07-31T00:57:37.057392: step 6952, loss 0.523523.
Train: 2018-07-31T00:57:37.213624: step 6953, loss 0.5393.
Train: 2018-07-31T00:57:37.354199: step 6954, loss 0.602631.
Train: 2018-07-31T00:57:37.494790: step 6955, loss 0.586786.
Train: 2018-07-31T00:57:37.635407: step 6956, loss 0.555073.
Train: 2018-07-31T00:57:37.776001: step 6957, loss 0.578861.
Train: 2018-07-31T00:57:37.916591: step 6958, loss 0.650248.
Train: 2018-07-31T00:57:38.088401: step 6959, loss 0.507613.
Train: 2018-07-31T00:57:38.229018: step 6960, loss 0.539287.
Test: 2018-07-31T00:57:38.478936: step 6960, loss 0.549759.
Train: 2018-07-31T00:57:38.635147: step 6961, loss 0.57886.
Train: 2018-07-31T00:57:38.791378: step 6962, loss 0.570939.
Train: 2018-07-31T00:57:38.931953: step 6963, loss 0.570937.
Train: 2018-07-31T00:57:39.072547: step 6964, loss 0.610554.
Train: 2018-07-31T00:57:39.213138: step 6965, loss 0.586776.
Train: 2018-07-31T00:57:39.353729: step 6966, loss 0.515614.
Train: 2018-07-31T00:57:39.494321: step 6967, loss 0.626305.
Train: 2018-07-31T00:57:39.634916: step 6968, loss 0.507784.
Train: 2018-07-31T00:57:39.775505: step 6969, loss 0.563059.
Train: 2018-07-31T00:57:39.916122: step 6970, loss 0.531427.
Test: 2018-07-31T00:57:40.150449: step 6970, loss 0.549765.
Train: 2018-07-31T00:57:40.306633: step 6971, loss 0.539272.
Train: 2018-07-31T00:57:40.447248: step 6972, loss 0.531254.
Train: 2018-07-31T00:57:40.587815: step 6973, loss 0.578858.
Train: 2018-07-31T00:57:40.728409: step 6974, loss 0.56291.
Train: 2018-07-31T00:57:40.869024: step 6975, loss 0.546894.
Train: 2018-07-31T00:57:41.009592: step 6976, loss 0.578865.
Train: 2018-07-31T00:57:41.165805: step 6977, loss 0.554789.
Train: 2018-07-31T00:57:41.306397: step 6978, loss 0.611045.
Train: 2018-07-31T00:57:41.446998: step 6979, loss 0.514491.
Train: 2018-07-31T00:57:41.603227: step 6980, loss 0.60307.
Test: 2018-07-31T00:57:41.853144: step 6980, loss 0.549231.
Train: 2018-07-31T00:57:42.009358: step 6981, loss 0.562745.
Train: 2018-07-31T00:57:42.149974: step 6982, loss 0.562736.
Train: 2018-07-31T00:57:42.290549: step 6983, loss 0.538485.
Train: 2018-07-31T00:57:42.431134: step 6984, loss 0.603165.
Train: 2018-07-31T00:57:42.571726: step 6985, loss 0.546523.
Train: 2018-07-31T00:57:42.712319: step 6986, loss 0.538409.
Train: 2018-07-31T00:57:42.852910: step 6987, loss 0.578901.
Train: 2018-07-31T00:57:42.993545: step 6988, loss 0.611354.
Train: 2018-07-31T00:57:43.134119: step 6989, loss 0.562684.
Train: 2018-07-31T00:57:43.290308: step 6990, loss 0.619423.
Test: 2018-07-31T00:57:43.524630: step 6990, loss 0.549161.
Train: 2018-07-31T00:57:43.665220: step 6991, loss 0.55462.
Train: 2018-07-31T00:57:43.805837: step 6992, loss 0.538488.
Train: 2018-07-31T00:57:43.962026: step 6993, loss 0.595036.
Train: 2018-07-31T00:57:44.102618: step 6994, loss 0.586947.
Train: 2018-07-31T00:57:44.243211: step 6995, loss 0.562773.
Train: 2018-07-31T00:57:44.383803: step 6996, loss 0.611035.
Train: 2018-07-31T00:57:44.524395: step 6997, loss 0.59491.
Train: 2018-07-31T00:57:44.664987: step 6998, loss 0.610855.
Train: 2018-07-31T00:57:44.805604: step 6999, loss 0.546985.
Train: 2018-07-31T00:57:44.946222: step 7000, loss 0.562966.
Test: 2018-07-31T00:57:45.196142: step 7000, loss 0.549729.
Train: 2018-07-31T00:57:45.945961: step 7001, loss 0.491661.
Train: 2018-07-31T00:57:46.102151: step 7002, loss 0.555082.
Train: 2018-07-31T00:57:46.258362: step 7003, loss 0.60264.
Train: 2018-07-31T00:57:46.398955: step 7004, loss 0.578859.
Train: 2018-07-31T00:57:46.539572: step 7005, loss 0.563031.
Train: 2018-07-31T00:57:46.680138: step 7006, loss 0.491854.
Train: 2018-07-31T00:57:46.836353: step 7007, loss 0.523413.
Train: 2018-07-31T00:57:46.992590: step 7008, loss 0.562978.
Train: 2018-07-31T00:57:47.133185: step 7009, loss 0.5709.
Train: 2018-07-31T00:57:47.289372: step 7010, loss 0.538985.
Test: 2018-07-31T00:57:47.523693: step 7010, loss 0.549482.
Train: 2018-07-31T00:57:47.679905: step 7011, loss 0.498911.
Train: 2018-07-31T00:57:47.820522: step 7012, loss 0.562815.
Train: 2018-07-31T00:57:47.976711: step 7013, loss 0.538596.
Train: 2018-07-31T00:57:48.117302: step 7014, loss 0.570803.
Train: 2018-07-31T00:57:48.257895: step 7015, loss 0.538327.
Train: 2018-07-31T00:57:48.398486: step 7016, loss 0.611503.
Train: 2018-07-31T00:57:48.539078: step 7017, loss 0.578934.
Train: 2018-07-31T00:57:48.679671: step 7018, loss 0.538071.
Train: 2018-07-31T00:57:48.835909: step 7019, loss 0.595334.
Train: 2018-07-31T00:57:48.992099: step 7020, loss 0.529776.
Test: 2018-07-31T00:57:49.226417: step 7020, loss 0.5488.
Train: 2018-07-31T00:57:49.382644: step 7021, loss 0.488658.
Train: 2018-07-31T00:57:49.523247: step 7022, loss 0.513106.
Train: 2018-07-31T00:57:49.663833: step 7023, loss 0.587293.
Train: 2018-07-31T00:57:49.804406: step 7024, loss 0.554174.
Train: 2018-07-31T00:57:49.945027: step 7025, loss 0.662215.
Train: 2018-07-31T00:57:50.101238: step 7026, loss 0.537505.
Train: 2018-07-31T00:57:50.237193: step 7027, loss 0.628986.
Train: 2018-07-31T00:57:50.393431: step 7028, loss 0.554144.
Train: 2018-07-31T00:57:50.534050: step 7029, loss 0.562459.
Train: 2018-07-31T00:57:50.674593: step 7030, loss 0.570758.
Test: 2018-07-31T00:57:50.924533: step 7030, loss 0.548607.
Train: 2018-07-31T00:57:51.065150: step 7031, loss 0.5956.
Train: 2018-07-31T00:57:51.221339: step 7032, loss 0.529429.
Train: 2018-07-31T00:57:51.361932: step 7033, loss 0.603784.
Train: 2018-07-31T00:57:51.502559: step 7034, loss 0.513072.
Train: 2018-07-31T00:57:51.643113: step 7035, loss 0.480168.
Train: 2018-07-31T00:57:51.799345: step 7036, loss 0.570757.
Train: 2018-07-31T00:57:51.939938: step 7037, loss 0.554249.
Train: 2018-07-31T00:57:52.080513: step 7038, loss 0.570757.
Train: 2018-07-31T00:57:52.221129: step 7039, loss 0.653418.
Train: 2018-07-31T00:57:52.361697: step 7040, loss 0.570756.
Test: 2018-07-31T00:57:52.596016: step 7040, loss 0.548723.
Train: 2018-07-31T00:57:52.752230: step 7041, loss 0.521329.
Train: 2018-07-31T00:57:52.892847: step 7042, loss 0.521363.
Train: 2018-07-31T00:57:53.033414: step 7043, loss 0.570757.
Train: 2018-07-31T00:57:53.189627: step 7044, loss 0.562522.
Train: 2018-07-31T00:57:53.330220: step 7045, loss 0.562522.
Train: 2018-07-31T00:57:53.470811: step 7046, loss 0.6284.
Train: 2018-07-31T00:57:53.611403: step 7047, loss 0.537875.
Train: 2018-07-31T00:57:53.751997: step 7048, loss 0.537907.
Train: 2018-07-31T00:57:53.892588: step 7049, loss 0.521497.
Train: 2018-07-31T00:57:54.048802: step 7050, loss 0.587191.
Test: 2018-07-31T00:57:54.283151: step 7050, loss 0.548785.
Train: 2018-07-31T00:57:54.439360: step 7051, loss 0.554329.
Train: 2018-07-31T00:57:54.579927: step 7052, loss 0.529677.
Train: 2018-07-31T00:57:54.720544: step 7053, loss 0.578981.
Train: 2018-07-31T00:57:54.876758: step 7054, loss 0.554306.
Train: 2018-07-31T00:57:55.017325: step 7055, loss 0.546069.
Train: 2018-07-31T00:57:55.157947: step 7056, loss 0.537811.
Train: 2018-07-31T00:57:55.298508: step 7057, loss 0.628487.
Train: 2018-07-31T00:57:55.439146: step 7058, loss 0.58724.
Train: 2018-07-31T00:57:55.579717: step 7059, loss 0.546062.
Train: 2018-07-31T00:57:55.720285: step 7060, loss 0.628342.
Test: 2018-07-31T00:57:55.970227: step 7060, loss 0.548805.
Train: 2018-07-31T00:57:56.110818: step 7061, loss 0.57076.
Train: 2018-07-31T00:57:56.267032: step 7062, loss 0.538005.
Train: 2018-07-31T00:57:56.407653: step 7063, loss 0.505342.
Train: 2018-07-31T00:57:56.563838: step 7064, loss 0.562589.
Train: 2018-07-31T00:57:56.720052: step 7065, loss 0.61984.
Train: 2018-07-31T00:57:56.860644: step 7066, loss 0.578937.
Train: 2018-07-31T00:57:57.001236: step 7067, loss 0.538156.
Train: 2018-07-31T00:57:57.141852: step 7068, loss 0.554482.
Train: 2018-07-31T00:57:57.282420: step 7069, loss 0.603348.
Train: 2018-07-31T00:57:57.423036: step 7070, loss 0.554522.
Test: 2018-07-31T00:57:57.672983: step 7070, loss 0.549061.
Train: 2018-07-31T00:57:57.813544: step 7071, loss 0.570786.
Train: 2018-07-31T00:57:57.969758: step 7072, loss 0.587014.
Train: 2018-07-31T00:57:58.110350: step 7073, loss 0.586995.
Train: 2018-07-31T00:57:58.250968: step 7074, loss 0.578884.
Train: 2018-07-31T00:57:58.391559: step 7075, loss 0.570817.
Train: 2018-07-31T00:57:58.547749: step 7076, loss 0.546687.
Train: 2018-07-31T00:57:58.688363: step 7077, loss 0.530655.
Train: 2018-07-31T00:57:58.828959: step 7078, loss 0.570835.
Train: 2018-07-31T00:57:58.985146: step 7079, loss 0.570813.
Train: 2018-07-31T00:57:59.125737: step 7080, loss 0.498553.
Test: 2018-07-31T00:57:59.360088: step 7080, loss 0.549257.
Train: 2018-07-31T00:57:59.500673: step 7081, loss 0.506628.
Train: 2018-07-31T00:57:59.641250: step 7082, loss 0.506359.
Train: 2018-07-31T00:57:59.813077: step 7083, loss 0.578992.
Train: 2018-07-31T00:57:59.953667: step 7084, loss 0.562633.
Train: 2018-07-31T00:58:00.094262: step 7085, loss 0.521936.
Train: 2018-07-31T00:58:00.234853: step 7086, loss 0.554477.
Train: 2018-07-31T00:58:00.375480: step 7087, loss 0.537808.
Train: 2018-07-31T00:58:00.516062: step 7088, loss 0.455153.
Train: 2018-07-31T00:58:00.672251: step 7089, loss 0.613188.
Train: 2018-07-31T00:58:00.828463: step 7090, loss 0.562403.
Test: 2018-07-31T00:58:01.062810: step 7090, loss 0.548329.
Train: 2018-07-31T00:58:01.203402: step 7091, loss 0.545876.
Train: 2018-07-31T00:58:01.359613: step 7092, loss 0.570841.
Train: 2018-07-31T00:58:01.500206: step 7093, loss 0.603938.
Train: 2018-07-31T00:58:01.640798: step 7094, loss 0.562257.
Train: 2018-07-31T00:58:01.781389: step 7095, loss 0.528722.
Train: 2018-07-31T00:58:01.937579: step 7096, loss 0.511574.
Train: 2018-07-31T00:58:02.078171: step 7097, loss 0.598413.
Train: 2018-07-31T00:58:02.218788: step 7098, loss 0.570524.
Train: 2018-07-31T00:58:02.359356: step 7099, loss 0.52893.
Train: 2018-07-31T00:58:02.515568: step 7100, loss 0.552861.
Test: 2018-07-31T00:58:02.749889: step 7100, loss 0.54799.
Train: 2018-07-31T00:58:03.468496: step 7101, loss 0.63793.
Train: 2018-07-31T00:58:03.609064: step 7102, loss 0.605669.
Train: 2018-07-31T00:58:03.765306: step 7103, loss 0.562456.
Train: 2018-07-31T00:58:03.921490: step 7104, loss 0.59041.
Train: 2018-07-31T00:58:04.062083: step 7105, loss 0.621771.
Train: 2018-07-31T00:58:04.202698: step 7106, loss 0.562637.
Train: 2018-07-31T00:58:04.343299: step 7107, loss 0.546015.
Train: 2018-07-31T00:58:04.483874: step 7108, loss 0.545934.
Train: 2018-07-31T00:58:04.624474: step 7109, loss 0.562521.
Train: 2018-07-31T00:58:04.780664: step 7110, loss 0.570759.
Test: 2018-07-31T00:58:05.014984: step 7110, loss 0.548844.
Train: 2018-07-31T00:58:05.171198: step 7111, loss 0.546178.
Train: 2018-07-31T00:58:05.311813: step 7112, loss 0.546226.
Train: 2018-07-31T00:58:05.452405: step 7113, loss 0.554429.
Train: 2018-07-31T00:58:05.592973: step 7114, loss 0.529961.
Train: 2018-07-31T00:58:05.733569: step 7115, loss 0.538126.
Train: 2018-07-31T00:58:05.889778: step 7116, loss 0.497275.
Train: 2018-07-31T00:58:06.030371: step 7117, loss 0.595328.
Train: 2018-07-31T00:58:06.170986: step 7118, loss 0.636323.
Train: 2018-07-31T00:58:06.311579: step 7119, loss 0.619876.
Train: 2018-07-31T00:58:06.467767: step 7120, loss 0.570762.
Test: 2018-07-31T00:58:06.702089: step 7120, loss 0.548971.
Train: 2018-07-31T00:58:06.858302: step 7121, loss 0.554477.
Train: 2018-07-31T00:58:06.998918: step 7122, loss 0.538244.
Train: 2018-07-31T00:58:07.155131: step 7123, loss 0.578909.
Train: 2018-07-31T00:58:07.295699: step 7124, loss 0.554557.
Train: 2018-07-31T00:58:07.436290: step 7125, loss 0.611336.
Train: 2018-07-31T00:58:07.576882: step 7126, loss 0.50606.
Train: 2018-07-31T00:58:07.717474: step 7127, loss 0.595072.
Train: 2018-07-31T00:58:07.873714: step 7128, loss 0.603131.
Train: 2018-07-31T00:58:08.029903: step 7129, loss 0.603078.
Train: 2018-07-31T00:58:08.170493: step 7130, loss 0.586918.
Test: 2018-07-31T00:58:08.404845: step 7130, loss 0.549398.
Train: 2018-07-31T00:58:08.545406: step 7131, loss 0.570847.
Train: 2018-07-31T00:58:08.685999: step 7132, loss 0.49088.
Train: 2018-07-31T00:58:08.842212: step 7133, loss 0.618832.
Train: 2018-07-31T00:58:08.982804: step 7134, loss 0.618757.
Train: 2018-07-31T00:58:09.123396: step 7135, loss 0.539079.
Train: 2018-07-31T00:58:09.263988: step 7136, loss 0.555036.
Train: 2018-07-31T00:58:09.404580: step 7137, loss 0.634369.
Train: 2018-07-31T00:58:09.545215: step 7138, loss 0.594675.
Train: 2018-07-31T00:58:09.685764: step 7139, loss 0.523697.
Train: 2018-07-31T00:58:09.841977: step 7140, loss 0.539531.
Test: 2018-07-31T00:58:10.076329: step 7140, loss 0.550015.
Train: 2018-07-31T00:58:10.232536: step 7141, loss 0.539562.
Train: 2018-07-31T00:58:10.388724: step 7142, loss 0.571007.
Train: 2018-07-31T00:58:10.529317: step 7143, loss 0.547416.
Train: 2018-07-31T00:58:10.685531: step 7144, loss 0.547393.
Train: 2018-07-31T00:58:10.826139: step 7145, loss 0.594622.
Train: 2018-07-31T00:58:10.966714: step 7146, loss 0.602512.
Train: 2018-07-31T00:58:11.122928: step 7147, loss 0.586744.
Train: 2018-07-31T00:58:11.263544: step 7148, loss 0.563119.
Train: 2018-07-31T00:58:11.404113: step 7149, loss 0.602475.
Train: 2018-07-31T00:58:11.544721: step 7150, loss 0.531717.
Test: 2018-07-31T00:58:11.779026: step 7150, loss 0.54999.
Train: 2018-07-31T00:58:11.935262: step 7151, loss 0.516005.
Train: 2018-07-31T00:58:12.075829: step 7152, loss 0.578873.
Train: 2018-07-31T00:58:12.216447: step 7153, loss 0.539474.
Train: 2018-07-31T00:58:12.372660: step 7154, loss 0.499968.
Train: 2018-07-31T00:58:12.513245: step 7155, loss 0.594731.
Train: 2018-07-31T00:58:12.653819: step 7156, loss 0.539183.
Train: 2018-07-31T00:58:12.794429: step 7157, loss 0.59477.
Train: 2018-07-31T00:58:12.950625: step 7158, loss 0.586823.
Train: 2018-07-31T00:58:13.075595: step 7159, loss 0.554915.
Train: 2018-07-31T00:58:13.216187: step 7160, loss 0.522919.
Test: 2018-07-31T00:58:13.466141: step 7160, loss 0.549392.
Train: 2018-07-31T00:58:13.606721: step 7161, loss 0.554812.
Train: 2018-07-31T00:58:13.747314: step 7162, loss 0.54675.
Train: 2018-07-31T00:58:13.887905: step 7163, loss 0.546671.
Train: 2018-07-31T00:58:14.044121: step 7164, loss 0.554657.
Train: 2018-07-31T00:58:14.184710: step 7165, loss 0.562712.
Train: 2018-07-31T00:58:14.325305: step 7166, loss 0.562641.
Train: 2018-07-31T00:58:14.465894: step 7167, loss 0.546356.
Train: 2018-07-31T00:58:14.622108: step 7168, loss 0.603439.
Train: 2018-07-31T00:58:14.747103: step 7169, loss 0.497243.
Train: 2018-07-31T00:58:14.887723: step 7170, loss 0.595347.
Test: 2018-07-31T00:58:15.137613: step 7170, loss 0.548805.
Train: 2018-07-31T00:58:15.278229: step 7171, loss 0.620028.
Train: 2018-07-31T00:58:15.434419: step 7172, loss 0.636442.
Train: 2018-07-31T00:58:15.575028: step 7173, loss 0.554374.
Train: 2018-07-31T00:58:15.731225: step 7174, loss 0.546241.
Train: 2018-07-31T00:58:15.871840: step 7175, loss 0.562599.
Train: 2018-07-31T00:58:16.028029: step 7176, loss 0.57077.
Train: 2018-07-31T00:58:16.168647: step 7177, loss 0.546318.
Train: 2018-07-31T00:58:16.324835: step 7178, loss 0.619665.
Train: 2018-07-31T00:58:16.465451: step 7179, loss 0.587048.
Train: 2018-07-31T00:58:16.621639: step 7180, loss 0.505868.
Test: 2018-07-31T00:58:16.855960: step 7180, loss 0.54913.
Train: 2018-07-31T00:58:16.996553: step 7181, loss 0.522129.
Train: 2018-07-31T00:58:17.152767: step 7182, loss 0.55456.
Train: 2018-07-31T00:58:17.293382: step 7183, loss 0.530187.
Train: 2018-07-31T00:58:17.433965: step 7184, loss 0.530123.
Train: 2018-07-31T00:58:17.574590: step 7185, loss 0.644117.
Train: 2018-07-31T00:58:17.715159: step 7186, loss 0.603368.
Train: 2018-07-31T00:58:17.855727: step 7187, loss 0.546361.
Train: 2018-07-31T00:58:17.996319: step 7188, loss 0.521972.
Train: 2018-07-31T00:58:18.152555: step 7189, loss 0.546363.
Train: 2018-07-31T00:58:18.308745: step 7190, loss 0.570774.
Test: 2018-07-31T00:58:18.543092: step 7190, loss 0.548961.
Train: 2018-07-31T00:58:18.683656: step 7191, loss 0.587073.
Train: 2018-07-31T00:58:18.839871: step 7192, loss 0.54632.
Train: 2018-07-31T00:58:18.996083: step 7193, loss 0.497365.
Train: 2018-07-31T00:58:19.136676: step 7194, loss 0.538054.
Train: 2018-07-31T00:58:19.292891: step 7195, loss 0.603424.
Train: 2018-07-31T00:58:19.433481: step 7196, loss 0.488712.
Train: 2018-07-31T00:58:19.589719: step 7197, loss 0.496068.
Train: 2018-07-31T00:58:19.730320: step 7198, loss 0.587607.
Train: 2018-07-31T00:58:19.886525: step 7199, loss 0.54574.
Train: 2018-07-31T00:58:20.027093: step 7200, loss 0.56095.
Test: 2018-07-31T00:58:20.277033: step 7200, loss 0.547923.
Train: 2018-07-31T00:58:21.011237: step 7201, loss 0.545596.
Train: 2018-07-31T00:58:21.151829: step 7202, loss 0.495101.
Train: 2018-07-31T00:58:21.292420: step 7203, loss 0.639616.
Train: 2018-07-31T00:58:21.448636: step 7204, loss 0.597987.
Train: 2018-07-31T00:58:21.589227: step 7205, loss 0.502029.
Train: 2018-07-31T00:58:21.729827: step 7206, loss 0.503756.
Train: 2018-07-31T00:58:21.870436: step 7207, loss 0.57119.
Train: 2018-07-31T00:58:22.011002: step 7208, loss 0.55323.
Train: 2018-07-31T00:58:22.167217: step 7209, loss 0.571697.
Train: 2018-07-31T00:58:22.307833: step 7210, loss 0.553816.
Test: 2018-07-31T00:58:22.542130: step 7210, loss 0.548198.
Train: 2018-07-31T00:58:22.682721: step 7211, loss 0.545295.
Train: 2018-07-31T00:58:22.854555: step 7212, loss 0.604507.
Train: 2018-07-31T00:58:22.995172: step 7213, loss 0.579171.
Train: 2018-07-31T00:58:23.135766: step 7214, loss 0.520518.
Train: 2018-07-31T00:58:23.291954: step 7215, loss 0.495277.
Train: 2018-07-31T00:58:23.432572: step 7216, loss 0.56237.
Train: 2018-07-31T00:58:23.588783: step 7217, loss 0.545582.
Train: 2018-07-31T00:58:23.729379: step 7218, loss 0.545438.
Train: 2018-07-31T00:58:23.869942: step 7219, loss 0.562287.
Train: 2018-07-31T00:58:24.010534: step 7220, loss 0.629801.
Test: 2018-07-31T00:58:24.244886: step 7220, loss 0.548278.
Train: 2018-07-31T00:58:24.416691: step 7221, loss 0.511674.
Train: 2018-07-31T00:58:24.557280: step 7222, loss 0.54556.
Train: 2018-07-31T00:58:24.713496: step 7223, loss 0.528435.
Train: 2018-07-31T00:58:24.854088: step 7224, loss 0.51125.
Train: 2018-07-31T00:58:24.994680: step 7225, loss 0.570857.
Train: 2018-07-31T00:58:25.135271: step 7226, loss 0.485926.
Train: 2018-07-31T00:58:25.275864: step 7227, loss 0.579416.
Train: 2018-07-31T00:58:25.416457: step 7228, loss 0.588106.
Train: 2018-07-31T00:58:25.557049: step 7229, loss 0.561263.
Train: 2018-07-31T00:58:25.697640: step 7230, loss 0.517373.
Test: 2018-07-31T00:58:25.931991: step 7230, loss 0.547733.
Train: 2018-07-31T00:58:26.088197: step 7231, loss 0.589805.
Train: 2018-07-31T00:58:26.244388: step 7232, loss 0.578959.
Train: 2018-07-31T00:58:26.385003: step 7233, loss 0.603368.
Train: 2018-07-31T00:58:26.541193: step 7234, loss 0.578704.
Train: 2018-07-31T00:58:26.681784: step 7235, loss 0.623312.
Train: 2018-07-31T00:58:26.822401: step 7236, loss 0.531641.
Train: 2018-07-31T00:58:26.978614: step 7237, loss 0.599133.
Train: 2018-07-31T00:58:27.119207: step 7238, loss 0.537435.
Train: 2018-07-31T00:58:27.259773: step 7239, loss 0.529227.
Train: 2018-07-31T00:58:27.415986: step 7240, loss 0.596024.
Test: 2018-07-31T00:58:27.650338: step 7240, loss 0.548532.
Train: 2018-07-31T00:58:27.790900: step 7241, loss 0.504335.
Train: 2018-07-31T00:58:27.947138: step 7242, loss 0.587276.
Train: 2018-07-31T00:58:28.087705: step 7243, loss 0.554252.
Train: 2018-07-31T00:58:28.228322: step 7244, loss 0.578989.
Train: 2018-07-31T00:58:28.368890: step 7245, loss 0.488591.
Train: 2018-07-31T00:58:28.509481: step 7246, loss 0.54611.
Train: 2018-07-31T00:58:28.665695: step 7247, loss 0.562544.
Train: 2018-07-31T00:58:28.806312: step 7248, loss 0.702885.
Train: 2018-07-31T00:58:28.946880: step 7249, loss 0.52158.
Train: 2018-07-31T00:58:29.103093: step 7250, loss 0.505317.
Test: 2018-07-31T00:58:29.337446: step 7250, loss 0.548888.
Train: 2018-07-31T00:58:29.478029: step 7251, loss 0.587118.
Train: 2018-07-31T00:58:29.634242: step 7252, loss 0.611617.
Train: 2018-07-31T00:58:29.774810: step 7253, loss 0.587092.
Train: 2018-07-31T00:58:29.915402: step 7254, loss 0.521982.
Train: 2018-07-31T00:58:30.055995: step 7255, loss 0.546412.
Train: 2018-07-31T00:58:30.212232: step 7256, loss 0.505838.
Train: 2018-07-31T00:58:30.352799: step 7257, loss 0.473283.
Train: 2018-07-31T00:58:30.509015: step 7258, loss 0.562647.
Train: 2018-07-31T00:58:30.649606: step 7259, loss 0.529903.
Train: 2018-07-31T00:58:30.790197: step 7260, loss 0.537959.
Test: 2018-07-31T00:58:31.040167: step 7260, loss 0.548742.
Train: 2018-07-31T00:58:31.180767: step 7261, loss 0.620186.
Train: 2018-07-31T00:58:31.321324: step 7262, loss 0.562516.
Train: 2018-07-31T00:58:31.461915: step 7263, loss 0.595488.
Train: 2018-07-31T00:58:31.602508: step 7264, loss 0.479977.
Train: 2018-07-31T00:58:31.727478: step 7265, loss 0.512811.
Train: 2018-07-31T00:58:31.883690: step 7266, loss 0.58732.
Train: 2018-07-31T00:58:32.024308: step 7267, loss 0.61238.
Train: 2018-07-31T00:58:32.164903: step 7268, loss 0.520736.
Train: 2018-07-31T00:58:32.321125: step 7269, loss 0.504059.
Train: 2018-07-31T00:58:32.461680: step 7270, loss 0.587728.
Test: 2018-07-31T00:58:32.696000: step 7270, loss 0.548378.
Train: 2018-07-31T00:58:32.852213: step 7271, loss 0.595995.
Train: 2018-07-31T00:58:32.992806: step 7272, loss 0.562406.
Train: 2018-07-31T00:58:33.133428: step 7273, loss 0.579185.
Train: 2018-07-31T00:58:33.274037: step 7274, loss 0.579103.
Train: 2018-07-31T00:58:33.414582: step 7275, loss 0.520565.
Train: 2018-07-31T00:58:33.555174: step 7276, loss 0.679587.
Train: 2018-07-31T00:58:33.695767: step 7277, loss 0.579109.
Train: 2018-07-31T00:58:33.836358: step 7278, loss 0.520869.
Train: 2018-07-31T00:58:33.976975: step 7279, loss 0.554159.
Train: 2018-07-31T00:58:34.117542: step 7280, loss 0.554182.
Test: 2018-07-31T00:58:34.367484: step 7280, loss 0.548621.
Train: 2018-07-31T00:58:34.523722: step 7281, loss 0.562479.
Train: 2018-07-31T00:58:34.664290: step 7282, loss 0.537688.
Train: 2018-07-31T00:58:34.804883: step 7283, loss 0.570756.
Train: 2018-07-31T00:58:34.961096: step 7284, loss 0.554245.
Train: 2018-07-31T00:58:35.101707: step 7285, loss 0.579007.
Train: 2018-07-31T00:58:35.242304: step 7286, loss 0.537785.
Train: 2018-07-31T00:58:35.382873: step 7287, loss 0.529554.
Train: 2018-07-31T00:58:35.539085: step 7288, loss 0.603733.
Train: 2018-07-31T00:58:35.679677: step 7289, loss 0.562525.
Train: 2018-07-31T00:58:35.820269: step 7290, loss 0.578983.
Test: 2018-07-31T00:58:36.054620: step 7290, loss 0.548765.
Train: 2018-07-31T00:58:36.195183: step 7291, loss 0.578987.
Train: 2018-07-31T00:58:36.351418: step 7292, loss 0.603616.
Train: 2018-07-31T00:58:36.507633: step 7293, loss 0.537986.
Train: 2018-07-31T00:58:36.648200: step 7294, loss 0.513489.
Train: 2018-07-31T00:58:36.804414: step 7295, loss 0.562581.
Train: 2018-07-31T00:58:36.945007: step 7296, loss 0.497148.
Train: 2018-07-31T00:58:37.085622: step 7297, loss 0.619912.
Train: 2018-07-31T00:58:37.241812: step 7298, loss 0.52981.
Train: 2018-07-31T00:58:37.382414: step 7299, loss 0.546169.
Train: 2018-07-31T00:58:37.522994: step 7300, loss 0.570758.
Test: 2018-07-31T00:58:37.772938: step 7300, loss 0.548804.
Train: 2018-07-31T00:58:38.569625: step 7301, loss 0.570771.
Train: 2018-07-31T00:58:38.710243: step 7302, loss 0.554324.
Train: 2018-07-31T00:58:38.850835: step 7303, loss 0.537887.
Train: 2018-07-31T00:58:38.991426: step 7304, loss 0.570752.
Train: 2018-07-31T00:58:39.147615: step 7305, loss 0.562524.
Train: 2018-07-31T00:58:39.288206: step 7306, loss 0.570733.
Train: 2018-07-31T00:58:39.444421: step 7307, loss 0.521385.
Train: 2018-07-31T00:58:39.585014: step 7308, loss 0.579001.
Train: 2018-07-31T00:58:39.725605: step 7309, loss 0.537771.
Train: 2018-07-31T00:58:39.866196: step 7310, loss 0.537674.
Test: 2018-07-31T00:58:40.100550: step 7310, loss 0.548625.
Train: 2018-07-31T00:58:40.256731: step 7311, loss 0.612056.
Train: 2018-07-31T00:58:40.397346: step 7312, loss 0.56252.
Train: 2018-07-31T00:58:40.553560: step 7313, loss 0.512845.
Train: 2018-07-31T00:58:40.694128: step 7314, loss 0.53753.
Train: 2018-07-31T00:58:40.850366: step 7315, loss 0.545799.
Train: 2018-07-31T00:58:40.990958: step 7316, loss 0.604082.
Train: 2018-07-31T00:58:41.147147: step 7317, loss 0.554163.
Train: 2018-07-31T00:58:41.287739: step 7318, loss 0.570723.
Train: 2018-07-31T00:58:41.443955: step 7319, loss 0.562533.
Train: 2018-07-31T00:58:41.584578: step 7320, loss 0.545725.
Test: 2018-07-31T00:58:41.818895: step 7320, loss 0.548483.
Train: 2018-07-31T00:58:41.975078: step 7321, loss 0.562556.
Train: 2018-07-31T00:58:42.115695: step 7322, loss 0.520705.
Train: 2018-07-31T00:58:42.271884: step 7323, loss 0.512254.
Train: 2018-07-31T00:58:42.412475: step 7324, loss 0.570886.
Train: 2018-07-31T00:58:42.537471: step 7325, loss 0.570637.
Train: 2018-07-31T00:58:42.678038: step 7326, loss 0.554261.
Train: 2018-07-31T00:58:42.834251: step 7327, loss 0.545584.
Train: 2018-07-31T00:58:42.959222: step 7328, loss 0.562614.
Train: 2018-07-31T00:58:43.099814: step 7329, loss 0.545551.
Train: 2018-07-31T00:58:43.256028: step 7330, loss 0.570604.
Test: 2018-07-31T00:58:43.490378: step 7330, loss 0.548275.
Train: 2018-07-31T00:58:43.646561: step 7331, loss 0.570835.
Train: 2018-07-31T00:58:43.771532: step 7332, loss 0.50351.
Train: 2018-07-31T00:58:43.912125: step 7333, loss 0.60434.
Train: 2018-07-31T00:58:44.068338: step 7334, loss 0.613121.
Train: 2018-07-31T00:58:44.208954: step 7335, loss 0.587666.
Train: 2018-07-31T00:58:44.349522: step 7336, loss 0.537167.
Train: 2018-07-31T00:58:44.474492: step 7337, loss 0.55394.
Train: 2018-07-31T00:58:44.615084: step 7338, loss 0.570736.
Train: 2018-07-31T00:58:44.755701: step 7339, loss 0.604146.
Train: 2018-07-31T00:58:44.911891: step 7340, loss 0.595858.
Test: 2018-07-31T00:58:45.146210: step 7340, loss 0.548544.
Train: 2018-07-31T00:58:45.286802: step 7341, loss 0.56248.
Train: 2018-07-31T00:58:45.443041: step 7342, loss 0.595496.
Train: 2018-07-31T00:58:45.583636: step 7343, loss 0.570726.
Train: 2018-07-31T00:58:45.739846: step 7344, loss 0.587228.
Train: 2018-07-31T00:58:45.896035: step 7345, loss 0.546192.
Train: 2018-07-31T00:58:46.036627: step 7346, loss 0.530028.
Train: 2018-07-31T00:58:46.177220: step 7347, loss 0.521886.
Train: 2018-07-31T00:58:46.317812: step 7348, loss 0.538203.
Train: 2018-07-31T00:58:46.458404: step 7349, loss 0.473082.
Train: 2018-07-31T00:58:46.598995: step 7350, loss 0.578922.
Test: 2018-07-31T00:58:46.833349: step 7350, loss 0.548901.
Train: 2018-07-31T00:58:46.973932: step 7351, loss 0.603463.
Train: 2018-07-31T00:58:47.130145: step 7352, loss 0.603504.
Train: 2018-07-31T00:58:47.270737: step 7353, loss 0.529898.
Train: 2018-07-31T00:58:47.411305: step 7354, loss 0.570726.
Train: 2018-07-31T00:58:47.567543: step 7355, loss 0.562588.
Train: 2018-07-31T00:58:47.708137: step 7356, loss 0.579007.
Train: 2018-07-31T00:58:47.848727: step 7357, loss 0.603491.
Train: 2018-07-31T00:58:48.004915: step 7358, loss 0.529993.
Train: 2018-07-31T00:58:48.145533: step 7359, loss 0.562615.
Train: 2018-07-31T00:58:48.286125: step 7360, loss 0.562631.
Test: 2018-07-31T00:58:48.536072: step 7360, loss 0.548995.
Train: 2018-07-31T00:58:48.692256: step 7361, loss 0.595212.
Train: 2018-07-31T00:58:48.848470: step 7362, loss 0.554507.
Train: 2018-07-31T00:58:48.989060: step 7363, loss 0.481396.
Train: 2018-07-31T00:58:49.129677: step 7364, loss 0.595186.
Train: 2018-07-31T00:58:49.270269: step 7365, loss 0.554492.
Train: 2018-07-31T00:58:49.426457: step 7366, loss 0.635924.
Train: 2018-07-31T00:58:49.551429: step 7367, loss 0.546374.
Train: 2018-07-31T00:58:49.707656: step 7368, loss 0.562657.
Train: 2018-07-31T00:58:49.848233: step 7369, loss 0.57893.
Train: 2018-07-31T00:58:49.988851: step 7370, loss 0.603242.
Test: 2018-07-31T00:58:50.238769: step 7370, loss 0.549133.
Train: 2018-07-31T00:58:50.379360: step 7371, loss 0.619399.
Train: 2018-07-31T00:58:50.535598: step 7372, loss 0.578891.
Train: 2018-07-31T00:58:50.676167: step 7373, loss 0.55473.
Train: 2018-07-31T00:58:50.816759: step 7374, loss 0.530698.
Train: 2018-07-31T00:58:50.957375: step 7375, loss 0.570855.
Train: 2018-07-31T00:58:51.113563: step 7376, loss 0.538837.
Train: 2018-07-31T00:58:51.254156: step 7377, loss 0.522851.
Train: 2018-07-31T00:58:51.394748: step 7378, loss 0.570857.
Train: 2018-07-31T00:58:51.550962: step 7379, loss 0.554831.
Train: 2018-07-31T00:58:51.691554: step 7380, loss 0.5468.
Test: 2018-07-31T00:58:51.941495: step 7380, loss 0.54937.
Train: 2018-07-31T00:58:52.082087: step 7381, loss 0.619015.
Train: 2018-07-31T00:58:52.222679: step 7382, loss 0.530725.
Train: 2018-07-31T00:58:52.363271: step 7383, loss 0.522666.
Train: 2018-07-31T00:58:52.503863: step 7384, loss 0.594958.
Train: 2018-07-31T00:58:52.644454: step 7385, loss 0.538633.
Train: 2018-07-31T00:58:52.785046: step 7386, loss 0.675592.
Train: 2018-07-31T00:58:52.941260: step 7387, loss 0.61911.
Train: 2018-07-31T00:58:53.081877: step 7388, loss 0.659119.
Train: 2018-07-31T00:58:53.222444: step 7389, loss 0.578861.
Train: 2018-07-31T00:58:53.363036: step 7390, loss 0.610657.
Test: 2018-07-31T00:58:53.613008: step 7390, loss 0.549796.
Train: 2018-07-31T00:58:53.753569: step 7391, loss 0.46815.
Train: 2018-07-31T00:58:53.894178: step 7392, loss 0.578863.
Train: 2018-07-31T00:58:54.034754: step 7393, loss 0.555244.
Train: 2018-07-31T00:58:54.175345: step 7394, loss 0.531698.
Train: 2018-07-31T00:58:54.331572: step 7395, loss 0.57887.
Train: 2018-07-31T00:58:54.472153: step 7396, loss 0.531742.
Train: 2018-07-31T00:58:54.612745: step 7397, loss 0.571011.
Train: 2018-07-31T00:58:54.753336: step 7398, loss 0.578869.
Train: 2018-07-31T00:58:54.893929: step 7399, loss 0.563139.
Train: 2018-07-31T00:58:55.034519: step 7400, loss 0.571.
Test: 2018-07-31T00:58:55.268870: step 7400, loss 0.549944.
Train: 2018-07-31T00:58:56.018685: step 7401, loss 0.539513.
Train: 2018-07-31T00:58:56.174902: step 7402, loss 0.500069.
Train: 2018-07-31T00:58:56.331092: step 7403, loss 0.523546.
Train: 2018-07-31T00:58:56.471683: step 7404, loss 0.602655.
Train: 2018-07-31T00:58:56.627932: step 7405, loss 0.523198.
Train: 2018-07-31T00:58:56.784110: step 7406, loss 0.57886.
Train: 2018-07-31T00:58:56.940348: step 7407, loss 0.506857.
Train: 2018-07-31T00:58:57.080940: step 7408, loss 0.546738.
Train: 2018-07-31T00:58:57.237153: step 7409, loss 0.578885.
Train: 2018-07-31T00:58:57.377746: step 7410, loss 0.522247.
Test: 2018-07-31T00:58:57.627687: step 7410, loss 0.549052.
Train: 2018-07-31T00:58:57.768273: step 7411, loss 0.57892.
Train: 2018-07-31T00:58:57.940091: step 7412, loss 0.546323.
Train: 2018-07-31T00:58:58.080682: step 7413, loss 0.47264.
Train: 2018-07-31T00:58:58.221300: step 7414, loss 0.546102.
Train: 2018-07-31T00:58:58.361867: step 7415, loss 0.595536.
Train: 2018-07-31T00:58:58.518079: step 7416, loss 0.570758.
Train: 2018-07-31T00:58:58.658671: step 7417, loss 0.520885.
Train: 2018-07-31T00:58:58.799287: step 7418, loss 0.504034.
Train: 2018-07-31T00:58:58.939903: step 7419, loss 0.52051.
Train: 2018-07-31T00:58:59.096070: step 7420, loss 0.579212.
Test: 2018-07-31T00:58:59.330388: step 7420, loss 0.548213.
Train: 2018-07-31T00:58:59.486603: step 7421, loss 0.545466.
Train: 2018-07-31T00:58:59.627194: step 7422, loss 0.57083.
Train: 2018-07-31T00:58:59.767811: step 7423, loss 0.570846.
Train: 2018-07-31T00:58:59.908403: step 7424, loss 0.553822.
Train: 2018-07-31T00:59:00.064593: step 7425, loss 0.545269.
Train: 2018-07-31T00:59:00.205208: step 7426, loss 0.511039.
Train: 2018-07-31T00:59:00.345801: step 7427, loss 0.510908.
Train: 2018-07-31T00:59:00.486369: step 7428, loss 0.570931.
Train: 2018-07-31T00:59:00.626960: step 7429, loss 0.51063.
Train: 2018-07-31T00:59:00.767552: step 7430, loss 0.596918.
Test: 2018-07-31T00:59:01.001898: step 7430, loss 0.547845.
Train: 2018-07-31T00:59:01.158111: step 7431, loss 0.527721.
Train: 2018-07-31T00:59:01.298702: step 7432, loss 0.53633.
Train: 2018-07-31T00:59:01.470514: step 7433, loss 0.510218.
Train: 2018-07-31T00:59:01.611113: step 7434, loss 0.675609.
Train: 2018-07-31T00:59:01.767318: step 7435, loss 0.57977.
Train: 2018-07-31T00:59:01.907934: step 7436, loss 0.605837.
Train: 2018-07-31T00:59:02.048527: step 7437, loss 0.544995.
Train: 2018-07-31T00:59:02.204716: step 7438, loss 0.536368.
Train: 2018-07-31T00:59:02.345309: step 7439, loss 0.588276.
Train: 2018-07-31T00:59:02.485899: step 7440, loss 0.588214.
Test: 2018-07-31T00:59:02.720253: step 7440, loss 0.547932.
Train: 2018-07-31T00:59:02.876457: step 7441, loss 0.484933.
Train: 2018-07-31T00:59:03.017038: step 7442, loss 0.596695.
Train: 2018-07-31T00:59:03.157631: step 7443, loss 0.553763.
Train: 2018-07-31T00:59:03.298209: step 7444, loss 0.588001.
Train: 2018-07-31T00:59:03.454423: step 7445, loss 0.579404.
Train: 2018-07-31T00:59:03.595015: step 7446, loss 0.596373.
Train: 2018-07-31T00:59:03.735632: step 7447, loss 0.562352.
Train: 2018-07-31T00:59:03.891822: step 7448, loss 0.537024.
Train: 2018-07-31T00:59:04.032413: step 7449, loss 0.528682.
Train: 2018-07-31T00:59:04.173006: step 7450, loss 0.520348.
Test: 2018-07-31T00:59:04.391733: step 7450, loss 0.54832.
Train: 2018-07-31T00:59:04.547917: step 7451, loss 0.612783.
Train: 2018-07-31T00:59:04.688534: step 7452, loss 0.570779.
Train: 2018-07-31T00:59:04.829102: step 7453, loss 0.545685.
Train: 2018-07-31T00:59:04.969693: step 7454, loss 0.612505.
Train: 2018-07-31T00:59:05.110287: step 7455, loss 0.595732.
Train: 2018-07-31T00:59:05.250877: step 7456, loss 0.587346.
Train: 2018-07-31T00:59:05.391469: step 7457, loss 0.537708.
Train: 2018-07-31T00:59:05.532097: step 7458, loss 0.562519.
Train: 2018-07-31T00:59:05.688274: step 7459, loss 0.578975.
Train: 2018-07-31T00:59:05.828867: step 7460, loss 0.529807.
Test: 2018-07-31T00:59:06.063187: step 7460, loss 0.548898.
Train: 2018-07-31T00:59:06.219401: step 7461, loss 0.554415.
Train: 2018-07-31T00:59:06.359994: step 7462, loss 0.595263.
Train: 2018-07-31T00:59:06.500585: step 7463, loss 0.644096.
Train: 2018-07-31T00:59:06.641201: step 7464, loss 0.562675.
Train: 2018-07-31T00:59:06.781793: step 7465, loss 0.5142.
Train: 2018-07-31T00:59:06.938006: step 7466, loss 0.546601.
Train: 2018-07-31T00:59:07.078575: step 7467, loss 0.603061.
Train: 2018-07-31T00:59:07.234789: step 7468, loss 0.554743.
Train: 2018-07-31T00:59:07.375415: step 7469, loss 0.538717.
Train: 2018-07-31T00:59:07.515973: step 7470, loss 0.538746.
Test: 2018-07-31T00:59:07.750291: step 7470, loss 0.54938.
Train: 2018-07-31T00:59:07.906530: step 7471, loss 0.530721.
Train: 2018-07-31T00:59:08.047123: step 7472, loss 0.546743.
Train: 2018-07-31T00:59:08.187690: step 7473, loss 0.522578.
Train: 2018-07-31T00:59:08.328282: step 7474, loss 0.546638.
Train: 2018-07-31T00:59:08.562627: step 7475, loss 0.586968.
Train: 2018-07-31T00:59:08.703218: step 7476, loss 0.53033.
Train: 2018-07-31T00:59:08.859438: step 7477, loss 0.587017.
Train: 2018-07-31T00:59:09.000024: step 7478, loss 0.562659.
Train: 2018-07-31T00:59:09.140592: step 7479, loss 0.505685.
Train: 2018-07-31T00:59:09.281209: step 7480, loss 0.562614.
Test: 2018-07-31T00:59:09.531155: step 7480, loss 0.54889.
Train: 2018-07-31T00:59:09.687340: step 7481, loss 0.60348.
Train: 2018-07-31T00:59:09.827955: step 7482, loss 0.521639.
Train: 2018-07-31T00:59:09.968522: step 7483, loss 0.603577.
Train: 2018-07-31T00:59:10.124737: step 7484, loss 0.537919.
Train: 2018-07-31T00:59:10.280949: step 7485, loss 0.578979.
Train: 2018-07-31T00:59:10.421566: step 7486, loss 0.562532.
Train: 2018-07-31T00:59:10.562158: step 7487, loss 0.513142.
Train: 2018-07-31T00:59:10.702725: step 7488, loss 0.537779.
Train: 2018-07-31T00:59:10.858964: step 7489, loss 0.587278.
Train: 2018-07-31T00:59:10.999532: step 7490, loss 0.603838.
Test: 2018-07-31T00:59:11.233852: step 7490, loss 0.548634.
Train: 2018-07-31T00:59:11.390066: step 7491, loss 0.595567.
Train: 2018-07-31T00:59:11.530682: step 7492, loss 0.595545.
Train: 2018-07-31T00:59:11.671250: step 7493, loss 0.504764.
Train: 2018-07-31T00:59:11.827463: step 7494, loss 0.537766.
Train: 2018-07-31T00:59:11.968055: step 7495, loss 0.579007.
Train: 2018-07-31T00:59:12.124292: step 7496, loss 0.521259.
Train: 2018-07-31T00:59:12.264859: step 7497, loss 0.636807.
Train: 2018-07-31T00:59:12.405452: step 7498, loss 0.521273.
Train: 2018-07-31T00:59:12.530423: step 7499, loss 0.529524.
Train: 2018-07-31T00:59:12.686636: step 7500, loss 0.562504.
Test: 2018-07-31T00:59:12.920957: step 7500, loss 0.548673.
Train: 2018-07-31T00:59:13.623940: step 7501, loss 0.554243.
Train: 2018-07-31T00:59:13.780154: step 7502, loss 0.53771.
Train: 2018-07-31T00:59:13.920723: step 7503, loss 0.645189.
Train: 2018-07-31T00:59:14.076937: step 7504, loss 0.620324.
Train: 2018-07-31T00:59:14.217529: step 7505, loss 0.488344.
Train: 2018-07-31T00:59:14.358119: step 7506, loss 0.603707.
Train: 2018-07-31T00:59:14.498737: step 7507, loss 0.554307.
Train: 2018-07-31T00:59:14.639329: step 7508, loss 0.570759.
Train: 2018-07-31T00:59:14.795518: step 7509, loss 0.570761.
Train: 2018-07-31T00:59:14.936109: step 7510, loss 0.562569.
Test: 2018-07-31T00:59:15.186072: step 7510, loss 0.548878.
Train: 2018-07-31T00:59:15.326668: step 7511, loss 0.611682.
Train: 2018-07-31T00:59:15.467261: step 7512, loss 0.619754.
Train: 2018-07-31T00:59:15.607851: step 7513, loss 0.570781.
Train: 2018-07-31T00:59:15.748420: step 7514, loss 0.505934.
Train: 2018-07-31T00:59:15.904632: step 7515, loss 0.586988.
Train: 2018-07-31T00:59:16.045224: step 7516, loss 0.635432.
Train: 2018-07-31T00:59:16.201437: step 7517, loss 0.570827.
Train: 2018-07-31T00:59:16.342030: step 7518, loss 0.562824.
Train: 2018-07-31T00:59:16.482621: step 7519, loss 0.50688.
Train: 2018-07-31T00:59:16.638836: step 7520, loss 0.562883.
Test: 2018-07-31T00:59:16.873157: step 7520, loss 0.549529.
Train: 2018-07-31T00:59:17.013773: step 7521, loss 0.658679.
Train: 2018-07-31T00:59:17.169985: step 7522, loss 0.602729.
Train: 2018-07-31T00:59:17.310553: step 7523, loss 0.531296.
Train: 2018-07-31T00:59:17.451147: step 7524, loss 0.53932.
Train: 2018-07-31T00:59:17.591762: step 7525, loss 0.539376.
Train: 2018-07-31T00:59:17.747951: step 7526, loss 0.563075.
Train: 2018-07-31T00:59:17.872921: step 7527, loss 0.602539.
Train: 2018-07-31T00:59:18.029136: step 7528, loss 0.555213.
Train: 2018-07-31T00:59:18.169727: step 7529, loss 0.586745.
Train: 2018-07-31T00:59:18.325964: step 7530, loss 0.633972.
Test: 2018-07-31T00:59:18.560261: step 7530, loss 0.550016.
Train: 2018-07-31T00:59:18.732119: step 7531, loss 0.60243.
Train: 2018-07-31T00:59:18.872705: step 7532, loss 0.555395.
Train: 2018-07-31T00:59:19.013308: step 7533, loss 0.532028.
Train: 2018-07-31T00:59:19.153871: step 7534, loss 0.649108.
Train: 2018-07-31T00:59:19.294488: step 7535, loss 0.586681.
Train: 2018-07-31T00:59:19.435056: step 7536, loss 0.563407.
Train: 2018-07-31T00:59:19.575647: step 7537, loss 0.609871.
Train: 2018-07-31T00:59:19.716265: step 7538, loss 0.602079.
Train: 2018-07-31T00:59:19.856857: step 7539, loss 0.540554.
Train: 2018-07-31T00:59:20.013047: step 7540, loss 0.555989.
Test: 2018-07-31T00:59:20.247396: step 7540, loss 0.55087.
Train: 2018-07-31T00:59:20.387982: step 7541, loss 0.510114.
Train: 2018-07-31T00:59:20.544172: step 7542, loss 0.55602.
Train: 2018-07-31T00:59:20.684763: step 7543, loss 0.617308.
Train: 2018-07-31T00:59:20.825381: step 7544, loss 0.571324.
Train: 2018-07-31T00:59:20.965947: step 7545, loss 0.51769.
Train: 2018-07-31T00:59:21.106541: step 7546, loss 0.58665.
Train: 2018-07-31T00:59:21.247149: step 7547, loss 0.525192.
Train: 2018-07-31T00:59:21.387723: step 7548, loss 0.548151.
Train: 2018-07-31T00:59:21.543937: step 7549, loss 0.5326.
Train: 2018-07-31T00:59:21.684554: step 7550, loss 0.513804.
Test: 2018-07-31T00:59:21.918881: step 7550, loss 0.55027.
Train: 2018-07-31T00:59:22.075087: step 7551, loss 0.532156.
Train: 2018-07-31T00:59:22.231301: step 7552, loss 0.547546.
Train: 2018-07-31T00:59:22.371886: step 7553, loss 0.523727.
Train: 2018-07-31T00:59:22.528081: step 7554, loss 0.515451.
Train: 2018-07-31T00:59:22.668673: step 7555, loss 0.602804.
Train: 2018-07-31T00:59:22.809266: step 7556, loss 0.562821.
Train: 2018-07-31T00:59:22.949858: step 7557, loss 0.530505.
Train: 2018-07-31T00:59:23.090477: step 7558, loss 0.546485.
Train: 2018-07-31T00:59:23.231042: step 7559, loss 0.570782.
Train: 2018-07-31T00:59:23.371635: step 7560, loss 0.578955.
Test: 2018-07-31T00:59:23.621606: step 7560, loss 0.548801.
Train: 2018-07-31T00:59:23.762168: step 7561, loss 0.546132.
Train: 2018-07-31T00:59:23.902760: step 7562, loss 0.529565.
Train: 2018-07-31T00:59:24.043352: step 7563, loss 0.587297.
Train: 2018-07-31T00:59:24.199566: step 7564, loss 0.562465.
Train: 2018-07-31T00:59:24.340158: step 7565, loss 0.587388.
Train: 2018-07-31T00:59:24.480750: step 7566, loss 0.529132.
Train: 2018-07-31T00:59:24.621365: step 7567, loss 0.52071.
Train: 2018-07-31T00:59:24.761955: step 7568, loss 0.562408.
Train: 2018-07-31T00:59:24.902551: step 7569, loss 0.57078.
Train: 2018-07-31T00:59:25.043143: step 7570, loss 0.562388.
Test: 2018-07-31T00:59:25.293059: step 7570, loss 0.548296.
Train: 2018-07-31T00:59:25.433676: step 7571, loss 0.5792.
Train: 2018-07-31T00:59:25.574243: step 7572, loss 0.604454.
Train: 2018-07-31T00:59:25.714835: step 7573, loss 0.596023.
Train: 2018-07-31T00:59:25.871050: step 7574, loss 0.579182.
Train: 2018-07-31T00:59:26.011665: step 7575, loss 0.579183.
Train: 2018-07-31T00:59:26.152232: step 7576, loss 0.562407.
Train: 2018-07-31T00:59:26.308447: step 7577, loss 0.579117.
Train: 2018-07-31T00:59:26.449063: step 7578, loss 0.570763.
Train: 2018-07-31T00:59:26.589655: step 7579, loss 0.537533.
Train: 2018-07-31T00:59:26.745845: step 7580, loss 0.479546.
Test: 2018-07-31T00:59:26.980199: step 7580, loss 0.548572.
Train: 2018-07-31T00:59:27.120780: step 7581, loss 0.53758.
Train: 2018-07-31T00:59:27.292615: step 7582, loss 0.545856.
Train: 2018-07-31T00:59:27.417561: step 7583, loss 0.637232.
Train: 2018-07-31T00:59:27.573776: step 7584, loss 0.529255.
Train: 2018-07-31T00:59:27.714367: step 7585, loss 0.579058.
Train: 2018-07-31T00:59:27.854960: step 7586, loss 0.62052.
Train: 2018-07-31T00:59:28.011173: step 7587, loss 0.521097.
Train: 2018-07-31T00:59:28.151763: step 7588, loss 0.54595.
Train: 2018-07-31T00:59:28.292381: step 7589, loss 0.686456.
Train: 2018-07-31T00:59:28.432973: step 7590, loss 0.603698.
Test: 2018-07-31T00:59:28.682915: step 7590, loss 0.548826.
Train: 2018-07-31T00:59:28.823507: step 7591, loss 0.570761.
Train: 2018-07-31T00:59:28.964099: step 7592, loss 0.52176.
Train: 2018-07-31T00:59:29.120314: step 7593, loss 0.635942.
Train: 2018-07-31T00:59:29.260906: step 7594, loss 0.505871.
Train: 2018-07-31T00:59:29.417094: step 7595, loss 0.578896.
Train: 2018-07-31T00:59:29.557686: step 7596, loss 0.514281.
Train: 2018-07-31T00:59:29.698276: step 7597, loss 0.570917.
Train: 2018-07-31T00:59:29.838869: step 7598, loss 0.56274.
Train: 2018-07-31T00:59:29.979480: step 7599, loss 0.522523.
Train: 2018-07-31T00:59:30.135703: step 7600, loss 0.627164.
Test: 2018-07-31T00:59:30.385647: step 7600, loss 0.549275.
Train: 2018-07-31T00:59:31.135442: step 7601, loss 0.466245.
Train: 2018-07-31T00:59:31.291680: step 7602, loss 0.530469.
Train: 2018-07-31T00:59:31.432271: step 7603, loss 0.562873.
Train: 2018-07-31T00:59:31.588461: step 7604, loss 0.603379.
Train: 2018-07-31T00:59:31.729076: step 7605, loss 0.538306.
Train: 2018-07-31T00:59:31.885266: step 7606, loss 0.595199.
Train: 2018-07-31T00:59:32.025857: step 7607, loss 0.530246.
Train: 2018-07-31T00:59:32.150828: step 7608, loss 0.587032.
Train: 2018-07-31T00:59:32.291420: step 7609, loss 0.522086.
Train: 2018-07-31T00:59:32.432013: step 7610, loss 0.570784.
Test: 2018-07-31T00:59:32.681954: step 7610, loss 0.549015.
Train: 2018-07-31T00:59:32.822572: step 7611, loss 0.562643.
Train: 2018-07-31T00:59:32.963164: step 7612, loss 0.578922.
Train: 2018-07-31T00:59:33.103755: step 7613, loss 0.513724.
Train: 2018-07-31T00:59:33.244322: step 7614, loss 0.578934.
Train: 2018-07-31T00:59:33.400537: step 7615, loss 0.570772.
Train: 2018-07-31T00:59:33.541127: step 7616, loss 0.505328.
Train: 2018-07-31T00:59:33.697342: step 7617, loss 0.611749.
Train: 2018-07-31T00:59:33.837957: step 7618, loss 0.570772.
Train: 2018-07-31T00:59:33.978525: step 7619, loss 0.61999.
Train: 2018-07-31T00:59:34.119117: step 7620, loss 0.529788.
Test: 2018-07-31T00:59:34.369088: step 7620, loss 0.548853.
Train: 2018-07-31T00:59:34.509651: step 7621, loss 0.529798.
Train: 2018-07-31T00:59:34.650244: step 7622, loss 0.595355.
Train: 2018-07-31T00:59:34.790835: step 7623, loss 0.578958.
Train: 2018-07-31T00:59:34.931434: step 7624, loss 0.554386.
Train: 2018-07-31T00:59:35.072047: step 7625, loss 0.587136.
Train: 2018-07-31T00:59:35.212636: step 7626, loss 0.570767.
Train: 2018-07-31T00:59:35.353203: step 7627, loss 0.546267.
Train: 2018-07-31T00:59:35.509418: step 7628, loss 0.538122.
Train: 2018-07-31T00:59:35.650033: step 7629, loss 0.529958.
Train: 2018-07-31T00:59:35.790625: step 7630, loss 0.611615.
Test: 2018-07-31T00:59:36.024923: step 7630, loss 0.548916.
Train: 2018-07-31T00:59:36.181136: step 7631, loss 0.603437.
Train: 2018-07-31T00:59:36.321745: step 7632, loss 0.603388.
Train: 2018-07-31T00:59:36.462318: step 7633, loss 0.611459.
Train: 2018-07-31T00:59:36.602910: step 7634, loss 0.52214.
Train: 2018-07-31T00:59:36.743527: step 7635, loss 0.603174.
Train: 2018-07-31T00:59:36.884120: step 7636, loss 0.586966.
Train: 2018-07-31T00:59:37.024711: step 7637, loss 0.530589.
Train: 2018-07-31T00:59:37.180925: step 7638, loss 0.522628.
Train: 2018-07-31T00:59:37.321510: step 7639, loss 0.546751.
Train: 2018-07-31T00:59:37.462085: step 7640, loss 0.546742.
Test: 2018-07-31T00:59:37.712027: step 7640, loss 0.54932.
Train: 2018-07-31T00:59:37.852644: step 7641, loss 0.538669.
Train: 2018-07-31T00:59:37.993210: step 7642, loss 0.562844.
Train: 2018-07-31T00:59:38.133802: step 7643, loss 0.578846.
Train: 2018-07-31T00:59:38.274394: step 7644, loss 0.546709.
Train: 2018-07-31T00:59:38.430607: step 7645, loss 0.530303.
Train: 2018-07-31T00:59:38.571203: step 7646, loss 0.538227.
Train: 2018-07-31T00:59:38.711816: step 7647, loss 0.619939.
Train: 2018-07-31T00:59:38.852409: step 7648, loss 0.496925.
Train: 2018-07-31T00:59:39.008597: step 7649, loss 0.579281.
Train: 2018-07-31T00:59:39.164835: step 7650, loss 0.545892.
Test: 2018-07-31T00:59:39.399133: step 7650, loss 0.548311.
Train: 2018-07-31T00:59:39.539723: step 7651, loss 0.562416.
Train: 2018-07-31T00:59:39.695937: step 7652, loss 0.511347.
Train: 2018-07-31T00:59:39.836528: step 7653, loss 0.570825.
Train: 2018-07-31T00:59:39.977121: step 7654, loss 0.624608.
Train: 2018-07-31T00:59:40.117712: step 7655, loss 0.578057.
Train: 2018-07-31T00:59:40.258304: step 7656, loss 0.502504.
Train: 2018-07-31T00:59:40.398921: step 7657, loss 0.570224.
Train: 2018-07-31T00:59:40.555111: step 7658, loss 0.623329.
Train: 2018-07-31T00:59:40.695702: step 7659, loss 0.552983.
Train: 2018-07-31T00:59:40.836294: step 7660, loss 0.528767.
Test: 2018-07-31T00:59:41.070615: step 7660, loss 0.548167.
Train: 2018-07-31T00:59:41.211205: step 7661, loss 0.627705.
Train: 2018-07-31T00:59:41.351798: step 7662, loss 0.546654.
Train: 2018-07-31T00:59:41.492391: step 7663, loss 0.546405.
Train: 2018-07-31T00:59:41.648604: step 7664, loss 0.529984.
Train: 2018-07-31T00:59:41.789226: step 7665, loss 0.570794.
Train: 2018-07-31T00:59:41.929788: step 7666, loss 0.5379.
Train: 2018-07-31T00:59:42.054758: step 7667, loss 0.555106.
Train: 2018-07-31T00:59:42.195376: step 7668, loss 0.587547.
Train: 2018-07-31T00:59:42.351565: step 7669, loss 0.53822.
Train: 2018-07-31T00:59:42.492158: step 7670, loss 0.570676.
Test: 2018-07-31T00:59:42.726477: step 7670, loss 0.548934.
Train: 2018-07-31T00:59:42.867068: step 7671, loss 0.538114.
Train: 2018-07-31T00:59:43.007662: step 7672, loss 0.595348.
Train: 2018-07-31T00:59:43.148270: step 7673, loss 0.513926.
Train: 2018-07-31T00:59:43.288869: step 7674, loss 0.595491.
Train: 2018-07-31T00:59:43.429437: step 7675, loss 0.546187.
Train: 2018-07-31T00:59:43.570044: step 7676, loss 0.603486.
Train: 2018-07-31T00:59:43.710621: step 7677, loss 0.513708.
Train: 2018-07-31T00:59:43.882455: step 7678, loss 0.529733.
Train: 2018-07-31T00:59:44.038712: step 7679, loss 0.611605.
Train: 2018-07-31T00:59:44.179286: step 7680, loss 0.578667.
Test: 2018-07-31T00:59:44.429203: step 7680, loss 0.548846.
Train: 2018-07-31T00:59:44.569796: step 7681, loss 0.553992.
Train: 2018-07-31T00:59:44.726009: step 7682, loss 0.587002.
Train: 2018-07-31T00:59:44.866600: step 7683, loss 0.627709.
Train: 2018-07-31T00:59:45.007194: step 7684, loss 0.61986.
Train: 2018-07-31T00:59:45.147809: step 7685, loss 0.570731.
Train: 2018-07-31T00:59:45.303997: step 7686, loss 0.610936.
Train: 2018-07-31T00:59:45.460212: step 7687, loss 0.530465.
Train: 2018-07-31T00:59:45.600803: step 7688, loss 0.554967.
Train: 2018-07-31T00:59:45.741397: step 7689, loss 0.594429.
Train: 2018-07-31T00:59:45.882006: step 7690, loss 0.55456.
Test: 2018-07-31T00:59:46.116310: step 7690, loss 0.549434.
Train: 2018-07-31T00:59:46.272521: step 7691, loss 0.555184.
Train: 2018-07-31T00:59:46.413138: step 7692, loss 0.554534.
Train: 2018-07-31T00:59:46.553705: step 7693, loss 0.554841.
Train: 2018-07-31T00:59:46.694304: step 7694, loss 0.514482.
Train: 2018-07-31T00:59:46.834913: step 7695, loss 0.514309.
Train: 2018-07-31T00:59:46.975481: step 7696, loss 0.513843.
Train: 2018-07-31T00:59:47.131695: step 7697, loss 0.522996.
Train: 2018-07-31T00:59:47.272286: step 7698, loss 0.503616.
Train: 2018-07-31T00:59:47.412904: step 7699, loss 0.554237.
Train: 2018-07-31T00:59:47.553496: step 7700, loss 0.590782.
Test: 2018-07-31T00:59:47.803413: step 7700, loss 0.547653.
Train: 2018-07-31T00:59:48.568883: step 7701, loss 0.671404.
Train: 2018-07-31T00:59:48.725101: step 7702, loss 0.529494.
Train: 2018-07-31T00:59:48.881285: step 7703, loss 0.562441.
Train: 2018-07-31T00:59:49.021877: step 7704, loss 0.497751.
Train: 2018-07-31T00:59:49.146847: step 7705, loss 0.571296.
Train: 2018-07-31T00:59:49.303062: step 7706, loss 0.58761.
Train: 2018-07-31T00:59:49.443654: step 7707, loss 0.578381.
Train: 2018-07-31T00:59:49.584245: step 7708, loss 0.58776.
Train: 2018-07-31T00:59:49.724839: step 7709, loss 0.644858.
Train: 2018-07-31T00:59:49.865430: step 7710, loss 0.587147.
Test: 2018-07-31T00:59:50.099781: step 7710, loss 0.549245.
Train: 2018-07-31T00:59:50.255988: step 7711, loss 0.514397.
Train: 2018-07-31T00:59:50.396579: step 7712, loss 0.5389.
Train: 2018-07-31T00:59:50.537148: step 7713, loss 0.602944.
Train: 2018-07-31T00:59:50.677739: step 7714, loss 0.570882.
Train: 2018-07-31T00:59:50.818332: step 7715, loss 0.570889.
Train: 2018-07-31T00:59:50.974545: step 7716, loss 0.578859.
Train: 2018-07-31T00:59:51.115162: step 7717, loss 0.49939.
Train: 2018-07-31T00:59:51.255757: step 7718, loss 0.594772.
Train: 2018-07-31T00:59:51.396320: step 7719, loss 0.626548.
Train: 2018-07-31T00:59:51.568156: step 7720, loss 0.578862.
Test: 2018-07-31T00:59:51.802502: step 7720, loss 0.549771.
Train: 2018-07-31T00:59:51.958714: step 7721, loss 0.578859.
Train: 2018-07-31T00:59:52.114904: step 7722, loss 0.56306.
Train: 2018-07-31T00:59:52.255507: step 7723, loss 0.539428.
Train: 2018-07-31T00:59:52.396087: step 7724, loss 0.515804.
Train: 2018-07-31T00:59:52.552301: step 7725, loss 0.594644.
Train: 2018-07-31T00:59:52.692892: step 7726, loss 0.523635.
Train: 2018-07-31T00:59:52.849107: step 7727, loss 0.602568.
Train: 2018-07-31T00:59:52.989699: step 7728, loss 0.52354.
Train: 2018-07-31T00:59:53.130290: step 7729, loss 0.539272.
Train: 2018-07-31T00:59:53.286504: step 7730, loss 0.475738.
Test: 2018-07-31T00:59:53.536446: step 7730, loss 0.549586.
Train: 2018-07-31T00:59:53.677038: step 7731, loss 0.618694.
Train: 2018-07-31T00:59:53.817629: step 7732, loss 0.562911.
Train: 2018-07-31T00:59:53.958220: step 7733, loss 0.530819.
Train: 2018-07-31T00:59:54.098813: step 7734, loss 0.506564.
Train: 2018-07-31T00:59:54.255038: step 7735, loss 0.490137.
Train: 2018-07-31T00:59:54.395619: step 7736, loss 0.603207.
Train: 2018-07-31T00:59:54.536211: step 7737, loss 0.595212.
Train: 2018-07-31T00:59:54.692449: step 7738, loss 0.538074.
Train: 2018-07-31T00:59:54.833018: step 7739, loss 0.587173.
Train: 2018-07-31T00:59:54.973609: step 7740, loss 0.504837.
Test: 2018-07-31T00:59:55.223551: step 7740, loss 0.548577.
Train: 2018-07-31T00:59:55.364167: step 7741, loss 0.579124.
Train: 2018-07-31T00:59:55.504734: step 7742, loss 0.57933.
Train: 2018-07-31T00:59:55.645351: step 7743, loss 0.545894.
Train: 2018-07-31T00:59:55.801540: step 7744, loss 0.595718.
Train: 2018-07-31T00:59:55.942131: step 7745, loss 0.603975.
Train: 2018-07-31T00:59:56.067102: step 7746, loss 0.496041.
Train: 2018-07-31T00:59:56.207694: step 7747, loss 0.537553.
Train: 2018-07-31T00:59:56.363909: step 7748, loss 0.54579.
Train: 2018-07-31T00:59:56.488880: step 7749, loss 0.612447.
Train: 2018-07-31T00:59:56.629471: step 7750, loss 0.537398.
Test: 2018-07-31T00:59:56.879442: step 7750, loss 0.548459.
Train: 2018-07-31T00:59:57.020003: step 7751, loss 0.512369.
Train: 2018-07-31T00:59:57.176218: step 7752, loss 0.562367.
Train: 2018-07-31T00:59:57.316811: step 7753, loss 0.595798.
Train: 2018-07-31T00:59:57.457427: step 7754, loss 0.545522.
Train: 2018-07-31T00:59:57.613615: step 7755, loss 0.579368.
Train: 2018-07-31T00:59:57.754232: step 7756, loss 0.562527.
Train: 2018-07-31T00:59:57.894798: step 7757, loss 0.545962.
Train: 2018-07-31T00:59:58.035392: step 7758, loss 0.621177.
Train: 2018-07-31T00:59:58.176008: step 7759, loss 0.570693.
Train: 2018-07-31T00:59:58.332198: step 7760, loss 0.57076.
Test: 2018-07-31T00:59:58.566517: step 7760, loss 0.548539.
Train: 2018-07-31T00:59:58.722732: step 7761, loss 0.520851.
Train: 2018-07-31T00:59:58.878944: step 7762, loss 0.587384.
Train: 2018-07-31T00:59:59.003915: step 7763, loss 0.529259.
Train: 2018-07-31T00:59:59.144506: step 7764, loss 0.520988.
Train: 2018-07-31T00:59:59.300721: step 7765, loss 0.545864.
Train: 2018-07-31T00:59:59.441314: step 7766, loss 0.520941.
Train: 2018-07-31T00:59:59.581905: step 7767, loss 0.579077.
Train: 2018-07-31T00:59:59.738119: step 7768, loss 0.562438.
Train: 2018-07-31T00:59:59.878711: step 7769, loss 0.595745.
Train: 2018-07-31T01:00:00.019302: step 7770, loss 0.504162.
Test: 2018-07-31T01:00:00.269243: step 7770, loss 0.54847.
Train: 2018-07-31T01:00:00.409835: step 7771, loss 0.570761.
Train: 2018-07-31T01:00:00.550426: step 7772, loss 0.554095.
Train: 2018-07-31T01:00:00.691019: step 7773, loss 0.587443.
Train: 2018-07-31T01:00:00.831612: step 7774, loss 0.562403.
Train: 2018-07-31T01:00:00.972205: step 7775, loss 0.52907.
Train: 2018-07-31T01:00:01.112796: step 7776, loss 0.520719.
Train: 2018-07-31T01:00:01.253413: step 7777, loss 0.687832.
Train: 2018-07-31T01:00:01.394010: step 7778, loss 0.537416.
Train: 2018-07-31T01:00:01.534626: step 7779, loss 0.60407.
Train: 2018-07-31T01:00:01.690786: step 7780, loss 0.496017.
Test: 2018-07-31T01:00:01.925136: step 7780, loss 0.548559.
Train: 2018-07-31T01:00:02.065738: step 7781, loss 0.545859.
Train: 2018-07-31T01:00:02.221913: step 7782, loss 0.512673.
Train: 2018-07-31T01:00:02.362527: step 7783, loss 0.520914.
Train: 2018-07-31T01:00:02.503096: step 7784, loss 0.479211.
Train: 2018-07-31T01:00:02.659333: step 7785, loss 0.595837.
Train: 2018-07-31T01:00:02.815522: step 7786, loss 0.595936.
Train: 2018-07-31T01:00:02.956140: step 7787, loss 0.587532.
Train: 2018-07-31T01:00:03.096707: step 7788, loss 0.545652.
Train: 2018-07-31T01:00:03.237299: step 7789, loss 0.595952.
Train: 2018-07-31T01:00:03.393536: step 7790, loss 0.579161.
Test: 2018-07-31T01:00:03.627864: step 7790, loss 0.548408.
Train: 2018-07-31T01:00:03.784046: step 7791, loss 0.570762.
Train: 2018-07-31T01:00:03.924651: step 7792, loss 0.537354.
Train: 2018-07-31T01:00:04.065231: step 7793, loss 0.637537.
Train: 2018-07-31T01:00:04.221444: step 7794, loss 0.554117.
Train: 2018-07-31T01:00:04.362034: step 7795, loss 0.562451.
Train: 2018-07-31T01:00:04.518248: step 7796, loss 0.570752.
Train: 2018-07-31T01:00:04.674461: step 7797, loss 0.603848.
Train: 2018-07-31T01:00:04.830675: step 7798, loss 0.579004.
Train: 2018-07-31T01:00:04.971268: step 7799, loss 0.562538.
Train: 2018-07-31T01:00:05.127516: step 7800, loss 0.628144.
Test: 2018-07-31T01:00:05.361833: step 7800, loss 0.548934.
Train: 2018-07-31T01:00:06.096028: step 7801, loss 0.546281.
Train: 2018-07-31T01:00:06.252219: step 7802, loss 0.570785.
Train: 2018-07-31T01:00:06.377188: step 7803, loss 0.578886.
Train: 2018-07-31T01:00:06.533402: step 7804, loss 0.554636.
Train: 2018-07-31T01:00:06.674018: step 7805, loss 0.554685.
Train: 2018-07-31T01:00:06.814586: step 7806, loss 0.554702.
Train: 2018-07-31T01:00:06.955202: step 7807, loss 0.643232.
Train: 2018-07-31T01:00:07.095794: step 7808, loss 0.530824.
Train: 2018-07-31T01:00:07.236386: step 7809, loss 0.570904.
Train: 2018-07-31T01:00:07.376953: step 7810, loss 0.618742.
Test: 2018-07-31T01:00:07.626896: step 7810, loss 0.549649.
Train: 2018-07-31T01:00:07.767513: step 7811, loss 0.555078.
Train: 2018-07-31T01:00:07.923726: step 7812, loss 0.555102.
Train: 2018-07-31T01:00:08.064292: step 7813, loss 0.563057.
Train: 2018-07-31T01:00:08.220507: step 7814, loss 0.523643.
Train: 2018-07-31T01:00:08.361123: step 7815, loss 0.570979.
Train: 2018-07-31T01:00:08.517312: step 7816, loss 0.586751.
Train: 2018-07-31T01:00:08.657928: step 7817, loss 0.54734.
Train: 2018-07-31T01:00:08.798496: step 7818, loss 0.578869.
Train: 2018-07-31T01:00:08.954710: step 7819, loss 0.634025.
Train: 2018-07-31T01:00:09.095302: step 7820, loss 0.610332.
Test: 2018-07-31T01:00:09.329622: step 7820, loss 0.550052.
Train: 2018-07-31T01:00:09.470238: step 7821, loss 0.476911.
Train: 2018-07-31T01:00:09.626452: step 7822, loss 0.563187.
Train: 2018-07-31T01:00:09.767045: step 7823, loss 0.531799.
Train: 2018-07-31T01:00:09.907610: step 7824, loss 0.586725.
Train: 2018-07-31T01:00:10.048203: step 7825, loss 0.500255.
Train: 2018-07-31T01:00:10.188796: step 7826, loss 0.60251.
Train: 2018-07-31T01:00:10.345009: step 7827, loss 0.563071.
Train: 2018-07-31T01:00:10.485602: step 7828, loss 0.578855.
Train: 2018-07-31T01:00:10.626194: step 7829, loss 0.563036.
Train: 2018-07-31T01:00:10.766786: step 7830, loss 0.539234.
Test: 2018-07-31T01:00:11.001136: step 7830, loss 0.549687.
Train: 2018-07-31T01:00:11.172941: step 7831, loss 0.499473.
Train: 2018-07-31T01:00:11.313533: step 7832, loss 0.56293.
Train: 2018-07-31T01:00:11.454126: step 7833, loss 0.546825.
Train: 2018-07-31T01:00:11.594741: step 7834, loss 0.514656.
Train: 2018-07-31T01:00:11.750965: step 7835, loss 0.538499.
Train: 2018-07-31T01:00:11.891546: step 7836, loss 0.603536.
Train: 2018-07-31T01:00:12.032138: step 7837, loss 0.578793.
Train: 2018-07-31T01:00:12.188353: step 7838, loss 0.628027.
Train: 2018-07-31T01:00:12.328918: step 7839, loss 0.538248.
Train: 2018-07-31T01:00:12.485157: step 7840, loss 0.578798.
Test: 2018-07-31T01:00:12.735106: step 7840, loss 0.548886.
Train: 2018-07-31T01:00:12.875667: step 7841, loss 0.529927.
Train: 2018-07-31T01:00:13.016283: step 7842, loss 0.497077.
Train: 2018-07-31T01:00:13.156868: step 7843, loss 0.537951.
Train: 2018-07-31T01:00:13.313091: step 7844, loss 0.562342.
Train: 2018-07-31T01:00:13.453682: step 7845, loss 0.562818.
Train: 2018-07-31T01:00:13.609870: step 7846, loss 0.546163.
Train: 2018-07-31T01:00:13.766084: step 7847, loss 0.587839.
Train: 2018-07-31T01:00:13.906691: step 7848, loss 0.612606.
Train: 2018-07-31T01:00:14.047285: step 7849, loss 0.520979.
Train: 2018-07-31T01:00:14.203505: step 7850, loss 0.587323.
Test: 2018-07-31T01:00:14.437801: step 7850, loss 0.548595.
Train: 2018-07-31T01:00:14.578406: step 7851, loss 0.570761.
Train: 2018-07-31T01:00:14.719013: step 7852, loss 0.56248.
Train: 2018-07-31T01:00:14.875223: step 7853, loss 0.554196.
Train: 2018-07-31T01:00:15.031412: step 7854, loss 0.545923.
Train: 2018-07-31T01:00:15.172003: step 7855, loss 0.49623.
Train: 2018-07-31T01:00:15.328216: step 7856, loss 0.554168.
Train: 2018-07-31T01:00:15.468810: step 7857, loss 0.512601.
Train: 2018-07-31T01:00:15.609401: step 7858, loss 0.612406.
Train: 2018-07-31T01:00:15.749993: step 7859, loss 0.545759.
Train: 2018-07-31T01:00:15.906221: step 7860, loss 0.57912.
Test: 2018-07-31T01:00:16.140526: step 7860, loss 0.54843.
Train: 2018-07-31T01:00:16.296742: step 7861, loss 0.512305.
Train: 2018-07-31T01:00:16.437357: step 7862, loss 0.545678.
Train: 2018-07-31T01:00:16.577923: step 7863, loss 0.53727.
Train: 2018-07-31T01:00:16.734138: step 7864, loss 0.52881.
Train: 2018-07-31T01:00:16.874731: step 7865, loss 0.545545.
Train: 2018-07-31T01:00:17.030943: step 7866, loss 0.579232.
Train: 2018-07-31T01:00:17.171536: step 7867, loss 0.55391.
Train: 2018-07-31T01:00:17.312127: step 7868, loss 0.528529.
Train: 2018-07-31T01:00:17.452720: step 7869, loss 0.664032.
Train: 2018-07-31T01:00:17.593311: step 7870, loss 0.570813.
Test: 2018-07-31T01:00:17.827632: step 7870, loss 0.548203.
Train: 2018-07-31T01:00:17.968249: step 7871, loss 0.630007.
Train: 2018-07-31T01:00:18.108840: step 7872, loss 0.587658.
Train: 2018-07-31T01:00:18.249407: step 7873, loss 0.570815.
Train: 2018-07-31T01:00:18.390000: step 7874, loss 0.537274.
Train: 2018-07-31T01:00:18.530591: step 7875, loss 0.520635.
Train: 2018-07-31T01:00:18.671209: step 7876, loss 0.604135.
Train: 2018-07-31T01:00:18.827398: step 7877, loss 0.504184.
Train: 2018-07-31T01:00:18.967989: step 7878, loss 0.570768.
Train: 2018-07-31T01:00:19.108582: step 7879, loss 0.545846.
Train: 2018-07-31T01:00:19.264796: step 7880, loss 0.56247.
Test: 2018-07-31T01:00:19.499115: step 7880, loss 0.548579.
Train: 2018-07-31T01:00:19.639707: step 7881, loss 0.545881.
Train: 2018-07-31T01:00:19.780299: step 7882, loss 0.645371.
Train: 2018-07-31T01:00:19.936513: step 7883, loss 0.51287.
Train: 2018-07-31T01:00:20.077122: step 7884, loss 0.603791.
Train: 2018-07-31T01:00:20.217698: step 7885, loss 0.537781.
Train: 2018-07-31T01:00:20.358313: step 7886, loss 0.537818.
Train: 2018-07-31T01:00:20.498908: step 7887, loss 0.653048.
Train: 2018-07-31T01:00:20.655120: step 7888, loss 0.611791.
Train: 2018-07-31T01:00:20.795712: step 7889, loss 0.627992.
Train: 2018-07-31T01:00:20.951925: step 7890, loss 0.538241.
Test: 2018-07-31T01:00:21.201842: step 7890, loss 0.549127.
Train: 2018-07-31T01:00:21.342433: step 7891, loss 0.611309.
Train: 2018-07-31T01:00:21.483025: step 7892, loss 0.522421.
Train: 2018-07-31T01:00:21.623642: step 7893, loss 0.562793.
Train: 2018-07-31T01:00:21.764210: step 7894, loss 0.522741.
Train: 2018-07-31T01:00:21.904827: step 7895, loss 0.602882.
Train: 2018-07-31T01:00:22.061015: step 7896, loss 0.618798.
Train: 2018-07-31T01:00:22.201606: step 7897, loss 0.531075.
Train: 2018-07-31T01:00:22.357838: step 7898, loss 0.515269.
Train: 2018-07-31T01:00:22.498414: step 7899, loss 0.586797.
Train: 2018-07-31T01:00:22.639029: step 7900, loss 0.57092.
Test: 2018-07-31T01:00:22.888971: step 7900, loss 0.549708.
Train: 2018-07-31T01:00:23.638770: step 7901, loss 0.586812.
Train: 2018-07-31T01:00:23.779388: step 7902, loss 0.673894.
Train: 2018-07-31T01:00:23.919987: step 7903, loss 0.563107.
Train: 2018-07-31T01:00:24.076169: step 7904, loss 0.500194.
Train: 2018-07-31T01:00:24.216761: step 7905, loss 0.531717.
Train: 2018-07-31T01:00:24.357353: step 7906, loss 0.563166.
Train: 2018-07-31T01:00:24.482323: step 7907, loss 0.578846.
Train: 2018-07-31T01:00:24.622940: step 7908, loss 0.571011.
Train: 2018-07-31T01:00:24.779153: step 7909, loss 0.586721.
Train: 2018-07-31T01:00:24.919720: step 7910, loss 0.563172.
Test: 2018-07-31T01:00:25.154073: step 7910, loss 0.549988.
Train: 2018-07-31T01:00:25.310254: step 7911, loss 0.500311.
Train: 2018-07-31T01:00:25.450871: step 7912, loss 0.586717.
Train: 2018-07-31T01:00:25.591439: step 7913, loss 0.531538.
Train: 2018-07-31T01:00:25.732030: step 7914, loss 0.547264.
Train: 2018-07-31T01:00:25.888245: step 7915, loss 0.562979.
Train: 2018-07-31T01:00:26.044459: step 7916, loss 0.586841.
Train: 2018-07-31T01:00:26.185050: step 7917, loss 0.475345.
Train: 2018-07-31T01:00:26.325643: step 7918, loss 0.602608.
Train: 2018-07-31T01:00:26.466255: step 7919, loss 0.538639.
Train: 2018-07-31T01:00:26.622475: step 7920, loss 0.538849.
Test: 2018-07-31T01:00:26.872420: step 7920, loss 0.549146.
Train: 2018-07-31T01:00:27.013006: step 7921, loss 0.595559.
Train: 2018-07-31T01:00:27.153601: step 7922, loss 0.54647.
Train: 2018-07-31T01:00:27.294164: step 7923, loss 0.546368.
Train: 2018-07-31T01:00:27.434757: step 7924, loss 0.619967.
Train: 2018-07-31T01:00:27.575374: step 7925, loss 0.513963.
Train: 2018-07-31T01:00:27.715941: step 7926, loss 0.562638.
Train: 2018-07-31T01:00:27.856533: step 7927, loss 0.571016.
Train: 2018-07-31T01:00:27.997150: step 7928, loss 0.587012.
Train: 2018-07-31T01:00:28.137742: step 7929, loss 0.505235.
Train: 2018-07-31T01:00:28.278327: step 7930, loss 0.603602.
Test: 2018-07-31T01:00:28.528281: step 7930, loss 0.548813.
Train: 2018-07-31T01:00:28.684466: step 7931, loss 0.529859.
Train: 2018-07-31T01:00:28.825081: step 7932, loss 0.554408.
Train: 2018-07-31T01:00:28.965666: step 7933, loss 0.570742.
Train: 2018-07-31T01:00:29.121862: step 7934, loss 0.578948.
Train: 2018-07-31T01:00:29.262455: step 7935, loss 0.653063.
Train: 2018-07-31T01:00:29.418667: step 7936, loss 0.59536.
Train: 2018-07-31T01:00:29.559259: step 7937, loss 0.611667.
Train: 2018-07-31T01:00:29.699852: step 7938, loss 0.521875.
Train: 2018-07-31T01:00:29.840443: step 7939, loss 0.587037.
Train: 2018-07-31T01:00:29.996657: step 7940, loss 0.546461.
Test: 2018-07-31T01:00:30.230979: step 7940, loss 0.549173.
Train: 2018-07-31T01:00:30.387215: step 7941, loss 0.554606.
Train: 2018-07-31T01:00:30.543404: step 7942, loss 0.570803.
Train: 2018-07-31T01:00:30.683997: step 7943, loss 0.530435.
Train: 2018-07-31T01:00:30.824588: step 7944, loss 0.562744.
Train: 2018-07-31T01:00:30.965180: step 7945, loss 0.546601.
Train: 2018-07-31T01:00:31.105797: step 7946, loss 0.578886.
Train: 2018-07-31T01:00:31.261987: step 7947, loss 0.562753.
Train: 2018-07-31T01:00:31.402603: step 7948, loss 0.498194.
Train: 2018-07-31T01:00:31.543195: step 7949, loss 0.554645.
Train: 2018-07-31T01:00:31.699383: step 7950, loss 0.514139.
Test: 2018-07-31T01:00:31.933705: step 7950, loss 0.549108.
Train: 2018-07-31T01:00:32.089917: step 7951, loss 0.627608.
Train: 2018-07-31T01:00:32.230509: step 7952, loss 0.546421.
Train: 2018-07-31T01:00:32.371102: step 7953, loss 0.595181.
Train: 2018-07-31T01:00:32.511694: step 7954, loss 0.530102.
Train: 2018-07-31T01:00:32.652284: step 7955, loss 0.562633.
Train: 2018-07-31T01:00:32.792902: step 7956, loss 0.635995.
Train: 2018-07-31T01:00:32.933483: step 7957, loss 0.489327.
Train: 2018-07-31T01:00:33.074062: step 7958, loss 0.644151.
Train: 2018-07-31T01:00:33.214653: step 7959, loss 0.611497.
Train: 2018-07-31T01:00:33.370868: step 7960, loss 0.587037.
Test: 2018-07-31T01:00:33.605189: step 7960, loss 0.549114.
Train: 2018-07-31T01:00:33.745778: step 7961, loss 0.546478.
Train: 2018-07-31T01:00:33.886385: step 7962, loss 0.546531.
Train: 2018-07-31T01:00:34.026963: step 7963, loss 0.570808.
Train: 2018-07-31T01:00:34.167581: step 7964, loss 0.530464.
Train: 2018-07-31T01:00:34.308147: step 7965, loss 0.538544.
Train: 2018-07-31T01:00:34.464362: step 7966, loss 0.619239.
Train: 2018-07-31T01:00:34.604969: step 7967, loss 0.538565.
Train: 2018-07-31T01:00:34.745570: step 7968, loss 0.490206.
Train: 2018-07-31T01:00:34.886164: step 7969, loss 0.514283.
Train: 2018-07-31T01:00:35.042351: step 7970, loss 0.595093.
Test: 2018-07-31T01:00:35.276703: step 7970, loss 0.549088.
Train: 2018-07-31T01:00:35.432883: step 7971, loss 0.538341.
Train: 2018-07-31T01:00:35.573477: step 7972, loss 0.481346.
Train: 2018-07-31T01:00:35.714093: step 7973, loss 0.562575.
Train: 2018-07-31T01:00:35.854660: step 7974, loss 0.513422.
Train: 2018-07-31T01:00:35.995284: step 7975, loss 0.537793.
Train: 2018-07-31T01:00:36.135869: step 7976, loss 0.570813.
Train: 2018-07-31T01:00:36.276437: step 7977, loss 0.520793.
Train: 2018-07-31T01:00:36.417028: step 7978, loss 0.570647.
Train: 2018-07-31T01:00:36.573242: step 7979, loss 0.579335.
Train: 2018-07-31T01:00:36.713835: step 7980, loss 0.537171.
Test: 2018-07-31T01:00:36.963777: step 7980, loss 0.54802.
Train: 2018-07-31T01:00:37.104369: step 7981, loss 0.57088.
Train: 2018-07-31T01:00:37.260581: step 7982, loss 0.663957.
Train: 2018-07-31T01:00:37.401200: step 7983, loss 0.545279.
Train: 2018-07-31T01:00:37.541766: step 7984, loss 0.553731.
Train: 2018-07-31T01:00:37.697980: step 7985, loss 0.562144.
Train: 2018-07-31T01:00:37.838570: step 7986, loss 0.57064.
Train: 2018-07-31T01:00:37.979187: step 7987, loss 0.562278.
Train: 2018-07-31T01:00:38.119779: step 7988, loss 0.55374.
Train: 2018-07-31T01:00:38.260347: step 7989, loss 0.578828.
Train: 2018-07-31T01:00:38.400938: step 7990, loss 0.519547.
Test: 2018-07-31T01:00:38.635260: step 7990, loss 0.548158.
Train: 2018-07-31T01:00:38.775876: step 7991, loss 0.56195.
Train: 2018-07-31T01:00:38.932089: step 7992, loss 0.561709.
Train: 2018-07-31T01:00:39.072674: step 7993, loss 0.536909.
Train: 2018-07-31T01:00:39.213273: step 7994, loss 0.51052.
Train: 2018-07-31T01:00:39.353859: step 7995, loss 0.632713.
Train: 2018-07-31T01:00:39.510055: step 7996, loss 0.559105.
Train: 2018-07-31T01:00:39.650648: step 7997, loss 0.502156.
Train: 2018-07-31T01:00:39.791238: step 7998, loss 0.576946.
Train: 2018-07-31T01:00:39.931830: step 7999, loss 0.543466.
Train: 2018-07-31T01:00:40.072423: step 8000, loss 0.626726.
Test: 2018-07-31T01:00:40.322394: step 8000, loss 0.547689.
Train: 2018-07-31T01:00:41.025325: step 8001, loss 0.565128.
Train: 2018-07-31T01:00:41.165917: step 8002, loss 0.536106.
Train: 2018-07-31T01:00:41.306533: step 8003, loss 0.543753.
Train: 2018-07-31T01:00:41.447101: step 8004, loss 0.536471.
Train: 2018-07-31T01:00:41.603338: step 8005, loss 0.469541.
Train: 2018-07-31T01:00:41.743907: step 8006, loss 0.519597.
Train: 2018-07-31T01:00:41.884499: step 8007, loss 0.511126.
Train: 2018-07-31T01:00:42.025092: step 8008, loss 0.568267.
Train: 2018-07-31T01:00:42.165683: step 8009, loss 0.564372.
Train: 2018-07-31T01:00:42.290678: step 8010, loss 0.584364.
Test: 2018-07-31T01:00:42.540624: step 8010, loss 0.547832.
Train: 2018-07-31T01:00:42.696832: step 8011, loss 0.605088.
Train: 2018-07-31T01:00:42.837400: step 8012, loss 0.520345.
Train: 2018-07-31T01:00:42.977992: step 8013, loss 0.451031.
Train: 2018-07-31T01:00:43.134234: step 8014, loss 0.50902.
Train: 2018-07-31T01:00:43.274818: step 8015, loss 0.564651.
Train: 2018-07-31T01:00:43.431012: step 8016, loss 0.546381.
Train: 2018-07-31T01:00:43.571605: step 8017, loss 0.513376.
Train: 2018-07-31T01:00:43.712220: step 8018, loss 0.578489.
Train: 2018-07-31T01:00:43.868410: step 8019, loss 0.575269.
Train: 2018-07-31T01:00:44.009001: step 8020, loss 0.542605.
Test: 2018-07-31T01:00:44.243322: step 8020, loss 0.547559.
Train: 2018-07-31T01:00:44.415155: step 8021, loss 0.563977.
Train: 2018-07-31T01:00:44.555748: step 8022, loss 0.554671.
Train: 2018-07-31T01:00:44.696364: step 8023, loss 0.627258.
Train: 2018-07-31T01:00:44.836946: step 8024, loss 0.539915.
Train: 2018-07-31T01:00:44.977524: step 8025, loss 0.553083.
Train: 2018-07-31T01:00:45.133738: step 8026, loss 0.654644.
Train: 2018-07-31T01:00:45.274342: step 8027, loss 0.562513.
Train: 2018-07-31T01:00:45.414947: step 8028, loss 0.570511.
Train: 2018-07-31T01:00:45.555513: step 8029, loss 0.578991.
Train: 2018-07-31T01:00:45.696105: step 8030, loss 0.53723.
Test: 2018-07-31T01:00:45.930454: step 8030, loss 0.548767.
Train: 2018-07-31T01:00:46.071042: step 8031, loss 0.54604.
Train: 2018-07-31T01:00:46.227233: step 8032, loss 0.587713.
Train: 2018-07-31T01:00:46.383469: step 8033, loss 0.562522.
Train: 2018-07-31T01:00:46.539658: step 8034, loss 0.619431.
Train: 2018-07-31T01:00:46.680250: step 8035, loss 0.603193.
Train: 2018-07-31T01:00:46.820842: step 8036, loss 0.691521.
Train: 2018-07-31T01:00:46.961434: step 8037, loss 0.546923.
Train: 2018-07-31T01:00:47.102025: step 8038, loss 0.594735.
Train: 2018-07-31T01:00:47.242618: step 8039, loss 0.594644.
Train: 2018-07-31T01:00:47.383210: step 8040, loss 0.516122.
Test: 2018-07-31T01:00:47.633153: step 8040, loss 0.550175.
Train: 2018-07-31T01:00:47.773768: step 8041, loss 0.594513.
Train: 2018-07-31T01:00:47.929982: step 8042, loss 0.625588.
Train: 2018-07-31T01:00:48.070549: step 8043, loss 0.563442.
Train: 2018-07-31T01:00:48.226789: step 8044, loss 0.594364.
Train: 2018-07-31T01:00:48.351759: step 8045, loss 0.517592.
Train: 2018-07-31T01:00:48.507972: step 8046, loss 0.533066.
Train: 2018-07-31T01:00:48.664163: step 8047, loss 0.563707.
Train: 2018-07-31T01:00:48.804778: step 8048, loss 0.517861.
Train: 2018-07-31T01:00:48.945369: step 8049, loss 0.586648.
Train: 2018-07-31T01:00:49.085962: step 8050, loss 0.617279.
Test: 2018-07-31T01:00:49.335879: step 8050, loss 0.550873.
Train: 2018-07-31T01:00:49.476495: step 8051, loss 0.62492.
Train: 2018-07-31T01:00:49.617087: step 8052, loss 0.586648.
Train: 2018-07-31T01:00:49.773300: step 8053, loss 0.518004.
Train: 2018-07-31T01:00:49.913893: step 8054, loss 0.540885.
Train: 2018-07-31T01:00:50.070082: step 8055, loss 0.563743.
Train: 2018-07-31T01:00:50.210673: step 8056, loss 0.563714.
Train: 2018-07-31T01:00:50.351283: step 8057, loss 0.571336.
Train: 2018-07-31T01:00:50.491858: step 8058, loss 0.532974.
Train: 2018-07-31T01:00:50.643961: step 8059, loss 0.555903.
Train: 2018-07-31T01:00:50.784552: step 8060, loss 0.609784.
Test: 2018-07-31T01:00:51.018874: step 8060, loss 0.550564.
Train: 2018-07-31T01:00:51.175087: step 8061, loss 0.586659.
Train: 2018-07-31T01:00:51.315696: step 8062, loss 0.548009.
Train: 2018-07-31T01:00:51.456270: step 8063, loss 0.501478.
Train: 2018-07-31T01:00:51.612485: step 8064, loss 0.532277.
Train: 2018-07-31T01:00:51.753100: step 8065, loss 0.571111.
Train: 2018-07-31T01:00:51.893692: step 8066, loss 0.531868.
Train: 2018-07-31T01:00:52.034260: step 8067, loss 0.531611.
Train: 2018-07-31T01:00:52.190499: step 8068, loss 0.555086.
Train: 2018-07-31T01:00:52.331066: step 8069, loss 0.586836.
Train: 2018-07-31T01:00:52.487303: step 8070, loss 0.602891.
Test: 2018-07-31T01:00:52.721627: step 8070, loss 0.549385.
Train: 2018-07-31T01:00:52.862191: step 8071, loss 0.562837.
Train: 2018-07-31T01:00:53.002783: step 8072, loss 0.538748.
Train: 2018-07-31T01:00:53.143375: step 8073, loss 0.538596.
Train: 2018-07-31T01:00:53.299588: step 8074, loss 0.554542.
Train: 2018-07-31T01:00:53.455827: step 8075, loss 0.587189.
Train: 2018-07-31T01:00:53.596432: step 8076, loss 0.595101.
Train: 2018-07-31T01:00:53.736986: step 8077, loss 0.554626.
Train: 2018-07-31T01:00:53.877580: step 8078, loss 0.505528.
Train: 2018-07-31T01:00:54.018201: step 8079, loss 0.579005.
Train: 2018-07-31T01:00:54.174384: step 8080, loss 0.529813.
Test: 2018-07-31T01:00:54.408705: step 8080, loss 0.548811.
Train: 2018-07-31T01:00:54.564918: step 8081, loss 0.52978.
Train: 2018-07-31T01:00:54.705511: step 8082, loss 0.537822.
Train: 2018-07-31T01:00:54.846102: step 8083, loss 0.604001.
Train: 2018-07-31T01:00:54.986693: step 8084, loss 0.587334.
Train: 2018-07-31T01:00:55.127285: step 8085, loss 0.554211.
Train: 2018-07-31T01:00:55.283501: step 8086, loss 0.512812.
Train: 2018-07-31T01:00:55.424092: step 8087, loss 0.59569.
Train: 2018-07-31T01:00:55.564683: step 8088, loss 0.637162.
Train: 2018-07-31T01:00:55.705275: step 8089, loss 0.521041.
Train: 2018-07-31T01:00:55.845880: step 8090, loss 0.620469.
Test: 2018-07-31T01:00:56.095809: step 8090, loss 0.548628.
Train: 2018-07-31T01:00:56.236426: step 8091, loss 0.512845.
Train: 2018-07-31T01:00:56.376992: step 8092, loss 0.521129.
Train: 2018-07-31T01:00:56.517610: step 8093, loss 0.529372.
Train: 2018-07-31T01:00:56.673800: step 8094, loss 0.512742.
Train: 2018-07-31T01:00:56.814390: step 8095, loss 0.520919.
Train: 2018-07-31T01:00:56.970604: step 8096, loss 0.562433.
Train: 2018-07-31T01:00:57.111195: step 8097, loss 0.604177.
Train: 2018-07-31T01:00:57.267411: step 8098, loss 0.61258.
Train: 2018-07-31T01:00:57.408001: step 8099, loss 0.562412.
Train: 2018-07-31T01:00:57.548595: step 8100, loss 0.487206.
Test: 2018-07-31T01:00:57.782945: step 8100, loss 0.548398.
Train: 2018-07-31T01:00:58.579627: step 8101, loss 0.55404.
Train: 2018-07-31T01:00:58.720195: step 8102, loss 0.604287.
Train: 2018-07-31T01:00:58.860787: step 8103, loss 0.587532.
Train: 2018-07-31T01:00:59.001380: step 8104, loss 0.545662.
Train: 2018-07-31T01:00:59.157593: step 8105, loss 0.528936.
Train: 2018-07-31T01:00:59.313806: step 8106, loss 0.579145.
Train: 2018-07-31T01:00:59.454398: step 8107, loss 0.604243.
Train: 2018-07-31T01:00:59.595014: step 8108, loss 0.61255.
Train: 2018-07-31T01:00:59.735582: step 8109, loss 0.462412.
Train: 2018-07-31T01:00:59.891797: step 8110, loss 0.520759.
Test: 2018-07-31T01:01:00.126149: step 8110, loss 0.548456.
Train: 2018-07-31T01:01:00.266733: step 8111, loss 0.587448.
Train: 2018-07-31T01:01:00.422922: step 8112, loss 0.52906.
Train: 2018-07-31T01:01:00.563537: step 8113, loss 0.604155.
Train: 2018-07-31T01:01:00.719752: step 8114, loss 0.554081.
Train: 2018-07-31T01:01:00.860319: step 8115, loss 0.537407.
Train: 2018-07-31T01:01:01.000935: step 8116, loss 0.570767.
Train: 2018-07-31T01:01:01.141507: step 8117, loss 0.545749.
Train: 2018-07-31T01:01:01.282119: step 8118, loss 0.570765.
Train: 2018-07-31T01:01:01.422687: step 8119, loss 0.554094.
Train: 2018-07-31T01:01:01.563278: step 8120, loss 0.520736.
Test: 2018-07-31T01:01:01.797600: step 8120, loss 0.548425.
Train: 2018-07-31T01:01:01.953837: step 8121, loss 0.51236.
Train: 2018-07-31T01:01:02.094405: step 8122, loss 0.587498.
Train: 2018-07-31T01:01:02.234996: step 8123, loss 0.545674.
Train: 2018-07-31T01:01:02.391210: step 8124, loss 0.520538.
Train: 2018-07-31T01:01:02.531826: step 8125, loss 0.654659.
Train: 2018-07-31T01:01:02.672394: step 8126, loss 0.637853.
Train: 2018-07-31T01:01:02.828607: step 8127, loss 0.528976.
Train: 2018-07-31T01:01:02.969224: step 8128, loss 0.562421.
Train: 2018-07-31T01:01:03.109791: step 8129, loss 0.579096.
Train: 2018-07-31T01:01:03.250383: step 8130, loss 0.637289.
Test: 2018-07-31T01:01:03.500326: step 8130, loss 0.548593.
Train: 2018-07-31T01:01:03.640917: step 8131, loss 0.570757.
Train: 2018-07-31T01:01:03.781509: step 8132, loss 0.595526.
Train: 2018-07-31T01:01:03.922101: step 8133, loss 0.554312.
Train: 2018-07-31T01:01:04.062693: step 8134, loss 0.513405.
Train: 2018-07-31T01:01:04.218908: step 8135, loss 0.587122.
Train: 2018-07-31T01:01:04.359501: step 8136, loss 0.538142.
Train: 2018-07-31T01:01:04.500091: step 8137, loss 0.570777.
Train: 2018-07-31T01:01:04.640683: step 8138, loss 0.530126.
Train: 2018-07-31T01:01:04.781301: step 8139, loss 0.505777.
Train: 2018-07-31T01:01:04.937490: step 8140, loss 0.562649.
Test: 2018-07-31T01:01:05.171839: step 8140, loss 0.549009.
Train: 2018-07-31T01:01:05.328046: step 8141, loss 0.530086.
Train: 2018-07-31T01:01:05.468615: step 8142, loss 0.570775.
Train: 2018-07-31T01:01:05.593585: step 8143, loss 0.554452.
Train: 2018-07-31T01:01:05.734177: step 8144, loss 0.529919.
Train: 2018-07-31T01:01:05.874794: step 8145, loss 0.587136.
Train: 2018-07-31T01:01:06.015361: step 8146, loss 0.64451.
Train: 2018-07-31T01:01:06.155954: step 8147, loss 0.603507.
Train: 2018-07-31T01:01:06.312167: step 8148, loss 0.55443.
Train: 2018-07-31T01:01:06.437139: step 8149, loss 0.587087.
Train: 2018-07-31T01:01:06.593352: step 8150, loss 0.562639.
Test: 2018-07-31T01:01:06.827697: step 8150, loss 0.549053.
Train: 2018-07-31T01:01:06.983885: step 8151, loss 0.554534.
Train: 2018-07-31T01:01:07.140098: step 8152, loss 0.513991.
Train: 2018-07-31T01:01:07.265068: step 8153, loss 0.578904.
Train: 2018-07-31T01:01:07.405686: step 8154, loss 0.63189.
Train: 2018-07-31T01:01:07.546253: step 8155, loss 0.603175.
Train: 2018-07-31T01:01:07.686844: step 8156, loss 0.5466.
Train: 2018-07-31T01:01:07.827454: step 8157, loss 0.538606.
Train: 2018-07-31T01:01:07.968029: step 8158, loss 0.578874.
Train: 2018-07-31T01:01:08.124242: step 8159, loss 0.546739.
Train: 2018-07-31T01:01:08.264858: step 8160, loss 0.490573.
Test: 2018-07-31T01:01:08.499181: step 8160, loss 0.54934.
Train: 2018-07-31T01:01:08.655392: step 8161, loss 0.498506.
Train: 2018-07-31T01:01:08.874091: step 8162, loss 0.562759.
Train: 2018-07-31T01:01:09.014659: step 8163, loss 0.554643.
Train: 2018-07-31T01:01:09.155275: step 8164, loss 0.570793.
Train: 2018-07-31T01:01:09.311466: step 8165, loss 0.481486.
Train: 2018-07-31T01:01:09.452056: step 8166, loss 0.562604.
Train: 2018-07-31T01:01:09.592674: step 8167, loss 0.587101.
Train: 2018-07-31T01:01:09.733266: step 8168, loss 0.472273.
Train: 2018-07-31T01:01:09.889454: step 8169, loss 0.570865.
Train: 2018-07-31T01:01:10.045669: step 8170, loss 0.537713.
Test: 2018-07-31T01:01:10.295610: step 8170, loss 0.548512.
Train: 2018-07-31T01:01:10.436202: step 8171, loss 0.570774.
Train: 2018-07-31T01:01:10.592414: step 8172, loss 0.512395.
Train: 2018-07-31T01:01:10.733007: step 8173, loss 0.562494.
Train: 2018-07-31T01:01:10.873604: step 8174, loss 0.5875.
Train: 2018-07-31T01:01:11.029812: step 8175, loss 0.478064.
Train: 2018-07-31T01:01:11.154783: step 8176, loss 0.537187.
Train: 2018-07-31T01:01:11.295375: step 8177, loss 0.545168.
Train: 2018-07-31T01:01:11.451590: step 8178, loss 0.622278.
Train: 2018-07-31T01:01:11.592181: step 8179, loss 0.622254.
Train: 2018-07-31T01:01:11.732771: step 8180, loss 0.579242.
Test: 2018-07-31T01:01:11.967122: step 8180, loss 0.548046.
Train: 2018-07-31T01:01:12.123306: step 8181, loss 0.579491.
Train: 2018-07-31T01:01:12.263899: step 8182, loss 0.519932.
Train: 2018-07-31T01:01:12.404489: step 8183, loss 0.536893.
Train: 2018-07-31T01:01:12.560704: step 8184, loss 0.638721.
Train: 2018-07-31T01:01:12.701320: step 8185, loss 0.494616.
Train: 2018-07-31T01:01:12.841911: step 8186, loss 0.596212.
Train: 2018-07-31T01:01:12.998126: step 8187, loss 0.528551.
Train: 2018-07-31T01:01:13.138693: step 8188, loss 0.537022.
Train: 2018-07-31T01:01:13.279286: step 8189, loss 0.537027.
Train: 2018-07-31T01:01:13.435497: step 8190, loss 0.570811.
Test: 2018-07-31T01:01:13.669845: step 8190, loss 0.548218.
Train: 2018-07-31T01:01:13.810410: step 8191, loss 0.562364.
Train: 2018-07-31T01:01:13.966624: step 8192, loss 0.553921.
Train: 2018-07-31T01:01:14.107241: step 8193, loss 0.553925.
Train: 2018-07-31T01:01:14.247808: step 8194, loss 0.528611.
Train: 2018-07-31T01:01:14.388400: step 8195, loss 0.545482.
Train: 2018-07-31T01:01:14.528993: step 8196, loss 0.613042.
Train: 2018-07-31T01:01:14.669585: step 8197, loss 0.511733.
Train: 2018-07-31T01:01:14.825799: step 8198, loss 0.663654.
Train: 2018-07-31T01:01:14.966415: step 8199, loss 0.553954.
Train: 2018-07-31T01:01:15.138226: step 8200, loss 0.537172.
Test: 2018-07-31T01:01:15.372547: step 8200, loss 0.548337.
Train: 2018-07-31T01:01:16.137992: step 8201, loss 0.64631.
Train: 2018-07-31T01:01:16.278627: step 8202, loss 0.487136.
Train: 2018-07-31T01:01:16.419199: step 8203, loss 0.629231.
Train: 2018-07-31T01:01:16.559769: step 8204, loss 0.504148.
Train: 2018-07-31T01:01:16.715980: step 8205, loss 0.570761.
Train: 2018-07-31T01:01:16.872218: step 8206, loss 0.595665.
Train: 2018-07-31T01:01:17.028408: step 8207, loss 0.603888.
Train: 2018-07-31T01:01:17.169023: step 8208, loss 0.58727.
Train: 2018-07-31T01:01:17.309592: step 8209, loss 0.587214.
Train: 2018-07-31T01:01:17.465806: step 8210, loss 0.505186.
Test: 2018-07-31T01:01:17.700151: step 8210, loss 0.548886.
Train: 2018-07-31T01:01:17.840742: step 8211, loss 0.521685.
Train: 2018-07-31T01:01:18.012553: step 8212, loss 0.578941.
Train: 2018-07-31T01:01:18.168766: step 8213, loss 0.693217.
Train: 2018-07-31T01:01:18.309358: step 8214, loss 0.554526.
Train: 2018-07-31T01:01:18.465572: step 8215, loss 0.5465.
Train: 2018-07-31T01:01:18.606163: step 8216, loss 0.619267.
Train: 2018-07-31T01:01:18.746754: step 8217, loss 0.570836.
Train: 2018-07-31T01:01:18.887371: step 8218, loss 0.546806.
Train: 2018-07-31T01:01:19.043560: step 8219, loss 0.562877.
Train: 2018-07-31T01:01:19.199798: step 8220, loss 0.570882.
Test: 2018-07-31T01:01:19.434096: step 8220, loss 0.549622.
Train: 2018-07-31T01:01:19.637171: step 8221, loss 0.539081.
Train: 2018-07-31T01:01:19.777763: step 8222, loss 0.578851.
Train: 2018-07-31T01:01:19.918390: step 8223, loss 0.562995.
Train: 2018-07-31T01:01:20.074594: step 8224, loss 0.531312.
Train: 2018-07-31T01:01:20.215186: step 8225, loss 0.539226.
Train: 2018-07-31T01:01:20.355753: step 8226, loss 0.531281.
Train: 2018-07-31T01:01:20.496370: step 8227, loss 0.570911.
Train: 2018-07-31T01:01:20.636937: step 8228, loss 0.52317.
Train: 2018-07-31T01:01:20.777528: step 8229, loss 0.507091.
Train: 2018-07-31T01:01:20.918121: step 8230, loss 0.506845.
Test: 2018-07-31T01:01:21.168063: step 8230, loss 0.549307.
Train: 2018-07-31T01:01:21.308654: step 8231, loss 0.514505.
Train: 2018-07-31T01:01:21.464867: step 8232, loss 0.554538.
Train: 2018-07-31T01:01:21.605485: step 8233, loss 0.578906.
Train: 2018-07-31T01:01:21.746054: step 8234, loss 0.595308.
Train: 2018-07-31T01:01:21.886644: step 8235, loss 0.554233.
Train: 2018-07-31T01:01:22.042859: step 8236, loss 0.554499.
Train: 2018-07-31T01:01:22.183451: step 8237, loss 0.645191.
Train: 2018-07-31T01:01:22.324043: step 8238, loss 0.570703.
Train: 2018-07-31T01:01:22.464638: step 8239, loss 0.554225.
Train: 2018-07-31T01:01:22.605227: step 8240, loss 0.562429.
Test: 2018-07-31T01:01:22.839576: step 8240, loss 0.548673.
Train: 2018-07-31T01:01:22.980139: step 8241, loss 0.636865.
Train: 2018-07-31T01:01:23.136353: step 8242, loss 0.496628.
Train: 2018-07-31T01:01:23.276945: step 8243, loss 0.579002.
Train: 2018-07-31T01:01:23.417536: step 8244, loss 0.554302.
Train: 2018-07-31T01:01:23.558128: step 8245, loss 0.504952.
Train: 2018-07-31T01:01:23.698745: step 8246, loss 0.570798.
Train: 2018-07-31T01:01:23.854958: step 8247, loss 0.52959.
Train: 2018-07-31T01:01:23.995526: step 8248, loss 0.496529.
Train: 2018-07-31T01:01:24.136135: step 8249, loss 0.645189.
Train: 2018-07-31T01:01:24.292355: step 8250, loss 0.529393.
Test: 2018-07-31T01:01:24.542274: step 8250, loss 0.548599.
Train: 2018-07-31T01:01:24.682889: step 8251, loss 0.52935.
Train: 2018-07-31T01:01:24.839079: step 8252, loss 0.545873.
Train: 2018-07-31T01:01:24.995316: step 8253, loss 0.56245.
Train: 2018-07-31T01:01:25.135908: step 8254, loss 0.554117.
Train: 2018-07-31T01:01:25.276475: step 8255, loss 0.554094.
Train: 2018-07-31T01:01:25.417068: step 8256, loss 0.6125.
Train: 2018-07-31T01:01:25.557660: step 8257, loss 0.520691.
Train: 2018-07-31T01:01:25.698251: step 8258, loss 0.604181.
Train: 2018-07-31T01:01:25.838861: step 8259, loss 0.562419.
Train: 2018-07-31T01:01:25.979436: step 8260, loss 0.554075.
Test: 2018-07-31T01:01:26.229378: step 8260, loss 0.548457.
Train: 2018-07-31T01:01:26.369969: step 8261, loss 0.60414.
Train: 2018-07-31T01:01:26.510593: step 8262, loss 0.562432.
Train: 2018-07-31T01:01:26.651154: step 8263, loss 0.604044.
Train: 2018-07-31T01:01:26.807392: step 8264, loss 0.562457.
Train: 2018-07-31T01:01:26.947983: step 8265, loss 0.57904.
Train: 2018-07-31T01:01:27.104174: step 8266, loss 0.562493.
Train: 2018-07-31T01:01:27.244766: step 8267, loss 0.59549.
Train: 2018-07-31T01:01:27.385381: step 8268, loss 0.595421.
Train: 2018-07-31T01:01:27.525949: step 8269, loss 0.595341.
Train: 2018-07-31T01:01:27.666565: step 8270, loss 0.54629.
Test: 2018-07-31T01:01:27.916512: step 8270, loss 0.549022.
Train: 2018-07-31T01:01:28.057074: step 8271, loss 0.570781.
Train: 2018-07-31T01:01:28.197666: step 8272, loss 0.619454.
Train: 2018-07-31T01:01:28.338257: step 8273, loss 0.595041.
Train: 2018-07-31T01:01:28.478876: step 8274, loss 0.522585.
Train: 2018-07-31T01:01:28.619468: step 8275, loss 0.618955.
Train: 2018-07-31T01:01:28.760036: step 8276, loss 0.594833.
Train: 2018-07-31T01:01:28.885004: step 8277, loss 0.562955.
Train: 2018-07-31T01:01:29.041219: step 8278, loss 0.53925.
Train: 2018-07-31T01:01:29.181837: step 8279, loss 0.578861.
Train: 2018-07-31T01:01:29.338050: step 8280, loss 0.547342.
Test: 2018-07-31T01:01:29.572375: step 8280, loss 0.549958.
Train: 2018-07-31T01:01:29.728559: step 8281, loss 0.49233.
Train: 2018-07-31T01:01:29.884773: step 8282, loss 0.578866.
Train: 2018-07-31T01:01:30.025365: step 8283, loss 0.523757.
Train: 2018-07-31T01:01:30.165980: step 8284, loss 0.586736.
Train: 2018-07-31T01:01:30.322193: step 8285, loss 0.531526.
Train: 2018-07-31T01:01:30.462785: step 8286, loss 0.610499.
Train: 2018-07-31T01:01:30.603353: step 8287, loss 0.594657.
Train: 2018-07-31T01:01:30.759606: step 8288, loss 0.578852.
Train: 2018-07-31T01:01:30.915782: step 8289, loss 0.602553.
Train: 2018-07-31T01:01:31.087639: step 8290, loss 0.610538.
Test: 2018-07-31T01:01:31.321935: step 8290, loss 0.549907.
Train: 2018-07-31T01:01:31.462526: step 8291, loss 0.49221.
Train: 2018-07-31T01:01:31.618742: step 8292, loss 0.578866.
Train: 2018-07-31T01:01:31.759333: step 8293, loss 0.57099.
Train: 2018-07-31T01:01:31.899926: step 8294, loss 0.507994.
Train: 2018-07-31T01:01:32.056139: step 8295, loss 0.555204.
Train: 2018-07-31T01:01:32.196755: step 8296, loss 0.602562.
Train: 2018-07-31T01:01:32.337346: step 8297, loss 0.539332.
Train: 2018-07-31T01:01:32.493536: step 8298, loss 0.626361.
Train: 2018-07-31T01:01:32.634128: step 8299, loss 0.563029.
Train: 2018-07-31T01:01:32.774744: step 8300, loss 0.602606.
Test: 2018-07-31T01:01:33.009039: step 8300, loss 0.549808.
Train: 2018-07-31T01:01:33.758865: step 8301, loss 0.570952.
Train: 2018-07-31T01:01:33.915079: step 8302, loss 0.53145.
Train: 2018-07-31T01:01:34.055671: step 8303, loss 0.594669.
Train: 2018-07-31T01:01:34.211884: step 8304, loss 0.476154.
Train: 2018-07-31T01:01:34.352476: step 8305, loss 0.546137.
Train: 2018-07-31T01:01:34.493084: step 8306, loss 0.610602.
Train: 2018-07-31T01:01:34.649305: step 8307, loss 0.515299.
Train: 2018-07-31T01:01:34.789872: step 8308, loss 0.562928.
Train: 2018-07-31T01:01:34.946104: step 8309, loss 0.530941.
Train: 2018-07-31T01:01:35.086703: step 8310, loss 0.570799.
Test: 2018-07-31T01:01:35.321030: step 8310, loss 0.549307.
Train: 2018-07-31T01:01:35.477213: step 8311, loss 0.570764.
Train: 2018-07-31T01:01:35.617803: step 8312, loss 0.530369.
Train: 2018-07-31T01:01:35.758425: step 8313, loss 0.643773.
Train: 2018-07-31T01:01:35.914608: step 8314, loss 0.578758.
Train: 2018-07-31T01:01:36.055226: step 8315, loss 0.538916.
Train: 2018-07-31T01:01:36.195819: step 8316, loss 0.546075.
Train: 2018-07-31T01:01:36.352031: step 8317, loss 0.513657.
Train: 2018-07-31T01:01:36.492598: step 8318, loss 0.586979.
Train: 2018-07-31T01:01:36.633215: step 8319, loss 0.596521.
Train: 2018-07-31T01:01:36.789405: step 8320, loss 0.505284.
Test: 2018-07-31T01:01:37.023751: step 8320, loss 0.548844.
Train: 2018-07-31T01:01:37.179940: step 8321, loss 0.553777.
Train: 2018-07-31T01:01:37.336176: step 8322, loss 0.570264.
Train: 2018-07-31T01:01:37.476769: step 8323, loss 0.571344.
Train: 2018-07-31T01:01:37.632956: step 8324, loss 0.562006.
Train: 2018-07-31T01:01:37.773574: step 8325, loss 0.554617.
Train: 2018-07-31T01:01:37.929764: step 8326, loss 0.563436.
Train: 2018-07-31T01:01:38.070354: step 8327, loss 0.521661.
Train: 2018-07-31T01:01:38.226614: step 8328, loss 0.521732.
Train: 2018-07-31T01:01:38.382783: step 8329, loss 0.488105.
Train: 2018-07-31T01:01:38.523398: step 8330, loss 0.571036.
Test: 2018-07-31T01:01:38.757724: step 8330, loss 0.54852.
Train: 2018-07-31T01:01:38.913908: step 8331, loss 0.504473.
Train: 2018-07-31T01:01:39.054499: step 8332, loss 0.612667.
Train: 2018-07-31T01:01:39.195091: step 8333, loss 0.520687.
Train: 2018-07-31T01:01:39.335684: step 8334, loss 0.529128.
Train: 2018-07-31T01:01:39.476275: step 8335, loss 0.562443.
Train: 2018-07-31T01:01:39.616868: step 8336, loss 0.579211.
Train: 2018-07-31T01:01:39.773105: step 8337, loss 0.54554.
Train: 2018-07-31T01:01:39.929319: step 8338, loss 0.587626.
Train: 2018-07-31T01:01:40.085509: step 8339, loss 0.621378.
Train: 2018-07-31T01:01:40.226124: step 8340, loss 0.537103.
Test: 2018-07-31T01:01:40.460454: step 8340, loss 0.548268.
Train: 2018-07-31T01:01:40.616657: step 8341, loss 0.503415.
Train: 2018-07-31T01:01:40.757250: step 8342, loss 0.587666.
Train: 2018-07-31T01:01:40.897843: step 8343, loss 0.604538.
Train: 2018-07-31T01:01:41.054030: step 8344, loss 0.638206.
Train: 2018-07-31T01:01:41.194623: step 8345, loss 0.537176.
Train: 2018-07-31T01:01:41.350836: step 8346, loss 0.579166.
Train: 2018-07-31T01:01:41.491427: step 8347, loss 0.478751.
Train: 2018-07-31T01:01:41.647641: step 8348, loss 0.579135.
Train: 2018-07-31T01:01:41.788234: step 8349, loss 0.528992.
Train: 2018-07-31T01:01:41.928850: step 8350, loss 0.478867.
Test: 2018-07-31T01:01:42.178768: step 8350, loss 0.548389.
Train: 2018-07-31T01:01:42.319366: step 8351, loss 0.478715.
Train: 2018-07-31T01:01:42.475572: step 8352, loss 0.621165.
Train: 2018-07-31T01:01:42.616166: step 8353, loss 0.537154.
Train: 2018-07-31T01:01:42.772379: step 8354, loss 0.587645.
Train: 2018-07-31T01:01:42.912972: step 8355, loss 0.596093.
Train: 2018-07-31T01:01:43.053587: step 8356, loss 0.579229.
Train: 2018-07-31T01:01:43.194180: step 8357, loss 0.596066.
Train: 2018-07-31T01:01:43.334747: step 8358, loss 0.562381.
Train: 2018-07-31T01:01:43.475340: step 8359, loss 0.629556.
Train: 2018-07-31T01:01:43.615956: step 8360, loss 0.587514.
Test: 2018-07-31T01:01:43.865873: step 8360, loss 0.54846.
Train: 2018-07-31T01:01:44.006482: step 8361, loss 0.637487.
Train: 2018-07-31T01:01:44.162679: step 8362, loss 0.570758.
Train: 2018-07-31T01:01:44.303270: step 8363, loss 0.63682.
Train: 2018-07-31T01:01:44.443888: step 8364, loss 0.628209.
Train: 2018-07-31T01:01:44.600076: step 8365, loss 0.587072.
Train: 2018-07-31T01:01:44.740668: step 8366, loss 0.586982.
Train: 2018-07-31T01:01:44.896905: step 8367, loss 0.490505.
Train: 2018-07-31T01:01:45.037472: step 8368, loss 0.506886.
Train: 2018-07-31T01:01:45.193688: step 8369, loss 0.602792.
Train: 2018-07-31T01:01:45.334279: step 8370, loss 0.562955.
Test: 2018-07-31T01:01:45.568600: step 8370, loss 0.549717.
Train: 2018-07-31T01:01:45.709216: step 8371, loss 0.586789.
Train: 2018-07-31T01:01:45.865404: step 8372, loss 0.618397.
Train: 2018-07-31T01:01:46.005996: step 8373, loss 0.578866.
Train: 2018-07-31T01:01:46.146588: step 8374, loss 0.523943.
Train: 2018-07-31T01:01:46.287180: step 8375, loss 0.563218.
Train: 2018-07-31T01:01:46.443394: step 8376, loss 0.531981.
Train: 2018-07-31T01:01:46.584013: step 8377, loss 0.602327.
Train: 2018-07-31T01:01:46.724577: step 8378, loss 0.594499.
Train: 2018-07-31T01:01:46.865170: step 8379, loss 0.578897.
Train: 2018-07-31T01:01:47.021384: step 8380, loss 0.571126.
Test: 2018-07-31T01:01:47.255730: step 8380, loss 0.55037.
Train: 2018-07-31T01:01:47.396296: step 8381, loss 0.547844.
Train: 2018-07-31T01:01:47.536889: step 8382, loss 0.602196.
Train: 2018-07-31T01:01:47.693102: step 8383, loss 0.602171.
Train: 2018-07-31T01:01:47.849314: step 8384, loss 0.609874.
Train: 2018-07-31T01:01:47.989905: step 8385, loss 0.602088.
Train: 2018-07-31T01:01:48.130499: step 8386, loss 0.540512.
Train: 2018-07-31T01:01:48.271091: step 8387, loss 0.494547.
Train: 2018-07-31T01:01:48.427329: step 8388, loss 0.571294.
Train: 2018-07-31T01:01:48.599140: step 8389, loss 0.594335.
Train: 2018-07-31T01:01:48.739731: step 8390, loss 0.53287.
Test: 2018-07-31T01:01:48.974052: step 8390, loss 0.55069.
Train: 2018-07-31T01:01:49.114643: step 8391, loss 0.532809.
Train: 2018-07-31T01:01:49.255236: step 8392, loss 0.555821.
Train: 2018-07-31T01:01:49.395853: step 8393, loss 0.540292.
Train: 2018-07-31T01:01:49.552040: step 8394, loss 0.602176.
Train: 2018-07-31T01:01:49.692633: step 8395, loss 0.508988.
Train: 2018-07-31T01:01:49.833225: step 8396, loss 0.555503.
Train: 2018-07-31T01:01:49.973842: step 8397, loss 0.53193.
Train: 2018-07-31T01:01:50.130032: step 8398, loss 0.555293.
Train: 2018-07-31T01:01:50.270624: step 8399, loss 0.570969.
Train: 2018-07-31T01:01:50.411239: step 8400, loss 0.499628.
Test: 2018-07-31T01:01:50.661157: step 8400, loss 0.549583.
Train: 2018-07-31T01:01:51.379737: step 8401, loss 0.547002.
Train: 2018-07-31T01:01:51.520355: step 8402, loss 0.530828.
Train: 2018-07-31T01:01:51.676561: step 8403, loss 0.603026.
Train: 2018-07-31T01:01:51.817135: step 8404, loss 0.530393.
Train: 2018-07-31T01:01:51.957728: step 8405, loss 0.562672.
Train: 2018-07-31T01:01:52.098319: step 8406, loss 0.521869.
Train: 2018-07-31T01:01:52.238913: step 8407, loss 0.578954.
Train: 2018-07-31T01:01:52.379505: step 8408, loss 0.652957.
Train: 2018-07-31T01:01:52.520097: step 8409, loss 0.587218.
Train: 2018-07-31T01:01:52.660722: step 8410, loss 0.554291.
Test: 2018-07-31T01:01:52.895038: step 8410, loss 0.54873.
Train: 2018-07-31T01:01:53.035600: step 8411, loss 0.480168.
Train: 2018-07-31T01:01:53.191815: step 8412, loss 0.570755.
Train: 2018-07-31T01:01:53.332405: step 8413, loss 0.562485.
Train: 2018-07-31T01:01:53.472997: step 8414, loss 0.537627.
Train: 2018-07-31T01:01:53.613614: step 8415, loss 0.620561.
Train: 2018-07-31T01:01:53.754207: step 8416, loss 0.554154.
Train: 2018-07-31T01:01:53.910419: step 8417, loss 0.554152.
Train: 2018-07-31T01:01:54.050987: step 8418, loss 0.579068.
Train: 2018-07-31T01:01:54.191579: step 8419, loss 0.653818.
Train: 2018-07-31T01:01:54.347792: step 8420, loss 0.562473.
Test: 2018-07-31T01:01:54.582143: step 8420, loss 0.548641.
Train: 2018-07-31T01:01:54.722705: step 8421, loss 0.55422.
Train: 2018-07-31T01:01:54.863296: step 8422, loss 0.529493.
Train: 2018-07-31T01:01:55.019511: step 8423, loss 0.496553.
Train: 2018-07-31T01:01:55.160102: step 8424, loss 0.587256.
Train: 2018-07-31T01:01:55.316318: step 8425, loss 0.546008.
Train: 2018-07-31T01:01:55.456932: step 8426, loss 0.579008.
Train: 2018-07-31T01:01:55.597528: step 8427, loss 0.554257.
Train: 2018-07-31T01:01:55.753738: step 8428, loss 0.554258.
Train: 2018-07-31T01:01:55.894335: step 8429, loss 0.595506.
Train: 2018-07-31T01:01:56.034898: step 8430, loss 0.521295.
Test: 2018-07-31T01:01:56.284840: step 8430, loss 0.548702.
Train: 2018-07-31T01:01:56.441053: step 8431, loss 0.611984.
Train: 2018-07-31T01:01:56.581645: step 8432, loss 0.570757.
Train: 2018-07-31T01:01:56.722254: step 8433, loss 0.529621.
Train: 2018-07-31T01:01:56.878475: step 8434, loss 0.537859.
Train: 2018-07-31T01:01:57.019059: step 8435, loss 0.578985.
Train: 2018-07-31T01:01:57.159635: step 8436, loss 0.628333.
Train: 2018-07-31T01:01:57.300245: step 8437, loss 0.56255.
Train: 2018-07-31T01:01:57.440819: step 8438, loss 0.537977.
Train: 2018-07-31T01:01:57.581412: step 8439, loss 0.578953.
Train: 2018-07-31T01:01:57.722027: step 8440, loss 0.595302.
Test: 2018-07-31T01:01:57.956322: step 8440, loss 0.548938.
Train: 2018-07-31T01:01:58.112561: step 8441, loss 0.480982.
Train: 2018-07-31T01:01:58.253145: step 8442, loss 0.619757.
Train: 2018-07-31T01:01:58.409343: step 8443, loss 0.497381.
Train: 2018-07-31T01:01:58.565555: step 8444, loss 0.546296.
Train: 2018-07-31T01:01:58.706186: step 8445, loss 0.472782.
Train: 2018-07-31T01:01:58.846740: step 8446, loss 0.554385.
Train: 2018-07-31T01:01:58.987349: step 8447, loss 0.554336.
Train: 2018-07-31T01:01:59.127923: step 8448, loss 0.578991.
Train: 2018-07-31T01:01:59.268540: step 8449, loss 0.562506.
Train: 2018-07-31T01:01:59.424730: step 8450, loss 0.587284.
Test: 2018-07-31T01:01:59.659079: step 8450, loss 0.548634.
Train: 2018-07-31T01:01:59.815264: step 8451, loss 0.529402.
Train: 2018-07-31T01:01:59.955855: step 8452, loss 0.454793.
Train: 2018-07-31T01:02:00.096471: step 8453, loss 0.562446.
Train: 2018-07-31T01:02:00.252662: step 8454, loss 0.587449.
Train: 2018-07-31T01:02:00.408874: step 8455, loss 0.570772.
Train: 2018-07-31T01:02:00.549467: step 8456, loss 0.615996.
Train: 2018-07-31T01:02:00.690057: step 8457, loss 0.487025.
Train: 2018-07-31T01:02:00.830675: step 8458, loss 0.545613.
Train: 2018-07-31T01:02:00.971241: step 8459, loss 0.596002.
Train: 2018-07-31T01:02:01.127468: step 8460, loss 0.4951.
Test: 2018-07-31T01:02:01.361809: step 8460, loss 0.54826.
Train: 2018-07-31T01:02:01.502393: step 8461, loss 0.562373.
Train: 2018-07-31T01:02:01.658582: step 8462, loss 0.503285.
Train: 2018-07-31T01:02:01.799191: step 8463, loss 0.587743.
Train: 2018-07-31T01:02:01.939764: step 8464, loss 0.536927.
Train: 2018-07-31T01:02:02.096003: step 8465, loss 0.511407.
Train: 2018-07-31T01:02:02.236595: step 8466, loss 0.579365.
Train: 2018-07-31T01:02:02.377162: step 8467, loss 0.545289.
Train: 2018-07-31T01:02:02.517779: step 8468, loss 0.613576.
Train: 2018-07-31T01:02:02.673993: step 8469, loss 0.57942.
Train: 2018-07-31T01:02:02.830180: step 8470, loss 0.519657.
Test: 2018-07-31T01:02:03.080124: step 8470, loss 0.548038.
Train: 2018-07-31T01:02:03.220715: step 8471, loss 0.54526.
Train: 2018-07-31T01:02:03.361307: step 8472, loss 0.553797.
Train: 2018-07-31T01:02:03.517520: step 8473, loss 0.579424.
Train: 2018-07-31T01:02:03.658114: step 8474, loss 0.605039.
Train: 2018-07-31T01:02:03.783108: step 8475, loss 0.622033.
Train: 2018-07-31T01:02:03.939297: step 8476, loss 0.519831.
Train: 2018-07-31T01:02:04.079913: step 8477, loss 0.562349.
Train: 2018-07-31T01:02:04.220505: step 8478, loss 0.511534.
Train: 2018-07-31T01:02:04.361074: step 8479, loss 0.579283.
Train: 2018-07-31T01:02:04.517286: step 8480, loss 0.621529.
Test: 2018-07-31T01:02:04.751608: step 8480, loss 0.548253.
Train: 2018-07-31T01:02:04.892199: step 8481, loss 0.520222.
Train: 2018-07-31T01:02:05.048413: step 8482, loss 0.55396.
Train: 2018-07-31T01:02:05.189005: step 8483, loss 0.663232.
Train: 2018-07-31T01:02:05.329596: step 8484, loss 0.562404.
Train: 2018-07-31T01:02:05.470212: step 8485, loss 0.62917.
Train: 2018-07-31T01:02:05.626426: step 8486, loss 0.579062.
Train: 2018-07-31T01:02:05.767018: step 8487, loss 0.496393.
Train: 2018-07-31T01:02:05.923243: step 8488, loss 0.496609.
Train: 2018-07-31T01:02:06.063799: step 8489, loss 0.636593.
Train: 2018-07-31T01:02:06.220038: step 8490, loss 0.570761.
Test: 2018-07-31T01:02:06.454365: step 8490, loss 0.548876.
Train: 2018-07-31T01:02:06.594950: step 8491, loss 0.554398.
Train: 2018-07-31T01:02:06.751166: step 8492, loss 0.611595.
Train: 2018-07-31T01:02:06.891730: step 8493, loss 0.489398.
Train: 2018-07-31T01:02:07.032321: step 8494, loss 0.587041.
Train: 2018-07-31T01:02:07.172914: step 8495, loss 0.627597.
Train: 2018-07-31T01:02:07.313507: step 8496, loss 0.595074.
Train: 2018-07-31T01:02:07.454098: step 8497, loss 0.586944.
Train: 2018-07-31T01:02:07.594690: step 8498, loss 0.554771.
Train: 2018-07-31T01:02:07.735307: step 8499, loss 0.514793.
Train: 2018-07-31T01:02:07.891497: step 8500, loss 0.546873.
Test: 2018-07-31T01:02:08.125816: step 8500, loss 0.549497.
Train: 2018-07-31T01:02:08.875641: step 8501, loss 0.498952.
Train: 2018-07-31T01:02:09.016232: step 8502, loss 0.570864.
Train: 2018-07-31T01:02:09.156824: step 8503, loss 0.538839.
Train: 2018-07-31T01:02:09.297417: step 8504, loss 0.514736.
Train: 2018-07-31T01:02:09.438008: step 8505, loss 0.562799.
Train: 2018-07-31T01:02:09.578601: step 8506, loss 0.546655.
Train: 2018-07-31T01:02:09.719194: step 8507, loss 0.498121.
Train: 2018-07-31T01:02:09.859810: step 8508, loss 0.546468.
Train: 2018-07-31T01:02:10.000377: step 8509, loss 0.5952.
Train: 2018-07-31T01:02:10.140971: step 8510, loss 0.497304.
Test: 2018-07-31T01:02:10.390927: step 8510, loss 0.54884.
Train: 2018-07-31T01:02:10.531504: step 8511, loss 0.63633.
Train: 2018-07-31T01:02:10.672095: step 8512, loss 0.529705.
Train: 2018-07-31T01:02:10.828309: step 8513, loss 0.513142.
Train: 2018-07-31T01:02:10.953279: step 8514, loss 0.603787.
Train: 2018-07-31T01:02:11.093871: step 8515, loss 0.570756.
Train: 2018-07-31T01:02:11.250086: step 8516, loss 0.529331.
Train: 2018-07-31T01:02:11.390702: step 8517, loss 0.57906.
Train: 2018-07-31T01:02:11.562512: step 8518, loss 0.595698.
Train: 2018-07-31T01:02:11.703103: step 8519, loss 0.495927.
Train: 2018-07-31T01:02:11.843696: step 8520, loss 0.479145.
Test: 2018-07-31T01:02:12.078049: step 8520, loss 0.548419.
Train: 2018-07-31T01:02:12.218608: step 8521, loss 0.59584.
Train: 2018-07-31T01:02:12.359225: step 8522, loss 0.595899.
Train: 2018-07-31T01:02:12.499837: step 8523, loss 0.528868.
Train: 2018-07-31T01:02:12.656031: step 8524, loss 0.537205.
Train: 2018-07-31T01:02:12.812244: step 8525, loss 0.562381.
Train: 2018-07-31T01:02:12.952828: step 8526, loss 0.596062.
Train: 2018-07-31T01:02:13.093404: step 8527, loss 0.579223.
Train: 2018-07-31T01:02:13.233995: step 8528, loss 0.587643.
Train: 2018-07-31T01:02:13.374586: step 8529, loss 0.570794.
Train: 2018-07-31T01:02:13.515179: step 8530, loss 0.545574.
Test: 2018-07-31T01:02:13.765145: step 8530, loss 0.548323.
Train: 2018-07-31T01:02:13.905737: step 8531, loss 0.595979.
Train: 2018-07-31T01:02:14.046306: step 8532, loss 0.512094.
Train: 2018-07-31T01:02:14.186897: step 8533, loss 0.629434.
Train: 2018-07-31T01:02:14.327489: step 8534, loss 0.537326.
Train: 2018-07-31T01:02:14.483703: step 8535, loss 0.55407.
Train: 2018-07-31T01:02:14.624296: step 8536, loss 0.612459.
Train: 2018-07-31T01:02:14.764887: step 8537, loss 0.504212.
Train: 2018-07-31T01:02:14.921131: step 8538, loss 0.520895.
Train: 2018-07-31T01:02:15.061717: step 8539, loss 0.579071.
Train: 2018-07-31T01:02:15.202284: step 8540, loss 0.57076.
Test: 2018-07-31T01:02:15.452256: step 8540, loss 0.548555.
Train: 2018-07-31T01:02:15.592817: step 8541, loss 0.520951.
Train: 2018-07-31T01:02:15.764652: step 8542, loss 0.504333.
Train: 2018-07-31T01:02:15.905244: step 8543, loss 0.520869.
Train: 2018-07-31T01:02:16.061459: step 8544, loss 0.595764.
Train: 2018-07-31T01:02:16.202050: step 8545, loss 0.587451.
Train: 2018-07-31T01:02:16.358264: step 8546, loss 0.520701.
Train: 2018-07-31T01:02:16.498857: step 8547, loss 0.587476.
Train: 2018-07-31T01:02:16.639475: step 8548, loss 0.512282.
Train: 2018-07-31T01:02:16.780040: step 8549, loss 0.562407.
Train: 2018-07-31T01:02:16.920633: step 8550, loss 0.562402.
Test: 2018-07-31T01:02:17.170598: step 8550, loss 0.548362.
Train: 2018-07-31T01:02:17.326786: step 8551, loss 0.654585.
Train: 2018-07-31T01:02:17.467378: step 8552, loss 0.554039.
Train: 2018-07-31T01:02:17.607972: step 8553, loss 0.662692.
Train: 2018-07-31T01:02:17.748569: step 8554, loss 0.637373.
Train: 2018-07-31T01:02:17.889180: step 8555, loss 0.579041.
Train: 2018-07-31T01:02:18.029746: step 8556, loss 0.570757.
Train: 2018-07-31T01:02:18.185984: step 8557, loss 0.480536.
Train: 2018-07-31T01:02:18.326577: step 8558, loss 0.513491.
Train: 2018-07-31T01:02:18.482767: step 8559, loss 0.472688.
Train: 2018-07-31T01:02:18.623382: step 8560, loss 0.570766.
Test: 2018-07-31T01:02:18.857708: step 8560, loss 0.548859.
Train: 2018-07-31T01:02:19.013893: step 8561, loss 0.505249.
Train: 2018-07-31T01:02:19.154508: step 8562, loss 0.611792.
Train: 2018-07-31T01:02:19.295074: step 8563, loss 0.587184.
Train: 2018-07-31T01:02:19.451331: step 8564, loss 0.578972.
Train: 2018-07-31T01:02:19.591906: step 8565, loss 0.661049.
Train: 2018-07-31T01:02:19.748095: step 8566, loss 0.644436.
Train: 2018-07-31T01:02:19.888705: step 8567, loss 0.587075.
Train: 2018-07-31T01:02:20.029304: step 8568, loss 0.603241.
Train: 2018-07-31T01:02:20.185493: step 8569, loss 0.546599.
Train: 2018-07-31T01:02:20.326109: step 8570, loss 0.643176.
Test: 2018-07-31T01:02:20.560407: step 8570, loss 0.549491.
Train: 2018-07-31T01:02:20.716642: step 8571, loss 0.546891.
Train: 2018-07-31T01:02:20.857211: step 8572, loss 0.539078.
Train: 2018-07-31T01:02:20.997828: step 8573, loss 0.64229.
Train: 2018-07-31T01:02:21.154016: step 8574, loss 0.570973.
Train: 2018-07-31T01:02:21.294609: step 8575, loss 0.539599.
Train: 2018-07-31T01:02:21.435225: step 8576, loss 0.625854.
Train: 2018-07-31T01:02:21.575793: step 8577, loss 0.594485.
Train: 2018-07-31T01:02:21.716409: step 8578, loss 0.49355.
Train: 2018-07-31T01:02:21.872599: step 8579, loss 0.555687.
Train: 2018-07-31T01:02:22.013189: step 8580, loss 0.501575.
Test: 2018-07-31T01:02:22.263161: step 8580, loss 0.550478.
Train: 2018-07-31T01:02:22.403747: step 8581, loss 0.578925.
Train: 2018-07-31T01:02:22.559972: step 8582, loss 0.609905.
Train: 2018-07-31T01:02:22.700529: step 8583, loss 0.578924.
Train: 2018-07-31T01:02:22.841123: step 8584, loss 0.555712.
Train: 2018-07-31T01:02:22.981743: step 8585, loss 0.540235.
Train: 2018-07-31T01:02:23.137953: step 8586, loss 0.578922.
Train: 2018-07-31T01:02:23.294164: step 8587, loss 0.532414.
Train: 2018-07-31T01:02:23.434732: step 8588, loss 0.54009.
Train: 2018-07-31T01:02:23.575348: step 8589, loss 0.539987.
Train: 2018-07-31T01:02:23.715940: step 8590, loss 0.586695.
Test: 2018-07-31T01:02:23.965881: step 8590, loss 0.550128.
Train: 2018-07-31T01:02:24.106450: step 8591, loss 0.594531.
Train: 2018-07-31T01:02:24.247066: step 8592, loss 0.508349.
Train: 2018-07-31T01:02:24.403280: step 8593, loss 0.57101.
Train: 2018-07-31T01:02:24.543846: step 8594, loss 0.555222.
Train: 2018-07-31T01:02:24.684438: step 8595, loss 0.634181.
Train: 2018-07-31T01:02:24.825030: step 8596, loss 0.555131.
Train: 2018-07-31T01:02:24.965624: step 8597, loss 0.570941.
Train: 2018-07-31T01:02:25.106215: step 8598, loss 0.602639.
Train: 2018-07-31T01:02:25.262428: step 8599, loss 0.539224.
Train: 2018-07-31T01:02:25.403045: step 8600, loss 0.547126.
Test: 2018-07-31T01:02:25.637374: step 8600, loss 0.549668.
Train: 2018-07-31T01:02:26.387166: step 8601, loss 0.547086.
Train: 2018-07-31T01:02:26.527756: step 8602, loss 0.554989.
Train: 2018-07-31T01:02:26.683996: step 8603, loss 0.546976.
Train: 2018-07-31T01:02:26.824563: step 8604, loss 0.562885.
Train: 2018-07-31T01:02:26.965155: step 8605, loss 0.442788.
Train: 2018-07-31T01:02:27.121369: step 8606, loss 0.5467.
Train: 2018-07-31T01:02:27.261984: step 8607, loss 0.614451.
Train: 2018-07-31T01:02:27.402592: step 8608, loss 0.587008.
Train: 2018-07-31T01:02:27.543145: step 8609, loss 0.546407.
Train: 2018-07-31T01:02:27.699359: step 8610, loss 0.578923.
Test: 2018-07-31T01:02:27.933706: step 8610, loss 0.548945.
Train: 2018-07-31T01:02:28.105513: step 8611, loss 0.521811.
Train: 2018-07-31T01:02:28.246106: step 8612, loss 0.603491.
Train: 2018-07-31T01:02:28.386697: step 8613, loss 0.570763.
Train: 2018-07-31T01:02:28.542935: step 8614, loss 0.628164.
Train: 2018-07-31T01:02:28.683502: step 8615, loss 0.63632.
Train: 2018-07-31T01:02:28.824119: step 8616, loss 0.538067.
Train: 2018-07-31T01:02:28.980308: step 8617, loss 0.538122.
Train: 2018-07-31T01:02:29.120899: step 8618, loss 0.546307.
Train: 2018-07-31T01:02:29.261516: step 8619, loss 0.603385.
Train: 2018-07-31T01:02:29.402108: step 8620, loss 0.570778.
Test: 2018-07-31T01:02:29.652056: step 8620, loss 0.549035.
Train: 2018-07-31T01:02:29.792618: step 8621, loss 0.587044.
Train: 2018-07-31T01:02:29.933235: step 8622, loss 0.578905.
Train: 2018-07-31T01:02:30.073802: step 8623, loss 0.595097.
Train: 2018-07-31T01:02:30.230016: step 8624, loss 0.578888.
Train: 2018-07-31T01:02:30.370606: step 8625, loss 0.530528.
Train: 2018-07-31T01:02:30.511199: step 8626, loss 0.54669.
Train: 2018-07-31T01:02:30.651791: step 8627, loss 0.546717.
Train: 2018-07-31T01:02:30.792383: step 8628, loss 0.546727.
Train: 2018-07-31T01:02:30.948614: step 8629, loss 0.570835.
Train: 2018-07-31T01:02:31.089190: step 8630, loss 0.538685.
Test: 2018-07-31T01:02:31.323510: step 8630, loss 0.549316.
Train: 2018-07-31T01:02:31.464102: step 8631, loss 0.546701.
Train: 2018-07-31T01:02:31.635937: step 8632, loss 0.578876.
Train: 2018-07-31T01:02:31.792150: step 8633, loss 0.546651.
Train: 2018-07-31T01:02:31.948363: step 8634, loss 0.595011.
Train: 2018-07-31T01:02:32.088956: step 8635, loss 0.538547.
Train: 2018-07-31T01:02:32.229548: step 8636, loss 0.554663.
Train: 2018-07-31T01:02:32.370140: step 8637, loss 0.562721.
Train: 2018-07-31T01:02:32.510731: step 8638, loss 0.578894.
Train: 2018-07-31T01:02:32.651324: step 8639, loss 0.530332.
Train: 2018-07-31T01:02:32.791939: step 8640, loss 0.562693.
Test: 2018-07-31T01:02:33.041887: step 8640, loss 0.549086.
Train: 2018-07-31T01:02:33.182492: step 8641, loss 0.530231.
Train: 2018-07-31T01:02:33.323041: step 8642, loss 0.538257.
Train: 2018-07-31T01:02:33.479255: step 8643, loss 0.578931.
Train: 2018-07-31T01:02:33.619871: step 8644, loss 0.513628.
Train: 2018-07-31T01:02:33.760438: step 8645, loss 0.603497.
Train: 2018-07-31T01:02:33.916652: step 8646, loss 0.546158.
Train: 2018-07-31T01:02:34.057244: step 8647, loss 0.595342.
Train: 2018-07-31T01:02:34.197860: step 8648, loss 0.546144.
Train: 2018-07-31T01:02:34.354049: step 8649, loss 0.59543.
Train: 2018-07-31T01:02:34.494641: step 8650, loss 0.611902.
Test: 2018-07-31T01:02:34.728995: step 8650, loss 0.548775.
Train: 2018-07-31T01:02:34.869553: step 8651, loss 0.537923.
Train: 2018-07-31T01:02:35.025792: step 8652, loss 0.570757.
Train: 2018-07-31T01:02:35.182016: step 8653, loss 0.570754.
Train: 2018-07-31T01:02:35.322573: step 8654, loss 0.546163.
Train: 2018-07-31T01:02:35.463192: step 8655, loss 0.496982.
Train: 2018-07-31T01:02:35.619380: step 8656, loss 0.57079.
Train: 2018-07-31T01:02:35.759995: step 8657, loss 0.513269.
Train: 2018-07-31T01:02:35.900586: step 8658, loss 0.570764.
Train: 2018-07-31T01:02:36.041154: step 8659, loss 0.44706.
Train: 2018-07-31T01:02:36.181771: step 8660, loss 0.579093.
Test: 2018-07-31T01:02:36.431717: step 8660, loss 0.548494.
Train: 2018-07-31T01:02:36.572281: step 8661, loss 0.512484.
Train: 2018-07-31T01:02:36.712871: step 8662, loss 0.637608.
Train: 2018-07-31T01:02:36.853482: step 8663, loss 0.545841.
Train: 2018-07-31T01:02:36.994056: step 8664, loss 0.562418.
Train: 2018-07-31T01:02:37.150270: step 8665, loss 0.587682.
Train: 2018-07-31T01:02:37.290886: step 8666, loss 0.596286.
Train: 2018-07-31T01:02:37.431479: step 8667, loss 0.5122.
Train: 2018-07-31T01:02:37.572071: step 8668, loss 0.487105.
Train: 2018-07-31T01:02:37.712662: step 8669, loss 0.587511.
Train: 2018-07-31T01:02:37.868876: step 8670, loss 0.579197.
Test: 2018-07-31T01:02:38.103174: step 8670, loss 0.548341.
Train: 2018-07-31T01:02:38.259386: step 8671, loss 0.587563.
Train: 2018-07-31T01:02:38.415599: step 8672, loss 0.537233.
Train: 2018-07-31T01:02:38.571839: step 8673, loss 0.554004.
Train: 2018-07-31T01:02:38.712428: step 8674, loss 0.52044.
Train: 2018-07-31T01:02:38.868617: step 8675, loss 0.562387.
Train: 2018-07-31T01:02:39.009210: step 8676, loss 0.444718.
Train: 2018-07-31T01:02:39.149826: step 8677, loss 0.579233.
Train: 2018-07-31T01:02:39.290418: step 8678, loss 0.629963.
Train: 2018-07-31T01:02:39.431003: step 8679, loss 0.511643.
Train: 2018-07-31T01:02:39.587201: step 8680, loss 0.613139.
Test: 2018-07-31T01:02:39.821552: step 8680, loss 0.548185.
Train: 2018-07-31T01:02:39.962110: step 8681, loss 0.630054.
Train: 2018-07-31T01:02:40.118326: step 8682, loss 0.537024.
Train: 2018-07-31T01:02:40.258917: step 8683, loss 0.604547.
Train: 2018-07-31T01:02:40.399510: step 8684, loss 0.612877.
Train: 2018-07-31T01:02:40.540126: step 8685, loss 0.52045.
Train: 2018-07-31T01:02:40.696339: step 8686, loss 0.512185.
Train: 2018-07-31T01:02:40.836930: step 8687, loss 0.662751.
Train: 2018-07-31T01:02:40.977498: step 8688, loss 0.570765.
Train: 2018-07-31T01:02:41.133713: step 8689, loss 0.645523.
Train: 2018-07-31T01:02:41.274305: step 8690, loss 0.512894.
Test: 2018-07-31T01:02:41.508656: step 8690, loss 0.548722.
Train: 2018-07-31T01:02:41.664861: step 8691, loss 0.587233.
Train: 2018-07-31T01:02:41.805454: step 8692, loss 0.554345.
Train: 2018-07-31T01:02:41.946046: step 8693, loss 0.554403.
Train: 2018-07-31T01:02:42.102235: step 8694, loss 0.562613.
Train: 2018-07-31T01:02:42.242851: step 8695, loss 0.587059.
Train: 2018-07-31T01:02:42.383420: step 8696, loss 0.59514.
Train: 2018-07-31T01:02:42.539633: step 8697, loss 0.514166.
Train: 2018-07-31T01:02:42.680225: step 8698, loss 0.498117.
Train: 2018-07-31T01:02:42.820841: step 8699, loss 0.554654.
Train: 2018-07-31T01:02:42.977029: step 8700, loss 0.538486.
Test: 2018-07-31T01:02:43.211379: step 8700, loss 0.54917.
Train: 2018-07-31T01:02:43.992416: step 8701, loss 0.530366.
Train: 2018-07-31T01:02:44.133034: step 8702, loss 0.554605.
Train: 2018-07-31T01:02:44.289247: step 8703, loss 0.595136.
Train: 2018-07-31T01:02:44.429832: step 8704, loss 0.538294.
Train: 2018-07-31T01:02:44.570431: step 8705, loss 0.546372.
Train: 2018-07-31T01:02:44.710998: step 8706, loss 0.570763.
Train: 2018-07-31T01:02:44.851616: step 8707, loss 0.611547.
Train: 2018-07-31T01:02:45.007805: step 8708, loss 0.562656.
Train: 2018-07-31T01:02:45.148397: step 8709, loss 0.562633.
Train: 2018-07-31T01:02:45.289013: step 8710, loss 0.587141.
Test: 2018-07-31T01:02:45.538931: step 8710, loss 0.548979.
Train: 2018-07-31T01:02:45.679540: step 8711, loss 0.578946.
Train: 2018-07-31T01:02:45.820115: step 8712, loss 0.530087.
Train: 2018-07-31T01:02:45.960708: step 8713, loss 0.578918.
Train: 2018-07-31T01:02:46.101326: step 8714, loss 0.619586.
Train: 2018-07-31T01:02:46.241891: step 8715, loss 0.554548.
Train: 2018-07-31T01:02:46.398103: step 8716, loss 0.505922.
Train: 2018-07-31T01:02:46.538697: step 8717, loss 0.546461.
Train: 2018-07-31T01:02:46.679313: step 8718, loss 0.55456.
Train: 2018-07-31T01:02:46.835526: step 8719, loss 0.481459.
Train: 2018-07-31T01:02:46.976095: step 8720, loss 0.627772.
Test: 2018-07-31T01:02:47.210415: step 8720, loss 0.548983.
Train: 2018-07-31T01:02:47.366652: step 8721, loss 0.54633.
Train: 2018-07-31T01:02:47.522842: step 8722, loss 0.562615.
Train: 2018-07-31T01:02:47.663433: step 8723, loss 0.554439.
Train: 2018-07-31T01:02:47.804043: step 8724, loss 0.562593.
Train: 2018-07-31T01:02:47.944641: step 8725, loss 0.562583.
Train: 2018-07-31T01:02:48.085233: step 8726, loss 0.538006.
Train: 2018-07-31T01:02:48.241447: step 8727, loss 0.521559.
Train: 2018-07-31T01:02:48.382014: step 8728, loss 0.578977.
Train: 2018-07-31T01:02:48.522606: step 8729, loss 0.537838.
Train: 2018-07-31T01:02:48.663199: step 8730, loss 0.546021.
Test: 2018-07-31T01:02:48.897549: step 8730, loss 0.548744.
Train: 2018-07-31T01:02:49.053731: step 8731, loss 0.529447.
Train: 2018-07-31T01:02:49.209946: step 8732, loss 0.537628.
Train: 2018-07-31T01:02:49.350537: step 8733, loss 0.579064.
Train: 2018-07-31T01:02:49.506751: step 8734, loss 0.604047.
Train: 2018-07-31T01:02:49.647344: step 8735, loss 0.512472.
Train: 2018-07-31T01:02:49.787960: step 8736, loss 0.537401.
Train: 2018-07-31T01:02:49.928544: step 8737, loss 0.554056.
Train: 2018-07-31T01:02:50.084741: step 8738, loss 0.595894.
Train: 2018-07-31T01:02:50.225333: step 8739, loss 0.629432.
Train: 2018-07-31T01:02:50.365925: step 8740, loss 0.612629.
Test: 2018-07-31T01:02:50.600270: step 8740, loss 0.548419.
Train: 2018-07-31T01:02:50.756457: step 8741, loss 0.579123.
Train: 2018-07-31T01:02:50.912672: step 8742, loss 0.512437.
Train: 2018-07-31T01:02:51.068887: step 8743, loss 0.545795.
Train: 2018-07-31T01:02:51.209478: step 8744, loss 0.545813.
Train: 2018-07-31T01:02:51.350070: step 8745, loss 0.579073.
Train: 2018-07-31T01:02:51.490662: step 8746, loss 0.520929.
Train: 2018-07-31T01:02:51.631255: step 8747, loss 0.603985.
Train: 2018-07-31T01:02:51.787491: step 8748, loss 0.537566.
Train: 2018-07-31T01:02:51.943681: step 8749, loss 0.545874.
Train: 2018-07-31T01:02:52.084271: step 8750, loss 0.562463.
Test: 2018-07-31T01:02:52.334245: step 8750, loss 0.548577.
Train: 2018-07-31T01:02:52.474831: step 8751, loss 0.579053.
Train: 2018-07-31T01:02:52.631020: step 8752, loss 0.587333.
Train: 2018-07-31T01:02:52.771612: step 8753, loss 0.52937.
Train: 2018-07-31T01:02:52.912208: step 8754, loss 0.612127.
Train: 2018-07-31T01:02:53.052795: step 8755, loss 0.612061.
Train: 2018-07-31T01:02:53.209009: step 8756, loss 0.554279.
Train: 2018-07-31T01:02:53.349625: step 8757, loss 0.546098.
Train: 2018-07-31T01:02:53.490211: step 8758, loss 0.545047.
Train: 2018-07-31T01:02:53.646431: step 8759, loss 0.562566.
Train: 2018-07-31T01:02:53.786998: step 8760, loss 0.546199.
Test: 2018-07-31T01:02:54.036941: step 8760, loss 0.548878.
Train: 2018-07-31T01:02:54.177532: step 8761, loss 0.570765.
Train: 2018-07-31T01:02:54.318124: step 8762, loss 0.546235.
Train: 2018-07-31T01:02:54.458716: step 8763, loss 0.546243.
Train: 2018-07-31T01:02:54.599308: step 8764, loss 0.595295.
Train: 2018-07-31T01:02:54.739900: step 8765, loss 0.562599.
Train: 2018-07-31T01:02:54.880511: step 8766, loss 0.554441.
Train: 2018-07-31T01:02:55.036730: step 8767, loss 0.603419.
Train: 2018-07-31T01:02:55.192920: step 8768, loss 0.554473.
Train: 2018-07-31T01:02:55.333536: step 8769, loss 0.562635.
Train: 2018-07-31T01:02:55.505346: step 8770, loss 0.603323.
Test: 2018-07-31T01:02:55.739668: step 8770, loss 0.549065.
Train: 2018-07-31T01:02:55.880258: step 8771, loss 0.587029.
Train: 2018-07-31T01:02:56.036499: step 8772, loss 0.635623.
Train: 2018-07-31T01:02:56.177106: step 8773, loss 0.65962.
Train: 2018-07-31T01:02:56.333279: step 8774, loss 0.610981.
Train: 2018-07-31T01:02:56.473870: step 8775, loss 0.53897.
Train: 2018-07-31T01:02:56.614486: step 8776, loss 0.515347.
Train: 2018-07-31T01:02:56.770675: step 8777, loss 0.499716.
Train: 2018-07-31T01:02:56.911268: step 8778, loss 0.539329.
Train: 2018-07-31T01:02:57.051860: step 8779, loss 0.531431.
Train: 2018-07-31T01:02:57.192452: step 8780, loss 0.62633.
Test: 2018-07-31T01:02:57.426804: step 8780, loss 0.549808.
Train: 2018-07-31T01:02:57.582985: step 8781, loss 0.610486.
Train: 2018-07-31T01:02:57.723578: step 8782, loss 0.539398.
Train: 2018-07-31T01:02:57.864169: step 8783, loss 0.539427.
Train: 2018-07-31T01:02:58.004762: step 8784, loss 0.641971.
Train: 2018-07-31T01:02:58.145378: step 8785, loss 0.547367.
Train: 2018-07-31T01:02:58.285971: step 8786, loss 0.586735.
Train: 2018-07-31T01:02:58.426550: step 8787, loss 0.563156.
Train: 2018-07-31T01:02:58.567129: step 8788, loss 0.625973.
Train: 2018-07-31T01:02:58.723343: step 8789, loss 0.578879.
Train: 2018-07-31T01:02:58.895203: step 8790, loss 0.5867.
Test: 2018-07-31T01:02:59.129528: step 8790, loss 0.550245.
Train: 2018-07-31T01:02:59.301332: step 8791, loss 0.563302.
Train: 2018-07-31T01:02:59.441925: step 8792, loss 0.539996.
Train: 2018-07-31T01:02:59.582518: step 8793, loss 0.578905.
Train: 2018-07-31T01:02:59.723109: step 8794, loss 0.51677.
Train: 2018-07-31T01:02:59.863700: step 8795, loss 0.602224.
Train: 2018-07-31T01:03:00.019914: step 8796, loss 0.586678.
Train: 2018-07-31T01:03:00.160506: step 8797, loss 0.509003.
Train: 2018-07-31T01:03:00.301099: step 8798, loss 0.547795.
Train: 2018-07-31T01:03:00.441715: step 8799, loss 0.555523.
Train: 2018-07-31T01:03:00.597903: step 8800, loss 0.524239.
Test: 2018-07-31T01:03:00.832225: step 8800, loss 0.5501.
Train: 2018-07-31T01:03:01.613291: step 8801, loss 0.508397.
Train: 2018-07-31T01:03:01.769529: step 8802, loss 0.51594.
Train: 2018-07-31T01:03:01.910122: step 8803, loss 0.610494.
Train: 2018-07-31T01:03:02.050689: step 8804, loss 0.515353.
Train: 2018-07-31T01:03:02.191293: step 8805, loss 0.594811.
Train: 2018-07-31T01:03:02.331897: step 8806, loss 0.530839.
Train: 2018-07-31T01:03:02.488086: step 8807, loss 0.514578.
Train: 2018-07-31T01:03:02.628677: step 8808, loss 0.54658.
Train: 2018-07-31T01:03:02.769294: step 8809, loss 0.562673.
Train: 2018-07-31T01:03:02.925508: step 8810, loss 0.513718.
Test: 2018-07-31T01:03:03.175456: step 8810, loss 0.548849.
Train: 2018-07-31T01:03:03.316042: step 8811, loss 0.497027.
Train: 2018-07-31T01:03:03.456634: step 8812, loss 0.603742.
Train: 2018-07-31T01:03:03.597200: step 8813, loss 0.554187.
Train: 2018-07-31T01:03:03.737793: step 8814, loss 0.570744.
Train: 2018-07-31T01:03:03.878385: step 8815, loss 0.545753.
Train: 2018-07-31T01:03:04.019003: step 8816, loss 0.579123.
Train: 2018-07-31T01:03:04.159609: step 8817, loss 0.545643.
Train: 2018-07-31T01:03:04.300187: step 8818, loss 0.570768.
Train: 2018-07-31T01:03:04.456376: step 8819, loss 0.528624.
Train: 2018-07-31T01:03:04.596968: step 8820, loss 0.520099.
Test: 2018-07-31T01:03:04.831317: step 8820, loss 0.548159.
Train: 2018-07-31T01:03:04.971904: step 8821, loss 0.613211.
Train: 2018-07-31T01:03:05.128118: step 8822, loss 0.54532.
Train: 2018-07-31T01:03:05.284331: step 8823, loss 0.604696.
Train: 2018-07-31T01:03:05.424906: step 8824, loss 0.511322.
Train: 2018-07-31T01:03:05.581124: step 8825, loss 0.68146.
Train: 2018-07-31T01:03:05.721728: step 8826, loss 0.579402.
Train: 2018-07-31T01:03:05.862296: step 8827, loss 0.443608.
Train: 2018-07-31T01:03:06.018534: step 8828, loss 0.60505.
Train: 2018-07-31T01:03:06.159101: step 8829, loss 0.469037.
Train: 2018-07-31T01:03:06.299693: step 8830, loss 0.57924.
Test: 2018-07-31T01:03:06.534013: step 8830, loss 0.548112.
Train: 2018-07-31T01:03:06.690227: step 8831, loss 0.545105.
Train: 2018-07-31T01:03:06.830847: step 8832, loss 0.596502.
Train: 2018-07-31T01:03:06.971411: step 8833, loss 0.536626.
Train: 2018-07-31T01:03:07.112002: step 8834, loss 0.53664.
Train: 2018-07-31T01:03:07.268218: step 8835, loss 0.545779.
Train: 2018-07-31T01:03:07.408809: step 8836, loss 0.579183.
Train: 2018-07-31T01:03:07.549425: step 8837, loss 0.502906.
Train: 2018-07-31T01:03:07.689992: step 8838, loss 0.647814.
Train: 2018-07-31T01:03:07.846206: step 8839, loss 0.519798.
Train: 2018-07-31T01:03:08.002420: step 8840, loss 0.604442.
Test: 2018-07-31T01:03:08.236741: step 8840, loss 0.548125.
Train: 2018-07-31T01:03:08.377357: step 8841, loss 0.519767.
Train: 2018-07-31T01:03:08.517956: step 8842, loss 0.638688.
Train: 2018-07-31T01:03:08.658551: step 8843, loss 0.553745.
Train: 2018-07-31T01:03:08.814729: step 8844, loss 0.570461.
Train: 2018-07-31T01:03:08.986566: step 8845, loss 0.570748.
Train: 2018-07-31T01:03:09.127158: step 8846, loss 0.604805.
Train: 2018-07-31T01:03:09.267748: step 8847, loss 0.487484.
Train: 2018-07-31T01:03:09.408340: step 8848, loss 0.528924.
Train: 2018-07-31T01:03:09.548957: step 8849, loss 0.612133.
Train: 2018-07-31T01:03:09.689549: step 8850, loss 0.512642.
Test: 2018-07-31T01:03:09.939466: step 8850, loss 0.54855.
Train: 2018-07-31T01:03:10.080083: step 8851, loss 0.57889.
Train: 2018-07-31T01:03:10.236272: step 8852, loss 0.537694.
Train: 2018-07-31T01:03:10.361243: step 8853, loss 0.504594.
Train: 2018-07-31T01:03:10.533078: step 8854, loss 0.570708.
Train: 2018-07-31T01:03:10.673686: step 8855, loss 0.546081.
Train: 2018-07-31T01:03:10.814260: step 8856, loss 0.58751.
Train: 2018-07-31T01:03:10.970475: step 8857, loss 0.570888.
Train: 2018-07-31T01:03:11.126712: step 8858, loss 0.521108.
Train: 2018-07-31T01:03:11.267279: step 8859, loss 0.54585.
Train: 2018-07-31T01:03:11.407897: step 8860, loss 0.628814.
Test: 2018-07-31T01:03:11.642193: step 8860, loss 0.548584.
Train: 2018-07-31T01:03:11.798407: step 8861, loss 0.562433.
Train: 2018-07-31T01:03:11.938997: step 8862, loss 0.670113.
Train: 2018-07-31T01:03:12.095212: step 8863, loss 0.603709.
Train: 2018-07-31T01:03:12.235829: step 8864, loss 0.513255.
Train: 2018-07-31T01:03:12.376397: step 8865, loss 0.529809.
Train: 2018-07-31T01:03:12.548266: step 8866, loss 0.587123.
Train: 2018-07-31T01:03:12.688822: step 8867, loss 0.513638.
Train: 2018-07-31T01:03:12.829439: step 8868, loss 0.513678.
Train: 2018-07-31T01:03:12.970031: step 8869, loss 0.570772.
Train: 2018-07-31T01:03:13.126221: step 8870, loss 0.489132.
Test: 2018-07-31T01:03:13.360571: step 8870, loss 0.548886.
Train: 2018-07-31T01:03:13.501132: step 8871, loss 0.513504.
Train: 2018-07-31T01:03:13.657371: step 8872, loss 0.58717.
Train: 2018-07-31T01:03:13.797944: step 8873, loss 0.546095.
Train: 2018-07-31T01:03:13.938530: step 8874, loss 0.603713.
Train: 2018-07-31T01:03:14.079121: step 8875, loss 0.58725.
Train: 2018-07-31T01:03:14.219713: step 8876, loss 0.537762.
Train: 2018-07-31T01:03:14.360306: step 8877, loss 0.587265.
Train: 2018-07-31T01:03:14.500898: step 8878, loss 0.562502.
Train: 2018-07-31T01:03:14.641516: step 8879, loss 0.603772.
Train: 2018-07-31T01:03:14.797705: step 8880, loss 0.529531.
Test: 2018-07-31T01:03:15.032025: step 8880, loss 0.548709.
Train: 2018-07-31T01:03:15.188261: step 8881, loss 0.579.
Train: 2018-07-31T01:03:15.328829: step 8882, loss 0.546045.
Train: 2018-07-31T01:03:15.485079: step 8883, loss 0.554287.
Train: 2018-07-31T01:03:15.625636: step 8884, loss 0.504884.
Train: 2018-07-31T01:03:15.766251: step 8885, loss 0.529537.
Train: 2018-07-31T01:03:15.938063: step 8886, loss 0.603791.
Train: 2018-07-31T01:03:16.078655: step 8887, loss 0.57902.
Train: 2018-07-31T01:03:16.219247: step 8888, loss 0.529436.
Train: 2018-07-31T01:03:16.359837: step 8889, loss 0.587297.
Train: 2018-07-31T01:03:16.500431: step 8890, loss 0.512863.
Test: 2018-07-31T01:03:16.734749: step 8890, loss 0.548626.
Train: 2018-07-31T01:03:16.890981: step 8891, loss 0.48796.
Train: 2018-07-31T01:03:17.031555: step 8892, loss 0.587362.
Train: 2018-07-31T01:03:17.172147: step 8893, loss 0.545815.
Train: 2018-07-31T01:03:17.312763: step 8894, loss 0.612416.
Train: 2018-07-31T01:03:17.453331: step 8895, loss 0.587432.
Train: 2018-07-31T01:03:17.609546: step 8896, loss 0.645739.
Train: 2018-07-31T01:03:17.750162: step 8897, loss 0.545826.
Train: 2018-07-31T01:03:17.890757: step 8898, loss 0.554166.
Train: 2018-07-31T01:03:18.031340: step 8899, loss 0.579041.
Train: 2018-07-31T01:03:18.187534: step 8900, loss 0.545951.
Test: 2018-07-31T01:03:18.421854: step 8900, loss 0.54867.
Train: 2018-07-31T01:03:19.156059: step 8901, loss 0.636814.
Train: 2018-07-31T01:03:19.296675: step 8902, loss 0.570757.
Train: 2018-07-31T01:03:19.437267: step 8903, loss 0.537928.
Train: 2018-07-31T01:03:19.593456: step 8904, loss 0.554382.
Train: 2018-07-31T01:03:19.734073: step 8905, loss 0.668884.
Train: 2018-07-31T01:03:19.890262: step 8906, loss 0.513777.
Train: 2018-07-31T01:03:20.015232: step 8907, loss 0.546419.
Train: 2018-07-31T01:03:20.155823: step 8908, loss 0.538364.
Train: 2018-07-31T01:03:20.296416: step 8909, loss 0.528145.
Train: 2018-07-31T01:03:20.437033: step 8910, loss 0.578896.
Test: 2018-07-31T01:03:20.671328: step 8910, loss 0.54915.
Train: 2018-07-31T01:03:20.858783: step 8911, loss 0.5708.
Train: 2018-07-31T01:03:21.030654: step 8912, loss 0.603161.
Train: 2018-07-31T01:03:21.171212: step 8913, loss 0.562731.
Train: 2018-07-31T01:03:21.311828: step 8914, loss 0.530475.
Train: 2018-07-31T01:03:21.452419: step 8915, loss 0.595013.
Train: 2018-07-31T01:03:21.593012: step 8916, loss 0.546648.
Train: 2018-07-31T01:03:21.749201: step 8917, loss 0.530552.
Train: 2018-07-31T01:03:21.889818: step 8918, loss 0.594995.
Train: 2018-07-31T01:03:22.030386: step 8919, loss 0.570823.
Train: 2018-07-31T01:03:22.171003: step 8920, loss 0.627191.
Test: 2018-07-31T01:03:22.405329: step 8920, loss 0.549337.
Train: 2018-07-31T01:03:22.561511: step 8921, loss 0.55476.
Train: 2018-07-31T01:03:22.702103: step 8922, loss 0.586895.
Train: 2018-07-31T01:03:22.842694: step 8923, loss 0.610912.
Train: 2018-07-31T01:03:22.983287: step 8924, loss 0.578862.
Train: 2018-07-31T01:03:23.123878: step 8925, loss 0.586828.
Train: 2018-07-31T01:03:23.264470: step 8926, loss 0.515299.
Train: 2018-07-31T01:03:23.405090: step 8927, loss 0.578859.
Train: 2018-07-31T01:03:23.545677: step 8928, loss 0.602629.
Train: 2018-07-31T01:03:23.701892: step 8929, loss 0.586767.
Train: 2018-07-31T01:03:23.842486: step 8930, loss 0.515763.
Test: 2018-07-31T01:03:24.076781: step 8930, loss 0.549901.
Train: 2018-07-31T01:03:24.217372: step 8931, loss 0.626155.
Train: 2018-07-31T01:03:24.357965: step 8932, loss 0.555273.
Train: 2018-07-31T01:03:24.498556: step 8933, loss 0.516044.
Train: 2018-07-31T01:03:24.639149: step 8934, loss 0.55531.
Train: 2018-07-31T01:03:24.795387: step 8935, loss 0.578871.
Train: 2018-07-31T01:03:24.935954: step 8936, loss 0.555292.
Train: 2018-07-31T01:03:25.076545: step 8937, loss 0.594597.
Train: 2018-07-31T01:03:25.217138: step 8938, loss 0.539553.
Train: 2018-07-31T01:03:25.357730: step 8939, loss 0.539523.
Train: 2018-07-31T01:03:25.513944: step 8940, loss 0.626147.
Test: 2018-07-31T01:03:25.748294: step 8940, loss 0.54991.
Train: 2018-07-31T01:03:25.904502: step 8941, loss 0.531589.
Train: 2018-07-31T01:03:26.060716: step 8942, loss 0.58675.
Train: 2018-07-31T01:03:26.201283: step 8943, loss 0.578863.
Train: 2018-07-31T01:03:26.341900: step 8944, loss 0.539413.
Train: 2018-07-31T01:03:26.498120: step 8945, loss 0.594656.
Train: 2018-07-31T01:03:26.638682: step 8946, loss 0.610455.
Train: 2018-07-31T01:03:26.779273: step 8947, loss 0.61832.
Train: 2018-07-31T01:03:26.904269: step 8948, loss 0.578866.
Train: 2018-07-31T01:03:27.044860: step 8949, loss 0.563152.
Train: 2018-07-31T01:03:27.201049: step 8950, loss 0.578874.
Test: 2018-07-31T01:03:27.435402: step 8950, loss 0.550094.
Train: 2018-07-31T01:03:27.575960: step 8951, loss 0.618044.
Train: 2018-07-31T01:03:27.716584: step 8952, loss 0.578887.
Train: 2018-07-31T01:03:27.872767: step 8953, loss 0.578896.
Train: 2018-07-31T01:03:28.013375: step 8954, loss 0.586678.
Train: 2018-07-31T01:03:28.153975: step 8955, loss 0.609923.
Train: 2018-07-31T01:03:28.294542: step 8956, loss 0.532584.
Train: 2018-07-31T01:03:28.450780: step 8957, loss 0.563525.
Train: 2018-07-31T01:03:28.591373: step 8958, loss 0.525055.
Train: 2018-07-31T01:03:28.731965: step 8959, loss 0.578954.
Train: 2018-07-31T01:03:28.872556: step 8960, loss 0.501949.
Test: 2018-07-31T01:03:29.122475: step 8960, loss 0.55059.
Train: 2018-07-31T01:03:29.263067: step 8961, loss 0.501788.
Train: 2018-07-31T01:03:29.403658: step 8962, loss 0.571179.
Train: 2018-07-31T01:03:29.544252: step 8963, loss 0.547826.
Train: 2018-07-31T01:03:29.700488: step 8964, loss 0.578892.
Train: 2018-07-31T01:03:29.841055: step 8965, loss 0.594529.
Train: 2018-07-31T01:03:29.981649: step 8966, loss 0.523986.
Train: 2018-07-31T01:03:30.122258: step 8967, loss 0.531667.
Train: 2018-07-31T01:03:30.262833: step 8968, loss 0.547272.
Train: 2018-07-31T01:03:30.403442: step 8969, loss 0.586789.
Train: 2018-07-31T01:03:30.559638: step 8970, loss 0.602724.
Test: 2018-07-31T01:03:30.793989: step 8970, loss 0.549567.
Train: 2018-07-31T01:03:30.950172: step 8971, loss 0.618716.
Train: 2018-07-31T01:03:31.090780: step 8972, loss 0.554933.
Train: 2018-07-31T01:03:31.231355: step 8973, loss 0.546933.
Train: 2018-07-31T01:03:31.371947: step 8974, loss 0.594846.
Train: 2018-07-31T01:03:31.528162: step 8975, loss 0.610843.
Train: 2018-07-31T01:03:31.684375: step 8976, loss 0.554893.
Train: 2018-07-31T01:03:31.824968: step 8977, loss 0.554901.
Train: 2018-07-31T01:03:31.981181: step 8978, loss 0.483018.
Train: 2018-07-31T01:03:32.137428: step 8979, loss 0.546849.
Train: 2018-07-31T01:03:32.278009: step 8980, loss 0.594914.
Test: 2018-07-31T01:03:32.512337: step 8980, loss 0.549346.
Train: 2018-07-31T01:03:32.668518: step 8981, loss 0.562802.
Train: 2018-07-31T01:03:32.809112: step 8982, loss 0.554738.
Train: 2018-07-31T01:03:32.949727: step 8983, loss 0.546648.
Train: 2018-07-31T01:03:33.090303: step 8984, loss 0.578884.
Train: 2018-07-31T01:03:33.230888: step 8985, loss 0.538476.
Train: 2018-07-31T01:03:33.371503: step 8986, loss 0.562701.
Train: 2018-07-31T01:03:33.527717: step 8987, loss 0.522129.
Train: 2018-07-31T01:03:33.683931: step 8988, loss 0.578914.
Train: 2018-07-31T01:03:33.824498: step 8989, loss 0.554485.
Train: 2018-07-31T01:03:33.965091: step 8990, loss 0.636061.
Test: 2018-07-31T01:03:34.215031: step 8990, loss 0.548945.
Train: 2018-07-31T01:03:34.355624: step 8991, loss 0.513649.
Train: 2018-07-31T01:03:34.496240: step 8992, loss 0.513583.
Train: 2018-07-31T01:03:34.652429: step 8993, loss 0.546204.
Train: 2018-07-31T01:03:34.793021: step 8994, loss 0.587172.
Train: 2018-07-31T01:03:34.933637: step 8995, loss 0.546106.
Train: 2018-07-31T01:03:35.089851: step 8996, loss 0.644837.
Train: 2018-07-31T01:03:35.230419: step 8997, loss 0.620119.
Train: 2018-07-31T01:03:35.371029: step 8998, loss 0.554337.
Train: 2018-07-31T01:03:35.527249: step 8999, loss 0.578961.
Train: 2018-07-31T01:03:35.667815: step 9000, loss 0.546212.
Test: 2018-07-31T01:03:35.917766: step 9000, loss 0.548903.
Train: 2018-07-31T01:03:36.667583: step 9001, loss 0.562593.
Train: 2018-07-31T01:03:36.823796: step 9002, loss 0.505449.
Train: 2018-07-31T01:03:36.980010: step 9003, loss 0.578938.
Train: 2018-07-31T01:03:37.120601: step 9004, loss 0.587105.
Train: 2018-07-31T01:03:37.261210: step 9005, loss 0.603419.
Train: 2018-07-31T01:03:37.401810: step 9006, loss 0.538181.
Train: 2018-07-31T01:03:37.542401: step 9007, loss 0.570779.
Train: 2018-07-31T01:03:37.698592: step 9008, loss 0.578915.
Train: 2018-07-31T01:03:37.854805: step 9009, loss 0.505794.
Train: 2018-07-31T01:03:37.995396: step 9010, loss 0.60329.
Test: 2018-07-31T01:03:38.229716: step 9010, loss 0.549067.
Train: 2018-07-31T01:03:38.370310: step 9011, loss 0.562667.
Train: 2018-07-31T01:03:38.526522: step 9012, loss 0.595136.
Train: 2018-07-31T01:03:38.667115: step 9013, loss 0.54648.
Train: 2018-07-31T01:03:38.807705: step 9014, loss 0.570798.
Train: 2018-07-31T01:03:38.948297: step 9015, loss 0.586985.
Train: 2018-07-31T01:03:39.088891: step 9016, loss 0.554645.
Train: 2018-07-31T01:03:39.229482: step 9017, loss 0.546591.
Train: 2018-07-31T01:03:39.385733: step 9018, loss 0.586954.
Train: 2018-07-31T01:03:39.510667: step 9019, loss 0.578881.
Train: 2018-07-31T01:03:39.666880: step 9020, loss 0.538609.
Test: 2018-07-31T01:03:39.916822: step 9020, loss 0.549292.
Train: 2018-07-31T01:03:40.073059: step 9021, loss 0.61913.
Train: 2018-07-31T01:03:40.213626: step 9022, loss 0.58691.
Train: 2018-07-31T01:03:40.354243: step 9023, loss 0.522719.
Train: 2018-07-31T01:03:40.494810: step 9024, loss 0.522758.
Train: 2018-07-31T01:03:40.651024: step 9025, loss 0.506697.
Train: 2018-07-31T01:03:40.791615: step 9026, loss 0.522634.
Train: 2018-07-31T01:03:40.932208: step 9027, loss 0.506374.
Train: 2018-07-31T01:03:41.072800: step 9028, loss 0.54654.
Train: 2018-07-31T01:03:41.213392: step 9029, loss 0.546429.
Train: 2018-07-31T01:03:41.354010: step 9030, loss 0.472952.
Test: 2018-07-31T01:03:41.603957: step 9030, loss 0.548834.
Train: 2018-07-31T01:03:41.744518: step 9031, loss 0.562564.
Train: 2018-07-31T01:03:41.885135: step 9032, loss 0.480117.
Train: 2018-07-31T01:03:42.041360: step 9033, loss 0.554172.
Train: 2018-07-31T01:03:42.181940: step 9034, loss 0.537401.
Train: 2018-07-31T01:03:42.322532: step 9035, loss 0.545616.
Train: 2018-07-31T01:03:42.478721: step 9036, loss 0.537069.
Train: 2018-07-31T01:03:42.634936: step 9037, loss 0.562352.
Train: 2018-07-31T01:03:42.775526: step 9038, loss 0.562342.
Train: 2018-07-31T01:03:42.900522: step 9039, loss 0.48542.
Train: 2018-07-31T01:03:43.056712: step 9040, loss 0.510811.
Test: 2018-07-31T01:03:43.291061: step 9040, loss 0.547883.
Train: 2018-07-31T01:03:43.431648: step 9041, loss 0.519181.
Train: 2018-07-31T01:03:43.587838: step 9042, loss 0.571025.
Train: 2018-07-31T01:03:43.728429: step 9043, loss 0.492655.
Train: 2018-07-31T01:03:43.869045: step 9044, loss 0.676207.
Train: 2018-07-31T01:03:44.025234: step 9045, loss 0.579929.
Train: 2018-07-31T01:03:44.165851: step 9046, loss 0.544839.
Train: 2018-07-31T01:03:44.322040: step 9047, loss 0.615093.
Train: 2018-07-31T01:03:44.462633: step 9048, loss 0.615044.
Train: 2018-07-31T01:03:44.603225: step 9049, loss 0.553625.
Train: 2018-07-31T01:03:44.743816: step 9050, loss 0.536161.
Test: 2018-07-31T01:03:44.978136: step 9050, loss 0.547758.
Train: 2018-07-31T01:03:45.134350: step 9051, loss 0.553643.
Train: 2018-07-31T01:03:45.274966: step 9052, loss 0.553652.
Train: 2018-07-31T01:03:45.415535: step 9053, loss 0.527589.
Train: 2018-07-31T01:03:45.556124: step 9054, loss 0.597074.
Train: 2018-07-31T01:03:45.696718: step 9055, loss 0.553682.
Train: 2018-07-31T01:03:45.837338: step 9056, loss 0.484529.
Train: 2018-07-31T01:03:45.977926: step 9057, loss 0.545056.
Train: 2018-07-31T01:03:46.134116: step 9058, loss 0.545061.
Train: 2018-07-31T01:03:46.274707: step 9059, loss 0.510516.
Train: 2018-07-31T01:03:46.415299: step 9060, loss 0.507027.
Test: 2018-07-31T01:03:46.665242: step 9060, loss 0.547848.
Train: 2018-07-31T01:03:46.805833: step 9061, loss 0.536378.
Train: 2018-07-31T01:03:46.962048: step 9062, loss 0.579683.
Train: 2018-07-31T01:03:47.102663: step 9063, loss 0.536324.
Train: 2018-07-31T01:03:47.243231: step 9064, loss 0.527621.
Train: 2018-07-31T01:03:47.383821: step 9065, loss 0.544968.
Train: 2018-07-31T01:03:47.540061: step 9066, loss 0.544951.
Train: 2018-07-31T01:03:47.680628: step 9067, loss 0.518801.
Train: 2018-07-31T01:03:47.836842: step 9068, loss 0.492563.
Train: 2018-07-31T01:03:47.977433: step 9069, loss 0.527388.
Train: 2018-07-31T01:03:48.133648: step 9070, loss 0.597469.
Test: 2018-07-31T01:03:48.367967: step 9070, loss 0.547689.
Train: 2018-07-31T01:03:48.524182: step 9071, loss 0.553614.
Train: 2018-07-31T01:03:48.664798: step 9072, loss 0.588768.
Train: 2018-07-31T01:03:48.805365: step 9073, loss 0.571189.
Train: 2018-07-31T01:03:48.945983: step 9074, loss 0.606313.
Train: 2018-07-31T01:03:49.086549: step 9075, loss 0.501017.
Train: 2018-07-31T01:03:49.242763: step 9076, loss 0.518581.
Train: 2018-07-31T01:03:49.383356: step 9077, loss 0.509826.
Train: 2018-07-31T01:03:49.523971: step 9078, loss 0.60621.
Train: 2018-07-31T01:03:49.664563: step 9079, loss 0.562382.
Train: 2018-07-31T01:03:49.820777: step 9080, loss 0.518629.
Test: 2018-07-31T01:03:50.070721: step 9080, loss 0.547727.
Train: 2018-07-31T01:03:50.211285: step 9081, loss 0.553629.
Train: 2018-07-31T01:03:50.351878: step 9082, loss 0.527404.
Train: 2018-07-31T01:03:50.492469: step 9083, loss 0.63231.
Train: 2018-07-31T01:03:50.633087: step 9084, loss 0.640897.
Train: 2018-07-31T01:03:50.773680: step 9085, loss 0.649291.
Train: 2018-07-31T01:03:50.914270: step 9086, loss 0.562341.
Train: 2018-07-31T01:03:51.054839: step 9087, loss 0.502128.
Train: 2018-07-31T01:03:51.206440: step 9088, loss 0.528059.
Train: 2018-07-31T01:03:51.347032: step 9089, loss 0.553793.
Train: 2018-07-31T01:03:51.487648: step 9090, loss 0.562341.
Test: 2018-07-31T01:03:51.737567: step 9090, loss 0.548111.
Train: 2018-07-31T01:03:51.878159: step 9091, loss 0.613345.
Train: 2018-07-31T01:03:52.018749: step 9092, loss 0.613166.
Train: 2018-07-31T01:03:52.159342: step 9093, loss 0.562371.
Train: 2018-07-31T01:03:52.315557: step 9094, loss 0.537215.
Train: 2018-07-31T01:03:52.456148: step 9095, loss 0.604222.
Train: 2018-07-31T01:03:52.596741: step 9096, loss 0.545783.
Train: 2018-07-31T01:03:52.737333: step 9097, loss 0.587352.
Train: 2018-07-31T01:03:52.893546: step 9098, loss 0.562492.
Train: 2018-07-31T01:03:53.034161: step 9099, loss 0.546054.
Train: 2018-07-31T01:03:53.174728: step 9100, loss 0.529709.
Test: 2018-07-31T01:03:53.424701: step 9100, loss 0.548846.
Train: 2018-07-31T01:03:54.143278: step 9101, loss 0.603541.
Train: 2018-07-31T01:03:54.299465: step 9102, loss 0.562596.
Train: 2018-07-31T01:03:54.440085: step 9103, loss 0.578927.
Train: 2018-07-31T01:03:54.596296: step 9104, loss 0.63583.
Train: 2018-07-31T01:03:54.736862: step 9105, loss 0.570798.
Train: 2018-07-31T01:03:54.877455: step 9106, loss 0.56275.
Train: 2018-07-31T01:03:55.033669: step 9107, loss 0.554757.
Train: 2018-07-31T01:03:55.174262: step 9108, loss 0.594897.
Train: 2018-07-31T01:03:55.314855: step 9109, loss 0.554894.
Train: 2018-07-31T01:03:55.455446: step 9110, loss 0.546986.
Test: 2018-07-31T01:03:55.689773: step 9110, loss 0.549632.
Train: 2018-07-31T01:03:55.830381: step 9111, loss 0.547045.
Train: 2018-07-31T01:03:55.970949: step 9112, loss 0.602692.
Train: 2018-07-31T01:03:56.127164: step 9113, loss 0.57093.
Train: 2018-07-31T01:03:56.267755: step 9114, loss 0.57886.
Train: 2018-07-31T01:03:56.408359: step 9115, loss 0.531456.
Train: 2018-07-31T01:03:56.548938: step 9116, loss 0.594654.
Train: 2018-07-31T01:03:56.689532: step 9117, loss 0.58675.
Train: 2018-07-31T01:03:56.845769: step 9118, loss 0.563119.
Train: 2018-07-31T01:03:56.986336: step 9119, loss 0.571005.
Train: 2018-07-31T01:03:57.126953: step 9120, loss 0.602438.
Test: 2018-07-31T01:03:57.361248: step 9120, loss 0.55006.
Train: 2018-07-31T01:03:57.517464: step 9121, loss 0.516143.
Train: 2018-07-31T01:03:57.658054: step 9122, loss 0.523995.
Train: 2018-07-31T01:03:57.814292: step 9123, loss 0.53963.
Train: 2018-07-31T01:03:57.954884: step 9124, loss 0.578869.
Train: 2018-07-31T01:03:58.111074: step 9125, loss 0.578867.
Train: 2018-07-31T01:03:58.251684: step 9126, loss 0.570983.
Train: 2018-07-31T01:03:58.407878: step 9127, loss 0.539418.
Train: 2018-07-31T01:03:58.564093: step 9128, loss 0.539352.
Train: 2018-07-31T01:03:58.704685: step 9129, loss 0.531342.
Train: 2018-07-31T01:03:58.845301: step 9130, loss 0.562972.
Test: 2018-07-31T01:03:59.079624: step 9130, loss 0.549584.
Train: 2018-07-31T01:03:59.235835: step 9131, loss 0.539032.
Train: 2018-07-31T01:03:59.376403: step 9132, loss 0.610828.
Train: 2018-07-31T01:03:59.516994: step 9133, loss 0.562852.
Train: 2018-07-31T01:03:59.657586: step 9134, loss 0.554807.
Train: 2018-07-31T01:03:59.798179: step 9135, loss 0.594941.
Train: 2018-07-31T01:03:59.938771: step 9136, loss 0.522576.
Train: 2018-07-31T01:04:00.079387: step 9137, loss 0.522473.
Train: 2018-07-31T01:04:00.235576: step 9138, loss 0.481923.
Train: 2018-07-31T01:04:00.391789: step 9139, loss 0.578906.
Train: 2018-07-31T01:04:00.532406: step 9140, loss 0.562629.
Test: 2018-07-31T01:04:00.782348: step 9140, loss 0.548902.
Train: 2018-07-31T01:04:00.938537: step 9141, loss 0.521723.
Train: 2018-07-31T01:04:01.079128: step 9142, loss 0.652825.
Train: 2018-07-31T01:04:01.235367: step 9143, loss 0.578977.
Train: 2018-07-31T01:04:01.375932: step 9144, loss 0.529639.
Train: 2018-07-31T01:04:01.516550: step 9145, loss 0.554286.
Train: 2018-07-31T01:04:01.657118: step 9146, loss 0.570756.
Train: 2018-07-31T01:04:01.797709: step 9147, loss 0.5625.
Train: 2018-07-31T01:04:01.953947: step 9148, loss 0.537704.
Train: 2018-07-31T01:04:02.110138: step 9149, loss 0.537661.
Train: 2018-07-31T01:04:02.250753: step 9150, loss 0.537607.
Test: 2018-07-31T01:04:02.485050: step 9150, loss 0.548548.
Train: 2018-07-31T01:04:02.656884: step 9151, loss 0.554151.
Train: 2018-07-31T01:04:02.797501: step 9152, loss 0.529163.
Train: 2018-07-31T01:04:02.953714: step 9153, loss 0.545747.
Train: 2018-07-31T01:04:03.094307: step 9154, loss 0.579131.
Train: 2018-07-31T01:04:03.234899: step 9155, loss 0.595896.
Train: 2018-07-31T01:04:03.375490: step 9156, loss 0.612667.
Train: 2018-07-31T01:04:03.516058: step 9157, loss 0.478692.
Train: 2018-07-31T01:04:03.656674: step 9158, loss 0.579159.
Train: 2018-07-31T01:04:03.797240: step 9159, loss 0.595931.
Train: 2018-07-31T01:04:03.969113: step 9160, loss 0.528881.
Test: 2018-07-31T01:04:04.203430: step 9160, loss 0.548367.
Train: 2018-07-31T01:04:04.359609: step 9161, loss 0.612683.
Train: 2018-07-31T01:04:04.500227: step 9162, loss 0.654486.
Train: 2018-07-31T01:04:04.640794: step 9163, loss 0.570767.
Train: 2018-07-31T01:04:04.781411: step 9164, loss 0.554129.
Train: 2018-07-31T01:04:04.921977: step 9165, loss 0.545881.
Train: 2018-07-31T01:04:05.078192: step 9166, loss 0.595576.
Train: 2018-07-31T01:04:05.218784: step 9167, loss 0.521263.
Train: 2018-07-31T01:04:05.375022: step 9168, loss 0.595461.
Train: 2018-07-31T01:04:05.515614: step 9169, loss 0.537899.
Train: 2018-07-31T01:04:05.656206: step 9170, loss 0.587165.
Test: 2018-07-31T01:04:05.906152: step 9170, loss 0.548873.
Train: 2018-07-31T01:04:06.046740: step 9171, loss 0.497102.
Train: 2018-07-31T01:04:06.187307: step 9172, loss 0.562584.
Train: 2018-07-31T01:04:06.327924: step 9173, loss 0.554406.
Train: 2018-07-31T01:04:06.499734: step 9174, loss 0.521692.
Train: 2018-07-31T01:04:06.640326: step 9175, loss 0.660821.
Train: 2018-07-31T01:04:06.780918: step 9176, loss 0.546248.
Train: 2018-07-31T01:04:06.937132: step 9177, loss 0.603429.
Train: 2018-07-31T01:04:07.093370: step 9178, loss 0.595222.
Train: 2018-07-31T01:04:07.233937: step 9179, loss 0.481373.
Train: 2018-07-31T01:04:07.390150: step 9180, loss 0.578911.
Test: 2018-07-31T01:04:07.640092: step 9180, loss 0.549066.
Train: 2018-07-31T01:04:07.780684: step 9181, loss 0.546425.
Train: 2018-07-31T01:04:07.921277: step 9182, loss 0.53831.
Train: 2018-07-31T01:04:08.061883: step 9183, loss 0.643896.
Train: 2018-07-31T01:04:08.202461: step 9184, loss 0.514015.
Train: 2018-07-31T01:04:08.358697: step 9185, loss 0.578902.
Train: 2018-07-31T01:04:08.499266: step 9186, loss 0.570794.
Train: 2018-07-31T01:04:08.639858: step 9187, loss 0.514094.
Train: 2018-07-31T01:04:08.796072: step 9188, loss 0.603217.
Train: 2018-07-31T01:04:08.936664: step 9189, loss 0.514076.
Train: 2018-07-31T01:04:09.077256: step 9190, loss 0.578902.
Test: 2018-07-31T01:04:09.311575: step 9190, loss 0.549082.
Train: 2018-07-31T01:04:09.452167: step 9191, loss 0.595131.
Train: 2018-07-31T01:04:09.592784: step 9192, loss 0.538342.
Train: 2018-07-31T01:04:09.733352: step 9193, loss 0.562674.
Train: 2018-07-31T01:04:09.889566: step 9194, loss 0.473355.
Train: 2018-07-31T01:04:10.030181: step 9195, loss 0.635971.
Train: 2018-07-31T01:04:10.170751: step 9196, loss 0.51369.
Train: 2018-07-31T01:04:10.311342: step 9197, loss 0.546001.
Train: 2018-07-31T01:04:10.451935: step 9198, loss 0.538368.
Train: 2018-07-31T01:04:10.592550: step 9199, loss 0.570807.
Train: 2018-07-31T01:04:10.748740: step 9200, loss 0.50481.
Test: 2018-07-31T01:04:10.983085: step 9200, loss 0.548504.
Train: 2018-07-31T01:04:11.764127: step 9201, loss 0.59616.
Train: 2018-07-31T01:04:11.904717: step 9202, loss 0.562373.
Train: 2018-07-31T01:04:12.060932: step 9203, loss 0.561832.
Train: 2018-07-31T01:04:12.201525: step 9204, loss 0.520686.
Train: 2018-07-31T01:04:12.342116: step 9205, loss 0.604704.
Train: 2018-07-31T01:04:12.482717: step 9206, loss 0.570921.
Train: 2018-07-31T01:04:12.623343: step 9207, loss 0.553855.
Train: 2018-07-31T01:04:12.779513: step 9208, loss 0.612782.
Train: 2018-07-31T01:04:12.920106: step 9209, loss 0.513004.
Train: 2018-07-31T01:04:13.060698: step 9210, loss 0.578903.
Test: 2018-07-31T01:04:13.295050: step 9210, loss 0.548609.
Train: 2018-07-31T01:04:13.435634: step 9211, loss 0.633005.
Train: 2018-07-31T01:04:13.607445: step 9212, loss 0.471685.
Train: 2018-07-31T01:04:13.748037: step 9213, loss 0.521254.
Train: 2018-07-31T01:04:13.904274: step 9214, loss 0.595553.
Train: 2018-07-31T01:04:14.044843: step 9215, loss 0.529448.
Train: 2018-07-31T01:04:14.201054: step 9216, loss 0.628644.
Train: 2018-07-31T01:04:14.341672: step 9217, loss 0.579013.
Train: 2018-07-31T01:04:14.497861: step 9218, loss 0.587254.
Train: 2018-07-31T01:04:14.638478: step 9219, loss 0.595458.
Train: 2018-07-31T01:04:14.779045: step 9220, loss 0.537906.
Test: 2018-07-31T01:04:15.013396: step 9220, loss 0.548831.
Train: 2018-07-31T01:04:15.169603: step 9221, loss 0.521562.
Train: 2018-07-31T01:04:15.325792: step 9222, loss 0.546176.
Train: 2018-07-31T01:04:15.466385: step 9223, loss 0.537985.
Train: 2018-07-31T01:04:15.622597: step 9224, loss 0.521573.
Train: 2018-07-31T01:04:15.763189: step 9225, loss 0.554342.
Train: 2018-07-31T01:04:15.919419: step 9226, loss 0.554317.
Train: 2018-07-31T01:04:16.060014: step 9227, loss 0.496668.
Train: 2018-07-31T01:04:16.200612: step 9228, loss 0.62854.
Train: 2018-07-31T01:04:16.341179: step 9229, loss 0.595542.
Train: 2018-07-31T01:04:16.481771: step 9230, loss 0.488144.
Test: 2018-07-31T01:04:16.731714: step 9230, loss 0.548623.
Train: 2018-07-31T01:04:16.872305: step 9231, loss 0.612129.
Train: 2018-07-31T01:04:17.028546: step 9232, loss 0.537652.
Train: 2018-07-31T01:04:17.169111: step 9233, loss 0.554193.
Train: 2018-07-31T01:04:17.309702: step 9234, loss 0.56247.
Train: 2018-07-31T01:04:17.450295: step 9235, loss 0.554171.
Train: 2018-07-31T01:04:17.590911: step 9236, loss 0.686951.
Train: 2018-07-31T01:04:17.731507: step 9237, loss 0.521089.
Train: 2018-07-31T01:04:17.887692: step 9238, loss 0.554222.
Train: 2018-07-31T01:04:18.028284: step 9239, loss 0.579014.
Train: 2018-07-31T01:04:18.168875: step 9240, loss 0.56251.
Test: 2018-07-31T01:04:18.403198: step 9240, loss 0.548729.
Train: 2018-07-31T01:04:18.559410: step 9241, loss 0.562521.
Train: 2018-07-31T01:04:18.700003: step 9242, loss 0.546082.
Train: 2018-07-31T01:04:18.840653: step 9243, loss 0.554321.
Train: 2018-07-31T01:04:18.981186: step 9244, loss 0.595403.
Train: 2018-07-31T01:04:19.121779: step 9245, loss 0.513335.
Train: 2018-07-31T01:04:19.262370: step 9246, loss 0.513337.
Train: 2018-07-31T01:04:19.402986: step 9247, loss 0.570759.
Train: 2018-07-31T01:04:19.543553: step 9248, loss 0.603634.
Train: 2018-07-31T01:04:19.699793: step 9249, loss 0.529679.
Train: 2018-07-31T01:04:19.840384: step 9250, loss 0.546099.
Test: 2018-07-31T01:04:20.074679: step 9250, loss 0.548755.
Train: 2018-07-31T01:04:20.230894: step 9251, loss 0.521402.
Train: 2018-07-31T01:04:20.371509: step 9252, loss 0.603707.
Train: 2018-07-31T01:04:20.527700: step 9253, loss 0.562517.
Train: 2018-07-31T01:04:20.668291: step 9254, loss 0.562511.
Train: 2018-07-31T01:04:20.808907: step 9255, loss 0.611997.
Train: 2018-07-31T01:04:20.949499: step 9256, loss 0.504845.
Train: 2018-07-31T01:04:21.105713: step 9257, loss 0.513043.
Train: 2018-07-31T01:04:21.246297: step 9258, loss 0.537735.
Train: 2018-07-31T01:04:21.386897: step 9259, loss 0.529398.
Train: 2018-07-31T01:04:21.543087: step 9260, loss 0.570706.
Test: 2018-07-31T01:04:21.777408: step 9260, loss 0.548504.
Train: 2018-07-31T01:04:21.917999: step 9261, loss 0.479195.
Train: 2018-07-31T01:04:22.058589: step 9262, loss 0.604148.
Train: 2018-07-31T01:04:22.199182: step 9263, loss 0.537037.
Train: 2018-07-31T01:04:22.339774: step 9264, loss 0.562115.
Train: 2018-07-31T01:04:22.480391: step 9265, loss 0.579972.
Train: 2018-07-31T01:04:22.636581: step 9266, loss 0.509978.
Train: 2018-07-31T01:04:22.777196: step 9267, loss 0.511332.
Train: 2018-07-31T01:04:22.917763: step 9268, loss 0.578285.
Train: 2018-07-31T01:04:23.058356: step 9269, loss 0.562529.
Train: 2018-07-31T01:04:23.198950: step 9270, loss 0.606448.
Test: 2018-07-31T01:04:23.448922: step 9270, loss 0.547654.
Train: 2018-07-31T01:04:23.589481: step 9271, loss 0.517687.
Train: 2018-07-31T01:04:23.745697: step 9272, loss 0.668593.
Train: 2018-07-31T01:04:23.886288: step 9273, loss 0.536881.
Train: 2018-07-31T01:04:24.026879: step 9274, loss 0.641522.
Train: 2018-07-31T01:04:24.183092: step 9275, loss 0.527331.
Train: 2018-07-31T01:04:24.323708: step 9276, loss 0.646883.
Train: 2018-07-31T01:04:24.464278: step 9277, loss 0.545774.
Train: 2018-07-31T01:04:24.604868: step 9278, loss 0.620473.
Train: 2018-07-31T01:04:24.761083: step 9279, loss 0.579066.
Train: 2018-07-31T01:04:24.901676: step 9280, loss 0.513396.
Test: 2018-07-31T01:04:25.136014: step 9280, loss 0.548928.
Train: 2018-07-31T01:04:25.276595: step 9281, loss 0.619768.
Train: 2018-07-31T01:04:25.432799: step 9282, loss 0.587041.
Train: 2018-07-31T01:04:25.573429: step 9283, loss 0.554619.
Train: 2018-07-31T01:04:25.729631: step 9284, loss 0.57082.
Train: 2018-07-31T01:04:25.885818: step 9285, loss 0.482515.
Train: 2018-07-31T01:04:26.026412: step 9286, loss 0.506694.
Train: 2018-07-31T01:04:26.151406: step 9287, loss 0.538759.
Train: 2018-07-31T01:04:26.307596: step 9288, loss 0.57887.
Train: 2018-07-31T01:04:26.448188: step 9289, loss 0.594939.
Train: 2018-07-31T01:04:26.588780: step 9290, loss 0.570838.
Test: 2018-07-31T01:04:26.823127: step 9290, loss 0.549362.
Train: 2018-07-31T01:04:26.979330: step 9291, loss 0.51463.
Train: 2018-07-31T01:04:27.135526: step 9292, loss 0.530644.
Train: 2018-07-31T01:04:27.291765: step 9293, loss 0.530564.
Train: 2018-07-31T01:04:27.432331: step 9294, loss 0.6031.
Train: 2018-07-31T01:04:27.572925: step 9295, loss 0.595052.
Train: 2018-07-31T01:04:27.713540: step 9296, loss 0.611231.
Train: 2018-07-31T01:04:27.854133: step 9297, loss 0.651596.
Train: 2018-07-31T01:04:28.010323: step 9298, loss 0.55471.
Train: 2018-07-31T01:04:28.150915: step 9299, loss 0.538684.
Train: 2018-07-31T01:04:28.291505: step 9300, loss 0.498604.
Test: 2018-07-31T01:04:28.541477: step 9300, loss 0.549362.
Train: 2018-07-31T01:04:29.306921: step 9301, loss 0.506601.
Train: 2018-07-31T01:04:29.463106: step 9302, loss 0.538651.
Train: 2018-07-31T01:04:29.603699: step 9303, loss 0.60307.
Train: 2018-07-31T01:04:29.744290: step 9304, loss 0.546595.
Train: 2018-07-31T01:04:29.884881: step 9305, loss 0.546552.
Train: 2018-07-31T01:04:30.025474: step 9306, loss 0.514106.
Train: 2018-07-31T01:04:30.166066: step 9307, loss 0.538301.
Train: 2018-07-31T01:04:30.322280: step 9308, loss 0.58707.
Train: 2018-07-31T01:04:30.462872: step 9309, loss 0.521781.
Train: 2018-07-31T01:04:30.619110: step 9310, loss 0.61171.
Test: 2018-07-31T01:04:30.853408: step 9310, loss 0.548825.
Train: 2018-07-31T01:04:31.009618: step 9311, loss 0.529756.
Train: 2018-07-31T01:04:31.150210: step 9312, loss 0.636504.
Train: 2018-07-31T01:04:31.290803: step 9313, loss 0.603634.
Train: 2018-07-31T01:04:31.431394: step 9314, loss 0.587184.
Train: 2018-07-31T01:04:31.587633: step 9315, loss 0.619957.
Train: 2018-07-31T01:04:31.728202: step 9316, loss 0.619833.
Train: 2018-07-31T01:04:31.868793: step 9317, loss 0.489315.
Train: 2018-07-31T01:04:32.009384: step 9318, loss 0.538247.
Train: 2018-07-31T01:04:32.149976: step 9319, loss 0.538285.
Train: 2018-07-31T01:04:32.290569: step 9320, loss 0.619536.
Test: 2018-07-31T01:04:32.524889: step 9320, loss 0.549096.
Train: 2018-07-31T01:04:32.665482: step 9321, loss 0.562686.
Train: 2018-07-31T01:04:32.821695: step 9322, loss 0.619402.
Train: 2018-07-31T01:04:32.946666: step 9323, loss 0.595048.
Train: 2018-07-31T01:04:33.102904: step 9324, loss 0.570823.
Train: 2018-07-31T01:04:33.243470: step 9325, loss 0.57084.
Train: 2018-07-31T01:04:33.384064: step 9326, loss 0.578865.
Train: 2018-07-31T01:04:33.524680: step 9327, loss 0.522949.
Train: 2018-07-31T01:04:33.665248: step 9328, loss 0.562907.
Train: 2018-07-31T01:04:33.805864: step 9329, loss 0.586824.
Train: 2018-07-31T01:04:33.962090: step 9330, loss 0.52317.
Test: 2018-07-31T01:04:34.196403: step 9330, loss 0.549628.
Train: 2018-07-31T01:04:34.336989: step 9331, loss 0.626585.
Train: 2018-07-31T01:04:34.493198: step 9332, loss 0.570904.
Train: 2018-07-31T01:04:34.633795: step 9333, loss 0.578863.
Train: 2018-07-31T01:04:34.774387: step 9334, loss 0.50762.
Train: 2018-07-31T01:04:34.914979: step 9335, loss 0.531354.
Train: 2018-07-31T01:04:35.071168: step 9336, loss 0.578822.
Train: 2018-07-31T01:04:35.211785: step 9337, loss 0.555059.
Train: 2018-07-31T01:04:35.352376: step 9338, loss 0.539178.
Train: 2018-07-31T01:04:35.508566: step 9339, loss 0.531097.
Train: 2018-07-31T01:04:35.649157: step 9340, loss 0.523015.
Test: 2018-07-31T01:04:35.883509: step 9340, loss 0.549446.
Train: 2018-07-31T01:04:36.039692: step 9341, loss 0.61089.
Train: 2018-07-31T01:04:36.195928: step 9342, loss 0.578817.
Train: 2018-07-31T01:04:36.352118: step 9343, loss 0.562823.
Train: 2018-07-31T01:04:36.477089: step 9344, loss 0.562793.
Train: 2018-07-31T01:04:36.633302: step 9345, loss 0.570878.
Train: 2018-07-31T01:04:36.773893: step 9346, loss 0.506289.
Train: 2018-07-31T01:04:36.914486: step 9347, loss 0.562761.
Train: 2018-07-31T01:04:37.055078: step 9348, loss 0.651924.
Train: 2018-07-31T01:04:37.195671: step 9349, loss 0.595257.
Train: 2018-07-31T01:04:37.351884: step 9350, loss 0.578724.
Test: 2018-07-31T01:04:37.586206: step 9350, loss 0.549139.
Train: 2018-07-31T01:04:37.742441: step 9351, loss 0.554655.
Train: 2018-07-31T01:04:37.883010: step 9352, loss 0.578947.
Train: 2018-07-31T01:04:38.039224: step 9353, loss 0.530624.
Train: 2018-07-31T01:04:38.164218: step 9354, loss 0.546677.
Train: 2018-07-31T01:04:38.304786: step 9355, loss 0.530479.
Train: 2018-07-31T01:04:38.460999: step 9356, loss 0.546614.
Train: 2018-07-31T01:04:38.601593: step 9357, loss 0.570799.
Train: 2018-07-31T01:04:38.742208: step 9358, loss 0.578886.
Train: 2018-07-31T01:04:38.898422: step 9359, loss 0.57083.
Train: 2018-07-31T01:04:39.054610: step 9360, loss 0.522228.
Test: 2018-07-31T01:04:39.288961: step 9360, loss 0.549108.
Train: 2018-07-31T01:04:39.429560: step 9361, loss 0.538379.
Train: 2018-07-31T01:04:39.570139: step 9362, loss 0.649267.
Train: 2018-07-31T01:04:39.741949: step 9363, loss 0.522033.
Train: 2018-07-31T01:04:39.882542: step 9364, loss 0.562631.
Train: 2018-07-31T01:04:40.038781: step 9365, loss 0.603263.
Train: 2018-07-31T01:04:40.179371: step 9366, loss 0.578825.
Train: 2018-07-31T01:04:40.335562: step 9367, loss 0.603253.
Train: 2018-07-31T01:04:40.476176: step 9368, loss 0.627591.
Train: 2018-07-31T01:04:40.616745: step 9369, loss 0.611256.
Train: 2018-07-31T01:04:40.772958: step 9370, loss 0.546623.
Test: 2018-07-31T01:04:41.007278: step 9370, loss 0.549254.
Train: 2018-07-31T01:04:41.147870: step 9371, loss 0.530586.
Train: 2018-07-31T01:04:41.288462: step 9372, loss 0.635092.
Train: 2018-07-31T01:04:41.429055: step 9373, loss 0.522898.
Train: 2018-07-31T01:04:41.585269: step 9374, loss 0.578872.
Train: 2018-07-31T01:04:41.725884: step 9375, loss 0.546872.
Train: 2018-07-31T01:04:41.882074: step 9376, loss 0.554951.
Train: 2018-07-31T01:04:42.022682: step 9377, loss 0.563057.
Train: 2018-07-31T01:04:42.163281: step 9378, loss 0.539037.
Train: 2018-07-31T01:04:42.303875: step 9379, loss 0.58686.
Train: 2018-07-31T01:04:42.460063: step 9380, loss 0.562952.
Test: 2018-07-31T01:04:42.710029: step 9380, loss 0.54963.
Train: 2018-07-31T01:04:42.850596: step 9381, loss 0.499312.
Train: 2018-07-31T01:04:43.006813: step 9382, loss 0.570879.
Train: 2018-07-31T01:04:43.147415: step 9383, loss 0.54706.
Train: 2018-07-31T01:04:43.287995: step 9384, loss 0.570729.
Train: 2018-07-31T01:04:43.428585: step 9385, loss 0.546632.
Train: 2018-07-31T01:04:43.584800: step 9386, loss 0.522496.
Train: 2018-07-31T01:04:43.725393: step 9387, loss 0.570697.
Train: 2018-07-31T01:04:43.865983: step 9388, loss 0.604078.
Train: 2018-07-31T01:04:44.006575: step 9389, loss 0.578796.
Train: 2018-07-31T01:04:44.162790: step 9390, loss 0.537917.
Test: 2018-07-31T01:04:44.397140: step 9390, loss 0.548944.
Train: 2018-07-31T01:04:44.537700: step 9391, loss 0.538582.
Train: 2018-07-31T01:04:44.678293: step 9392, loss 0.627759.
Train: 2018-07-31T01:04:44.818885: step 9393, loss 0.513325.
Train: 2018-07-31T01:04:44.975100: step 9394, loss 0.561986.
Train: 2018-07-31T01:04:45.115691: step 9395, loss 0.611912.
Train: 2018-07-31T01:04:45.256307: step 9396, loss 0.578427.
Train: 2018-07-31T01:04:45.396900: step 9397, loss 0.579198.
Train: 2018-07-31T01:04:45.537469: step 9398, loss 0.578983.
Train: 2018-07-31T01:04:45.678083: step 9399, loss 0.537796.
Train: 2018-07-31T01:04:45.834297: step 9400, loss 0.603607.
Test: 2018-07-31T01:04:46.084215: step 9400, loss 0.548993.
Train: 2018-07-31T01:04:46.818450: step 9401, loss 0.555042.
Train: 2018-07-31T01:04:46.959008: step 9402, loss 0.537833.
Train: 2018-07-31T01:04:47.099627: step 9403, loss 0.530385.
Train: 2018-07-31T01:04:47.255815: step 9404, loss 0.52171.
Train: 2018-07-31T01:04:47.396431: step 9405, loss 0.603809.
Train: 2018-07-31T01:04:47.537027: step 9406, loss 0.521995.
Train: 2018-07-31T01:04:47.693214: step 9407, loss 0.514261.
Train: 2018-07-31T01:04:47.833841: step 9408, loss 0.570436.
Train: 2018-07-31T01:04:47.974421: step 9409, loss 0.554569.
Train: 2018-07-31T01:04:48.114988: step 9410, loss 0.570455.
Test: 2018-07-31T01:04:48.364955: step 9410, loss 0.548677.
Train: 2018-07-31T01:04:48.505546: step 9411, loss 0.553486.
Train: 2018-07-31T01:04:48.661735: step 9412, loss 0.619668.
Train: 2018-07-31T01:04:48.802327: step 9413, loss 0.505294.
Train: 2018-07-31T01:04:48.958542: step 9414, loss 0.545426.
Train: 2018-07-31T01:04:49.099134: step 9415, loss 0.554826.
Train: 2018-07-31T01:04:49.255346: step 9416, loss 0.6285.
Train: 2018-07-31T01:04:49.395963: step 9417, loss 0.537751.
Train: 2018-07-31T01:04:49.536538: step 9418, loss 0.528876.
Train: 2018-07-31T01:04:49.692745: step 9419, loss 0.538014.
Train: 2018-07-31T01:04:49.833336: step 9420, loss 0.544771.
Test: 2018-07-31T01:04:50.067684: step 9420, loss 0.548357.
Train: 2018-07-31T01:04:50.223871: step 9421, loss 0.572459.
Train: 2018-07-31T01:04:50.364461: step 9422, loss 0.478206.
Train: 2018-07-31T01:04:50.505054: step 9423, loss 0.580191.
Train: 2018-07-31T01:04:50.661267: step 9424, loss 0.520703.
Train: 2018-07-31T01:04:50.801859: step 9425, loss 0.570551.
Train: 2018-07-31T01:04:50.942477: step 9426, loss 0.495995.
Train: 2018-07-31T01:04:51.083068: step 9427, loss 0.460672.
Train: 2018-07-31T01:04:51.223655: step 9428, loss 0.650324.
Train: 2018-07-31T01:04:51.364227: step 9429, loss 0.545315.
Train: 2018-07-31T01:04:51.504844: step 9430, loss 0.519461.
Test: 2018-07-31T01:04:51.739166: step 9430, loss 0.547953.
Train: 2018-07-31T01:04:51.879757: step 9431, loss 0.518498.
Train: 2018-07-31T01:04:52.051567: step 9432, loss 0.59837.
Train: 2018-07-31T01:04:52.192159: step 9433, loss 0.588531.
Train: 2018-07-31T01:04:52.332751: step 9434, loss 0.614547.
Train: 2018-07-31T01:04:52.473344: step 9435, loss 0.561474.
Train: 2018-07-31T01:04:52.613935: step 9436, loss 0.545003.
Train: 2018-07-31T01:04:52.770149: step 9437, loss 0.469404.
Train: 2018-07-31T01:04:52.910740: step 9438, loss 0.563122.
Train: 2018-07-31T01:04:53.051332: step 9439, loss 0.520193.
Train: 2018-07-31T01:04:53.207546: step 9440, loss 0.52837.
Test: 2018-07-31T01:04:53.441896: step 9440, loss 0.548149.
Train: 2018-07-31T01:04:53.582502: step 9441, loss 0.570931.
Train: 2018-07-31T01:04:53.738671: step 9442, loss 0.554054.
Train: 2018-07-31T01:04:53.879288: step 9443, loss 0.545459.
Train: 2018-07-31T01:04:54.035479: step 9444, loss 0.545475.
Train: 2018-07-31T01:04:54.176069: step 9445, loss 0.528174.
Train: 2018-07-31T01:04:54.332307: step 9446, loss 0.545306.
Train: 2018-07-31T01:04:54.472875: step 9447, loss 0.579477.
Train: 2018-07-31T01:04:54.613467: step 9448, loss 0.622174.
Train: 2018-07-31T01:04:54.754058: step 9449, loss 0.570861.
Train: 2018-07-31T01:04:54.894675: step 9450, loss 0.47724.
Test: 2018-07-31T01:04:55.144593: step 9450, loss 0.548084.
Train: 2018-07-31T01:04:55.285184: step 9451, loss 0.545342.
Train: 2018-07-31T01:04:55.425778: step 9452, loss 0.485674.
Train: 2018-07-31T01:04:55.566368: step 9453, loss 0.656224.
Train: 2018-07-31T01:04:55.706960: step 9454, loss 0.613545.
Train: 2018-07-31T01:04:55.847553: step 9455, loss 0.596415.
Train: 2018-07-31T01:04:55.972523: step 9456, loss 0.511375.
Train: 2018-07-31T01:04:56.113115: step 9457, loss 0.54538.
Train: 2018-07-31T01:04:56.253707: step 9458, loss 0.579301.
Train: 2018-07-31T01:04:56.394324: step 9459, loss 0.553895.
Train: 2018-07-31T01:04:56.534917: step 9460, loss 0.545462.
Test: 2018-07-31T01:04:56.784834: step 9460, loss 0.548197.
Train: 2018-07-31T01:04:56.925424: step 9461, loss 0.629901.
Train: 2018-07-31T01:04:57.081639: step 9462, loss 0.537117.
Train: 2018-07-31T01:04:57.222255: step 9463, loss 0.621207.
Train: 2018-07-31T01:04:57.378445: step 9464, loss 0.528897.
Train: 2018-07-31T01:04:57.519061: step 9465, loss 0.604198.
Train: 2018-07-31T01:04:57.659629: step 9466, loss 0.520782.
Train: 2018-07-31T01:04:57.800220: step 9467, loss 0.570761.
Train: 2018-07-31T01:04:57.940837: step 9468, loss 0.529277.
Train: 2018-07-31T01:04:58.081406: step 9469, loss 0.587329.
Train: 2018-07-31T01:04:58.237619: step 9470, loss 0.636929.
Test: 2018-07-31T01:04:58.471938: step 9470, loss 0.548707.
Train: 2018-07-31T01:04:58.612529: step 9471, loss 0.529539.
Train: 2018-07-31T01:04:58.768744: step 9472, loss 0.562534.
Train: 2018-07-31T01:04:58.909337: step 9473, loss 0.537935.
Train: 2018-07-31T01:04:59.049929: step 9474, loss 0.546179.
Train: 2018-07-31T01:04:59.190545: step 9475, loss 0.538015.
Train: 2018-07-31T01:04:59.331112: step 9476, loss 0.628063.
Train: 2018-07-31T01:04:59.487325: step 9477, loss 0.57894.
Train: 2018-07-31T01:04:59.627918: step 9478, loss 0.627853.
Train: 2018-07-31T01:04:59.768533: step 9479, loss 0.522026.
Train: 2018-07-31T01:04:59.909102: step 9480, loss 0.578902.
Test: 2018-07-31T01:05:00.159073: step 9480, loss 0.549162.
Train: 2018-07-31T01:05:00.299636: step 9481, loss 0.481793.
Train: 2018-07-31T01:05:00.440228: step 9482, loss 0.595076.
Train: 2018-07-31T01:05:00.580837: step 9483, loss 0.643575.
Train: 2018-07-31T01:05:00.721429: step 9484, loss 0.506299.
Train: 2018-07-31T01:05:00.877650: step 9485, loss 0.562764.
Train: 2018-07-31T01:05:01.018217: step 9486, loss 0.586928.
Train: 2018-07-31T01:05:01.174429: step 9487, loss 0.570832.
Train: 2018-07-31T01:05:01.330643: step 9488, loss 0.522646.
Train: 2018-07-31T01:05:01.455663: step 9489, loss 0.627063.
Train: 2018-07-31T01:05:01.611828: step 9490, loss 0.594907.
Test: 2018-07-31T01:05:01.846148: step 9490, loss 0.549456.
Train: 2018-07-31T01:05:01.986740: step 9491, loss 0.570861.
Train: 2018-07-31T01:05:02.142954: step 9492, loss 0.602824.
Train: 2018-07-31T01:05:02.299168: step 9493, loss 0.626657.
Train: 2018-07-31T01:05:02.439799: step 9494, loss 0.547117.
Train: 2018-07-31T01:05:02.595997: step 9495, loss 0.57886.
Train: 2018-07-31T01:05:02.736582: step 9496, loss 0.570974.
Train: 2018-07-31T01:05:02.892777: step 9497, loss 0.571.
Train: 2018-07-31T01:05:03.049017: step 9498, loss 0.61812.
Train: 2018-07-31T01:05:03.189583: step 9499, loss 0.563237.
Train: 2018-07-31T01:05:03.330175: step 9500, loss 0.508685.
Test: 2018-07-31T01:05:03.564525: step 9500, loss 0.550254.
Train: 2018-07-31T01:05:04.314345: step 9501, loss 0.578895.
Train: 2018-07-31T01:05:04.470533: step 9502, loss 0.539966.
Train: 2018-07-31T01:05:04.611150: step 9503, loss 0.547752.
Train: 2018-07-31T01:05:04.751717: step 9504, loss 0.610063.
Train: 2018-07-31T01:05:04.892311: step 9505, loss 0.56332.
Train: 2018-07-31T01:05:05.048522: step 9506, loss 0.539957.
Train: 2018-07-31T01:05:05.189139: step 9507, loss 0.586689.
Train: 2018-07-31T01:05:05.345353: step 9508, loss 0.649066.
Train: 2018-07-31T01:05:05.485921: step 9509, loss 0.462145.
Train: 2018-07-31T01:05:05.626512: step 9510, loss 0.594483.
Test: 2018-07-31T01:05:05.876454: step 9510, loss 0.55023.
Train: 2018-07-31T01:05:06.032667: step 9511, loss 0.586692.
Train: 2018-07-31T01:05:06.188905: step 9512, loss 0.461869.
Train: 2018-07-31T01:05:06.329473: step 9513, loss 0.529841.
Train: 2018-07-31T01:05:06.470090: step 9514, loss 0.50817.
Train: 2018-07-31T01:05:06.610696: step 9515, loss 0.578862.
Train: 2018-07-31T01:05:06.766895: step 9516, loss 0.610577.
Train: 2018-07-31T01:05:06.907463: step 9517, loss 0.562955.
Train: 2018-07-31T01:05:07.048056: step 9518, loss 0.57886.
Train: 2018-07-31T01:05:07.204268: step 9519, loss 0.490975.
Train: 2018-07-31T01:05:07.344861: step 9520, loss 0.514708.
Test: 2018-07-31T01:05:07.579213: step 9520, loss 0.549271.
Train: 2018-07-31T01:05:07.719773: step 9521, loss 0.594993.
Train: 2018-07-31T01:05:07.875986: step 9522, loss 0.546549.
Train: 2018-07-31T01:05:08.000957: step 9523, loss 0.513994.
Train: 2018-07-31T01:05:08.157171: step 9524, loss 0.570776.
Train: 2018-07-31T01:05:08.297761: step 9525, loss 0.578946.
Train: 2018-07-31T01:05:08.438380: step 9526, loss 0.570762.
Train: 2018-07-31T01:05:08.594568: step 9527, loss 0.554312.
Train: 2018-07-31T01:05:08.735160: step 9528, loss 0.488334.
Train: 2018-07-31T01:05:08.891375: step 9529, loss 0.52939.
Train: 2018-07-31T01:05:09.047586: step 9530, loss 0.579066.
Test: 2018-07-31T01:05:09.281909: step 9530, loss 0.548476.
Train: 2018-07-31T01:05:09.453773: step 9531, loss 0.570764.
Train: 2018-07-31T01:05:09.594335: step 9532, loss 0.662664.
Train: 2018-07-31T01:05:09.734950: step 9533, loss 0.520652.
Train: 2018-07-31T01:05:09.875519: step 9534, loss 0.554053.
Train: 2018-07-31T01:05:10.016111: step 9535, loss 0.52895.
Train: 2018-07-31T01:05:10.156703: step 9536, loss 0.587527.
Train: 2018-07-31T01:05:10.297295: step 9537, loss 0.587535.
Train: 2018-07-31T01:05:10.437885: step 9538, loss 0.554024.
Train: 2018-07-31T01:05:10.594123: step 9539, loss 0.545655.
Train: 2018-07-31T01:05:10.734691: step 9540, loss 0.604272.
Test: 2018-07-31T01:05:10.969043: step 9540, loss 0.548399.
Train: 2018-07-31T01:05:11.125226: step 9541, loss 0.579139.
Train: 2018-07-31T01:05:11.265817: step 9542, loss 0.60418.
Train: 2018-07-31T01:05:11.406434: step 9543, loss 0.570765.
Train: 2018-07-31T01:05:11.562623: step 9544, loss 0.579072.
Train: 2018-07-31T01:05:11.703214: step 9545, loss 0.496151.
Train: 2018-07-31T01:05:11.843814: step 9546, loss 0.554194.
Train: 2018-07-31T01:05:11.984399: step 9547, loss 0.562482.
Train: 2018-07-31T01:05:12.140612: step 9548, loss 0.529415.
Train: 2018-07-31T01:05:12.281204: step 9549, loss 0.579024.
Train: 2018-07-31T01:05:12.421796: step 9550, loss 0.587285.
Test: 2018-07-31T01:05:12.656118: step 9550, loss 0.548675.
Train: 2018-07-31T01:05:12.812331: step 9551, loss 0.512968.
Train: 2018-07-31T01:05:12.952947: step 9552, loss 0.570756.
Train: 2018-07-31T01:05:13.093514: step 9553, loss 0.570756.
Train: 2018-07-31T01:05:13.234106: step 9554, loss 0.512992.
Train: 2018-07-31T01:05:13.374698: step 9555, loss 0.521207.
Train: 2018-07-31T01:05:13.515290: step 9556, loss 0.579028.
Train: 2018-07-31T01:05:13.671529: step 9557, loss 0.62043.
Train: 2018-07-31T01:05:13.827717: step 9558, loss 0.496289.
Train: 2018-07-31T01:05:13.968310: step 9559, loss 0.612167.
Train: 2018-07-31T01:05:14.108901: step 9560, loss 0.521084.
Test: 2018-07-31T01:05:14.343247: step 9560, loss 0.548612.
Train: 2018-07-31T01:05:14.483813: step 9561, loss 0.637023.
Train: 2018-07-31T01:05:14.640026: step 9562, loss 0.529395.
Train: 2018-07-31T01:05:14.780619: step 9563, loss 0.603829.
Train: 2018-07-31T01:05:14.921211: step 9564, loss 0.504708.
Train: 2018-07-31T01:05:15.061803: step 9565, loss 0.595523.
Train: 2018-07-31T01:05:15.218017: step 9566, loss 0.537764.
Train: 2018-07-31T01:05:15.358609: step 9567, loss 0.60374.
Train: 2018-07-31T01:05:15.514822: step 9568, loss 0.587228.
Train: 2018-07-31T01:05:15.655415: step 9569, loss 0.521433.
Train: 2018-07-31T01:05:15.827259: step 9570, loss 0.488607.
Test: 2018-07-31T01:05:16.061602: step 9570, loss 0.548761.
Train: 2018-07-31T01:05:16.233405: step 9571, loss 0.546086.
Train: 2018-07-31T01:05:16.358375: step 9572, loss 0.504877.
Train: 2018-07-31T01:05:16.498966: step 9573, loss 0.529479.
Train: 2018-07-31T01:05:16.639583: step 9574, loss 0.603875.
Train: 2018-07-31T01:05:16.795773: step 9575, loss 0.628806.
Train: 2018-07-31T01:05:16.936365: step 9576, loss 0.51272.
Train: 2018-07-31T01:05:17.076957: step 9577, loss 0.545862.
Train: 2018-07-31T01:05:17.217573: step 9578, loss 0.504296.
Train: 2018-07-31T01:05:17.373761: step 9579, loss 0.629049.
Train: 2018-07-31T01:05:17.514354: step 9580, loss 0.487465.
Test: 2018-07-31T01:05:17.764296: step 9580, loss 0.548442.
Train: 2018-07-31T01:05:17.904912: step 9581, loss 0.562429.
Train: 2018-07-31T01:05:18.045479: step 9582, loss 0.57914.
Train: 2018-07-31T01:05:18.170449: step 9583, loss 0.604241.
Train: 2018-07-31T01:05:18.326663: step 9584, loss 0.554042.
Train: 2018-07-31T01:05:18.467280: step 9585, loss 0.595861.
Train: 2018-07-31T01:05:18.623493: step 9586, loss 0.587479.
Train: 2018-07-31T01:05:18.764060: step 9587, loss 0.60413.
Train: 2018-07-31T01:05:18.920275: step 9588, loss 0.579081.
Train: 2018-07-31T01:05:19.045247: step 9589, loss 0.570758.
Train: 2018-07-31T01:05:19.185838: step 9590, loss 0.628674.
Test: 2018-07-31T01:05:19.420158: step 9590, loss 0.548733.
Train: 2018-07-31T01:05:19.560750: step 9591, loss 0.661397.
Train: 2018-07-31T01:05:19.716964: step 9592, loss 0.587144.
Train: 2018-07-31T01:05:19.857555: step 9593, loss 0.521936.
Train: 2018-07-31T01:05:19.998146: step 9594, loss 0.554588.
Train: 2018-07-31T01:05:20.138738: step 9595, loss 0.595029.
Train: 2018-07-31T01:05:20.294977: step 9596, loss 0.546719.
Train: 2018-07-31T01:05:20.435563: step 9597, loss 0.522786.
Train: 2018-07-31T01:05:20.576136: step 9598, loss 0.594854.
Train: 2018-07-31T01:05:20.716728: step 9599, loss 0.491122.
Train: 2018-07-31T01:05:20.872942: step 9600, loss 0.546965.
Test: 2018-07-31T01:05:21.122916: step 9600, loss 0.549551.
Train: 2018-07-31T01:05:21.825871: step 9601, loss 0.531006.
Train: 2018-07-31T01:05:21.982059: step 9602, loss 0.570875.
Train: 2018-07-31T01:05:22.122651: step 9603, loss 0.546892.
Train: 2018-07-31T01:05:22.263266: step 9604, loss 0.570861.
Train: 2018-07-31T01:05:22.419479: step 9605, loss 0.618931.
Train: 2018-07-31T01:05:22.560047: step 9606, loss 0.562843.
Train: 2018-07-31T01:05:22.700638: step 9607, loss 0.578869.
Train: 2018-07-31T01:05:22.841256: step 9608, loss 0.586866.
Train: 2018-07-31T01:05:22.981823: step 9609, loss 0.562867.
Train: 2018-07-31T01:05:23.122434: step 9610, loss 0.60284.
Test: 2018-07-31T01:05:23.372358: step 9610, loss 0.549539.
Train: 2018-07-31T01:05:23.512949: step 9611, loss 0.594819.
Train: 2018-07-31T01:05:23.669163: step 9612, loss 0.618672.
Train: 2018-07-31T01:05:23.825376: step 9613, loss 0.523293.
Train: 2018-07-31T01:05:23.965968: step 9614, loss 0.531311.
Train: 2018-07-31T01:05:24.122182: step 9615, loss 0.531338.
Train: 2018-07-31T01:05:24.262772: step 9616, loss 0.610555.
Train: 2018-07-31T01:05:24.403366: step 9617, loss 0.602616.
Train: 2018-07-31T01:05:24.559604: step 9618, loss 0.555138.
Train: 2018-07-31T01:05:24.715793: step 9619, loss 0.570961.
Train: 2018-07-31T01:05:24.856386: step 9620, loss 0.547287.
Test: 2018-07-31T01:05:25.090737: step 9620, loss 0.549871.
Train: 2018-07-31T01:05:25.231301: step 9621, loss 0.555186.
Train: 2018-07-31T01:05:25.387510: step 9622, loss 0.626226.
Train: 2018-07-31T01:05:25.528128: step 9623, loss 0.515792.
Train: 2018-07-31T01:05:25.668696: step 9624, loss 0.523661.
Train: 2018-07-31T01:05:25.824909: step 9625, loss 0.626246.
Train: 2018-07-31T01:05:25.981122: step 9626, loss 0.555174.
Train: 2018-07-31T01:05:26.121738: step 9627, loss 0.547269.
Train: 2018-07-31T01:05:26.262330: step 9628, loss 0.56305.
Train: 2018-07-31T01:05:26.402898: step 9629, loss 0.594684.
Train: 2018-07-31T01:05:26.543493: step 9630, loss 0.594678.
Test: 2018-07-31T01:05:26.793461: step 9630, loss 0.549791.
Train: 2018-07-31T01:05:26.949645: step 9631, loss 0.515569.
Train: 2018-07-31T01:05:27.090260: step 9632, loss 0.467982.
Train: 2018-07-31T01:05:27.230853: step 9633, loss 0.594783.
Train: 2018-07-31T01:05:27.387041: step 9634, loss 0.578725.
Train: 2018-07-31T01:05:27.527633: step 9635, loss 0.578865.
Train: 2018-07-31T01:05:27.668227: step 9636, loss 0.481967.
Train: 2018-07-31T01:05:27.808817: step 9637, loss 0.547096.
Train: 2018-07-31T01:05:27.949420: step 9638, loss 0.596282.
Train: 2018-07-31T01:05:28.090003: step 9639, loss 0.626488.
Train: 2018-07-31T01:05:28.230595: step 9640, loss 0.546014.
Test: 2018-07-31T01:05:28.480567: step 9640, loss 0.54881.
Train: 2018-07-31T01:05:28.621145: step 9641, loss 0.553851.
Train: 2018-07-31T01:05:28.761744: step 9642, loss 0.563111.
Train: 2018-07-31T01:05:28.902311: step 9643, loss 0.570903.
Train: 2018-07-31T01:05:29.058526: step 9644, loss 0.604085.
Train: 2018-07-31T01:05:29.199135: step 9645, loss 0.504412.
Train: 2018-07-31T01:05:29.339735: step 9646, loss 0.563843.
Train: 2018-07-31T01:05:29.480301: step 9647, loss 0.546131.
Train: 2018-07-31T01:05:29.620893: step 9648, loss 0.56287.
Train: 2018-07-31T01:05:29.761512: step 9649, loss 0.58841.
Train: 2018-07-31T01:05:29.902102: step 9650, loss 0.521318.
Test: 2018-07-31T01:05:30.152019: step 9650, loss 0.548918.
Train: 2018-07-31T01:05:30.292612: step 9651, loss 0.586986.
Train: 2018-07-31T01:05:30.433204: step 9652, loss 0.505525.
Train: 2018-07-31T01:05:30.589418: step 9653, loss 0.594911.
Train: 2018-07-31T01:05:30.730011: step 9654, loss 0.595192.
Train: 2018-07-31T01:05:30.870601: step 9655, loss 0.497631.
Train: 2018-07-31T01:05:31.011192: step 9656, loss 0.570929.
Train: 2018-07-31T01:05:31.151809: step 9657, loss 0.578811.
Train: 2018-07-31T01:05:31.292402: step 9658, loss 0.521745.
Train: 2018-07-31T01:05:31.432969: step 9659, loss 0.595281.
Train: 2018-07-31T01:05:31.573562: step 9660, loss 0.562714.
Test: 2018-07-31T01:05:31.823503: step 9660, loss 0.548859.
Train: 2018-07-31T01:05:31.964119: step 9661, loss 0.513553.
Train: 2018-07-31T01:05:32.104687: step 9662, loss 0.57079.
Train: 2018-07-31T01:05:32.260925: step 9663, loss 0.513281.
Train: 2018-07-31T01:05:32.401493: step 9664, loss 0.509845.
Train: 2018-07-31T01:05:32.542086: step 9665, loss 0.611967.
Train: 2018-07-31T01:05:32.667056: step 9666, loss 0.529377.
Train: 2018-07-31T01:05:32.807648: step 9667, loss 0.570856.
Train: 2018-07-31T01:05:32.948240: step 9668, loss 0.537544.
Train: 2018-07-31T01:05:33.088870: step 9669, loss 0.57909.
Train: 2018-07-31T01:05:33.229448: step 9670, loss 0.554087.
Test: 2018-07-31T01:05:33.479366: step 9670, loss 0.548467.
Train: 2018-07-31T01:05:33.635579: step 9671, loss 0.504087.
Train: 2018-07-31T01:05:33.776172: step 9672, loss 0.570672.
Train: 2018-07-31T01:05:33.916764: step 9673, loss 0.554002.
Train: 2018-07-31T01:05:34.057379: step 9674, loss 0.58772.
Train: 2018-07-31T01:05:34.197949: step 9675, loss 0.537017.
Train: 2018-07-31T01:05:34.338586: step 9676, loss 0.579014.
Train: 2018-07-31T01:05:34.479130: step 9677, loss 0.545521.
Train: 2018-07-31T01:05:34.619723: step 9678, loss 0.562394.
Train: 2018-07-31T01:05:34.760314: step 9679, loss 0.587932.
Train: 2018-07-31T01:05:34.900919: step 9680, loss 0.604375.
Test: 2018-07-31T01:05:35.150850: step 9680, loss 0.548278.
Train: 2018-07-31T01:05:35.291459: step 9681, loss 0.494795.
Train: 2018-07-31T01:05:35.432066: step 9682, loss 0.478205.
Train: 2018-07-31T01:05:35.588246: step 9683, loss 0.562178.
Train: 2018-07-31T01:05:35.728840: step 9684, loss 0.622378.
Train: 2018-07-31T01:05:35.869447: step 9685, loss 0.520692.
Train: 2018-07-31T01:05:36.010048: step 9686, loss 0.579541.
Train: 2018-07-31T01:05:36.150615: step 9687, loss 0.503394.
Train: 2018-07-31T01:05:36.291207: step 9688, loss 0.528442.
Train: 2018-07-31T01:05:36.431816: step 9689, loss 0.520024.
Train: 2018-07-31T01:05:36.588013: step 9690, loss 0.503024.
Test: 2018-07-31T01:05:36.822360: step 9690, loss 0.54812.
Train: 2018-07-31T01:05:36.962925: step 9691, loss 0.570852.
Train: 2018-07-31T01:05:37.119138: step 9692, loss 0.519849.
Train: 2018-07-31T01:05:37.275351: step 9693, loss 0.519948.
Train: 2018-07-31T01:05:37.415943: step 9694, loss 0.54514.
Train: 2018-07-31T01:05:37.572182: step 9695, loss 0.536639.
Train: 2018-07-31T01:05:37.712748: step 9696, loss 0.484934.
Train: 2018-07-31T01:05:37.853341: step 9697, loss 0.59685.
Train: 2018-07-31T01:05:37.993943: step 9698, loss 0.562395.
Train: 2018-07-31T01:05:38.134550: step 9699, loss 0.518946.
Train: 2018-07-31T01:05:38.275118: step 9700, loss 0.579645.
Test: 2018-07-31T01:05:38.509468: step 9700, loss 0.547763.
Train: 2018-07-31T01:05:39.243664: step 9701, loss 0.475261.
Train: 2018-07-31T01:05:39.399854: step 9702, loss 0.518657.
Train: 2018-07-31T01:05:39.540470: step 9703, loss 0.50963.
Train: 2018-07-31T01:05:39.696658: step 9704, loss 0.571137.
Train: 2018-07-31T01:05:39.837251: step 9705, loss 0.57993.
Train: 2018-07-31T01:05:39.993466: step 9706, loss 0.571139.
Train: 2018-07-31T01:05:40.134081: step 9707, loss 0.58881.
Train: 2018-07-31T01:05:40.305893: step 9708, loss 0.57133.
Train: 2018-07-31T01:05:40.446483: step 9709, loss 0.553841.
Train: 2018-07-31T01:05:40.587076: step 9710, loss 0.553592.
Test: 2018-07-31T01:05:40.821428: step 9710, loss 0.547624.
Train: 2018-07-31T01:05:40.961988: step 9711, loss 0.553641.
Train: 2018-07-31T01:05:41.118226: step 9712, loss 0.571031.
Train: 2018-07-31T01:05:41.258817: step 9713, loss 0.482874.
Train: 2018-07-31T01:05:41.399410: step 9714, loss 0.659729.
Train: 2018-07-31T01:05:41.555623: step 9715, loss 0.465479.
Train: 2018-07-31T01:05:41.711813: step 9716, loss 0.597623.
Train: 2018-07-31T01:05:41.868026: step 9717, loss 0.553598.
Train: 2018-07-31T01:05:42.008643: step 9718, loss 0.535679.
Train: 2018-07-31T01:05:42.149211: step 9719, loss 0.544861.
Train: 2018-07-31T01:05:42.321046: step 9720, loss 0.60596.
Test: 2018-07-31T01:05:42.555395: step 9720, loss 0.547757.
Train: 2018-07-31T01:05:42.695983: step 9721, loss 0.510109.
Train: 2018-07-31T01:05:42.852169: step 9722, loss 0.588229.
Train: 2018-07-31T01:05:42.992762: step 9723, loss 0.528057.
Train: 2018-07-31T01:05:43.148975: step 9724, loss 0.501776.
Train: 2018-07-31T01:05:43.289567: step 9725, loss 0.544862.
Train: 2018-07-31T01:05:43.430160: step 9726, loss 0.510153.
Train: 2018-07-31T01:05:43.570777: step 9727, loss 0.587797.
Train: 2018-07-31T01:05:43.711368: step 9728, loss 0.484521.
Train: 2018-07-31T01:05:43.851938: step 9729, loss 0.527488.
Train: 2018-07-31T01:05:44.008150: step 9730, loss 0.631833.
Test: 2018-07-31T01:05:44.242472: step 9730, loss 0.547742.
Train: 2018-07-31T01:05:44.398708: step 9731, loss 0.580055.
Train: 2018-07-31T01:05:44.539293: step 9732, loss 0.622793.
Train: 2018-07-31T01:05:44.679868: step 9733, loss 0.588914.
Train: 2018-07-31T01:05:44.836081: step 9734, loss 0.622742.
Train: 2018-07-31T01:05:44.976697: step 9735, loss 0.596524.
Train: 2018-07-31T01:05:45.132887: step 9736, loss 0.613447.
Train: 2018-07-31T01:05:45.273479: step 9737, loss 0.519948.
Train: 2018-07-31T01:05:45.414095: step 9738, loss 0.554011.
Train: 2018-07-31T01:05:45.554687: step 9739, loss 0.570861.
Train: 2018-07-31T01:05:45.710877: step 9740, loss 0.562553.
Test: 2018-07-31T01:05:45.945197: step 9740, loss 0.548568.
Train: 2018-07-31T01:05:46.085788: step 9741, loss 0.537578.
Train: 2018-07-31T01:05:46.226404: step 9742, loss 0.579023.
Train: 2018-07-31T01:05:46.382595: step 9743, loss 0.521321.
Train: 2018-07-31T01:05:46.523212: step 9744, loss 0.537871.
Train: 2018-07-31T01:05:46.663810: step 9745, loss 0.578971.
Train: 2018-07-31T01:05:46.804399: step 9746, loss 0.537968.
Train: 2018-07-31T01:05:46.944987: step 9747, loss 0.562572.
Train: 2018-07-31T01:05:47.101201: step 9748, loss 0.488913.
Train: 2018-07-31T01:05:47.257391: step 9749, loss 0.570763.
Train: 2018-07-31T01:05:47.398000: step 9750, loss 0.652753.
Test: 2018-07-31T01:05:47.632301: step 9750, loss 0.548868.
Train: 2018-07-31T01:05:47.772918: step 9751, loss 0.65263.
Train: 2018-07-31T01:05:47.929108: step 9752, loss 0.570773.
Train: 2018-07-31T01:05:48.069699: step 9753, loss 0.660214.
Train: 2018-07-31T01:05:48.210316: step 9754, loss 0.506112.
Train: 2018-07-31T01:05:48.350883: step 9755, loss 0.57082.
Train: 2018-07-31T01:05:48.491515: step 9756, loss 0.602969.
Train: 2018-07-31T01:05:48.632084: step 9757, loss 0.618873.
Train: 2018-07-31T01:05:48.788281: step 9758, loss 0.539039.
Train: 2018-07-31T01:05:48.928872: step 9759, loss 0.570923.
Train: 2018-07-31T01:05:49.069490: step 9760, loss 0.570951.
Test: 2018-07-31T01:05:49.303812: step 9760, loss 0.549885.
Train: 2018-07-31T01:05:49.459999: step 9761, loss 0.58675.
Train: 2018-07-31T01:05:49.600615: step 9762, loss 0.555286.
Train: 2018-07-31T01:05:49.756804: step 9763, loss 0.586717.
Train: 2018-07-31T01:05:49.897395: step 9764, loss 0.539773.
Train: 2018-07-31T01:05:50.038012: step 9765, loss 0.602318.
Train: 2018-07-31T01:05:50.194202: step 9766, loss 0.508753.
Train: 2018-07-31T01:05:50.334818: step 9767, loss 0.555521.
Train: 2018-07-31T01:05:50.475386: step 9768, loss 0.578895.
Train: 2018-07-31T01:05:50.615977: step 9769, loss 0.602276.
Train: 2018-07-31T01:05:50.772218: step 9770, loss 0.602261.
Test: 2018-07-31T01:05:51.022133: step 9770, loss 0.550326.
Train: 2018-07-31T01:05:51.162749: step 9771, loss 0.578904.
Train: 2018-07-31T01:05:51.318963: step 9772, loss 0.57891.
Train: 2018-07-31T01:05:51.475184: step 9773, loss 0.633197.
Train: 2018-07-31T01:05:51.615743: step 9774, loss 0.571199.
Train: 2018-07-31T01:05:51.740714: step 9775, loss 0.609796.
Train: 2018-07-31T01:05:51.896927: step 9776, loss 0.555899.
Train: 2018-07-31T01:05:52.037520: step 9777, loss 0.540628.
Train: 2018-07-31T01:05:52.178113: step 9778, loss 0.548342.
Train: 2018-07-31T01:05:52.318728: step 9779, loss 0.525375.
Train: 2018-07-31T01:05:52.459320: step 9780, loss 0.609653.
Test: 2018-07-31T01:05:52.709237: step 9780, loss 0.550801.
Train: 2018-07-31T01:05:52.849829: step 9781, loss 0.540638.
Train: 2018-07-31T01:05:53.021676: step 9782, loss 0.571297.
Train: 2018-07-31T01:05:53.162256: step 9783, loss 0.555912.
Train: 2018-07-31T01:05:53.302866: step 9784, loss 0.517387.
Train: 2018-07-31T01:05:53.443440: step 9785, loss 0.594378.
Train: 2018-07-31T01:05:53.584032: step 9786, loss 0.602133.
Train: 2018-07-31T01:05:53.724624: step 9787, loss 0.602154.
Train: 2018-07-31T01:05:53.865216: step 9788, loss 0.594413.
Train: 2018-07-31T01:05:54.005834: step 9789, loss 0.57118.
Train: 2018-07-31T01:05:54.146400: step 9790, loss 0.578925.
Test: 2018-07-31T01:05:54.380752: step 9790, loss 0.550485.
Train: 2018-07-31T01:05:54.536959: step 9791, loss 0.547968.
Train: 2018-07-31T01:05:54.693172: step 9792, loss 0.563438.
Train: 2018-07-31T01:05:54.849362: step 9793, loss 0.609913.
Train: 2018-07-31T01:05:54.989954: step 9794, loss 0.609905.
Train: 2018-07-31T01:05:55.130546: step 9795, loss 0.54025.
Train: 2018-07-31T01:05:55.271137: step 9796, loss 0.54026.
Train: 2018-07-31T01:05:55.411729: step 9797, loss 0.52475.
Train: 2018-07-31T01:05:55.552321: step 9798, loss 0.524635.
Train: 2018-07-31T01:05:55.692938: step 9799, loss 0.516678.
Train: 2018-07-31T01:05:55.849128: step 9800, loss 0.578887.
Test: 2018-07-31T01:05:56.083473: step 9800, loss 0.550059.
Train: 2018-07-31T01:05:56.833272: step 9801, loss 0.563197.
Train: 2018-07-31T01:05:56.973863: step 9802, loss 0.57887.
Train: 2018-07-31T01:05:57.114456: step 9803, loss 0.563086.
Train: 2018-07-31T01:05:57.255072: step 9804, loss 0.570952.
Train: 2018-07-31T01:05:57.395664: step 9805, loss 0.562999.
Train: 2018-07-31T01:05:57.551853: step 9806, loss 0.602706.
Train: 2018-07-31T01:05:57.708066: step 9807, loss 0.626614.
Train: 2018-07-31T01:05:57.848658: step 9808, loss 0.475437.
Train: 2018-07-31T01:05:58.004897: step 9809, loss 0.634659.
Train: 2018-07-31T01:05:58.145464: step 9810, loss 0.554944.
Test: 2018-07-31T01:05:58.395405: step 9810, loss 0.549547.
Train: 2018-07-31T01:05:58.536004: step 9811, loss 0.578859.
Train: 2018-07-31T01:05:58.692211: step 9812, loss 0.538976.
Train: 2018-07-31T01:05:58.832803: step 9813, loss 0.57886.
Train: 2018-07-31T01:05:58.973420: step 9814, loss 0.538926.
Train: 2018-07-31T01:05:59.113987: step 9815, loss 0.528754.
Train: 2018-07-31T01:05:59.254604: step 9816, loss 0.570854.
Train: 2018-07-31T01:05:59.395170: step 9817, loss 0.538744.
Train: 2018-07-31T01:05:59.535788: step 9818, loss 0.546706.
Train: 2018-07-31T01:05:59.676380: step 9819, loss 0.538572.
Train: 2018-07-31T01:05:59.816947: step 9820, loss 0.586973.
Test: 2018-07-31T01:06:00.066921: step 9820, loss 0.54913.
Train: 2018-07-31T01:06:00.207499: step 9821, loss 0.611299.
Train: 2018-07-31T01:06:00.348073: step 9822, loss 0.570794.
Train: 2018-07-31T01:06:00.488690: step 9823, loss 0.570792.
Train: 2018-07-31T01:06:00.644880: step 9824, loss 0.570791.
Train: 2018-07-31T01:06:00.769876: step 9825, loss 0.619455.
Train: 2018-07-31T01:06:00.926066: step 9826, loss 0.522197.
Train: 2018-07-31T01:06:01.066655: step 9827, loss 0.554601.
Train: 2018-07-31T01:06:01.222869: step 9828, loss 0.603193.
Train: 2018-07-31T01:06:01.363486: step 9829, loss 0.489883.
Train: 2018-07-31T01:06:01.504053: step 9830, loss 0.489797.
Test: 2018-07-31T01:06:01.753995: step 9830, loss 0.549061.
Train: 2018-07-31T01:06:01.894610: step 9831, loss 0.652007.
Train: 2018-07-31T01:06:02.035179: step 9832, loss 0.546413.
Train: 2018-07-31T01:06:02.191392: step 9833, loss 0.530134.
Train: 2018-07-31T01:06:02.347605: step 9834, loss 0.57892.
Train: 2018-07-31T01:06:02.472600: step 9835, loss 0.530033.
Train: 2018-07-31T01:06:02.628790: step 9836, loss 0.578933.
Train: 2018-07-31T01:06:02.785027: step 9837, loss 0.587109.
Train: 2018-07-31T01:06:02.925594: step 9838, loss 0.587114.
Train: 2018-07-31T01:06:03.066186: step 9839, loss 0.505408.
Train: 2018-07-31T01:06:03.206778: step 9840, loss 0.570767.
Test: 2018-07-31T01:06:03.456733: step 9840, loss 0.548871.
Train: 2018-07-31T01:06:03.597313: step 9841, loss 0.59532.
Train: 2018-07-31T01:06:03.737905: step 9842, loss 0.538025.
Train: 2018-07-31T01:06:03.878495: step 9843, loss 0.546191.
Train: 2018-07-31T01:06:04.034731: step 9844, loss 0.578952.
Train: 2018-07-31T01:06:04.175326: step 9845, loss 0.595331.
Train: 2018-07-31T01:06:04.331515: step 9846, loss 0.570823.
Train: 2018-07-31T01:06:04.472132: step 9847, loss 0.505294.
Train: 2018-07-31T01:06:04.612724: step 9848, loss 0.578991.
Train: 2018-07-31T01:06:04.768937: step 9849, loss 0.595344.
Train: 2018-07-31T01:06:04.909529: step 9850, loss 0.5462.
Test: 2018-07-31T01:06:05.159455: step 9850, loss 0.548868.
Train: 2018-07-31T01:06:05.315660: step 9851, loss 0.578951.
Train: 2018-07-31T01:06:05.471898: step 9852, loss 0.58713.
Train: 2018-07-31T01:06:05.612490: step 9853, loss 0.546251.
Train: 2018-07-31T01:06:05.753056: step 9854, loss 0.554435.
Train: 2018-07-31T01:06:05.909272: step 9855, loss 0.595263.
Train: 2018-07-31T01:06:06.049888: step 9856, loss 0.554464.
Train: 2018-07-31T01:06:06.190480: step 9857, loss 0.570776.
Train: 2018-07-31T01:06:06.331047: step 9858, loss 0.521937.
Train: 2018-07-31T01:06:06.487261: step 9859, loss 0.587061.
Train: 2018-07-31T01:06:06.627870: step 9860, loss 0.57078.
Test: 2018-07-31T01:06:06.862172: step 9860, loss 0.549028.
Train: 2018-07-31T01:06:07.018387: step 9861, loss 0.570782.
Train: 2018-07-31T01:06:07.174600: step 9862, loss 0.603302.
Train: 2018-07-31T01:06:07.315191: step 9863, loss 0.51398.
Train: 2018-07-31T01:06:07.471406: step 9864, loss 0.57891.
Train: 2018-07-31T01:06:07.611996: step 9865, loss 0.586999.
Train: 2018-07-31T01:06:07.768211: step 9866, loss 0.587017.
Train: 2018-07-31T01:06:07.908804: step 9867, loss 0.506143.
Train: 2018-07-31T01:06:08.049412: step 9868, loss 0.546538.
Train: 2018-07-31T01:06:08.189988: step 9869, loss 0.578892.
Train: 2018-07-31T01:06:08.346201: step 9870, loss 0.578892.
Test: 2018-07-31T01:06:08.580550: step 9870, loss 0.54917.
Train: 2018-07-31T01:06:08.736734: step 9871, loss 0.651682.
Train: 2018-07-31T01:06:08.877351: step 9872, loss 0.603088.
Train: 2018-07-31T01:06:09.017919: step 9873, loss 0.603005.
Train: 2018-07-31T01:06:09.158511: step 9874, loss 0.562839.
Train: 2018-07-31T01:06:09.299103: step 9875, loss 0.506974.
Train: 2018-07-31T01:06:09.439694: step 9876, loss 0.546956.
Train: 2018-07-31T01:06:09.564690: step 9877, loss 0.578859.
Train: 2018-07-31T01:06:09.720903: step 9878, loss 0.539048.
Train: 2018-07-31T01:06:09.877092: step 9879, loss 0.570898.
Train: 2018-07-31T01:06:10.017709: step 9880, loss 0.578859.
Test: 2018-07-31T01:06:10.267656: step 9880, loss 0.549623.
Train: 2018-07-31T01:06:10.423840: step 9881, loss 0.570903.
Train: 2018-07-31T01:06:10.564438: step 9882, loss 0.62657.
Train: 2018-07-31T01:06:10.705024: step 9883, loss 0.531238.
Train: 2018-07-31T01:06:10.845614: step 9884, loss 0.59472.
Train: 2018-07-31T01:06:10.986232: step 9885, loss 0.539254.
Train: 2018-07-31T01:06:11.126799: step 9886, loss 0.499672.
Train: 2018-07-31T01:06:11.283012: step 9887, loss 0.547176.
Train: 2018-07-31T01:06:11.423628: step 9888, loss 0.515228.
Train: 2018-07-31T01:06:11.564221: step 9889, loss 0.570801.
Train: 2018-07-31T01:06:11.704789: step 9890, loss 0.506673.
Test: 2018-07-31T01:06:11.939110: step 9890, loss 0.549075.
Train: 2018-07-31T01:06:12.095323: step 9891, loss 0.506163.
Train: 2018-07-31T01:06:12.235915: step 9892, loss 0.562255.
Train: 2018-07-31T01:06:12.376507: step 9893, loss 0.604006.
Train: 2018-07-31T01:06:12.517100: step 9894, loss 0.525607.
Train: 2018-07-31T01:06:12.657692: step 9895, loss 0.457402.
Train: 2018-07-31T01:06:12.798283: step 9896, loss 0.537902.
Train: 2018-07-31T01:06:12.938875: step 9897, loss 0.515131.
Train: 2018-07-31T01:06:13.095089: step 9898, loss 0.600113.
Train: 2018-07-31T01:06:13.220058: step 9899, loss 0.515113.
Train: 2018-07-31T01:06:13.376273: step 9900, loss 0.488893.
Test: 2018-07-31T01:06:13.610623: step 9900, loss 0.547532.
Train: 2018-07-31T01:06:14.360419: step 9901, loss 0.460324.
Train: 2018-07-31T01:06:14.501010: step 9902, loss 0.672796.
Train: 2018-07-31T01:06:14.641602: step 9903, loss 0.587803.
Train: 2018-07-31T01:06:14.782194: step 9904, loss 0.505366.
Train: 2018-07-31T01:06:14.922786: step 9905, loss 0.583183.
Train: 2018-07-31T01:06:15.063377: step 9906, loss 0.531447.
Train: 2018-07-31T01:06:15.203970: step 9907, loss 0.564245.
Train: 2018-07-31T01:06:15.375841: step 9908, loss 0.631865.
Train: 2018-07-31T01:06:15.516421: step 9909, loss 0.518275.
Train: 2018-07-31T01:06:15.656989: step 9910, loss 0.66558.
Test: 2018-07-31T01:06:15.906960: step 9910, loss 0.548166.
Train: 2018-07-31T01:06:16.078789: step 9911, loss 0.55354.
Train: 2018-07-31T01:06:16.219381: step 9912, loss 0.437543.
Train: 2018-07-31T01:06:16.375570: step 9913, loss 0.586953.
Train: 2018-07-31T01:06:16.516163: step 9914, loss 0.619666.
Train: 2018-07-31T01:06:16.656778: step 9915, loss 0.562837.
Train: 2018-07-31T01:06:16.828589: step 9916, loss 0.538544.
Train: 2018-07-31T01:06:16.984827: step 9917, loss 0.578349.
Train: 2018-07-31T01:06:17.125395: step 9918, loss 0.481473.
Train: 2018-07-31T01:06:17.266005: step 9919, loss 0.586706.
Train: 2018-07-31T01:06:17.422202: step 9920, loss 0.571388.
Test: 2018-07-31T01:06:17.656521: step 9920, loss 0.549234.
Train: 2018-07-31T01:06:17.797144: step 9921, loss 0.587036.
Train: 2018-07-31T01:06:17.937743: step 9922, loss 0.538362.
Train: 2018-07-31T01:06:18.093942: step 9923, loss 0.538338.
Train: 2018-07-31T01:06:18.234511: step 9924, loss 0.54651.
Train: 2018-07-31T01:06:18.375126: step 9925, loss 0.579292.
Train: 2018-07-31T01:06:18.531340: step 9926, loss 0.514342.
Train: 2018-07-31T01:06:18.671907: step 9927, loss 0.571122.
Train: 2018-07-31T01:06:18.812501: step 9928, loss 0.55465.
Train: 2018-07-31T01:06:18.953116: step 9929, loss 0.611554.
Train: 2018-07-31T01:06:19.093720: step 9930, loss 0.627471.
Test: 2018-07-31T01:06:19.343649: step 9930, loss 0.54918.
Train: 2018-07-31T01:06:19.499840: step 9931, loss 0.562721.
Train: 2018-07-31T01:06:19.640448: step 9932, loss 0.53855.
Train: 2018-07-31T01:06:19.781023: step 9933, loss 0.538564.
Train: 2018-07-31T01:06:19.921639: step 9934, loss 0.578859.
Train: 2018-07-31T01:06:20.062231: step 9935, loss 0.570806.
Train: 2018-07-31T01:06:20.202799: step 9936, loss 0.635272.
Train: 2018-07-31T01:06:20.343391: step 9937, loss 0.522581.
Train: 2018-07-31T01:06:20.483982: step 9938, loss 0.490482.
Train: 2018-07-31T01:06:20.624575: step 9939, loss 0.57083.
Train: 2018-07-31T01:06:20.780789: step 9940, loss 0.514459.
Test: 2018-07-31T01:06:21.015139: step 9940, loss 0.549231.
Train: 2018-07-31T01:06:21.155702: step 9941, loss 0.546607.
Train: 2018-07-31T01:06:21.296293: step 9942, loss 0.554627.
Train: 2018-07-31T01:06:21.452506: step 9943, loss 0.651861.
Train: 2018-07-31T01:06:21.608721: step 9944, loss 0.546474.
Train: 2018-07-31T01:06:21.749337: step 9945, loss 0.63567.
Train: 2018-07-31T01:06:21.905550: step 9946, loss 0.570797.
Train: 2018-07-31T01:06:22.046116: step 9947, loss 0.554629.
Train: 2018-07-31T01:06:22.202354: step 9948, loss 0.55465.
Train: 2018-07-31T01:06:22.342947: step 9949, loss 0.586959.
Train: 2018-07-31T01:06:22.499138: step 9950, loss 0.586946.
Test: 2018-07-31T01:06:22.733487: step 9950, loss 0.549299.
Train: 2018-07-31T01:06:22.889671: step 9951, loss 0.530565.
Train: 2018-07-31T01:06:23.030286: step 9952, loss 0.53059.
Train: 2018-07-31T01:06:23.170879: step 9953, loss 0.611078.
Train: 2018-07-31T01:06:23.311448: step 9954, loss 0.514521.
Train: 2018-07-31T01:06:23.467659: step 9955, loss 0.586924.
Train: 2018-07-31T01:06:23.608269: step 9956, loss 0.578875.
Train: 2018-07-31T01:06:23.748844: step 9957, loss 0.538648.
Train: 2018-07-31T01:06:23.905058: step 9958, loss 0.530587.
Train: 2018-07-31T01:06:24.030028: step 9959, loss 0.546649.
Train: 2018-07-31T01:06:24.170620: step 9960, loss 0.530466.
Test: 2018-07-31T01:06:24.404973: step 9960, loss 0.549172.
Train: 2018-07-31T01:06:24.561155: step 9961, loss 0.595065.
Train: 2018-07-31T01:06:24.701745: step 9962, loss 0.586993.
Train: 2018-07-31T01:06:24.842337: step 9963, loss 0.562694.
Train: 2018-07-31T01:06:24.982930: step 9964, loss 0.562688.
Train: 2018-07-31T01:06:25.123547: step 9965, loss 0.603233.
Train: 2018-07-31T01:06:25.279736: step 9966, loss 0.63186.
Train: 2018-07-31T01:06:25.435972: step 9967, loss 0.570802.
Train: 2018-07-31T01:06:25.576541: step 9968, loss 0.562739.
Train: 2018-07-31T01:06:25.717160: step 9969, loss 0.619172.
Train: 2018-07-31T01:06:25.857725: step 9970, loss 0.514591.
Test: 2018-07-31T01:06:26.107667: step 9970, loss 0.549388.
Train: 2018-07-31T01:06:26.248304: step 9971, loss 0.602941.
Train: 2018-07-31T01:06:26.388852: step 9972, loss 0.618899.
Train: 2018-07-31T01:06:26.545089: step 9973, loss 0.522993.
Train: 2018-07-31T01:06:26.685680: step 9974, loss 0.570892.
Train: 2018-07-31T01:06:26.826273: step 9975, loss 0.562952.
Train: 2018-07-31T01:06:26.998083: step 9976, loss 0.555032.
Train: 2018-07-31T01:06:27.138675: step 9977, loss 0.594729.
Train: 2018-07-31T01:06:27.279267: step 9978, loss 0.523397.
Train: 2018-07-31T01:06:27.419858: step 9979, loss 0.531328.
Train: 2018-07-31T01:06:27.560460: step 9980, loss 0.6185.
Test: 2018-07-31T01:06:27.794803: step 9980, loss 0.549741.
Train: 2018-07-31T01:06:27.950986: step 9981, loss 0.610556.
Train: 2018-07-31T01:06:28.107198: step 9982, loss 0.531389.
Train: 2018-07-31T01:06:28.247789: step 9983, loss 0.539318.
Train: 2018-07-31T01:06:28.388412: step 9984, loss 0.531389.
Train: 2018-07-31T01:06:28.544596: step 9985, loss 0.531328.
Train: 2018-07-31T01:06:28.685188: step 9986, loss 0.618554.
Train: 2018-07-31T01:06:28.825804: step 9987, loss 0.539135.
Train: 2018-07-31T01:06:28.966373: step 9988, loss 0.56295.
Train: 2018-07-31T01:06:29.106989: step 9989, loss 0.53903.
Train: 2018-07-31T01:06:29.263176: step 9990, loss 0.58684.
Test: 2018-07-31T01:06:29.497499: step 9990, loss 0.5495.
Train: 2018-07-31T01:06:29.653711: step 9991, loss 0.554889.
Train: 2018-07-31T01:06:29.794327: step 9992, loss 0.522844.
Train: 2018-07-31T01:06:29.934894: step 9993, loss 0.514693.
Train: 2018-07-31T01:06:30.075487: step 9994, loss 0.546676.
Train: 2018-07-31T01:06:30.231700: step 9995, loss 0.62735.
Train: 2018-07-31T01:06:30.372318: step 9996, loss 0.522256.
Train: 2018-07-31T01:06:30.528507: step 9997, loss 0.489683.
Train: 2018-07-31T01:06:30.669122: step 9998, loss 0.546347.
Train: 2018-07-31T01:06:30.825312: step 9999, loss 0.570764.
Train: 2018-07-31T01:06:30.965903: step 10000, loss 0.488718.
Test: 2018-07-31T01:06:31.200250: step 10000, loss 0.548706.
Train: 2018-07-31T01:06:31.934427: step 10001, loss 0.636694.
Train: 2018-07-31T01:06:32.075044: step 10002, loss 0.545969.
Train: 2018-07-31T01:06:32.215610: step 10003, loss 0.562451.
Train: 2018-07-31T01:06:32.356202: step 10004, loss 0.628877.
Train: 2018-07-31T01:06:32.496795: step 10005, loss 0.62891.
Train: 2018-07-31T01:06:32.653008: step 10006, loss 0.504396.
Train: 2018-07-31T01:06:32.793618: step 10007, loss 0.554189.
Train: 2018-07-31T01:06:32.934193: step 10008, loss 0.570759.
Train: 2018-07-31T01:06:33.074810: step 10009, loss 0.570772.
Train: 2018-07-31T01:06:33.215376: step 10010, loss 0.562454.
Test: 2018-07-31T01:06:33.449727: step 10010, loss 0.548588.
Train: 2018-07-31T01:06:33.605911: step 10011, loss 0.545907.
Train: 2018-07-31T01:06:33.746527: step 10012, loss 0.529333.
Train: 2018-07-31T01:06:33.887095: step 10013, loss 0.603923.
Train: 2018-07-31T01:06:34.027686: step 10014, loss 0.521049.
Train: 2018-07-31T01:06:34.183900: step 10015, loss 0.521017.
Train: 2018-07-31T01:06:34.324516: step 10016, loss 0.512655.
Train: 2018-07-31T01:06:34.465108: step 10017, loss 0.562459.
Train: 2018-07-31T01:06:34.605701: step 10018, loss 0.595767.
Train: 2018-07-31T01:06:34.746293: step 10019, loss 0.57911.
Train: 2018-07-31T01:06:34.886861: step 10020, loss 0.520721.
Test: 2018-07-31T01:06:35.136832: step 10020, loss 0.548436.
Train: 2018-07-31T01:06:35.277393: step 10021, loss 0.587467.
Train: 2018-07-31T01:06:35.418011: step 10022, loss 0.529013.
Train: 2018-07-31T01:06:35.558602: step 10023, loss 0.528981.
Train: 2018-07-31T01:06:35.714792: step 10024, loss 0.520558.
Train: 2018-07-31T01:06:35.855385: step 10025, loss 0.579168.
Train: 2018-07-31T01:06:35.995975: step 10026, loss 0.570786.
Train: 2018-07-31T01:06:36.136568: step 10027, loss 0.638027.
Train: 2018-07-31T01:06:36.292782: step 10028, loss 0.528807.
Train: 2018-07-31T01:06:36.433374: step 10029, loss 0.520429.
Train: 2018-07-31T01:06:36.573990: step 10030, loss 0.520408.
Test: 2018-07-31T01:06:36.808318: step 10030, loss 0.548304.
Train: 2018-07-31T01:06:36.964500: step 10031, loss 0.54557.
Train: 2018-07-31T01:06:37.105115: step 10032, loss 0.570795.
Train: 2018-07-31T01:06:37.261306: step 10033, loss 0.562374.
Train: 2018-07-31T01:06:37.417542: step 10034, loss 0.503368.
Train: 2018-07-31T01:06:37.558135: step 10035, loss 0.613023.
Train: 2018-07-31T01:06:37.698726: step 10036, loss 0.638366.
Train: 2018-07-31T01:06:37.839318: step 10037, loss 0.612952.
Train: 2018-07-31T01:06:37.995506: step 10038, loss 0.478321.
Train: 2018-07-31T01:06:38.136099: step 10039, loss 0.63798.
Train: 2018-07-31T01:06:38.292313: step 10040, loss 0.587532.
Test: 2018-07-31T01:06:38.526633: step 10040, loss 0.548433.
Train: 2018-07-31T01:06:38.667224: step 10041, loss 0.579121.
Train: 2018-07-31T01:06:38.807842: step 10042, loss 0.554113.
Train: 2018-07-31T01:06:38.948411: step 10043, loss 0.545856.
Train: 2018-07-31T01:06:39.104622: step 10044, loss 0.545911.
Train: 2018-07-31T01:06:39.260836: step 10045, loss 0.504618.
Train: 2018-07-31T01:06:39.401429: step 10046, loss 0.61208.
Train: 2018-07-31T01:06:39.542021: step 10047, loss 0.562504.
Train: 2018-07-31T01:06:39.682642: step 10048, loss 0.6202.
Train: 2018-07-31T01:06:39.838827: step 10049, loss 0.578977.
Train: 2018-07-31T01:06:39.979443: step 10050, loss 0.628127.
Test: 2018-07-31T01:06:40.213739: step 10050, loss 0.548943.
Train: 2018-07-31T01:06:40.369953: step 10051, loss 0.448357.
Train: 2018-07-31T01:06:40.510567: step 10052, loss 0.595232.
Train: 2018-07-31T01:06:40.651135: step 10053, loss 0.619612.
Train: 2018-07-31T01:06:40.791727: step 10054, loss 0.481521.
Train: 2018-07-31T01:06:40.947942: step 10055, loss 0.651894.
Train: 2018-07-31T01:06:41.088550: step 10056, loss 0.595069.
Train: 2018-07-31T01:06:41.244746: step 10057, loss 0.530502.
Train: 2018-07-31T01:06:41.400961: step 10058, loss 0.570828.
Train: 2018-07-31T01:06:41.541552: step 10059, loss 0.490524.
Train: 2018-07-31T01:06:41.682143: step 10060, loss 0.570838.
Test: 2018-07-31T01:06:41.932117: step 10060, loss 0.549354.
Train: 2018-07-31T01:06:42.072678: step 10061, loss 0.643128.
Train: 2018-07-31T01:06:42.213295: step 10062, loss 0.57085.
Train: 2018-07-31T01:06:42.369484: step 10063, loss 0.53085.
Train: 2018-07-31T01:06:42.510099: step 10064, loss 0.506896.
Train: 2018-07-31T01:06:42.650667: step 10065, loss 0.610874.
Train: 2018-07-31T01:06:42.791278: step 10066, loss 0.554864.
Train: 2018-07-31T01:06:42.931875: step 10067, loss 0.64286.
Train: 2018-07-31T01:06:43.072472: step 10068, loss 0.546923.
Train: 2018-07-31T01:06:43.213035: step 10069, loss 0.53101.
Train: 2018-07-31T01:06:43.369250: step 10070, loss 0.610754.
Test: 2018-07-31T01:06:43.603599: step 10070, loss 0.549594.
Train: 2018-07-31T01:06:43.744162: step 10071, loss 0.507185.
Train: 2018-07-31T01:06:43.900375: step 10072, loss 0.499189.
Train: 2018-07-31T01:06:44.040967: step 10073, loss 0.562894.
Train: 2018-07-31T01:06:44.181582: step 10074, loss 0.61086.
Train: 2018-07-31T01:06:44.322175: step 10075, loss 0.522832.
Train: 2018-07-31T01:06:44.478389: step 10076, loss 0.61094.
Train: 2018-07-31T01:06:44.618956: step 10077, loss 0.610955.
Train: 2018-07-31T01:06:44.759595: step 10078, loss 0.610931.
Train: 2018-07-31T01:06:44.900140: step 10079, loss 0.578864.
Train: 2018-07-31T01:06:45.040731: step 10080, loss 0.514958.
Test: 2018-07-31T01:06:45.290703: step 10080, loss 0.549518.
Train: 2018-07-31T01:06:45.431265: step 10081, loss 0.594831.
Train: 2018-07-31T01:06:45.571858: step 10082, loss 0.530998.
Train: 2018-07-31T01:06:45.712449: step 10083, loss 0.562906.
Train: 2018-07-31T01:06:45.868663: step 10084, loss 0.554926.
Train: 2018-07-31T01:06:46.009280: step 10085, loss 0.522992.
Train: 2018-07-31T01:06:46.149848: step 10086, loss 0.522912.
Train: 2018-07-31T01:06:46.290464: step 10087, loss 0.522781.
Train: 2018-07-31T01:06:46.446653: step 10088, loss 0.578872.
Train: 2018-07-31T01:06:46.587245: step 10089, loss 0.457997.
Train: 2018-07-31T01:06:46.727862: step 10090, loss 0.562699.
Test: 2018-07-31T01:06:46.962188: step 10090, loss 0.549025.
Train: 2018-07-31T01:06:47.118372: step 10091, loss 0.570781.
Train: 2018-07-31T01:06:47.258962: step 10092, loss 0.5871.
Train: 2018-07-31T01:06:47.399579: step 10093, loss 0.669019.
Train: 2018-07-31T01:06:47.540172: step 10094, loss 0.521637.
Train: 2018-07-31T01:06:47.680739: step 10095, loss 0.521588.
Train: 2018-07-31T01:06:47.852574: step 10096, loss 0.529709.
Train: 2018-07-31T01:06:47.993167: step 10097, loss 0.521381.
Train: 2018-07-31T01:06:48.133759: step 10098, loss 0.570756.
Train: 2018-07-31T01:06:48.289971: step 10099, loss 0.603852.
Train: 2018-07-31T01:06:48.430564: step 10100, loss 0.55419.
Test: 2018-07-31T01:06:48.664911: step 10100, loss 0.548576.
Train: 2018-07-31T01:06:49.445975: step 10101, loss 0.520999.
Train: 2018-07-31T01:06:49.586568: step 10102, loss 0.520907.
Train: 2018-07-31T01:06:49.758378: step 10103, loss 0.554104.
Train: 2018-07-31T01:06:49.883349: step 10104, loss 0.52902.
Train: 2018-07-31T01:06:50.023940: step 10105, loss 0.629384.
Train: 2018-07-31T01:06:50.164533: step 10106, loss 0.52888.
Train: 2018-07-31T01:06:50.305125: step 10107, loss 0.562392.
Train: 2018-07-31T01:06:50.445716: step 10108, loss 0.570787.
Train: 2018-07-31T01:06:50.586309: step 10109, loss 0.596005.
Train: 2018-07-31T01:06:50.711304: step 10110, loss 0.562385.
Test: 2018-07-31T01:06:50.961223: step 10110, loss 0.548321.
Train: 2018-07-31T01:06:51.101838: step 10111, loss 0.545589.
Train: 2018-07-31T01:06:51.258050: step 10112, loss 0.579183.
Train: 2018-07-31T01:06:51.414240: step 10113, loss 0.545608.
Train: 2018-07-31T01:06:51.554832: step 10114, loss 0.604335.
Train: 2018-07-31T01:06:51.694812: step 10115, loss 0.621035.
Train: 2018-07-31T01:06:51.835406: step 10116, loss 0.529003.
Train: 2018-07-31T01:06:51.975996: step 10117, loss 0.669154.
Train: 2018-07-31T01:06:52.116589: step 10118, loss 0.645488.
Train: 2018-07-31T01:06:52.257180: step 10119, loss 0.570756.
Train: 2018-07-31T01:06:52.397772: step 10120, loss 0.628236.
Test: 2018-07-31T01:06:52.647745: step 10120, loss 0.548953.
Train: 2018-07-31T01:06:52.788315: step 10121, loss 0.529985.
Train: 2018-07-31T01:06:52.944522: step 10122, loss 0.481513.
Train: 2018-07-31T01:06:53.085137: step 10123, loss 0.578894.
Train: 2018-07-31T01:06:53.225704: step 10124, loss 0.538524.
Train: 2018-07-31T01:06:53.366314: step 10125, loss 0.562765.
Train: 2018-07-31T01:06:53.522509: step 10126, loss 0.578874.
Train: 2018-07-31T01:06:53.663102: step 10127, loss 0.610989.
Train: 2018-07-31T01:06:53.803694: step 10128, loss 0.538823.
Train: 2018-07-31T01:06:53.944286: step 10129, loss 0.562874.
Train: 2018-07-31T01:06:54.084903: step 10130, loss 0.602809.
Test: 2018-07-31T01:06:54.334850: step 10130, loss 0.549591.
Train: 2018-07-31T01:06:54.475411: step 10131, loss 0.539033.
Train: 2018-07-31T01:06:54.631626: step 10132, loss 0.554993.
Train: 2018-07-31T01:06:54.772217: step 10133, loss 0.57091.
Train: 2018-07-31T01:06:54.928431: step 10134, loss 0.531204.
Train: 2018-07-31T01:06:55.069022: step 10135, loss 0.594747.
Train: 2018-07-31T01:06:55.225261: step 10136, loss 0.539157.
Train: 2018-07-31T01:06:55.381449: step 10137, loss 0.531201.
Train: 2018-07-31T01:06:55.537663: step 10138, loss 0.578858.
Train: 2018-07-31T01:06:55.662651: step 10139, loss 0.554981.
Train: 2018-07-31T01:06:55.818848: step 10140, loss 0.531054.
Test: 2018-07-31T01:06:56.053193: step 10140, loss 0.549527.
Train: 2018-07-31T01:06:56.193777: step 10141, loss 0.554913.
Train: 2018-07-31T01:06:56.334351: step 10142, loss 0.514874.
Train: 2018-07-31T01:06:56.474943: step 10143, loss 0.58689.
Train: 2018-07-31T01:06:56.615536: step 10144, loss 0.643211.
Train: 2018-07-31T01:06:56.756127: step 10145, loss 0.506492.
Train: 2018-07-31T01:06:56.912340: step 10146, loss 0.586933.
Train: 2018-07-31T01:06:57.052957: step 10147, loss 0.57888.
Train: 2018-07-31T01:06:57.193550: step 10148, loss 0.538554.
Train: 2018-07-31T01:06:57.349739: step 10149, loss 0.554662.
Train: 2018-07-31T01:06:57.490330: step 10150, loss 0.586975.
Test: 2018-07-31T01:06:57.724652: step 10150, loss 0.549159.
Train: 2018-07-31T01:06:57.880863: step 10151, loss 0.595068.
Train: 2018-07-31T01:06:58.021474: step 10152, loss 0.684009.
Train: 2018-07-31T01:06:58.162072: step 10153, loss 0.546635.
Train: 2018-07-31T01:06:58.302665: step 10154, loss 0.594959.
Train: 2018-07-31T01:06:58.458854: step 10155, loss 0.570847.
Train: 2018-07-31T01:06:58.599445: step 10156, loss 0.562865.
Train: 2018-07-31T01:06:58.755659: step 10157, loss 0.594822.
Train: 2018-07-31T01:06:58.896277: step 10158, loss 0.554982.
Train: 2018-07-31T01:06:59.036842: step 10159, loss 0.610626.
Train: 2018-07-31T01:06:59.193094: step 10160, loss 0.507595.
Test: 2018-07-31T01:06:59.427407: step 10160, loss 0.549795.
Train: 2018-07-31T01:06:59.583615: step 10161, loss 0.570951.
Train: 2018-07-31T01:06:59.724207: step 10162, loss 0.570964.
Train: 2018-07-31T01:06:59.880397: step 10163, loss 0.586756.
Train: 2018-07-31T01:07:00.021013: step 10164, loss 0.5631.
Train: 2018-07-31T01:07:00.161579: step 10165, loss 0.547368.
Train: 2018-07-31T01:07:00.302172: step 10166, loss 0.555251.
Train: 2018-07-31T01:07:00.458410: step 10167, loss 0.58674.
Train: 2018-07-31T01:07:00.599002: step 10168, loss 0.492295.
Train: 2018-07-31T01:07:00.739569: step 10169, loss 0.594631.
Train: 2018-07-31T01:07:00.880161: step 10170, loss 0.515738.
Test: 2018-07-31T01:07:01.130128: step 10170, loss 0.549799.
Train: 2018-07-31T01:07:01.270720: step 10171, loss 0.539322.
Train: 2018-07-31T01:07:01.411337: step 10172, loss 0.618505.
Train: 2018-07-31T01:07:01.551923: step 10173, loss 0.586797.
Train: 2018-07-31T01:07:01.692496: step 10174, loss 0.586802.
Train: 2018-07-31T01:07:01.848714: step 10175, loss 0.483524.
Train: 2018-07-31T01:07:01.989277: step 10176, loss 0.610707.
Train: 2018-07-31T01:07:02.129868: step 10177, loss 0.523066.
Train: 2018-07-31T01:07:02.286107: step 10178, loss 0.570878.
Train: 2018-07-31T01:07:02.426675: step 10179, loss 0.554795.
Train: 2018-07-31T01:07:02.582888: step 10180, loss 0.530613.
Test: 2018-07-31T01:07:02.817208: step 10180, loss 0.549165.
Train: 2018-07-31T01:07:02.973421: step 10181, loss 0.489706.
Train: 2018-07-31T01:07:03.114037: step 10182, loss 0.594929.
Train: 2018-07-31T01:07:03.270227: step 10183, loss 0.504118.
Train: 2018-07-31T01:07:03.410819: step 10184, loss 0.48511.
Train: 2018-07-31T01:07:03.551442: step 10185, loss 0.593974.
Train: 2018-07-31T01:07:03.707638: step 10186, loss 0.591879.
Train: 2018-07-31T01:07:03.848216: step 10187, loss 0.549079.
Train: 2018-07-31T01:07:03.988834: step 10188, loss 0.630965.
Train: 2018-07-31T01:07:04.129402: step 10189, loss 0.605796.
Train: 2018-07-31T01:07:04.269994: step 10190, loss 0.655602.
Test: 2018-07-31T01:07:04.504315: step 10190, loss 0.548594.
Train: 2018-07-31T01:07:04.644905: step 10191, loss 0.570725.
Train: 2018-07-31T01:07:04.785521: step 10192, loss 0.570614.
Train: 2018-07-31T01:07:04.926089: step 10193, loss 0.595243.
Train: 2018-07-31T01:07:05.066706: step 10194, loss 0.546462.
Train: 2018-07-31T01:07:05.207273: step 10195, loss 0.619329.
Train: 2018-07-31T01:07:05.347890: step 10196, loss 0.627221.
Train: 2018-07-31T01:07:05.488457: step 10197, loss 0.522744.
Train: 2018-07-31T01:07:05.629074: step 10198, loss 0.570871.
Train: 2018-07-31T01:07:05.769666: step 10199, loss 0.523101.
Train: 2018-07-31T01:07:05.910235: step 10200, loss 0.499343.
Test: 2018-07-31T01:07:06.160175: step 10200, loss 0.549635.
Train: 2018-07-31T01:07:06.894397: step 10201, loss 0.594764.
Train: 2018-07-31T01:07:07.050591: step 10202, loss 0.586807.
Train: 2018-07-31T01:07:07.191209: step 10203, loss 0.562976.
Train: 2018-07-31T01:07:07.331776: step 10204, loss 0.570923.
Train: 2018-07-31T01:07:07.472392: step 10205, loss 0.602649.
Train: 2018-07-31T01:07:07.628605: step 10206, loss 0.563022.
Train: 2018-07-31T01:07:07.769198: step 10207, loss 0.507675.
Train: 2018-07-31T01:07:07.925387: step 10208, loss 0.547206.
Train: 2018-07-31T01:07:08.081601: step 10209, loss 0.499646.
Train: 2018-07-31T01:07:08.222194: step 10210, loss 0.531206.
Test: 2018-07-31T01:07:08.472164: step 10210, loss 0.549578.
Train: 2018-07-31T01:07:08.612750: step 10211, loss 0.53105.
Train: 2018-07-31T01:07:08.768939: step 10212, loss 0.506874.
Train: 2018-07-31T01:07:08.909532: step 10213, loss 0.570834.
Train: 2018-07-31T01:07:09.081367: step 10214, loss 0.538522.
Train: 2018-07-31T01:07:09.221958: step 10215, loss 0.489708.
Train: 2018-07-31T01:07:09.362575: step 10216, loss 0.513688.
Train: 2018-07-31T01:07:09.518788: step 10217, loss 0.628206.
Train: 2018-07-31T01:07:09.659356: step 10218, loss 0.636675.
Train: 2018-07-31T01:07:09.799966: step 10219, loss 0.529479.
Train: 2018-07-31T01:07:09.956161: step 10220, loss 0.52938.
Test: 2018-07-31T01:07:10.190511: step 10220, loss 0.548562.
Train: 2018-07-31T01:07:10.331098: step 10221, loss 0.628848.
Train: 2018-07-31T01:07:10.502909: step 10222, loss 0.554147.
Train: 2018-07-31T01:07:10.643501: step 10223, loss 0.529189.
Train: 2018-07-31T01:07:10.784117: step 10224, loss 0.52913.
Train: 2018-07-31T01:07:10.924686: step 10225, loss 0.562424.
Train: 2018-07-31T01:07:11.065276: step 10226, loss 0.554056.
Train: 2018-07-31T01:07:11.205899: step 10227, loss 0.570775.
Train: 2018-07-31T01:07:11.362106: step 10228, loss 0.629433.
Train: 2018-07-31T01:07:11.502691: step 10229, loss 0.595898.
Train: 2018-07-31T01:07:11.658889: step 10230, loss 0.487155.
Test: 2018-07-31T01:07:11.893238: step 10230, loss 0.548402.
Train: 2018-07-31T01:07:12.049446: step 10231, loss 0.537318.
Train: 2018-07-31T01:07:12.190039: step 10232, loss 0.554037.
Train: 2018-07-31T01:07:12.330605: step 10233, loss 0.520531.
Train: 2018-07-31T01:07:12.471222: step 10234, loss 0.604323.
Train: 2018-07-31T01:07:12.611791: step 10235, loss 0.554008.
Train: 2018-07-31T01:07:12.752381: step 10236, loss 0.562393.
Train: 2018-07-31T01:07:12.893017: step 10237, loss 0.554005.
Train: 2018-07-31T01:07:13.033566: step 10238, loss 0.554004.
Train: 2018-07-31T01:07:13.174157: step 10239, loss 0.495275.
Train: 2018-07-31T01:07:13.330372: step 10240, loss 0.520378.
Test: 2018-07-31T01:07:13.564724: step 10240, loss 0.548277.
Train: 2018-07-31T01:07:13.705282: step 10241, loss 0.663403.
Train: 2018-07-31T01:07:13.845876: step 10242, loss 0.520307.
Train: 2018-07-31T01:07:13.986467: step 10243, loss 0.486626.
Train: 2018-07-31T01:07:14.127073: step 10244, loss 0.570802.
Train: 2018-07-31T01:07:14.283274: step 10245, loss 0.53704.
Train: 2018-07-31T01:07:14.423890: step 10246, loss 0.587724.
Train: 2018-07-31T01:07:14.580079: step 10247, loss 0.511602.
Train: 2018-07-31T01:07:14.720671: step 10248, loss 0.562354.
Train: 2018-07-31T01:07:14.876908: step 10249, loss 0.562351.
Train: 2018-07-31T01:07:15.017475: step 10250, loss 0.545373.
Test: 2018-07-31T01:07:15.251796: step 10250, loss 0.548119.
Train: 2018-07-31T01:07:15.408022: step 10251, loss 0.579337.
Train: 2018-07-31T01:07:15.548601: step 10252, loss 0.528356.
Train: 2018-07-31T01:07:15.704815: step 10253, loss 0.55384.
Train: 2018-07-31T01:07:15.845432: step 10254, loss 0.519794.
Train: 2018-07-31T01:07:15.986000: step 10255, loss 0.545305.
Train: 2018-07-31T01:07:16.126590: step 10256, loss 0.622062.
Train: 2018-07-31T01:07:16.282805: step 10257, loss 0.604982.
Train: 2018-07-31T01:07:16.439063: step 10258, loss 0.57937.
Train: 2018-07-31T01:07:16.595232: step 10259, loss 0.562343.
Train: 2018-07-31T01:07:16.735823: step 10260, loss 0.51144.
Test: 2018-07-31T01:07:16.970145: step 10260, loss 0.548153.
Train: 2018-07-31T01:07:17.126357: step 10261, loss 0.56237.
Train: 2018-07-31T01:07:17.266951: step 10262, loss 0.596232.
Train: 2018-07-31T01:07:17.423162: step 10263, loss 0.570816.
Train: 2018-07-31T01:07:17.579377: step 10264, loss 0.596116.
Train: 2018-07-31T01:07:17.704347: step 10265, loss 0.570797.
Train: 2018-07-31T01:07:17.860561: step 10266, loss 0.528829.
Train: 2018-07-31T01:07:18.001153: step 10267, loss 0.621027.
Train: 2018-07-31T01:07:18.141770: step 10268, loss 0.491177.
Train: 2018-07-31T01:07:18.282337: step 10269, loss 0.562427.
Train: 2018-07-31T01:07:18.422930: step 10270, loss 0.512482.
Test: 2018-07-31T01:07:18.657275: step 10270, loss 0.548497.
Train: 2018-07-31T01:07:18.797865: step 10271, loss 0.579087.
Train: 2018-07-31T01:07:18.954053: step 10272, loss 0.537487.
Train: 2018-07-31T01:07:19.094645: step 10273, loss 0.595713.
Train: 2018-07-31T01:07:19.250860: step 10274, loss 0.537521.
Train: 2018-07-31T01:07:19.391453: step 10275, loss 0.587372.
Train: 2018-07-31T01:07:19.547665: step 10276, loss 0.579056.
Train: 2018-07-31T01:07:19.688281: step 10277, loss 0.579044.
Train: 2018-07-31T01:07:19.828875: step 10278, loss 0.537669.
Train: 2018-07-31T01:07:19.969441: step 10279, loss 0.537704.
Train: 2018-07-31T01:07:20.125681: step 10280, loss 0.595535.
Test: 2018-07-31T01:07:20.359977: step 10280, loss 0.548691.
Train: 2018-07-31T01:07:20.516190: step 10281, loss 0.52951.
Train: 2018-07-31T01:07:20.656805: step 10282, loss 0.64497.
Train: 2018-07-31T01:07:20.812994: step 10283, loss 0.636576.
Train: 2018-07-31T01:07:20.953610: step 10284, loss 0.537982.
Train: 2018-07-31T01:07:21.094178: step 10285, loss 0.497227.
Train: 2018-07-31T01:07:21.266014: step 10286, loss 0.529961.
Train: 2018-07-31T01:07:21.406606: step 10287, loss 0.538132.
Train: 2018-07-31T01:07:21.547197: step 10288, loss 0.489143.
Train: 2018-07-31T01:07:21.687788: step 10289, loss 0.546229.
Train: 2018-07-31T01:07:21.828380: step 10290, loss 0.52158.
Test: 2018-07-31T01:07:22.078353: step 10290, loss 0.54877.
Train: 2018-07-31T01:07:22.265803: step 10291, loss 0.578979.
Train: 2018-07-31T01:07:22.437614: step 10292, loss 0.578996.
Train: 2018-07-31T01:07:22.593828: step 10293, loss 0.579008.
Train: 2018-07-31T01:07:22.734436: step 10294, loss 0.562498.
Train: 2018-07-31T01:07:22.875036: step 10295, loss 0.537697.
Train: 2018-07-31T01:07:23.015602: step 10296, loss 0.579031.
Train: 2018-07-31T01:07:23.156219: step 10297, loss 0.603875.
Train: 2018-07-31T01:07:23.296787: step 10298, loss 0.562481.
Train: 2018-07-31T01:07:23.437378: step 10299, loss 0.562485.
Train: 2018-07-31T01:07:23.577972: step 10300, loss 0.512886.
Test: 2018-07-31T01:07:23.827913: step 10300, loss 0.548631.
Train: 2018-07-31T01:07:24.546520: step 10301, loss 0.562484.
Train: 2018-07-31T01:07:24.702707: step 10302, loss 0.579032.
Train: 2018-07-31T01:07:24.843300: step 10303, loss 0.603859.
Train: 2018-07-31T01:07:24.983892: step 10304, loss 0.529423.
Train: 2018-07-31T01:07:25.124486: step 10305, loss 0.529434.
Train: 2018-07-31T01:07:25.280699: step 10306, loss 0.587293.
Train: 2018-07-31T01:07:25.421289: step 10307, loss 0.537691.
Train: 2018-07-31T01:07:25.561906: step 10308, loss 0.603831.
Train: 2018-07-31T01:07:25.702473: step 10309, loss 0.529445.
Train: 2018-07-31T01:07:25.858687: step 10310, loss 0.488133.
Test: 2018-07-31T01:07:26.093038: step 10310, loss 0.548621.
Train: 2018-07-31T01:07:26.249222: step 10311, loss 0.521101.
Train: 2018-07-31T01:07:26.389813: step 10312, loss 0.562463.
Train: 2018-07-31T01:07:26.546027: step 10313, loss 0.529201.
Train: 2018-07-31T01:07:26.686643: step 10314, loss 0.545767.
Train: 2018-07-31T01:07:26.827227: step 10315, loss 0.587476.
Train: 2018-07-31T01:07:26.967843: step 10316, loss 0.53731.
Train: 2018-07-31T01:07:27.108419: step 10317, loss 0.537254.
Train: 2018-07-31T01:07:27.264633: step 10318, loss 0.587582.
Train: 2018-07-31T01:07:27.405199: step 10319, loss 0.511935.
Train: 2018-07-31T01:07:27.545792: step 10320, loss 0.562374.
Test: 2018-07-31T01:07:27.795764: step 10320, loss 0.548235.
Train: 2018-07-31T01:07:27.936368: step 10321, loss 0.520176.
Train: 2018-07-31T01:07:28.076917: step 10322, loss 0.528532.
Train: 2018-07-31T01:07:28.217510: step 10323, loss 0.545395.
Train: 2018-07-31T01:07:28.358102: step 10324, loss 0.468854.
Train: 2018-07-31T01:07:28.498718: step 10325, loss 0.613541.
Train: 2018-07-31T01:07:28.639314: step 10326, loss 0.519573.
Train: 2018-07-31T01:07:28.795499: step 10327, loss 0.733859.
Train: 2018-07-31T01:07:28.936092: step 10328, loss 0.493826.
Train: 2018-07-31T01:07:29.076684: step 10329, loss 0.44246.
Train: 2018-07-31T01:07:29.217275: step 10330, loss 0.596662.
Test: 2018-07-31T01:07:29.467246: step 10330, loss 0.547949.
Train: 2018-07-31T01:07:29.623431: step 10331, loss 0.545157.
Train: 2018-07-31T01:07:29.764046: step 10332, loss 0.519343.
Train: 2018-07-31T01:07:29.904640: step 10333, loss 0.502055.
Train: 2018-07-31T01:07:30.045247: step 10334, loss 0.562339.
Train: 2018-07-31T01:07:30.185798: step 10335, loss 0.536398.
Train: 2018-07-31T01:07:30.342012: step 10336, loss 0.63166.
Train: 2018-07-31T01:07:30.498251: step 10337, loss 0.579674.
Train: 2018-07-31T01:07:30.654440: step 10338, loss 0.648928.
Train: 2018-07-31T01:07:30.810653: step 10339, loss 0.536433.
Train: 2018-07-31T01:07:30.951246: step 10340, loss 0.562337.
Test: 2018-07-31T01:07:31.185565: step 10340, loss 0.547937.
Train: 2018-07-31T01:07:31.341796: step 10341, loss 0.588127.
Train: 2018-07-31T01:07:31.482369: step 10342, loss 0.553762.
Train: 2018-07-31T01:07:31.622962: step 10343, loss 0.553786.
Train: 2018-07-31T01:07:31.779176: step 10344, loss 0.545279.
Train: 2018-07-31T01:07:31.919793: step 10345, loss 0.579368.
Train: 2018-07-31T01:07:32.060361: step 10346, loss 0.46044.
Train: 2018-07-31T01:07:32.200953: step 10347, loss 0.655746.
Train: 2018-07-31T01:07:32.341568: step 10348, loss 0.511531.
Train: 2018-07-31T01:07:32.497759: step 10349, loss 0.604659.
Train: 2018-07-31T01:07:32.638374: step 10350, loss 0.570807.
Test: 2018-07-31T01:07:32.888333: step 10350, loss 0.548271.
Train: 2018-07-31T01:07:33.028884: step 10351, loss 0.604483.
Train: 2018-07-31T01:07:33.169475: step 10352, loss 0.503627.
Train: 2018-07-31T01:07:33.310067: step 10353, loss 0.570778.
Train: 2018-07-31T01:07:33.450685: step 10354, loss 0.595865.
Train: 2018-07-31T01:07:33.591276: step 10355, loss 0.554082.
Train: 2018-07-31T01:07:33.731861: step 10356, loss 0.554115.
Train: 2018-07-31T01:07:33.872435: step 10357, loss 0.603989.
Train: 2018-07-31T01:07:34.013029: step 10358, loss 0.703306.
Train: 2018-07-31T01:07:34.169241: step 10359, loss 0.521337.
Train: 2018-07-31T01:07:34.309840: step 10360, loss 0.578963.
Test: 2018-07-31T01:07:34.559776: step 10360, loss 0.548928.
Train: 2018-07-31T01:07:34.700366: step 10361, loss 0.578936.
Train: 2018-07-31T01:07:34.872202: step 10362, loss 0.619569.
Train: 2018-07-31T01:07:35.012794: step 10363, loss 0.635514.
Train: 2018-07-31T01:07:35.153386: step 10364, loss 0.554759.
Train: 2018-07-31T01:07:35.309623: step 10365, loss 0.546888.
Train: 2018-07-31T01:07:35.450193: step 10366, loss 0.626605.
Train: 2018-07-31T01:07:35.575161: step 10367, loss 0.57886.
Train: 2018-07-31T01:07:35.715754: step 10368, loss 0.49226.
Train: 2018-07-31T01:07:35.856363: step 10369, loss 0.578872.
Train: 2018-07-31T01:07:36.012560: step 10370, loss 0.602372.
Test: 2018-07-31T01:07:36.262531: step 10370, loss 0.550205.
Train: 2018-07-31T01:07:36.418715: step 10371, loss 0.508636.
Train: 2018-07-31T01:07:36.574952: step 10372, loss 0.508729.
Train: 2018-07-31T01:07:36.715521: step 10373, loss 0.610091.
Train: 2018-07-31T01:07:36.856137: step 10374, loss 0.610077.
Train: 2018-07-31T01:07:37.012325: step 10375, loss 0.539975.
Train: 2018-07-31T01:07:37.152917: step 10376, loss 0.57112.
Train: 2018-07-31T01:07:37.293510: step 10377, loss 0.617797.
Train: 2018-07-31T01:07:37.434102: step 10378, loss 0.563374.
Train: 2018-07-31T01:07:37.574693: step 10379, loss 0.578914.
Train: 2018-07-31T01:07:37.730911: step 10380, loss 0.501407.
Test: 2018-07-31T01:07:37.965260: step 10380, loss 0.550406.
Train: 2018-07-31T01:07:38.105844: step 10381, loss 0.547882.
Train: 2018-07-31T01:07:38.262033: step 10382, loss 0.571139.
Train: 2018-07-31T01:07:38.402626: step 10383, loss 0.547782.
Train: 2018-07-31T01:07:38.543217: step 10384, loss 0.617867.
Train: 2018-07-31T01:07:38.683809: step 10385, loss 0.578893.
Train: 2018-07-31T01:07:38.824425: step 10386, loss 0.563289.
Train: 2018-07-31T01:07:38.980638: step 10387, loss 0.539863.
Train: 2018-07-31T01:07:39.136831: step 10388, loss 0.57107.
Train: 2018-07-31T01:07:39.261799: step 10389, loss 0.571057.
Train: 2018-07-31T01:07:39.402391: step 10390, loss 0.578878.
Test: 2018-07-31T01:07:39.652333: step 10390, loss 0.550068.
Train: 2018-07-31T01:07:39.792925: step 10391, loss 0.547518.
Train: 2018-07-31T01:07:39.933516: step 10392, loss 0.657372.
Train: 2018-07-31T01:07:40.105351: step 10393, loss 0.59456.
Train: 2018-07-31T01:07:40.245943: step 10394, loss 0.563217.
Train: 2018-07-31T01:07:40.386535: step 10395, loss 0.602349.
Train: 2018-07-31T01:07:40.527145: step 10396, loss 0.586697.
Train: 2018-07-31T01:07:40.667761: step 10397, loss 0.571102.
Train: 2018-07-31T01:07:40.808311: step 10398, loss 0.477762.
Train: 2018-07-31T01:07:40.964549: step 10399, loss 0.578898.
Train: 2018-07-31T01:07:41.105142: step 10400, loss 0.516561.
Test: 2018-07-31T01:07:41.355058: step 10400, loss 0.550198.
Train: 2018-07-31T01:07:42.058044: step 10401, loss 0.500814.
Train: 2018-07-31T01:07:42.214234: step 10402, loss 0.602384.
Train: 2018-07-31T01:07:42.354824: step 10403, loss 0.586726.
Train: 2018-07-31T01:07:42.495441: step 10404, loss 0.531654.
Train: 2018-07-31T01:07:42.651655: step 10405, loss 0.578863.
Train: 2018-07-31T01:07:42.792221: step 10406, loss 0.547237.
Train: 2018-07-31T01:07:42.948460: step 10407, loss 0.50753.
Train: 2018-07-31T01:07:43.089028: step 10408, loss 0.547039.
Train: 2018-07-31T01:07:43.229619: step 10409, loss 0.514978.
Train: 2018-07-31T01:07:43.370236: step 10410, loss 0.643051.
Test: 2018-07-31T01:07:43.604533: step 10410, loss 0.549321.
Train: 2018-07-31T01:07:43.745124: step 10411, loss 0.611041.
Train: 2018-07-31T01:07:43.885744: step 10412, loss 0.538624.
Train: 2018-07-31T01:07:44.026353: step 10413, loss 0.514375.
Train: 2018-07-31T01:07:44.182523: step 10414, loss 0.635481.
Train: 2018-07-31T01:07:44.338735: step 10415, loss 0.586982.
Train: 2018-07-31T01:07:44.479326: step 10416, loss 0.578892.
Train: 2018-07-31T01:07:44.619918: step 10417, loss 0.506092.
Train: 2018-07-31T01:07:44.776133: step 10418, loss 0.5627.
Train: 2018-07-31T01:07:44.916725: step 10419, loss 0.424334.
Train: 2018-07-31T01:07:45.057317: step 10420, loss 0.562638.
Test: 2018-07-31T01:07:45.307298: step 10420, loss 0.548913.
Train: 2018-07-31T01:07:45.463471: step 10421, loss 0.521741.
Train: 2018-07-31T01:07:45.604088: step 10422, loss 0.505109.
Train: 2018-07-31T01:07:45.744679: step 10423, loss 0.587253.
Train: 2018-07-31T01:07:45.885248: step 10424, loss 0.661851.
Train: 2018-07-31T01:07:46.025840: step 10425, loss 0.479548.
Train: 2018-07-31T01:07:46.182054: step 10426, loss 0.570761.
Train: 2018-07-31T01:07:46.322669: step 10427, loss 0.620775.
Train: 2018-07-31T01:07:46.463236: step 10428, loss 0.61247.
Train: 2018-07-31T01:07:46.603854: step 10429, loss 0.554093.
Train: 2018-07-31T01:07:46.760068: step 10430, loss 0.612425.
Test: 2018-07-31T01:07:47.009985: step 10430, loss 0.548511.
Train: 2018-07-31T01:07:47.166199: step 10431, loss 0.587399.
Train: 2018-07-31T01:07:47.306791: step 10432, loss 0.529253.
Train: 2018-07-31T01:07:47.431761: step 10433, loss 0.579048.
Train: 2018-07-31T01:07:47.572352: step 10434, loss 0.579034.
Train: 2018-07-31T01:07:47.697323: step 10435, loss 0.521183.
Train: 2018-07-31T01:07:47.837915: step 10436, loss 0.570756.
Train: 2018-07-31T01:07:47.978506: step 10437, loss 0.562509.
Train: 2018-07-31T01:07:48.134751: step 10438, loss 0.669629.
Train: 2018-07-31T01:07:48.275312: step 10439, loss 0.587184.
Train: 2018-07-31T01:07:48.400308: step 10440, loss 0.546218.
Test: 2018-07-31T01:07:48.650257: step 10440, loss 0.548949.
Train: 2018-07-31T01:07:48.790842: step 10441, loss 0.546295.
Train: 2018-07-31T01:07:48.947029: step 10442, loss 0.530074.
Train: 2018-07-31T01:07:49.087646: step 10443, loss 0.530129.
Train: 2018-07-31T01:07:49.228214: step 10444, loss 0.562656.
Train: 2018-07-31T01:07:49.368806: step 10445, loss 0.57891.
Train: 2018-07-31T01:07:49.509398: step 10446, loss 0.627627.
Train: 2018-07-31T01:07:49.649991: step 10447, loss 0.570795.
Train: 2018-07-31T01:07:49.806238: step 10448, loss 0.586978.
Train: 2018-07-31T01:07:49.946797: step 10449, loss 0.611155.
Train: 2018-07-31T01:07:50.087388: step 10450, loss 0.675382.
Test: 2018-07-31T01:07:50.337361: step 10450, loss 0.54947.
Train: 2018-07-31T01:07:50.477947: step 10451, loss 0.53887.
Train: 2018-07-31T01:07:50.634136: step 10452, loss 0.483286.
Train: 2018-07-31T01:07:50.774753: step 10453, loss 0.507309.
Train: 2018-07-31T01:07:50.915344: step 10454, loss 0.562961.
Train: 2018-07-31T01:07:51.071532: step 10455, loss 0.555013.
Train: 2018-07-31T01:07:51.212126: step 10456, loss 0.578858.
Train: 2018-07-31T01:07:51.352718: step 10457, loss 0.562957.
Train: 2018-07-31T01:07:51.493334: step 10458, loss 0.555002.
Train: 2018-07-31T01:07:51.633901: step 10459, loss 0.523169.
Train: 2018-07-31T01:07:51.774518: step 10460, loss 0.626664.
Test: 2018-07-31T01:07:52.024465: step 10460, loss 0.549583.
Train: 2018-07-31T01:07:52.165027: step 10461, loss 0.523091.
Train: 2018-07-31T01:07:52.305620: step 10462, loss 0.618734.
Train: 2018-07-31T01:07:52.446237: step 10463, loss 0.562915.
Train: 2018-07-31T01:07:52.618045: step 10464, loss 0.594802.
Train: 2018-07-31T01:07:52.774260: step 10465, loss 0.515141.
Train: 2018-07-31T01:07:52.930474: step 10466, loss 0.546983.
Train: 2018-07-31T01:07:53.071066: step 10467, loss 0.491113.
Train: 2018-07-31T01:07:53.211657: step 10468, loss 0.546868.
Train: 2018-07-31T01:07:53.352248: step 10469, loss 0.618978.
Train: 2018-07-31T01:07:53.492840: step 10470, loss 0.570838.
Test: 2018-07-31T01:07:53.742782: step 10470, loss 0.549321.
Train: 2018-07-31T01:07:53.883399: step 10471, loss 0.554747.
Train: 2018-07-31T01:07:54.039616: step 10472, loss 0.578877.
Train: 2018-07-31T01:07:54.180179: step 10473, loss 0.578879.
Train: 2018-07-31T01:07:54.336394: step 10474, loss 0.603068.
Train: 2018-07-31T01:07:54.477003: step 10475, loss 0.482179.
Train: 2018-07-31T01:07:54.617579: step 10476, loss 0.603095.
Train: 2018-07-31T01:07:54.773815: step 10477, loss 0.546589.
Train: 2018-07-31T01:07:54.930040: step 10478, loss 0.562726.
Train: 2018-07-31T01:07:55.070621: step 10479, loss 0.538455.
Train: 2018-07-31T01:07:55.211207: step 10480, loss 0.586994.
Test: 2018-07-31T01:07:55.461160: step 10480, loss 0.549121.
Train: 2018-07-31T01:07:55.601723: step 10481, loss 0.530279.
Train: 2018-07-31T01:07:55.757936: step 10482, loss 0.522103.
Train: 2018-07-31T01:07:55.898528: step 10483, loss 0.546385.
Train: 2018-07-31T01:07:56.039160: step 10484, loss 0.562623.
Train: 2018-07-31T01:07:56.179712: step 10485, loss 0.562601.
Train: 2018-07-31T01:07:56.320304: step 10486, loss 0.529844.
Train: 2018-07-31T01:07:56.460896: step 10487, loss 0.537944.
Train: 2018-07-31T01:07:56.601489: step 10488, loss 0.554305.
Train: 2018-07-31T01:07:56.742097: step 10489, loss 0.570756.
Train: 2018-07-31T01:07:56.882671: step 10490, loss 0.488107.
Test: 2018-07-31T01:07:57.132644: step 10490, loss 0.548575.
Train: 2018-07-31T01:07:57.273205: step 10491, loss 0.487824.
Train: 2018-07-31T01:07:57.413822: step 10492, loss 0.537435.
Train: 2018-07-31T01:07:57.554414: step 10493, loss 0.57915.
Train: 2018-07-31T01:07:57.710603: step 10494, loss 0.604393.
Train: 2018-07-31T01:07:57.851195: step 10495, loss 0.621315.
Train: 2018-07-31T01:07:58.007409: step 10496, loss 0.562373.
Train: 2018-07-31T01:07:58.132379: step 10497, loss 0.587654.
Train: 2018-07-31T01:07:58.304216: step 10498, loss 0.612917.
Train: 2018-07-31T01:07:58.444806: step 10499, loss 0.54556.
Train: 2018-07-31T01:07:58.585398: step 10500, loss 0.520387.
Test: 2018-07-31T01:07:58.819745: step 10500, loss 0.548325.
Train: 2018-07-31T01:07:59.569560: step 10501, loss 0.587579.
Train: 2018-07-31T01:07:59.725757: step 10502, loss 0.503674.
Train: 2018-07-31T01:07:59.866373: step 10503, loss 0.621124.
Train: 2018-07-31T01:08:00.022563: step 10504, loss 0.495357.
Train: 2018-07-31T01:08:00.163155: step 10505, loss 0.587543.
Train: 2018-07-31T01:08:00.288125: step 10506, loss 0.579156.
Train: 2018-07-31T01:08:00.444338: step 10507, loss 0.562405.
Train: 2018-07-31T01:08:00.584929: step 10508, loss 0.620945.
Train: 2018-07-31T01:08:00.741143: step 10509, loss 0.604139.
Train: 2018-07-31T01:08:00.881737: step 10510, loss 0.479269.
Test: 2018-07-31T01:08:01.116081: step 10510, loss 0.548536.
Train: 2018-07-31T01:08:01.272269: step 10511, loss 0.562451.
Train: 2018-07-31T01:08:01.412886: step 10512, loss 0.587359.
Train: 2018-07-31T01:08:01.569076: step 10513, loss 0.595619.
Train: 2018-07-31T01:08:01.709667: step 10514, loss 0.570757.
Train: 2018-07-31T01:08:01.850258: step 10515, loss 0.504756.
Train: 2018-07-31T01:08:01.990851: step 10516, loss 0.55427.
Train: 2018-07-31T01:08:02.147065: step 10517, loss 0.603711.
Train: 2018-07-31T01:08:02.303278: step 10518, loss 0.54608.
Train: 2018-07-31T01:08:02.443870: step 10519, loss 0.587194.
Train: 2018-07-31T01:08:02.568840: step 10520, loss 0.546147.
Test: 2018-07-31T01:08:02.818783: step 10520, loss 0.54884.
Train: 2018-07-31T01:08:02.959398: step 10521, loss 0.546175.
Train: 2018-07-31T01:08:03.115619: step 10522, loss 0.521617.
Train: 2018-07-31T01:08:03.256197: step 10523, loss 0.480627.
Train: 2018-07-31T01:08:03.396796: step 10524, loss 0.61182.
Train: 2018-07-31T01:08:03.553010: step 10525, loss 0.595415.
Train: 2018-07-31T01:08:03.709200: step 10526, loss 0.570759.
Train: 2018-07-31T01:08:03.849816: step 10527, loss 0.603622.
Train: 2018-07-31T01:08:03.990383: step 10528, loss 0.488704.
Train: 2018-07-31T01:08:04.146614: step 10529, loss 0.55434.
Train: 2018-07-31T01:08:04.287212: step 10530, loss 0.554329.
Test: 2018-07-31T01:08:04.521540: step 10530, loss 0.54877.
Train: 2018-07-31T01:08:04.662100: step 10531, loss 0.57898.
Train: 2018-07-31T01:08:04.802694: step 10532, loss 0.578982.
Train: 2018-07-31T01:08:04.958907: step 10533, loss 0.480321.
Train: 2018-07-31T01:08:05.099499: step 10534, loss 0.521347.
Train: 2018-07-31T01:08:05.240108: step 10535, loss 0.529485.
Train: 2018-07-31T01:08:05.380681: step 10536, loss 0.562479.
Train: 2018-07-31T01:08:05.536896: step 10537, loss 0.545866.
Train: 2018-07-31T01:08:05.677512: step 10538, loss 0.587397.
Train: 2018-07-31T01:08:05.833702: step 10539, loss 0.529111.
Train: 2018-07-31T01:08:05.974294: step 10540, loss 0.595811.
Test: 2018-07-31T01:08:06.208615: step 10540, loss 0.548421.
Train: 2018-07-31T01:08:06.364826: step 10541, loss 0.545703.
Train: 2018-07-31T01:08:06.521039: step 10542, loss 0.604233.
Train: 2018-07-31T01:08:06.661632: step 10543, loss 0.52895.
Train: 2018-07-31T01:08:06.817847: step 10544, loss 0.604252.
Train: 2018-07-31T01:08:06.958437: step 10545, loss 0.595868.
Train: 2018-07-31T01:08:07.099055: step 10546, loss 0.562416.
Train: 2018-07-31T01:08:07.239646: step 10547, loss 0.529053.
Train: 2018-07-31T01:08:07.380239: step 10548, loss 0.545752.
Train: 2018-07-31T01:08:07.536428: step 10549, loss 0.495743.
Train: 2018-07-31T01:08:07.677021: step 10550, loss 0.537387.
Test: 2018-07-31T01:08:07.911365: step 10550, loss 0.548417.
Train: 2018-07-31T01:08:08.067552: step 10551, loss 0.554056.
Train: 2018-07-31T01:08:08.208145: step 10552, loss 0.570774.
Train: 2018-07-31T01:08:08.364382: step 10553, loss 0.47864.
Train: 2018-07-31T01:08:08.504975: step 10554, loss 0.537197.
Train: 2018-07-31T01:08:08.645544: step 10555, loss 0.587634.
Train: 2018-07-31T01:08:08.786135: step 10556, loss 0.553936.
Train: 2018-07-31T01:08:08.926727: step 10557, loss 0.562364.
Train: 2018-07-31T01:08:09.067319: step 10558, loss 0.53699.
Train: 2018-07-31T01:08:09.207935: step 10559, loss 0.545418.
Train: 2018-07-31T01:08:09.364148: step 10560, loss 0.621718.
Test: 2018-07-31T01:08:09.598475: step 10560, loss 0.54815.
Train: 2018-07-31T01:08:09.754659: step 10561, loss 0.62171.
Train: 2018-07-31T01:08:09.895251: step 10562, loss 0.562356.
Train: 2018-07-31T01:08:10.035866: step 10563, loss 0.596172.
Train: 2018-07-31T01:08:10.192080: step 10564, loss 0.629832.
Train: 2018-07-31T01:08:10.332648: step 10565, loss 0.595991.
Train: 2018-07-31T01:08:10.473257: step 10566, loss 0.59587.
Train: 2018-07-31T01:08:10.629454: step 10567, loss 0.512481.
Train: 2018-07-31T01:08:10.770048: step 10568, loss 0.554161.
Train: 2018-07-31T01:08:10.910639: step 10569, loss 0.504555.
Train: 2018-07-31T01:08:11.051230: step 10570, loss 0.580122.
Test: 2018-07-31T01:08:11.285580: step 10570, loss 0.548689.
Train: 2018-07-31T01:08:11.441763: step 10571, loss 0.579007.
Train: 2018-07-31T01:08:11.582356: step 10572, loss 0.620162.
Train: 2018-07-31T01:08:11.722971: step 10573, loss 0.578969.
Train: 2018-07-31T01:08:11.863541: step 10574, loss 0.497126.
Train: 2018-07-31T01:08:12.019752: step 10575, loss 0.554428.
Train: 2018-07-31T01:08:12.160368: step 10576, loss 0.489155.
Train: 2018-07-31T01:08:12.300961: step 10577, loss 0.562603.
Train: 2018-07-31T01:08:12.457149: step 10578, loss 0.578941.
Train: 2018-07-31T01:08:12.613389: step 10579, loss 0.472685.
Train: 2018-07-31T01:08:12.753980: step 10580, loss 0.537997.
Test: 2018-07-31T01:08:12.988307: step 10580, loss 0.548794.
Train: 2018-07-31T01:08:13.160110: step 10581, loss 0.554334.
Train: 2018-07-31T01:08:13.300702: step 10582, loss 0.513128.
Train: 2018-07-31T01:08:13.456940: step 10583, loss 0.496414.
Train: 2018-07-31T01:08:13.597508: step 10584, loss 0.52918.
Train: 2018-07-31T01:08:13.753722: step 10585, loss 0.545412.
Train: 2018-07-31T01:08:13.894316: step 10586, loss 0.588209.
Train: 2018-07-31T01:08:14.034905: step 10587, loss 0.570552.
Train: 2018-07-31T01:08:14.191119: step 10588, loss 0.571441.
Train: 2018-07-31T01:08:14.331711: step 10589, loss 0.579043.
Train: 2018-07-31T01:08:14.472327: step 10590, loss 0.553895.
Test: 2018-07-31T01:08:14.722244: step 10590, loss 0.548141.
Train: 2018-07-31T01:08:14.862861: step 10591, loss 0.51141.
Train: 2018-07-31T01:08:15.019051: step 10592, loss 0.520028.
Train: 2018-07-31T01:08:15.159689: step 10593, loss 0.588072.
Train: 2018-07-31T01:08:15.315868: step 10594, loss 0.554157.
Train: 2018-07-31T01:08:15.456448: step 10595, loss 0.630412.
Train: 2018-07-31T01:08:15.597039: step 10596, loss 0.528375.
Train: 2018-07-31T01:08:15.737656: step 10597, loss 0.528377.
Train: 2018-07-31T01:08:15.878242: step 10598, loss 0.638817.
Train: 2018-07-31T01:08:16.018816: step 10599, loss 0.664166.
Train: 2018-07-31T01:08:16.175030: step 10600, loss 0.553905.
Test: 2018-07-31T01:08:16.424972: step 10600, loss 0.548259.
Train: 2018-07-31T01:08:17.127931: step 10601, loss 0.503388.
Train: 2018-07-31T01:08:17.284145: step 10602, loss 0.511908.
Train: 2018-07-31T01:08:17.424737: step 10603, loss 0.579186.
Train: 2018-07-31T01:08:17.565347: step 10604, loss 0.629631.
Train: 2018-07-31T01:08:17.705947: step 10605, loss 0.487047.
Train: 2018-07-31T01:08:17.846539: step 10606, loss 0.579138.
Train: 2018-07-31T01:08:17.987123: step 10607, loss 0.604186.
Train: 2018-07-31T01:08:18.143320: step 10608, loss 0.570763.
Train: 2018-07-31T01:08:18.283911: step 10609, loss 0.554109.
Train: 2018-07-31T01:08:18.424502: step 10610, loss 0.554214.
Test: 2018-07-31T01:08:18.658853: step 10610, loss 0.548575.
Train: 2018-07-31T01:08:18.799415: step 10611, loss 0.521007.
Train: 2018-07-31T01:08:18.940006: step 10612, loss 0.52096.
Train: 2018-07-31T01:08:19.096221: step 10613, loss 0.620601.
Train: 2018-07-31T01:08:19.236812: step 10614, loss 0.612069.
Train: 2018-07-31T01:08:19.377429: step 10615, loss 0.562424.
Train: 2018-07-31T01:08:19.518022: step 10616, loss 0.562347.
Train: 2018-07-31T01:08:19.658613: step 10617, loss 0.611969.
Train: 2018-07-31T01:08:19.814802: step 10618, loss 0.55423.
Train: 2018-07-31T01:08:19.939773: step 10619, loss 0.611503.
Train: 2018-07-31T01:08:20.080389: step 10620, loss 0.644816.
Test: 2018-07-31T01:08:20.330308: step 10620, loss 0.548974.
Train: 2018-07-31T01:08:20.486520: step 10621, loss 0.54651.
Train: 2018-07-31T01:08:20.627136: step 10622, loss 0.58703.
Train: 2018-07-31T01:08:20.767728: step 10623, loss 0.578905.
Train: 2018-07-31T01:08:20.923916: step 10624, loss 0.5148.
Train: 2018-07-31T01:08:21.064510: step 10625, loss 0.602837.
Train: 2018-07-31T01:08:21.205127: step 10626, loss 0.50718.
Train: 2018-07-31T01:08:21.345719: step 10627, loss 0.547022.
Train: 2018-07-31T01:08:21.486286: step 10628, loss 0.602753.
Train: 2018-07-31T01:08:21.626878: step 10629, loss 0.523243.
Train: 2018-07-31T01:08:21.767471: step 10630, loss 0.554977.
Test: 2018-07-31T01:08:22.001821: step 10630, loss 0.549644.
Train: 2018-07-31T01:08:22.158028: step 10631, loss 0.546905.
Train: 2018-07-31T01:08:22.298596: step 10632, loss 0.650582.
Train: 2018-07-31T01:08:22.439188: step 10633, loss 0.603129.
Train: 2018-07-31T01:08:22.579780: step 10634, loss 0.586677.
Train: 2018-07-31T01:08:22.720372: step 10635, loss 0.483907.
Train: 2018-07-31T01:08:22.860963: step 10636, loss 0.610543.
Train: 2018-07-31T01:08:23.001557: step 10637, loss 0.61842.
Train: 2018-07-31T01:08:23.142173: step 10638, loss 0.586733.
Train: 2018-07-31T01:08:23.298386: step 10639, loss 0.555343.
Train: 2018-07-31T01:08:23.438953: step 10640, loss 0.547519.
Test: 2018-07-31T01:08:23.673302: step 10640, loss 0.550122.
Train: 2018-07-31T01:08:23.829488: step 10641, loss 0.555436.
Train: 2018-07-31T01:08:23.970080: step 10642, loss 0.547584.
Train: 2018-07-31T01:08:24.110696: step 10643, loss 0.60233.
Train: 2018-07-31T01:08:24.251263: step 10644, loss 0.571082.
Train: 2018-07-31T01:08:24.391855: step 10645, loss 0.524188.
Train: 2018-07-31T01:08:24.548070: step 10646, loss 0.555428.
Train: 2018-07-31T01:08:24.688662: step 10647, loss 0.602369.
Train: 2018-07-31T01:08:24.829252: step 10648, loss 0.539712.
Train: 2018-07-31T01:08:24.969870: step 10649, loss 0.492574.
Train: 2018-07-31T01:08:25.110437: step 10650, loss 0.531611.
Test: 2018-07-31T01:08:25.344758: step 10650, loss 0.549752.
Train: 2018-07-31T01:08:25.500972: step 10651, loss 0.539014.
Train: 2018-07-31T01:08:25.625966: step 10652, loss 0.506517.
Train: 2018-07-31T01:08:25.766558: step 10653, loss 0.546547.
Train: 2018-07-31T01:08:25.907126: step 10654, loss 0.52931.
Train: 2018-07-31T01:08:26.047718: step 10655, loss 0.554928.
Train: 2018-07-31T01:08:26.188328: step 10656, loss 0.603091.
Train: 2018-07-31T01:08:26.328919: step 10657, loss 0.547961.
Train: 2018-07-31T01:08:26.485115: step 10658, loss 0.605398.
Train: 2018-07-31T01:08:26.625706: step 10659, loss 0.511179.
Train: 2018-07-31T01:08:26.766299: step 10660, loss 0.632039.
Test: 2018-07-31T01:08:27.016241: step 10660, loss 0.54784.
Train: 2018-07-31T01:08:27.156850: step 10661, loss 0.648057.
Train: 2018-07-31T01:08:27.297435: step 10662, loss 0.592127.
Train: 2018-07-31T01:08:27.438041: step 10663, loss 0.53639.
Train: 2018-07-31T01:08:27.594231: step 10664, loss 0.562873.
Train: 2018-07-31T01:08:27.734822: step 10665, loss 0.613975.
Train: 2018-07-31T01:08:27.875438: step 10666, loss 0.563607.
Train: 2018-07-31T01:08:28.016031: step 10667, loss 0.522115.
Train: 2018-07-31T01:08:28.172221: step 10668, loss 0.563874.
Train: 2018-07-31T01:08:28.312813: step 10669, loss 0.570619.
Train: 2018-07-31T01:08:28.453406: step 10670, loss 0.530459.
Test: 2018-07-31T01:08:28.687750: step 10670, loss 0.549465.
Train: 2018-07-31T01:08:28.843939: step 10671, loss 0.586764.
Train: 2018-07-31T01:08:28.984554: step 10672, loss 0.602983.
Train: 2018-07-31T01:08:29.140768: step 10673, loss 0.531005.
Train: 2018-07-31T01:08:29.281352: step 10674, loss 0.499528.
Train: 2018-07-31T01:08:29.421947: step 10675, loss 0.570999.
Train: 2018-07-31T01:08:29.578141: step 10676, loss 0.523267.
Train: 2018-07-31T01:08:29.718733: step 10677, loss 0.539103.
Train: 2018-07-31T01:08:29.859326: step 10678, loss 0.594777.
Train: 2018-07-31T01:08:29.984296: step 10679, loss 0.562895.
Train: 2018-07-31T01:08:30.124888: step 10680, loss 0.602862.
Test: 2018-07-31T01:08:30.359208: step 10680, loss 0.549484.
Train: 2018-07-31T01:08:30.499799: step 10681, loss 0.586882.
Train: 2018-07-31T01:08:30.640391: step 10682, loss 0.562878.
Train: 2018-07-31T01:08:30.780985: step 10683, loss 0.610834.
Train: 2018-07-31T01:08:30.921576: step 10684, loss 0.570876.
Train: 2018-07-31T01:08:31.062167: step 10685, loss 0.586835.
Train: 2018-07-31T01:08:31.202759: step 10686, loss 0.475318.
Train: 2018-07-31T01:08:31.343351: step 10687, loss 0.531023.
Train: 2018-07-31T01:08:31.483944: step 10688, loss 0.530938.
Train: 2018-07-31T01:08:31.624537: step 10689, loss 0.522815.
Train: 2018-07-31T01:08:31.780750: step 10690, loss 0.538705.
Test: 2018-07-31T01:08:32.015096: step 10690, loss 0.549254.
Train: 2018-07-31T01:08:32.155674: step 10691, loss 0.57888.
Train: 2018-07-31T01:08:32.311877: step 10692, loss 0.586976.
Train: 2018-07-31T01:08:32.452469: step 10693, loss 0.530284.
Train: 2018-07-31T01:08:32.593085: step 10694, loss 0.554538.
Train: 2018-07-31T01:08:32.733677: step 10695, loss 0.595212.
Train: 2018-07-31T01:08:32.874269: step 10696, loss 0.611562.
Train: 2018-07-31T01:08:33.014837: step 10697, loss 0.562612.
Train: 2018-07-31T01:08:33.155429: step 10698, loss 0.570772.
Train: 2018-07-31T01:08:33.280399: step 10699, loss 0.554446.
Train: 2018-07-31T01:08:33.436614: step 10700, loss 0.538113.
Test: 2018-07-31T01:08:33.670932: step 10700, loss 0.548915.
Train: 2018-07-31T01:08:34.405134: step 10701, loss 0.497234.
Train: 2018-07-31T01:08:34.561350: step 10702, loss 0.578953.
Train: 2018-07-31T01:08:34.701941: step 10703, loss 0.529757.
Train: 2018-07-31T01:08:34.842532: step 10704, loss 0.488577.
Train: 2018-07-31T01:08:34.998748: step 10705, loss 0.579004.
Train: 2018-07-31T01:08:35.139338: step 10706, loss 0.537677.
Train: 2018-07-31T01:08:35.295553: step 10707, loss 0.479522.
Train: 2018-07-31T01:08:35.436169: step 10708, loss 0.545771.
Train: 2018-07-31T01:08:35.576736: step 10709, loss 0.579142.
Train: 2018-07-31T01:08:35.717328: step 10710, loss 0.57078.
Test: 2018-07-31T01:08:35.967270: step 10710, loss 0.548283.
Train: 2018-07-31T01:08:36.107861: step 10711, loss 0.638118.
Train: 2018-07-31T01:08:36.264099: step 10712, loss 0.655005.
Train: 2018-07-31T01:08:36.404692: step 10713, loss 0.553986.
Train: 2018-07-31T01:08:36.545283: step 10714, loss 0.545603.
Train: 2018-07-31T01:08:36.685876: step 10715, loss 0.587557.
Train: 2018-07-31T01:08:36.826445: step 10716, loss 0.562407.
Train: 2018-07-31T01:08:36.967036: step 10717, loss 0.570773.
Train: 2018-07-31T01:08:37.123273: step 10718, loss 0.587444.
Train: 2018-07-31T01:08:37.263842: step 10719, loss 0.545797.
Train: 2018-07-31T01:08:37.404433: step 10720, loss 0.562451.
Test: 2018-07-31T01:08:37.638784: step 10720, loss 0.548575.
Train: 2018-07-31T01:08:37.779346: step 10721, loss 0.597847.
Train: 2018-07-31T01:08:37.935560: step 10722, loss 0.537661.
Train: 2018-07-31T01:08:38.091772: step 10723, loss 0.554239.
Train: 2018-07-31T01:08:38.232382: step 10724, loss 0.595497.
Train: 2018-07-31T01:08:38.372957: step 10725, loss 0.628371.
Train: 2018-07-31T01:08:38.529170: step 10726, loss 0.644583.
Train: 2018-07-31T01:08:38.669763: step 10727, loss 0.587095.
Train: 2018-07-31T01:08:38.810355: step 10728, loss 0.562666.
Train: 2018-07-31T01:08:38.950970: step 10729, loss 0.489972.
Train: 2018-07-31T01:08:39.091539: step 10730, loss 0.530496.
Test: 2018-07-31T01:08:39.341481: step 10730, loss 0.549282.
Train: 2018-07-31T01:08:39.482096: step 10731, loss 0.530556.
Train: 2018-07-31T01:08:39.638284: step 10732, loss 0.474218.
Train: 2018-07-31T01:08:39.778876: step 10733, loss 0.595011.
Train: 2018-07-31T01:08:39.919469: step 10734, loss 0.595029.
Train: 2018-07-31T01:08:40.060061: step 10735, loss 0.490072.
Train: 2018-07-31T01:08:40.216275: step 10736, loss 0.546534.
Train: 2018-07-31T01:08:40.341246: step 10737, loss 0.530265.
Train: 2018-07-31T01:08:40.497460: step 10738, loss 0.505761.
Train: 2018-07-31T01:08:40.622429: step 10739, loss 0.546297.
Train: 2018-07-31T01:08:40.778642: step 10740, loss 0.570768.
Test: 2018-07-31T01:08:41.012963: step 10740, loss 0.548788.
Train: 2018-07-31T01:08:41.169176: step 10741, loss 0.562548.
Train: 2018-07-31T01:08:41.309793: step 10742, loss 0.562523.
Train: 2018-07-31T01:08:41.450386: step 10743, loss 0.587274.
Train: 2018-07-31T01:08:41.606575: step 10744, loss 0.587295.
Train: 2018-07-31T01:08:41.747165: step 10745, loss 0.554205.
Train: 2018-07-31T01:08:41.887804: step 10746, loss 0.570759.
Train: 2018-07-31T01:08:42.028350: step 10747, loss 0.537611.
Train: 2018-07-31T01:08:42.168942: step 10748, loss 0.537581.
Train: 2018-07-31T01:08:42.309534: step 10749, loss 0.487711.
Train: 2018-07-31T01:08:42.465772: step 10750, loss 0.562436.
Test: 2018-07-31T01:08:42.715714: step 10750, loss 0.548442.
Train: 2018-07-31T01:08:42.856295: step 10751, loss 0.587459.
Train: 2018-07-31T01:08:42.996898: step 10752, loss 0.620922.
Train: 2018-07-31T01:08:43.153087: step 10753, loss 0.620917.
Train: 2018-07-31T01:08:43.293681: step 10754, loss 0.554076.
Train: 2018-07-31T01:08:43.434295: step 10755, loss 0.53743.
Train: 2018-07-31T01:08:43.590485: step 10756, loss 0.54578.
Train: 2018-07-31T01:08:43.715457: step 10757, loss 0.562437.
Train: 2018-07-31T01:08:43.871669: step 10758, loss 0.495876.
Train: 2018-07-31T01:08:44.012262: step 10759, loss 0.53745.
Train: 2018-07-31T01:08:44.152853: step 10760, loss 0.612464.
Test: 2018-07-31T01:08:44.387198: step 10760, loss 0.548459.
Train: 2018-07-31T01:08:44.527792: step 10761, loss 0.512392.
Train: 2018-07-31T01:08:44.668381: step 10762, loss 0.51234.
Train: 2018-07-31T01:08:44.808948: step 10763, loss 0.579138.
Train: 2018-07-31T01:08:44.949566: step 10764, loss 0.554033.
Train: 2018-07-31T01:08:45.105755: step 10765, loss 0.595922.
Train: 2018-07-31T01:08:45.246346: step 10766, loss 0.545632.
Train: 2018-07-31T01:08:45.386964: step 10767, loss 0.562396.
Train: 2018-07-31T01:08:45.527555: step 10768, loss 0.570781.
Train: 2018-07-31T01:08:45.683769: step 10769, loss 0.512087.
Train: 2018-07-31T01:08:45.824338: step 10770, loss 0.520434.
Test: 2018-07-31T01:08:46.074308: step 10770, loss 0.548278.
Train: 2018-07-31T01:08:46.214871: step 10771, loss 0.52877.
Train: 2018-07-31T01:08:46.355487: step 10772, loss 0.579216.
Train: 2018-07-31T01:08:46.496054: step 10773, loss 0.570799.
Train: 2018-07-31T01:08:46.636645: step 10774, loss 0.612985.
Train: 2018-07-31T01:08:46.777238: step 10775, loss 0.612959.
Train: 2018-07-31T01:08:46.917854: step 10776, loss 0.537129.
Train: 2018-07-31T01:08:47.058446: step 10777, loss 0.528761.
Train: 2018-07-31T01:08:47.214636: step 10778, loss 0.528781.
Train: 2018-07-31T01:08:47.339614: step 10779, loss 0.570787.
Train: 2018-07-31T01:08:47.480224: step 10780, loss 0.528787.
Test: 2018-07-31T01:08:47.730141: step 10780, loss 0.548293.
Train: 2018-07-31T01:08:47.870757: step 10781, loss 0.537176.
Train: 2018-07-31T01:08:48.026947: step 10782, loss 0.520336.
Train: 2018-07-31T01:08:48.167563: step 10783, loss 0.713956.
Train: 2018-07-31T01:08:48.308129: step 10784, loss 0.604399.
Train: 2018-07-31T01:08:48.448721: step 10785, loss 0.604287.
Train: 2018-07-31T01:08:48.589338: step 10786, loss 0.529038.
Train: 2018-07-31T01:08:48.745528: step 10787, loss 0.56244.
Train: 2018-07-31T01:08:48.886119: step 10788, loss 0.603962.
Train: 2018-07-31T01:08:49.026712: step 10789, loss 0.537665.
Train: 2018-07-31T01:08:49.182926: step 10790, loss 0.587259.
Test: 2018-07-31T01:08:49.417273: step 10790, loss 0.548752.
Train: 2018-07-31T01:08:49.573459: step 10791, loss 0.488484.
Train: 2018-07-31T01:08:49.714057: step 10792, loss 0.513226.
Train: 2018-07-31T01:08:49.854644: step 10793, loss 0.570759.
Train: 2018-07-31T01:08:50.010856: step 10794, loss 0.480342.
Train: 2018-07-31T01:08:50.151447: step 10795, loss 0.554289.
Train: 2018-07-31T01:08:50.292040: step 10796, loss 0.546012.
Train: 2018-07-31T01:08:50.432632: step 10797, loss 0.545966.
Train: 2018-07-31T01:08:50.588847: step 10798, loss 0.579036.
Train: 2018-07-31T01:08:50.729439: step 10799, loss 0.603919.
Train: 2018-07-31T01:08:50.870031: step 10800, loss 0.545882.
Test: 2018-07-31T01:08:51.104350: step 10800, loss 0.54857.
Train: 2018-07-31T01:08:51.854176: step 10801, loss 0.579054.
Train: 2018-07-31T01:08:51.994768: step 10802, loss 0.587348.
Train: 2018-07-31T01:08:52.150981: step 10803, loss 0.570758.
Train: 2018-07-31T01:08:52.291572: step 10804, loss 0.554193.
Train: 2018-07-31T01:08:52.432164: step 10805, loss 0.521099.
Train: 2018-07-31T01:08:52.572755: step 10806, loss 0.496254.
Train: 2018-07-31T01:08:52.713349: step 10807, loss 0.653672.
Train: 2018-07-31T01:08:52.853941: step 10808, loss 0.537614.
Train: 2018-07-31T01:08:53.010153: step 10809, loss 0.570757.
Train: 2018-07-31T01:08:53.150773: step 10810, loss 0.579038.
Test: 2018-07-31T01:08:53.400694: step 10810, loss 0.548625.
Train: 2018-07-31T01:08:53.541284: step 10811, loss 0.537657.
Train: 2018-07-31T01:08:53.681871: step 10812, loss 0.603849.
Train: 2018-07-31T01:08:53.822489: step 10813, loss 0.55423.
Train: 2018-07-31T01:08:53.963056: step 10814, loss 0.636796.
Train: 2018-07-31T01:08:54.119268: step 10815, loss 0.562524.
Train: 2018-07-31T01:08:54.259886: step 10816, loss 0.537905.
Train: 2018-07-31T01:08:54.400454: step 10817, loss 0.521561.
Train: 2018-07-31T01:08:54.541044: step 10818, loss 0.61174.
Train: 2018-07-31T01:08:54.681662: step 10819, loss 0.521675.
Train: 2018-07-31T01:08:54.837852: step 10820, loss 0.554413.
Test: 2018-07-31T01:08:55.072203: step 10820, loss 0.548904.
Train: 2018-07-31T01:08:55.212788: step 10821, loss 0.603465.
Train: 2018-07-31T01:08:55.384598: step 10822, loss 0.570771.
Train: 2018-07-31T01:08:55.525189: step 10823, loss 0.546316.
Train: 2018-07-31T01:08:55.681403: step 10824, loss 0.595216.
Train: 2018-07-31T01:08:55.822019: step 10825, loss 0.50571.
Train: 2018-07-31T01:08:55.962587: step 10826, loss 0.530112.
Train: 2018-07-31T01:08:56.118802: step 10827, loss 0.505659.
Train: 2018-07-31T01:08:56.259392: step 10828, loss 0.619711.
Train: 2018-07-31T01:08:56.415607: step 10829, loss 0.570772.
Train: 2018-07-31T01:08:56.556199: step 10830, loss 0.538123.
Test: 2018-07-31T01:08:56.790518: step 10830, loss 0.548921.
Train: 2018-07-31T01:08:56.946757: step 10831, loss 0.529927.
Train: 2018-07-31T01:08:57.087323: step 10832, loss 0.505324.
Train: 2018-07-31T01:08:57.227915: step 10833, loss 0.546157.
Train: 2018-07-31T01:08:57.368507: step 10834, loss 0.611876.
Train: 2018-07-31T01:08:57.509100: step 10835, loss 0.529589.
Train: 2018-07-31T01:08:57.649691: step 10836, loss 0.60375.
Train: 2018-07-31T01:08:57.790283: step 10837, loss 0.570756.
Train: 2018-07-31T01:08:57.930875: step 10838, loss 0.636807.
Train: 2018-07-31T01:08:58.071468: step 10839, loss 0.554268.
Train: 2018-07-31T01:08:58.227682: step 10840, loss 0.587227.
Test: 2018-07-31T01:08:58.462003: step 10840, loss 0.548769.
Train: 2018-07-31T01:08:58.618216: step 10841, loss 0.50499.
Train: 2018-07-31T01:08:58.758808: step 10842, loss 0.505006.
Train: 2018-07-31T01:08:58.899400: step 10843, loss 0.603669.
Train: 2018-07-31T01:08:59.039991: step 10844, loss 0.578986.
Train: 2018-07-31T01:08:59.180583: step 10845, loss 0.59543.
Train: 2018-07-31T01:08:59.321176: step 10846, loss 0.66933.
Train: 2018-07-31T01:08:59.461767: step 10847, loss 0.595321.
Train: 2018-07-31T01:08:59.602360: step 10848, loss 0.530011.
Train: 2018-07-31T01:08:59.742998: step 10849, loss 0.546394.
Train: 2018-07-31T01:08:59.899166: step 10850, loss 0.554566.
Test: 2018-07-31T01:09:00.133511: step 10850, loss 0.549137.
Train: 2018-07-31T01:09:00.289700: step 10851, loss 0.5627.
Train: 2018-07-31T01:09:00.430316: step 10852, loss 0.595062.
Train: 2018-07-31T01:09:00.570884: step 10853, loss 0.53047.
Train: 2018-07-31T01:09:00.711499: step 10854, loss 0.562759.
Train: 2018-07-31T01:09:00.867725: step 10855, loss 0.538612.
Train: 2018-07-31T01:09:01.008280: step 10856, loss 0.586928.
Train: 2018-07-31T01:09:01.148872: step 10857, loss 0.586921.
Train: 2018-07-31T01:09:01.289464: step 10858, loss 0.594946.
Train: 2018-07-31T01:09:01.445679: step 10859, loss 0.53875.
Train: 2018-07-31T01:09:01.586270: step 10860, loss 0.530767.
Test: 2018-07-31T01:09:01.820621: step 10860, loss 0.549405.
Train: 2018-07-31T01:09:01.976804: step 10861, loss 0.57085.
Train: 2018-07-31T01:09:02.117397: step 10862, loss 0.610935.
Train: 2018-07-31T01:09:02.258013: step 10863, loss 0.522809.
Train: 2018-07-31T01:09:02.398623: step 10864, loss 0.54683.
Train: 2018-07-31T01:09:02.554798: step 10865, loss 0.594891.
Train: 2018-07-31T01:09:02.695386: step 10866, loss 0.594889.
Train: 2018-07-31T01:09:02.835977: step 10867, loss 0.634896.
Train: 2018-07-31T01:09:02.992215: step 10868, loss 0.506993.
Train: 2018-07-31T01:09:03.148405: step 10869, loss 0.59482.
Train: 2018-07-31T01:09:03.289021: step 10870, loss 0.594798.
Test: 2018-07-31T01:09:03.538939: step 10870, loss 0.549627.
Train: 2018-07-31T01:09:03.679530: step 10871, loss 0.539085.
Train: 2018-07-31T01:09:03.835743: step 10872, loss 0.613827.
Train: 2018-07-31T01:09:03.976360: step 10873, loss 0.547131.
Train: 2018-07-31T01:09:04.116952: step 10874, loss 0.594704.
Train: 2018-07-31T01:09:04.257520: step 10875, loss 0.563044.
Train: 2018-07-31T01:09:04.398137: step 10876, loss 0.626246.
Train: 2018-07-31T01:09:04.538704: step 10877, loss 0.555237.
Train: 2018-07-31T01:09:04.679295: step 10878, loss 0.58673.
Train: 2018-07-31T01:09:04.819887: step 10879, loss 0.586718.
Train: 2018-07-31T01:09:04.976102: step 10880, loss 0.618004.
Test: 2018-07-31T01:09:05.210423: step 10880, loss 0.550235.
Train: 2018-07-31T01:09:05.351013: step 10881, loss 0.602288.
Train: 2018-07-31T01:09:05.491606: step 10882, loss 0.56337.
Train: 2018-07-31T01:09:05.632197: step 10883, loss 0.516962.
Train: 2018-07-31T01:09:05.772789: step 10884, loss 0.555725.
Train: 2018-07-31T01:09:05.913381: step 10885, loss 0.540288.
Train: 2018-07-31T01:09:06.069621: step 10886, loss 0.563471.
Train: 2018-07-31T01:09:06.210189: step 10887, loss 0.555723.
Train: 2018-07-31T01:09:06.350805: step 10888, loss 0.547959.
Train: 2018-07-31T01:09:06.491396: step 10889, loss 0.56341.
Train: 2018-07-31T01:09:06.631989: step 10890, loss 0.594479.
Test: 2018-07-31T01:09:06.881906: step 10890, loss 0.55034.
Train: 2018-07-31T01:09:07.022521: step 10891, loss 0.524497.
Train: 2018-07-31T01:09:07.163091: step 10892, loss 0.532167.
Train: 2018-07-31T01:09:07.319303: step 10893, loss 0.602319.
Train: 2018-07-31T01:09:07.475516: step 10894, loss 0.508457.
Train: 2018-07-31T01:09:07.616133: step 10895, loss 0.563172.
Train: 2018-07-31T01:09:07.756701: step 10896, loss 0.586741.
Train: 2018-07-31T01:09:07.912914: step 10897, loss 0.586756.
Train: 2018-07-31T01:09:08.053505: step 10898, loss 0.547232.
Train: 2018-07-31T01:09:08.194122: step 10899, loss 0.531317.
Train: 2018-07-31T01:09:08.350311: step 10900, loss 0.634481.
Test: 2018-07-31T01:09:08.600253: step 10900, loss 0.549632.
Train: 2018-07-31T01:09:09.318836: step 10901, loss 0.547045.
Train: 2018-07-31T01:09:09.490694: step 10902, loss 0.586823.
Train: 2018-07-31T01:09:09.631286: step 10903, loss 0.634649.
Train: 2018-07-31T01:09:09.787499: step 10904, loss 0.54701.
Train: 2018-07-31T01:09:09.928066: step 10905, loss 0.602737.
Train: 2018-07-31T01:09:10.084280: step 10906, loss 0.626561.
Train: 2018-07-31T01:09:10.224872: step 10907, loss 0.618512.
Train: 2018-07-31T01:09:10.365490: step 10908, loss 0.586765.
Train: 2018-07-31T01:09:10.506057: step 10909, loss 0.484354.
Train: 2018-07-31T01:09:10.662294: step 10910, loss 0.570999.
Test: 2018-07-31T01:09:10.912242: step 10910, loss 0.549978.
Train: 2018-07-31T01:09:11.052828: step 10911, loss 0.539561.
Train: 2018-07-31T01:09:11.193394: step 10912, loss 0.508035.
Train: 2018-07-31T01:09:11.334014: step 10913, loss 0.531466.
Train: 2018-07-31T01:09:11.474580: step 10914, loss 0.531408.
Train: 2018-07-31T01:09:11.615171: step 10915, loss 0.602808.
Train: 2018-07-31T01:09:11.771385: step 10916, loss 0.553431.
Train: 2018-07-31T01:09:11.911977: step 10917, loss 0.562636.
Train: 2018-07-31T01:09:12.068190: step 10918, loss 0.513054.
Train: 2018-07-31T01:09:12.208782: step 10919, loss 0.521543.
Train: 2018-07-31T01:09:12.349374: step 10920, loss 0.46024.
Test: 2018-07-31T01:09:12.599347: step 10920, loss 0.547643.
Train: 2018-07-31T01:09:12.739910: step 10921, loss 0.536162.
Train: 2018-07-31T01:09:12.880501: step 10922, loss 0.571205.
Train: 2018-07-31T01:09:13.036738: step 10923, loss 0.514778.
Train: 2018-07-31T01:09:13.177331: step 10924, loss 0.481856.
Train: 2018-07-31T01:09:13.333537: step 10925, loss 0.513469.
Train: 2018-07-31T01:09:13.489758: step 10926, loss 0.504254.
Train: 2018-07-31T01:09:13.630326: step 10927, loss 0.532797.
Train: 2018-07-31T01:09:13.770917: step 10928, loss 0.646278.
Train: 2018-07-31T01:09:13.927132: step 10929, loss 0.567769.
Train: 2018-07-31T01:09:14.067724: step 10930, loss 0.550905.
Test: 2018-07-31T01:09:14.302072: step 10930, loss 0.547512.
Train: 2018-07-31T01:09:14.442660: step 10931, loss 0.594807.
Train: 2018-07-31T01:09:14.598849: step 10932, loss 0.5817.
Train: 2018-07-31T01:09:14.739440: step 10933, loss 0.527867.
Train: 2018-07-31T01:09:14.895678: step 10934, loss 0.554888.
Train: 2018-07-31T01:09:15.036246: step 10935, loss 0.637954.
Train: 2018-07-31T01:09:15.192483: step 10936, loss 0.520433.
Train: 2018-07-31T01:09:15.333050: step 10937, loss 0.570809.
Train: 2018-07-31T01:09:15.489266: step 10938, loss 0.554408.
Train: 2018-07-31T01:09:15.645478: step 10939, loss 0.538159.
Train: 2018-07-31T01:09:15.786070: step 10940, loss 0.530064.
Test: 2018-07-31T01:09:16.020391: step 10940, loss 0.548997.
Train: 2018-07-31T01:09:16.176628: step 10941, loss 0.546348.
Train: 2018-07-31T01:09:16.317221: step 10942, loss 0.546336.
Train: 2018-07-31T01:09:16.457813: step 10943, loss 0.570774.
Train: 2018-07-31T01:09:16.614026: step 10944, loss 0.529985.
Train: 2018-07-31T01:09:16.754593: step 10945, loss 0.480927.
Train: 2018-07-31T01:09:16.942049: step 10946, loss 0.570764.
Train: 2018-07-31T01:09:17.082642: step 10947, loss 0.595396.
Train: 2018-07-31T01:09:17.223235: step 10948, loss 0.587206.
Train: 2018-07-31T01:09:17.363850: step 10949, loss 0.669508.
Train: 2018-07-31T01:09:17.504443: step 10950, loss 0.611829.
Test: 2018-07-31T01:09:17.754371: step 10950, loss 0.548857.
Train: 2018-07-31T01:09:17.894976: step 10951, loss 0.554383.
Train: 2018-07-31T01:09:18.051165: step 10952, loss 0.562598.
Train: 2018-07-31T01:09:18.191757: step 10953, loss 0.521858.
Train: 2018-07-31T01:09:18.332373: step 10954, loss 0.513767.
Train: 2018-07-31T01:09:18.472941: step 10955, loss 0.611507.
Train: 2018-07-31T01:09:18.629178: step 10956, loss 0.587057.
Train: 2018-07-31T01:09:18.769772: step 10957, loss 0.587039.
Train: 2018-07-31T01:09:18.910339: step 10958, loss 0.651914.
Train: 2018-07-31T01:09:19.066553: step 10959, loss 0.603136.
Train: 2018-07-31T01:09:19.191523: step 10960, loss 0.60302.
Test: 2018-07-31T01:09:19.441464: step 10960, loss 0.54943.
Train: 2018-07-31T01:09:19.582057: step 10961, loss 0.498764.
Train: 2018-07-31T01:09:19.722673: step 10962, loss 0.490983.
Train: 2018-07-31T01:09:19.878863: step 10963, loss 0.562892.
Train: 2018-07-31T01:09:20.019479: step 10964, loss 0.554916.
Train: 2018-07-31T01:09:20.160070: step 10965, loss 0.554917.
Train: 2018-07-31T01:09:20.300638: step 10966, loss 0.610794.
Train: 2018-07-31T01:09:20.456852: step 10967, loss 0.499091.
Train: 2018-07-31T01:09:20.597443: step 10968, loss 0.530955.
Train: 2018-07-31T01:09:20.738064: step 10969, loss 0.618853.
Train: 2018-07-31T01:09:20.894249: step 10970, loss 0.602865.
Test: 2018-07-31T01:09:21.128600: step 10970, loss 0.54948.
Train: 2018-07-31T01:09:21.269160: step 10971, loss 0.594854.
Train: 2018-07-31T01:09:21.425399: step 10972, loss 0.570875.
Train: 2018-07-31T01:09:21.565991: step 10973, loss 0.531.
Train: 2018-07-31T01:09:21.722181: step 10974, loss 0.538984.
Train: 2018-07-31T01:09:21.862771: step 10975, loss 0.475126.
Train: 2018-07-31T01:09:22.003364: step 10976, loss 0.498851.
Train: 2018-07-31T01:09:22.143956: step 10977, loss 0.546736.
Train: 2018-07-31T01:09:22.284549: step 10978, loss 0.611149.
Train: 2018-07-31T01:09:22.440761: step 10979, loss 0.546541.
Train: 2018-07-31T01:09:22.581353: step 10980, loss 0.62756.
Test: 2018-07-31T01:09:22.831297: step 10980, loss 0.549075.
Train: 2018-07-31T01:09:23.034374: step 10981, loss 0.611377.
Train: 2018-07-31T01:09:23.190587: step 10982, loss 0.603253.
Train: 2018-07-31T01:09:23.331179: step 10983, loss 0.570794.
Train: 2018-07-31T01:09:23.471770: step 10984, loss 0.578895.
Train: 2018-07-31T01:09:23.627984: step 10985, loss 0.546547.
Train: 2018-07-31T01:09:23.768575: step 10986, loss 0.538492.
Train: 2018-07-31T01:09:23.924790: step 10987, loss 0.60312.
Train: 2018-07-31T01:09:24.049761: step 10988, loss 0.562744.
Train: 2018-07-31T01:09:24.205975: step 10989, loss 0.457943.
Train: 2018-07-31T01:09:24.346604: step 10990, loss 0.611192.
Test: 2018-07-31T01:09:24.580917: step 10990, loss 0.549194.
Train: 2018-07-31T01:09:24.737122: step 10991, loss 0.546566.
Train: 2018-07-31T01:09:24.893330: step 10992, loss 0.554629.
Train: 2018-07-31T01:09:25.033929: step 10993, loss 0.530322.
Train: 2018-07-31T01:09:25.174495: step 10994, loss 0.603229.
Train: 2018-07-31T01:09:25.315113: step 10995, loss 0.595132.
Train: 2018-07-31T01:09:25.455706: step 10996, loss 0.554566.
Train: 2018-07-31T01:09:25.611919: step 10997, loss 0.68437.
Train: 2018-07-31T01:09:25.752510: step 10998, loss 0.53035.
Train: 2018-07-31T01:09:25.908700: step 10999, loss 0.603116.
Train: 2018-07-31T01:09:26.049317: step 11000, loss 0.570821.
Test: 2018-07-31T01:09:26.283644: step 11000, loss 0.549333.
Train: 2018-07-31T01:09:27.033460: step 11001, loss 0.522603.
Train: 2018-07-31T01:09:27.174053: step 11002, loss 0.56281.
Train: 2018-07-31T01:09:27.314621: step 11003, loss 0.594914.
Train: 2018-07-31T01:09:27.455237: step 11004, loss 0.562843.
Train: 2018-07-31T01:09:27.595833: step 11005, loss 0.514855.
Train: 2018-07-31T01:09:27.752017: step 11006, loss 0.594868.
Train: 2018-07-31T01:09:27.892634: step 11007, loss 0.578863.
Train: 2018-07-31T01:09:28.033202: step 11008, loss 0.618819.
Train: 2018-07-31T01:09:28.173794: step 11009, loss 0.570884.
Train: 2018-07-31T01:09:28.314386: step 11010, loss 0.554975.
Test: 2018-07-31T01:09:28.564353: step 11010, loss 0.549641.
Train: 2018-07-31T01:09:28.704945: step 11011, loss 0.570908.
Train: 2018-07-31T01:09:28.845540: step 11012, loss 0.467689.
Train: 2018-07-31T01:09:28.986105: step 11013, loss 0.58681.
Train: 2018-07-31T01:09:29.142318: step 11014, loss 0.547031.
Train: 2018-07-31T01:09:29.282909: step 11015, loss 0.602758.
Train: 2018-07-31T01:09:29.423526: step 11016, loss 0.562923.
Train: 2018-07-31T01:09:29.579740: step 11017, loss 0.467274.
Train: 2018-07-31T01:09:29.720332: step 11018, loss 0.642797.
Train: 2018-07-31T01:09:29.876521: step 11019, loss 0.538879.
Train: 2018-07-31T01:09:30.017137: step 11020, loss 0.482786.
Test: 2018-07-31T01:09:30.267085: step 11020, loss 0.549357.
Train: 2018-07-31T01:09:30.407671: step 11021, loss 0.51462.
Train: 2018-07-31T01:09:30.563861: step 11022, loss 0.530501.
Train: 2018-07-31T01:09:30.704452: step 11023, loss 0.579976.
Train: 2018-07-31T01:09:30.845045: step 11024, loss 0.562656.
Train: 2018-07-31T01:09:30.985636: step 11025, loss 0.562619.
Train: 2018-07-31T01:09:31.110607: step 11026, loss 0.668905.
Train: 2018-07-31T01:09:31.266821: step 11027, loss 0.55441.
Train: 2018-07-31T01:09:31.423059: step 11028, loss 0.472593.
Train: 2018-07-31T01:09:31.563625: step 11029, loss 0.505162.
Train: 2018-07-31T01:09:31.704218: step 11030, loss 0.587213.
Test: 2018-07-31T01:09:31.954170: step 11030, loss 0.548698.
Train: 2018-07-31T01:09:32.094764: step 11031, loss 0.546016.
Train: 2018-07-31T01:09:32.235367: step 11032, loss 0.587291.
Train: 2018-07-31T01:09:32.375959: step 11033, loss 0.521074.
Train: 2018-07-31T01:09:32.532148: step 11034, loss 0.595656.
Train: 2018-07-31T01:09:32.672765: step 11035, loss 0.595688.
Train: 2018-07-31T01:09:32.813358: step 11036, loss 0.57908.
Train: 2018-07-31T01:09:32.969547: step 11037, loss 0.446109.
Train: 2018-07-31T01:09:33.110140: step 11038, loss 0.545774.
Train: 2018-07-31T01:09:33.250755: step 11039, loss 0.637568.
Train: 2018-07-31T01:09:33.391322: step 11040, loss 0.645924.
Test: 2018-07-31T01:09:33.625644: step 11040, loss 0.548467.
Train: 2018-07-31T01:09:33.781880: step 11041, loss 0.545756.
Train: 2018-07-31T01:09:33.938087: step 11042, loss 0.645697.
Train: 2018-07-31T01:09:34.078686: step 11043, loss 0.545856.
Train: 2018-07-31T01:09:34.219271: step 11044, loss 0.529356.
Train: 2018-07-31T01:09:34.359870: step 11045, loss 0.52942.
Train: 2018-07-31T01:09:34.500438: step 11046, loss 0.537712.
Train: 2018-07-31T01:09:34.641029: step 11047, loss 0.5212.
Train: 2018-07-31T01:09:34.781647: step 11048, loss 0.446781.
Train: 2018-07-31T01:09:34.922214: step 11049, loss 0.562467.
Train: 2018-07-31T01:09:35.078426: step 11050, loss 0.604014.
Test: 2018-07-31T01:09:35.328399: step 11050, loss 0.548493.
Train: 2018-07-31T01:09:35.468987: step 11051, loss 0.595736.
Train: 2018-07-31T01:09:35.625176: step 11052, loss 0.570753.
Train: 2018-07-31T01:09:35.765768: step 11053, loss 0.579033.
Train: 2018-07-31T01:09:35.906383: step 11054, loss 0.54566.
Train: 2018-07-31T01:09:36.046950: step 11055, loss 0.520204.
Train: 2018-07-31T01:09:36.187542: step 11056, loss 0.561382.
Train: 2018-07-31T01:09:36.328135: step 11057, loss 0.631302.
Train: 2018-07-31T01:09:36.484348: step 11058, loss 0.569256.
Train: 2018-07-31T01:09:36.624941: step 11059, loss 0.623332.
Train: 2018-07-31T01:09:36.749936: step 11060, loss 0.51169.
Test: 2018-07-31T01:09:36.999882: step 11060, loss 0.548173.
Train: 2018-07-31T01:09:37.140481: step 11061, loss 0.588314.
Train: 2018-07-31T01:09:37.281037: step 11062, loss 0.613375.
Train: 2018-07-31T01:09:37.421641: step 11063, loss 0.513199.
Train: 2018-07-31T01:09:37.577841: step 11064, loss 0.471246.
Train: 2018-07-31T01:09:37.718435: step 11065, loss 0.628633.
Train: 2018-07-31T01:09:37.859026: step 11066, loss 0.628294.
Train: 2018-07-31T01:09:38.015238: step 11067, loss 0.578955.
Train: 2018-07-31T01:09:38.155857: step 11068, loss 0.562609.
Train: 2018-07-31T01:09:38.296449: step 11069, loss 0.54639.
Train: 2018-07-31T01:09:38.437015: step 11070, loss 0.49776.
Test: 2018-07-31T01:09:38.686988: step 11070, loss 0.549092.
Train: 2018-07-31T01:09:38.843197: step 11071, loss 0.587015.
Train: 2018-07-31T01:09:38.983761: step 11072, loss 0.514052.
Train: 2018-07-31T01:09:39.139975: step 11073, loss 0.538353.
Train: 2018-07-31T01:09:39.296190: step 11074, loss 0.578906.
Train: 2018-07-31T01:09:39.436782: step 11075, loss 0.522054.
Train: 2018-07-31T01:09:39.577399: step 11076, loss 0.562648.
Train: 2018-07-31T01:09:39.717966: step 11077, loss 0.562633.
Train: 2018-07-31T01:09:39.858582: step 11078, loss 0.530004.
Train: 2018-07-31T01:09:39.999174: step 11079, loss 0.578938.
Train: 2018-07-31T01:09:40.139742: step 11080, loss 0.513516.
Test: 2018-07-31T01:09:40.389727: step 11080, loss 0.548838.
Train: 2018-07-31T01:09:40.545898: step 11081, loss 0.62814.
Train: 2018-07-31T01:09:40.702135: step 11082, loss 0.505156.
Train: 2018-07-31T01:09:40.842728: step 11083, loss 0.546116.
Train: 2018-07-31T01:09:40.983319: step 11084, loss 0.513149.
Train: 2018-07-31T01:09:41.123886: step 11085, loss 0.546.
Train: 2018-07-31T01:09:41.280101: step 11086, loss 0.554207.
Train: 2018-07-31T01:09:41.420693: step 11087, loss 0.603943.
Train: 2018-07-31T01:09:41.561283: step 11088, loss 0.537531.
Train: 2018-07-31T01:09:41.717498: step 11089, loss 0.595724.
Train: 2018-07-31T01:09:41.842468: step 11090, loss 0.562437.
Test: 2018-07-31T01:09:42.092411: step 11090, loss 0.548483.
Train: 2018-07-31T01:09:42.233003: step 11091, loss 0.562434.
Train: 2018-07-31T01:09:42.389216: step 11092, loss 0.545766.
Train: 2018-07-31T01:09:42.529807: step 11093, loss 0.537417.
Train: 2018-07-31T01:09:42.654779: step 11094, loss 0.554077.
Train: 2018-07-31T01:09:42.795370: step 11095, loss 0.604179.
Train: 2018-07-31T01:09:42.951582: step 11096, loss 0.512314.
Train: 2018-07-31T01:09:43.092193: step 11097, loss 0.570771.
Train: 2018-07-31T01:09:43.248390: step 11098, loss 0.629295.
Train: 2018-07-31T01:09:43.388981: step 11099, loss 0.62087.
Train: 2018-07-31T01:09:43.529573: step 11100, loss 0.570764.
Test: 2018-07-31T01:09:43.763894: step 11100, loss 0.548536.
Train: 2018-07-31T01:09:44.513743: step 11101, loss 0.5126.
Train: 2018-07-31T01:09:44.669932: step 11102, loss 0.554163.
Train: 2018-07-31T01:09:44.810523: step 11103, loss 0.537601.
Train: 2018-07-31T01:09:44.951114: step 11104, loss 0.612182.
Train: 2018-07-31T01:09:45.122950: step 11105, loss 0.570756.
Train: 2018-07-31T01:09:45.263541: step 11106, loss 0.562499.
Train: 2018-07-31T01:09:45.404159: step 11107, loss 0.570757.
Train: 2018-07-31T01:09:45.544727: step 11108, loss 0.587218.
Train: 2018-07-31T01:09:45.685318: step 11109, loss 0.54612.
Train: 2018-07-31T01:09:45.841532: step 11110, loss 0.578961.
Test: 2018-07-31T01:09:46.075853: step 11110, loss 0.548871.
Train: 2018-07-31T01:09:46.232065: step 11111, loss 0.587132.
Train: 2018-07-31T01:09:46.372682: step 11112, loss 0.554438.
Train: 2018-07-31T01:09:46.513251: step 11113, loss 0.611542.
Train: 2018-07-31T01:09:46.669464: step 11114, loss 0.497624.
Train: 2018-07-31T01:09:46.810054: step 11115, loss 0.619518.
Train: 2018-07-31T01:09:46.966268: step 11116, loss 0.530268.
Train: 2018-07-31T01:09:47.106885: step 11117, loss 0.61128.
Train: 2018-07-31T01:09:47.263098: step 11118, loss 0.530417.
Train: 2018-07-31T01:09:47.403666: step 11119, loss 0.546611.
Train: 2018-07-31T01:09:47.544297: step 11120, loss 0.554687.
Test: 2018-07-31T01:09:47.778578: step 11120, loss 0.549258.
Train: 2018-07-31T01:09:47.934791: step 11121, loss 0.538575.
Train: 2018-07-31T01:09:48.075382: step 11122, loss 0.55469.
Train: 2018-07-31T01:09:48.215976: step 11123, loss 0.562742.
Train: 2018-07-31T01:09:48.356567: step 11124, loss 0.578883.
Train: 2018-07-31T01:09:48.512782: step 11125, loss 0.490053.
Train: 2018-07-31T01:09:48.653400: step 11126, loss 0.554632.
Train: 2018-07-31T01:09:48.793966: step 11127, loss 0.546479.
Train: 2018-07-31T01:09:48.934557: step 11128, loss 0.505797.
Train: 2018-07-31T01:09:49.075151: step 11129, loss 0.595199.
Train: 2018-07-31T01:09:49.231364: step 11130, loss 0.587095.
Test: 2018-07-31T01:09:49.465715: step 11130, loss 0.54888.
Train: 2018-07-31T01:09:49.606275: step 11131, loss 0.546222.
Train: 2018-07-31T01:09:49.762488: step 11132, loss 0.521597.
Train: 2018-07-31T01:09:49.903080: step 11133, loss 0.562524.
Train: 2018-07-31T01:09:50.043698: step 11134, loss 0.546121.
Train: 2018-07-31T01:09:50.184293: step 11135, loss 0.595482.
Train: 2018-07-31T01:09:50.324856: step 11136, loss 0.545972.
Train: 2018-07-31T01:09:50.465473: step 11137, loss 0.587349.
Train: 2018-07-31T01:09:50.606040: step 11138, loss 0.62044.
Train: 2018-07-31T01:09:50.746632: step 11139, loss 0.496297.
Train: 2018-07-31T01:09:50.887250: step 11140, loss 0.587322.
Test: 2018-07-31T01:09:51.137166: step 11140, loss 0.548624.
Train: 2018-07-31T01:09:51.277760: step 11141, loss 0.545946.
Train: 2018-07-31T01:09:51.433973: step 11142, loss 0.562512.
Train: 2018-07-31T01:09:51.590186: step 11143, loss 0.537656.
Train: 2018-07-31T01:09:51.746400: step 11144, loss 0.570785.
Train: 2018-07-31T01:09:51.902637: step 11145, loss 0.570749.
Train: 2018-07-31T01:09:52.039090: step 11146, loss 0.5542.
Train: 2018-07-31T01:09:52.179685: step 11147, loss 0.545911.
Train: 2018-07-31T01:09:52.335924: step 11148, loss 0.579038.
Train: 2018-07-31T01:09:52.476491: step 11149, loss 0.529345.
Train: 2018-07-31T01:09:52.617124: step 11150, loss 0.545894.
Test: 2018-07-31T01:09:52.851405: step 11150, loss 0.548573.
Train: 2018-07-31T01:09:53.007618: step 11151, loss 0.520991.
Train: 2018-07-31T01:09:53.148210: step 11152, loss 0.562453.
Train: 2018-07-31T01:09:53.288827: step 11153, loss 0.612352.
Train: 2018-07-31T01:09:53.429411: step 11154, loss 0.612348.
Train: 2018-07-31T01:09:53.570004: step 11155, loss 0.495995.
Train: 2018-07-31T01:09:53.710603: step 11156, loss 0.562451.
Train: 2018-07-31T01:09:53.866792: step 11157, loss 0.562449.
Train: 2018-07-31T01:09:54.007384: step 11158, loss 0.645559.
Train: 2018-07-31T01:09:54.147976: step 11159, loss 0.612234.
Train: 2018-07-31T01:09:54.288568: step 11160, loss 0.537672.
Test: 2018-07-31T01:09:54.538539: step 11160, loss 0.54868.
Train: 2018-07-31T01:09:54.694723: step 11161, loss 0.562503.
Train: 2018-07-31T01:09:54.835316: step 11162, loss 0.513098.
Train: 2018-07-31T01:09:54.975907: step 11163, loss 0.628374.
Train: 2018-07-31T01:09:55.116499: step 11164, loss 0.546121.
Train: 2018-07-31T01:09:55.257092: step 11165, loss 0.636358.
Train: 2018-07-31T01:09:55.397708: step 11166, loss 0.603462.
Train: 2018-07-31T01:09:55.538289: step 11167, loss 0.530068.
Train: 2018-07-31T01:09:55.678894: step 11168, loss 0.627629.
Train: 2018-07-31T01:09:55.819485: step 11169, loss 0.449476.
Train: 2018-07-31T01:09:55.975708: step 11170, loss 0.603133.
Test: 2018-07-31T01:09:56.209994: step 11170, loss 0.549234.
Train: 2018-07-31T01:09:56.350585: step 11171, loss 0.506269.
Train: 2018-07-31T01:09:56.506797: step 11172, loss 0.611151.
Train: 2018-07-31T01:09:56.647390: step 11173, loss 0.546648.
Train: 2018-07-31T01:09:56.803604: step 11174, loss 0.562772.
Train: 2018-07-31T01:09:56.944197: step 11175, loss 0.586924.
Train: 2018-07-31T01:09:57.084789: step 11176, loss 0.578873.
Train: 2018-07-31T01:09:57.241003: step 11177, loss 0.562808.
Train: 2018-07-31T01:09:57.381594: step 11178, loss 0.538751.
Train: 2018-07-31T01:09:57.522210: step 11179, loss 0.546781.
Train: 2018-07-31T01:09:57.678423: step 11180, loss 0.675153.
Test: 2018-07-31T01:09:57.912749: step 11180, loss 0.549448.
Train: 2018-07-31T01:09:58.068934: step 11181, loss 0.522829.
Train: 2018-07-31T01:09:58.209525: step 11182, loss 0.570866.
Train: 2018-07-31T01:09:58.365737: step 11183, loss 0.562885.
Train: 2018-07-31T01:09:58.506331: step 11184, loss 0.602804.
Train: 2018-07-31T01:09:58.646946: step 11185, loss 0.570891.
Train: 2018-07-31T01:09:58.803160: step 11186, loss 0.634554.
Train: 2018-07-31T01:09:58.943752: step 11187, loss 0.531261.
Train: 2018-07-31T01:09:59.084344: step 11188, loss 0.570941.
Train: 2018-07-31T01:09:59.240532: step 11189, loss 0.515613.
Train: 2018-07-31T01:09:59.381150: step 11190, loss 0.547242.
Test: 2018-07-31T01:09:59.631096: step 11190, loss 0.549801.
Train: 2018-07-31T01:09:59.771657: step 11191, loss 0.65794.
Train: 2018-07-31T01:09:59.912250: step 11192, loss 0.547287.
Train: 2018-07-31T01:10:00.052842: step 11193, loss 0.555208.
Train: 2018-07-31T01:10:00.193459: step 11194, loss 0.610388.
Train: 2018-07-31T01:10:00.334026: step 11195, loss 0.555261.
Train: 2018-07-31T01:10:00.490266: step 11196, loss 0.57887.
Train: 2018-07-31T01:10:00.630856: step 11197, loss 0.531756.
Train: 2018-07-31T01:10:00.787047: step 11198, loss 0.586725.
Train: 2018-07-31T01:10:00.927662: step 11199, loss 0.586722.
Train: 2018-07-31T01:10:01.068255: step 11200, loss 0.578875.
Test: 2018-07-31T01:10:01.302550: step 11200, loss 0.550078.
Train: 2018-07-31T01:10:02.068022: step 11201, loss 0.51618.
Train: 2018-07-31T01:10:02.224246: step 11202, loss 0.516141.
Train: 2018-07-31T01:10:02.364825: step 11203, loss 0.563157.
Train: 2018-07-31T01:10:02.521016: step 11204, loss 0.570995.
Train: 2018-07-31T01:10:02.661608: step 11205, loss 0.539438.
Train: 2018-07-31T01:10:02.817821: step 11206, loss 0.547248.
Train: 2018-07-31T01:10:02.958411: step 11207, loss 0.547163.
Train: 2018-07-31T01:10:03.099004: step 11208, loss 0.507338.
Train: 2018-07-31T01:10:03.255217: step 11209, loss 0.562903.
Train: 2018-07-31T01:10:03.395834: step 11210, loss 0.514795.
Test: 2018-07-31T01:10:03.645751: step 11210, loss 0.549307.
Train: 2018-07-31T01:10:03.786343: step 11211, loss 0.546692.
Train: 2018-07-31T01:10:03.942581: step 11212, loss 0.546555.
Train: 2018-07-31T01:10:04.098771: step 11213, loss 0.59515.
Train: 2018-07-31T01:10:04.239386: step 11214, loss 0.587063.
Train: 2018-07-31T01:10:04.395575: step 11215, loss 0.603457.
Train: 2018-07-31T01:10:04.536167: step 11216, loss 0.464489.
Train: 2018-07-31T01:10:04.676759: step 11217, loss 0.603571.
Train: 2018-07-31T01:10:04.848594: step 11218, loss 0.529665.
Train: 2018-07-31T01:10:04.989188: step 11219, loss 0.537799.
Train: 2018-07-31T01:10:05.129804: step 11220, loss 0.562494.
Test: 2018-07-31T01:10:05.364125: step 11220, loss 0.548604.
Train: 2018-07-31T01:10:05.520313: step 11221, loss 0.496217.
Train: 2018-07-31T01:10:05.660929: step 11222, loss 0.545825.
Train: 2018-07-31T01:10:05.801526: step 11223, loss 0.554086.
Train: 2018-07-31T01:10:05.942113: step 11224, loss 0.545673.
Train: 2018-07-31T01:10:06.098303: step 11225, loss 0.637927.
Train: 2018-07-31T01:10:06.238918: step 11226, loss 0.511979.
Train: 2018-07-31T01:10:06.379485: step 11227, loss 0.495045.
Train: 2018-07-31T01:10:06.520104: step 11228, loss 0.511717.
Train: 2018-07-31T01:10:06.676293: step 11229, loss 0.562354.
Train: 2018-07-31T01:10:06.816883: step 11230, loss 0.587851.
Test: 2018-07-31T01:10:07.066825: step 11230, loss 0.548082.
Train: 2018-07-31T01:10:07.207417: step 11231, loss 0.596394.
Train: 2018-07-31T01:10:07.348011: step 11232, loss 0.553819.
Train: 2018-07-31T01:10:07.504250: step 11233, loss 0.553814.
Train: 2018-07-31T01:10:07.644816: step 11234, loss 0.519683.
Train: 2018-07-31T01:10:07.785432: step 11235, loss 0.553796.
Train: 2018-07-31T01:10:07.925998: step 11236, loss 0.639289.
Train: 2018-07-31T01:10:08.066616: step 11237, loss 0.579422.
Train: 2018-07-31T01:10:08.207182: step 11238, loss 0.579401.
Train: 2018-07-31T01:10:08.363398: step 11239, loss 0.528283.
Train: 2018-07-31T01:10:08.503989: step 11240, loss 0.604869.
Test: 2018-07-31T01:10:08.738333: step 11240, loss 0.548137.
Train: 2018-07-31T01:10:08.894522: step 11241, loss 0.579323.
Train: 2018-07-31T01:10:09.035114: step 11242, loss 0.53696.
Train: 2018-07-31T01:10:09.191328: step 11243, loss 0.613059.
Train: 2018-07-31T01:10:09.331919: step 11244, loss 0.562374.
Train: 2018-07-31T01:10:09.456890: step 11245, loss 0.621189.
Train: 2018-07-31T01:10:09.613129: step 11246, loss 0.487104.
Train: 2018-07-31T01:10:09.753697: step 11247, loss 0.637567.
Train: 2018-07-31T01:10:09.878666: step 11248, loss 0.595719.
Train: 2018-07-31T01:10:10.034880: step 11249, loss 0.521047.
Train: 2018-07-31T01:10:10.175474: step 11250, loss 0.554234.
Test: 2018-07-31T01:10:10.409823: step 11250, loss 0.548715.
Train: 2018-07-31T01:10:10.566006: step 11251, loss 0.562516.
Train: 2018-07-31T01:10:10.722221: step 11252, loss 0.554315.
Train: 2018-07-31T01:10:10.847215: step 11253, loss 0.529732.
Train: 2018-07-31T01:10:11.003404: step 11254, loss 0.554368.
Train: 2018-07-31T01:10:11.144022: step 11255, loss 0.587147.
Train: 2018-07-31T01:10:11.284588: step 11256, loss 0.570766.
Train: 2018-07-31T01:10:11.425179: step 11257, loss 0.660636.
Train: 2018-07-31T01:10:11.581393: step 11258, loss 0.611485.
Train: 2018-07-31T01:10:11.721985: step 11259, loss 0.619435.
Train: 2018-07-31T01:10:11.862578: step 11260, loss 0.570816.
Test: 2018-07-31T01:10:12.112551: step 11260, loss 0.549372.
Train: 2018-07-31T01:10:12.268731: step 11261, loss 0.570842.
Train: 2018-07-31T01:10:12.409324: step 11262, loss 0.562879.
Train: 2018-07-31T01:10:12.549916: step 11263, loss 0.547018.
Train: 2018-07-31T01:10:12.690533: step 11264, loss 0.562986.
Train: 2018-07-31T01:10:12.831100: step 11265, loss 0.578859.
Train: 2018-07-31T01:10:12.971693: step 11266, loss 0.563069.
Train: 2018-07-31T01:10:13.112284: step 11267, loss 0.594627.
Train: 2018-07-31T01:10:13.252876: step 11268, loss 0.571017.
Train: 2018-07-31T01:10:13.409101: step 11269, loss 0.586714.
Train: 2018-07-31T01:10:13.565321: step 11270, loss 0.516308.
Test: 2018-07-31T01:10:13.799625: step 11270, loss 0.550164.
Train: 2018-07-31T01:10:13.955836: step 11271, loss 0.539802.
Train: 2018-07-31T01:10:14.112052: step 11272, loss 0.594508.
Train: 2018-07-31T01:10:14.252642: step 11273, loss 0.563265.
Train: 2018-07-31T01:10:14.408857: step 11274, loss 0.578919.
Train: 2018-07-31T01:10:14.549448: step 11275, loss 0.563238.
Train: 2018-07-31T01:10:14.690039: step 11276, loss 0.610171.
Train: 2018-07-31T01:10:14.846254: step 11277, loss 0.59454.
Train: 2018-07-31T01:10:14.986870: step 11278, loss 0.485466.
Train: 2018-07-31T01:10:15.127462: step 11279, loss 0.586688.
Train: 2018-07-31T01:10:15.283675: step 11280, loss 0.578894.
Test: 2018-07-31T01:10:15.533623: step 11280, loss 0.550237.
Train: 2018-07-31T01:10:15.674184: step 11281, loss 0.532103.
Train: 2018-07-31T01:10:15.830398: step 11282, loss 0.539849.
Train: 2018-07-31T01:10:15.971015: step 11283, loss 0.60233.
Train: 2018-07-31T01:10:16.111607: step 11284, loss 0.594604.
Train: 2018-07-31T01:10:16.267820: step 11285, loss 0.555362.
Train: 2018-07-31T01:10:16.408405: step 11286, loss 0.476966.
Train: 2018-07-31T01:10:16.549003: step 11287, loss 0.547409.
Train: 2018-07-31T01:10:16.705193: step 11288, loss 0.499939.
Train: 2018-07-31T01:10:16.845786: step 11289, loss 0.46781.
Train: 2018-07-31T01:10:16.986378: step 11290, loss 0.57064.
Test: 2018-07-31T01:10:17.220697: step 11290, loss 0.549044.
Train: 2018-07-31T01:10:17.376912: step 11291, loss 0.578996.
Train: 2018-07-31T01:10:17.517527: step 11292, loss 0.661258.
Train: 2018-07-31T01:10:17.658119: step 11293, loss 0.529921.
Train: 2018-07-31T01:10:17.814309: step 11294, loss 0.587359.
Train: 2018-07-31T01:10:17.954900: step 11295, loss 0.472866.
Train: 2018-07-31T01:10:18.111114: step 11296, loss 0.570957.
Train: 2018-07-31T01:10:18.251723: step 11297, loss 0.554708.
Train: 2018-07-31T01:10:18.392297: step 11298, loss 0.496931.
Train: 2018-07-31T01:10:18.548513: step 11299, loss 0.562709.
Train: 2018-07-31T01:10:18.689104: step 11300, loss 0.471279.
Test: 2018-07-31T01:10:18.923462: step 11300, loss 0.548436.
Train: 2018-07-31T01:10:19.657628: step 11301, loss 0.578822.
Train: 2018-07-31T01:10:19.813840: step 11302, loss 0.520492.
Train: 2018-07-31T01:10:19.970054: step 11303, loss 0.587882.
Train: 2018-07-31T01:10:20.110645: step 11304, loss 0.534852.
Train: 2018-07-31T01:10:20.251238: step 11305, loss 0.545176.
Train: 2018-07-31T01:10:20.407451: step 11306, loss 0.527337.
Train: 2018-07-31T01:10:20.548043: step 11307, loss 0.526237.
Train: 2018-07-31T01:10:20.688666: step 11308, loss 0.586096.
Train: 2018-07-31T01:10:20.829253: step 11309, loss 0.571721.
Train: 2018-07-31T01:10:20.985465: step 11310, loss 0.536135.
Test: 2018-07-31T01:10:21.235412: step 11310, loss 0.547784.
Train: 2018-07-31T01:10:21.375975: step 11311, loss 0.50846.
Train: 2018-07-31T01:10:21.516567: step 11312, loss 0.596261.
Train: 2018-07-31T01:10:21.657159: step 11313, loss 0.526783.
Train: 2018-07-31T01:10:21.813373: step 11314, loss 0.513455.
Train: 2018-07-31T01:10:21.969622: step 11315, loss 0.616407.
Train: 2018-07-31T01:10:22.110179: step 11316, loss 0.636231.
Train: 2018-07-31T01:10:22.250769: step 11317, loss 0.626159.
Train: 2018-07-31T01:10:22.391362: step 11318, loss 0.551323.
Train: 2018-07-31T01:10:22.531954: step 11319, loss 0.57361.
Train: 2018-07-31T01:10:22.672546: step 11320, loss 0.544907.
Test: 2018-07-31T01:10:22.906898: step 11320, loss 0.548402.
Train: 2018-07-31T01:10:23.063078: step 11321, loss 0.620312.
Train: 2018-07-31T01:10:23.203671: step 11322, loss 0.529251.
Train: 2018-07-31T01:10:23.344263: step 11323, loss 0.504938.
Train: 2018-07-31T01:10:23.500477: step 11324, loss 0.554522.
Train: 2018-07-31T01:10:23.641070: step 11325, loss 0.68441.
Train: 2018-07-31T01:10:23.781685: step 11326, loss 0.56268.
Train: 2018-07-31T01:10:23.922254: step 11327, loss 0.490043.
Train: 2018-07-31T01:10:24.062846: step 11328, loss 0.562761.
Train: 2018-07-31T01:10:24.203437: step 11329, loss 0.498429.
Train: 2018-07-31T01:10:24.344029: step 11330, loss 0.570824.
Test: 2018-07-31T01:10:24.594000: step 11330, loss 0.549319.
Train: 2018-07-31T01:10:24.734612: step 11331, loss 0.58691.
Train: 2018-07-31T01:10:24.875173: step 11332, loss 0.611036.
Train: 2018-07-31T01:10:25.015747: step 11333, loss 0.498639.
Train: 2018-07-31T01:10:25.171988: step 11334, loss 0.538739.
Train: 2018-07-31T01:10:25.312555: step 11335, loss 0.554788.
Train: 2018-07-31T01:10:25.468766: step 11336, loss 0.58691.
Train: 2018-07-31T01:10:25.609382: step 11337, loss 0.554758.
Train: 2018-07-31T01:10:25.749975: step 11338, loss 0.458193.
Train: 2018-07-31T01:10:25.906163: step 11339, loss 0.562747.
Train: 2018-07-31T01:10:26.031134: step 11340, loss 0.619375.
Test: 2018-07-31T01:10:26.281076: step 11340, loss 0.549118.
Train: 2018-07-31T01:10:26.421667: step 11341, loss 0.497853.
Train: 2018-07-31T01:10:26.562284: step 11342, loss 0.562678.
Train: 2018-07-31T01:10:26.718498: step 11343, loss 0.595207.
Train: 2018-07-31T01:10:26.859101: step 11344, loss 0.554472.
Train: 2018-07-31T01:10:26.984035: step 11345, loss 0.562575.
Train: 2018-07-31T01:10:27.124628: step 11346, loss 0.660664.
Train: 2018-07-31T01:10:27.265221: step 11347, loss 0.595295.
Train: 2018-07-31T01:10:27.405837: step 11348, loss 0.55446.
Train: 2018-07-31T01:10:27.546403: step 11349, loss 0.611501.
Train: 2018-07-31T01:10:27.687023: step 11350, loss 0.53016.
Test: 2018-07-31T01:10:27.936939: step 11350, loss 0.549091.
Train: 2018-07-31T01:10:28.077554: step 11351, loss 0.578879.
Train: 2018-07-31T01:10:28.218122: step 11352, loss 0.538414.
Train: 2018-07-31T01:10:28.358714: step 11353, loss 0.538426.
Train: 2018-07-31T01:10:28.499330: step 11354, loss 0.522233.
Train: 2018-07-31T01:10:28.639897: step 11355, loss 0.595104.
Train: 2018-07-31T01:10:28.796137: step 11356, loss 0.546506.
Train: 2018-07-31T01:10:28.952324: step 11357, loss 0.578854.
Train: 2018-07-31T01:10:29.108563: step 11358, loss 0.538375.
Train: 2018-07-31T01:10:29.249130: step 11359, loss 0.627538.
Train: 2018-07-31T01:10:29.389724: step 11360, loss 0.514048.
Test: 2018-07-31T01:10:29.639695: step 11360, loss 0.549082.
Train: 2018-07-31T01:10:29.780256: step 11361, loss 0.554422.
Train: 2018-07-31T01:10:29.920847: step 11362, loss 0.522198.
Train: 2018-07-31T01:10:30.061441: step 11363, loss 0.595421.
Train: 2018-07-31T01:10:30.217679: step 11364, loss 0.54624.
Train: 2018-07-31T01:10:30.358246: step 11365, loss 0.530127.
Train: 2018-07-31T01:10:30.498839: step 11366, loss 0.578755.
Train: 2018-07-31T01:10:30.639431: step 11367, loss 0.644455.
Train: 2018-07-31T01:10:30.780023: step 11368, loss 0.562592.
Train: 2018-07-31T01:10:30.920639: step 11369, loss 0.562646.
Train: 2018-07-31T01:10:31.076828: step 11370, loss 0.529996.
Test: 2018-07-31T01:10:31.311147: step 11370, loss 0.548998.
Train: 2018-07-31T01:10:31.467361: step 11371, loss 0.5463.
Train: 2018-07-31T01:10:31.607955: step 11372, loss 0.652124.
Train: 2018-07-31T01:10:31.764167: step 11373, loss 0.57901.
Train: 2018-07-31T01:10:31.904784: step 11374, loss 0.578956.
Train: 2018-07-31T01:10:32.061017: step 11375, loss 0.54646.
Train: 2018-07-31T01:10:32.201589: step 11376, loss 0.46584.
Train: 2018-07-31T01:10:32.342181: step 11377, loss 0.554662.
Train: 2018-07-31T01:10:32.482773: step 11378, loss 0.538381.
Train: 2018-07-31T01:10:32.638986: step 11379, loss 0.514028.
Train: 2018-07-31T01:10:32.779553: step 11380, loss 0.546364.
Test: 2018-07-31T01:10:33.029526: step 11380, loss 0.548954.
Train: 2018-07-31T01:10:33.170112: step 11381, loss 0.562535.
Train: 2018-07-31T01:10:33.310680: step 11382, loss 0.546107.
Train: 2018-07-31T01:10:33.466895: step 11383, loss 0.538026.
Train: 2018-07-31T01:10:33.607484: step 11384, loss 0.504814.
Train: 2018-07-31T01:10:33.748102: step 11385, loss 0.52939.
Train: 2018-07-31T01:10:33.888670: step 11386, loss 0.537904.
Train: 2018-07-31T01:10:34.029286: step 11387, loss 0.604097.
Train: 2018-07-31T01:10:34.169878: step 11388, loss 0.520438.
Train: 2018-07-31T01:10:34.341712: step 11389, loss 0.511832.
Train: 2018-07-31T01:10:34.482304: step 11390, loss 0.535669.
Test: 2018-07-31T01:10:34.716631: step 11390, loss 0.547937.
Train: 2018-07-31T01:10:34.872815: step 11391, loss 0.511318.
Train: 2018-07-31T01:10:35.013423: step 11392, loss 0.543659.
Train: 2018-07-31T01:10:35.153998: step 11393, loss 0.543829.
Train: 2018-07-31T01:10:35.294590: step 11394, loss 0.64317.
Train: 2018-07-31T01:10:35.435206: step 11395, loss 0.554009.
Train: 2018-07-31T01:10:35.575774: step 11396, loss 0.528591.
Train: 2018-07-31T01:10:35.716366: step 11397, loss 0.552284.
Train: 2018-07-31T01:10:35.856982: step 11398, loss 0.526438.
Train: 2018-07-31T01:10:36.013171: step 11399, loss 0.501592.
Train: 2018-07-31T01:10:36.153764: step 11400, loss 0.53515.
Test: 2018-07-31T01:10:36.403735: step 11400, loss 0.54754.
Train: 2018-07-31T01:10:37.153531: step 11401, loss 0.559589.
Train: 2018-07-31T01:10:37.294146: step 11402, loss 0.612705.
Train: 2018-07-31T01:10:37.450336: step 11403, loss 0.642202.
Train: 2018-07-31T01:10:37.606548: step 11404, loss 0.597918.
Train: 2018-07-31T01:10:37.747140: step 11405, loss 0.572003.
Train: 2018-07-31T01:10:37.887757: step 11406, loss 0.579317.
Train: 2018-07-31T01:10:38.028324: step 11407, loss 0.511018.
Train: 2018-07-31T01:10:38.168918: step 11408, loss 0.638803.
Train: 2018-07-31T01:10:38.309509: step 11409, loss 0.511937.
Train: 2018-07-31T01:10:38.465722: step 11410, loss 0.562565.
Test: 2018-07-31T01:10:38.715694: step 11410, loss 0.548358.
Train: 2018-07-31T01:10:38.856256: step 11411, loss 0.612912.
Train: 2018-07-31T01:10:39.012494: step 11412, loss 0.571089.
Train: 2018-07-31T01:10:39.168684: step 11413, loss 0.595752.
Train: 2018-07-31T01:10:39.309275: step 11414, loss 0.57073.
Train: 2018-07-31T01:10:39.449866: step 11415, loss 0.513649.
Train: 2018-07-31T01:10:39.590459: step 11416, loss 0.578918.
Train: 2018-07-31T01:10:39.731050: step 11417, loss 0.538329.
Train: 2018-07-31T01:10:39.871642: step 11418, loss 0.514103.
Train: 2018-07-31T01:10:40.027881: step 11419, loss 0.611271.
Train: 2018-07-31T01:10:40.168448: step 11420, loss 0.67586.
Test: 2018-07-31T01:10:40.418390: step 11420, loss 0.5493.
Train: 2018-07-31T01:10:40.559007: step 11421, loss 0.611069.
Train: 2018-07-31T01:10:40.699574: step 11422, loss 0.586876.
Train: 2018-07-31T01:10:40.840166: step 11423, loss 0.570887.
Train: 2018-07-31T01:10:40.996404: step 11424, loss 0.578859.
Train: 2018-07-31T01:10:41.152593: step 11425, loss 0.570957.
Train: 2018-07-31T01:10:41.293185: step 11426, loss 0.586741.
Train: 2018-07-31T01:10:41.433805: step 11427, loss 0.594563.
Train: 2018-07-31T01:10:41.574396: step 11428, loss 0.55545.
Train: 2018-07-31T01:10:41.730583: step 11429, loss 0.617833.
Train: 2018-07-31T01:10:41.871192: step 11430, loss 0.571161.
Test: 2018-07-31T01:10:42.121116: step 11430, loss 0.550535.
Train: 2018-07-31T01:10:42.261709: step 11431, loss 0.59439.
Train: 2018-07-31T01:10:42.402301: step 11432, loss 0.525065.
Train: 2018-07-31T01:10:42.558538: step 11433, loss 0.563604.
Train: 2018-07-31T01:10:42.699107: step 11434, loss 0.571308.
Train: 2018-07-31T01:10:42.839699: step 11435, loss 0.578986.
Train: 2018-07-31T01:10:42.980316: step 11436, loss 0.586646.
Train: 2018-07-31T01:10:43.120883: step 11437, loss 0.540799.
Train: 2018-07-31T01:10:43.277110: step 11438, loss 0.624851.
Train: 2018-07-31T01:10:43.417713: step 11439, loss 0.594289.
Train: 2018-07-31T01:10:43.558280: step 11440, loss 0.53334.
Test: 2018-07-31T01:10:43.792633: step 11440, loss 0.551068.
Train: 2018-07-31T01:10:43.948815: step 11441, loss 0.518159.
Train: 2018-07-31T01:10:44.105051: step 11442, loss 0.617095.
Train: 2018-07-31T01:10:44.245620: step 11443, loss 0.540924.
Train: 2018-07-31T01:10:44.386236: step 11444, loss 0.609496.
Train: 2018-07-31T01:10:44.526802: step 11445, loss 0.571368.
Train: 2018-07-31T01:10:44.667394: step 11446, loss 0.548511.
Train: 2018-07-31T01:10:44.807993: step 11447, loss 0.517882.
Train: 2018-07-31T01:10:44.964216: step 11448, loss 0.602.
Train: 2018-07-31T01:10:45.104794: step 11449, loss 0.555961.
Train: 2018-07-31T01:10:45.245384: step 11450, loss 0.540319.
Test: 2018-07-31T01:10:45.479704: step 11450, loss 0.550546.
Train: 2018-07-31T01:10:45.635918: step 11451, loss 0.59432.
Train: 2018-07-31T01:10:45.792133: step 11452, loss 0.586943.
Train: 2018-07-31T01:10:45.932725: step 11453, loss 0.509282.
Train: 2018-07-31T01:10:46.088936: step 11454, loss 0.524343.
Train: 2018-07-31T01:10:46.229553: step 11455, loss 0.563299.
Train: 2018-07-31T01:10:46.370122: step 11456, loss 0.586637.
Train: 2018-07-31T01:10:46.510714: step 11457, loss 0.5228.
Train: 2018-07-31T01:10:46.666927: step 11458, loss 0.579467.
Train: 2018-07-31T01:10:46.807519: step 11459, loss 0.523187.
Train: 2018-07-31T01:10:46.948111: step 11460, loss 0.473729.
Test: 2018-07-31T01:10:47.198054: step 11460, loss 0.548907.
Train: 2018-07-31T01:10:47.338644: step 11461, loss 0.538682.
Train: 2018-07-31T01:10:47.479238: step 11462, loss 0.554172.
Train: 2018-07-31T01:10:47.604207: step 11463, loss 0.607041.
Train: 2018-07-31T01:10:47.760420: step 11464, loss 0.580956.
Train: 2018-07-31T01:10:47.901014: step 11465, loss 0.487481.
Train: 2018-07-31T01:10:48.041604: step 11466, loss 0.563635.
Train: 2018-07-31T01:10:48.182221: step 11467, loss 0.598692.
Train: 2018-07-31T01:10:48.338410: step 11468, loss 0.579346.
Train: 2018-07-31T01:10:48.479003: step 11469, loss 0.578379.
Train: 2018-07-31T01:10:48.619620: step 11470, loss 0.538246.
Test: 2018-07-31T01:10:48.853946: step 11470, loss 0.548613.
Train: 2018-07-31T01:10:49.010153: step 11471, loss 0.579086.
Train: 2018-07-31T01:10:49.150745: step 11472, loss 0.603636.
Train: 2018-07-31T01:10:49.306962: step 11473, loss 0.521577.
Train: 2018-07-31T01:10:49.447550: step 11474, loss 0.587258.
Train: 2018-07-31T01:10:49.588117: step 11475, loss 0.58714.
Train: 2018-07-31T01:10:49.728736: step 11476, loss 0.580063.
Train: 2018-07-31T01:10:49.884961: step 11477, loss 0.521755.
Train: 2018-07-31T01:10:50.025540: step 11478, loss 0.570769.
Train: 2018-07-31T01:10:50.166133: step 11479, loss 0.603429.
Train: 2018-07-31T01:10:50.306699: step 11480, loss 0.546298.
Test: 2018-07-31T01:10:50.556642: step 11480, loss 0.548978.
Train: 2018-07-31T01:10:50.697257: step 11481, loss 0.530011.
Train: 2018-07-31T01:10:50.853447: step 11482, loss 0.554462.
Train: 2018-07-31T01:10:50.994052: step 11483, loss 0.554455.
Train: 2018-07-31T01:10:51.134630: step 11484, loss 0.587095.
Train: 2018-07-31T01:10:51.275236: step 11485, loss 0.61974.
Train: 2018-07-31T01:10:51.431437: step 11486, loss 0.562619.
Train: 2018-07-31T01:10:51.556432: step 11487, loss 0.521921.
Train: 2018-07-31T01:10:51.697028: step 11488, loss 0.497515.
Train: 2018-07-31T01:10:51.853212: step 11489, loss 0.578956.
Train: 2018-07-31T01:10:51.993805: step 11490, loss 0.595309.
Test: 2018-07-31T01:10:52.243765: step 11490, loss 0.548954.
Train: 2018-07-31T01:10:52.384363: step 11491, loss 0.562606.
Train: 2018-07-31T01:10:52.540552: step 11492, loss 0.562623.
Train: 2018-07-31T01:10:52.681143: step 11493, loss 0.578931.
Train: 2018-07-31T01:10:52.821760: step 11494, loss 0.49741.
Train: 2018-07-31T01:10:52.962351: step 11495, loss 0.570741.
Train: 2018-07-31T01:10:53.118540: step 11496, loss 0.538042.
Train: 2018-07-31T01:10:53.259133: step 11497, loss 0.578957.
Train: 2018-07-31T01:10:53.399726: step 11498, loss 0.595302.
Train: 2018-07-31T01:10:53.540318: step 11499, loss 0.537992.
Train: 2018-07-31T01:10:53.680910: step 11500, loss 0.472375.
Test: 2018-07-31T01:10:53.930881: step 11500, loss 0.548847.
Train: 2018-07-31T01:10:54.743161: step 11501, loss 0.546153.
Train: 2018-07-31T01:10:54.883752: step 11502, loss 0.513113.
Train: 2018-07-31T01:10:55.024369: step 11503, loss 0.512797.
Train: 2018-07-31T01:10:55.164937: step 11504, loss 0.545952.
Train: 2018-07-31T01:10:55.305529: step 11505, loss 0.529029.
Train: 2018-07-31T01:10:55.446121: step 11506, loss 0.545331.
Train: 2018-07-31T01:10:55.586742: step 11507, loss 0.604475.
Train: 2018-07-31T01:10:55.742951: step 11508, loss 0.604308.
Train: 2018-07-31T01:10:55.883518: step 11509, loss 0.528144.
Train: 2018-07-31T01:10:56.024135: step 11510, loss 0.596568.
Test: 2018-07-31T01:10:56.274083: step 11510, loss 0.548039.
Train: 2018-07-31T01:10:56.414644: step 11511, loss 0.562315.
Train: 2018-07-31T01:10:56.555235: step 11512, loss 0.562801.
Train: 2018-07-31T01:10:56.695829: step 11513, loss 0.528342.
Train: 2018-07-31T01:10:56.836420: step 11514, loss 0.579543.
Train: 2018-07-31T01:10:56.992655: step 11515, loss 0.553728.
Train: 2018-07-31T01:10:57.133227: step 11516, loss 0.579184.
Train: 2018-07-31T01:10:57.273843: step 11517, loss 0.638685.
Train: 2018-07-31T01:10:57.414434: step 11518, loss 0.646965.
Train: 2018-07-31T01:10:57.555002: step 11519, loss 0.511809.
Train: 2018-07-31T01:10:57.695619: step 11520, loss 0.587093.
Test: 2018-07-31T01:10:57.945537: step 11520, loss 0.548446.
Train: 2018-07-31T01:10:58.086128: step 11521, loss 0.52054.
Train: 2018-07-31T01:10:58.242342: step 11522, loss 0.562432.
Train: 2018-07-31T01:10:58.382934: step 11523, loss 0.720491.
Train: 2018-07-31T01:10:58.523525: step 11524, loss 0.58718.
Train: 2018-07-31T01:10:58.664117: step 11525, loss 0.611523.
Train: 2018-07-31T01:10:58.820331: step 11526, loss 0.554304.
Train: 2018-07-31T01:10:58.960923: step 11527, loss 0.505914.
Train: 2018-07-31T01:10:59.101515: step 11528, loss 0.578871.
Train: 2018-07-31T01:10:59.257753: step 11529, loss 0.522335.
Train: 2018-07-31T01:10:59.398322: step 11530, loss 0.562752.
Test: 2018-07-31T01:10:59.648263: step 11530, loss 0.549322.
Train: 2018-07-31T01:10:59.788855: step 11531, loss 0.578827.
Train: 2018-07-31T01:10:59.929470: step 11532, loss 0.595079.
Train: 2018-07-31T01:11:00.085685: step 11533, loss 0.610884.
Train: 2018-07-31T01:11:00.241897: step 11534, loss 0.61883.
Train: 2018-07-31T01:11:00.382465: step 11535, loss 0.515395.
Train: 2018-07-31T01:11:00.523058: step 11536, loss 0.570928.
Train: 2018-07-31T01:11:00.663673: step 11537, loss 0.547324.
Train: 2018-07-31T01:11:00.819863: step 11538, loss 0.586767.
Train: 2018-07-31T01:11:00.960454: step 11539, loss 0.5946.
Train: 2018-07-31T01:11:01.101046: step 11540, loss 0.555375.
Test: 2018-07-31T01:11:01.351019: step 11540, loss 0.550105.
Train: 2018-07-31T01:11:01.491580: step 11541, loss 0.555278.
Train: 2018-07-31T01:11:01.632173: step 11542, loss 0.539778.
Train: 2018-07-31T01:11:01.772789: step 11543, loss 0.508643.
Train: 2018-07-31T01:11:01.928979: step 11544, loss 0.547608.
Train: 2018-07-31T01:11:02.069569: step 11545, loss 0.555377.
Train: 2018-07-31T01:11:02.210176: step 11546, loss 0.48448.
Train: 2018-07-31T01:11:02.350754: step 11547, loss 0.563105.
Train: 2018-07-31T01:11:02.491347: step 11548, loss 0.515433.
Train: 2018-07-31T01:11:02.631938: step 11549, loss 0.594863.
Train: 2018-07-31T01:11:02.772530: step 11550, loss 0.531092.
Test: 2018-07-31T01:11:03.006851: step 11550, loss 0.549361.
Train: 2018-07-31T01:11:03.147448: step 11551, loss 0.586801.
Train: 2018-07-31T01:11:03.303657: step 11552, loss 0.570889.
Train: 2018-07-31T01:11:03.444272: step 11553, loss 0.522349.
Train: 2018-07-31T01:11:03.584839: step 11554, loss 0.554578.
Train: 2018-07-31T01:11:03.725432: step 11555, loss 0.513947.
Train: 2018-07-31T01:11:03.866024: step 11556, loss 0.603495.
Train: 2018-07-31T01:11:04.022238: step 11557, loss 0.611704.
Train: 2018-07-31T01:11:04.162854: step 11558, loss 0.513409.
Train: 2018-07-31T01:11:04.303421: step 11559, loss 0.587175.
Train: 2018-07-31T01:11:04.444039: step 11560, loss 0.570848.
Test: 2018-07-31T01:11:04.678364: step 11560, loss 0.548739.
Train: 2018-07-31T01:11:04.834572: step 11561, loss 0.554288.
Train: 2018-07-31T01:11:04.975141: step 11562, loss 0.529569.
Train: 2018-07-31T01:11:05.100135: step 11563, loss 0.570669.
Train: 2018-07-31T01:11:05.240704: step 11564, loss 0.570764.
Train: 2018-07-31T01:11:05.396917: step 11565, loss 0.554188.
Train: 2018-07-31T01:11:05.537509: step 11566, loss 0.579077.
Train: 2018-07-31T01:11:05.678101: step 11567, loss 0.562452.
Train: 2018-07-31T01:11:05.818716: step 11568, loss 0.645402.
Train: 2018-07-31T01:11:05.959309: step 11569, loss 0.612153.
Train: 2018-07-31T01:11:06.115499: step 11570, loss 0.513092.
Test: 2018-07-31T01:11:06.349817: step 11570, loss 0.548809.
Train: 2018-07-31T01:11:06.506032: step 11571, loss 0.554324.
Train: 2018-07-31T01:11:06.646624: step 11572, loss 0.546129.
Train: 2018-07-31T01:11:06.787216: step 11573, loss 0.496865.
Train: 2018-07-31T01:11:06.927807: step 11574, loss 0.57077.
Train: 2018-07-31T01:11:07.068399: step 11575, loss 0.562533.
Train: 2018-07-31T01:11:07.208991: step 11576, loss 0.570757.
Train: 2018-07-31T01:11:07.349584: step 11577, loss 0.513187.
Train: 2018-07-31T01:11:07.490175: step 11578, loss 0.570762.
Train: 2018-07-31T01:11:07.630793: step 11579, loss 0.504811.
Train: 2018-07-31T01:11:07.787005: step 11580, loss 0.60379.
Test: 2018-07-31T01:11:08.021304: step 11580, loss 0.548593.
Train: 2018-07-31T01:11:08.177516: step 11581, loss 0.562498.
Train: 2018-07-31T01:11:08.318107: step 11582, loss 0.579019.
Train: 2018-07-31T01:11:08.474344: step 11583, loss 0.554203.
Train: 2018-07-31T01:11:08.614913: step 11584, loss 0.562466.
Train: 2018-07-31T01:11:08.755504: step 11585, loss 0.595596.
Train: 2018-07-31T01:11:08.896121: step 11586, loss 0.636912.
Train: 2018-07-31T01:11:09.036713: step 11587, loss 0.537709.
Train: 2018-07-31T01:11:09.192903: step 11588, loss 0.620168.
Train: 2018-07-31T01:11:09.349116: step 11589, loss 0.537712.
Train: 2018-07-31T01:11:09.520951: step 11590, loss 0.636968.
Test: 2018-07-31T01:11:09.755302: step 11590, loss 0.548698.
Train: 2018-07-31T01:11:09.911483: step 11591, loss 0.587055.
Train: 2018-07-31T01:11:10.052075: step 11592, loss 0.57077.
Train: 2018-07-31T01:11:10.192686: step 11593, loss 0.522059.
Train: 2018-07-31T01:11:10.333260: step 11594, loss 0.51412.
Train: 2018-07-31T01:11:10.489474: step 11595, loss 0.481813.
Train: 2018-07-31T01:11:10.645688: step 11596, loss 0.586974.
Train: 2018-07-31T01:11:10.770683: step 11597, loss 0.570902.
Train: 2018-07-31T01:11:10.911274: step 11598, loss 0.554559.
Train: 2018-07-31T01:11:11.051866: step 11599, loss 0.60315.
Train: 2018-07-31T01:11:11.192458: step 11600, loss 0.578969.
Test: 2018-07-31T01:11:11.426753: step 11600, loss 0.54896.
Train: 2018-07-31T01:11:12.145360: step 11601, loss 0.538319.
Train: 2018-07-31T01:11:12.285951: step 11602, loss 0.594993.
Train: 2018-07-31T01:11:12.442142: step 11603, loss 0.578831.
Train: 2018-07-31T01:11:12.582735: step 11604, loss 0.6116.
Train: 2018-07-31T01:11:12.723325: step 11605, loss 0.578934.
Train: 2018-07-31T01:11:12.863937: step 11606, loss 0.506358.
Train: 2018-07-31T01:11:13.020130: step 11607, loss 0.570767.
Train: 2018-07-31T01:11:13.160723: step 11608, loss 0.57886.
Train: 2018-07-31T01:11:13.301339: step 11609, loss 0.530702.
Train: 2018-07-31T01:11:13.441906: step 11610, loss 0.53872.
Test: 2018-07-31T01:11:13.691861: step 11610, loss 0.54928.
Train: 2018-07-31T01:11:13.832464: step 11611, loss 0.578843.
Train: 2018-07-31T01:11:13.988655: step 11612, loss 0.570837.
Train: 2018-07-31T01:11:14.129270: step 11613, loss 0.54664.
Train: 2018-07-31T01:11:14.269855: step 11614, loss 0.570782.
Train: 2018-07-31T01:11:14.410448: step 11615, loss 0.53054.
Train: 2018-07-31T01:11:14.551023: step 11616, loss 0.538493.
Train: 2018-07-31T01:11:14.707261: step 11617, loss 0.5627.
Train: 2018-07-31T01:11:14.847869: step 11618, loss 0.56263.
Train: 2018-07-31T01:11:15.004040: step 11619, loss 0.529823.
Train: 2018-07-31T01:11:15.144633: step 11620, loss 0.537838.
Test: 2018-07-31T01:11:15.394600: step 11620, loss 0.548425.
Train: 2018-07-31T01:11:15.535167: step 11621, loss 0.586255.
Train: 2018-07-31T01:11:15.691404: step 11622, loss 0.621422.
Train: 2018-07-31T01:11:15.831972: step 11623, loss 0.571855.
Train: 2018-07-31T01:11:15.988192: step 11624, loss 0.537959.
Train: 2018-07-31T01:11:16.144399: step 11625, loss 0.562237.
Train: 2018-07-31T01:11:16.284991: step 11626, loss 0.496014.
Train: 2018-07-31T01:11:16.425607: step 11627, loss 0.563642.
Train: 2018-07-31T01:11:16.581797: step 11628, loss 0.553903.
Train: 2018-07-31T01:11:16.722413: step 11629, loss 0.520853.
Train: 2018-07-31T01:11:16.862982: step 11630, loss 0.546241.
Test: 2018-07-31T01:11:17.112952: step 11630, loss 0.548191.
Train: 2018-07-31T01:11:17.284757: step 11631, loss 0.512042.
Train: 2018-07-31T01:11:17.425348: step 11632, loss 0.570413.
Train: 2018-07-31T01:11:17.565941: step 11633, loss 0.536787.
Train: 2018-07-31T01:11:17.722178: step 11634, loss 0.54514.
Train: 2018-07-31T01:11:17.878369: step 11635, loss 0.511988.
Train: 2018-07-31T01:11:18.018961: step 11636, loss 0.590363.
Train: 2018-07-31T01:11:18.175174: step 11637, loss 0.59546.
Train: 2018-07-31T01:11:18.315787: step 11638, loss 0.648501.
Train: 2018-07-31T01:11:18.471980: step 11639, loss 0.511876.
Train: 2018-07-31T01:11:18.612589: step 11640, loss 0.555313.
Test: 2018-07-31T01:11:18.846921: step 11640, loss 0.548253.
Train: 2018-07-31T01:11:19.003129: step 11641, loss 0.529421.
Train: 2018-07-31T01:11:19.143721: step 11642, loss 0.629374.
Train: 2018-07-31T01:11:19.284313: step 11643, loss 0.520512.
Train: 2018-07-31T01:11:19.440503: step 11644, loss 0.529192.
Train: 2018-07-31T01:11:19.565497: step 11645, loss 0.537441.
Train: 2018-07-31T01:11:19.721687: step 11646, loss 0.545773.
Train: 2018-07-31T01:11:19.862278: step 11647, loss 0.529174.
Train: 2018-07-31T01:11:20.018494: step 11648, loss 0.495857.
Train: 2018-07-31T01:11:20.159085: step 11649, loss 0.579109.
Train: 2018-07-31T01:11:20.299675: step 11650, loss 0.58749.
Test: 2018-07-31T01:11:20.534033: step 11650, loss 0.548404.
Train: 2018-07-31T01:11:20.705831: step 11651, loss 0.554043.
Train: 2018-07-31T01:11:20.846422: step 11652, loss 0.637762.
Train: 2018-07-31T01:11:20.987039: step 11653, loss 0.545677.
Train: 2018-07-31T01:11:21.127607: step 11654, loss 0.554051.
Train: 2018-07-31T01:11:21.268198: step 11655, loss 0.545701.
Train: 2018-07-31T01:11:21.408791: step 11656, loss 0.55406.
Train: 2018-07-31T01:11:21.565006: step 11657, loss 0.579124.
Train: 2018-07-31T01:11:21.705596: step 11658, loss 0.587467.
Train: 2018-07-31T01:11:21.846189: step 11659, loss 0.579105.
Train: 2018-07-31T01:11:21.986781: step 11660, loss 0.520805.
Test: 2018-07-31T01:11:22.236752: step 11660, loss 0.548506.
Train: 2018-07-31T01:11:22.377339: step 11661, loss 0.620691.
Train: 2018-07-31T01:11:22.517930: step 11662, loss 0.570759.
Train: 2018-07-31T01:11:22.674119: step 11663, loss 0.603912.
Train: 2018-07-31T01:11:22.814713: step 11664, loss 0.595551.
Train: 2018-07-31T01:11:22.955304: step 11665, loss 0.546046.
Train: 2018-07-31T01:11:23.111542: step 11666, loss 0.546116.
Train: 2018-07-31T01:11:23.252135: step 11667, loss 0.570763.
Train: 2018-07-31T01:11:23.408323: step 11668, loss 0.562587.
Train: 2018-07-31T01:11:23.548916: step 11669, loss 0.587099.
Train: 2018-07-31T01:11:23.689509: step 11670, loss 0.595212.
Test: 2018-07-31T01:11:23.923855: step 11670, loss 0.549104.
Train: 2018-07-31T01:11:24.142527: step 11671, loss 0.570787.
Train: 2018-07-31T01:11:24.283142: step 11672, loss 0.586996.
Train: 2018-07-31T01:11:24.439380: step 11673, loss 0.522362.
Train: 2018-07-31T01:11:24.579949: step 11674, loss 0.595002.
Train: 2018-07-31T01:11:24.720516: step 11675, loss 0.570831.
Train: 2018-07-31T01:11:24.876755: step 11676, loss 0.538742.
Train: 2018-07-31T01:11:25.032943: step 11677, loss 0.562836.
Train: 2018-07-31T01:11:25.173548: step 11678, loss 0.562852.
Train: 2018-07-31T01:11:25.314126: step 11679, loss 0.538866.
Train: 2018-07-31T01:11:25.454719: step 11680, loss 0.554867.
Test: 2018-07-31T01:11:25.704690: step 11680, loss 0.549465.
Train: 2018-07-31T01:11:25.845252: step 11681, loss 0.570863.
Train: 2018-07-31T01:11:26.001467: step 11682, loss 0.586864.
Train: 2018-07-31T01:11:26.142058: step 11683, loss 0.570865.
Train: 2018-07-31T01:11:26.282675: step 11684, loss 0.530897.
Train: 2018-07-31T01:11:26.438864: step 11685, loss 0.570865.
Train: 2018-07-31T01:11:26.595101: step 11686, loss 0.546861.
Train: 2018-07-31T01:11:26.735670: step 11687, loss 0.522816.
Train: 2018-07-31T01:11:26.876261: step 11688, loss 0.578868.
Train: 2018-07-31T01:11:27.016870: step 11689, loss 0.52265.
Train: 2018-07-31T01:11:27.173065: step 11690, loss 0.538629.
Test: 2018-07-31T01:11:27.407419: step 11690, loss 0.549226.
Train: 2018-07-31T01:11:27.563624: step 11691, loss 0.490107.
Train: 2018-07-31T01:11:27.704192: step 11692, loss 0.554586.
Train: 2018-07-31T01:11:27.860406: step 11693, loss 0.56264.
Train: 2018-07-31T01:11:28.000997: step 11694, loss 0.5871.
Train: 2018-07-31T01:11:28.141591: step 11695, loss 0.570763.
Train: 2018-07-31T01:11:28.282182: step 11696, loss 0.603577.
Train: 2018-07-31T01:11:28.422774: step 11697, loss 0.620054.
Train: 2018-07-31T01:11:28.579012: step 11698, loss 0.554342.
Train: 2018-07-31T01:11:28.719604: step 11699, loss 0.570765.
Train: 2018-07-31T01:11:28.875794: step 11700, loss 0.570762.
Test: 2018-07-31T01:11:29.110114: step 11700, loss 0.548844.
Train: 2018-07-31T01:11:29.828725: step 11701, loss 0.587152.
Train: 2018-07-31T01:11:29.969286: step 11702, loss 0.587133.
Train: 2018-07-31T01:11:30.109879: step 11703, loss 0.578941.
Train: 2018-07-31T01:11:30.266093: step 11704, loss 0.521844.
Train: 2018-07-31T01:11:30.391063: step 11705, loss 0.54633.
Train: 2018-07-31T01:11:30.531679: step 11706, loss 0.652238.
Train: 2018-07-31T01:11:30.687893: step 11707, loss 0.513897.
Train: 2018-07-31T01:11:30.828460: step 11708, loss 0.513955.
Train: 2018-07-31T01:11:30.969053: step 11709, loss 0.578907.
Train: 2018-07-31T01:11:31.109643: step 11710, loss 0.546426.
Test: 2018-07-31T01:11:31.359587: step 11710, loss 0.54906.
Train: 2018-07-31T01:11:31.515827: step 11711, loss 0.562662.
Train: 2018-07-31T01:11:31.672014: step 11712, loss 0.562659.
Train: 2018-07-31T01:11:31.812605: step 11713, loss 0.530143.
Train: 2018-07-31T01:11:31.953197: step 11714, loss 0.505685.
Train: 2018-07-31T01:11:32.093813: step 11715, loss 0.521836.
Train: 2018-07-31T01:11:32.250002: step 11716, loss 0.546222.
Train: 2018-07-31T01:11:32.390596: step 11717, loss 0.595396.
Train: 2018-07-31T01:11:32.531212: step 11718, loss 0.521412.
Train: 2018-07-31T01:11:32.671803: step 11719, loss 0.546014.
Train: 2018-07-31T01:11:32.812370: step 11720, loss 0.612092.
Test: 2018-07-31T01:11:33.062313: step 11720, loss 0.548601.
Train: 2018-07-31T01:11:33.202904: step 11721, loss 0.603965.
Train: 2018-07-31T01:11:33.359117: step 11722, loss 0.554203.
Train: 2018-07-31T01:11:33.499709: step 11723, loss 0.529361.
Train: 2018-07-31T01:11:33.655947: step 11724, loss 0.587335.
Train: 2018-07-31T01:11:33.796533: step 11725, loss 0.595618.
Train: 2018-07-31T01:11:33.937133: step 11726, loss 0.595603.
Train: 2018-07-31T01:11:34.093321: step 11727, loss 0.595557.
Train: 2018-07-31T01:11:34.249534: step 11728, loss 0.554254.
Train: 2018-07-31T01:11:34.390127: step 11729, loss 0.611924.
Train: 2018-07-31T01:11:34.530717: step 11730, loss 0.578976.
Test: 2018-07-31T01:11:34.765069: step 11730, loss 0.548866.
Train: 2018-07-31T01:11:34.921277: step 11731, loss 0.56258.
Train: 2018-07-31T01:11:35.077466: step 11732, loss 0.538114.
Train: 2018-07-31T01:11:35.218059: step 11733, loss 0.578926.
Train: 2018-07-31T01:11:35.374272: step 11734, loss 0.521991.
Train: 2018-07-31T01:11:35.514864: step 11735, loss 0.51391.
Train: 2018-07-31T01:11:35.655479: step 11736, loss 0.595169.
Train: 2018-07-31T01:11:35.811670: step 11737, loss 0.570787.
Train: 2018-07-31T01:11:35.952262: step 11738, loss 0.546427.
Train: 2018-07-31T01:11:36.077256: step 11739, loss 0.570785.
Train: 2018-07-31T01:11:36.233446: step 11740, loss 0.570793.
Test: 2018-07-31T01:11:36.467765: step 11740, loss 0.549078.
Train: 2018-07-31T01:11:36.608356: step 11741, loss 0.587008.
Train: 2018-07-31T01:11:36.748949: step 11742, loss 0.489699.
Train: 2018-07-31T01:11:36.905164: step 11743, loss 0.465212.
Train: 2018-07-31T01:11:37.045779: step 11744, loss 0.538019.
Train: 2018-07-31T01:11:37.201968: step 11745, loss 0.58732.
Train: 2018-07-31T01:11:37.342585: step 11746, loss 0.587229.
Train: 2018-07-31T01:11:37.483177: step 11747, loss 0.537888.
Train: 2018-07-31T01:11:37.623769: step 11748, loss 0.61204.
Train: 2018-07-31T01:11:37.779959: step 11749, loss 0.520999.
Train: 2018-07-31T01:11:37.920549: step 11750, loss 0.463062.
Test: 2018-07-31T01:11:38.154903: step 11750, loss 0.548418.
Train: 2018-07-31T01:11:38.311089: step 11751, loss 0.561906.
Train: 2018-07-31T01:11:38.451675: step 11752, loss 0.596383.
Train: 2018-07-31T01:11:38.592266: step 11753, loss 0.561543.
Train: 2018-07-31T01:11:38.732867: step 11754, loss 0.622753.
Train: 2018-07-31T01:11:38.889074: step 11755, loss 0.544134.
Train: 2018-07-31T01:11:39.029689: step 11756, loss 0.571346.
Train: 2018-07-31T01:11:39.185877: step 11757, loss 0.536497.
Train: 2018-07-31T01:11:39.326496: step 11758, loss 0.536988.
Train: 2018-07-31T01:11:39.482708: step 11759, loss 0.56097.
Train: 2018-07-31T01:11:39.638897: step 11760, loss 0.494757.
Test: 2018-07-31T01:11:39.873248: step 11760, loss 0.547996.
Train: 2018-07-31T01:11:40.029463: step 11761, loss 0.596926.
Train: 2018-07-31T01:11:40.170047: step 11762, loss 0.554227.
Train: 2018-07-31T01:11:40.310617: step 11763, loss 0.547217.
Train: 2018-07-31T01:11:40.451206: step 11764, loss 0.621604.
Train: 2018-07-31T01:11:40.591799: step 11765, loss 0.57929.
Train: 2018-07-31T01:11:40.732390: step 11766, loss 0.520178.
Train: 2018-07-31T01:11:40.873038: step 11767, loss 0.56186.
Train: 2018-07-31T01:11:41.013576: step 11768, loss 0.545166.
Train: 2018-07-31T01:11:41.169790: step 11769, loss 0.571604.
Train: 2018-07-31T01:11:41.326004: step 11770, loss 0.545297.
Test: 2018-07-31T01:11:41.560324: step 11770, loss 0.548441.
Train: 2018-07-31T01:11:41.716560: step 11771, loss 0.637345.
Train: 2018-07-31T01:11:41.857152: step 11772, loss 0.637178.
Train: 2018-07-31T01:11:41.997719: step 11773, loss 0.628784.
Train: 2018-07-31T01:11:42.138336: step 11774, loss 0.472353.
Train: 2018-07-31T01:11:42.278905: step 11775, loss 0.546266.
Train: 2018-07-31T01:11:42.435118: step 11776, loss 0.603386.
Train: 2018-07-31T01:11:42.575711: step 11777, loss 0.570796.
Train: 2018-07-31T01:11:42.716328: step 11778, loss 0.666386.
Train: 2018-07-31T01:11:42.856893: step 11779, loss 0.619182.
Train: 2018-07-31T01:11:42.997503: step 11780, loss 0.562835.
Test: 2018-07-31T01:11:43.247470: step 11780, loss 0.549546.
Train: 2018-07-31T01:11:43.388045: step 11781, loss 0.570884.
Train: 2018-07-31T01:11:43.528629: step 11782, loss 0.578858.
Train: 2018-07-31T01:11:43.669203: step 11783, loss 0.539339.
Train: 2018-07-31T01:11:43.809795: step 11784, loss 0.586744.
Train: 2018-07-31T01:11:43.950412: step 11785, loss 0.539607.
Train: 2018-07-31T01:11:44.090979: step 11786, loss 0.516191.
Train: 2018-07-31T01:11:44.247194: step 11787, loss 0.508397.
Train: 2018-07-31T01:11:44.387786: step 11788, loss 0.516156.
Train: 2018-07-31T01:11:44.528378: step 11789, loss 0.516001.
Train: 2018-07-31T01:11:44.668969: step 11790, loss 0.61041.
Test: 2018-07-31T01:11:44.918941: step 11790, loss 0.549822.
Train: 2018-07-31T01:11:45.059553: step 11791, loss 0.563054.
Train: 2018-07-31T01:11:45.215716: step 11792, loss 0.58678.
Train: 2018-07-31T01:11:45.356332: step 11793, loss 0.594722.
Train: 2018-07-31T01:11:45.496925: step 11794, loss 0.650291.
Train: 2018-07-31T01:11:45.653115: step 11795, loss 0.531305.
Train: 2018-07-31T01:11:45.793724: step 11796, loss 0.570936.
Train: 2018-07-31T01:11:45.934322: step 11797, loss 0.64222.
Train: 2018-07-31T01:11:46.074889: step 11798, loss 0.578861.
Train: 2018-07-31T01:11:46.215483: step 11799, loss 0.555205.
Train: 2018-07-31T01:11:46.356074: step 11800, loss 0.531623.
Test: 2018-07-31T01:11:46.606016: step 11800, loss 0.549953.
Train: 2018-07-31T01:11:47.324597: step 11801, loss 0.531644.
Train: 2018-07-31T01:11:47.465189: step 11802, loss 0.594616.
Train: 2018-07-31T01:11:47.605806: step 11803, loss 0.523745.
Train: 2018-07-31T01:11:47.746373: step 11804, loss 0.649813.
Train: 2018-07-31T01:11:47.886966: step 11805, loss 0.610367.
Train: 2018-07-31T01:11:48.027559: step 11806, loss 0.508127.
Train: 2018-07-31T01:11:48.183771: step 11807, loss 0.531715.
Train: 2018-07-31T01:11:48.324363: step 11808, loss 0.578868.
Train: 2018-07-31T01:11:48.464980: step 11809, loss 0.586738.
Train: 2018-07-31T01:11:48.605547: step 11810, loss 0.633967.
Test: 2018-07-31T01:11:48.855520: step 11810, loss 0.549988.
Train: 2018-07-31T01:11:49.011726: step 11811, loss 0.602449.
Train: 2018-07-31T01:11:49.152295: step 11812, loss 0.578875.
Train: 2018-07-31T01:11:49.292911: step 11813, loss 0.508445.
Train: 2018-07-31T01:11:49.449125: step 11814, loss 0.563234.
Train: 2018-07-31T01:11:49.605314: step 11815, loss 0.555412.
Train: 2018-07-31T01:11:49.745906: step 11816, loss 0.594534.
Train: 2018-07-31T01:11:49.886515: step 11817, loss 0.59453.
Train: 2018-07-31T01:11:50.042712: step 11818, loss 0.55543.
Train: 2018-07-31T01:11:50.183304: step 11819, loss 0.610149.
Train: 2018-07-31T01:11:50.323894: step 11820, loss 0.532051.
Test: 2018-07-31T01:11:50.558249: step 11820, loss 0.550205.
Train: 2018-07-31T01:11:50.698831: step 11821, loss 0.500833.
Train: 2018-07-31T01:11:50.855022: step 11822, loss 0.500689.
Train: 2018-07-31T01:11:50.995613: step 11823, loss 0.547489.
Train: 2018-07-31T01:11:51.151851: step 11824, loss 0.57099.
Train: 2018-07-31T01:11:51.292418: step 11825, loss 0.547264.
Train: 2018-07-31T01:11:51.433010: step 11826, loss 0.515432.
Train: 2018-07-31T01:11:51.573602: step 11827, loss 0.562933.
Train: 2018-07-31T01:11:51.714194: step 11828, loss 0.474888.
Train: 2018-07-31T01:11:51.854786: step 11829, loss 0.53865.
Train: 2018-07-31T01:11:51.995386: step 11830, loss 0.570812.
Test: 2018-07-31T01:11:52.245321: step 11830, loss 0.549015.
Train: 2018-07-31T01:11:52.385913: step 11831, loss 0.619607.
Train: 2018-07-31T01:11:52.542126: step 11832, loss 0.59525.
Train: 2018-07-31T01:11:52.682741: step 11833, loss 0.538031.
Train: 2018-07-31T01:11:52.823309: step 11834, loss 0.570801.
Train: 2018-07-31T01:11:52.963902: step 11835, loss 0.587198.
Train: 2018-07-31T01:11:53.104494: step 11836, loss 0.52958.
Train: 2018-07-31T01:11:53.245085: step 11837, loss 0.570765.
Train: 2018-07-31T01:11:53.385677: step 11838, loss 0.455126.
Train: 2018-07-31T01:11:53.526270: step 11839, loss 0.521031.
Train: 2018-07-31T01:11:53.698106: step 11840, loss 0.57075.
Test: 2018-07-31T01:11:53.932459: step 11840, loss 0.548368.
Train: 2018-07-31T01:11:54.073017: step 11841, loss 0.520744.
Train: 2018-07-31T01:11:54.229232: step 11842, loss 0.587583.
Train: 2018-07-31T01:11:54.369822: step 11843, loss 0.596071.
Train: 2018-07-31T01:11:54.510439: step 11844, loss 0.528637.
Train: 2018-07-31T01:11:54.651031: step 11845, loss 0.528509.
Train: 2018-07-31T01:11:54.791623: step 11846, loss 0.511604.
Train: 2018-07-31T01:11:54.932190: step 11847, loss 0.545449.
Train: 2018-07-31T01:11:55.088403: step 11848, loss 0.5453.
Train: 2018-07-31T01:11:55.229022: step 11849, loss 0.570715.
Train: 2018-07-31T01:11:55.369613: step 11850, loss 0.58808.
Test: 2018-07-31T01:11:55.619560: step 11850, loss 0.547965.
Train: 2018-07-31T01:11:55.775768: step 11851, loss 0.485072.
Train: 2018-07-31T01:11:55.916361: step 11852, loss 0.596508.
Train: 2018-07-31T01:11:56.056927: step 11853, loss 0.562138.
Train: 2018-07-31T01:11:56.197538: step 11854, loss 0.579265.
Train: 2018-07-31T01:11:56.353733: step 11855, loss 0.605592.
Train: 2018-07-31T01:11:56.494349: step 11856, loss 0.501636.
Train: 2018-07-31T01:11:56.650538: step 11857, loss 0.571218.
Train: 2018-07-31T01:11:56.806753: step 11858, loss 0.571007.
Train: 2018-07-31T01:11:56.947371: step 11859, loss 0.518621.
Train: 2018-07-31T01:11:57.087979: step 11860, loss 0.51898.
Test: 2018-07-31T01:11:57.322258: step 11860, loss 0.547664.
Train: 2018-07-31T01:11:57.462848: step 11861, loss 0.466732.
Train: 2018-07-31T01:11:57.619087: step 11862, loss 0.553995.
Train: 2018-07-31T01:11:57.744031: step 11863, loss 0.55387.
Train: 2018-07-31T01:11:57.900247: step 11864, loss 0.62226.
Train: 2018-07-31T01:11:58.056460: step 11865, loss 0.562578.
Train: 2018-07-31T01:11:58.197075: step 11866, loss 0.510039.
Train: 2018-07-31T01:11:58.353265: step 11867, loss 0.51738.
Train: 2018-07-31T01:11:58.493881: step 11868, loss 0.58017.
Train: 2018-07-31T01:11:58.634448: step 11869, loss 0.580992.
Train: 2018-07-31T01:11:58.775065: step 11870, loss 0.564343.
Test: 2018-07-31T01:11:59.024984: step 11870, loss 0.547644.
Train: 2018-07-31T01:11:59.165574: step 11871, loss 0.634099.
Train: 2018-07-31T01:11:59.321788: step 11872, loss 0.510575.
Train: 2018-07-31T01:11:59.462405: step 11873, loss 0.588123.
Train: 2018-07-31T01:11:59.602996: step 11874, loss 0.5457.
Train: 2018-07-31T01:11:59.759197: step 11875, loss 0.52811.
Train: 2018-07-31T01:11:59.915399: step 11876, loss 0.511191.
Train: 2018-07-31T01:12:00.055992: step 11877, loss 0.604747.
Train: 2018-07-31T01:12:00.196582: step 11878, loss 0.663875.
Train: 2018-07-31T01:12:00.337201: step 11879, loss 0.57918.
Train: 2018-07-31T01:12:00.477792: step 11880, loss 0.570792.
Test: 2018-07-31T01:12:00.712118: step 11880, loss 0.548431.
Train: 2018-07-31T01:12:00.868325: step 11881, loss 0.604174.
Train: 2018-07-31T01:12:01.024514: step 11882, loss 0.545822.
Train: 2018-07-31T01:12:01.149509: step 11883, loss 0.570757.
Train: 2018-07-31T01:12:01.305699: step 11884, loss 0.587255.
Train: 2018-07-31T01:12:01.446291: step 11885, loss 0.611839.
Train: 2018-07-31T01:12:01.586882: step 11886, loss 0.52171.
Train: 2018-07-31T01:12:01.727474: step 11887, loss 0.587072.
Train: 2018-07-31T01:12:01.883688: step 11888, loss 0.587025.
Train: 2018-07-31T01:12:02.024281: step 11889, loss 0.546543.
Train: 2018-07-31T01:12:02.164896: step 11890, loss 0.546629.
Test: 2018-07-31T01:12:02.414819: step 11890, loss 0.54928.
Train: 2018-07-31T01:12:02.555449: step 11891, loss 0.594956.
Train: 2018-07-31T01:12:02.696026: step 11892, loss 0.490608.
Train: 2018-07-31T01:12:02.852212: step 11893, loss 0.522691.
Train: 2018-07-31T01:12:03.008449: step 11894, loss 0.643136.
Train: 2018-07-31T01:12:03.149017: step 11895, loss 0.563006.
Train: 2018-07-31T01:12:03.305231: step 11896, loss 0.562889.
Train: 2018-07-31T01:12:03.445842: step 11897, loss 0.554859.
Train: 2018-07-31T01:12:03.586414: step 11898, loss 0.506984.
Train: 2018-07-31T01:12:03.727007: step 11899, loss 0.634861.
Train: 2018-07-31T01:12:03.867598: step 11900, loss 0.51498.
Test: 2018-07-31T01:12:04.101944: step 11900, loss 0.549506.
Train: 2018-07-31T01:12:04.851742: step 11901, loss 0.570873.
Train: 2018-07-31T01:12:04.992359: step 11902, loss 0.522921.
Train: 2018-07-31T01:12:05.132951: step 11903, loss 0.59487.
Train: 2018-07-31T01:12:05.289142: step 11904, loss 0.538825.
Train: 2018-07-31T01:12:05.445355: step 11905, loss 0.578866.
Train: 2018-07-31T01:12:05.585971: step 11906, loss 0.578865.
Train: 2018-07-31T01:12:05.726563: step 11907, loss 0.5307.
Train: 2018-07-31T01:12:05.882753: step 11908, loss 0.627099.
Train: 2018-07-31T01:12:06.023344: step 11909, loss 0.530634.
Train: 2018-07-31T01:12:06.163960: step 11910, loss 0.619058.
Test: 2018-07-31T01:12:06.398256: step 11910, loss 0.549319.
Train: 2018-07-31T01:12:06.570090: step 11911, loss 0.506493.
Train: 2018-07-31T01:12:06.726305: step 11912, loss 0.530522.
Train: 2018-07-31T01:12:06.866920: step 11913, loss 0.586949.
Train: 2018-07-31T01:12:07.023134: step 11914, loss 0.578879.
Train: 2018-07-31T01:12:07.163729: step 11915, loss 0.611693.
Train: 2018-07-31T01:12:07.304318: step 11916, loss 0.522201.
Train: 2018-07-31T01:12:07.460508: step 11917, loss 0.595418.
Train: 2018-07-31T01:12:07.601100: step 11918, loss 0.530308.
Train: 2018-07-31T01:12:07.726094: step 11919, loss 0.538585.
Train: 2018-07-31T01:12:07.882284: step 11920, loss 0.570832.
Test: 2018-07-31T01:12:08.116603: step 11920, loss 0.549055.
Train: 2018-07-31T01:12:08.257195: step 11921, loss 0.578844.
Train: 2018-07-31T01:12:08.413409: step 11922, loss 0.594954.
Train: 2018-07-31T01:12:08.554002: step 11923, loss 0.546651.
Train: 2018-07-31T01:12:08.710216: step 11924, loss 0.619315.
Train: 2018-07-31T01:12:08.835209: step 11925, loss 0.562766.
Train: 2018-07-31T01:12:08.991423: step 11926, loss 0.554737.
Train: 2018-07-31T01:12:09.132015: step 11927, loss 0.635151.
Train: 2018-07-31T01:12:09.272607: step 11928, loss 0.498656.
Train: 2018-07-31T01:12:09.413200: step 11929, loss 0.59704.
Train: 2018-07-31T01:12:09.569389: step 11930, loss 0.60289.
Test: 2018-07-31T01:12:09.803709: step 11930, loss 0.549497.
Train: 2018-07-31T01:12:09.959923: step 11931, loss 0.562876.
Train: 2018-07-31T01:12:10.100514: step 11932, loss 0.515018.
Train: 2018-07-31T01:12:10.241105: step 11933, loss 0.594818.
Train: 2018-07-31T01:12:10.381699: step 11934, loss 0.594805.
Train: 2018-07-31T01:12:10.522291: step 11935, loss 0.602743.
Train: 2018-07-31T01:12:10.662882: step 11936, loss 0.555025.
Train: 2018-07-31T01:12:10.819120: step 11937, loss 0.547131.
Train: 2018-07-31T01:12:10.975313: step 11938, loss 0.634335.
Train: 2018-07-31T01:12:11.115925: step 11939, loss 0.578861.
Train: 2018-07-31T01:12:11.272113: step 11940, loss 0.58675.
Test: 2018-07-31T01:12:11.506465: step 11940, loss 0.550116.
Train: 2018-07-31T01:12:11.662647: step 11941, loss 0.563137.
Train: 2018-07-31T01:12:11.803240: step 11942, loss 0.531776.
Train: 2018-07-31T01:12:11.943833: step 11943, loss 0.48477.
Train: 2018-07-31T01:12:12.084442: step 11944, loss 0.586723.
Train: 2018-07-31T01:12:12.225016: step 11945, loss 0.571012.
Train: 2018-07-31T01:12:12.381230: step 11946, loss 0.547408.
Train: 2018-07-31T01:12:12.521822: step 11947, loss 0.53949.
Train: 2018-07-31T01:12:12.646817: step 11948, loss 0.547302.
Train: 2018-07-31T01:12:12.787410: step 11949, loss 0.563043.
Train: 2018-07-31T01:12:12.927977: step 11950, loss 0.523375.
Test: 2018-07-31T01:12:13.177918: step 11950, loss 0.549524.
Train: 2018-07-31T01:12:13.318511: step 11951, loss 0.547053.
Train: 2018-07-31T01:12:13.459103: step 11952, loss 0.491071.
Train: 2018-07-31T01:12:13.599696: step 11953, loss 0.594922.
Train: 2018-07-31T01:12:13.740286: step 11954, loss 0.619124.
Train: 2018-07-31T01:12:13.880880: step 11955, loss 0.595083.
Train: 2018-07-31T01:12:14.021470: step 11956, loss 0.538515.
Train: 2018-07-31T01:12:14.162062: step 11957, loss 0.538416.
Train: 2018-07-31T01:12:14.302655: step 11958, loss 0.505966.
Train: 2018-07-31T01:12:14.443264: step 11959, loss 0.50573.
Train: 2018-07-31T01:12:14.599460: step 11960, loss 0.53805.
Test: 2018-07-31T01:12:14.833811: step 11960, loss 0.548764.
Train: 2018-07-31T01:12:14.989995: step 11961, loss 0.603761.
Train: 2018-07-31T01:12:15.146207: step 11962, loss 0.513125.
Train: 2018-07-31T01:12:15.286799: step 11963, loss 0.554087.
Train: 2018-07-31T01:12:15.427392: step 11964, loss 0.562528.
Train: 2018-07-31T01:12:15.552362: step 11965, loss 0.603911.
Train: 2018-07-31T01:12:15.692955: step 11966, loss 0.478885.
Train: 2018-07-31T01:12:15.849203: step 11967, loss 0.603984.
Train: 2018-07-31T01:12:15.989761: step 11968, loss 0.545569.
Train: 2018-07-31T01:12:16.130376: step 11969, loss 0.537155.
Train: 2018-07-31T01:12:16.270968: step 11970, loss 0.63896.
Test: 2018-07-31T01:12:16.520886: step 11970, loss 0.548064.
Train: 2018-07-31T01:12:16.661479: step 11971, loss 0.545498.
Train: 2018-07-31T01:12:16.802070: step 11972, loss 0.58717.
Train: 2018-07-31T01:12:16.942661: step 11973, loss 0.554194.
Train: 2018-07-31T01:12:17.098875: step 11974, loss 0.59658.
Train: 2018-07-31T01:12:17.239492: step 11975, loss 0.544433.
Train: 2018-07-31T01:12:17.395680: step 11976, loss 0.580004.
Train: 2018-07-31T01:12:17.536272: step 11977, loss 0.613583.
Train: 2018-07-31T01:12:17.676889: step 11978, loss 0.554016.
Train: 2018-07-31T01:12:17.833078: step 11979, loss 0.570784.
Train: 2018-07-31T01:12:17.989315: step 11980, loss 0.554141.
Test: 2018-07-31T01:12:18.239232: step 11980, loss 0.548601.
Train: 2018-07-31T01:12:18.379826: step 11981, loss 0.545987.
Train: 2018-07-31T01:12:18.520442: step 11982, loss 0.529534.
Train: 2018-07-31T01:12:18.676630: step 11983, loss 0.554283.
Train: 2018-07-31T01:12:18.817224: step 11984, loss 0.546066.
Train: 2018-07-31T01:12:18.957815: step 11985, loss 0.5543.
Train: 2018-07-31T01:12:19.098406: step 11986, loss 0.611899.
Train: 2018-07-31T01:12:19.238999: step 11987, loss 0.529668.
Train: 2018-07-31T01:12:19.379616: step 11988, loss 0.58719.
Train: 2018-07-31T01:12:19.535806: step 11989, loss 0.562554.
Train: 2018-07-31T01:12:19.676396: step 11990, loss 0.521563.
Test: 2018-07-31T01:12:19.910750: step 11990, loss 0.548839.
Train: 2018-07-31T01:12:20.066929: step 11991, loss 0.595364.
Train: 2018-07-31T01:12:20.191926: step 11992, loss 0.513397.
Train: 2018-07-31T01:12:20.348113: step 11993, loss 0.59536.
Train: 2018-07-31T01:12:20.488706: step 11994, loss 0.537977.
Train: 2018-07-31T01:12:20.629300: step 11995, loss 0.619953.
Train: 2018-07-31T01:12:20.769915: step 11996, loss 0.578953.
Train: 2018-07-31T01:12:20.926129: step 11997, loss 0.595299.
Train: 2018-07-31T01:12:21.082318: step 11998, loss 0.513651.
Train: 2018-07-31T01:12:21.222910: step 11999, loss 0.595237.
Train: 2018-07-31T01:12:21.363503: step 12000, loss 0.595206.
Test: 2018-07-31T01:12:21.613467: step 12000, loss 0.54905.
Train: 2018-07-31T01:12:22.394508: step 12001, loss 0.562658.
Train: 2018-07-31T01:12:22.550724: step 12002, loss 0.522117.
Train: 2018-07-31T01:12:22.706936: step 12003, loss 0.546468.
Train: 2018-07-31T01:12:22.847529: step 12004, loss 0.554582.
Train: 2018-07-31T01:12:22.988139: step 12005, loss 0.489701.
Train: 2018-07-31T01:12:23.144334: step 12006, loss 0.611403.
Train: 2018-07-31T01:12:23.284925: step 12007, loss 0.554516.
Train: 2018-07-31T01:12:23.441141: step 12008, loss 0.522016.
Train: 2018-07-31T01:12:23.597378: step 12009, loss 0.570798.
Train: 2018-07-31T01:12:23.737945: step 12010, loss 0.644159.
Test: 2018-07-31T01:12:23.972268: step 12010, loss 0.548984.
Train: 2018-07-31T01:12:24.128503: step 12011, loss 0.570763.
Train: 2018-07-31T01:12:24.269072: step 12012, loss 0.538217.
Train: 2018-07-31T01:12:24.409709: step 12013, loss 0.55454.
Train: 2018-07-31T01:12:24.550279: step 12014, loss 0.554522.
Train: 2018-07-31T01:12:24.706469: step 12015, loss 0.505676.
Train: 2018-07-31T01:12:24.847061: step 12016, loss 0.619672.
Train: 2018-07-31T01:12:24.987677: step 12017, loss 0.595226.
Train: 2018-07-31T01:12:25.128270: step 12018, loss 0.489351.
Train: 2018-07-31T01:12:25.268863: step 12019, loss 0.554477.
Train: 2018-07-31T01:12:25.409430: step 12020, loss 0.546296.
Test: 2018-07-31T01:12:25.643749: step 12020, loss 0.548918.
Train: 2018-07-31T01:12:25.799963: step 12021, loss 0.59528.
Train: 2018-07-31T01:12:25.940556: step 12022, loss 0.529904.
Train: 2018-07-31T01:12:26.081147: step 12023, loss 0.538039.
Train: 2018-07-31T01:12:26.221739: step 12024, loss 0.562566.
Train: 2018-07-31T01:12:26.377951: step 12025, loss 0.587164.
Train: 2018-07-31T01:12:26.518545: step 12026, loss 0.521501.
Train: 2018-07-31T01:12:26.674757: step 12027, loss 0.562526.
Train: 2018-07-31T01:12:26.815351: step 12028, loss 0.628373.
Train: 2018-07-31T01:12:26.955943: step 12029, loss 0.529592.
Train: 2018-07-31T01:12:27.096559: step 12030, loss 0.488383.
Test: 2018-07-31T01:12:27.330884: step 12030, loss 0.548685.
Train: 2018-07-31T01:12:27.487068: step 12031, loss 0.562496.
Train: 2018-07-31T01:12:27.627661: step 12032, loss 0.537678.
Train: 2018-07-31T01:12:27.783874: step 12033, loss 0.579068.
Train: 2018-07-31T01:12:27.924493: step 12034, loss 0.562428.
Train: 2018-07-31T01:12:28.080679: step 12035, loss 0.654047.
Train: 2018-07-31T01:12:28.221269: step 12036, loss 0.537516.
Train: 2018-07-31T01:12:28.361888: step 12037, loss 0.537543.
Train: 2018-07-31T01:12:28.518076: step 12038, loss 0.587436.
Train: 2018-07-31T01:12:28.674290: step 12039, loss 0.562487.
Train: 2018-07-31T01:12:28.814880: step 12040, loss 0.603784.
Test: 2018-07-31T01:12:29.049204: step 12040, loss 0.548646.
Train: 2018-07-31T01:12:29.205414: step 12041, loss 0.636863.
Train: 2018-07-31T01:12:29.346007: step 12042, loss 0.537798.
Train: 2018-07-31T01:12:29.486600: step 12043, loss 0.521442.
Train: 2018-07-31T01:12:29.627216: step 12044, loss 0.537937.
Train: 2018-07-31T01:12:29.767783: step 12045, loss 0.60357.
Train: 2018-07-31T01:12:29.908400: step 12046, loss 0.505206.
Train: 2018-07-31T01:12:30.048992: step 12047, loss 0.537992.
Train: 2018-07-31T01:12:30.205181: step 12048, loss 0.578955.
Train: 2018-07-31T01:12:30.345773: step 12049, loss 0.603569.
Train: 2018-07-31T01:12:30.501987: step 12050, loss 0.546193.
Test: 2018-07-31T01:12:30.736338: step 12050, loss 0.548871.
Train: 2018-07-31T01:12:30.892520: step 12051, loss 0.521666.
Train: 2018-07-31T01:12:31.033136: step 12052, loss 0.652666.
Train: 2018-07-31T01:12:31.173721: step 12053, loss 0.554412.
Train: 2018-07-31T01:12:31.314320: step 12054, loss 0.578936.
Train: 2018-07-31T01:12:31.454887: step 12055, loss 0.546315.
Train: 2018-07-31T01:12:31.595480: step 12056, loss 0.562632.
Train: 2018-07-31T01:12:31.736072: step 12057, loss 0.513813.
Train: 2018-07-31T01:12:31.876665: step 12058, loss 0.505656.
Train: 2018-07-31T01:12:32.017281: step 12059, loss 0.513708.
Train: 2018-07-31T01:12:32.157848: step 12060, loss 0.554426.
Test: 2018-07-31T01:12:32.407790: step 12060, loss 0.548857.
Train: 2018-07-31T01:12:32.548411: step 12061, loss 0.570764.
Train: 2018-07-31T01:12:32.704620: step 12062, loss 0.619994.
Train: 2018-07-31T01:12:32.845213: step 12063, loss 0.603597.
Train: 2018-07-31T01:12:33.001426: step 12064, loss 0.505121.
Train: 2018-07-31T01:12:33.157615: step 12065, loss 0.537916.
Train: 2018-07-31T01:12:33.298206: step 12066, loss 0.554318.
Train: 2018-07-31T01:12:33.454444: step 12067, loss 0.578987.
Train: 2018-07-31T01:12:33.610658: step 12068, loss 0.611933.
Train: 2018-07-31T01:12:33.751226: step 12069, loss 0.471984.
Train: 2018-07-31T01:12:33.891819: step 12070, loss 0.595485.
Test: 2018-07-31T01:12:34.126138: step 12070, loss 0.548698.
Train: 2018-07-31T01:12:34.266730: step 12071, loss 0.562509.
Train: 2018-07-31T01:12:34.407340: step 12072, loss 0.603758.
Train: 2018-07-31T01:12:34.547932: step 12073, loss 0.554264.
Train: 2018-07-31T01:12:34.688542: step 12074, loss 0.579.
Train: 2018-07-31T01:12:34.829098: step 12075, loss 0.611943.
Train: 2018-07-31T01:12:34.985312: step 12076, loss 0.554312.
Train: 2018-07-31T01:12:35.125903: step 12077, loss 0.546126.
Train: 2018-07-31T01:12:35.266495: step 12078, loss 0.546151.
Train: 2018-07-31T01:12:35.407112: step 12079, loss 0.58716.
Train: 2018-07-31T01:12:35.547705: step 12080, loss 0.632464.
Test: 2018-07-31T01:12:35.797655: step 12080, loss 0.548915.
Train: 2018-07-31T01:12:35.953835: step 12081, loss 0.562599.
Train: 2018-07-31T01:12:36.094427: step 12082, loss 0.627841.
Train: 2018-07-31T01:12:36.235020: step 12083, loss 0.554536.
Train: 2018-07-31T01:12:36.375636: step 12084, loss 0.505983.
Train: 2018-07-31T01:12:36.516228: step 12085, loss 0.578892.
Train: 2018-07-31T01:12:36.656794: step 12086, loss 0.530415.
Train: 2018-07-31T01:12:36.813009: step 12087, loss 0.554664.
Train: 2018-07-31T01:12:36.953601: step 12088, loss 0.554671.
Train: 2018-07-31T01:12:37.094193: step 12089, loss 0.603095.
Train: 2018-07-31T01:12:37.234784: step 12090, loss 0.538565.
Test: 2018-07-31T01:12:37.469105: step 12090, loss 0.549257.
Train: 2018-07-31T01:12:37.609734: step 12091, loss 0.546635.
Train: 2018-07-31T01:12:37.750288: step 12092, loss 0.570818.
Train: 2018-07-31T01:12:37.890882: step 12093, loss 0.522438.
Train: 2018-07-31T01:12:38.047120: step 12094, loss 0.55467.
Train: 2018-07-31T01:12:38.187687: step 12095, loss 0.481925.
Train: 2018-07-31T01:12:38.328303: step 12096, loss 0.546487.
Train: 2018-07-31T01:12:38.468889: step 12097, loss 0.522028.
Train: 2018-07-31T01:12:38.625084: step 12098, loss 0.627854.
Train: 2018-07-31T01:12:38.765701: step 12099, loss 0.521759.
Train: 2018-07-31T01:12:38.906293: step 12100, loss 0.603516.
Test: 2018-07-31T01:12:39.156214: step 12100, loss 0.548833.
Train: 2018-07-31T01:12:39.906058: step 12101, loss 0.603557.
Train: 2018-07-31T01:12:40.046651: step 12102, loss 0.55436.
Train: 2018-07-31T01:12:40.187265: step 12103, loss 0.603576.
Train: 2018-07-31T01:12:40.343431: step 12104, loss 0.48877.
Train: 2018-07-31T01:12:40.484048: step 12105, loss 0.513305.
Train: 2018-07-31T01:12:40.624641: step 12106, loss 0.628323.
Train: 2018-07-31T01:12:40.780869: step 12107, loss 0.669475.
Train: 2018-07-31T01:12:40.921421: step 12108, loss 0.55434.
Train: 2018-07-31T01:12:41.062014: step 12109, loss 0.529779.
Train: 2018-07-31T01:12:41.202606: step 12110, loss 0.603523.
Test: 2018-07-31T01:12:41.436926: step 12110, loss 0.548897.
Train: 2018-07-31T01:12:41.577519: step 12111, loss 0.677061.
Train: 2018-07-31T01:12:41.718110: step 12112, loss 0.603359.
Train: 2018-07-31T01:12:41.858713: step 12113, loss 0.505918.
Train: 2018-07-31T01:12:41.999294: step 12114, loss 0.595066.
Train: 2018-07-31T01:12:42.139886: step 12115, loss 0.603068.
Train: 2018-07-31T01:12:42.280502: step 12116, loss 0.562804.
Train: 2018-07-31T01:12:42.436693: step 12117, loss 0.554841.
Train: 2018-07-31T01:12:42.577285: step 12118, loss 0.602822.
Train: 2018-07-31T01:12:42.717900: step 12119, loss 0.562936.
Train: 2018-07-31T01:12:42.858468: step 12120, loss 0.555039.
Test: 2018-07-31T01:12:43.108409: step 12120, loss 0.549745.
Train: 2018-07-31T01:12:43.249002: step 12121, loss 0.555091.
Train: 2018-07-31T01:12:43.389618: step 12122, loss 0.59468.
Train: 2018-07-31T01:12:43.530185: step 12123, loss 0.539394.
Train: 2018-07-31T01:12:43.686423: step 12124, loss 0.57098.
Train: 2018-07-31T01:12:43.827040: step 12125, loss 0.515855.
Train: 2018-07-31T01:12:43.967585: step 12126, loss 0.570987.
Train: 2018-07-31T01:12:44.139417: step 12127, loss 0.547343.
Train: 2018-07-31T01:12:44.280010: step 12128, loss 0.507886.
Train: 2018-07-31T01:12:44.420627: step 12129, loss 0.507736.
Train: 2018-07-31T01:12:44.576816: step 12130, loss 0.563002.
Test: 2018-07-31T01:12:44.811136: step 12130, loss 0.549634.
Train: 2018-07-31T01:12:44.967374: step 12131, loss 0.555.
Train: 2018-07-31T01:12:45.107942: step 12132, loss 0.562906.
Train: 2018-07-31T01:12:45.248534: step 12133, loss 0.570864.
Train: 2018-07-31T01:12:45.389126: step 12134, loss 0.586886.
Train: 2018-07-31T01:12:45.529742: step 12135, loss 0.562804.
Train: 2018-07-31T01:12:45.670327: step 12136, loss 0.522549.
Train: 2018-07-31T01:12:45.826523: step 12137, loss 0.546618.
Train: 2018-07-31T01:12:45.967140: step 12138, loss 0.562717.
Train: 2018-07-31T01:12:46.123329: step 12139, loss 0.587006.
Train: 2018-07-31T01:12:46.263920: step 12140, loss 0.505836.
Test: 2018-07-31T01:12:46.498270: step 12140, loss 0.549004.
Train: 2018-07-31T01:12:46.654453: step 12141, loss 0.57892.
Train: 2018-07-31T01:12:46.795046: step 12142, loss 0.554458.
Train: 2018-07-31T01:12:46.935637: step 12143, loss 0.562594.
Train: 2018-07-31T01:12:47.076231: step 12144, loss 0.521629.
Train: 2018-07-31T01:12:47.201201: step 12145, loss 0.636436.
Train: 2018-07-31T01:12:47.373035: step 12146, loss 0.513257.
Train: 2018-07-31T01:12:47.513629: step 12147, loss 0.578986.
Train: 2018-07-31T01:12:47.654221: step 12148, loss 0.537813.
Train: 2018-07-31T01:12:47.794812: step 12149, loss 0.579004.
Train: 2018-07-31T01:12:47.935405: step 12150, loss 0.521228.
Test: 2018-07-31T01:12:48.169724: step 12150, loss 0.548642.
Train: 2018-07-31T01:12:48.325938: step 12151, loss 0.496348.
Train: 2018-07-31T01:12:48.466531: step 12152, loss 0.554178.
Train: 2018-07-31T01:12:48.607147: step 12153, loss 0.537516.
Train: 2018-07-31T01:12:48.747760: step 12154, loss 0.529098.
Train: 2018-07-31T01:12:48.888305: step 12155, loss 0.554054.
Train: 2018-07-31T01:12:49.028899: step 12156, loss 0.503729.
Train: 2018-07-31T01:12:49.185112: step 12157, loss 0.55397.
Train: 2018-07-31T01:12:49.325704: step 12158, loss 0.562368.
Train: 2018-07-31T01:12:49.466295: step 12159, loss 0.545438.
Train: 2018-07-31T01:12:49.606912: step 12160, loss 0.469048.
Test: 2018-07-31T01:12:49.841238: step 12160, loss 0.54808.
Train: 2018-07-31T01:12:49.997422: step 12161, loss 0.570858.
Train: 2018-07-31T01:12:50.138014: step 12162, loss 0.511079.
Train: 2018-07-31T01:12:50.278606: step 12163, loss 0.596632.
Train: 2018-07-31T01:12:50.419197: step 12164, loss 0.545146.
Train: 2018-07-31T01:12:50.575446: step 12165, loss 0.57095.
Train: 2018-07-31T01:12:50.700382: step 12166, loss 0.519199.
Train: 2018-07-31T01:12:50.840974: step 12167, loss 0.605566.
Train: 2018-07-31T01:12:50.981567: step 12168, loss 0.570993.
Train: 2018-07-31T01:12:51.137779: step 12169, loss 0.562342.
Train: 2018-07-31T01:12:51.278395: step 12170, loss 0.605604.
Test: 2018-07-31T01:12:51.512717: step 12170, loss 0.547866.
Train: 2018-07-31T01:12:51.668929: step 12171, loss 0.545055.
Train: 2018-07-31T01:12:51.809522: step 12172, loss 0.527803.
Train: 2018-07-31T01:12:51.950089: step 12173, loss 0.519189.
Train: 2018-07-31T01:12:52.090681: step 12174, loss 0.484659.
Train: 2018-07-31T01:12:52.231273: step 12175, loss 0.545055.
Train: 2018-07-31T01:12:52.387510: step 12176, loss 0.519074.
Train: 2018-07-31T01:12:52.539621: step 12177, loss 0.571014.
Train: 2018-07-31T01:12:52.680213: step 12178, loss 0.536316.
Train: 2018-07-31T01:12:52.836426: step 12179, loss 0.588416.
Train: 2018-07-31T01:12:52.977019: step 12180, loss 0.492828.
Test: 2018-07-31T01:12:53.211373: step 12180, loss 0.547783.
Train: 2018-07-31T01:12:53.351959: step 12181, loss 0.544953.
Train: 2018-07-31T01:12:53.492523: step 12182, loss 0.597209.
Train: 2018-07-31T01:12:53.633141: step 12183, loss 0.518795.
Train: 2018-07-31T01:12:53.773707: step 12184, loss 0.588519.
Train: 2018-07-31T01:12:53.929938: step 12185, loss 0.614661.
Train: 2018-07-31T01:12:54.086134: step 12186, loss 0.54495.
Train: 2018-07-31T01:12:54.211130: step 12187, loss 0.553661.
Train: 2018-07-31T01:12:54.351723: step 12188, loss 0.579712.
Train: 2018-07-31T01:12:54.492289: step 12189, loss 0.597008.
Train: 2018-07-31T01:12:54.632898: step 12190, loss 0.605559.
Test: 2018-07-31T01:12:54.882823: step 12190, loss 0.547909.
Train: 2018-07-31T01:12:55.023416: step 12191, loss 0.545107.
Train: 2018-07-31T01:12:55.164032: step 12192, loss 0.562335.
Train: 2018-07-31T01:12:55.304598: step 12193, loss 0.5709.
Train: 2018-07-31T01:12:55.460813: step 12194, loss 0.570876.
Train: 2018-07-31T01:12:55.617026: step 12195, loss 0.579366.
Train: 2018-07-31T01:12:55.757617: step 12196, loss 0.604767.
Train: 2018-07-31T01:12:55.898234: step 12197, loss 0.613058.
Train: 2018-07-31T01:12:56.038826: step 12198, loss 0.629651.
Train: 2018-07-31T01:12:56.179419: step 12199, loss 0.60421.
Train: 2018-07-31T01:12:56.319985: step 12200, loss 0.603989.
Test: 2018-07-31T01:12:56.569927: step 12200, loss 0.548683.
Train: 2018-07-31T01:12:57.319776: step 12201, loss 0.612019.
Train: 2018-07-31T01:12:57.460369: step 12202, loss 0.554374.
Train: 2018-07-31T01:12:57.600949: step 12203, loss 0.554492.
Train: 2018-07-31T01:12:57.757149: step 12204, loss 0.546502.
Train: 2018-07-31T01:12:57.897765: step 12205, loss 0.603064.
Train: 2018-07-31T01:12:58.038334: step 12206, loss 0.538761.
Train: 2018-07-31T01:12:58.178927: step 12207, loss 0.514941.
Train: 2018-07-31T01:12:58.319518: step 12208, loss 0.531032.
Train: 2018-07-31T01:12:58.460110: step 12209, loss 0.602742.
Train: 2018-07-31T01:12:58.616324: step 12210, loss 0.515295.
Test: 2018-07-31T01:12:58.850676: step 12210, loss 0.549677.
Train: 2018-07-31T01:12:58.991234: step 12211, loss 0.578858.
Train: 2018-07-31T01:12:59.131853: step 12212, loss 0.586794.
Train: 2018-07-31T01:12:59.272419: step 12213, loss 0.555079.
Train: 2018-07-31T01:12:59.413012: step 12214, loss 0.602624.
Train: 2018-07-31T01:12:59.553603: step 12215, loss 0.555127.
Train: 2018-07-31T01:12:59.694195: step 12216, loss 0.507725.
Train: 2018-07-31T01:12:59.834788: step 12217, loss 0.547225.
Train: 2018-07-31T01:12:59.991002: step 12218, loss 0.602612.
Train: 2018-07-31T01:13:00.131594: step 12219, loss 0.602616.
Train: 2018-07-31T01:13:00.272186: step 12220, loss 0.586774.
Test: 2018-07-31T01:13:00.522127: step 12220, loss 0.549804.
Train: 2018-07-31T01:13:00.662720: step 12221, loss 0.665838.
Train: 2018-07-31T01:13:00.803312: step 12222, loss 0.563098.
Train: 2018-07-31T01:13:00.943903: step 12223, loss 0.610321.
Train: 2018-07-31T01:13:01.084495: step 12224, loss 0.547526.
Train: 2018-07-31T01:13:01.240709: step 12225, loss 0.633619.
Train: 2018-07-31T01:13:01.381300: step 12226, loss 0.485396.
Train: 2018-07-31T01:13:01.537539: step 12227, loss 0.578901.
Train: 2018-07-31T01:13:01.678131: step 12228, loss 0.524491.
Train: 2018-07-31T01:13:01.818723: step 12229, loss 0.555583.
Train: 2018-07-31T01:13:01.974911: step 12230, loss 0.571125.
Test: 2018-07-31T01:13:02.209283: step 12230, loss 0.550305.
Train: 2018-07-31T01:13:02.349829: step 12231, loss 0.530136.
Train: 2018-07-31T01:13:02.490434: step 12232, loss 0.56331.
Train: 2018-07-31T01:13:02.631008: step 12233, loss 0.586695.
Train: 2018-07-31T01:13:02.771625: step 12234, loss 0.516384.
Train: 2018-07-31T01:13:02.912210: step 12235, loss 0.571049.
Train: 2018-07-31T01:13:03.052784: step 12236, loss 0.563182.
Train: 2018-07-31T01:13:03.208998: step 12237, loss 0.57887.
Train: 2018-07-31T01:13:03.349614: step 12238, loss 0.515873.
Train: 2018-07-31T01:13:03.490183: step 12239, loss 0.539385.
Train: 2018-07-31T01:13:03.630799: step 12240, loss 0.5155.
Test: 2018-07-31T01:13:03.880716: step 12240, loss 0.549638.
Train: 2018-07-31T01:13:04.036953: step 12241, loss 0.547052.
Train: 2018-07-31T01:13:04.177520: step 12242, loss 0.49902.
Train: 2018-07-31T01:13:04.318112: step 12243, loss 0.554793.
Train: 2018-07-31T01:13:04.474331: step 12244, loss 0.570817.
Train: 2018-07-31T01:13:04.614917: step 12245, loss 0.5546.
Train: 2018-07-31T01:13:04.755535: step 12246, loss 0.570783.
Train: 2018-07-31T01:13:04.911725: step 12247, loss 0.627888.
Train: 2018-07-31T01:13:05.052316: step 12248, loss 0.562595.
Train: 2018-07-31T01:13:05.192932: step 12249, loss 0.595321.
Train: 2018-07-31T01:13:05.349146: step 12250, loss 0.546192.
Test: 2018-07-31T01:13:05.583443: step 12250, loss 0.548835.
Train: 2018-07-31T01:13:05.724035: step 12251, loss 0.513376.
Train: 2018-07-31T01:13:05.880248: step 12252, loss 0.611825.
Train: 2018-07-31T01:13:06.020838: step 12253, loss 0.52967.
Train: 2018-07-31T01:13:06.161432: step 12254, loss 0.554303.
Train: 2018-07-31T01:13:06.302024: step 12255, loss 0.578994.
Train: 2018-07-31T01:13:06.442617: step 12256, loss 0.537786.
Train: 2018-07-31T01:13:06.583232: step 12257, loss 0.587259.
Train: 2018-07-31T01:13:06.723824: step 12258, loss 0.612029.
Train: 2018-07-31T01:13:06.880013: step 12259, loss 0.60375.
Train: 2018-07-31T01:13:07.020605: step 12260, loss 0.52958.
Test: 2018-07-31T01:13:07.254927: step 12260, loss 0.548747.
Train: 2018-07-31T01:13:07.411140: step 12261, loss 0.529613.
Train: 2018-07-31T01:13:07.551753: step 12262, loss 0.587215.
Train: 2018-07-31T01:13:07.692358: step 12263, loss 0.587205.
Train: 2018-07-31T01:13:07.832915: step 12264, loss 0.620045.
Train: 2018-07-31T01:13:07.989153: step 12265, loss 0.644525.
Train: 2018-07-31T01:13:08.129721: step 12266, loss 0.521782.
Train: 2018-07-31T01:13:08.270313: step 12267, loss 0.538202.
Train: 2018-07-31T01:13:08.410905: step 12268, loss 0.562654.
Train: 2018-07-31T01:13:08.551497: step 12269, loss 0.513973.
Train: 2018-07-31T01:13:08.692107: step 12270, loss 0.530222.
Test: 2018-07-31T01:13:08.926409: step 12270, loss 0.549078.
Train: 2018-07-31T01:13:09.067000: step 12271, loss 0.522087.
Train: 2018-07-31T01:13:09.207604: step 12272, loss 0.538276.
Train: 2018-07-31T01:13:09.363832: step 12273, loss 0.562638.
Train: 2018-07-31T01:13:09.566908: step 12274, loss 0.578927.
Train: 2018-07-31T01:13:09.723122: step 12275, loss 0.56261.
Train: 2018-07-31T01:13:09.879335: step 12276, loss 0.562601.
Train: 2018-07-31T01:13:10.019903: step 12277, loss 0.587118.
Train: 2018-07-31T01:13:10.160496: step 12278, loss 0.489.
Train: 2018-07-31T01:13:10.301086: step 12279, loss 0.562573.
Train: 2018-07-31T01:13:10.441704: step 12280, loss 0.611778.
Test: 2018-07-31T01:13:10.691651: step 12280, loss 0.548812.
Train: 2018-07-31T01:13:10.816591: step 12281, loss 0.578967.
Train: 2018-07-31T01:13:10.957184: step 12282, loss 0.554351.
Train: 2018-07-31T01:13:11.097776: step 12283, loss 0.603583.
Train: 2018-07-31T01:13:11.253990: step 12284, loss 0.578961.
Train: 2018-07-31T01:13:11.394582: step 12285, loss 0.570764.
Train: 2018-07-31T01:13:11.535174: step 12286, loss 0.603483.
Train: 2018-07-31T01:13:11.675790: step 12287, loss 0.570771.
Train: 2018-07-31T01:13:11.831977: step 12288, loss 0.58707.
Train: 2018-07-31T01:13:11.972595: step 12289, loss 0.58704.
Train: 2018-07-31T01:13:12.113188: step 12290, loss 0.538366.
Test: 2018-07-31T01:13:12.363105: step 12290, loss 0.549156.
Train: 2018-07-31T01:13:12.503696: step 12291, loss 0.578893.
Train: 2018-07-31T01:13:12.659910: step 12292, loss 0.59504.
Train: 2018-07-31T01:13:12.800501: step 12293, loss 0.627223.
Train: 2018-07-31T01:13:12.956741: step 12294, loss 0.514637.
Train: 2018-07-31T01:13:13.097335: step 12295, loss 0.522777.
Train: 2018-07-31T01:13:13.237899: step 12296, loss 0.53083.
Train: 2018-07-31T01:13:13.394112: step 12297, loss 0.506811.
Train: 2018-07-31T01:13:13.550351: step 12298, loss 0.5468.
Train: 2018-07-31T01:13:13.690918: step 12299, loss 0.52266.
Train: 2018-07-31T01:13:13.847132: step 12300, loss 0.538627.
Test: 2018-07-31T01:13:14.081451: step 12300, loss 0.549221.
Train: 2018-07-31T01:13:14.800034: step 12301, loss 0.56274.
Train: 2018-07-31T01:13:14.956248: step 12302, loss 0.595079.
Train: 2018-07-31T01:13:15.096838: step 12303, loss 0.595112.
Train: 2018-07-31T01:13:15.237430: step 12304, loss 0.538341.
Train: 2018-07-31T01:13:15.393643: step 12305, loss 0.619521.
Train: 2018-07-31T01:13:15.534262: step 12306, loss 0.546421.
Train: 2018-07-31T01:13:15.674828: step 12307, loss 0.554537.
Train: 2018-07-31T01:13:15.815446: step 12308, loss 0.562656.
Train: 2018-07-31T01:13:15.956013: step 12309, loss 0.635835.
Train: 2018-07-31T01:13:16.096606: step 12310, loss 0.522055.
Test: 2018-07-31T01:13:16.346562: step 12310, loss 0.549066.
Train: 2018-07-31T01:13:16.487138: step 12311, loss 0.603269.
Train: 2018-07-31T01:13:16.643353: step 12312, loss 0.595128.
Train: 2018-07-31T01:13:16.768324: step 12313, loss 0.627493.
Train: 2018-07-31T01:13:16.924547: step 12314, loss 0.554656.
Train: 2018-07-31T01:13:17.049506: step 12315, loss 0.570821.
Train: 2018-07-31T01:13:17.205719: step 12316, loss 0.522592.
Train: 2018-07-31T01:13:17.361934: step 12317, loss 0.602966.
Train: 2018-07-31T01:13:17.502551: step 12318, loss 0.538778.
Train: 2018-07-31T01:13:17.658739: step 12319, loss 0.538815.
Train: 2018-07-31T01:13:17.799331: step 12320, loss 0.63492.
Test: 2018-07-31T01:13:18.033651: step 12320, loss 0.549486.
Train: 2018-07-31T01:13:18.174243: step 12321, loss 0.570868.
Train: 2018-07-31T01:13:18.330456: step 12322, loss 0.554918.
Train: 2018-07-31T01:13:18.455428: step 12323, loss 0.570888.
Train: 2018-07-31T01:13:18.596020: step 12324, loss 0.610706.
Train: 2018-07-31T01:13:18.736611: step 12325, loss 0.515291.
Train: 2018-07-31T01:13:18.877203: step 12326, loss 0.507389.
Train: 2018-07-31T01:13:19.017810: step 12327, loss 0.562963.
Train: 2018-07-31T01:13:19.174010: step 12328, loss 0.570904.
Train: 2018-07-31T01:13:19.314603: step 12329, loss 0.539056.
Train: 2018-07-31T01:13:19.455234: step 12330, loss 0.539004.
Test: 2018-07-31T01:13:19.689515: step 12330, loss 0.549516.
Train: 2018-07-31T01:13:19.845753: step 12331, loss 0.538933.
Train: 2018-07-31T01:13:19.986318: step 12332, loss 0.594872.
Train: 2018-07-31T01:13:20.126911: step 12333, loss 0.586882.
Train: 2018-07-31T01:13:20.283149: step 12334, loss 0.594912.
Train: 2018-07-31T01:13:20.423715: step 12335, loss 0.610959.
Train: 2018-07-31T01:13:20.579930: step 12336, loss 0.514742.
Train: 2018-07-31T01:13:20.720522: step 12337, loss 0.570849.
Train: 2018-07-31T01:13:20.861114: step 12338, loss 0.514707.
Train: 2018-07-31T01:13:21.001706: step 12339, loss 0.635086.
Train: 2018-07-31T01:13:21.157944: step 12340, loss 0.66718.
Test: 2018-07-31T01:13:21.407891: step 12340, loss 0.549438.
Train: 2018-07-31T01:13:21.548453: step 12341, loss 0.538825.
Train: 2018-07-31T01:13:21.689044: step 12342, loss 0.5229.
Train: 2018-07-31T01:13:21.829637: step 12343, loss 0.578862.
Train: 2018-07-31T01:13:21.970254: step 12344, loss 0.64274.
Train: 2018-07-31T01:13:22.126444: step 12345, loss 0.594792.
Train: 2018-07-31T01:13:22.267059: step 12346, loss 0.610637.
Train: 2018-07-31T01:13:22.407626: step 12347, loss 0.563024.
Train: 2018-07-31T01:13:22.548244: step 12348, loss 0.563073.
Train: 2018-07-31T01:13:22.704433: step 12349, loss 0.570991.
Train: 2018-07-31T01:13:22.860672: step 12350, loss 0.508155.
Test: 2018-07-31T01:13:23.094994: step 12350, loss 0.550015.
Train: 2018-07-31T01:13:23.251179: step 12351, loss 0.492492.
Train: 2018-07-31T01:13:23.391770: step 12352, loss 0.555281.
Train: 2018-07-31T01:13:23.532364: step 12353, loss 0.610366.
Train: 2018-07-31T01:13:23.688576: step 12354, loss 0.586744.
Train: 2018-07-31T01:13:23.844815: step 12355, loss 0.507958.
Train: 2018-07-31T01:13:23.985407: step 12356, loss 0.586753.
Train: 2018-07-31T01:13:24.125973: step 12357, loss 0.594657.
Train: 2018-07-31T01:13:24.266568: step 12358, loss 0.523565.
Train: 2018-07-31T01:13:24.407183: step 12359, loss 0.515582.
Train: 2018-07-31T01:13:24.547750: step 12360, loss 0.610574.
Test: 2018-07-31T01:13:24.797693: step 12360, loss 0.549687.
Train: 2018-07-31T01:13:24.985172: step 12361, loss 0.602673.
Train: 2018-07-31T01:13:25.125739: step 12362, loss 0.523273.
Train: 2018-07-31T01:13:25.266357: step 12363, loss 0.507298.
Train: 2018-07-31T01:13:25.422547: step 12364, loss 0.586831.
Train: 2018-07-31T01:13:25.563139: step 12365, loss 0.546916.
Train: 2018-07-31T01:13:25.719352: step 12366, loss 0.498831.
Train: 2018-07-31T01:13:25.859967: step 12367, loss 0.514625.
Train: 2018-07-31T01:13:26.016181: step 12368, loss 0.570817.
Train: 2018-07-31T01:13:26.172394: step 12369, loss 0.473674.
Train: 2018-07-31T01:13:26.312980: step 12370, loss 0.619598.
Test: 2018-07-31T01:13:26.547309: step 12370, loss 0.548933.
Train: 2018-07-31T01:13:26.703497: step 12371, loss 0.554442.
Train: 2018-07-31T01:13:26.859708: step 12372, loss 0.578955.
Train: 2018-07-31T01:13:27.000301: step 12373, loss 0.529699.
Train: 2018-07-31T01:13:27.156539: step 12374, loss 0.570757.
Train: 2018-07-31T01:13:27.297131: step 12375, loss 0.537729.
Train: 2018-07-31T01:13:27.437700: step 12376, loss 0.562478.
Train: 2018-07-31T01:13:27.578316: step 12377, loss 0.545865.
Train: 2018-07-31T01:13:27.718883: step 12378, loss 0.520857.
Train: 2018-07-31T01:13:27.859500: step 12379, loss 0.504037.
Train: 2018-07-31T01:13:28.000067: step 12380, loss 0.537289.
Test: 2018-07-31T01:13:28.250039: step 12380, loss 0.548313.
Train: 2018-07-31T01:13:28.390625: step 12381, loss 0.520373.
Train: 2018-07-31T01:13:28.546845: step 12382, loss 0.526375.
Train: 2018-07-31T01:13:28.687406: step 12383, loss 0.545412.
Train: 2018-07-31T01:13:28.828024: step 12384, loss 0.536833.
Train: 2018-07-31T01:13:28.984236: step 12385, loss 0.519657.
Train: 2018-07-31T01:13:29.140424: step 12386, loss 0.545194.
Train: 2018-07-31T01:13:29.281017: step 12387, loss 0.527926.
Train: 2018-07-31T01:13:29.421609: step 12388, loss 0.5278.
Train: 2018-07-31T01:13:29.562202: step 12389, loss 0.562346.
Train: 2018-07-31T01:13:29.702795: step 12390, loss 0.614519.
Test: 2018-07-31T01:13:29.952776: step 12390, loss 0.547776.
Train: 2018-07-31T01:13:30.093354: step 12391, loss 0.510115.
Train: 2018-07-31T01:13:30.249541: step 12392, loss 0.614717.
Train: 2018-07-31T01:13:30.390158: step 12393, loss 0.571098.
Train: 2018-07-31T01:13:30.546347: step 12394, loss 0.588558.
Train: 2018-07-31T01:13:30.686938: step 12395, loss 0.588535.
Train: 2018-07-31T01:13:30.827555: step 12396, loss 0.632041.
Train: 2018-07-31T01:13:30.983745: step 12397, loss 0.544982.
Train: 2018-07-31T01:13:31.124337: step 12398, loss 0.527698.
Train: 2018-07-31T01:13:31.280549: step 12399, loss 0.605563.
Train: 2018-07-31T01:13:31.421165: step 12400, loss 0.562337.
Test: 2018-07-31T01:13:31.655487: step 12400, loss 0.547941.
Train: 2018-07-31T01:13:32.389664: step 12401, loss 0.510764.
Train: 2018-07-31T01:13:32.530256: step 12402, loss 0.588073.
Train: 2018-07-31T01:13:32.670849: step 12403, loss 0.536658.
Train: 2018-07-31T01:13:32.811440: step 12404, loss 0.519621.
Train: 2018-07-31T01:13:32.967654: step 12405, loss 0.536736.
Train: 2018-07-31T01:13:33.108245: step 12406, loss 0.562339.
Train: 2018-07-31T01:13:33.248844: step 12407, loss 0.528253.
Train: 2018-07-31T01:13:33.389429: step 12408, loss 0.613459.
Train: 2018-07-31T01:13:33.530022: step 12409, loss 0.511299.
Train: 2018-07-31T01:13:33.701858: step 12410, loss 0.528331.
Test: 2018-07-31T01:13:33.936177: step 12410, loss 0.548103.
Train: 2018-07-31T01:13:34.092390: step 12411, loss 0.570848.
Train: 2018-07-31T01:13:34.233007: step 12412, loss 0.51984.
Train: 2018-07-31T01:13:34.389197: step 12413, loss 0.587857.
Train: 2018-07-31T01:13:34.529789: step 12414, loss 0.553845.
Train: 2018-07-31T01:13:34.670380: step 12415, loss 0.596338.
Train: 2018-07-31T01:13:34.811021: step 12416, loss 0.647227.
Train: 2018-07-31T01:13:34.967187: step 12417, loss 0.536968.
Train: 2018-07-31T01:13:35.107778: step 12418, loss 0.621468.
Train: 2018-07-31T01:13:35.263991: step 12419, loss 0.553964.
Train: 2018-07-31T01:13:35.404607: step 12420, loss 0.537228.
Test: 2018-07-31T01:13:35.638934: step 12420, loss 0.548391.
Train: 2018-07-31T01:13:35.795118: step 12421, loss 0.537301.
Train: 2018-07-31T01:13:35.951354: step 12422, loss 0.579123.
Train: 2018-07-31T01:13:36.107544: step 12423, loss 0.529083.
Train: 2018-07-31T01:13:36.248161: step 12424, loss 0.554111.
Train: 2018-07-31T01:13:36.388747: step 12425, loss 0.537494.
Train: 2018-07-31T01:13:36.529345: step 12426, loss 0.537511.
Train: 2018-07-31T01:13:36.669912: step 12427, loss 0.545825.
Train: 2018-07-31T01:13:36.826151: step 12428, loss 0.678836.
Train: 2018-07-31T01:13:36.966717: step 12429, loss 0.570758.
Train: 2018-07-31T01:13:37.122931: step 12430, loss 0.62868.
Test: 2018-07-31T01:13:37.357284: step 12430, loss 0.548702.
Train: 2018-07-31T01:13:37.513489: step 12431, loss 0.611984.
Train: 2018-07-31T01:13:37.654081: step 12432, loss 0.55434.
Train: 2018-07-31T01:13:37.794649: step 12433, loss 0.554408.
Train: 2018-07-31T01:13:37.935240: step 12434, loss 0.578927.
Train: 2018-07-31T01:13:38.075834: step 12435, loss 0.595163.
Train: 2018-07-31T01:13:38.216453: step 12436, loss 0.570799.
Train: 2018-07-31T01:13:38.357042: step 12437, loss 0.53047.
Train: 2018-07-31T01:13:38.513231: step 12438, loss 0.627176.
Train: 2018-07-31T01:13:38.653822: step 12439, loss 0.602934.
Train: 2018-07-31T01:13:38.794439: step 12440, loss 0.530919.
Test: 2018-07-31T01:13:39.028766: step 12440, loss 0.549577.
Train: 2018-07-31T01:13:39.184949: step 12441, loss 0.570891.
Train: 2018-07-31T01:13:39.325541: step 12442, loss 0.57091.
Train: 2018-07-31T01:13:39.466157: step 12443, loss 0.515424.
Train: 2018-07-31T01:13:39.606750: step 12444, loss 0.578859.
Train: 2018-07-31T01:13:39.762938: step 12445, loss 0.61843.
Train: 2018-07-31T01:13:39.903531: step 12446, loss 0.563067.
Train: 2018-07-31T01:13:40.044123: step 12447, loss 0.500023.
Train: 2018-07-31T01:13:40.184715: step 12448, loss 0.578864.
Train: 2018-07-31T01:13:40.309709: step 12449, loss 0.460608.
Train: 2018-07-31T01:13:40.465900: step 12450, loss 0.594667.
Test: 2018-07-31T01:13:40.700263: step 12450, loss 0.549773.
Train: 2018-07-31T01:13:40.840810: step 12451, loss 0.57886.
Train: 2018-07-31T01:13:40.997024: step 12452, loss 0.610558.
Train: 2018-07-31T01:13:41.153273: step 12453, loss 0.63434.
Train: 2018-07-31T01:13:41.293841: step 12454, loss 0.499708.
Train: 2018-07-31T01:13:41.434420: step 12455, loss 0.594696.
Train: 2018-07-31T01:13:41.575013: step 12456, loss 0.570944.
Train: 2018-07-31T01:13:41.715605: step 12457, loss 0.507634.
Train: 2018-07-31T01:13:41.871820: step 12458, loss 0.515473.
Train: 2018-07-31T01:13:42.028057: step 12459, loss 0.618564.
Train: 2018-07-31T01:13:42.168650: step 12460, loss 0.562962.
Test: 2018-07-31T01:13:42.402947: step 12460, loss 0.549623.
Train: 2018-07-31T01:13:42.559159: step 12461, loss 0.578859.
Train: 2018-07-31T01:13:42.699750: step 12462, loss 0.547016.
Train: 2018-07-31T01:13:42.855988: step 12463, loss 0.602766.
Train: 2018-07-31T01:13:42.996556: step 12464, loss 0.578859.
Train: 2018-07-31T01:13:43.137166: step 12465, loss 0.586828.
Train: 2018-07-31T01:13:43.293362: step 12466, loss 0.547001.
Train: 2018-07-31T01:13:43.433953: step 12467, loss 0.554966.
Train: 2018-07-31T01:13:43.590176: step 12468, loss 0.602759.
Train: 2018-07-31T01:13:43.746416: step 12469, loss 0.570897.
Train: 2018-07-31T01:13:43.886973: step 12470, loss 0.586816.
Test: 2018-07-31T01:13:44.121291: step 12470, loss 0.549641.
Train: 2018-07-31T01:13:44.261884: step 12471, loss 0.562955.
Train: 2018-07-31T01:13:44.418122: step 12472, loss 0.475566.
Train: 2018-07-31T01:13:44.558690: step 12473, loss 0.586797.
Train: 2018-07-31T01:13:44.699306: step 12474, loss 0.602834.
Train: 2018-07-31T01:13:44.839898: step 12475, loss 0.507119.
Train: 2018-07-31T01:13:44.980466: step 12476, loss 0.52297.
Train: 2018-07-31T01:13:45.121082: step 12477, loss 0.579005.
Train: 2018-07-31T01:13:45.261650: step 12478, loss 0.578952.
Train: 2018-07-31T01:13:45.402242: step 12479, loss 0.506623.
Train: 2018-07-31T01:13:45.558455: step 12480, loss 0.586957.
Test: 2018-07-31T01:13:45.792806: step 12480, loss 0.54928.
Train: 2018-07-31T01:13:45.948990: step 12481, loss 0.570822.
Train: 2018-07-31T01:13:46.089581: step 12482, loss 0.595013.
Train: 2018-07-31T01:13:46.230172: step 12483, loss 0.554677.
Train: 2018-07-31T01:13:46.386386: step 12484, loss 0.514285.
Train: 2018-07-31T01:13:46.526978: step 12485, loss 0.562712.
Train: 2018-07-31T01:13:46.667599: step 12486, loss 0.546484.
Train: 2018-07-31T01:13:46.808188: step 12487, loss 0.554549.
Train: 2018-07-31T01:13:46.964376: step 12488, loss 0.521974.
Train: 2018-07-31T01:13:47.104993: step 12489, loss 0.578929.
Train: 2018-07-31T01:13:47.261182: step 12490, loss 0.570769.
Test: 2018-07-31T01:13:47.495532: step 12490, loss 0.548872.
Train: 2018-07-31T01:13:47.636113: step 12491, loss 0.554395.
Train: 2018-07-31T01:13:47.792307: step 12492, loss 0.57896.
Train: 2018-07-31T01:13:47.932924: step 12493, loss 0.554347.
Train: 2018-07-31T01:13:48.104751: step 12494, loss 0.521465.
Train: 2018-07-31T01:13:48.229706: step 12495, loss 0.570758.
Train: 2018-07-31T01:13:48.385919: step 12496, loss 0.603727.
Train: 2018-07-31T01:13:48.526511: step 12497, loss 0.579002.
Train: 2018-07-31T01:13:48.667102: step 12498, loss 0.546022.
Train: 2018-07-31T01:13:48.792072: step 12499, loss 0.513031.
Train: 2018-07-31T01:13:48.932690: step 12500, loss 0.554244.
Test: 2018-07-31T01:13:49.167021: step 12500, loss 0.548646.
Train: 2018-07-31T01:13:49.916811: step 12501, loss 0.570756.
Train: 2018-07-31T01:13:50.073061: step 12502, loss 0.537664.
Train: 2018-07-31T01:13:50.213633: step 12503, loss 0.521055.
Train: 2018-07-31T01:13:50.354209: step 12504, loss 0.628852.
Train: 2018-07-31T01:13:50.510431: step 12505, loss 0.64546.
Train: 2018-07-31T01:13:50.651037: step 12506, loss 0.512729.
Train: 2018-07-31T01:13:50.791630: step 12507, loss 0.487895.
Train: 2018-07-31T01:13:50.947844: step 12508, loss 0.637154.
Train: 2018-07-31T01:13:51.088411: step 12509, loss 0.55423.
Train: 2018-07-31T01:13:51.229027: step 12510, loss 0.521002.
Test: 2018-07-31T01:13:51.478944: step 12510, loss 0.548483.
Train: 2018-07-31T01:13:51.635182: step 12511, loss 0.579041.
Train: 2018-07-31T01:13:51.775775: step 12512, loss 0.562496.
Train: 2018-07-31T01:13:51.916366: step 12513, loss 0.537615.
Train: 2018-07-31T01:13:52.056952: step 12514, loss 0.554275.
Train: 2018-07-31T01:13:52.213147: step 12515, loss 0.595612.
Train: 2018-07-31T01:13:52.353740: step 12516, loss 0.612172.
Train: 2018-07-31T01:13:52.494331: step 12517, loss 0.529416.
Train: 2018-07-31T01:13:52.650545: step 12518, loss 0.521187.
Train: 2018-07-31T01:13:52.791137: step 12519, loss 0.504656.
Train: 2018-07-31T01:13:52.931730: step 12520, loss 0.562484.
Test: 2018-07-31T01:13:53.166050: step 12520, loss 0.548663.
Train: 2018-07-31T01:13:53.322263: step 12521, loss 0.554194.
Train: 2018-07-31T01:13:53.462856: step 12522, loss 0.562467.
Train: 2018-07-31T01:13:53.603445: step 12523, loss 0.562461.
Train: 2018-07-31T01:13:53.744063: step 12524, loss 0.537546.
Train: 2018-07-31T01:13:53.900276: step 12525, loss 0.595697.
Train: 2018-07-31T01:13:54.040844: step 12526, loss 0.612328.
Train: 2018-07-31T01:13:54.181437: step 12527, loss 0.529232.
Train: 2018-07-31T01:13:54.337649: step 12528, loss 0.529243.
Train: 2018-07-31T01:13:54.478242: step 12529, loss 0.512615.
Train: 2018-07-31T01:13:54.618860: step 12530, loss 0.587395.
Test: 2018-07-31T01:13:54.868775: step 12530, loss 0.548533.
Train: 2018-07-31T01:13:55.009368: step 12531, loss 0.554119.
Train: 2018-07-31T01:13:55.165598: step 12532, loss 0.554111.
Train: 2018-07-31T01:13:55.306183: step 12533, loss 0.491343.
Train: 2018-07-31T01:13:55.462387: step 12534, loss 0.629194.
Train: 2018-07-31T01:13:55.602979: step 12535, loss 0.554072.
Train: 2018-07-31T01:13:55.743570: step 12536, loss 0.487264.
Train: 2018-07-31T01:13:55.884162: step 12537, loss 0.520587.
Train: 2018-07-31T01:13:56.024755: step 12538, loss 0.528865.
Train: 2018-07-31T01:13:56.165372: step 12539, loss 0.562382.
Train: 2018-07-31T01:13:56.305939: step 12540, loss 0.688728.
Test: 2018-07-31T01:13:56.555911: step 12540, loss 0.548272.
Train: 2018-07-31T01:13:56.696499: step 12541, loss 0.604454.
Train: 2018-07-31T01:13:56.837065: step 12542, loss 0.503564.
Train: 2018-07-31T01:13:56.993309: step 12543, loss 0.50359.
Train: 2018-07-31T01:13:57.133869: step 12544, loss 0.553973.
Train: 2018-07-31T01:13:57.274462: step 12545, loss 0.486685.
Train: 2018-07-31T01:13:57.415053: step 12546, loss 0.562368.
Train: 2018-07-31T01:13:57.555645: step 12547, loss 0.545374.
Train: 2018-07-31T01:13:57.696263: step 12548, loss 0.579284.
Train: 2018-07-31T01:13:57.852452: step 12549, loss 0.562108.
Train: 2018-07-31T01:13:57.993069: step 12550, loss 0.519295.
Test: 2018-07-31T01:13:58.227396: step 12550, loss 0.547951.
Train: 2018-07-31T01:13:58.383579: step 12551, loss 0.596332.
Train: 2018-07-31T01:13:58.524179: step 12552, loss 0.66733.
Train: 2018-07-31T01:13:58.680384: step 12553, loss 0.545536.
Train: 2018-07-31T01:13:58.820976: step 12554, loss 0.588657.
Train: 2018-07-31T01:13:58.961592: step 12555, loss 0.579339.
Train: 2018-07-31T01:13:59.102184: step 12556, loss 0.579296.
Train: 2018-07-31T01:13:59.242752: step 12557, loss 0.553971.
Train: 2018-07-31T01:13:59.383344: step 12558, loss 0.579129.
Train: 2018-07-31T01:13:59.523936: step 12559, loss 0.587435.
Train: 2018-07-31T01:13:59.680173: step 12560, loss 0.479356.
Test: 2018-07-31T01:13:59.930120: step 12560, loss 0.548578.
Train: 2018-07-31T01:14:00.070706: step 12561, loss 0.529259.
Train: 2018-07-31T01:14:00.211273: step 12562, loss 0.587351.
Train: 2018-07-31T01:14:00.351891: step 12563, loss 0.587334.
Train: 2018-07-31T01:14:00.508081: step 12564, loss 0.56248.
Train: 2018-07-31T01:14:00.648672: step 12565, loss 0.529434.
Train: 2018-07-31T01:14:00.789264: step 12566, loss 0.512941.
Train: 2018-07-31T01:14:00.929918: step 12567, loss 0.587281.
Train: 2018-07-31T01:14:01.086070: step 12568, loss 0.537713.
Train: 2018-07-31T01:14:01.226661: step 12569, loss 0.545967.
Train: 2018-07-31T01:14:01.367254: step 12570, loss 0.554222.
Test: 2018-07-31T01:14:01.601599: step 12570, loss 0.551032.
Train: 2018-07-31T01:14:01.742184: step 12571, loss 0.521124.
Train: 2018-07-31T01:14:01.898380: step 12572, loss 0.612172.
Train: 2018-07-31T01:14:02.054593: step 12573, loss 0.496205.
Train: 2018-07-31T01:14:02.210807: step 12574, loss 0.57076.
Train: 2018-07-31T01:14:02.351399: step 12575, loss 0.512637.
Train: 2018-07-31T01:14:02.491991: step 12576, loss 0.579081.
Train: 2018-07-31T01:14:02.632584: step 12577, loss 0.520794.
Train: 2018-07-31T01:14:02.773175: step 12578, loss 0.612485.
Train: 2018-07-31T01:14:02.929387: step 12579, loss 0.537376.
Train: 2018-07-31T01:14:03.069981: step 12580, loss 0.620901.
Test: 2018-07-31T01:14:03.304325: step 12580, loss 0.548433.
Train: 2018-07-31T01:14:03.460513: step 12581, loss 0.58747.
Train: 2018-07-31T01:14:03.601105: step 12582, loss 0.545742.
Train: 2018-07-31T01:14:03.741697: step 12583, loss 0.629112.
Train: 2018-07-31T01:14:03.882291: step 12584, loss 0.645617.
Train: 2018-07-31T01:14:04.022906: step 12585, loss 0.562471.
Train: 2018-07-31T01:14:04.163498: step 12586, loss 0.653332.
Train: 2018-07-31T01:14:04.304107: step 12587, loss 0.52968.
Train: 2018-07-31T01:14:04.444701: step 12588, loss 0.570766.
Train: 2018-07-31T01:14:04.600872: step 12589, loss 0.53001.
Train: 2018-07-31T01:14:04.757084: step 12590, loss 0.538258.
Test: 2018-07-31T01:14:04.991429: step 12590, loss 0.549103.
Train: 2018-07-31T01:14:05.132022: step 12591, loss 0.562673.
Train: 2018-07-31T01:14:05.288210: step 12592, loss 0.530285.
Train: 2018-07-31T01:14:05.428802: step 12593, loss 0.578895.
Train: 2018-07-31T01:14:05.569395: step 12594, loss 0.603154.
Train: 2018-07-31T01:14:05.725633: step 12595, loss 0.482004.
Train: 2018-07-31T01:14:05.897444: step 12596, loss 0.546584.
Train: 2018-07-31T01:14:06.038034: step 12597, loss 0.546567.
Train: 2018-07-31T01:14:06.163006: step 12598, loss 0.611245.
Train: 2018-07-31T01:14:06.319219: step 12599, loss 0.570802.
Train: 2018-07-31T01:14:06.459812: step 12600, loss 0.586974.
Test: 2018-07-31T01:14:06.694163: step 12600, loss 0.549201.
Train: 2018-07-31T01:14:07.397109: step 12601, loss 0.514257.
Train: 2018-07-31T01:14:07.537683: step 12602, loss 0.586969.
Train: 2018-07-31T01:14:07.678276: step 12603, loss 0.554634.
Train: 2018-07-31T01:14:07.834513: step 12604, loss 0.5708.
Train: 2018-07-31T01:14:07.975106: step 12605, loss 0.619384.
Train: 2018-07-31T01:14:08.131322: step 12606, loss 0.586962.
Train: 2018-07-31T01:14:08.287532: step 12607, loss 0.514401.
Train: 2018-07-31T01:14:08.428124: step 12608, loss 0.530535.
Train: 2018-07-31T01:14:08.568691: step 12609, loss 0.627242.
Train: 2018-07-31T01:14:08.709284: step 12610, loss 0.554714.
Test: 2018-07-31T01:14:08.959226: step 12610, loss 0.549268.
Train: 2018-07-31T01:14:09.099852: step 12611, loss 0.514464.
Train: 2018-07-31T01:14:09.240434: step 12612, loss 0.554704.
Train: 2018-07-31T01:14:09.396648: step 12613, loss 0.53048.
Train: 2018-07-31T01:14:09.537215: step 12614, loss 0.53043.
Train: 2018-07-31T01:14:09.677806: step 12615, loss 0.59511.
Train: 2018-07-31T01:14:09.818401: step 12616, loss 0.538417.
Train: 2018-07-31T01:14:09.974637: step 12617, loss 0.530225.
Train: 2018-07-31T01:14:10.115230: step 12618, loss 0.546262.
Train: 2018-07-31T01:14:10.271457: step 12619, loss 0.529905.
Train: 2018-07-31T01:14:10.427633: step 12620, loss 0.570898.
Test: 2018-07-31T01:14:10.661953: step 12620, loss 0.548628.
Train: 2018-07-31T01:14:10.802545: step 12621, loss 0.603715.
Train: 2018-07-31T01:14:10.943136: step 12622, loss 0.570685.
Train: 2018-07-31T01:14:11.099350: step 12623, loss 0.496765.
Train: 2018-07-31T01:14:11.239942: step 12624, loss 0.513033.
Train: 2018-07-31T01:14:11.380533: step 12625, loss 0.537677.
Train: 2018-07-31T01:14:11.521127: step 12626, loss 0.62061.
Train: 2018-07-31T01:14:11.661718: step 12627, loss 0.587474.
Train: 2018-07-31T01:14:11.802309: step 12628, loss 0.604126.
Train: 2018-07-31T01:14:11.942902: step 12629, loss 0.529348.
Train: 2018-07-31T01:14:12.099116: step 12630, loss 0.587296.
Test: 2018-07-31T01:14:12.333469: step 12630, loss 0.548545.
Train: 2018-07-31T01:14:12.489648: step 12631, loss 0.587421.
Train: 2018-07-31T01:14:12.630266: step 12632, loss 0.603859.
Train: 2018-07-31T01:14:12.770832: step 12633, loss 0.512842.
Train: 2018-07-31T01:14:12.927046: step 12634, loss 0.620401.
Train: 2018-07-31T01:14:13.067639: step 12635, loss 0.513087.
Train: 2018-07-31T01:14:13.223851: step 12636, loss 0.562553.
Train: 2018-07-31T01:14:13.348822: step 12637, loss 0.578977.
Train: 2018-07-31T01:14:13.489416: step 12638, loss 0.578984.
Train: 2018-07-31T01:14:13.645627: step 12639, loss 0.496842.
Train: 2018-07-31T01:14:13.786238: step 12640, loss 0.554366.
Test: 2018-07-31T01:14:14.020572: step 12640, loss 0.548786.
Train: 2018-07-31T01:14:14.176754: step 12641, loss 0.521473.
Train: 2018-07-31T01:14:14.317346: step 12642, loss 0.578973.
Train: 2018-07-31T01:14:14.473583: step 12643, loss 0.628348.
Train: 2018-07-31T01:14:14.629773: step 12644, loss 0.488551.
Train: 2018-07-31T01:14:14.770366: step 12645, loss 0.595439.
Train: 2018-07-31T01:14:14.910981: step 12646, loss 0.58721.
Train: 2018-07-31T01:14:15.051550: step 12647, loss 0.521433.
Train: 2018-07-31T01:14:15.192166: step 12648, loss 0.587205.
Train: 2018-07-31T01:14:15.332751: step 12649, loss 0.5872.
Train: 2018-07-31T01:14:15.473324: step 12650, loss 0.562546.
Test: 2018-07-31T01:14:15.707674: step 12650, loss 0.548807.
Train: 2018-07-31T01:14:15.863860: step 12651, loss 0.587176.
Train: 2018-07-31T01:14:16.004451: step 12652, loss 0.529776.
Train: 2018-07-31T01:14:16.129422: step 12653, loss 0.587162.
Train: 2018-07-31T01:14:16.285634: step 12654, loss 0.587127.
Train: 2018-07-31T01:14:16.426228: step 12655, loss 0.619824.
Train: 2018-07-31T01:14:16.566845: step 12656, loss 0.505536.
Train: 2018-07-31T01:14:16.723033: step 12657, loss 0.562653.
Train: 2018-07-31T01:14:16.863649: step 12658, loss 0.587055.
Train: 2018-07-31T01:14:17.004217: step 12659, loss 0.578914.
Train: 2018-07-31T01:14:17.160431: step 12660, loss 0.578908.
Test: 2018-07-31T01:14:17.394750: step 12660, loss 0.549135.
Train: 2018-07-31T01:14:17.535342: step 12661, loss 0.522208.
Train: 2018-07-31T01:14:17.675934: step 12662, loss 0.497965.
Train: 2018-07-31T01:14:17.832148: step 12663, loss 0.586996.
Train: 2018-07-31T01:14:17.972740: step 12664, loss 0.554592.
Train: 2018-07-31T01:14:18.113332: step 12665, loss 0.570794.
Train: 2018-07-31T01:14:18.253924: step 12666, loss 0.570793.
Train: 2018-07-31T01:14:18.394541: step 12667, loss 0.570793.
Train: 2018-07-31T01:14:18.535133: step 12668, loss 0.530253.
Train: 2018-07-31T01:14:18.675742: step 12669, loss 0.57079.
Train: 2018-07-31T01:14:18.816293: step 12670, loss 0.522087.
Test: 2018-07-31T01:14:19.066267: step 12670, loss 0.549143.
Train: 2018-07-31T01:14:19.206825: step 12671, loss 0.570784.
Train: 2018-07-31T01:14:19.363041: step 12672, loss 0.554509.
Train: 2018-07-31T01:14:19.519253: step 12673, loss 0.554488.
Train: 2018-07-31T01:14:19.659845: step 12674, loss 0.603391.
Train: 2018-07-31T01:14:19.800437: step 12675, loss 0.497371.
Train: 2018-07-31T01:14:19.956651: step 12676, loss 0.595275.
Train: 2018-07-31T01:14:20.097268: step 12677, loss 0.611639.
Train: 2018-07-31T01:14:20.253456: step 12678, loss 0.570769.
Train: 2018-07-31T01:14:20.394048: step 12679, loss 0.538107.
Train: 2018-07-31T01:14:20.534640: step 12680, loss 0.546273.
Test: 2018-07-31T01:14:20.768960: step 12680, loss 0.548923.
Train: 2018-07-31T01:14:20.909552: step 12681, loss 0.562601.
Train: 2018-07-31T01:14:21.050145: step 12682, loss 0.529914.
Train: 2018-07-31T01:14:21.206359: step 12683, loss 0.603484.
Train: 2018-07-31T01:14:21.346950: step 12684, loss 0.527693.
Train: 2018-07-31T01:14:21.487542: step 12685, loss 0.603504.
Train: 2018-07-31T01:14:21.628134: step 12686, loss 0.51349.
Train: 2018-07-31T01:14:21.768750: step 12687, loss 0.52982.
Train: 2018-07-31T01:14:21.924964: step 12688, loss 0.578962.
Train: 2018-07-31T01:14:22.065555: step 12689, loss 0.578968.
Train: 2018-07-31T01:14:22.206148: step 12690, loss 0.587182.
Test: 2018-07-31T01:14:22.456093: step 12690, loss 0.548802.
Train: 2018-07-31T01:14:22.596683: step 12691, loss 0.554341.
Train: 2018-07-31T01:14:22.752869: step 12692, loss 0.57897.
Train: 2018-07-31T01:14:22.909084: step 12693, loss 0.554349.
Train: 2018-07-31T01:14:23.049700: step 12694, loss 0.537945.
Train: 2018-07-31T01:14:23.205914: step 12695, loss 0.595381.
Train: 2018-07-31T01:14:23.362127: step 12696, loss 0.660993.
Train: 2018-07-31T01:14:23.518340: step 12697, loss 0.521674.
Train: 2018-07-31T01:14:23.674530: step 12698, loss 0.644301.
Train: 2018-07-31T01:14:23.815146: step 12699, loss 0.627794.
Train: 2018-07-31T01:14:23.955715: step 12700, loss 0.530234.
Test: 2018-07-31T01:14:24.205683: step 12700, loss 0.54918.
Train: 2018-07-31T01:14:24.955504: step 12701, loss 0.570804.
Train: 2018-07-31T01:14:25.096072: step 12702, loss 0.635326.
Train: 2018-07-31T01:14:25.236664: step 12703, loss 0.57084.
Train: 2018-07-31T01:14:25.377255: step 12704, loss 0.482871.
Train: 2018-07-31T01:14:25.517848: step 12705, loss 0.530941.
Train: 2018-07-31T01:14:25.658441: step 12706, loss 0.554915.
Train: 2018-07-31T01:14:25.799058: step 12707, loss 0.57886.
Train: 2018-07-31T01:14:25.955247: step 12708, loss 0.570884.
Train: 2018-07-31T01:14:26.095838: step 12709, loss 0.562917.
Train: 2018-07-31T01:14:26.236455: step 12710, loss 0.554954.
Test: 2018-07-31T01:14:26.470782: step 12710, loss 0.549578.
Train: 2018-07-31T01:14:26.626988: step 12711, loss 0.586828.
Train: 2018-07-31T01:14:26.767579: step 12712, loss 0.554965.
Train: 2018-07-31T01:14:26.908147: step 12713, loss 0.547004.
Train: 2018-07-31T01:14:27.064386: step 12714, loss 0.578859.
Train: 2018-07-31T01:14:27.220598: step 12715, loss 0.507153.
Train: 2018-07-31T01:14:27.361166: step 12716, loss 0.562903.
Train: 2018-07-31T01:14:27.501783: step 12717, loss 0.618812.
Train: 2018-07-31T01:14:27.642375: step 12718, loss 0.554889.
Train: 2018-07-31T01:14:27.798588: step 12719, loss 0.602844.
Train: 2018-07-31T01:14:27.939159: step 12720, loss 0.530921.
Test: 2018-07-31T01:14:28.173507: step 12720, loss 0.54949.
Train: 2018-07-31T01:14:28.329691: step 12721, loss 0.562876.
Train: 2018-07-31T01:14:28.470306: step 12722, loss 0.530881.
Train: 2018-07-31T01:14:28.610899: step 12723, loss 0.594878.
Train: 2018-07-31T01:14:28.751490: step 12724, loss 0.618917.
Train: 2018-07-31T01:14:28.892058: step 12725, loss 0.618886.
Train: 2018-07-31T01:14:29.048295: step 12726, loss 0.538913.
Train: 2018-07-31T01:14:29.188876: step 12727, loss 0.602805.
Train: 2018-07-31T01:14:29.345102: step 12728, loss 0.61073.
Train: 2018-07-31T01:14:29.485695: step 12729, loss 0.523225.
Train: 2018-07-31T01:14:29.641883: step 12730, loss 0.53917.
Test: 2018-07-31T01:14:29.876203: step 12730, loss 0.549702.
Train: 2018-07-31T01:14:30.032423: step 12731, loss 0.594727.
Train: 2018-07-31T01:14:30.188630: step 12732, loss 0.531301.
Train: 2018-07-31T01:14:30.329221: step 12733, loss 0.539229.
Train: 2018-07-31T01:14:30.469813: step 12734, loss 0.52334.
Train: 2018-07-31T01:14:30.610430: step 12735, loss 0.586803.
Train: 2018-07-31T01:14:30.750999: step 12736, loss 0.594763.
Train: 2018-07-31T01:14:30.891589: step 12737, loss 0.531128.
Train: 2018-07-31T01:14:31.032183: step 12738, loss 0.554966.
Train: 2018-07-31T01:14:31.172774: step 12739, loss 0.59481.
Train: 2018-07-31T01:14:31.328988: step 12740, loss 0.507045.
Test: 2018-07-31T01:14:31.563341: step 12740, loss 0.549484.
Train: 2018-07-31T01:14:31.719545: step 12741, loss 0.586857.
Train: 2018-07-31T01:14:31.860137: step 12742, loss 0.538841.
Train: 2018-07-31T01:14:32.016350: step 12743, loss 0.610942.
Train: 2018-07-31T01:14:32.172565: step 12744, loss 0.530728.
Train: 2018-07-31T01:14:32.297535: step 12745, loss 0.578871.
Train: 2018-07-31T01:14:32.453725: step 12746, loss 0.530627.
Train: 2018-07-31T01:14:32.609938: step 12747, loss 0.554716.
Train: 2018-07-31T01:14:32.750553: step 12748, loss 0.506276.
Train: 2018-07-31T01:14:32.891121: step 12749, loss 0.506083.
Train: 2018-07-31T01:14:33.031727: step 12750, loss 0.595149.
Test: 2018-07-31T01:14:33.266033: step 12750, loss 0.548998.
Train: 2018-07-31T01:14:33.406626: step 12751, loss 0.521922.
Train: 2018-07-31T01:14:33.562840: step 12752, loss 0.570769.
Train: 2018-07-31T01:14:33.703456: step 12753, loss 0.505223.
Train: 2018-07-31T01:14:33.859680: step 12754, loss 0.496751.
Train: 2018-07-31T01:14:34.000238: step 12755, loss 0.595541.
Train: 2018-07-31T01:14:34.140854: step 12756, loss 0.529307.
Train: 2018-07-31T01:14:34.312688: step 12757, loss 0.545799.
Train: 2018-07-31T01:14:34.453255: step 12758, loss 0.595821.
Train: 2018-07-31T01:14:34.593848: step 12759, loss 0.487068.
Train: 2018-07-31T01:14:34.750061: step 12760, loss 0.570786.
Test: 2018-07-31T01:14:34.984412: step 12760, loss 0.548263.
Train: 2018-07-31T01:14:35.124972: step 12761, loss 0.638198.
Train: 2018-07-31T01:14:35.265565: step 12762, loss 0.53707.
Train: 2018-07-31T01:14:35.406183: step 12763, loss 0.60458.
Train: 2018-07-31T01:14:35.546749: step 12764, loss 0.537038.
Train: 2018-07-31T01:14:35.702963: step 12765, loss 0.579258.
Train: 2018-07-31T01:14:35.859178: step 12766, loss 0.579255.
Train: 2018-07-31T01:14:35.984166: step 12767, loss 0.562367.
Train: 2018-07-31T01:14:36.124740: step 12768, loss 0.53707.
Train: 2018-07-31T01:14:36.265357: step 12769, loss 0.503356.
Train: 2018-07-31T01:14:36.421569: step 12770, loss 0.52862.
Test: 2018-07-31T01:14:36.655890: step 12770, loss 0.548216.
Train: 2018-07-31T01:14:36.812078: step 12771, loss 0.545469.
Train: 2018-07-31T01:14:36.952695: step 12772, loss 0.562359.
Train: 2018-07-31T01:14:37.093286: step 12773, loss 0.486162.
Train: 2018-07-31T01:14:37.233879: step 12774, loss 0.536895.
Train: 2018-07-31T01:14:37.374448: step 12775, loss 0.562344.
Train: 2018-07-31T01:14:37.515064: step 12776, loss 0.519738.
Train: 2018-07-31T01:14:37.655630: step 12777, loss 0.485473.
Train: 2018-07-31T01:14:37.796222: step 12778, loss 0.519487.
Train: 2018-07-31T01:14:37.952436: step 12779, loss 0.60534.
Train: 2018-07-31T01:14:38.108650: step 12780, loss 0.536477.
Test: 2018-07-31T01:14:38.358590: step 12780, loss 0.547872.
Train: 2018-07-31T01:14:38.499201: step 12781, loss 0.545062.
Train: 2018-07-31T01:14:38.639800: step 12782, loss 0.579657.
Train: 2018-07-31T01:14:38.796013: step 12783, loss 0.579682.
Train: 2018-07-31T01:14:38.936607: step 12784, loss 0.527658.
Train: 2018-07-31T01:14:39.077197: step 12785, loss 0.605747.
Train: 2018-07-31T01:14:39.233387: step 12786, loss 0.544995.
Train: 2018-07-31T01:14:39.374003: step 12787, loss 0.553674.
Train: 2018-07-31T01:14:39.514594: step 12788, loss 0.553676.
Train: 2018-07-31T01:14:39.655162: step 12789, loss 0.623016.
Train: 2018-07-31T01:14:39.811375: step 12790, loss 0.640202.
Test: 2018-07-31T01:14:40.045727: step 12790, loss 0.547898.
Train: 2018-07-31T01:14:40.201910: step 12791, loss 0.484743.
Train: 2018-07-31T01:14:40.342501: step 12792, loss 0.55373.
Train: 2018-07-31T01:14:40.498716: step 12793, loss 0.553745.
Train: 2018-07-31T01:14:40.654928: step 12794, loss 0.553759.
Train: 2018-07-31T01:14:40.795520: step 12795, loss 0.588024.
Train: 2018-07-31T01:14:40.936137: step 12796, loss 0.553792.
Train: 2018-07-31T01:14:41.092327: step 12797, loss 0.570867.
Train: 2018-07-31T01:14:41.232918: step 12798, loss 0.579364.
Train: 2018-07-31T01:14:41.373510: step 12799, loss 0.519905.
Train: 2018-07-31T01:14:41.514103: step 12800, loss 0.553878.
Test: 2018-07-31T01:14:41.764075: step 12800, loss 0.548183.
Train: 2018-07-31T01:14:42.498272: step 12801, loss 0.545431.
Train: 2018-07-31T01:14:42.638863: step 12802, loss 0.545454.
Train: 2018-07-31T01:14:42.795052: step 12803, loss 0.562365.
Train: 2018-07-31T01:14:42.935645: step 12804, loss 0.511734.
Train: 2018-07-31T01:14:43.076237: step 12805, loss 0.604562.
Train: 2018-07-31T01:14:43.232475: step 12806, loss 0.537078.
Train: 2018-07-31T01:14:43.373042: step 12807, loss 0.612931.
Train: 2018-07-31T01:14:43.513634: step 12808, loss 0.596029.
Train: 2018-07-31T01:14:43.654227: step 12809, loss 0.528819.
Train: 2018-07-31T01:14:43.794844: step 12810, loss 0.570778.
Test: 2018-07-31T01:14:44.044760: step 12810, loss 0.548397.
Train: 2018-07-31T01:14:44.185376: step 12811, loss 0.579139.
Train: 2018-07-31T01:14:44.325968: step 12812, loss 0.570768.
Train: 2018-07-31T01:14:44.482162: step 12813, loss 0.54577.
Train: 2018-07-31T01:14:44.622774: step 12814, loss 0.612351.
Train: 2018-07-31T01:14:44.763340: step 12815, loss 0.54587.
Train: 2018-07-31T01:14:44.903933: step 12816, loss 0.570757.
Train: 2018-07-31T01:14:45.060148: step 12817, loss 0.587278.
Train: 2018-07-31T01:14:45.200739: step 12818, loss 0.603718.
Train: 2018-07-31T01:14:45.356953: step 12819, loss 0.521476.
Train: 2018-07-31T01:14:45.497569: step 12820, loss 0.537974.
Test: 2018-07-31T01:14:45.731896: step 12820, loss 0.548869.
Train: 2018-07-31T01:14:45.888078: step 12821, loss 0.554392.
Train: 2018-07-31T01:14:46.028670: step 12822, loss 0.562589.
Train: 2018-07-31T01:14:46.169262: step 12823, loss 0.587109.
Train: 2018-07-31T01:14:46.309854: step 12824, loss 0.570773.
Train: 2018-07-31T01:14:46.450446: step 12825, loss 0.570777.
Train: 2018-07-31T01:14:46.591063: step 12826, loss 0.562647.
Train: 2018-07-31T01:14:46.731655: step 12827, loss 0.546414.
Train: 2018-07-31T01:14:46.872222: step 12828, loss 0.59514.
Train: 2018-07-31T01:14:47.012855: step 12829, loss 0.570794.
Train: 2018-07-31T01:14:47.153431: step 12830, loss 0.635551.
Test: 2018-07-31T01:14:47.403347: step 12830, loss 0.549226.
Train: 2018-07-31T01:14:47.543965: step 12831, loss 0.595024.
Train: 2018-07-31T01:14:47.700154: step 12832, loss 0.538653.
Train: 2018-07-31T01:14:47.840792: step 12833, loss 0.546767.
Train: 2018-07-31T01:14:47.996960: step 12834, loss 0.562843.
Train: 2018-07-31T01:14:48.121954: step 12835, loss 0.545792.
Train: 2018-07-31T01:14:48.278144: step 12836, loss 0.530898.
Train: 2018-07-31T01:14:48.418736: step 12837, loss 0.530888.
Train: 2018-07-31T01:14:48.559330: step 12838, loss 0.554853.
Train: 2018-07-31T01:14:48.715565: step 12839, loss 0.538799.
Train: 2018-07-31T01:14:48.871755: step 12840, loss 0.530713.
Test: 2018-07-31T01:14:49.106075: step 12840, loss 0.549302.
Train: 2018-07-31T01:14:49.262289: step 12841, loss 0.594929.
Train: 2018-07-31T01:14:49.402880: step 12842, loss 0.595088.
Train: 2018-07-31T01:14:49.559117: step 12843, loss 0.490164.
Train: 2018-07-31T01:14:49.715307: step 12844, loss 0.659784.
Train: 2018-07-31T01:14:49.855900: step 12845, loss 0.554673.
Train: 2018-07-31T01:14:50.012136: step 12846, loss 0.514288.
Train: 2018-07-31T01:14:50.152729: step 12847, loss 0.522297.
Train: 2018-07-31T01:14:50.293297: step 12848, loss 0.570797.
Train: 2018-07-31T01:14:50.433914: step 12849, loss 0.554562.
Train: 2018-07-31T01:14:50.574505: step 12850, loss 0.578912.
Test: 2018-07-31T01:14:50.824421: step 12850, loss 0.549015.
Train: 2018-07-31T01:14:50.996281: step 12851, loss 0.530093.
Train: 2018-07-31T01:14:51.136873: step 12852, loss 0.562623.
Train: 2018-07-31T01:14:51.277442: step 12853, loss 0.53811.
Train: 2018-07-31T01:14:51.433654: step 12854, loss 0.578947.
Train: 2018-07-31T01:14:51.574271: step 12855, loss 0.554378.
Train: 2018-07-31T01:14:51.730461: step 12856, loss 0.636395.
Train: 2018-07-31T01:14:51.871052: step 12857, loss 0.587164.
Train: 2018-07-31T01:14:52.011643: step 12858, loss 0.652704.
Train: 2018-07-31T01:14:52.152261: step 12859, loss 0.57894.
Train: 2018-07-31T01:14:52.292853: step 12860, loss 0.546332.
Test: 2018-07-31T01:14:52.527179: step 12860, loss 0.549037.
Train: 2018-07-31T01:14:52.683387: step 12861, loss 0.530133.
Train: 2018-07-31T01:14:52.823968: step 12862, loss 0.587027.
Train: 2018-07-31T01:14:52.964546: step 12863, loss 0.562688.
Train: 2018-07-31T01:14:53.105163: step 12864, loss 0.538423.
Train: 2018-07-31T01:14:53.245738: step 12865, loss 0.465659.
Train: 2018-07-31T01:14:53.401944: step 12866, loss 0.603198.
Train: 2018-07-31T01:14:53.542535: step 12867, loss 0.514065.
Train: 2018-07-31T01:14:53.698749: step 12868, loss 0.570789.
Train: 2018-07-31T01:14:53.823720: step 12869, loss 0.587038.
Train: 2018-07-31T01:14:53.979957: step 12870, loss 0.578914.
Test: 2018-07-31T01:14:54.214281: step 12870, loss 0.549026.
Train: 2018-07-31T01:14:54.354845: step 12871, loss 0.513846.
Train: 2018-07-31T01:14:54.495436: step 12872, loss 0.58706.
Train: 2018-07-31T01:14:54.651649: step 12873, loss 0.578928.
Train: 2018-07-31T01:14:54.792242: step 12874, loss 0.562627.
Train: 2018-07-31T01:14:54.932839: step 12875, loss 0.578934.
Train: 2018-07-31T01:14:55.073427: step 12876, loss 0.660438.
Train: 2018-07-31T01:14:55.214019: step 12877, loss 0.530128.
Train: 2018-07-31T01:14:55.354611: step 12878, loss 0.554546.
Train: 2018-07-31T01:14:55.479581: step 12879, loss 0.570793.
Train: 2018-07-31T01:14:55.635820: step 12880, loss 0.587.
Test: 2018-07-31T01:14:55.870146: step 12880, loss 0.549162.
Train: 2018-07-31T01:14:56.026328: step 12881, loss 0.643614.
Train: 2018-07-31T01:14:56.182543: step 12882, loss 0.538555.
Train: 2018-07-31T01:14:56.323135: step 12883, loss 0.578875.
Train: 2018-07-31T01:14:56.463727: step 12884, loss 0.530695.
Train: 2018-07-31T01:14:56.604318: step 12885, loss 0.538772.
Train: 2018-07-31T01:14:56.744935: step 12886, loss 0.506732.
Train: 2018-07-31T01:14:56.901148: step 12887, loss 0.554802.
Train: 2018-07-31T01:14:57.041741: step 12888, loss 0.57084.
Train: 2018-07-31T01:14:57.197930: step 12889, loss 0.611022.
Train: 2018-07-31T01:14:57.338521: step 12890, loss 0.627084.
Test: 2018-07-31T01:14:57.572875: step 12890, loss 0.549387.
Train: 2018-07-31T01:14:57.729054: step 12891, loss 0.538755.
Train: 2018-07-31T01:14:57.885293: step 12892, loss 0.466642.
Train: 2018-07-31T01:14:58.010238: step 12893, loss 0.498588.
Train: 2018-07-31T01:14:58.166452: step 12894, loss 0.619133.
Train: 2018-07-31T01:14:58.307044: step 12895, loss 0.522444.
Train: 2018-07-31T01:14:58.463257: step 12896, loss 0.554647.
Train: 2018-07-31T01:14:58.603851: step 12897, loss 0.538407.
Train: 2018-07-31T01:14:58.744444: step 12898, loss 0.546433.
Train: 2018-07-31T01:14:58.900657: step 12899, loss 0.635899.
Train: 2018-07-31T01:14:59.041249: step 12900, loss 0.56263.
Test: 2018-07-31T01:14:59.275571: step 12900, loss 0.548969.
Train: 2018-07-31T01:15:00.103500: step 12901, loss 0.505556.
Train: 2018-07-31T01:15:00.244091: step 12902, loss 0.505428.
Train: 2018-07-31T01:15:00.384683: step 12903, loss 0.595339.
Train: 2018-07-31T01:15:00.525275: step 12904, loss 0.521517.
Train: 2018-07-31T01:15:00.665867: step 12905, loss 0.611899.
Train: 2018-07-31T01:15:00.806459: step 12906, loss 0.529568.
Train: 2018-07-31T01:15:00.947076: step 12907, loss 0.529494.
Train: 2018-07-31T01:15:01.087643: step 12908, loss 0.587296.
Train: 2018-07-31T01:15:01.243857: step 12909, loss 0.603883.
Train: 2018-07-31T01:15:01.400071: step 12910, loss 0.504476.
Test: 2018-07-31T01:15:01.634417: step 12910, loss 0.548566.
Train: 2018-07-31T01:15:01.774983: step 12911, loss 0.603946.
Train: 2018-07-31T01:15:01.931196: step 12912, loss 0.537562.
Train: 2018-07-31T01:15:02.071787: step 12913, loss 0.595668.
Train: 2018-07-31T01:15:02.228001: step 12914, loss 0.562443.
Train: 2018-07-31T01:15:02.368593: step 12915, loss 0.620609.
Train: 2018-07-31T01:15:02.509185: step 12916, loss 0.529306.
Train: 2018-07-31T01:15:02.649803: step 12917, loss 0.579041.
Train: 2018-07-31T01:15:02.805990: step 12918, loss 0.504562.
Train: 2018-07-31T01:15:02.946584: step 12919, loss 0.512824.
Train: 2018-07-31T01:15:03.087200: step 12920, loss 0.545902.
Test: 2018-07-31T01:15:03.321527: step 12920, loss 0.548568.
Train: 2018-07-31T01:15:03.477710: step 12921, loss 0.520981.
Train: 2018-07-31T01:15:03.618301: step 12922, loss 0.604009.
Train: 2018-07-31T01:15:03.758917: step 12923, loss 0.579081.
Train: 2018-07-31T01:15:03.899510: step 12924, loss 0.545799.
Train: 2018-07-31T01:15:04.040077: step 12925, loss 0.570763.
Train: 2018-07-31T01:15:04.180669: step 12926, loss 0.587416.
Train: 2018-07-31T01:15:04.321261: step 12927, loss 0.587408.
Train: 2018-07-31T01:15:04.477492: step 12928, loss 0.545818.
Train: 2018-07-31T01:15:04.618105: step 12929, loss 0.529217.
Train: 2018-07-31T01:15:04.758683: step 12930, loss 0.504291.
Test: 2018-07-31T01:15:05.008601: step 12930, loss 0.548513.
Train: 2018-07-31T01:15:05.149193: step 12931, loss 0.529172.
Train: 2018-07-31T01:15:05.289810: step 12932, loss 0.537438.
Train: 2018-07-31T01:15:05.446021: step 12933, loss 0.629197.
Train: 2018-07-31T01:15:05.586615: step 12934, loss 0.462237.
Train: 2018-07-31T01:15:05.727182: step 12935, loss 0.654437.
Train: 2018-07-31T01:15:05.883394: step 12936, loss 0.554042.
Train: 2018-07-31T01:15:06.024012: step 12937, loss 0.562408.
Train: 2018-07-31T01:15:06.164597: step 12938, loss 0.570773.
Train: 2018-07-31T01:15:06.305171: step 12939, loss 0.595852.
Train: 2018-07-31T01:15:06.445765: step 12940, loss 0.512318.
Test: 2018-07-31T01:15:06.695736: step 12940, loss 0.548437.
Train: 2018-07-31T01:15:06.836298: step 12941, loss 0.545722.
Train: 2018-07-31T01:15:06.976889: step 12942, loss 0.53737.
Train: 2018-07-31T01:15:07.133104: step 12943, loss 0.587477.
Train: 2018-07-31T01:15:07.273695: step 12944, loss 0.570769.
Train: 2018-07-31T01:15:07.414288: step 12945, loss 0.529027.
Train: 2018-07-31T01:15:07.570525: step 12946, loss 0.52902.
Train: 2018-07-31T01:15:07.711119: step 12947, loss 0.57077.
Train: 2018-07-31T01:15:07.867306: step 12948, loss 0.629284.
Train: 2018-07-31T01:15:08.007899: step 12949, loss 0.612514.
Train: 2018-07-31T01:15:08.148491: step 12950, loss 0.554102.
Test: 2018-07-31T01:15:08.382839: step 12950, loss 0.548521.
Train: 2018-07-31T01:15:08.523402: step 12951, loss 0.554131.
Train: 2018-07-31T01:15:08.679615: step 12952, loss 0.554157.
Train: 2018-07-31T01:15:08.820232: step 12953, loss 0.628784.
Train: 2018-07-31T01:15:08.960801: step 12954, loss 0.636892.
Train: 2018-07-31T01:15:09.101417: step 12955, loss 0.521359.
Train: 2018-07-31T01:15:09.257629: step 12956, loss 0.505085.
Train: 2018-07-31T01:15:09.413843: step 12957, loss 0.562564.
Train: 2018-07-31T01:15:09.616897: step 12958, loss 0.497077.
Train: 2018-07-31T01:15:09.757489: step 12959, loss 0.611712.
Train: 2018-07-31T01:15:09.898080: step 12960, loss 0.660772.
Test: 2018-07-31T01:15:10.148051: step 12960, loss 0.54895.
Train: 2018-07-31T01:15:10.304260: step 12961, loss 0.627883.
Train: 2018-07-31T01:15:10.444853: step 12962, loss 0.538282.
Train: 2018-07-31T01:15:10.601042: step 12963, loss 0.538394.
Train: 2018-07-31T01:15:10.741657: step 12964, loss 0.611219.
Train: 2018-07-31T01:15:10.897847: step 12965, loss 0.522473.
Train: 2018-07-31T01:15:11.038438: step 12966, loss 0.562787.
Train: 2018-07-31T01:15:11.179031: step 12967, loss 0.570839.
Train: 2018-07-31T01:15:11.319623: step 12968, loss 0.522734.
Train: 2018-07-31T01:15:11.460239: step 12969, loss 0.530771.
Train: 2018-07-31T01:15:11.600831: step 12970, loss 0.538769.
Test: 2018-07-31T01:15:11.850749: step 12970, loss 0.549369.
Train: 2018-07-31T01:15:11.991340: step 12971, loss 0.562814.
Train: 2018-07-31T01:15:12.131933: step 12972, loss 0.60298.
Train: 2018-07-31T01:15:12.272524: step 12973, loss 0.594945.
Train: 2018-07-31T01:15:12.413141: step 12974, loss 0.514615.
Train: 2018-07-31T01:15:12.553708: step 12975, loss 0.53065.
Train: 2018-07-31T01:15:12.709924: step 12976, loss 0.619115.
Train: 2018-07-31T01:15:12.850514: step 12977, loss 0.538635.
Train: 2018-07-31T01:15:12.991130: step 12978, loss 0.627196.
Train: 2018-07-31T01:15:13.131697: step 12979, loss 0.546689.
Train: 2018-07-31T01:15:13.272291: step 12980, loss 0.53061.
Test: 2018-07-31T01:15:13.506638: step 12980, loss 0.5493.
Train: 2018-07-31T01:15:13.662823: step 12981, loss 0.611068.
Train: 2018-07-31T01:15:13.803417: step 12982, loss 0.57083.
Train: 2018-07-31T01:15:13.944032: step 12983, loss 0.53064.
Train: 2018-07-31T01:15:14.084601: step 12984, loss 0.554751.
Train: 2018-07-31T01:15:14.240831: step 12985, loss 0.530609.
Train: 2018-07-31T01:15:14.381405: step 12986, loss 0.597133.
Train: 2018-07-31T01:15:14.537650: step 12987, loss 0.594992.
Train: 2018-07-31T01:15:14.662589: step 12988, loss 0.570823.
Train: 2018-07-31T01:15:14.803182: step 12989, loss 0.570825.
Train: 2018-07-31T01:15:14.943786: step 12990, loss 0.578875.
Test: 2018-07-31T01:15:15.193741: step 12990, loss 0.549313.
Train: 2018-07-31T01:15:15.334308: step 12991, loss 0.562792.
Train: 2018-07-31T01:15:15.474899: step 12992, loss 0.562799.
Train: 2018-07-31T01:15:15.631113: step 12993, loss 0.594936.
Train: 2018-07-31T01:15:15.771729: step 12994, loss 0.610964.
Train: 2018-07-31T01:15:15.927919: step 12995, loss 0.618905.
Train: 2018-07-31T01:15:16.084155: step 12996, loss 0.530954.
Train: 2018-07-31T01:15:16.224725: step 12997, loss 0.666528.
Train: 2018-07-31T01:15:16.365341: step 12998, loss 0.435959.
Train: 2018-07-31T01:15:16.505932: step 12999, loss 0.523313.
Train: 2018-07-31T01:15:16.662121: step 13000, loss 0.570919.
Test: 2018-07-31T01:15:16.896472: step 13000, loss 0.549667.
Train: 2018-07-31T01:15:17.646291: step 13001, loss 0.483533.
Train: 2018-07-31T01:15:17.802481: step 13002, loss 0.562934.
Train: 2018-07-31T01:15:17.958694: step 13003, loss 0.554919.
Train: 2018-07-31T01:15:18.099285: step 13004, loss 0.610859.
Train: 2018-07-31T01:15:18.255499: step 13005, loss 0.474767.
Train: 2018-07-31T01:15:18.411713: step 13006, loss 0.659188.
Train: 2018-07-31T01:15:18.552304: step 13007, loss 0.619057.
Train: 2018-07-31T01:15:18.692897: step 13008, loss 0.627064.
Train: 2018-07-31T01:15:18.833489: step 13009, loss 0.538781.
Train: 2018-07-31T01:15:18.974081: step 13010, loss 0.49878.
Test: 2018-07-31T01:15:19.224047: step 13010, loss 0.549421.
Train: 2018-07-31T01:15:19.364638: step 13011, loss 0.610917.
Train: 2018-07-31T01:15:19.520827: step 13012, loss 0.626917.
Train: 2018-07-31T01:15:19.661455: step 13013, loss 0.602846.
Train: 2018-07-31T01:15:19.802011: step 13014, loss 0.57886.
Train: 2018-07-31T01:15:19.958224: step 13015, loss 0.531123.
Train: 2018-07-31T01:15:20.114463: step 13016, loss 0.491461.
Train: 2018-07-31T01:15:20.255029: step 13017, loss 0.523213.
Train: 2018-07-31T01:15:20.395622: step 13018, loss 0.562937.
Train: 2018-07-31T01:15:20.536215: step 13019, loss 0.57886.
Train: 2018-07-31T01:15:20.676805: step 13020, loss 0.594823.
Test: 2018-07-31T01:15:20.911157: step 13020, loss 0.549523.
Train: 2018-07-31T01:15:21.067341: step 13021, loss 0.586845.
Train: 2018-07-31T01:15:21.223552: step 13022, loss 0.562895.
Train: 2018-07-31T01:15:21.364145: step 13023, loss 0.54693.
Train: 2018-07-31T01:15:21.520358: step 13024, loss 0.483028.
Train: 2018-07-31T01:15:21.660950: step 13025, loss 0.522834.
Train: 2018-07-31T01:15:21.801543: step 13026, loss 0.57887.
Train: 2018-07-31T01:15:21.957755: step 13027, loss 0.578875.
Train: 2018-07-31T01:15:22.098368: step 13028, loss 0.562754.
Train: 2018-07-31T01:15:22.238958: step 13029, loss 0.490034.
Train: 2018-07-31T01:15:22.379534: step 13030, loss 0.611312.
Test: 2018-07-31T01:15:22.629486: step 13030, loss 0.549073.
Train: 2018-07-31T01:15:22.770067: step 13031, loss 0.465248.
Train: 2018-07-31T01:15:22.926279: step 13032, loss 0.562624.
Train: 2018-07-31T01:15:23.066896: step 13033, loss 0.56259.
Train: 2018-07-31T01:15:23.207465: step 13034, loss 0.570754.
Train: 2018-07-31T01:15:23.363701: step 13035, loss 0.554315.
Train: 2018-07-31T01:15:23.504269: step 13036, loss 0.636741.
Train: 2018-07-31T01:15:23.644861: step 13037, loss 0.537768.
Train: 2018-07-31T01:15:23.801099: step 13038, loss 0.529481.
Train: 2018-07-31T01:15:23.941668: step 13039, loss 0.579022.
Train: 2018-07-31T01:15:24.082261: step 13040, loss 0.636949.
Test: 2018-07-31T01:15:24.332201: step 13040, loss 0.548642.
Train: 2018-07-31T01:15:24.488414: step 13041, loss 0.529418.
Train: 2018-07-31T01:15:24.644654: step 13042, loss 0.537689.
Train: 2018-07-31T01:15:24.785244: step 13043, loss 0.570756.
Train: 2018-07-31T01:15:24.925813: step 13044, loss 0.51286.
Train: 2018-07-31T01:15:25.066428: step 13045, loss 0.529358.
Train: 2018-07-31T01:15:25.238274: step 13046, loss 0.595636.
Train: 2018-07-31T01:15:25.378830: step 13047, loss 0.56246.
Train: 2018-07-31T01:15:25.519446: step 13048, loss 0.628874.
Train: 2018-07-31T01:15:25.660013: step 13049, loss 0.587346.
Train: 2018-07-31T01:15:25.816227: step 13050, loss 0.545913.
Test: 2018-07-31T01:15:26.050549: step 13050, loss 0.54865.
Train: 2018-07-31T01:15:26.238028: step 13051, loss 0.579029.
Train: 2018-07-31T01:15:26.378596: step 13052, loss 0.6038.
Train: 2018-07-31T01:15:26.534811: step 13053, loss 0.620216.
Train: 2018-07-31T01:15:26.675451: step 13054, loss 0.554326.
Train: 2018-07-31T01:15:26.816017: step 13055, loss 0.529793.
Train: 2018-07-31T01:15:26.972213: step 13056, loss 0.603483.
Train: 2018-07-31T01:15:27.112823: step 13057, loss 0.595248.
Train: 2018-07-31T01:15:27.253391: step 13058, loss 0.595184.
Train: 2018-07-31T01:15:27.394008: step 13059, loss 0.514047.
Train: 2018-07-31T01:15:27.534600: step 13060, loss 0.506076.
Test: 2018-07-31T01:15:27.784518: step 13060, loss 0.549174.
Train: 2018-07-31T01:15:27.925109: step 13061, loss 0.498025.
Train: 2018-07-31T01:15:28.065726: step 13062, loss 0.595083.
Train: 2018-07-31T01:15:28.206318: step 13063, loss 0.578895.
Train: 2018-07-31T01:15:28.346910: step 13064, loss 0.546513.
Train: 2018-07-31T01:15:28.487476: step 13065, loss 0.53031.
Train: 2018-07-31T01:15:28.643718: step 13066, loss 0.546478.
Train: 2018-07-31T01:15:28.784307: step 13067, loss 0.457168.
Train: 2018-07-31T01:15:28.924899: step 13068, loss 0.53006.
Train: 2018-07-31T01:15:29.065491: step 13069, loss 0.57894.
Train: 2018-07-31T01:15:29.206058: step 13070, loss 0.587156.
Test: 2018-07-31T01:15:29.456001: step 13070, loss 0.548719.
Train: 2018-07-31T01:15:29.596636: step 13071, loss 0.587195.
Train: 2018-07-31T01:15:29.752807: step 13072, loss 0.57899.
Train: 2018-07-31T01:15:29.877777: step 13073, loss 0.504877.
Train: 2018-07-31T01:15:30.018369: step 13074, loss 0.455212.
Train: 2018-07-31T01:15:30.174583: step 13075, loss 0.554189.
Train: 2018-07-31T01:15:30.330820: step 13076, loss 0.653938.
Train: 2018-07-31T01:15:30.471408: step 13077, loss 0.604064.
Train: 2018-07-31T01:15:30.612004: step 13078, loss 0.504143.
Train: 2018-07-31T01:15:30.752596: step 13079, loss 0.537421.
Train: 2018-07-31T01:15:30.893188: step 13080, loss 0.52067.
Test: 2018-07-31T01:15:31.127515: step 13080, loss 0.548392.
Train: 2018-07-31T01:15:31.268075: step 13081, loss 0.520572.
Train: 2018-07-31T01:15:31.408692: step 13082, loss 0.554008.
Train: 2018-07-31T01:15:31.549261: step 13083, loss 0.570788.
Train: 2018-07-31T01:15:31.705491: step 13084, loss 0.629775.
Train: 2018-07-31T01:15:31.846067: step 13085, loss 0.579218.
Train: 2018-07-31T01:15:32.002309: step 13086, loss 0.604487.
Train: 2018-07-31T01:15:32.142872: step 13087, loss 0.511908.
Train: 2018-07-31T01:15:32.283465: step 13088, loss 0.562381.
Train: 2018-07-31T01:15:32.424080: step 13089, loss 0.54557.
Train: 2018-07-31T01:15:32.564647: step 13090, loss 0.587597.
Test: 2018-07-31T01:15:32.799000: step 13090, loss 0.548308.
Train: 2018-07-31T01:15:32.955205: step 13091, loss 0.545592.
Train: 2018-07-31T01:15:33.095773: step 13092, loss 0.570786.
Train: 2018-07-31T01:15:33.236365: step 13093, loss 0.545616.
Train: 2018-07-31T01:15:33.376958: step 13094, loss 0.629462.
Train: 2018-07-31T01:15:33.517550: step 13095, loss 0.545672.
Train: 2018-07-31T01:15:33.658141: step 13096, loss 0.545704.
Train: 2018-07-31T01:15:33.798733: step 13097, loss 0.504008.
Train: 2018-07-31T01:15:33.954947: step 13098, loss 0.537388.
Train: 2018-07-31T01:15:34.095539: step 13099, loss 0.545714.
Train: 2018-07-31T01:15:34.251753: step 13100, loss 0.562411.
Test: 2018-07-31T01:15:34.486103: step 13100, loss 0.54841.
Train: 2018-07-31T01:15:35.235897: step 13101, loss 0.54569.
Train: 2018-07-31T01:15:35.376490: step 13102, loss 0.654447.
Train: 2018-07-31T01:15:35.517080: step 13103, loss 0.554058.
Train: 2018-07-31T01:15:35.657673: step 13104, loss 0.579112.
Train: 2018-07-31T01:15:35.798265: step 13105, loss 0.545768.
Train: 2018-07-31T01:15:35.954480: step 13106, loss 0.5458.
Train: 2018-07-31T01:15:36.110717: step 13107, loss 0.587386.
Train: 2018-07-31T01:15:36.251309: step 13108, loss 0.562454.
Train: 2018-07-31T01:15:36.407499: step 13109, loss 0.579049.
Train: 2018-07-31T01:15:36.548109: step 13110, loss 0.537634.
Test: 2018-07-31T01:15:36.798056: step 13110, loss 0.548632.
Train: 2018-07-31T01:15:36.938638: step 13111, loss 0.587298.
Train: 2018-07-31T01:15:37.079240: step 13112, loss 0.488161.
Train: 2018-07-31T01:15:37.235430: step 13113, loss 0.537709.
Train: 2018-07-31T01:15:37.391666: step 13114, loss 0.595541.
Train: 2018-07-31T01:15:37.532235: step 13115, loss 0.488073.
Train: 2018-07-31T01:15:37.672851: step 13116, loss 0.570798.
Train: 2018-07-31T01:15:37.813418: step 13117, loss 0.50436.
Train: 2018-07-31T01:15:37.969631: step 13118, loss 0.529277.
Train: 2018-07-31T01:15:38.110223: step 13119, loss 0.520767.
Train: 2018-07-31T01:15:38.250815: step 13120, loss 0.545669.
Test: 2018-07-31T01:15:38.500787: step 13120, loss 0.548277.
Train: 2018-07-31T01:15:38.641374: step 13121, loss 0.520358.
Train: 2018-07-31T01:15:38.781942: step 13122, loss 0.672753.
Train: 2018-07-31T01:15:38.938156: step 13123, loss 0.545237.
Train: 2018-07-31T01:15:39.078747: step 13124, loss 0.56235.
Train: 2018-07-31T01:15:39.219364: step 13125, loss 0.604627.
Train: 2018-07-31T01:15:39.375587: step 13126, loss 0.579259.
Train: 2018-07-31T01:15:39.516169: step 13127, loss 0.528836.
Train: 2018-07-31T01:15:39.656761: step 13128, loss 0.6128.
Train: 2018-07-31T01:15:39.797353: step 13129, loss 0.621032.
Train: 2018-07-31T01:15:39.937920: step 13130, loss 0.554066.
Test: 2018-07-31T01:15:40.187864: step 13130, loss 0.548477.
Train: 2018-07-31T01:15:40.328479: step 13131, loss 0.5541.
Train: 2018-07-31T01:15:40.469071: step 13132, loss 0.545815.
Train: 2018-07-31T01:15:40.609663: step 13133, loss 0.612268.
Train: 2018-07-31T01:15:40.750231: step 13134, loss 0.562476.
Train: 2018-07-31T01:15:40.890849: step 13135, loss 0.612062.
Train: 2018-07-31T01:15:41.031439: step 13136, loss 0.570757.
Train: 2018-07-31T01:15:41.172032: step 13137, loss 0.54504.
Train: 2018-07-31T01:15:41.328221: step 13138, loss 0.513447.
Train: 2018-07-31T01:15:41.468813: step 13139, loss 0.578945.
Train: 2018-07-31T01:15:41.609405: step 13140, loss 0.497276.
Test: 2018-07-31T01:15:41.843752: step 13140, loss 0.548927.
Train: 2018-07-31T01:15:41.984316: step 13141, loss 0.578937.
Train: 2018-07-31T01:15:42.140554: step 13142, loss 0.570771.
Train: 2018-07-31T01:15:42.296744: step 13143, loss 0.611574.
Train: 2018-07-31T01:15:42.437335: step 13144, loss 0.546331.
Train: 2018-07-31T01:15:42.577945: step 13145, loss 0.611482.
Train: 2018-07-31T01:15:42.718568: step 13146, loss 0.611411.
Train: 2018-07-31T01:15:42.874734: step 13147, loss 0.587001.
Train: 2018-07-31T01:15:43.015326: step 13148, loss 0.62736.
Train: 2018-07-31T01:15:43.171540: step 13149, loss 0.586921.
Train: 2018-07-31T01:15:43.312156: step 13150, loss 0.498735.
Test: 2018-07-31T01:15:43.562073: step 13150, loss 0.549649.
Train: 2018-07-31T01:15:43.702692: step 13151, loss 0.474924.
Train: 2018-07-31T01:15:43.843256: step 13152, loss 0.61884.
Train: 2018-07-31T01:15:43.999470: step 13153, loss 0.498994.
Train: 2018-07-31T01:15:44.140063: step 13154, loss 0.538908.
Train: 2018-07-31T01:15:44.280655: step 13155, loss 0.602862.
Train: 2018-07-31T01:15:44.421246: step 13156, loss 0.626869.
Train: 2018-07-31T01:15:44.577458: step 13157, loss 0.578862.
Train: 2018-07-31T01:15:44.718077: step 13158, loss 0.562898.
Train: 2018-07-31T01:15:44.874265: step 13159, loss 0.57886.
Train: 2018-07-31T01:15:45.014881: step 13160, loss 0.562933.
Test: 2018-07-31T01:15:45.249180: step 13160, loss 0.549623.
Train: 2018-07-31T01:15:45.405415: step 13161, loss 0.547035.
Train: 2018-07-31T01:15:45.546006: step 13162, loss 0.602712.
Train: 2018-07-31T01:15:45.702220: step 13163, loss 0.61858.
Train: 2018-07-31T01:15:45.858408: step 13164, loss 0.57886.
Train: 2018-07-31T01:15:46.014623: step 13165, loss 0.578861.
Train: 2018-07-31T01:15:46.155239: step 13166, loss 0.507818.
Train: 2018-07-31T01:15:46.311443: step 13167, loss 0.578872.
Train: 2018-07-31T01:15:46.452039: step 13168, loss 0.594661.
Train: 2018-07-31T01:15:46.592637: step 13169, loss 0.578868.
Train: 2018-07-31T01:15:46.748826: step 13170, loss 0.586734.
Test: 2018-07-31T01:15:46.983148: step 13170, loss 0.549993.
Train: 2018-07-31T01:15:47.123762: step 13171, loss 0.516055.
Train: 2018-07-31T01:15:47.295598: step 13172, loss 0.547472.
Train: 2018-07-31T01:15:47.436182: step 13173, loss 0.571014.
Train: 2018-07-31T01:15:47.576756: step 13174, loss 0.539576.
Train: 2018-07-31T01:15:47.717349: step 13175, loss 0.500203.
Train: 2018-07-31T01:15:47.857967: step 13176, loss 0.555203.
Train: 2018-07-31T01:15:48.014178: step 13177, loss 0.547227.
Train: 2018-07-31T01:15:48.154771: step 13178, loss 0.570927.
Train: 2018-07-31T01:15:48.295339: step 13179, loss 0.539098.
Train: 2018-07-31T01:15:48.435931: step 13180, loss 0.546959.
Test: 2018-07-31T01:15:48.685872: step 13180, loss 0.549465.
Train: 2018-07-31T01:15:48.842110: step 13181, loss 0.522863.
Train: 2018-07-31T01:15:48.982702: step 13182, loss 0.53872.
Train: 2018-07-31T01:15:49.138891: step 13183, loss 0.595007.
Train: 2018-07-31T01:15:49.263879: step 13184, loss 0.562717.
Train: 2018-07-31T01:15:49.420076: step 13185, loss 0.497825.
Train: 2018-07-31T01:15:49.560691: step 13186, loss 0.611472.
Train: 2018-07-31T01:15:49.701260: step 13187, loss 0.58709.
Train: 2018-07-31T01:15:49.841853: step 13188, loss 0.546258.
Train: 2018-07-31T01:15:49.966847: step 13189, loss 0.595324.
Train: 2018-07-31T01:15:50.123060: step 13190, loss 0.562568.
Test: 2018-07-31T01:15:50.372978: step 13190, loss 0.54883.
Train: 2018-07-31T01:15:50.513568: step 13191, loss 0.554363.
Train: 2018-07-31T01:15:50.654160: step 13192, loss 0.50511.
Train: 2018-07-31T01:15:50.794773: step 13193, loss 0.529648.
Train: 2018-07-31T01:15:50.950967: step 13194, loss 0.504821.
Train: 2018-07-31T01:15:51.107181: step 13195, loss 0.512872.
Train: 2018-07-31T01:15:51.247797: step 13196, loss 0.620572.
Train: 2018-07-31T01:15:51.388364: step 13197, loss 0.57076.
Train: 2018-07-31T01:15:51.544579: step 13198, loss 0.54576.
Train: 2018-07-31T01:15:51.685195: step 13199, loss 0.562419.
Train: 2018-07-31T01:15:51.825762: step 13200, loss 0.570771.
Test: 2018-07-31T01:15:52.075735: step 13200, loss 0.548382.
Train: 2018-07-31T01:15:52.809931: step 13201, loss 0.579147.
Train: 2018-07-31T01:15:52.950497: step 13202, loss 0.545647.
Train: 2018-07-31T01:15:53.086504: step 13203, loss 0.554017.
Train: 2018-07-31T01:15:53.227095: step 13204, loss 0.629491.
Train: 2018-07-31T01:15:53.367688: step 13205, loss 0.520502.
Train: 2018-07-31T01:15:53.523876: step 13206, loss 0.604293.
Train: 2018-07-31T01:15:53.664469: step 13207, loss 0.554035.
Train: 2018-07-31T01:15:53.805061: step 13208, loss 0.554047.
Train: 2018-07-31T01:15:53.930055: step 13209, loss 0.503923.
Train: 2018-07-31T01:15:54.086244: step 13210, loss 0.579129.
Test: 2018-07-31T01:15:54.320596: step 13210, loss 0.548414.
Train: 2018-07-31T01:15:54.476779: step 13211, loss 0.512262.
Train: 2018-07-31T01:15:54.632992: step 13212, loss 0.595871.
Train: 2018-07-31T01:15:54.773607: step 13213, loss 0.587504.
Train: 2018-07-31T01:15:54.929821: step 13214, loss 0.545696.
Train: 2018-07-31T01:15:55.070390: step 13215, loss 0.587481.
Train: 2018-07-31T01:15:55.210981: step 13216, loss 0.579116.
Train: 2018-07-31T01:15:55.351598: step 13217, loss 0.587438.
Train: 2018-07-31T01:15:55.507787: step 13218, loss 0.595725.
Train: 2018-07-31T01:15:55.648379: step 13219, loss 0.529254.
Train: 2018-07-31T01:15:55.788970: step 13220, loss 0.529319.
Test: 2018-07-31T01:15:56.038942: step 13220, loss 0.548607.
Train: 2018-07-31T01:15:56.195125: step 13221, loss 0.570757.
Train: 2018-07-31T01:15:56.335742: step 13222, loss 0.587302.
Train: 2018-07-31T01:15:56.476334: step 13223, loss 0.455104.
Train: 2018-07-31T01:15:56.632553: step 13224, loss 0.545952.
Train: 2018-07-31T01:15:56.757495: step 13225, loss 0.545925.
Train: 2018-07-31T01:15:56.898086: step 13226, loss 0.5376.
Train: 2018-07-31T01:15:57.038677: step 13227, loss 0.520907.
Train: 2018-07-31T01:15:57.179270: step 13228, loss 0.637439.
Train: 2018-07-31T01:15:57.319886: step 13229, loss 0.545758.
Train: 2018-07-31T01:15:57.491697: step 13230, loss 0.612472.
Test: 2018-07-31T01:15:57.726018: step 13230, loss 0.548487.
Train: 2018-07-31T01:15:57.866609: step 13231, loss 0.520757.
Train: 2018-07-31T01:15:58.022822: step 13232, loss 0.545719.
Train: 2018-07-31T01:15:58.163438: step 13233, loss 0.562428.
Train: 2018-07-31T01:15:58.304031: step 13234, loss 0.545951.
Train: 2018-07-31T01:15:58.460220: step 13235, loss 0.554233.
Train: 2018-07-31T01:15:58.600813: step 13236, loss 0.529038.
Train: 2018-07-31T01:15:58.741404: step 13237, loss 0.595783.
Train: 2018-07-31T01:15:58.897619: step 13238, loss 0.545748.
Train: 2018-07-31T01:15:59.038234: step 13239, loss 0.545734.
Train: 2018-07-31T01:15:59.178826: step 13240, loss 0.612511.
Test: 2018-07-31T01:15:59.413123: step 13240, loss 0.548463.
Train: 2018-07-31T01:15:59.569335: step 13241, loss 0.57911.
Train: 2018-07-31T01:15:59.725561: step 13242, loss 0.545761.
Train: 2018-07-31T01:15:59.866165: step 13243, loss 0.579092.
Train: 2018-07-31T01:16:00.022379: step 13244, loss 0.570762.
Train: 2018-07-31T01:16:00.162971: step 13245, loss 0.554141.
Train: 2018-07-31T01:16:00.303538: step 13246, loss 0.587361.
Train: 2018-07-31T01:16:00.444155: step 13247, loss 0.521027.
Train: 2018-07-31T01:16:00.584747: step 13248, loss 0.603891.
Train: 2018-07-31T01:16:00.740959: step 13249, loss 0.562485.
Train: 2018-07-31T01:16:00.881552: step 13250, loss 0.562496.
Test: 2018-07-31T01:16:01.131494: step 13250, loss 0.548692.
Train: 2018-07-31T01:16:01.272078: step 13251, loss 0.628499.
Train: 2018-07-31T01:16:01.412679: step 13252, loss 0.59544.
Train: 2018-07-31T01:16:01.568892: step 13253, loss 0.578963.
Train: 2018-07-31T01:16:01.725104: step 13254, loss 0.513538.
Train: 2018-07-31T01:16:01.865672: step 13255, loss 0.521808.
Train: 2018-07-31T01:16:02.006289: step 13256, loss 0.570774.
Train: 2018-07-31T01:16:02.146858: step 13257, loss 0.635954.
Train: 2018-07-31T01:16:02.287449: step 13258, loss 0.50576.
Train: 2018-07-31T01:16:02.428066: step 13259, loss 0.587029.
Train: 2018-07-31T01:16:02.568658: step 13260, loss 0.554572.
Test: 2018-07-31T01:16:02.818603: step 13260, loss 0.549122.
Train: 2018-07-31T01:16:02.959166: step 13261, loss 0.611315.
Train: 2018-07-31T01:16:03.099758: step 13262, loss 0.570801.
Train: 2018-07-31T01:16:03.240375: step 13263, loss 0.635386.
Train: 2018-07-31T01:16:03.396595: step 13264, loss 0.490372.
Train: 2018-07-31T01:16:03.537156: step 13265, loss 0.570836.
Train: 2018-07-31T01:16:03.693370: step 13266, loss 0.55479.
Train: 2018-07-31T01:16:03.849584: step 13267, loss 0.522735.
Train: 2018-07-31T01:16:03.990174: step 13268, loss 0.586885.
Train: 2018-07-31T01:16:04.130767: step 13269, loss 0.56283.
Train: 2018-07-31T01:16:04.286981: step 13270, loss 0.522745.
Test: 2018-07-31T01:16:04.521332: step 13270, loss 0.549326.
Train: 2018-07-31T01:16:04.677514: step 13271, loss 0.618988.
Train: 2018-07-31T01:16:04.818130: step 13272, loss 0.53073.
Train: 2018-07-31T01:16:04.958698: step 13273, loss 0.514663.
Train: 2018-07-31T01:16:05.114911: step 13274, loss 0.619052.
Train: 2018-07-31T01:16:05.255503: step 13275, loss 0.522554.
Train: 2018-07-31T01:16:05.396120: step 13276, loss 0.611071.
Train: 2018-07-31T01:16:05.536689: step 13277, loss 0.586986.
Train: 2018-07-31T01:16:05.677327: step 13278, loss 0.54663.
Train: 2018-07-31T01:16:05.817871: step 13279, loss 0.562781.
Train: 2018-07-31T01:16:05.958489: step 13280, loss 0.57089.
Test: 2018-07-31T01:16:06.208407: step 13280, loss 0.549266.
Train: 2018-07-31T01:16:06.348996: step 13281, loss 0.570693.
Train: 2018-07-31T01:16:06.489590: step 13282, loss 0.578922.
Train: 2018-07-31T01:16:06.645804: step 13283, loss 0.506399.
Train: 2018-07-31T01:16:06.786396: step 13284, loss 0.530441.
Train: 2018-07-31T01:16:06.926988: step 13285, loss 0.570784.
Train: 2018-07-31T01:16:07.067580: step 13286, loss 0.538482.
Train: 2018-07-31T01:16:07.208172: step 13287, loss 0.497588.
Train: 2018-07-31T01:16:07.333143: step 13288, loss 0.614532.
Train: 2018-07-31T01:16:07.505001: step 13289, loss 0.570579.
Train: 2018-07-31T01:16:07.645584: step 13290, loss 0.570949.
Test: 2018-07-31T01:16:07.879890: step 13290, loss 0.548459.
Train: 2018-07-31T01:16:08.036102: step 13291, loss 0.670637.
Train: 2018-07-31T01:16:08.176695: step 13292, loss 0.561724.
Train: 2018-07-31T01:16:08.317311: step 13293, loss 0.53814.
Train: 2018-07-31T01:16:08.457903: step 13294, loss 0.578883.
Train: 2018-07-31T01:16:08.614092: step 13295, loss 0.504919.
Train: 2018-07-31T01:16:08.754684: step 13296, loss 0.58736.
Train: 2018-07-31T01:16:08.895300: step 13297, loss 0.554009.
Train: 2018-07-31T01:16:09.051489: step 13298, loss 0.627589.
Train: 2018-07-31T01:16:09.192082: step 13299, loss 0.587028.
Train: 2018-07-31T01:16:09.332674: step 13300, loss 0.497229.
Test: 2018-07-31T01:16:09.567026: step 13300, loss 0.548969.
Train: 2018-07-31T01:16:10.332440: step 13301, loss 0.513856.
Train: 2018-07-31T01:16:10.488653: step 13302, loss 0.659333.
Train: 2018-07-31T01:16:10.629269: step 13303, loss 0.601992.
Train: 2018-07-31T01:16:10.769862: step 13304, loss 0.545127.
Train: 2018-07-31T01:16:10.926051: step 13305, loss 0.479174.
Train: 2018-07-31T01:16:11.066643: step 13306, loss 0.469813.
Train: 2018-07-31T01:16:11.207271: step 13307, loss 0.596346.
Train: 2018-07-31T01:16:11.347851: step 13308, loss 0.606009.
Train: 2018-07-31T01:16:11.488443: step 13309, loss 0.491746.
Train: 2018-07-31T01:16:11.629036: step 13310, loss 0.582242.
Test: 2018-07-31T01:16:11.878952: step 13310, loss 0.547567.
Train: 2018-07-31T01:16:12.019564: step 13311, loss 0.571571.
Train: 2018-07-31T01:16:12.160137: step 13312, loss 0.493789.
Train: 2018-07-31T01:16:12.300753: step 13313, loss 0.590485.
Train: 2018-07-31T01:16:12.456967: step 13314, loss 0.496228.
Train: 2018-07-31T01:16:12.613156: step 13315, loss 0.53716.
Train: 2018-07-31T01:16:12.753773: step 13316, loss 0.542452.
Train: 2018-07-31T01:16:12.894364: step 13317, loss 0.551381.
Train: 2018-07-31T01:16:13.034956: step 13318, loss 0.589617.
Train: 2018-07-31T01:16:13.175524: step 13319, loss 0.539651.
Train: 2018-07-31T01:16:13.316115: step 13320, loss 0.575435.
Test: 2018-07-31T01:16:13.566058: step 13320, loss 0.548289.
Train: 2018-07-31T01:16:13.706674: step 13321, loss 0.537919.
Train: 2018-07-31T01:16:13.847241: step 13322, loss 0.596173.
Train: 2018-07-31T01:16:13.987835: step 13323, loss 0.570617.
Train: 2018-07-31T01:16:14.144047: step 13324, loss 0.580162.
Train: 2018-07-31T01:16:14.284639: step 13325, loss 0.570819.
Train: 2018-07-31T01:16:14.425255: step 13326, loss 0.538287.
Train: 2018-07-31T01:16:14.565840: step 13327, loss 0.530165.
Train: 2018-07-31T01:16:14.722062: step 13328, loss 0.595073.
Train: 2018-07-31T01:16:14.878251: step 13329, loss 0.562721.
Train: 2018-07-31T01:16:15.018842: step 13330, loss 0.578888.
Test: 2018-07-31T01:16:15.268808: step 13330, loss 0.549259.
Train: 2018-07-31T01:16:15.409401: step 13331, loss 0.538538.
Train: 2018-07-31T01:16:15.549967: step 13332, loss 0.595023.
Train: 2018-07-31T01:16:15.690559: step 13333, loss 0.514357.
Train: 2018-07-31T01:16:15.831151: step 13334, loss 0.498178.
Train: 2018-07-31T01:16:15.987390: step 13335, loss 0.562717.
Train: 2018-07-31T01:16:16.143603: step 13336, loss 0.554592.
Train: 2018-07-31T01:16:16.284188: step 13337, loss 0.546438.
Train: 2018-07-31T01:16:16.424788: step 13338, loss 0.546381.
Train: 2018-07-31T01:16:16.565379: step 13339, loss 0.513714.
Train: 2018-07-31T01:16:16.705946: step 13340, loss 0.595296.
Test: 2018-07-31T01:16:16.955889: step 13340, loss 0.54929.
Train: 2018-07-31T01:16:17.096505: step 13341, loss 0.603535.
Train: 2018-07-31T01:16:17.252719: step 13342, loss 0.52156.
Train: 2018-07-31T01:16:17.393285: step 13343, loss 0.554332.
Train: 2018-07-31T01:16:17.533903: step 13344, loss 0.562531.
Train: 2018-07-31T01:16:17.674470: step 13345, loss 0.529561.
Train: 2018-07-31T01:16:17.830708: step 13346, loss 0.545991.
Train: 2018-07-31T01:16:17.971301: step 13347, loss 0.562485.
Train: 2018-07-31T01:16:18.127489: step 13348, loss 0.529326.
Train: 2018-07-31T01:16:18.283710: step 13349, loss 0.545846.
Train: 2018-07-31T01:16:18.439917: step 13350, loss 0.620699.
Test: 2018-07-31T01:16:18.674238: step 13350, loss 0.548486.
Train: 2018-07-31T01:16:18.814828: step 13351, loss 0.587421.
Train: 2018-07-31T01:16:18.971066: step 13352, loss 0.604078.
Train: 2018-07-31T01:16:19.111635: step 13353, loss 0.620687.
Train: 2018-07-31T01:16:19.252225: step 13354, loss 0.612274.
Train: 2018-07-31T01:16:19.392817: step 13355, loss 0.562479.
Train: 2018-07-31T01:16:19.549055: step 13356, loss 0.53774.
Train: 2018-07-31T01:16:19.689625: step 13357, loss 0.578994.
Train: 2018-07-31T01:16:19.830241: step 13358, loss 0.570759.
Train: 2018-07-31T01:16:20.002051: step 13359, loss 0.505167.
Train: 2018-07-31T01:16:20.142641: step 13360, loss 0.611725.
Test: 2018-07-31T01:16:20.392585: step 13360, loss 0.548969.
Train: 2018-07-31T01:16:20.533200: step 13361, loss 0.628008.
Train: 2018-07-31T01:16:20.689390: step 13362, loss 0.530014.
Train: 2018-07-31T01:16:20.814386: step 13363, loss 0.578916.
Train: 2018-07-31T01:16:20.970598: step 13364, loss 0.595141.
Train: 2018-07-31T01:16:21.111164: step 13365, loss 0.595086.
Train: 2018-07-31T01:16:21.267404: step 13366, loss 0.586954.
Train: 2018-07-31T01:16:21.407996: step 13367, loss 0.562786.
Train: 2018-07-31T01:16:21.564184: step 13368, loss 0.570847.
Train: 2018-07-31T01:16:21.720422: step 13369, loss 0.554865.
Train: 2018-07-31T01:16:21.861045: step 13370, loss 0.610789.
Test: 2018-07-31T01:16:22.095342: step 13370, loss 0.55023.
Train: 2018-07-31T01:16:22.251525: step 13371, loss 0.547024.
Train: 2018-07-31T01:16:22.376519: step 13372, loss 0.562976.
Train: 2018-07-31T01:16:22.532708: step 13373, loss 0.610566.
Train: 2018-07-31T01:16:22.673301: step 13374, loss 0.578861.
Train: 2018-07-31T01:16:22.813917: step 13375, loss 0.523663.
Train: 2018-07-31T01:16:22.970104: step 13376, loss 0.531609.
Train: 2018-07-31T01:16:23.110698: step 13377, loss 0.500122.
Train: 2018-07-31T01:16:23.251315: step 13378, loss 0.610407.
Train: 2018-07-31T01:16:23.391906: step 13379, loss 0.610418.
Train: 2018-07-31T01:16:23.548120: step 13380, loss 0.547329.
Test: 2018-07-31T01:16:23.782414: step 13380, loss 0.549947.
Train: 2018-07-31T01:16:23.938630: step 13381, loss 0.555214.
Train: 2018-07-31T01:16:24.079222: step 13382, loss 0.570978.
Train: 2018-07-31T01:16:24.219814: step 13383, loss 0.578864.
Train: 2018-07-31T01:16:24.360430: step 13384, loss 0.610419.
Train: 2018-07-31T01:16:24.501022: step 13385, loss 0.626156.
Train: 2018-07-31T01:16:24.641613: step 13386, loss 0.49235.
Train: 2018-07-31T01:16:24.782181: step 13387, loss 0.523815.
Train: 2018-07-31T01:16:24.938394: step 13388, loss 0.594612.
Train: 2018-07-31T01:16:25.079011: step 13389, loss 0.500108.
Train: 2018-07-31T01:16:25.235201: step 13390, loss 0.539407.
Test: 2018-07-31T01:16:25.469521: step 13390, loss 0.549791.
Train: 2018-07-31T01:16:25.625734: step 13391, loss 0.594681.
Train: 2018-07-31T01:16:25.781946: step 13392, loss 0.618476.
Train: 2018-07-31T01:16:25.922540: step 13393, loss 0.642268.
Train: 2018-07-31T01:16:26.063155: step 13394, loss 0.547198.
Train: 2018-07-31T01:16:26.203724: step 13395, loss 0.539312.
Train: 2018-07-31T01:16:26.344316: step 13396, loss 0.499761.
Train: 2018-07-31T01:16:26.484908: step 13397, loss 0.563014.
Train: 2018-07-31T01:16:26.625526: step 13398, loss 0.539181.
Train: 2018-07-31T01:16:26.766091: step 13399, loss 0.555002.
Train: 2018-07-31T01:16:26.906683: step 13400, loss 0.610738.
Test: 2018-07-31T01:16:27.156658: step 13400, loss 0.549547.
Train: 2018-07-31T01:16:27.906448: step 13401, loss 0.586838.
Train: 2018-07-31T01:16:28.047066: step 13402, loss 0.578861.
Train: 2018-07-31T01:16:28.203275: step 13403, loss 0.546929.
Train: 2018-07-31T01:16:28.343872: step 13404, loss 0.642764.
Train: 2018-07-31T01:16:28.484439: step 13405, loss 0.610775.
Train: 2018-07-31T01:16:28.625031: step 13406, loss 0.507194.
Train: 2018-07-31T01:16:28.781275: step 13407, loss 0.523143.
Train: 2018-07-31T01:16:28.937458: step 13408, loss 0.56293.
Train: 2018-07-31T01:16:29.078050: step 13409, loss 0.57089.
Train: 2018-07-31T01:16:29.218667: step 13410, loss 0.531015.
Test: 2018-07-31T01:16:29.452963: step 13410, loss 0.549519.
Train: 2018-07-31T01:16:29.609199: step 13411, loss 0.522969.
Train: 2018-07-31T01:16:29.765389: step 13412, loss 0.586866.
Train: 2018-07-31T01:16:29.906006: step 13413, loss 0.522768.
Train: 2018-07-31T01:16:30.046572: step 13414, loss 0.602969.
Train: 2018-07-31T01:16:30.187182: step 13415, loss 0.482359.
Train: 2018-07-31T01:16:30.327783: step 13416, loss 0.570815.
Train: 2018-07-31T01:16:30.468348: step 13417, loss 0.506103.
Train: 2018-07-31T01:16:30.608942: step 13418, loss 0.562673.
Train: 2018-07-31T01:16:30.749559: step 13419, loss 0.497496.
Train: 2018-07-31T01:16:30.890143: step 13420, loss 0.570767.
Test: 2018-07-31T01:16:31.140067: step 13420, loss 0.548808.
Train: 2018-07-31T01:16:31.296280: step 13421, loss 0.546138.
Train: 2018-07-31T01:16:31.436874: step 13422, loss 0.546046.
Train: 2018-07-31T01:16:31.577465: step 13423, loss 0.628619.
Train: 2018-07-31T01:16:31.718056: step 13424, loss 0.570757.
Train: 2018-07-31T01:16:31.858648: step 13425, loss 0.603922.
Train: 2018-07-31T01:16:31.999268: step 13426, loss 0.545879.
Train: 2018-07-31T01:16:32.139874: step 13427, loss 0.579055.
Train: 2018-07-31T01:16:32.296046: step 13428, loss 0.554165.
Train: 2018-07-31T01:16:32.436638: step 13429, loss 0.570759.
Train: 2018-07-31T01:16:32.608473: step 13430, loss 0.645424.
Test: 2018-07-31T01:16:32.842793: step 13430, loss 0.54861.
Train: 2018-07-31T01:16:32.983385: step 13431, loss 0.545917.
Train: 2018-07-31T01:16:33.155222: step 13432, loss 0.570756.
Train: 2018-07-31T01:16:33.295837: step 13433, loss 0.59552.
Train: 2018-07-31T01:16:33.436429: step 13434, loss 0.455446.
Train: 2018-07-31T01:16:33.592618: step 13435, loss 0.488372.
Train: 2018-07-31T01:16:33.748830: step 13436, loss 0.537745.
Train: 2018-07-31T01:16:33.889423: step 13437, loss 0.570756.
Train: 2018-07-31T01:16:34.030015: step 13438, loss 0.504499.
Train: 2018-07-31T01:16:34.170607: step 13439, loss 0.562456.
Train: 2018-07-31T01:16:34.311224: step 13440, loss 0.562441.
Test: 2018-07-31T01:16:34.561172: step 13440, loss 0.548465.
Train: 2018-07-31T01:16:34.701734: step 13441, loss 0.595777.
Train: 2018-07-31T01:16:34.842349: step 13442, loss 0.604146.
Train: 2018-07-31T01:16:34.982942: step 13443, loss 0.645858.
Train: 2018-07-31T01:16:35.139156: step 13444, loss 0.57909.
Train: 2018-07-31T01:16:35.295345: step 13445, loss 0.603995.
Train: 2018-07-31T01:16:35.435960: step 13446, loss 0.61218.
Train: 2018-07-31T01:16:35.576527: step 13447, loss 0.570756.
Train: 2018-07-31T01:16:35.732741: step 13448, loss 0.537864.
Train: 2018-07-31T01:16:35.888955: step 13449, loss 0.55436.
Train: 2018-07-31T01:16:36.013950: step 13450, loss 0.570766.
Test: 2018-07-31T01:16:36.263867: step 13450, loss 0.548938.
Train: 2018-07-31T01:16:36.404483: step 13451, loss 0.595258.
Train: 2018-07-31T01:16:36.545076: step 13452, loss 0.56264.
Train: 2018-07-31T01:16:36.716885: step 13453, loss 0.530193.
Train: 2018-07-31T01:16:36.857478: step 13454, loss 0.595112.
Train: 2018-07-31T01:16:36.982449: step 13455, loss 0.530355.
Train: 2018-07-31T01:16:37.138662: step 13456, loss 0.595048.
Train: 2018-07-31T01:16:37.294900: step 13457, loss 0.538549.
Train: 2018-07-31T01:16:37.451114: step 13458, loss 0.538584.
Train: 2018-07-31T01:16:37.607327: step 13459, loss 0.60305.
Train: 2018-07-31T01:16:37.747920: step 13460, loss 0.538633.
Test: 2018-07-31T01:16:37.982214: step 13460, loss 0.549309.
Train: 2018-07-31T01:16:38.138429: step 13461, loss 0.578875.
Train: 2018-07-31T01:16:38.279020: step 13462, loss 0.562792.
Train: 2018-07-31T01:16:38.419613: step 13463, loss 0.570835.
Train: 2018-07-31T01:16:38.575827: step 13464, loss 0.619033.
Train: 2018-07-31T01:16:38.716442: step 13465, loss 0.538772.
Train: 2018-07-31T01:16:38.857053: step 13466, loss 0.586878.
Train: 2018-07-31T01:16:38.997602: step 13467, loss 0.490843.
Train: 2018-07-31T01:16:39.138194: step 13468, loss 0.538832.
Train: 2018-07-31T01:16:39.278785: step 13469, loss 0.602913.
Train: 2018-07-31T01:16:39.419378: step 13470, loss 0.562832.
Test: 2018-07-31T01:16:39.669321: step 13470, loss 0.549398.
Train: 2018-07-31T01:16:39.809936: step 13471, loss 0.562828.
Train: 2018-07-31T01:16:39.950529: step 13472, loss 0.506669.
Train: 2018-07-31T01:16:40.091120: step 13473, loss 0.546731.
Train: 2018-07-31T01:16:40.247311: step 13474, loss 0.554726.
Train: 2018-07-31T01:16:40.387902: step 13475, loss 0.586948.
Train: 2018-07-31T01:16:40.528518: step 13476, loss 0.562734.
Train: 2018-07-31T01:16:40.669087: step 13477, loss 0.554634.
Train: 2018-07-31T01:16:40.809703: step 13478, loss 0.578895.
Train: 2018-07-31T01:16:40.950271: step 13479, loss 0.562693.
Train: 2018-07-31T01:16:41.106482: step 13480, loss 0.603227.
Test: 2018-07-31T01:16:41.340835: step 13480, loss 0.549108.
Train: 2018-07-31T01:16:41.497016: step 13481, loss 0.570793.
Train: 2018-07-31T01:16:41.637609: step 13482, loss 0.56269.
Train: 2018-07-31T01:16:41.778201: step 13483, loss 0.505972.
Train: 2018-07-31T01:16:41.918792: step 13484, loss 0.546457.
Train: 2018-07-31T01:16:42.059385: step 13485, loss 0.51393.
Train: 2018-07-31T01:16:42.199977: step 13486, loss 0.562638.
Train: 2018-07-31T01:16:42.340569: step 13487, loss 0.652347.
Train: 2018-07-31T01:16:42.481165: step 13488, loss 0.562617.
Train: 2018-07-31T01:16:42.621752: step 13489, loss 0.464747.
Train: 2018-07-31T01:16:42.762370: step 13490, loss 0.587113.
Test: 2018-07-31T01:16:43.012288: step 13490, loss 0.548879.
Train: 2018-07-31T01:16:43.152896: step 13491, loss 0.538034.
Train: 2018-07-31T01:16:43.293471: step 13492, loss 0.513388.
Train: 2018-07-31T01:16:43.434064: step 13493, loss 0.537891.
Train: 2018-07-31T01:16:43.590277: step 13494, loss 0.595476.
Train: 2018-07-31T01:16:43.746491: step 13495, loss 0.537741.
Train: 2018-07-31T01:16:43.902727: step 13496, loss 0.570756.
Train: 2018-07-31T01:16:44.043295: step 13497, loss 0.529341.
Train: 2018-07-31T01:16:44.183887: step 13498, loss 0.520959.
Train: 2018-07-31T01:16:44.340101: step 13499, loss 0.604048.
Train: 2018-07-31T01:16:44.496315: step 13500, loss 0.595763.
Test: 2018-07-31T01:16:44.730665: step 13500, loss 0.548466.
Train: 2018-07-31T01:16:45.433595: step 13501, loss 0.570765.
Train: 2018-07-31T01:16:45.574211: step 13502, loss 0.537414.
Train: 2018-07-31T01:16:45.730401: step 13503, loss 0.562424.
Train: 2018-07-31T01:16:45.886615: step 13504, loss 0.537386.
Train: 2018-07-31T01:16:46.027257: step 13505, loss 0.520661.
Train: 2018-07-31T01:16:46.167822: step 13506, loss 0.545683.
Train: 2018-07-31T01:16:46.308414: step 13507, loss 0.579152.
Train: 2018-07-31T01:16:46.464628: step 13508, loss 0.537248.
Train: 2018-07-31T01:16:46.605196: step 13509, loss 0.629533.
Train: 2018-07-31T01:16:46.745811: step 13510, loss 0.50367.
Test: 2018-07-31T01:16:46.980108: step 13510, loss 0.54833.
Train: 2018-07-31T01:16:47.120700: step 13511, loss 0.612757.
Train: 2018-07-31T01:16:47.276938: step 13512, loss 0.537223.
Train: 2018-07-31T01:16:47.433151: step 13513, loss 0.503673.
Train: 2018-07-31T01:16:47.589375: step 13514, loss 0.553992.
Train: 2018-07-31T01:16:47.729956: step 13515, loss 0.545576.
Train: 2018-07-31T01:16:47.886171: step 13516, loss 0.520318.
Train: 2018-07-31T01:16:48.026762: step 13517, loss 0.553947.
Train: 2018-07-31T01:16:48.167330: step 13518, loss 0.545491.
Train: 2018-07-31T01:16:48.323544: step 13519, loss 0.638418.
Train: 2018-07-31T01:16:48.464135: step 13520, loss 0.511677.
Test: 2018-07-31T01:16:48.698455: step 13520, loss 0.548206.
Train: 2018-07-31T01:16:48.854670: step 13521, loss 0.553909.
Train: 2018-07-31T01:16:48.995262: step 13522, loss 0.486252.
Train: 2018-07-31T01:16:49.135878: step 13523, loss 0.519996.
Train: 2018-07-31T01:16:49.292067: step 13524, loss 0.502912.
Train: 2018-07-31T01:16:49.432659: step 13525, loss 0.562342.
Train: 2018-07-31T01:16:49.573250: step 13526, loss 0.50257.
Train: 2018-07-31T01:16:49.729464: step 13527, loss 0.562335.
Train: 2018-07-31T01:16:49.885687: step 13528, loss 0.536568.
Train: 2018-07-31T01:16:50.041892: step 13529, loss 0.614007.
Train: 2018-07-31T01:16:50.182483: step 13530, loss 0.674419.
Test: 2018-07-31T01:16:50.416805: step 13530, loss 0.547917.
Train: 2018-07-31T01:16:50.573041: step 13531, loss 0.562336.
Train: 2018-07-31T01:16:50.713608: step 13532, loss 0.562335.
Train: 2018-07-31T01:16:50.854201: step 13533, loss 0.528002.
Train: 2018-07-31T01:16:51.010414: step 13534, loss 0.502313.
Train: 2018-07-31T01:16:51.166629: step 13535, loss 0.57091.
Train: 2018-07-31T01:16:51.307220: step 13536, loss 0.510905.
Train: 2018-07-31T01:16:51.447812: step 13537, loss 0.570911.
Train: 2018-07-31T01:16:51.588403: step 13538, loss 0.596637.
Train: 2018-07-31T01:16:51.728995: step 13539, loss 0.536632.
Train: 2018-07-31T01:16:51.853966: step 13540, loss 0.553772.
Test: 2018-07-31T01:16:52.103932: step 13540, loss 0.548002.
Train: 2018-07-31T01:16:52.244501: step 13541, loss 0.639364.
Train: 2018-07-31T01:16:52.385092: step 13542, loss 0.570878.
Train: 2018-07-31T01:16:52.541306: step 13543, loss 0.656055.
Train: 2018-07-31T01:16:52.681922: step 13544, loss 0.553866.
Train: 2018-07-31T01:16:52.822535: step 13545, loss 0.587716.
Train: 2018-07-31T01:16:52.963081: step 13546, loss 0.587628.
Train: 2018-07-31T01:16:53.103674: step 13547, loss 0.528878.
Train: 2018-07-31T01:16:53.244266: step 13548, loss 0.512307.
Train: 2018-07-31T01:16:53.384858: step 13549, loss 0.587432.
Train: 2018-07-31T01:16:53.525451: step 13550, loss 0.53751.
Test: 2018-07-31T01:16:53.775391: step 13550, loss 0.548566.
Train: 2018-07-31T01:16:53.915992: step 13551, loss 0.612243.
Train: 2018-07-31T01:16:54.056575: step 13552, loss 0.562483.
Train: 2018-07-31T01:16:54.212789: step 13553, loss 0.529496.
Train: 2018-07-31T01:16:54.369002: step 13554, loss 0.570757.
Train: 2018-07-31T01:16:54.493997: step 13555, loss 0.529642.
Train: 2018-07-31T01:16:54.650187: step 13556, loss 0.570759.
Train: 2018-07-31T01:16:54.790803: step 13557, loss 0.496898.
Train: 2018-07-31T01:16:54.931395: step 13558, loss 0.537919.
Train: 2018-07-31T01:16:55.071990: step 13559, loss 0.529672.
Train: 2018-07-31T01:16:55.212580: step 13560, loss 0.554299.
Test: 2018-07-31T01:16:55.462497: step 13560, loss 0.548714.
Train: 2018-07-31T01:16:55.603113: step 13561, loss 0.59548.
Train: 2018-07-31T01:16:55.743680: step 13562, loss 0.52953.
Train: 2018-07-31T01:16:55.884272: step 13563, loss 0.59552.
Train: 2018-07-31T01:16:56.040486: step 13564, loss 0.512959.
Train: 2018-07-31T01:16:56.181080: step 13565, loss 0.603823.
Train: 2018-07-31T01:16:56.321671: step 13566, loss 0.579024.
Train: 2018-07-31T01:16:56.462310: step 13567, loss 0.537693.
Train: 2018-07-31T01:16:56.618476: step 13568, loss 0.545953.
Train: 2018-07-31T01:16:56.759092: step 13569, loss 0.628657.
Train: 2018-07-31T01:16:56.899659: step 13570, loss 0.537704.
Test: 2018-07-31T01:16:57.149602: step 13570, loss 0.548664.
Train: 2018-07-31T01:16:57.290195: step 13571, loss 0.587274.
Train: 2018-07-31T01:16:57.430785: step 13572, loss 0.546003.
Train: 2018-07-31T01:16:57.571377: step 13573, loss 0.554265.
Train: 2018-07-31T01:16:57.727592: step 13574, loss 0.51306.
Train: 2018-07-31T01:16:57.868184: step 13575, loss 0.537764.
Train: 2018-07-31T01:16:58.008775: step 13576, loss 0.54599.
Train: 2018-07-31T01:16:58.149368: step 13577, loss 0.628628.
Train: 2018-07-31T01:16:58.289983: step 13578, loss 0.570754.
Train: 2018-07-31T01:16:58.430551: step 13579, loss 0.579014.
Train: 2018-07-31T01:16:58.571143: step 13580, loss 0.587256.
Test: 2018-07-31T01:16:58.821085: step 13580, loss 0.548721.
Train: 2018-07-31T01:16:58.961701: step 13581, loss 0.628426.
Train: 2018-07-31T01:16:59.117891: step 13582, loss 0.513247.
Train: 2018-07-31T01:16:59.258483: step 13583, loss 0.554353.
Train: 2018-07-31T01:16:59.399099: step 13584, loss 0.587153.
Train: 2018-07-31T01:16:59.539692: step 13585, loss 0.570766.
Train: 2018-07-31T01:16:59.680258: step 13586, loss 0.538096.
Train: 2018-07-31T01:16:59.852094: step 13587, loss 0.611576.
Train: 2018-07-31T01:16:59.992686: step 13588, loss 0.595213.
Train: 2018-07-31T01:17:00.133278: step 13589, loss 0.587036.
Train: 2018-07-31T01:17:00.273870: step 13590, loss 0.562692.
Test: 2018-07-31T01:17:00.508220: step 13590, loss 0.549183.
Train: 2018-07-31T01:17:00.664431: step 13591, loss 0.595057.
Train: 2018-07-31T01:17:00.820617: step 13592, loss 0.562758.
Train: 2018-07-31T01:17:00.961210: step 13593, loss 0.562792.
Train: 2018-07-31T01:17:01.101825: step 13594, loss 0.594914.
Train: 2018-07-31T01:17:01.242410: step 13595, loss 0.570862.
Train: 2018-07-31T01:17:01.383010: step 13596, loss 0.666665.
Train: 2018-07-31T01:17:01.539222: step 13597, loss 0.515285.
Train: 2018-07-31T01:17:01.679790: step 13598, loss 0.578859.
Train: 2018-07-31T01:17:01.820383: step 13599, loss 0.634179.
Train: 2018-07-31T01:17:01.960974: step 13600, loss 0.626094.
Test: 2018-07-31T01:17:02.210916: step 13600, loss 0.550096.
Train: 2018-07-31T01:17:02.945121: step 13601, loss 0.547548.
Train: 2018-07-31T01:17:03.085710: step 13602, loss 0.571088.
Train: 2018-07-31T01:17:03.210683: step 13603, loss 0.508923.
Train: 2018-07-31T01:17:03.366921: step 13604, loss 0.501278.
Train: 2018-07-31T01:17:03.507513: step 13605, loss 0.571144.
Train: 2018-07-31T01:17:03.648097: step 13606, loss 0.516763.
Train: 2018-07-31T01:17:03.788697: step 13607, loss 0.594463.
Train: 2018-07-31T01:17:03.944886: step 13608, loss 0.571109.
Train: 2018-07-31T01:17:04.085477: step 13609, loss 0.610076.
Train: 2018-07-31T01:17:04.226071: step 13610, loss 0.617869.
Test: 2018-07-31T01:17:04.460420: step 13610, loss 0.550286.
Train: 2018-07-31T01:17:04.616602: step 13611, loss 0.51661.
Train: 2018-07-31T01:17:04.772817: step 13612, loss 0.485434.
Train: 2018-07-31T01:17:04.913408: step 13613, loss 0.594503.
Train: 2018-07-31T01:17:05.054001: step 13614, loss 0.547606.
Train: 2018-07-31T01:17:05.210214: step 13615, loss 0.618052.
Train: 2018-07-31T01:17:05.350830: step 13616, loss 0.602397.
Train: 2018-07-31T01:17:05.491422: step 13617, loss 0.531837.
Train: 2018-07-31T01:17:05.631991: step 13618, loss 0.523948.
Train: 2018-07-31T01:17:05.772582: step 13619, loss 0.547425.
Train: 2018-07-31T01:17:05.913175: step 13620, loss 0.586744.
Test: 2018-07-31T01:17:06.147525: step 13620, loss 0.549864.
Train: 2018-07-31T01:17:06.288111: step 13621, loss 0.49995.
Train: 2018-07-31T01:17:06.444324: step 13622, loss 0.602606.
Train: 2018-07-31T01:17:06.584910: step 13623, loss 0.578859.
Train: 2018-07-31T01:17:06.725483: step 13624, loss 0.562971.
Train: 2018-07-31T01:17:06.866093: step 13625, loss 0.618637.
Train: 2018-07-31T01:17:07.006693: step 13626, loss 0.586816.
Train: 2018-07-31T01:17:07.162883: step 13627, loss 0.59477.
Train: 2018-07-31T01:17:07.303520: step 13628, loss 0.602707.
Train: 2018-07-31T01:17:07.459687: step 13629, loss 0.570921.
Train: 2018-07-31T01:17:07.600326: step 13630, loss 0.539227.
Test: 2018-07-31T01:17:07.834630: step 13630, loss 0.549748.
Train: 2018-07-31T01:17:07.990813: step 13631, loss 0.507563.
Train: 2018-07-31T01:17:08.131405: step 13632, loss 0.57093.
Train: 2018-07-31T01:17:08.272021: step 13633, loss 0.570924.
Train: 2018-07-31T01:17:08.428236: step 13634, loss 0.51534.
Train: 2018-07-31T01:17:08.584455: step 13635, loss 0.594766.
Train: 2018-07-31T01:17:08.725041: step 13636, loss 0.531088.
Train: 2018-07-31T01:17:08.865633: step 13637, loss 0.515055.
Train: 2018-07-31T01:17:09.006199: step 13638, loss 0.570865.
Train: 2018-07-31T01:17:09.146791: step 13639, loss 0.57085.
Train: 2018-07-31T01:17:09.303030: step 13640, loss 0.522641.
Test: 2018-07-31T01:17:09.552948: step 13640, loss 0.549277.
Train: 2018-07-31T01:17:09.709160: step 13641, loss 0.586933.
Train: 2018-07-31T01:17:09.927859: step 13642, loss 0.473954.
Train: 2018-07-31T01:17:10.068450: step 13643, loss 0.538386.
Train: 2018-07-31T01:17:10.224665: step 13644, loss 0.595185.
Train: 2018-07-31T01:17:10.365257: step 13645, loss 0.570773.
Train: 2018-07-31T01:17:10.521470: step 13646, loss 0.603478.
Train: 2018-07-31T01:17:10.662066: step 13647, loss 0.570764.
Train: 2018-07-31T01:17:10.833897: step 13648, loss 0.554371.
Train: 2018-07-31T01:17:10.974490: step 13649, loss 0.611782.
Train: 2018-07-31T01:17:11.115105: step 13650, loss 0.59537.
Test: 2018-07-31T01:17:11.365022: step 13650, loss 0.548842.
Train: 2018-07-31T01:17:11.505614: step 13651, loss 0.652718.
Train: 2018-07-31T01:17:11.646208: step 13652, loss 0.595288.
Train: 2018-07-31T01:17:11.786799: step 13653, loss 0.497453.
Train: 2018-07-31T01:17:11.927391: step 13654, loss 0.52197.
Train: 2018-07-31T01:17:12.067983: step 13655, loss 0.587046.
Train: 2018-07-31T01:17:12.224197: step 13656, loss 0.603283.
Train: 2018-07-31T01:17:12.349191: step 13657, loss 0.465353.
Train: 2018-07-31T01:17:12.505380: step 13658, loss 0.546442.
Train: 2018-07-31T01:17:12.645973: step 13659, loss 0.587033.
Train: 2018-07-31T01:17:12.802186: step 13660, loss 0.554532.
Test: 2018-07-31T01:17:13.036536: step 13660, loss 0.549035.
Train: 2018-07-31T01:17:13.177133: step 13661, loss 0.570783.
Train: 2018-07-31T01:17:13.317689: step 13662, loss 0.538252.
Train: 2018-07-31T01:17:13.473904: step 13663, loss 0.603335.
Train: 2018-07-31T01:17:13.614495: step 13664, loss 0.489404.
Train: 2018-07-31T01:17:13.755087: step 13665, loss 0.546327.
Train: 2018-07-31T01:17:13.911301: step 13666, loss 0.603423.
Train: 2018-07-31T01:17:14.051894: step 13667, loss 0.554434.
Train: 2018-07-31T01:17:14.192509: step 13668, loss 0.644332.
Train: 2018-07-31T01:17:14.348723: step 13669, loss 0.627923.
Train: 2018-07-31T01:17:14.473719: step 13670, loss 0.595212.
Test: 2018-07-31T01:17:14.723612: step 13670, loss 0.549063.
Train: 2018-07-31T01:17:14.864202: step 13671, loss 0.497692.
Train: 2018-07-31T01:17:15.004794: step 13672, loss 0.554567.
Train: 2018-07-31T01:17:15.145411: step 13673, loss 0.489742.
Train: 2018-07-31T01:17:15.301601: step 13674, loss 0.546455.
Train: 2018-07-31T01:17:15.442218: step 13675, loss 0.538301.
Train: 2018-07-31T01:17:15.582814: step 13676, loss 0.603317.
Train: 2018-07-31T01:17:15.739023: step 13677, loss 0.554503.
Train: 2018-07-31T01:17:15.895236: step 13678, loss 0.55449.
Train: 2018-07-31T01:17:16.051425: step 13679, loss 0.595226.
Train: 2018-07-31T01:17:16.192042: step 13680, loss 0.546324.
Test: 2018-07-31T01:17:16.426369: step 13680, loss 0.548965.
Train: 2018-07-31T01:17:16.582564: step 13681, loss 0.497394.
Train: 2018-07-31T01:17:16.723168: step 13682, loss 0.611607.
Train: 2018-07-31T01:17:16.879357: step 13683, loss 0.497226.
Train: 2018-07-31T01:17:17.019949: step 13684, loss 0.587138.
Train: 2018-07-31T01:17:17.160540: step 13685, loss 0.619935.
Train: 2018-07-31T01:17:17.301132: step 13686, loss 0.61173.
Train: 2018-07-31T01:17:17.441725: step 13687, loss 0.505303.
Train: 2018-07-31T01:17:17.582317: step 13688, loss 0.578949.
Train: 2018-07-31T01:17:17.722909: step 13689, loss 0.611668.
Train: 2018-07-31T01:17:17.879147: step 13690, loss 0.546261.
Test: 2018-07-31T01:17:18.113467: step 13690, loss 0.54894.
Train: 2018-07-31T01:17:18.269656: step 13691, loss 0.538123.
Train: 2018-07-31T01:17:18.410250: step 13692, loss 0.529973.
Train: 2018-07-31T01:17:18.550839: step 13693, loss 0.554444.
Train: 2018-07-31T01:17:18.707054: step 13694, loss 0.578938.
Train: 2018-07-31T01:17:18.847646: step 13695, loss 0.554431.
Train: 2018-07-31T01:17:18.988236: step 13696, loss 0.538081.
Train: 2018-07-31T01:17:19.144451: step 13697, loss 0.538054.
Train: 2018-07-31T01:17:19.285043: step 13698, loss 0.5462.
Train: 2018-07-31T01:17:19.441280: step 13699, loss 0.570762.
Train: 2018-07-31T01:17:19.581850: step 13700, loss 0.546134.
Test: 2018-07-31T01:17:19.816201: step 13700, loss 0.548767.
Train: 2018-07-31T01:17:20.550371: step 13701, loss 0.537881.
Train: 2018-07-31T01:17:20.690965: step 13702, loss 0.52136.
Train: 2018-07-31T01:17:20.831555: step 13703, loss 0.570756.
Train: 2018-07-31T01:17:20.987771: step 13704, loss 0.562489.
Train: 2018-07-31T01:17:21.128385: step 13705, loss 0.645277.
Train: 2018-07-31T01:17:21.268954: step 13706, loss 0.521095.
Train: 2018-07-31T01:17:21.409546: step 13707, loss 0.537634.
Train: 2018-07-31T01:17:21.550138: step 13708, loss 0.479592.
Train: 2018-07-31T01:17:21.690729: step 13709, loss 0.587375.
Train: 2018-07-31T01:17:21.831345: step 13710, loss 0.537479.
Test: 2018-07-31T01:17:22.065641: step 13710, loss 0.548468.
Train: 2018-07-31T01:17:22.221856: step 13711, loss 0.587437.
Train: 2018-07-31T01:17:22.346851: step 13712, loss 0.587456.
Train: 2018-07-31T01:17:22.487417: step 13713, loss 0.562421.
Train: 2018-07-31T01:17:22.643631: step 13714, loss 0.495633.
Train: 2018-07-31T01:17:22.784249: step 13715, loss 0.545691.
Train: 2018-07-31T01:17:22.940463: step 13716, loss 0.562403.
Train: 2018-07-31T01:17:23.081053: step 13717, loss 0.545631.
Train: 2018-07-31T01:17:23.237267: step 13718, loss 0.553997.
Train: 2018-07-31T01:17:23.393457: step 13719, loss 0.66323.
Train: 2018-07-31T01:17:23.534073: step 13720, loss 0.5456.
Test: 2018-07-31T01:17:23.768368: step 13720, loss 0.548346.
Train: 2018-07-31T01:17:23.924606: step 13721, loss 0.545617.
Train: 2018-07-31T01:17:24.065175: step 13722, loss 0.520477.
Train: 2018-07-31T01:17:24.205766: step 13723, loss 0.545622.
Train: 2018-07-31T01:17:24.346382: step 13724, loss 0.587562.
Train: 2018-07-31T01:17:24.486949: step 13725, loss 0.4869.
Train: 2018-07-31T01:17:24.643164: step 13726, loss 0.604378.
Train: 2018-07-31T01:17:24.783756: step 13727, loss 0.637977.
Train: 2018-07-31T01:17:24.924348: step 13728, loss 0.562395.
Train: 2018-07-31T01:17:25.064939: step 13729, loss 0.520541.
Train: 2018-07-31T01:17:25.221154: step 13730, loss 0.545674.
Test: 2018-07-31T01:17:25.455474: step 13730, loss 0.548403.
Train: 2018-07-31T01:17:25.596065: step 13731, loss 0.537319.
Train: 2018-07-31T01:17:25.752278: step 13732, loss 0.554045.
Train: 2018-07-31T01:17:25.892894: step 13733, loss 0.562408.
Train: 2018-07-31T01:17:26.033464: step 13734, loss 0.554044.
Train: 2018-07-31T01:17:26.174079: step 13735, loss 0.537315.
Train: 2018-07-31T01:17:26.330268: step 13736, loss 0.570774.
Train: 2018-07-31T01:17:26.455266: step 13737, loss 0.612617.
Train: 2018-07-31T01:17:26.611452: step 13738, loss 0.554052.
Train: 2018-07-31T01:17:26.767666: step 13739, loss 0.554065.
Train: 2018-07-31T01:17:26.908275: step 13740, loss 0.512349.
Test: 2018-07-31T01:17:27.142580: step 13740, loss 0.548439.
Train: 2018-07-31T01:17:27.345654: step 13741, loss 0.491189.
Train: 2018-07-31T01:17:27.486247: step 13742, loss 0.579132.
Train: 2018-07-31T01:17:27.642461: step 13743, loss 0.612616.
Train: 2018-07-31T01:17:27.783054: step 13744, loss 0.512212.
Train: 2018-07-31T01:17:27.923662: step 13745, loss 0.629374.
Train: 2018-07-31T01:17:28.064242: step 13746, loss 0.595863.
Train: 2018-07-31T01:17:28.204853: step 13747, loss 0.562419.
Train: 2018-07-31T01:17:28.361043: step 13748, loss 0.570765.
Train: 2018-07-31T01:17:28.501635: step 13749, loss 0.512504.
Train: 2018-07-31T01:17:28.642227: step 13750, loss 0.570761.
Test: 2018-07-31T01:17:28.876572: step 13750, loss 0.54853.
Train: 2018-07-31T01:17:29.032761: step 13751, loss 0.587382.
Train: 2018-07-31T01:17:29.173377: step 13752, loss 0.645459.
Train: 2018-07-31T01:17:29.329566: step 13753, loss 0.537656.
Train: 2018-07-31T01:17:29.470159: step 13754, loss 0.537731.
Train: 2018-07-31T01:17:29.610774: step 13755, loss 0.546026.
Train: 2018-07-31T01:17:29.766987: step 13756, loss 0.504885.
Train: 2018-07-31T01:17:29.907556: step 13757, loss 0.562522.
Train: 2018-07-31T01:17:30.048165: step 13758, loss 0.546049.
Train: 2018-07-31T01:17:30.188738: step 13759, loss 0.562518.
Train: 2018-07-31T01:17:30.329331: step 13760, loss 0.578998.
Test: 2018-07-31T01:17:30.579303: step 13760, loss 0.548713.
Train: 2018-07-31T01:17:30.719866: step 13761, loss 0.537794.
Train: 2018-07-31T01:17:30.860458: step 13762, loss 0.537782.
Train: 2018-07-31T01:17:31.001049: step 13763, loss 0.612006.
Train: 2018-07-31T01:17:31.141641: step 13764, loss 0.521276.
Train: 2018-07-31T01:17:31.282233: step 13765, loss 0.554254.
Train: 2018-07-31T01:17:31.422844: step 13766, loss 0.521221.
Train: 2018-07-31T01:17:31.563442: step 13767, loss 0.521154.
Train: 2018-07-31T01:17:31.704010: step 13768, loss 0.620487.
Train: 2018-07-31T01:17:31.844619: step 13769, loss 0.603913.
Train: 2018-07-31T01:17:31.985195: step 13770, loss 0.521064.
Test: 2018-07-31T01:17:32.235160: step 13770, loss 0.548592.
Train: 2018-07-31T01:17:32.375745: step 13771, loss 0.562473.
Train: 2018-07-31T01:17:32.531942: step 13772, loss 0.545899.
Train: 2018-07-31T01:17:32.672533: step 13773, loss 0.554177.
Train: 2018-07-31T01:17:32.828745: step 13774, loss 0.61223.
Train: 2018-07-31T01:17:32.984961: step 13775, loss 0.545891.
Train: 2018-07-31T01:17:33.125576: step 13776, loss 0.529326.
Train: 2018-07-31T01:17:33.266143: step 13777, loss 0.463.
Train: 2018-07-31T01:17:33.406761: step 13778, loss 0.479371.
Train: 2018-07-31T01:17:33.547352: step 13779, loss 0.579104.
Train: 2018-07-31T01:17:33.703542: step 13780, loss 0.537322.
Test: 2018-07-31T01:17:33.937861: step 13780, loss 0.548347.
Train: 2018-07-31T01:17:34.078453: step 13781, loss 0.51207.
Train: 2018-07-31T01:17:34.234667: step 13782, loss 0.528708.
Train: 2018-07-31T01:17:34.375260: step 13783, loss 0.537017.
Train: 2018-07-31T01:17:34.515852: step 13784, loss 0.519952.
Train: 2018-07-31T01:17:34.656467: step 13785, loss 0.51977.
Train: 2018-07-31T01:17:34.812656: step 13786, loss 0.536671.
Train: 2018-07-31T01:17:34.953274: step 13787, loss 0.51939.
Train: 2018-07-31T01:17:35.109487: step 13788, loss 0.562313.
Train: 2018-07-31T01:17:35.265676: step 13789, loss 0.579727.
Train: 2018-07-31T01:17:35.406292: step 13790, loss 0.570929.
Test: 2018-07-31T01:17:35.656242: step 13790, loss 0.547642.
Train: 2018-07-31T01:17:35.796826: step 13791, loss 0.545073.
Train: 2018-07-31T01:17:35.953014: step 13792, loss 0.544964.
Train: 2018-07-31T01:17:36.093632: step 13793, loss 0.527467.
Train: 2018-07-31T01:17:36.234198: step 13794, loss 0.597394.
Train: 2018-07-31T01:17:36.374816: step 13795, loss 0.59732.
Train: 2018-07-31T01:17:36.515407: step 13796, loss 0.536174.
Train: 2018-07-31T01:17:36.671595: step 13797, loss 0.553638.
Train: 2018-07-31T01:17:36.812214: step 13798, loss 0.527461.
Train: 2018-07-31T01:17:36.952779: step 13799, loss 0.588547.
Train: 2018-07-31T01:17:37.093372: step 13800, loss 0.579804.
Test: 2018-07-31T01:17:37.343344: step 13800, loss 0.547775.
Train: 2018-07-31T01:17:38.077546: step 13801, loss 0.536234.
Train: 2018-07-31T01:17:38.233755: step 13802, loss 0.518858.
Train: 2018-07-31T01:17:38.374323: step 13803, loss 0.536265.
Train: 2018-07-31T01:17:38.530536: step 13804, loss 0.597135.
Train: 2018-07-31T01:17:38.671129: step 13805, loss 0.579723.
Train: 2018-07-31T01:17:38.796124: step 13806, loss 0.545003.
Train: 2018-07-31T01:17:38.936691: step 13807, loss 0.501723.
Train: 2018-07-31T01:17:39.077283: step 13808, loss 0.527715.
Train: 2018-07-31T01:17:39.217902: step 13809, loss 0.588317.
Train: 2018-07-31T01:17:39.358491: step 13810, loss 0.562342.
Test: 2018-07-31T01:17:39.608409: step 13810, loss 0.547864.
Train: 2018-07-31T01:17:39.749018: step 13811, loss 0.562341.
Train: 2018-07-31T01:17:39.889617: step 13812, loss 0.596885.
Train: 2018-07-31T01:17:40.030210: step 13813, loss 0.579577.
Train: 2018-07-31T01:17:40.170776: step 13814, loss 0.510731.
Train: 2018-07-31T01:17:40.311394: step 13815, loss 0.519336.
Train: 2018-07-31T01:17:40.451960: step 13816, loss 0.613943.
Train: 2018-07-31T01:17:40.592553: step 13817, loss 0.605235.
Train: 2018-07-31T01:17:40.733145: step 13818, loss 0.639253.
Train: 2018-07-31T01:17:40.873738: step 13819, loss 0.562343.
Train: 2018-07-31T01:17:41.014330: step 13820, loss 0.613196.
Test: 2018-07-31T01:17:41.248675: step 13820, loss 0.54825.
Train: 2018-07-31T01:17:41.404864: step 13821, loss 0.520203.
Train: 2018-07-31T01:17:41.545480: step 13822, loss 0.562385.
Train: 2018-07-31T01:17:41.686047: step 13823, loss 0.595899.
Train: 2018-07-31T01:17:41.826663: step 13824, loss 0.545742.
Train: 2018-07-31T01:17:41.967237: step 13825, loss 0.645589.
Train: 2018-07-31T01:17:42.123470: step 13826, loss 0.570756.
Train: 2018-07-31T01:17:42.264061: step 13827, loss 0.529573.
Train: 2018-07-31T01:17:42.420274: step 13828, loss 0.521512.
Train: 2018-07-31T01:17:42.560867: step 13829, loss 0.546197.
Train: 2018-07-31T01:17:42.701460: step 13830, loss 0.570768.
Test: 2018-07-31T01:17:42.935757: step 13830, loss 0.548944.
Train: 2018-07-31T01:17:43.091968: step 13831, loss 0.619736.
Train: 2018-07-31T01:17:43.232559: step 13832, loss 0.60333.
Train: 2018-07-31T01:17:43.373153: step 13833, loss 0.489695.
Train: 2018-07-31T01:17:43.513743: step 13834, loss 0.5627.
Train: 2018-07-31T01:17:43.654335: step 13835, loss 0.514192.
Train: 2018-07-31T01:17:43.794928: step 13836, loss 0.562717.
Train: 2018-07-31T01:17:43.919923: step 13837, loss 0.55463.
Train: 2018-07-31T01:17:44.060496: step 13838, loss 0.578892.
Train: 2018-07-31T01:17:44.201108: step 13839, loss 0.554626.
Train: 2018-07-31T01:17:44.357298: step 13840, loss 0.538453.
Test: 2018-07-31T01:17:44.591648: step 13840, loss 0.549103.
Train: 2018-07-31T01:17:44.732209: step 13841, loss 0.619374.
Train: 2018-07-31T01:17:44.888446: step 13842, loss 0.554615.
Train: 2018-07-31T01:17:45.029014: step 13843, loss 0.538462.
Train: 2018-07-31T01:17:45.169606: step 13844, loss 0.578891.
Train: 2018-07-31T01:17:45.310198: step 13845, loss 0.578891.
Train: 2018-07-31T01:17:45.466412: step 13846, loss 0.54654.
Train: 2018-07-31T01:17:45.607029: step 13847, loss 0.603144.
Train: 2018-07-31T01:17:45.747595: step 13848, loss 0.603128.
Train: 2018-07-31T01:17:45.903810: step 13849, loss 0.546627.
Train: 2018-07-31T01:17:46.044426: step 13850, loss 0.522458.
Test: 2018-07-31T01:17:46.278752: step 13850, loss 0.549262.
Train: 2018-07-31T01:17:46.434936: step 13851, loss 0.570831.
Train: 2018-07-31T01:17:46.575527: step 13852, loss 0.570822.
Train: 2018-07-31T01:17:46.716143: step 13853, loss 0.570825.
Train: 2018-07-31T01:17:46.856736: step 13854, loss 0.562766.
Train: 2018-07-31T01:17:46.997304: step 13855, loss 0.562772.
Train: 2018-07-31T01:17:47.153517: step 13856, loss 0.570829.
Train: 2018-07-31T01:17:47.294132: step 13857, loss 0.594974.
Train: 2018-07-31T01:17:47.434700: step 13858, loss 0.530624.
Train: 2018-07-31T01:17:47.575318: step 13859, loss 0.546708.
Train: 2018-07-31T01:17:47.731530: step 13860, loss 0.578875.
Test: 2018-07-31T01:17:47.965857: step 13860, loss 0.549315.
Train: 2018-07-31T01:17:48.137661: step 13861, loss 0.594966.
Train: 2018-07-31T01:17:48.278278: step 13862, loss 0.611038.
Train: 2018-07-31T01:17:48.418850: step 13863, loss 0.538726.
Train: 2018-07-31T01:17:48.575060: step 13864, loss 0.562823.
Train: 2018-07-31T01:17:48.715675: step 13865, loss 0.570849.
Train: 2018-07-31T01:17:48.856268: step 13866, loss 0.554828.
Train: 2018-07-31T01:17:49.012475: step 13867, loss 0.482745.
Train: 2018-07-31T01:17:49.153049: step 13868, loss 0.562822.
Train: 2018-07-31T01:17:49.309276: step 13869, loss 0.538695.
Train: 2018-07-31T01:17:49.449855: step 13870, loss 0.498364.
Test: 2018-07-31T01:17:49.684174: step 13870, loss 0.549203.
Train: 2018-07-31T01:17:49.840388: step 13871, loss 0.586964.
Train: 2018-07-31T01:17:49.980981: step 13872, loss 0.627481.
Train: 2018-07-31T01:17:50.121596: step 13873, loss 0.611315.
Train: 2018-07-31T01:17:50.262189: step 13874, loss 0.530289.
Train: 2018-07-31T01:17:50.402780: step 13875, loss 0.684267.
Train: 2018-07-31T01:17:50.543373: step 13876, loss 0.554629.
Train: 2018-07-31T01:17:50.683941: step 13877, loss 0.538521.
Train: 2018-07-31T01:17:50.824556: step 13878, loss 0.506303.
Train: 2018-07-31T01:17:50.980746: step 13879, loss 0.635353.
Train: 2018-07-31T01:17:51.105716: step 13880, loss 0.578879.
Test: 2018-07-31T01:17:51.355658: step 13880, loss 0.549295.
Train: 2018-07-31T01:17:51.496275: step 13881, loss 0.54669.
Train: 2018-07-31T01:17:51.636841: step 13882, loss 0.602991.
Train: 2018-07-31T01:17:51.793080: step 13883, loss 0.562816.
Train: 2018-07-31T01:17:51.933672: step 13884, loss 0.626963.
Train: 2018-07-31T01:17:52.089861: step 13885, loss 0.602848.
Train: 2018-07-31T01:17:52.230453: step 13886, loss 0.539008.
Train: 2018-07-31T01:17:52.371062: step 13887, loss 0.562953.
Train: 2018-07-31T01:17:52.527260: step 13888, loss 0.547106.
Train: 2018-07-31T01:17:52.667849: step 13889, loss 0.594717.
Train: 2018-07-31T01:17:52.808442: step 13890, loss 0.53928.
Test: 2018-07-31T01:17:53.058383: step 13890, loss 0.549794.
Train: 2018-07-31T01:17:53.199000: step 13891, loss 0.570951.
Train: 2018-07-31T01:17:53.339568: step 13892, loss 0.596777.
Train: 2018-07-31T01:17:53.495782: step 13893, loss 0.570969.
Train: 2018-07-31T01:17:53.636373: step 13894, loss 0.523675.
Train: 2018-07-31T01:17:53.776965: step 13895, loss 0.57098.
Train: 2018-07-31T01:17:53.917582: step 13896, loss 0.57098.
Train: 2018-07-31T01:17:54.058149: step 13897, loss 0.515793.
Train: 2018-07-31T01:17:54.214387: step 13898, loss 0.610438.
Train: 2018-07-31T01:17:54.354956: step 13899, loss 0.539387.
Train: 2018-07-31T01:17:54.511169: step 13900, loss 0.61047.
Test: 2018-07-31T01:17:54.745515: step 13900, loss 0.549828.
Train: 2018-07-31T01:17:55.479692: step 13901, loss 0.56306.
Train: 2018-07-31T01:17:55.635905: step 13902, loss 0.515656.
Train: 2018-07-31T01:17:55.776522: step 13903, loss 0.586771.
Train: 2018-07-31T01:17:55.917107: step 13904, loss 0.547194.
Train: 2018-07-31T01:17:56.057706: step 13905, loss 0.563008.
Train: 2018-07-31T01:17:56.198273: step 13906, loss 0.578859.
Train: 2018-07-31T01:17:56.338890: step 13907, loss 0.578858.
Train: 2018-07-31T01:17:56.495103: step 13908, loss 0.570912.
Train: 2018-07-31T01:17:56.635695: step 13909, loss 0.547061.
Train: 2018-07-31T01:17:56.791884: step 13910, loss 0.499298.
Test: 2018-07-31T01:17:57.026205: step 13910, loss 0.549563.
Train: 2018-07-31T01:17:57.182442: step 13911, loss 0.634684.
Train: 2018-07-31T01:17:57.323011: step 13912, loss 0.530984.
Train: 2018-07-31T01:17:57.463629: step 13913, loss 0.562881.
Train: 2018-07-31T01:17:57.635472: step 13914, loss 0.594865.
Train: 2018-07-31T01:17:57.776046: step 13915, loss 0.538838.
Train: 2018-07-31T01:17:57.916638: step 13916, loss 0.506737.
Train: 2018-07-31T01:17:58.057213: step 13917, loss 0.562804.
Train: 2018-07-31T01:17:58.197805: step 13918, loss 0.603029.
Train: 2018-07-31T01:17:58.338422: step 13919, loss 0.530519.
Train: 2018-07-31T01:17:58.479008: step 13920, loss 0.570811.
Test: 2018-07-31T01:17:58.713311: step 13920, loss 0.549174.
Train: 2018-07-31T01:17:58.853902: step 13921, loss 0.578891.
Train: 2018-07-31T01:17:59.025769: step 13922, loss 0.595084.
Train: 2018-07-31T01:17:59.181949: step 13923, loss 0.578895.
Train: 2018-07-31T01:17:59.322566: step 13924, loss 0.58699.
Train: 2018-07-31T01:17:59.478780: step 13925, loss 0.595074.
Train: 2018-07-31T01:17:59.619373: step 13926, loss 0.651615.
Train: 2018-07-31T01:17:59.775561: step 13927, loss 0.530541.
Train: 2018-07-31T01:17:59.916177: step 13928, loss 0.602994.
Train: 2018-07-31T01:18:00.072368: step 13929, loss 0.610945.
Train: 2018-07-31T01:18:00.212957: step 13930, loss 0.498936.
Test: 2018-07-31T01:18:00.447281: step 13930, loss 0.549533.
Train: 2018-07-31T01:18:00.603517: step 13931, loss 0.522995.
Train: 2018-07-31T01:18:00.744110: step 13932, loss 0.530991.
Train: 2018-07-31T01:18:00.900297: step 13933, loss 0.530965.
Train: 2018-07-31T01:18:01.025292: step 13934, loss 0.530903.
Train: 2018-07-31T01:18:01.165860: step 13935, loss 0.546828.
Train: 2018-07-31T01:18:01.306453: step 13936, loss 0.554788.
Train: 2018-07-31T01:18:01.447068: step 13937, loss 0.570829.
Train: 2018-07-31T01:18:01.603258: step 13938, loss 0.522452.
Train: 2018-07-31T01:18:01.743874: step 13939, loss 0.570806.
Train: 2018-07-31T01:18:01.900064: step 13940, loss 0.514087.
Test: 2018-07-31T01:18:02.134414: step 13940, loss 0.549048.
Train: 2018-07-31T01:18:02.274975: step 13941, loss 0.619545.
Train: 2018-07-31T01:18:02.431189: step 13942, loss 0.595198.
Train: 2018-07-31T01:18:02.571780: step 13943, loss 0.530048.
Train: 2018-07-31T01:18:02.712373: step 13944, loss 0.595244.
Train: 2018-07-31T01:18:02.868623: step 13945, loss 0.546288.
Train: 2018-07-31T01:18:03.009179: step 13946, loss 0.529931.
Train: 2018-07-31T01:18:03.149795: step 13947, loss 0.562587.
Train: 2018-07-31T01:18:03.290362: step 13948, loss 0.570764.
Train: 2018-07-31T01:18:03.430979: step 13949, loss 0.570762.
Train: 2018-07-31T01:18:03.587167: step 13950, loss 0.636387.
Test: 2018-07-31T01:18:03.821519: step 13950, loss 0.548842.
Train: 2018-07-31T01:18:03.977726: step 13951, loss 0.537984.
Train: 2018-07-31T01:18:04.133915: step 13952, loss 0.578955.
Train: 2018-07-31T01:18:04.274507: step 13953, loss 0.472545.
Train: 2018-07-31T01:18:04.415100: step 13954, loss 0.562568.
Train: 2018-07-31T01:18:04.555692: step 13955, loss 0.537944.
Train: 2018-07-31T01:18:04.696284: step 13956, loss 0.54611.
Train: 2018-07-31T01:18:04.836875: step 13957, loss 0.636598.
Train: 2018-07-31T01:18:04.977492: step 13958, loss 0.620131.
Train: 2018-07-31T01:18:05.118085: step 13959, loss 0.603628.
Train: 2018-07-31T01:18:05.258651: step 13960, loss 0.587161.
Test: 2018-07-31T01:18:05.508593: step 13960, loss 0.548891.
Train: 2018-07-31T01:18:05.664832: step 13961, loss 0.513517.
Train: 2018-07-31T01:18:05.805400: step 13962, loss 0.546264.
Train: 2018-07-31T01:18:05.961613: step 13963, loss 0.660556.
Train: 2018-07-31T01:18:06.102203: step 13964, loss 0.530083.
Train: 2018-07-31T01:18:06.242796: step 13965, loss 0.676403.
Train: 2018-07-31T01:18:06.383388: step 13966, loss 0.538437.
Train: 2018-07-31T01:18:06.523980: step 13967, loss 0.554685.
Train: 2018-07-31T01:18:06.664572: step 13968, loss 0.594964.
Train: 2018-07-31T01:18:06.805189: step 13969, loss 0.546786.
Train: 2018-07-31T01:18:06.961377: step 13970, loss 0.53085.
Test: 2018-07-31T01:18:07.211319: step 13970, loss 0.549492.
Train: 2018-07-31T01:18:07.367533: step 13971, loss 0.546892.
Train: 2018-07-31T01:18:07.508143: step 13972, loss 0.586848.
Train: 2018-07-31T01:18:07.648716: step 13973, loss 0.642691.
Train: 2018-07-31T01:18:07.789334: step 13974, loss 0.586817.
Train: 2018-07-31T01:18:07.929926: step 13975, loss 0.523309.
Train: 2018-07-31T01:18:08.070518: step 13976, loss 0.650174.
Train: 2018-07-31T01:18:08.226707: step 13977, loss 0.570963.
Train: 2018-07-31T01:18:08.367300: step 13978, loss 0.610368.
Train: 2018-07-31T01:18:08.507915: step 13979, loss 0.586721.
Train: 2018-07-31T01:18:08.648507: step 13980, loss 0.547606.
Test: 2018-07-31T01:18:08.898425: step 13980, loss 0.550234.
Train: 2018-07-31T01:18:09.039017: step 13981, loss 0.571094.
Train: 2018-07-31T01:18:09.179633: step 13982, loss 0.625583.
Train: 2018-07-31T01:18:09.320200: step 13983, loss 0.578917.
Train: 2018-07-31T01:18:09.460792: step 13984, loss 0.548016.
Train: 2018-07-31T01:18:09.601385: step 13985, loss 0.602082.
Train: 2018-07-31T01:18:09.741977: step 13986, loss 0.540504.
Train: 2018-07-31T01:18:09.882568: step 13987, loss 0.525215.
Train: 2018-07-31T01:18:10.023162: step 13988, loss 0.555938.
Train: 2018-07-31T01:18:10.179399: step 13989, loss 0.57897.
Train: 2018-07-31T01:18:10.319968: step 13990, loss 0.571286.
Test: 2018-07-31T01:18:10.569909: step 13990, loss 0.550725.
Train: 2018-07-31T01:18:10.710525: step 13991, loss 0.456003.
Train: 2018-07-31T01:18:10.866712: step 13992, loss 0.555818.
Train: 2018-07-31T01:18:11.007306: step 13993, loss 0.571193.
Train: 2018-07-31T01:18:11.132276: step 13994, loss 0.578914.
Train: 2018-07-31T01:18:11.288490: step 13995, loss 0.524444.
Train: 2018-07-31T01:18:11.444703: step 13996, loss 0.610117.
Train: 2018-07-31T01:18:11.600916: step 13997, loss 0.547583.
Train: 2018-07-31T01:18:11.741535: step 13998, loss 0.492578.
Train: 2018-07-31T01:18:11.882125: step 13999, loss 0.56311.
Train: 2018-07-31T01:18:12.038339: step 14000, loss 0.563043.
Test: 2018-07-31T01:18:12.272634: step 14000, loss 0.549689.
Train: 2018-07-31T01:18:13.038080: step 14001, loss 0.578858.
Train: 2018-07-31T01:18:13.178673: step 14002, loss 0.491279.
Train: 2018-07-31T01:18:13.319264: step 14003, loss 0.506885.
Train: 2018-07-31T01:18:13.459882: step 14004, loss 0.530628.
Train: 2018-07-31T01:18:13.600477: step 14005, loss 0.554633.
Train: 2018-07-31T01:18:13.741066: step 14006, loss 0.58703.
Train: 2018-07-31T01:18:13.897254: step 14007, loss 0.554448.
Train: 2018-07-31T01:18:14.037846: step 14008, loss 0.578942.
Train: 2018-07-31T01:18:14.178438: step 14009, loss 0.579024.
Train: 2018-07-31T01:18:14.334651: step 14010, loss 0.570739.
Test: 2018-07-31T01:18:14.568973: step 14010, loss 0.548663.
Train: 2018-07-31T01:18:14.740808: step 14011, loss 0.545971.
Train: 2018-07-31T01:18:14.881399: step 14012, loss 0.487984.
Train: 2018-07-31T01:18:15.021991: step 14013, loss 0.55406.
Train: 2018-07-31T01:18:15.162583: step 14014, loss 0.512303.
Train: 2018-07-31T01:18:15.318820: step 14015, loss 0.562685.
Train: 2018-07-31T01:18:15.459388: step 14016, loss 0.571197.
Train: 2018-07-31T01:18:15.615626: step 14017, loss 0.503322.
Train: 2018-07-31T01:18:15.756222: step 14018, loss 0.536714.
Train: 2018-07-31T01:18:15.896810: step 14019, loss 0.587431.
Train: 2018-07-31T01:18:16.053000: step 14020, loss 0.536885.
Test: 2018-07-31T01:18:16.287351: step 14020, loss 0.547959.
Train: 2018-07-31T01:18:16.427937: step 14021, loss 0.54504.
Train: 2018-07-31T01:18:16.568528: step 14022, loss 0.554247.
Train: 2018-07-31T01:18:16.709096: step 14023, loss 0.596247.
Train: 2018-07-31T01:18:16.865308: step 14024, loss 0.536701.
Train: 2018-07-31T01:18:17.005918: step 14025, loss 0.631895.
Train: 2018-07-31T01:18:17.162114: step 14026, loss 0.588802.
Train: 2018-07-31T01:18:17.302707: step 14027, loss 0.596559.
Train: 2018-07-31T01:18:17.443323: step 14028, loss 0.579412.
Train: 2018-07-31T01:18:17.583890: step 14029, loss 0.587793.
Train: 2018-07-31T01:18:17.724485: step 14030, loss 0.503173.
Test: 2018-07-31T01:18:17.974459: step 14030, loss 0.54823.
Train: 2018-07-31T01:18:18.130638: step 14031, loss 0.51172.
Train: 2018-07-31T01:18:18.271229: step 14032, loss 0.528627.
Train: 2018-07-31T01:18:18.411846: step 14033, loss 0.553934.
Train: 2018-07-31T01:18:18.583658: step 14034, loss 0.604541.
Train: 2018-07-31T01:18:18.724250: step 14035, loss 0.621351.
Train: 2018-07-31T01:18:18.864865: step 14036, loss 0.511947.
Train: 2018-07-31T01:18:19.005458: step 14037, loss 0.562389.
Train: 2018-07-31T01:18:19.146049: step 14038, loss 0.537237.
Train: 2018-07-31T01:18:19.286616: step 14039, loss 0.554018.
Train: 2018-07-31T01:18:19.427233: step 14040, loss 0.495402.
Test: 2018-07-31T01:18:19.677151: step 14040, loss 0.548362.
Train: 2018-07-31T01:18:19.817743: step 14041, loss 0.512112.
Train: 2018-07-31T01:18:19.958335: step 14042, loss 0.537208.
Train: 2018-07-31T01:18:20.098927: step 14043, loss 0.59826.
Train: 2018-07-31T01:18:20.255140: step 14044, loss 0.553963.
Train: 2018-07-31T01:18:20.395731: step 14045, loss 0.562376.
Train: 2018-07-31T01:18:20.536349: step 14046, loss 0.587647.
Train: 2018-07-31T01:18:20.676940: step 14047, loss 0.486575.
Train: 2018-07-31T01:18:20.833131: step 14048, loss 0.528642.
Train: 2018-07-31T01:18:20.973722: step 14049, loss 0.553919.
Train: 2018-07-31T01:18:21.114315: step 14050, loss 0.553902.
Test: 2018-07-31T01:18:21.348635: step 14050, loss 0.548174.
Train: 2018-07-31T01:18:21.504848: step 14051, loss 0.553887.
Train: 2018-07-31T01:18:21.645440: step 14052, loss 0.562352.
Train: 2018-07-31T01:18:21.786044: step 14053, loss 0.536896.
Train: 2018-07-31T01:18:21.926651: step 14054, loss 0.579335.
Train: 2018-07-31T01:18:22.067215: step 14055, loss 0.536853.
Train: 2018-07-31T01:18:22.223453: step 14056, loss 0.519826.
Train: 2018-07-31T01:18:22.379646: step 14057, loss 0.621946.
Train: 2018-07-31T01:18:22.520235: step 14058, loss 0.604908.
Train: 2018-07-31T01:18:22.660827: step 14059, loss 0.536835.
Train: 2018-07-31T01:18:22.817040: step 14060, loss 0.502868.
Test: 2018-07-31T01:18:23.051361: step 14060, loss 0.548109.
Train: 2018-07-31T01:18:23.191953: step 14061, loss 0.596366.
Train: 2018-07-31T01:18:23.332569: step 14062, loss 0.630306.
Train: 2018-07-31T01:18:23.473161: step 14063, loss 0.553886.
Train: 2018-07-31T01:18:23.629375: step 14064, loss 0.503167.
Train: 2018-07-31T01:18:23.785564: step 14065, loss 0.553897.
Train: 2018-07-31T01:18:23.926155: step 14066, loss 0.57081.
Train: 2018-07-31T01:18:24.066747: step 14067, loss 0.596085.
Train: 2018-07-31T01:18:24.207339: step 14068, loss 0.469686.
Train: 2018-07-31T01:18:24.363555: step 14069, loss 0.629823.
Train: 2018-07-31T01:18:24.504171: step 14070, loss 0.629747.
Test: 2018-07-31T01:18:24.738464: step 14070, loss 0.548327.
Train: 2018-07-31T01:18:24.894693: step 14071, loss 0.646345.
Train: 2018-07-31T01:18:25.050891: step 14072, loss 0.520622.
Train: 2018-07-31T01:18:25.191485: step 14073, loss 0.554098.
Train: 2018-07-31T01:18:25.332093: step 14074, loss 0.579072.
Train: 2018-07-31T01:18:25.472667: step 14075, loss 0.562475.
Train: 2018-07-31T01:18:25.628912: step 14076, loss 0.579017.
Train: 2018-07-31T01:18:25.753877: step 14077, loss 0.578994.
Train: 2018-07-31T01:18:25.894491: step 14078, loss 0.488638.
Train: 2018-07-31T01:18:26.050685: step 14079, loss 0.603573.
Train: 2018-07-31T01:18:26.206871: step 14080, loss 0.50527.
Test: 2018-07-31T01:18:26.441191: step 14080, loss 0.54888.
Train: 2018-07-31T01:18:26.581784: step 14081, loss 0.562583.
Train: 2018-07-31T01:18:26.737999: step 14082, loss 0.578945.
Train: 2018-07-31T01:18:26.878613: step 14083, loss 0.603455.
Train: 2018-07-31T01:18:27.019181: step 14084, loss 0.505506.
Train: 2018-07-31T01:18:27.159773: step 14085, loss 0.570773.
Train: 2018-07-31T01:18:27.300389: step 14086, loss 0.578928.
Train: 2018-07-31T01:18:27.440957: step 14087, loss 0.521891.
Train: 2018-07-31T01:18:27.581573: step 14088, loss 0.554476.
Train: 2018-07-31T01:18:27.722166: step 14089, loss 0.513704.
Train: 2018-07-31T01:18:27.893975: step 14090, loss 0.546277.
Test: 2018-07-31T01:18:28.128304: step 14090, loss 0.548893.
Train: 2018-07-31T01:18:28.268887: step 14091, loss 0.578945.
Train: 2018-07-31T01:18:28.409505: step 14092, loss 0.521643.
Train: 2018-07-31T01:18:28.565693: step 14093, loss 0.628176.
Train: 2018-07-31T01:18:28.721906: step 14094, loss 0.6528.
Train: 2018-07-31T01:18:28.862523: step 14095, loss 0.554385.
Train: 2018-07-31T01:18:29.003115: step 14096, loss 0.546234.
Train: 2018-07-31T01:18:29.143683: step 14097, loss 0.505409.
Train: 2018-07-31T01:18:29.284275: step 14098, loss 0.554422.
Train: 2018-07-31T01:18:29.424868: step 14099, loss 0.587121.
Train: 2018-07-31T01:18:29.565484: step 14100, loss 0.546238.
Test: 2018-07-31T01:18:29.815403: step 14100, loss 0.548891.
Train: 2018-07-31T01:18:30.580849: step 14101, loss 0.55441.
Train: 2018-07-31T01:18:30.721464: step 14102, loss 0.570766.
Train: 2018-07-31T01:18:30.862056: step 14103, loss 0.603498.
Train: 2018-07-31T01:18:31.002623: step 14104, loss 0.546237.
Train: 2018-07-31T01:18:31.143240: step 14105, loss 0.562594.
Train: 2018-07-31T01:18:31.299429: step 14106, loss 0.562597.
Train: 2018-07-31T01:18:31.455643: step 14107, loss 0.5626.
Train: 2018-07-31T01:18:31.611857: step 14108, loss 0.513603.
Train: 2018-07-31T01:18:31.736827: step 14109, loss 0.513555.
Train: 2018-07-31T01:18:31.893064: step 14110, loss 0.587141.
Test: 2018-07-31T01:18:32.142982: step 14110, loss 0.548839.
Train: 2018-07-31T01:18:32.283631: step 14111, loss 0.595352.
Train: 2018-07-31T01:18:32.439787: step 14112, loss 0.619951.
Train: 2018-07-31T01:18:32.580403: step 14113, loss 0.529817.
Train: 2018-07-31T01:18:32.736617: step 14114, loss 0.578952.
Train: 2018-07-31T01:18:32.877209: step 14115, loss 0.50531.
Train: 2018-07-31T01:18:33.033435: step 14116, loss 0.595327.
Train: 2018-07-31T01:18:33.173991: step 14117, loss 0.521648.
Train: 2018-07-31T01:18:33.314582: step 14118, loss 0.62811.
Train: 2018-07-31T01:18:33.455214: step 14119, loss 0.611695.
Train: 2018-07-31T01:18:33.595765: step 14120, loss 0.562596.
Test: 2018-07-31T01:18:33.845738: step 14120, loss 0.548936.
Train: 2018-07-31T01:18:34.001922: step 14121, loss 0.562614.
Train: 2018-07-31T01:18:34.142514: step 14122, loss 0.578924.
Train: 2018-07-31T01:18:34.298727: step 14123, loss 0.603315.
Train: 2018-07-31T01:18:34.454940: step 14124, loss 0.578904.
Train: 2018-07-31T01:18:34.595532: step 14125, loss 0.546519.
Train: 2018-07-31T01:18:34.751770: step 14126, loss 0.473861.
Train: 2018-07-31T01:18:34.892336: step 14127, loss 0.530398.
Train: 2018-07-31T01:18:35.032930: step 14128, loss 0.53844.
Train: 2018-07-31T01:18:35.173532: step 14129, loss 0.595104.
Train: 2018-07-31T01:18:35.329735: step 14130, loss 0.570793.
Test: 2018-07-31T01:18:35.564081: step 14130, loss 0.549091.
Train: 2018-07-31T01:18:35.704647: step 14131, loss 0.554566.
Train: 2018-07-31T01:18:35.860860: step 14132, loss 0.63573.
Train: 2018-07-31T01:18:36.001453: step 14133, loss 0.546463.
Train: 2018-07-31T01:18:36.142046: step 14134, loss 0.538373.
Train: 2018-07-31T01:18:36.282661: step 14135, loss 0.554582.
Train: 2018-07-31T01:18:36.438852: step 14136, loss 0.546468.
Train: 2018-07-31T01:18:36.595088: step 14137, loss 0.538336.
Train: 2018-07-31T01:18:36.735657: step 14138, loss 0.530172.
Train: 2018-07-31T01:18:36.891869: step 14139, loss 0.57078.
Train: 2018-07-31T01:18:37.032462: step 14140, loss 0.554479.
Test: 2018-07-31T01:18:37.266807: step 14140, loss 0.548945.
Train: 2018-07-31T01:18:37.407373: step 14141, loss 0.587093.
Train: 2018-07-31T01:18:37.563588: step 14142, loss 0.578937.
Train: 2018-07-31T01:18:37.704204: step 14143, loss 0.529924.
Train: 2018-07-31T01:18:37.844813: step 14144, loss 0.570767.
Train: 2018-07-31T01:18:37.985362: step 14145, loss 0.488936.
Train: 2018-07-31T01:18:38.141577: step 14146, loss 0.513355.
Train: 2018-07-31T01:18:38.282170: step 14147, loss 0.529629.
Train: 2018-07-31T01:18:38.422760: step 14148, loss 0.595517.
Train: 2018-07-31T01:18:38.563352: step 14149, loss 0.562484.
Train: 2018-07-31T01:18:38.703969: step 14150, loss 0.529316.
Test: 2018-07-31T01:18:38.953910: step 14150, loss 0.548537.
Train: 2018-07-31T01:18:39.094478: step 14151, loss 0.537528.
Train: 2018-07-31T01:18:39.250691: step 14152, loss 0.504128.
Train: 2018-07-31T01:18:39.391285: step 14153, loss 0.512265.
Train: 2018-07-31T01:18:39.547498: step 14154, loss 0.553997.
Train: 2018-07-31T01:18:39.688090: step 14155, loss 0.596063.
Train: 2018-07-31T01:18:39.844303: step 14156, loss 0.545486.
Train: 2018-07-31T01:18:39.984919: step 14157, loss 0.54545.
Train: 2018-07-31T01:18:40.125512: step 14158, loss 0.528425.
Train: 2018-07-31T01:18:40.281701: step 14159, loss 0.596355.
Train: 2018-07-31T01:18:40.422317: step 14160, loss 0.553828.
Test: 2018-07-31T01:18:40.656614: step 14160, loss 0.548063.
Train: 2018-07-31T01:18:40.812850: step 14161, loss 0.622015.
Train: 2018-07-31T01:18:40.969064: step 14162, loss 0.604953.
Train: 2018-07-31T01:18:41.125252: step 14163, loss 0.647456.
Train: 2018-07-31T01:18:41.281490: step 14164, loss 0.56235.
Train: 2018-07-31T01:18:41.422058: step 14165, loss 0.655416.
Train: 2018-07-31T01:18:41.578271: step 14166, loss 0.511857.
Train: 2018-07-31T01:18:41.718888: step 14167, loss 0.570783.
Train: 2018-07-31T01:18:41.875077: step 14168, loss 0.545684.
Train: 2018-07-31T01:18:42.015669: step 14169, loss 0.562427.
Train: 2018-07-31T01:18:42.156261: step 14170, loss 0.554127.
Test: 2018-07-31T01:18:42.406202: step 14170, loss 0.548563.
Train: 2018-07-31T01:18:42.546795: step 14171, loss 0.462885.
Train: 2018-07-31T01:18:42.703009: step 14172, loss 0.520976.
Train: 2018-07-31T01:18:42.859222: step 14173, loss 0.603964.
Train: 2018-07-31T01:18:42.999813: step 14174, loss 0.562446.
Train: 2018-07-31T01:18:43.156028: step 14175, loss 0.562474.
Train: 2018-07-31T01:18:43.296637: step 14176, loss 0.637259.
Train: 2018-07-31T01:18:43.437212: step 14177, loss 0.554194.
Train: 2018-07-31T01:18:43.593424: step 14178, loss 0.545967.
Train: 2018-07-31T01:18:43.749639: step 14179, loss 0.587261.
Train: 2018-07-31T01:18:43.890230: step 14180, loss 0.570757.
Test: 2018-07-31T01:18:44.124576: step 14180, loss 0.548762.
Train: 2018-07-31T01:18:44.265168: step 14181, loss 0.636547.
Train: 2018-07-31T01:18:44.405735: step 14182, loss 0.513383.
Train: 2018-07-31T01:18:44.546326: step 14183, loss 0.603493.
Train: 2018-07-31T01:18:44.702540: step 14184, loss 0.52997.
Train: 2018-07-31T01:18:44.827511: step 14185, loss 0.546335.
Train: 2018-07-31T01:18:44.968103: step 14186, loss 0.57078.
Train: 2018-07-31T01:18:45.124340: step 14187, loss 0.53827.
Train: 2018-07-31T01:18:45.264910: step 14188, loss 0.554537.
Train: 2018-07-31T01:18:45.421146: step 14189, loss 0.570786.
Train: 2018-07-31T01:18:45.577336: step 14190, loss 0.684452.
Test: 2018-07-31T01:18:45.827277: step 14190, loss 0.549148.
Train: 2018-07-31T01:18:45.983521: step 14191, loss 0.522232.
Train: 2018-07-31T01:18:46.124082: step 14192, loss 0.578888.
Train: 2018-07-31T01:18:46.280295: step 14193, loss 0.554687.
Train: 2018-07-31T01:18:46.420912: step 14194, loss 0.56277.
Train: 2018-07-31T01:18:46.561504: step 14195, loss 0.570833.
Train: 2018-07-31T01:18:46.702071: step 14196, loss 0.619054.
Train: 2018-07-31T01:18:46.842670: step 14197, loss 0.634983.
Train: 2018-07-31T01:18:46.983256: step 14198, loss 0.530954.
Train: 2018-07-31T01:18:47.123849: step 14199, loss 0.56293.
Train: 2018-07-31T01:18:47.264465: step 14200, loss 0.618596.
Test: 2018-07-31T01:18:47.514412: step 14200, loss 0.549743.
Train: 2018-07-31T01:18:48.248586: step 14201, loss 0.515473.
Train: 2018-07-31T01:18:48.389178: step 14202, loss 0.531393.
Train: 2018-07-31T01:18:48.529768: step 14203, loss 0.515602.
Train: 2018-07-31T01:18:48.686013: step 14204, loss 0.650082.
Train: 2018-07-31T01:18:48.810970: step 14205, loss 0.61048.
Train: 2018-07-31T01:18:48.967201: step 14206, loss 0.563085.
Train: 2018-07-31T01:18:49.107760: step 14207, loss 0.476472.
Train: 2018-07-31T01:18:49.248375: step 14208, loss 0.594629.
Train: 2018-07-31T01:18:49.388967: step 14209, loss 0.610396.
Train: 2018-07-31T01:18:49.529534: step 14210, loss 0.563114.
Test: 2018-07-31T01:18:49.779477: step 14210, loss 0.549941.
Train: 2018-07-31T01:18:49.920069: step 14211, loss 0.570995.
Train: 2018-07-31T01:18:50.076282: step 14212, loss 0.571001.
Train: 2018-07-31T01:18:50.216873: step 14213, loss 0.578869.
Train: 2018-07-31T01:18:50.357494: step 14214, loss 0.586729.
Train: 2018-07-31T01:18:50.498082: step 14215, loss 0.508214.
Train: 2018-07-31T01:18:50.638650: step 14216, loss 0.547448.
Train: 2018-07-31T01:18:50.779266: step 14217, loss 0.531682.
Train: 2018-07-31T01:18:50.919835: step 14218, loss 0.507948.
Train: 2018-07-31T01:18:51.060450: step 14219, loss 0.531431.
Train: 2018-07-31T01:18:51.201019: step 14220, loss 0.60266.
Test: 2018-07-31T01:18:51.450990: step 14220, loss 0.549622.
Train: 2018-07-31T01:18:51.591576: step 14221, loss 0.531126.
Train: 2018-07-31T01:18:51.747766: step 14222, loss 0.54691.
Train: 2018-07-31T01:18:51.872760: step 14223, loss 0.602857.
Train: 2018-07-31T01:18:52.028951: step 14224, loss 0.635027.
Train: 2018-07-31T01:18:52.169566: step 14225, loss 0.619146.
Train: 2018-07-31T01:18:52.310133: step 14226, loss 0.530657.
Train: 2018-07-31T01:18:52.450727: step 14227, loss 0.530575.
Train: 2018-07-31T01:18:52.591345: step 14228, loss 0.56285.
Train: 2018-07-31T01:18:52.731911: step 14229, loss 0.643173.
Train: 2018-07-31T01:18:52.888149: step 14230, loss 0.578797.
Test: 2018-07-31T01:18:53.122474: step 14230, loss 0.549297.
Train: 2018-07-31T01:18:53.278681: step 14231, loss 0.55458.
Train: 2018-07-31T01:18:53.419274: step 14232, loss 0.554859.
Train: 2018-07-31T01:18:53.570877: step 14233, loss 0.538626.
Train: 2018-07-31T01:18:53.711469: step 14234, loss 0.57926.
Train: 2018-07-31T01:18:53.852061: step 14235, loss 0.627298.
Train: 2018-07-31T01:18:53.992679: step 14236, loss 0.538799.
Train: 2018-07-31T01:18:54.133244: step 14237, loss 0.603186.
Train: 2018-07-31T01:18:54.273862: step 14238, loss 0.634744.
Train: 2018-07-31T01:18:54.414452: step 14239, loss 0.578851.
Train: 2018-07-31T01:18:54.555045: step 14240, loss 0.547163.
Test: 2018-07-31T01:18:54.804963: step 14240, loss 0.549814.
Train: 2018-07-31T01:18:54.945553: step 14241, loss 0.634213.
Train: 2018-07-31T01:18:55.101768: step 14242, loss 0.602508.
Train: 2018-07-31T01:18:55.242378: step 14243, loss 0.578872.
Train: 2018-07-31T01:18:55.382976: step 14244, loss 0.555413.
Train: 2018-07-31T01:18:55.539164: step 14245, loss 0.586692.
Train: 2018-07-31T01:18:55.664161: step 14246, loss 0.547791.
Train: 2018-07-31T01:18:55.820388: step 14247, loss 0.524577.
Train: 2018-07-31T01:18:55.976564: step 14248, loss 0.563401.
Train: 2018-07-31T01:18:56.117154: step 14249, loss 0.555653.
Train: 2018-07-31T01:18:56.257758: step 14250, loss 0.563405.
Test: 2018-07-31T01:18:56.492095: step 14250, loss 0.550405.
Train: 2018-07-31T01:18:56.648279: step 14251, loss 0.664253.
Train: 2018-07-31T01:18:56.804495: step 14252, loss 0.594411.
Train: 2018-07-31T01:18:56.945087: step 14253, loss 0.578934.
Train: 2018-07-31T01:18:57.101300: step 14254, loss 0.586655.
Train: 2018-07-31T01:18:57.226270: step 14255, loss 0.60974.
Train: 2018-07-31T01:18:57.382485: step 14256, loss 0.548276.
Train: 2018-07-31T01:18:57.538698: step 14257, loss 0.609635.
Train: 2018-07-31T01:18:57.679289: step 14258, loss 0.586648.
Train: 2018-07-31T01:18:57.819881: step 14259, loss 0.533288.
Train: 2018-07-31T01:18:57.960473: step 14260, loss 0.495268.
Test: 2018-07-31T01:18:58.194795: step 14260, loss 0.550975.
Train: 2018-07-31T01:18:58.351007: step 14261, loss 0.571405.
Train: 2018-07-31T01:18:58.491623: step 14262, loss 0.579001.
Train: 2018-07-31T01:18:58.647812: step 14263, loss 0.472038.
Train: 2018-07-31T01:18:58.788429: step 14264, loss 0.532976.
Train: 2018-07-31T01:18:58.928996: step 14265, loss 0.532667.
Train: 2018-07-31T01:18:59.069613: step 14266, loss 0.516485.
Train: 2018-07-31T01:18:59.210180: step 14267, loss 0.586773.
Train: 2018-07-31T01:18:59.366393: step 14268, loss 0.491739.
Train: 2018-07-31T01:18:59.506991: step 14269, loss 0.489951.
Train: 2018-07-31T01:18:59.647578: step 14270, loss 0.539282.
Test: 2018-07-31T01:18:59.881899: step 14270, loss 0.548323.
Train: 2018-07-31T01:19:00.038113: step 14271, loss 0.516695.
Train: 2018-07-31T01:19:00.178704: step 14272, loss 0.553229.
Train: 2018-07-31T01:19:00.319297: step 14273, loss 0.544796.
Train: 2018-07-31T01:19:00.459888: step 14274, loss 0.557978.
Train: 2018-07-31T01:19:00.600479: step 14275, loss 0.612637.
Train: 2018-07-31T01:19:00.756695: step 14276, loss 0.553474.
Train: 2018-07-31T01:19:00.897285: step 14277, loss 0.623767.
Train: 2018-07-31T01:19:01.037902: step 14278, loss 0.541667.
Train: 2018-07-31T01:19:01.178494: step 14279, loss 0.516762.
Train: 2018-07-31T01:19:01.334685: step 14280, loss 0.450644.
Test: 2018-07-31T01:19:01.569037: step 14280, loss 0.547598.
Train: 2018-07-31T01:19:01.725241: step 14281, loss 0.56459.
Train: 2018-07-31T01:19:01.865808: step 14282, loss 0.565827.
Train: 2018-07-31T01:19:02.006402: step 14283, loss 0.521625.
Train: 2018-07-31T01:19:02.147018: step 14284, loss 0.598416.
Train: 2018-07-31T01:19:02.287585: step 14285, loss 0.570954.
Train: 2018-07-31T01:19:02.428205: step 14286, loss 0.573155.
Train: 2018-07-31T01:19:02.568794: step 14287, loss 0.527591.
Train: 2018-07-31T01:19:02.709362: step 14288, loss 0.571622.
Train: 2018-07-31T01:19:02.849954: step 14289, loss 0.537356.
Train: 2018-07-31T01:19:03.006168: step 14290, loss 0.586212.
Test: 2018-07-31T01:19:03.240517: step 14290, loss 0.548424.
Train: 2018-07-31T01:19:03.396699: step 14291, loss 0.57889.
Train: 2018-07-31T01:19:03.537292: step 14292, loss 0.528982.
Train: 2018-07-31T01:19:03.677885: step 14293, loss 0.637059.
Train: 2018-07-31T01:19:03.818501: step 14294, loss 0.587349.
Train: 2018-07-31T01:19:03.959068: step 14295, loss 0.579147.
Train: 2018-07-31T01:19:04.099661: step 14296, loss 0.570926.
Train: 2018-07-31T01:19:04.240252: step 14297, loss 0.546087.
Train: 2018-07-31T01:19:04.380846: step 14298, loss 0.587124.
Train: 2018-07-31T01:19:04.537082: step 14299, loss 0.546305.
Train: 2018-07-31T01:19:04.693273: step 14300, loss 0.554488.
Test: 2018-07-31T01:19:04.927593: step 14300, loss 0.549047.
Train: 2018-07-31T01:19:05.677417: step 14301, loss 0.456905.
Train: 2018-07-31T01:19:05.818033: step 14302, loss 0.538206.
Train: 2018-07-31T01:19:05.974222: step 14303, loss 0.587085.
Train: 2018-07-31T01:19:06.114814: step 14304, loss 0.554447.
Train: 2018-07-31T01:19:06.255431: step 14305, loss 0.538089.
Train: 2018-07-31T01:19:06.396023: step 14306, loss 0.52168.
Train: 2018-07-31T01:19:06.552212: step 14307, loss 0.480585.
Train: 2018-07-31T01:19:06.708426: step 14308, loss 0.546076.
Train: 2018-07-31T01:19:06.849017: step 14309, loss 0.587269.
Train: 2018-07-31T01:19:06.989610: step 14310, loss 0.545924.
Test: 2018-07-31T01:19:07.239551: step 14310, loss 0.54856.
Train: 2018-07-31T01:19:07.380167: step 14311, loss 0.587354.
Train: 2018-07-31T01:19:07.536357: step 14312, loss 0.545814.
Train: 2018-07-31T01:19:07.676948: step 14313, loss 0.529118.
Train: 2018-07-31T01:19:07.817565: step 14314, loss 0.503982.
Train: 2018-07-31T01:19:07.958149: step 14315, loss 0.520519.
Train: 2018-07-31T01:19:08.098723: step 14316, loss 0.553975.
Train: 2018-07-31T01:19:08.239316: step 14317, loss 0.562356.
Train: 2018-07-31T01:19:08.379908: step 14318, loss 0.613052.
Train: 2018-07-31T01:19:08.520508: step 14319, loss 0.613272.
Train: 2018-07-31T01:19:08.661093: step 14320, loss 0.477634.
Test: 2018-07-31T01:19:08.911035: step 14320, loss 0.548143.
Train: 2018-07-31T01:19:09.051626: step 14321, loss 0.562367.
Train: 2018-07-31T01:19:09.192218: step 14322, loss 0.621681.
Train: 2018-07-31T01:19:09.348444: step 14323, loss 0.536882.
Train: 2018-07-31T01:19:09.489047: step 14324, loss 0.53682.
Train: 2018-07-31T01:19:09.629640: step 14325, loss 0.570926.
Train: 2018-07-31T01:19:09.770208: step 14326, loss 0.655909.
Train: 2018-07-31T01:19:09.942042: step 14327, loss 0.663956.
Train: 2018-07-31T01:19:10.082659: step 14328, loss 0.537047.
Train: 2018-07-31T01:19:10.223251: step 14329, loss 0.503556.
Train: 2018-07-31T01:19:10.363843: step 14330, loss 0.537236.
Test: 2018-07-31T01:19:10.613790: step 14330, loss 0.5491.
Train: 2018-07-31T01:19:10.754351: step 14331, loss 0.562411.
Train: 2018-07-31T01:19:10.894944: step 14332, loss 0.545703.
Train: 2018-07-31T01:19:11.035536: step 14333, loss 0.529018.
Train: 2018-07-31T01:19:11.176127: step 14334, loss 0.554074.
Train: 2018-07-31T01:19:11.332366: step 14335, loss 0.570767.
Train: 2018-07-31T01:19:11.488555: step 14336, loss 0.604128.
Train: 2018-07-31T01:19:11.629149: step 14337, loss 0.512463.
Train: 2018-07-31T01:19:11.769739: step 14338, loss 0.587414.
Train: 2018-07-31T01:19:11.910331: step 14339, loss 0.520854.
Train: 2018-07-31T01:19:12.050925: step 14340, loss 0.562444.
Test: 2018-07-31T01:19:12.285247: step 14340, loss 0.548566.
Train: 2018-07-31T01:19:12.441457: step 14341, loss 0.537497.
Train: 2018-07-31T01:19:12.582049: step 14342, loss 0.562443.
Train: 2018-07-31T01:19:12.722641: step 14343, loss 0.537483.
Train: 2018-07-31T01:19:12.863258: step 14344, loss 0.595736.
Train: 2018-07-31T01:19:13.003826: step 14345, loss 0.580194.
Train: 2018-07-31T01:19:13.144442: step 14346, loss 0.520864.
Train: 2018-07-31T01:19:13.300656: step 14347, loss 0.570761.
Train: 2018-07-31T01:19:13.441241: step 14348, loss 0.512549.
Train: 2018-07-31T01:19:13.581841: step 14349, loss 0.570762.
Train: 2018-07-31T01:19:13.738056: step 14350, loss 0.545783.
Test: 2018-07-31T01:19:13.988000: step 14350, loss 0.548478.
Train: 2018-07-31T01:19:14.128561: step 14351, loss 0.620756.
Train: 2018-07-31T01:19:14.284800: step 14352, loss 0.520806.
Train: 2018-07-31T01:19:14.425369: step 14353, loss 0.604071.
Train: 2018-07-31T01:19:14.565984: step 14354, loss 0.520842.
Train: 2018-07-31T01:19:14.722209: step 14355, loss 0.604042.
Train: 2018-07-31T01:19:14.862767: step 14356, loss 0.471015.
Train: 2018-07-31T01:19:15.003356: step 14357, loss 0.545802.
Train: 2018-07-31T01:19:15.143974: step 14358, loss 0.570764.
Train: 2018-07-31T01:19:15.300187: step 14359, loss 0.51242.
Train: 2018-07-31T01:19:15.440779: step 14360, loss 0.570768.
Test: 2018-07-31T01:19:15.690727: step 14360, loss 0.548414.
Train: 2018-07-31T01:19:15.831288: step 14361, loss 0.587486.
Train: 2018-07-31T01:19:15.987502: step 14362, loss 0.503886.
Train: 2018-07-31T01:19:16.143716: step 14363, loss 0.528912.
Train: 2018-07-31T01:19:16.284332: step 14364, loss 0.595946.
Train: 2018-07-31T01:19:16.424900: step 14365, loss 0.520413.
Train: 2018-07-31T01:19:16.565515: step 14366, loss 0.612828.
Train: 2018-07-31T01:19:16.706083: step 14367, loss 0.604427.
Train: 2018-07-31T01:19:16.846676: step 14368, loss 0.528778.
Train: 2018-07-31T01:19:16.987268: step 14369, loss 0.562386.
Train: 2018-07-31T01:19:17.143482: step 14370, loss 0.604374.
Test: 2018-07-31T01:19:17.393422: step 14370, loss 0.548319.
Train: 2018-07-31T01:19:17.534014: step 14371, loss 0.579167.
Train: 2018-07-31T01:19:17.674607: step 14372, loss 0.528913.
Train: 2018-07-31T01:19:17.830820: step 14373, loss 0.528948.
Train: 2018-07-31T01:19:17.971413: step 14374, loss 0.528958.
Train: 2018-07-31T01:19:18.112003: step 14375, loss 0.512213.
Train: 2018-07-31T01:19:18.268218: step 14376, loss 0.612657.
Train: 2018-07-31T01:19:18.408809: step 14377, loss 0.562401.
Train: 2018-07-31T01:19:18.565023: step 14378, loss 0.587525.
Train: 2018-07-31T01:19:18.705614: step 14379, loss 0.554039.
Train: 2018-07-31T01:19:18.861830: step 14380, loss 0.587496.
Test: 2018-07-31T01:19:19.096180: step 14380, loss 0.548432.
Train: 2018-07-31T01:19:19.252388: step 14381, loss 0.57912.
Train: 2018-07-31T01:19:19.392978: step 14382, loss 0.5124.
Train: 2018-07-31T01:19:19.533546: step 14383, loss 0.612433.
Train: 2018-07-31T01:19:19.674139: step 14384, loss 0.570762.
Train: 2018-07-31T01:19:19.814731: step 14385, loss 0.554146.
Train: 2018-07-31T01:19:19.955321: step 14386, loss 0.496106.
Train: 2018-07-31T01:19:20.127194: step 14387, loss 0.612232.
Train: 2018-07-31T01:19:20.267750: step 14388, loss 0.521044.
Train: 2018-07-31T01:19:20.408343: step 14389, loss 0.496202.
Train: 2018-07-31T01:19:20.548958: step 14390, loss 0.595638.
Test: 2018-07-31T01:19:20.798906: step 14390, loss 0.548551.
Train: 2018-07-31T01:19:20.939466: step 14391, loss 0.520989.
Train: 2018-07-31T01:19:21.080060: step 14392, loss 0.562456.
Train: 2018-07-31T01:19:21.220676: step 14393, loss 0.5209.
Train: 2018-07-31T01:19:21.376865: step 14394, loss 0.529149.
Train: 2018-07-31T01:19:21.501835: step 14395, loss 0.562427.
Train: 2018-07-31T01:19:21.658048: step 14396, loss 0.487246.
Train: 2018-07-31T01:19:21.783020: step 14397, loss 0.629413.
Train: 2018-07-31T01:19:21.939233: step 14398, loss 0.579166.
Train: 2018-07-31T01:19:22.095470: step 14399, loss 0.537221.
Train: 2018-07-31T01:19:22.251660: step 14400, loss 0.537195.
Test: 2018-07-31T01:19:22.485979: step 14400, loss 0.548278.
Train: 2018-07-31T01:19:23.235804: step 14401, loss 0.621233.
Train: 2018-07-31T01:19:23.376421: step 14402, loss 0.55398.
Train: 2018-07-31T01:19:23.532635: step 14403, loss 0.553982.
Train: 2018-07-31T01:19:23.673201: step 14404, loss 0.570787.
Train: 2018-07-31T01:19:23.813793: step 14405, loss 0.570785.
Train: 2018-07-31T01:19:23.954386: step 14406, loss 0.495268.
Train: 2018-07-31T01:19:24.110600: step 14407, loss 0.570785.
Train: 2018-07-31T01:19:24.251191: step 14408, loss 0.5288.
Train: 2018-07-31T01:19:24.391783: step 14409, loss 0.537175.
Train: 2018-07-31T01:19:24.532393: step 14410, loss 0.553968.
Test: 2018-07-31T01:19:24.782317: step 14410, loss 0.548275.
Train: 2018-07-31T01:19:24.922908: step 14411, loss 0.537116.
Train: 2018-07-31T01:19:25.079123: step 14412, loss 0.537081.
Train: 2018-07-31T01:19:25.219715: step 14413, loss 0.587692.
Train: 2018-07-31T01:19:25.360331: step 14414, loss 0.503231.
Train: 2018-07-31T01:19:25.500900: step 14415, loss 0.545436.
Train: 2018-07-31T01:19:25.672734: step 14416, loss 0.596251.
Train: 2018-07-31T01:19:25.813350: step 14417, loss 0.511474.
Train: 2018-07-31T01:19:25.953917: step 14418, loss 0.511402.
Train: 2018-07-31T01:19:26.094509: step 14419, loss 0.536819.
Train: 2018-07-31T01:19:26.235102: step 14420, loss 0.664661.
Test: 2018-07-31T01:19:26.485045: step 14420, loss 0.548064.
Train: 2018-07-31T01:19:26.625637: step 14421, loss 0.519718.
Train: 2018-07-31T01:19:26.766228: step 14422, loss 0.604976.
Train: 2018-07-31T01:19:26.922442: step 14423, loss 0.587904.
Train: 2018-07-31T01:19:27.063051: step 14424, loss 0.596383.
Train: 2018-07-31T01:19:27.203626: step 14425, loss 0.570839.
Train: 2018-07-31T01:19:27.344218: step 14426, loss 0.621664.
Train: 2018-07-31T01:19:27.484810: step 14427, loss 0.596141.
Train: 2018-07-31T01:19:27.625427: step 14428, loss 0.520323.
Train: 2018-07-31T01:19:27.765995: step 14429, loss 0.61272.
Train: 2018-07-31T01:19:27.906610: step 14430, loss 0.528986.
Test: 2018-07-31T01:19:28.140922: step 14430, loss 0.548474.
Train: 2018-07-31T01:19:28.359605: step 14431, loss 0.570765.
Train: 2018-07-31T01:19:28.500241: step 14432, loss 0.604002.
Train: 2018-07-31T01:19:28.640813: step 14433, loss 0.579039.
Train: 2018-07-31T01:19:28.781398: step 14434, loss 0.537746.
Train: 2018-07-31T01:19:28.937618: step 14435, loss 0.570758.
Train: 2018-07-31T01:19:29.109430: step 14436, loss 0.546137.
Train: 2018-07-31T01:19:29.265643: step 14437, loss 0.570764.
Train: 2018-07-31T01:19:29.406235: step 14438, loss 0.529901.
Train: 2018-07-31T01:19:29.546827: step 14439, loss 0.54628.
Train: 2018-07-31T01:19:29.687443: step 14440, loss 0.554457.
Test: 2018-07-31T01:19:29.921737: step 14440, loss 0.548965.
Train: 2018-07-31T01:19:30.062330: step 14441, loss 0.562621.
Train: 2018-07-31T01:19:30.218545: step 14442, loss 0.562625.
Train: 2018-07-31T01:19:30.359142: step 14443, loss 0.603364.
Train: 2018-07-31T01:19:30.499729: step 14444, loss 0.513822.
Train: 2018-07-31T01:19:30.655942: step 14445, loss 0.489415.
Train: 2018-07-31T01:19:30.796535: step 14446, loss 0.538179.
Train: 2018-07-31T01:19:30.952748: step 14447, loss 0.611596.
Train: 2018-07-31T01:19:31.093339: step 14448, loss 0.611622.
Train: 2018-07-31T01:19:31.233931: step 14449, loss 0.464602.
Train: 2018-07-31T01:19:31.374523: step 14450, loss 0.636211.
Test: 2018-07-31T01:19:31.624495: step 14450, loss 0.54889.
Train: 2018-07-31T01:19:31.765058: step 14451, loss 0.570767.
Train: 2018-07-31T01:19:31.905649: step 14452, loss 0.587123.
Train: 2018-07-31T01:19:32.046266: step 14453, loss 0.570769.
Train: 2018-07-31T01:19:32.202454: step 14454, loss 0.611593.
Train: 2018-07-31T01:19:32.327424: step 14455, loss 0.513731.
Train: 2018-07-31T01:19:32.483638: step 14456, loss 0.497479.
Train: 2018-07-31T01:19:32.608635: step 14457, loss 0.530019.
Train: 2018-07-31T01:19:32.764851: step 14458, loss 0.603424.
Train: 2018-07-31T01:19:32.905439: step 14459, loss 0.546269.
Train: 2018-07-31T01:19:33.061629: step 14460, loss 0.570768.
Test: 2018-07-31T01:19:33.295955: step 14460, loss 0.548896.
Train: 2018-07-31T01:19:33.436541: step 14461, loss 0.578944.
Train: 2018-07-31T01:19:33.577132: step 14462, loss 0.521702.
Train: 2018-07-31T01:19:33.717724: step 14463, loss 0.57895.
Train: 2018-07-31T01:19:33.858317: step 14464, loss 0.628087.
Train: 2018-07-31T01:19:33.998933: step 14465, loss 0.587128.
Train: 2018-07-31T01:19:34.139501: step 14466, loss 0.554432.
Train: 2018-07-31T01:19:34.295714: step 14467, loss 0.652369.
Train: 2018-07-31T01:19:34.436306: step 14468, loss 0.530103.
Train: 2018-07-31T01:19:34.576898: step 14469, loss 0.530189.
Train: 2018-07-31T01:19:34.717491: step 14470, loss 0.603236.
Test: 2018-07-31T01:19:34.951842: step 14470, loss 0.549144.
Train: 2018-07-31T01:19:35.108042: step 14471, loss 0.562702.
Train: 2018-07-31T01:19:35.248641: step 14472, loss 0.570805.
Train: 2018-07-31T01:19:35.389209: step 14473, loss 0.562741.
Train: 2018-07-31T01:19:35.529801: step 14474, loss 0.554699.
Train: 2018-07-31T01:19:35.670393: step 14475, loss 0.586929.
Train: 2018-07-31T01:19:35.810985: step 14476, loss 0.530625.
Train: 2018-07-31T01:19:35.951578: step 14477, loss 0.619061.
Train: 2018-07-31T01:19:36.092186: step 14478, loss 0.514669.
Train: 2018-07-31T01:19:36.232786: step 14479, loss 0.522709.
Train: 2018-07-31T01:19:36.388975: step 14480, loss 0.619012.
Test: 2018-07-31T01:19:36.623296: step 14480, loss 0.549382.
Train: 2018-07-31T01:19:36.779509: step 14481, loss 0.498627.
Train: 2018-07-31T01:19:36.920101: step 14482, loss 0.570838.
Train: 2018-07-31T01:19:37.060692: step 14483, loss 0.578873.
Train: 2018-07-31T01:19:37.216931: step 14484, loss 0.627129.
Train: 2018-07-31T01:19:37.357498: step 14485, loss 0.578871.
Train: 2018-07-31T01:19:37.498090: step 14486, loss 0.578869.
Train: 2018-07-31T01:19:37.638682: step 14487, loss 0.52276.
Train: 2018-07-31T01:19:37.779293: step 14488, loss 0.578866.
Train: 2018-07-31T01:19:37.919866: step 14489, loss 0.578865.
Train: 2018-07-31T01:19:38.060458: step 14490, loss 0.57086.
Test: 2018-07-31T01:19:38.294809: step 14490, loss 0.54947.
Train: 2018-07-31T01:19:38.450992: step 14491, loss 0.618856.
Train: 2018-07-31T01:19:38.591608: step 14492, loss 0.578861.
Train: 2018-07-31T01:19:38.747796: step 14493, loss 0.539014.
Train: 2018-07-31T01:19:38.888414: step 14494, loss 0.674389.
Train: 2018-07-31T01:19:39.028982: step 14495, loss 0.539188.
Train: 2018-07-31T01:19:39.169597: step 14496, loss 0.579915.
Train: 2018-07-31T01:19:39.310166: step 14497, loss 0.523583.
Train: 2018-07-31T01:19:39.450759: step 14498, loss 0.586752.
Train: 2018-07-31T01:19:39.606971: step 14499, loss 0.578866.
Train: 2018-07-31T01:19:39.747563: step 14500, loss 0.586735.
Test: 2018-07-31T01:19:39.981882: step 14500, loss 0.55001.
Train: 2018-07-31T01:19:40.794216: step 14501, loss 0.531747.
Train: 2018-07-31T01:19:40.950406: step 14502, loss 0.516076.
Train: 2018-07-31T01:19:41.091026: step 14503, loss 0.571015.
Train: 2018-07-31T01:19:41.231616: step 14504, loss 0.547425.
Train: 2018-07-31T01:19:41.387804: step 14505, loss 0.578867.
Train: 2018-07-31T01:19:41.544017: step 14506, loss 0.610374.
Train: 2018-07-31T01:19:41.684611: step 14507, loss 0.57099.
Train: 2018-07-31T01:19:41.825201: step 14508, loss 0.60249.
Train: 2018-07-31T01:19:41.981440: step 14509, loss 0.555264.
Train: 2018-07-31T01:19:42.122007: step 14510, loss 0.484496.
Test: 2018-07-31T01:19:42.356328: step 14510, loss 0.549919.
Train: 2018-07-31T01:19:42.512565: step 14511, loss 0.586743.
Train: 2018-07-31T01:19:42.653132: step 14512, loss 0.578864.
Train: 2018-07-31T01:19:42.793750: step 14513, loss 0.547297.
Train: 2018-07-31T01:19:42.934341: step 14514, loss 0.523554.
Train: 2018-07-31T01:19:43.090529: step 14515, loss 0.570942.
Train: 2018-07-31T01:19:43.246744: step 14516, loss 0.63439.
Train: 2018-07-31T01:19:43.402958: step 14517, loss 0.531251.
Train: 2018-07-31T01:19:43.543549: step 14518, loss 0.61063.
Train: 2018-07-31T01:19:43.684142: step 14519, loss 0.539145.
Train: 2018-07-31T01:19:43.824733: step 14520, loss 0.515275.
Test: 2018-07-31T01:19:44.074675: step 14520, loss 0.5496.
Train: 2018-07-31T01:19:44.215266: step 14521, loss 0.602745.
Train: 2018-07-31T01:19:44.355882: step 14522, loss 0.578859.
Train: 2018-07-31T01:19:44.496475: step 14523, loss 0.594805.
Train: 2018-07-31T01:19:44.652663: step 14524, loss 0.51509.
Train: 2018-07-31T01:19:44.808877: step 14525, loss 0.57886.
Train: 2018-07-31T01:19:44.949470: step 14526, loss 0.546921.
Train: 2018-07-31T01:19:45.105683: step 14527, loss 0.570869.
Train: 2018-07-31T01:19:45.246274: step 14528, loss 0.578863.
Train: 2018-07-31T01:19:45.386866: step 14529, loss 0.498817.
Train: 2018-07-31T01:19:45.527477: step 14530, loss 0.60293.
Test: 2018-07-31T01:19:45.777402: step 14530, loss 0.549367.
Train: 2018-07-31T01:19:45.917993: step 14531, loss 0.594927.
Train: 2018-07-31T01:19:46.058584: step 14532, loss 0.530688.
Train: 2018-07-31T01:19:46.214799: step 14533, loss 0.570834.
Train: 2018-07-31T01:19:46.355391: step 14534, loss 0.506471.
Train: 2018-07-31T01:19:46.495983: step 14535, loss 0.538574.
Train: 2018-07-31T01:19:46.636574: step 14536, loss 0.538485.
Train: 2018-07-31T01:19:46.777191: step 14537, loss 0.538385.
Train: 2018-07-31T01:19:46.917783: step 14538, loss 0.530148.
Train: 2018-07-31T01:19:47.073973: step 14539, loss 0.554464.
Train: 2018-07-31T01:19:47.214565: step 14540, loss 0.513494.
Test: 2018-07-31T01:19:47.448915: step 14540, loss 0.548789.
Train: 2018-07-31T01:19:47.589501: step 14541, loss 0.537903.
Train: 2018-07-31T01:19:47.745715: step 14542, loss 0.562509.
Train: 2018-07-31T01:19:47.901904: step 14543, loss 0.51282.
Train: 2018-07-31T01:19:48.042496: step 14544, loss 0.554138.
Train: 2018-07-31T01:19:48.183088: step 14545, loss 0.604139.
Train: 2018-07-31T01:19:48.323679: step 14546, loss 0.562409.
Train: 2018-07-31T01:19:48.464273: step 14547, loss 0.545636.
Train: 2018-07-31T01:19:48.620486: step 14548, loss 0.553989.
Train: 2018-07-31T01:19:48.761095: step 14549, loss 0.629696.
Train: 2018-07-31T01:19:48.917291: step 14550, loss 0.587627.
Test: 2018-07-31T01:19:49.151635: step 14550, loss 0.548291.
Train: 2018-07-31T01:19:49.292203: step 14551, loss 0.545555.
Train: 2018-07-31T01:19:49.432795: step 14552, loss 0.604432.
Train: 2018-07-31T01:19:49.573387: step 14553, loss 0.604387.
Train: 2018-07-31T01:19:49.714004: step 14554, loss 0.512101.
Train: 2018-07-31T01:19:49.854595: step 14555, loss 0.537279.
Train: 2018-07-31T01:19:50.010785: step 14556, loss 0.554035.
Train: 2018-07-31T01:19:50.151377: step 14557, loss 0.604241.
Train: 2018-07-31T01:19:50.291968: step 14558, loss 0.562415.
Train: 2018-07-31T01:19:50.432561: step 14559, loss 0.512355.
Train: 2018-07-31T01:19:50.573177: step 14560, loss 0.545739.
Test: 2018-07-31T01:19:50.823125: step 14560, loss 0.548452.
Train: 2018-07-31T01:19:50.963687: step 14561, loss 0.470657.
Train: 2018-07-31T01:19:51.119924: step 14562, loss 0.595843.
Train: 2018-07-31T01:19:51.276137: step 14563, loss 0.629322.
Train: 2018-07-31T01:19:51.416706: step 14564, loss 0.595844.
Train: 2018-07-31T01:19:51.572954: step 14565, loss 0.545732.
Train: 2018-07-31T01:19:51.713512: step 14566, loss 0.570765.
Train: 2018-07-31T01:19:51.854104: step 14567, loss 0.537462.
Train: 2018-07-31T01:19:51.994720: step 14568, loss 0.562442.
Train: 2018-07-31T01:19:52.135311: step 14569, loss 0.579073.
Train: 2018-07-31T01:19:52.291499: step 14570, loss 0.554152.
Test: 2018-07-31T01:19:52.525851: step 14570, loss 0.548569.
Train: 2018-07-31T01:19:52.666437: step 14571, loss 0.603941.
Train: 2018-07-31T01:19:52.807005: step 14572, loss 0.554195.
Train: 2018-07-31T01:19:52.947596: step 14573, loss 0.595562.
Train: 2018-07-31T01:19:53.103811: step 14574, loss 0.587258.
Train: 2018-07-31T01:19:53.244403: step 14575, loss 0.537836.
Train: 2018-07-31T01:19:53.384993: step 14576, loss 0.562543.
Train: 2018-07-31T01:19:53.525587: step 14577, loss 0.537951.
Train: 2018-07-31T01:19:53.666230: step 14578, loss 0.587152.
Train: 2018-07-31T01:19:53.822391: step 14579, loss 0.644411.
Train: 2018-07-31T01:19:53.963008: step 14580, loss 0.603404.
Test: 2018-07-31T01:19:54.212926: step 14580, loss 0.549043.
Train: 2018-07-31T01:19:54.353517: step 14581, loss 0.50576.
Train: 2018-07-31T01:19:54.509731: step 14582, loss 0.473454.
Train: 2018-07-31T01:19:54.650347: step 14583, loss 0.546453.
Train: 2018-07-31T01:19:54.790914: step 14584, loss 0.562672.
Train: 2018-07-31T01:19:54.947130: step 14585, loss 0.635751.
Train: 2018-07-31T01:19:55.087748: step 14586, loss 0.505902.
Train: 2018-07-31T01:19:55.228312: step 14587, loss 0.546451.
Train: 2018-07-31T01:19:55.384526: step 14588, loss 0.522081.
Train: 2018-07-31T01:19:55.525119: step 14589, loss 0.554524.
Train: 2018-07-31T01:19:55.665709: step 14590, loss 0.513788.
Test: 2018-07-31T01:19:55.900030: step 14590, loss 0.548943.
Train: 2018-07-31T01:19:56.056244: step 14591, loss 0.546289.
Train: 2018-07-31T01:19:56.196837: step 14592, loss 0.529859.
Train: 2018-07-31T01:19:56.337428: step 14593, loss 0.537939.
Train: 2018-07-31T01:19:56.462400: step 14594, loss 0.562526.
Train: 2018-07-31T01:19:56.618612: step 14595, loss 0.612026.
Train: 2018-07-31T01:19:56.759204: step 14596, loss 0.587287.
Train: 2018-07-31T01:19:56.899795: step 14597, loss 0.570756.
Train: 2018-07-31T01:19:57.056011: step 14598, loss 0.512842.
Train: 2018-07-31T01:19:57.196627: step 14599, loss 0.562473.
Train: 2018-07-31T01:19:57.337206: step 14600, loss 0.562465.
Test: 2018-07-31T01:19:57.587136: step 14600, loss 0.548557.
Train: 2018-07-31T01:19:58.352591: step 14601, loss 0.603961.
Train: 2018-07-31T01:19:58.524416: step 14602, loss 0.545861.
Train: 2018-07-31T01:19:58.665032: step 14603, loss 0.562458.
Train: 2018-07-31T01:19:58.821221: step 14604, loss 0.554157.
Train: 2018-07-31T01:19:58.961814: step 14605, loss 0.512648.
Train: 2018-07-31T01:19:59.102423: step 14606, loss 0.620623.
Train: 2018-07-31T01:19:59.242998: step 14607, loss 0.60399.
Train: 2018-07-31T01:19:59.383589: step 14608, loss 0.595649.
Train: 2018-07-31T01:19:59.524199: step 14609, loss 0.545914.
Train: 2018-07-31T01:19:59.664773: step 14610, loss 0.686522.
Test: 2018-07-31T01:19:59.914741: step 14610, loss 0.548728.
Train: 2018-07-31T01:20:00.070928: step 14611, loss 0.554285.
Train: 2018-07-31T01:20:00.211520: step 14612, loss 0.546138.
Train: 2018-07-31T01:20:00.367733: step 14613, loss 0.63624.
Train: 2018-07-31T01:20:00.508327: step 14614, loss 0.570775.
Train: 2018-07-31T01:20:00.648919: step 14615, loss 0.562669.
Train: 2018-07-31T01:20:00.789535: step 14616, loss 0.603162.
Train: 2018-07-31T01:20:00.930127: step 14617, loss 0.627223.
Train: 2018-07-31T01:20:01.086317: step 14618, loss 0.586884.
Train: 2018-07-31T01:20:01.211332: step 14619, loss 0.538975.
Train: 2018-07-31T01:20:01.383122: step 14620, loss 0.491449.
Test: 2018-07-31T01:20:01.617472: step 14620, loss 0.549709.
Train: 2018-07-31T01:20:01.758075: step 14621, loss 0.586791.
Train: 2018-07-31T01:20:01.914248: step 14622, loss 0.531359.
Train: 2018-07-31T01:20:02.054838: step 14623, loss 0.570951.
Train: 2018-07-31T01:20:02.195456: step 14624, loss 0.539347.
Train: 2018-07-31T01:20:02.351646: step 14625, loss 0.547252.
Train: 2018-07-31T01:20:02.492260: step 14626, loss 0.594673.
Train: 2018-07-31T01:20:02.632861: step 14627, loss 0.570957.
Train: 2018-07-31T01:20:02.773444: step 14628, loss 0.547249.
Train: 2018-07-31T01:20:02.914037: step 14629, loss 0.52352.
Train: 2018-07-31T01:20:03.054604: step 14630, loss 0.507609.
Test: 2018-07-31T01:20:03.304547: step 14630, loss 0.549689.
Train: 2018-07-31T01:20:03.445138: step 14631, loss 0.586796.
Train: 2018-07-31T01:20:03.585729: step 14632, loss 0.523185.
Train: 2018-07-31T01:20:03.726347: step 14633, loss 0.57886.
Train: 2018-07-31T01:20:03.882561: step 14634, loss 0.522907.
Train: 2018-07-31T01:20:04.023128: step 14635, loss 0.522742.
Train: 2018-07-31T01:20:04.163721: step 14636, loss 0.514497.
Train: 2018-07-31T01:20:04.304336: step 14637, loss 0.554639.
Train: 2018-07-31T01:20:04.460527: step 14638, loss 0.554554.
Train: 2018-07-31T01:20:04.601118: step 14639, loss 0.603377.
Train: 2018-07-31T01:20:04.741710: step 14640, loss 0.562597.
Test: 2018-07-31T01:20:04.976061: step 14640, loss 0.548856.
Train: 2018-07-31T01:20:05.116659: step 14641, loss 0.538001.
Train: 2018-07-31T01:20:05.272837: step 14642, loss 0.521483.
Train: 2018-07-31T01:20:05.413428: step 14643, loss 0.521321.
Train: 2018-07-31T01:20:05.554020: step 14644, loss 0.562491.
Train: 2018-07-31T01:20:05.694637: step 14645, loss 0.662058.
Train: 2018-07-31T01:20:05.835203: step 14646, loss 0.620576.
Train: 2018-07-31T01:20:05.975797: step 14647, loss 0.650968.
Train: 2018-07-31T01:20:06.116388: step 14648, loss 0.521094.
Train: 2018-07-31T01:20:06.256989: step 14649, loss 0.562491.
Train: 2018-07-31T01:20:06.397572: step 14650, loss 0.496471.
Test: 2018-07-31T01:20:06.647515: step 14650, loss 0.548677.
Train: 2018-07-31T01:20:06.788105: step 14651, loss 0.554247.
Train: 2018-07-31T01:20:06.944319: step 14652, loss 0.620296.
Train: 2018-07-31T01:20:07.084911: step 14653, loss 0.504775.
Train: 2018-07-31T01:20:07.225504: step 14654, loss 0.53776.
Train: 2018-07-31T01:20:07.366096: step 14655, loss 0.512975.
Train: 2018-07-31T01:20:07.506688: step 14656, loss 0.595558.
Train: 2018-07-31T01:20:07.647278: step 14657, loss 0.562484.
Train: 2018-07-31T01:20:07.803493: step 14658, loss 0.521096.
Train: 2018-07-31T01:20:07.944085: step 14659, loss 0.56247.
Train: 2018-07-31T01:20:08.100322: step 14660, loss 0.562462.
Test: 2018-07-31T01:20:08.350241: step 14660, loss 0.54855.
Train: 2018-07-31T01:20:08.490850: step 14661, loss 0.612274.
Train: 2018-07-31T01:20:08.631448: step 14662, loss 0.554161.
Train: 2018-07-31T01:20:08.772015: step 14663, loss 0.595656.
Train: 2018-07-31T01:20:08.912632: step 14664, loss 0.620503.
Train: 2018-07-31T01:20:09.068822: step 14665, loss 0.504578.
Train: 2018-07-31T01:20:09.209438: step 14666, loss 0.562491.
Train: 2018-07-31T01:20:09.350006: step 14667, loss 0.562497.
Train: 2018-07-31T01:20:09.506220: step 14668, loss 0.579009.
Train: 2018-07-31T01:20:09.646829: step 14669, loss 0.620217.
Train: 2018-07-31T01:20:09.787428: step 14670, loss 0.554309.
Test: 2018-07-31T01:20:10.037375: step 14670, loss 0.548803.
Train: 2018-07-31T01:20:10.177954: step 14671, loss 0.546133.
Train: 2018-07-31T01:20:10.318528: step 14672, loss 0.595355.
Train: 2018-07-31T01:20:10.459120: step 14673, loss 0.488954.
Train: 2018-07-31T01:20:10.615374: step 14674, loss 0.521691.
Train: 2018-07-31T01:20:10.771549: step 14675, loss 0.587135.
Train: 2018-07-31T01:20:10.912139: step 14676, loss 0.619875.
Train: 2018-07-31T01:20:11.052731: step 14677, loss 0.578943.
Train: 2018-07-31T01:20:11.193323: step 14678, loss 0.562608.
Train: 2018-07-31T01:20:11.333922: step 14679, loss 0.481096.
Train: 2018-07-31T01:20:11.474509: step 14680, loss 0.529986.
Test: 2018-07-31T01:20:11.708830: step 14680, loss 0.548924.
Train: 2018-07-31T01:20:11.865042: step 14681, loss 0.497265.
Train: 2018-07-31T01:20:12.005658: step 14682, loss 0.554389.
Train: 2018-07-31T01:20:12.146226: step 14683, loss 0.472274.
Train: 2018-07-31T01:20:12.286842: step 14684, loss 0.595478.
Train: 2018-07-31T01:20:12.427438: step 14685, loss 0.529436.
Train: 2018-07-31T01:20:12.583648: step 14686, loss 0.620501.
Train: 2018-07-31T01:20:12.724216: step 14687, loss 0.628886.
Train: 2018-07-31T01:20:12.864826: step 14688, loss 0.545849.
Train: 2018-07-31T01:20:13.005425: step 14689, loss 0.537539.
Train: 2018-07-31T01:20:13.145993: step 14690, loss 0.612312.
Test: 2018-07-31T01:20:13.380342: step 14690, loss 0.548543.
Train: 2018-07-31T01:20:13.536526: step 14691, loss 0.545842.
Train: 2018-07-31T01:20:13.677117: step 14692, loss 0.579063.
Train: 2018-07-31T01:20:13.817708: step 14693, loss 0.579057.
Train: 2018-07-31T01:20:13.958326: step 14694, loss 0.512726.
Train: 2018-07-31T01:20:14.098894: step 14695, loss 0.496142.
Train: 2018-07-31T01:20:14.239510: step 14696, loss 0.620569.
Train: 2018-07-31T01:20:14.395724: step 14697, loss 0.603963.
Train: 2018-07-31T01:20:14.536291: step 14698, loss 0.628807.
Train: 2018-07-31T01:20:14.676908: step 14699, loss 0.587303.
Train: 2018-07-31T01:20:14.833098: step 14700, loss 0.513003.
Test: 2018-07-31T01:20:15.067443: step 14700, loss 0.548721.
Train: 2018-07-31T01:20:15.832886: step 14701, loss 0.562519.
Train: 2018-07-31T01:20:15.973454: step 14702, loss 0.529623.
Train: 2018-07-31T01:20:16.114071: step 14703, loss 0.611869.
Train: 2018-07-31T01:20:16.254638: step 14704, loss 0.505089.
Train: 2018-07-31T01:20:16.410852: step 14705, loss 0.595381.
Train: 2018-07-31T01:20:16.551444: step 14706, loss 0.570763.
Train: 2018-07-31T01:20:16.707658: step 14707, loss 0.554384.
Train: 2018-07-31T01:20:16.848275: step 14708, loss 0.570766.
Train: 2018-07-31T01:20:16.988866: step 14709, loss 0.562591.
Train: 2018-07-31T01:20:17.129484: step 14710, loss 0.652458.
Test: 2018-07-31T01:20:17.363784: step 14710, loss 0.548985.
Train: 2018-07-31T01:20:17.519968: step 14711, loss 0.595217.
Train: 2018-07-31T01:20:17.660584: step 14712, loss 0.497693.
Train: 2018-07-31T01:20:17.801153: step 14713, loss 0.595123.
Train: 2018-07-31T01:20:17.957366: step 14714, loss 0.538421.
Train: 2018-07-31T01:20:18.082381: step 14715, loss 0.603144.
Train: 2018-07-31T01:20:18.238567: step 14716, loss 0.562743.
Train: 2018-07-31T01:20:18.379147: step 14717, loss 0.530542.
Train: 2018-07-31T01:20:18.535354: step 14718, loss 0.554726.
Train: 2018-07-31T01:20:18.675971: step 14719, loss 0.562777.
Train: 2018-07-31T01:20:18.847781: step 14720, loss 0.554739.
Test: 2018-07-31T01:20:19.097754: step 14720, loss 0.549308.
Train: 2018-07-31T01:20:19.238316: step 14721, loss 0.578886.
Train: 2018-07-31T01:20:19.394530: step 14722, loss 0.611044.
Train: 2018-07-31T01:20:19.535145: step 14723, loss 0.586899.
Train: 2018-07-31T01:20:19.675713: step 14724, loss 0.546793.
Train: 2018-07-31T01:20:19.816322: step 14725, loss 0.546825.
Train: 2018-07-31T01:20:19.956933: step 14726, loss 0.4908.
Train: 2018-07-31T01:20:20.113111: step 14727, loss 0.538785.
Train: 2018-07-31T01:20:20.253703: step 14728, loss 0.586841.
Train: 2018-07-31T01:20:20.409917: step 14729, loss 0.546757.
Train: 2018-07-31T01:20:20.550532: step 14730, loss 0.603039.
Test: 2018-07-31T01:20:20.784828: step 14730, loss 0.54922.
Train: 2018-07-31T01:20:20.956664: step 14731, loss 0.562622.
Train: 2018-07-31T01:20:21.097272: step 14732, loss 0.489887.
Train: 2018-07-31T01:20:21.237847: step 14733, loss 0.595256.
Train: 2018-07-31T01:20:21.378440: step 14734, loss 0.481261.
Train: 2018-07-31T01:20:21.519055: step 14735, loss 0.5292.
Train: 2018-07-31T01:20:21.675268: step 14736, loss 0.562014.
Train: 2018-07-31T01:20:21.815837: step 14737, loss 0.571905.
Train: 2018-07-31T01:20:21.972050: step 14738, loss 0.57976.
Train: 2018-07-31T01:20:22.097045: step 14739, loss 0.595926.
Train: 2018-07-31T01:20:22.253235: step 14740, loss 0.547194.
Test: 2018-07-31T01:20:22.487556: step 14740, loss 0.548376.
Train: 2018-07-31T01:20:22.628146: step 14741, loss 0.528764.
Train: 2018-07-31T01:20:22.784359: step 14742, loss 0.561784.
Train: 2018-07-31T01:20:22.924952: step 14743, loss 0.5459.
Train: 2018-07-31T01:20:23.065545: step 14744, loss 0.49601.
Train: 2018-07-31T01:20:23.221757: step 14745, loss 0.521463.
Train: 2018-07-31T01:20:23.362349: step 14746, loss 0.519443.
Train: 2018-07-31T01:20:23.502965: step 14747, loss 0.578414.
Train: 2018-07-31T01:20:23.643558: step 14748, loss 0.529491.
Train: 2018-07-31T01:20:23.784125: step 14749, loss 0.56226.
Train: 2018-07-31T01:20:23.924717: step 14750, loss 0.582086.
Test: 2018-07-31T01:20:24.159063: step 14750, loss 0.54805.
Train: 2018-07-31T01:20:24.315303: step 14751, loss 0.570293.
Train: 2018-07-31T01:20:24.455868: step 14752, loss 0.595516.
Train: 2018-07-31T01:20:24.612081: step 14753, loss 0.553416.
Train: 2018-07-31T01:20:24.737026: step 14754, loss 0.596896.
Train: 2018-07-31T01:20:24.877650: step 14755, loss 0.511167.
Train: 2018-07-31T01:20:25.033833: step 14756, loss 0.688511.
Train: 2018-07-31T01:20:25.174426: step 14757, loss 0.58774.
Train: 2018-07-31T01:20:25.315043: step 14758, loss 0.528844.
Train: 2018-07-31T01:20:25.455633: step 14759, loss 0.603868.
Train: 2018-07-31T01:20:25.596201: step 14760, loss 0.537745.
Test: 2018-07-31T01:20:25.846173: step 14760, loss 0.548652.
Train: 2018-07-31T01:20:26.002356: step 14761, loss 0.521312.
Train: 2018-07-31T01:20:26.142972: step 14762, loss 0.562519.
Train: 2018-07-31T01:20:26.283558: step 14763, loss 0.636649.
Train: 2018-07-31T01:20:26.424157: step 14764, loss 0.505063.
Train: 2018-07-31T01:20:26.564749: step 14765, loss 0.562608.
Train: 2018-07-31T01:20:26.720938: step 14766, loss 0.554403.
Train: 2018-07-31T01:20:26.861531: step 14767, loss 0.538062.
Train: 2018-07-31T01:20:27.002147: step 14768, loss 0.562589.
Train: 2018-07-31T01:20:27.158340: step 14769, loss 0.538091.
Train: 2018-07-31T01:20:27.314550: step 14770, loss 0.53808.
Test: 2018-07-31T01:20:27.548900: step 14770, loss 0.548889.
Train: 2018-07-31T01:20:27.689478: step 14771, loss 0.562585.
Train: 2018-07-31T01:20:27.830052: step 14772, loss 0.538047.
Train: 2018-07-31T01:20:27.986290: step 14773, loss 0.578972.
Train: 2018-07-31T01:20:28.126883: step 14774, loss 0.546121.
Train: 2018-07-31T01:20:28.267450: step 14775, loss 0.513263.
Train: 2018-07-31T01:20:28.408068: step 14776, loss 0.53771.
Train: 2018-07-31T01:20:28.564257: step 14777, loss 0.612049.
Train: 2018-07-31T01:20:28.704873: step 14778, loss 0.612472.
Train: 2018-07-31T01:20:28.845440: step 14779, loss 0.562519.
Train: 2018-07-31T01:20:28.986057: step 14780, loss 0.645224.
Test: 2018-07-31T01:20:29.220383: step 14780, loss 0.548759.
Train: 2018-07-31T01:20:29.376566: step 14781, loss 0.52966.
Train: 2018-07-31T01:20:29.532803: step 14782, loss 0.488681.
Train: 2018-07-31T01:20:29.688992: step 14783, loss 0.595392.
Train: 2018-07-31T01:20:29.829584: step 14784, loss 0.554346.
Train: 2018-07-31T01:20:29.970177: step 14785, loss 0.546145.
Train: 2018-07-31T01:20:30.110768: step 14786, loss 0.562555.
Train: 2018-07-31T01:20:30.251361: step 14787, loss 0.620002.
Train: 2018-07-31T01:20:30.391953: step 14788, loss 0.587157.
Train: 2018-07-31T01:20:30.516923: step 14789, loss 0.578949.
Train: 2018-07-31T01:20:30.657516: step 14790, loss 0.595276.
Test: 2018-07-31T01:20:30.907459: step 14790, loss 0.549028.
Train: 2018-07-31T01:20:31.048050: step 14791, loss 0.587075.
Train: 2018-07-31T01:20:31.204288: step 14792, loss 0.643936.
Train: 2018-07-31T01:20:31.344880: step 14793, loss 0.5708.
Train: 2018-07-31T01:20:31.501069: step 14794, loss 0.554692.
Train: 2018-07-31T01:20:31.641660: step 14795, loss 0.602982.
Train: 2018-07-31T01:20:31.797875: step 14796, loss 0.514814.
Train: 2018-07-31T01:20:31.938465: step 14797, loss 0.530932.
Train: 2018-07-31T01:20:32.079083: step 14798, loss 0.630987.
Train: 2018-07-31T01:20:32.235272: step 14799, loss 0.547025.
Train: 2018-07-31T01:20:32.375889: step 14800, loss 0.578859.
Test: 2018-07-31T01:20:32.625830: step 14800, loss 0.54972.
Train: 2018-07-31T01:20:33.391293: step 14801, loss 0.594718.
Train: 2018-07-31T01:20:33.531867: step 14802, loss 0.547215.
Train: 2018-07-31T01:20:33.688080: step 14803, loss 0.539365.
Train: 2018-07-31T01:20:33.844294: step 14804, loss 0.499923.
Train: 2018-07-31T01:20:33.984886: step 14805, loss 0.539353.
Train: 2018-07-31T01:20:34.125456: step 14806, loss 0.602602.
Train: 2018-07-31T01:20:34.266064: step 14807, loss 0.507576.
Train: 2018-07-31T01:20:34.406673: step 14808, loss 0.547103.
Train: 2018-07-31T01:20:34.562852: step 14809, loss 0.594784.
Train: 2018-07-31T01:20:34.703470: step 14810, loss 0.547005.
Test: 2018-07-31T01:20:34.937795: step 14810, loss 0.549515.
Train: 2018-07-31T01:20:35.093977: step 14811, loss 0.562911.
Train: 2018-07-31T01:20:35.234570: step 14812, loss 0.498891.
Train: 2018-07-31T01:20:35.375162: step 14813, loss 0.546743.
Train: 2018-07-31T01:20:35.531374: step 14814, loss 0.514433.
Train: 2018-07-31T01:20:35.671967: step 14815, loss 0.546694.
Train: 2018-07-31T01:20:35.812561: step 14816, loss 0.587081.
Train: 2018-07-31T01:20:35.953150: step 14817, loss 0.570646.
Train: 2018-07-31T01:20:36.109380: step 14818, loss 0.546224.
Train: 2018-07-31T01:20:36.249969: step 14819, loss 0.488606.
Train: 2018-07-31T01:20:36.390550: step 14820, loss 0.603482.
Test: 2018-07-31T01:20:36.624899: step 14820, loss 0.54858.
Train: 2018-07-31T01:20:36.765461: step 14821, loss 0.520837.
Train: 2018-07-31T01:20:36.906052: step 14822, loss 0.554385.
Train: 2018-07-31T01:20:37.046669: step 14823, loss 0.553679.
Train: 2018-07-31T01:20:37.187236: step 14824, loss 0.452567.
Train: 2018-07-31T01:20:37.343475: step 14825, loss 0.622145.
Train: 2018-07-31T01:20:37.484043: step 14826, loss 0.547273.
Train: 2018-07-31T01:20:37.624634: step 14827, loss 0.517752.
Train: 2018-07-31T01:20:37.780848: step 14828, loss 0.5516.
Train: 2018-07-31T01:20:37.921464: step 14829, loss 0.572379.
Train: 2018-07-31T01:20:38.062033: step 14830, loss 0.537281.
Test: 2018-07-31T01:20:38.311974: step 14830, loss 0.547504.
Train: 2018-07-31T01:20:38.452565: step 14831, loss 0.562922.
Train: 2018-07-31T01:20:38.608780: step 14832, loss 0.527405.
Train: 2018-07-31T01:20:38.749396: step 14833, loss 0.537265.
Train: 2018-07-31T01:20:38.889987: step 14834, loss 0.577661.
Train: 2018-07-31T01:20:39.046176: step 14835, loss 0.494704.
Train: 2018-07-31T01:20:39.186786: step 14836, loss 0.491519.
Train: 2018-07-31T01:20:39.342982: step 14837, loss 0.493953.
Train: 2018-07-31T01:20:39.499196: step 14838, loss 0.60702.
Train: 2018-07-31T01:20:39.624191: step 14839, loss 0.564169.
Train: 2018-07-31T01:20:39.764792: step 14840, loss 0.639655.
Test: 2018-07-31T01:20:40.014699: step 14840, loss 0.547507.
Train: 2018-07-31T01:20:40.155291: step 14841, loss 0.644117.
Train: 2018-07-31T01:20:40.295908: step 14842, loss 0.526807.
Train: 2018-07-31T01:20:40.452099: step 14843, loss 0.519823.
Train: 2018-07-31T01:20:40.577069: step 14844, loss 0.545339.
Train: 2018-07-31T01:20:40.733282: step 14845, loss 0.553717.
Train: 2018-07-31T01:20:40.873874: step 14846, loss 0.613491.
Train: 2018-07-31T01:20:41.014489: step 14847, loss 0.545418.
Train: 2018-07-31T01:20:41.170679: step 14848, loss 0.579278.
Train: 2018-07-31T01:20:41.311270: step 14849, loss 0.612969.
Train: 2018-07-31T01:20:41.451864: step 14850, loss 0.596013.
Test: 2018-07-31T01:20:41.701835: step 14850, loss 0.548369.
Train: 2018-07-31T01:20:41.842396: step 14851, loss 0.629422.
Train: 2018-07-31T01:20:41.982989: step 14852, loss 0.479044.
Train: 2018-07-31T01:20:42.123582: step 14853, loss 0.579077.
Train: 2018-07-31T01:20:42.264173: step 14854, loss 0.587344.
Train: 2018-07-31T01:20:42.420388: step 14855, loss 0.645158.
Train: 2018-07-31T01:20:42.560980: step 14856, loss 0.603672.
Train: 2018-07-31T01:20:42.701571: step 14857, loss 0.587138.
Train: 2018-07-31T01:20:42.842162: step 14858, loss 0.530053.
Train: 2018-07-31T01:20:42.982755: step 14859, loss 0.587016.
Train: 2018-07-31T01:20:43.123346: step 14860, loss 0.595047.
Test: 2018-07-31T01:20:43.357693: step 14860, loss 0.549312.
Train: 2018-07-31T01:20:43.529527: step 14861, loss 0.65932.
Train: 2018-07-31T01:20:43.685740: step 14862, loss 0.56287.
Train: 2018-07-31T01:20:43.826332: step 14863, loss 0.578859.
Train: 2018-07-31T01:20:43.966924: step 14864, loss 0.586774.
Train: 2018-07-31T01:20:44.107491: step 14865, loss 0.61824.
Train: 2018-07-31T01:20:44.248082: step 14866, loss 0.539726.
Train: 2018-07-31T01:20:44.388701: step 14867, loss 0.5633.
Train: 2018-07-31T01:20:44.529267: step 14868, loss 0.48569.
Train: 2018-07-31T01:20:44.669883: step 14869, loss 0.555639.
Train: 2018-07-31T01:20:44.826074: step 14870, loss 0.586671.
Test: 2018-07-31T01:20:45.060424: step 14870, loss 0.550598.
Train: 2018-07-31T01:20:45.216607: step 14871, loss 0.571176.
Train: 2018-07-31T01:20:45.357198: step 14872, loss 0.532488.
Train: 2018-07-31T01:20:45.497791: step 14873, loss 0.633118.
Train: 2018-07-31T01:20:45.638384: step 14874, loss 0.625329.
Train: 2018-07-31T01:20:45.778975: step 14875, loss 0.60209.
Train: 2018-07-31T01:20:45.919567: step 14876, loss 0.663607.
Train: 2018-07-31T01:20:46.060158: step 14877, loss 0.48706.
Train: 2018-07-31T01:20:46.200775: step 14878, loss 0.571356.
Train: 2018-07-31T01:20:46.341342: step 14879, loss 0.632457.
Train: 2018-07-31T01:20:46.497581: step 14880, loss 0.518127.
Test: 2018-07-31T01:20:46.747499: step 14880, loss 0.551097.
Train: 2018-07-31T01:20:46.888089: step 14881, loss 0.639887.
Train: 2018-07-31T01:20:47.044304: step 14882, loss 0.63976.
Train: 2018-07-31T01:20:47.184920: step 14883, loss 0.609329.
Train: 2018-07-31T01:20:47.325512: step 14884, loss 0.579145.
Train: 2018-07-31T01:20:47.466079: step 14885, loss 0.639169.
Train: 2018-07-31T01:20:47.606671: step 14886, loss 0.564306.
Train: 2018-07-31T01:20:47.762885: step 14887, loss 0.586715.
Train: 2018-07-31T01:20:47.903477: step 14888, loss 0.579325.
Train: 2018-07-31T01:20:48.044094: step 14889, loss 0.535067.
Train: 2018-07-31T01:20:48.200282: step 14890, loss 0.535162.
Test: 2018-07-31T01:20:48.434605: step 14890, loss 0.552309.
Train: 2018-07-31T01:20:48.575195: step 14891, loss 0.586763.
Train: 2018-07-31T01:20:48.731408: step 14892, loss 0.594134.
Train: 2018-07-31T01:20:48.872002: step 14893, loss 0.54994.
Train: 2018-07-31T01:20:49.012592: step 14894, loss 0.535179.
Train: 2018-07-31T01:20:49.168806: step 14895, loss 0.490788.
Train: 2018-07-31T01:20:49.309422: step 14896, loss 0.623788.
Train: 2018-07-31T01:20:49.450015: step 14897, loss 0.557012.
Train: 2018-07-31T01:20:49.590581: step 14898, loss 0.571804.
Train: 2018-07-31T01:20:49.731192: step 14899, loss 0.564263.
Train: 2018-07-31T01:20:49.871803: step 14900, loss 0.571687.
Test: 2018-07-31T01:20:50.121708: step 14900, loss 0.551525.
Train: 2018-07-31T01:20:50.840290: step 14901, loss 0.541547.
Train: 2018-07-31T01:20:50.980881: step 14902, loss 0.601736.
Train: 2018-07-31T01:20:51.121473: step 14903, loss 0.510921.
Train: 2018-07-31T01:20:51.262066: step 14904, loss 0.533455.
Train: 2018-07-31T01:20:51.402657: step 14905, loss 0.586586.
Train: 2018-07-31T01:20:51.543250: step 14906, loss 0.56358.
Train: 2018-07-31T01:20:51.683842: step 14907, loss 0.517085.
Train: 2018-07-31T01:20:51.824434: step 14908, loss 0.501205.
Train: 2018-07-31T01:20:51.980665: step 14909, loss 0.594903.
Train: 2018-07-31T01:20:52.121263: step 14910, loss 0.578128.
Test: 2018-07-31T01:20:52.355591: step 14910, loss 0.549559.
Train: 2018-07-31T01:20:52.496176: step 14911, loss 0.603847.
Train: 2018-07-31T01:20:52.636769: step 14912, loss 0.633655.
Train: 2018-07-31T01:20:52.777337: step 14913, loss 0.506386.
Train: 2018-07-31T01:20:52.917927: step 14914, loss 0.602392.
Train: 2018-07-31T01:20:53.074166: step 14915, loss 0.603447.
Train: 2018-07-31T01:20:53.230356: step 14916, loss 0.571033.
Train: 2018-07-31T01:20:53.370971: step 14917, loss 0.611481.
Train: 2018-07-31T01:20:53.511539: step 14918, loss 0.546643.
Train: 2018-07-31T01:20:53.652155: step 14919, loss 0.498877.
Train: 2018-07-31T01:20:53.792723: step 14920, loss 0.54621.
Test: 2018-07-31T01:20:54.027074: step 14920, loss 0.549298.
Train: 2018-07-31T01:20:54.167660: step 14921, loss 0.531216.
Train: 2018-07-31T01:20:54.323849: step 14922, loss 0.545709.
Train: 2018-07-31T01:20:54.464441: step 14923, loss 0.570578.
Train: 2018-07-31T01:20:54.605034: step 14924, loss 0.51324.
Train: 2018-07-31T01:20:54.745650: step 14925, loss 0.564131.
Train: 2018-07-31T01:20:54.886241: step 14926, loss 0.611818.
Train: 2018-07-31T01:20:55.042454: step 14927, loss 0.568807.
Train: 2018-07-31T01:20:55.183023: step 14928, loss 0.539183.
Train: 2018-07-31T01:20:55.323615: step 14929, loss 0.496752.
Train: 2018-07-31T01:20:55.479827: step 14930, loss 0.579265.
Test: 2018-07-31T01:20:55.714174: step 14930, loss 0.548393.
Train: 2018-07-31T01:20:55.870386: step 14931, loss 0.524563.
Train: 2018-07-31T01:20:56.010953: step 14932, loss 0.536381.
Train: 2018-07-31T01:20:56.151547: step 14933, loss 0.529022.
Train: 2018-07-31T01:20:56.292138: step 14934, loss 0.539425.
Train: 2018-07-31T01:20:56.432755: step 14935, loss 0.520578.
Train: 2018-07-31T01:20:56.573322: step 14936, loss 0.580157.
Train: 2018-07-31T01:20:56.729561: step 14937, loss 0.511704.
Train: 2018-07-31T01:20:56.901370: step 14938, loss 0.545756.
Train: 2018-07-31T01:20:57.041962: step 14939, loss 0.587375.
Train: 2018-07-31T01:20:57.182554: step 14940, loss 0.613771.
Test: 2018-07-31T01:20:57.432496: step 14940, loss 0.548237.
Train: 2018-07-31T01:20:57.573088: step 14941, loss 0.537164.
Train: 2018-07-31T01:20:57.729301: step 14942, loss 0.528212.
Train: 2018-07-31T01:20:57.869893: step 14943, loss 0.460459.
Train: 2018-07-31T01:20:58.026108: step 14944, loss 0.503311.
Train: 2018-07-31T01:20:58.166716: step 14945, loss 0.587931.
Train: 2018-07-31T01:20:58.307291: step 14946, loss 0.58905.
Train: 2018-07-31T01:20:58.447907: step 14947, loss 0.484439.
Train: 2018-07-31T01:20:58.588500: step 14948, loss 0.616073.
Train: 2018-07-31T01:20:58.729091: step 14949, loss 0.508482.
Train: 2018-07-31T01:20:58.869660: step 14950, loss 0.621514.
Test: 2018-07-31T01:20:59.119631: step 14950, loss 0.547905.
Train: 2018-07-31T01:20:59.275816: step 14951, loss 0.536247.
Train: 2018-07-31T01:20:59.416405: step 14952, loss 0.519211.
Train: 2018-07-31T01:20:59.556998: step 14953, loss 0.587731.
Train: 2018-07-31T01:20:59.713213: step 14954, loss 0.53698.
Train: 2018-07-31T01:20:59.853829: step 14955, loss 0.631391.
Train: 2018-07-31T01:20:59.994421: step 14956, loss 0.544961.
Train: 2018-07-31T01:21:00.135013: step 14957, loss 0.604121.
Train: 2018-07-31T01:21:00.291202: step 14958, loss 0.553479.
Train: 2018-07-31T01:21:00.431819: step 14959, loss 0.571393.
Train: 2018-07-31T01:21:00.572387: step 14960, loss 0.56215.
Test: 2018-07-31T01:21:00.806707: step 14960, loss 0.548204.
Train: 2018-07-31T01:21:00.962921: step 14961, loss 0.553654.
Train: 2018-07-31T01:21:01.103512: step 14962, loss 0.613211.
Train: 2018-07-31T01:21:01.244103: step 14963, loss 0.469712.
Train: 2018-07-31T01:21:01.400341: step 14964, loss 0.587486.
Train: 2018-07-31T01:21:01.540910: step 14965, loss 0.554186.
Train: 2018-07-31T01:21:01.681500: step 14966, loss 0.570634.
Train: 2018-07-31T01:21:01.837715: step 14967, loss 0.579.
Train: 2018-07-31T01:21:01.978307: step 14968, loss 0.571094.
Train: 2018-07-31T01:21:02.118898: step 14969, loss 0.629474.
Train: 2018-07-31T01:21:02.275112: step 14970, loss 0.653438.
Test: 2018-07-31T01:21:02.509463: step 14970, loss 0.548678.
Train: 2018-07-31T01:21:02.665645: step 14971, loss 0.595612.
Train: 2018-07-31T01:21:02.806238: step 14972, loss 0.50512.
Train: 2018-07-31T01:21:02.931207: step 14973, loss 0.505438.
Train: 2018-07-31T01:21:03.071800: step 14974, loss 0.562612.
Train: 2018-07-31T01:21:03.228038: step 14975, loss 0.570828.
Train: 2018-07-31T01:21:03.368605: step 14976, loss 0.554607.
Train: 2018-07-31T01:21:03.524833: step 14977, loss 0.530193.
Train: 2018-07-31T01:21:03.665412: step 14978, loss 0.522128.
Train: 2018-07-31T01:21:03.806004: step 14979, loss 0.546463.
Train: 2018-07-31T01:21:03.946597: step 14980, loss 0.530201.
Test: 2018-07-31T01:21:04.196538: step 14980, loss 0.549045.
Train: 2018-07-31T01:21:04.337128: step 14981, loss 0.49762.
Train: 2018-07-31T01:21:04.477721: step 14982, loss 0.497416.
Train: 2018-07-31T01:21:04.618359: step 14983, loss 0.611675.
Train: 2018-07-31T01:21:04.758905: step 14984, loss 0.619972.
Train: 2018-07-31T01:21:04.899522: step 14985, loss 0.56255.
Train: 2018-07-31T01:21:05.040114: step 14986, loss 0.570761.
Train: 2018-07-31T01:21:05.180706: step 14987, loss 0.496794.
Train: 2018-07-31T01:21:05.321273: step 14988, loss 0.570758.
Train: 2018-07-31T01:21:05.477488: step 14989, loss 0.546024.
Train: 2018-07-31T01:21:05.618081: step 14990, loss 0.678096.
Test: 2018-07-31T01:21:05.868051: step 14990, loss 0.548698.
Train: 2018-07-31T01:21:06.008629: step 14991, loss 0.537764.
Train: 2018-07-31T01:21:06.149229: step 14992, loss 0.579001.
Train: 2018-07-31T01:21:06.289822: step 14993, loss 0.537809.
Train: 2018-07-31T01:21:06.430389: step 14994, loss 0.562523.
Train: 2018-07-31T01:21:06.570982: step 14995, loss 0.554293.
Train: 2018-07-31T01:21:06.711597: step 14996, loss 0.546065.
Train: 2018-07-31T01:21:06.867787: step 14997, loss 0.611918.
Train: 2018-07-31T01:21:07.008378: step 14998, loss 0.521411.
Train: 2018-07-31T01:21:07.148996: step 14999, loss 0.48029.
Train: 2018-07-31T01:21:07.289591: step 15000, loss 0.537805.
Test: 2018-07-31T01:21:07.539534: step 15000, loss 0.548684.
Train: 2018-07-31T01:21:08.289352: step 15001, loss 0.57901.
Train: 2018-07-31T01:21:08.429919: step 15002, loss 0.570756.
Train: 2018-07-31T01:21:08.570530: step 15003, loss 0.545937.
Train: 2018-07-31T01:21:08.711104: step 15004, loss 0.545908.
Train: 2018-07-31T01:21:08.851742: step 15005, loss 0.579052.
Train: 2018-07-31T01:21:09.023531: step 15006, loss 0.620558.
Train: 2018-07-31T01:21:09.179746: step 15007, loss 0.554168.
Train: 2018-07-31T01:21:09.320362: step 15008, loss 0.562466.
Train: 2018-07-31T01:21:09.476551: step 15009, loss 0.56247.
Train: 2018-07-31T01:21:09.617167: step 15010, loss 0.512773.
Test: 2018-07-31T01:21:09.851464: step 15010, loss 0.54859.
Train: 2018-07-31T01:21:10.007700: step 15011, loss 0.554182.
Train: 2018-07-31T01:21:10.210754: step 15012, loss 0.587342.
Train: 2018-07-31T01:21:10.351345: step 15013, loss 0.554175.
Train: 2018-07-31T01:21:10.507585: step 15014, loss 0.58734.
Train: 2018-07-31T01:21:10.648152: step 15015, loss 0.512752.
Train: 2018-07-31T01:21:10.788743: step 15016, loss 0.504438.
Train: 2018-07-31T01:21:10.929334: step 15017, loss 0.529248.
Train: 2018-07-31T01:21:11.069927: step 15018, loss 0.537488.
Train: 2018-07-31T01:21:11.210544: step 15019, loss 0.53742.
Train: 2018-07-31T01:21:11.351112: step 15020, loss 0.462145.
Test: 2018-07-31T01:21:11.601054: step 15020, loss 0.548343.
Train: 2018-07-31T01:21:11.741670: step 15021, loss 0.621118.
Train: 2018-07-31T01:21:11.882263: step 15022, loss 0.579199.
Train: 2018-07-31T01:21:12.038507: step 15023, loss 0.570797.
Train: 2018-07-31T01:21:12.179067: step 15024, loss 0.570801.
Train: 2018-07-31T01:21:12.319635: step 15025, loss 0.579241.
Train: 2018-07-31T01:21:12.491469: step 15026, loss 0.562367.
Train: 2018-07-31T01:21:12.632086: step 15027, loss 0.494869.
Train: 2018-07-31T01:21:12.788275: step 15028, loss 0.613045.
Train: 2018-07-31T01:21:12.944512: step 15029, loss 0.579255.
Train: 2018-07-31T01:21:13.085105: step 15030, loss 0.604568.
Test: 2018-07-31T01:21:13.335023: step 15030, loss 0.548257.
Train: 2018-07-31T01:21:13.475614: step 15031, loss 0.587654.
Train: 2018-07-31T01:21:13.631828: step 15032, loss 0.579201.
Train: 2018-07-31T01:21:13.772445: step 15033, loss 0.579173.
Train: 2018-07-31T01:21:13.928633: step 15034, loss 0.537299.
Train: 2018-07-31T01:21:14.069250: step 15035, loss 0.629239.
Train: 2018-07-31T01:21:14.209817: step 15036, loss 0.612394.
Train: 2018-07-31T01:21:14.350409: step 15037, loss 0.545879.
Train: 2018-07-31T01:21:14.506621: step 15038, loss 0.570756.
Train: 2018-07-31T01:21:14.647216: step 15039, loss 0.636662.
Train: 2018-07-31T01:21:14.787807: step 15040, loss 0.595364.
Test: 2018-07-31T01:21:15.022158: step 15040, loss 0.548942.
Train: 2018-07-31T01:21:15.193985: step 15041, loss 0.529965.
Train: 2018-07-31T01:21:15.334577: step 15042, loss 0.562651.
Train: 2018-07-31T01:21:15.475164: step 15043, loss 0.554585.
Train: 2018-07-31T01:21:15.631383: step 15044, loss 0.586971.
Train: 2018-07-31T01:21:15.771952: step 15045, loss 0.522472.
Train: 2018-07-31T01:21:15.928189: step 15046, loss 0.683444.
Train: 2018-07-31T01:21:16.068758: step 15047, loss 0.49876.
Train: 2018-07-31T01:21:16.209349: step 15048, loss 0.610832.
Train: 2018-07-31T01:21:16.349941: step 15049, loss 0.531048.
Train: 2018-07-31T01:21:16.490534: step 15050, loss 0.531137.
Test: 2018-07-31T01:21:16.724854: step 15050, loss 0.549657.
Train: 2018-07-31T01:21:16.865469: step 15051, loss 0.547072.
Train: 2018-07-31T01:21:17.021683: step 15052, loss 0.594747.
Train: 2018-07-31T01:21:17.162251: step 15053, loss 0.499487.
Train: 2018-07-31T01:21:17.302843: step 15054, loss 0.570915.
Train: 2018-07-31T01:21:17.474678: step 15055, loss 0.594755.
Train: 2018-07-31T01:21:17.615287: step 15056, loss 0.57091.
Train: 2018-07-31T01:21:17.755880: step 15057, loss 0.547068.
Train: 2018-07-31T01:21:17.912075: step 15058, loss 0.547055.
Train: 2018-07-31T01:21:18.068288: step 15059, loss 0.499284.
Train: 2018-07-31T01:21:18.208905: step 15060, loss 0.562909.
Test: 2018-07-31T01:21:18.458852: step 15060, loss 0.54949.
Train: 2018-07-31T01:21:18.599440: step 15061, loss 0.506926.
Train: 2018-07-31T01:21:18.755628: step 15062, loss 0.498678.
Train: 2018-07-31T01:21:18.896219: step 15063, loss 0.562769.
Train: 2018-07-31T01:21:19.052433: step 15064, loss 0.546544.
Train: 2018-07-31T01:21:19.193024: step 15065, loss 0.489602.
Train: 2018-07-31T01:21:19.349262: step 15066, loss 0.627894.
Train: 2018-07-31T01:21:19.489855: step 15067, loss 0.472526.
Train: 2018-07-31T01:21:19.630432: step 15068, loss 0.60366.
Train: 2018-07-31T01:21:19.771039: step 15069, loss 0.537744.
Train: 2018-07-31T01:21:19.927252: step 15070, loss 0.612165.
Test: 2018-07-31T01:21:20.177170: step 15070, loss 0.548562.
Train: 2018-07-31T01:21:20.317762: step 15071, loss 0.637145.
Train: 2018-07-31T01:21:20.473976: step 15072, loss 0.595659.
Train: 2018-07-31T01:21:20.614567: step 15073, loss 0.520985.
Train: 2018-07-31T01:21:20.770781: step 15074, loss 0.537568.
Train: 2018-07-31T01:21:20.911373: step 15075, loss 0.512637.
Train: 2018-07-31T01:21:21.067586: step 15076, loss 0.570761.
Train: 2018-07-31T01:21:21.208179: step 15077, loss 0.612387.
Train: 2018-07-31T01:21:21.348772: step 15078, loss 0.54579.
Train: 2018-07-31T01:21:21.489413: step 15079, loss 0.587413.
Train: 2018-07-31T01:21:21.645575: step 15080, loss 0.495869.
Test: 2018-07-31T01:21:21.879926: step 15080, loss 0.548487.
Train: 2018-07-31T01:21:22.020541: step 15081, loss 0.58742.
Train: 2018-07-31T01:21:22.176702: step 15082, loss 0.554105.
Train: 2018-07-31T01:21:22.317294: step 15083, loss 0.504114.
Train: 2018-07-31T01:21:22.457885: step 15084, loss 0.512375.
Train: 2018-07-31T01:21:22.598476: step 15085, loss 0.57913.
Train: 2018-07-31T01:21:22.739095: step 15086, loss 0.487073.
Train: 2018-07-31T01:21:22.879662: step 15087, loss 0.621136.
Train: 2018-07-31T01:21:23.035876: step 15088, loss 0.604391.
Train: 2018-07-31T01:21:23.176492: step 15089, loss 0.579188.
Train: 2018-07-31T01:21:23.317060: step 15090, loss 0.537198.
Test: 2018-07-31T01:21:23.551412: step 15090, loss 0.548327.
Train: 2018-07-31T01:21:23.707594: step 15091, loss 0.570785.
Train: 2018-07-31T01:21:23.848210: step 15092, loss 0.537211.
Train: 2018-07-31T01:21:23.988794: step 15093, loss 0.595964.
Train: 2018-07-31T01:21:24.129371: step 15094, loss 0.453361.
Train: 2018-07-31T01:21:24.269986: step 15095, loss 0.60438.
Train: 2018-07-31T01:21:24.410553: step 15096, loss 0.579187.
Train: 2018-07-31T01:21:24.566767: step 15097, loss 0.612779.
Train: 2018-07-31T01:21:24.722980: step 15098, loss 0.60433.
Train: 2018-07-31T01:21:24.863597: step 15099, loss 0.620989.
Train: 2018-07-31T01:21:25.004189: step 15100, loss 0.633609.
Test: 2018-07-31T01:21:25.238515: step 15100, loss 0.548546.
