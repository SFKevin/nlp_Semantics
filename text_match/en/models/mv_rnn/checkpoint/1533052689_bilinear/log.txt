Train: 2018-07-31T23:58:17.010871: step 1, loss 1.32014.
Train: 2018-07-31T23:58:17.229539: step 2, loss 1.20435.
Train: 2018-07-31T23:58:17.416997: step 3, loss 1.10122.
Train: 2018-07-31T23:58:17.604480: step 4, loss 1.07719.
Train: 2018-07-31T23:58:17.791940: step 5, loss 1.03891.
Train: 2018-07-31T23:58:17.994984: step 6, loss 0.859644.
Train: 2018-07-31T23:58:18.182472: step 7, loss 0.791706.
Train: 2018-07-31T23:58:18.369922: step 8, loss 0.861828.
Train: 2018-07-31T23:58:18.573005: step 9, loss 0.700604.
Train: 2018-07-31T23:58:18.760460: step 10, loss 0.76075.
Test: 2018-07-31T23:58:19.463421: step 10, loss 0.711904.
Train: 2018-07-31T23:58:19.650846: step 11, loss 0.819863.
Train: 2018-07-31T23:58:19.838329: step 12, loss 0.646583.
Train: 2018-07-31T23:58:20.025791: step 13, loss 0.689762.
Train: 2018-07-31T23:58:20.213246: step 14, loss 0.68041.
Train: 2018-07-31T23:58:20.400671: step 15, loss 0.736992.
Train: 2018-07-31T23:58:20.572506: step 16, loss 0.64468.
Train: 2018-07-31T23:58:20.759962: step 17, loss 0.652649.
Train: 2018-07-31T23:58:20.947448: step 18, loss 0.621241.
Train: 2018-07-31T23:58:21.134898: step 19, loss 0.514329.
Train: 2018-07-31T23:58:21.306738: step 20, loss 0.688501.
Test: 2018-07-31T23:58:21.791005: step 20, loss 0.626356.
Train: 2018-07-31T23:58:21.962805: step 21, loss 0.715671.
Train: 2018-07-31T23:58:22.150262: step 22, loss 0.74364.
Train: 2018-07-31T23:58:22.337747: step 23, loss 0.63149.
Train: 2018-07-31T23:58:22.525174: step 24, loss 0.595832.
Train: 2018-07-31T23:58:22.712654: step 25, loss 0.647048.
Train: 2018-07-31T23:58:22.900117: step 26, loss 0.581087.
Train: 2018-07-31T23:58:23.071920: step 27, loss 0.608566.
Train: 2018-07-31T23:58:23.259406: step 28, loss 0.591979.
Train: 2018-07-31T23:58:23.446864: step 29, loss 0.683857.
Train: 2018-07-31T23:58:23.634314: step 30, loss 0.512926.
Test: 2018-07-31T23:58:24.102959: step 30, loss 0.600646.
Train: 2018-07-31T23:58:24.290385: step 31, loss 0.761579.
Train: 2018-07-31T23:58:24.477841: step 32, loss 0.58481.
Train: 2018-07-31T23:58:24.665331: step 33, loss 0.657821.
Train: 2018-07-31T23:58:24.837132: step 34, loss 0.545515.
Train: 2018-07-31T23:58:25.024588: step 35, loss 0.594231.
Train: 2018-07-31T23:58:25.196453: step 36, loss 0.65666.
Train: 2018-07-31T23:58:25.383909: step 37, loss 0.57154.
Train: 2018-07-31T23:58:25.571365: step 38, loss 0.484951.
Train: 2018-07-31T23:58:25.758822: step 39, loss 0.5837.
Train: 2018-07-31T23:58:25.946279: step 40, loss 0.675776.
Test: 2018-07-31T23:58:26.430539: step 40, loss 0.58555.
Train: 2018-07-31T23:58:26.602343: step 41, loss 0.685868.
Train: 2018-07-31T23:58:26.789800: step 42, loss 0.609794.
Train: 2018-07-31T23:58:26.992908: step 43, loss 0.591206.
Train: 2018-07-31T23:58:27.180363: step 44, loss 0.598434.
Train: 2018-07-31T23:58:27.352198: step 45, loss 0.63393.
Train: 2018-07-31T23:58:27.539658: step 46, loss 0.612276.
Train: 2018-07-31T23:58:27.727082: step 47, loss 0.613193.
Train: 2018-07-31T23:58:27.914537: step 48, loss 0.617858.
Train: 2018-07-31T23:58:28.102024: step 49, loss 0.680391.
Train: 2018-07-31T23:58:28.289482: step 50, loss 0.586454.
Test: 2018-07-31T23:58:28.758091: step 50, loss 0.584957.
Train: 2018-07-31T23:58:28.945546: step 51, loss 0.610309.
Train: 2018-07-31T23:58:29.133001: step 52, loss 0.565665.
Train: 2018-07-31T23:58:29.320487: step 53, loss 0.642725.
Train: 2018-07-31T23:58:29.507938: step 54, loss 0.53727.
Train: 2018-07-31T23:58:29.695399: step 55, loss 0.534659.
Train: 2018-07-31T23:58:29.882850: step 56, loss 0.611647.
Train: 2018-07-31T23:58:30.070312: step 57, loss 0.559049.
Train: 2018-07-31T23:58:30.242147: step 58, loss 0.554057.
Train: 2018-07-31T23:58:30.429572: step 59, loss 0.675951.
Train: 2018-07-31T23:58:30.617028: step 60, loss 0.68847.
Test: 2018-07-31T23:58:31.101322: step 60, loss 0.569317.
Train: 2018-07-31T23:58:31.273155: step 61, loss 0.533244.
Train: 2018-07-31T23:58:31.460581: step 62, loss 0.656676.
Train: 2018-07-31T23:58:31.648037: step 63, loss 0.660791.
Train: 2018-07-31T23:58:31.835492: step 64, loss 0.531851.
Train: 2018-07-31T23:58:32.022980: step 65, loss 0.550432.
Train: 2018-07-31T23:58:32.210431: step 66, loss 0.586066.
Train: 2018-07-31T23:58:32.397892: step 67, loss 0.702104.
Train: 2018-07-31T23:58:32.585342: step 68, loss 0.617294.
Train: 2018-07-31T23:58:32.772804: step 69, loss 0.6494.
Train: 2018-07-31T23:58:32.960231: step 70, loss 0.577206.
Test: 2018-07-31T23:58:33.428900: step 70, loss 0.575876.
Train: 2018-07-31T23:58:33.616356: step 71, loss 0.609162.
Train: 2018-07-31T23:58:33.803783: step 72, loss 0.595878.
Train: 2018-07-31T23:58:33.991239: step 73, loss 0.651233.
Train: 2018-07-31T23:58:34.178725: step 74, loss 0.643824.
Train: 2018-07-31T23:58:34.366151: step 75, loss 0.519878.
Train: 2018-07-31T23:58:34.553637: step 76, loss 0.53755.
Train: 2018-07-31T23:58:34.741093: step 77, loss 0.536873.
Train: 2018-07-31T23:58:34.928519: step 78, loss 0.599238.
Train: 2018-07-31T23:58:35.116005: step 79, loss 0.491688.
Train: 2018-07-31T23:58:35.303430: step 80, loss 0.608545.
Test: 2018-07-31T23:58:35.756482: step 80, loss 0.567178.
Train: 2018-07-31T23:58:35.943906: step 81, loss 0.655005.
Train: 2018-07-31T23:58:36.131392: step 82, loss 0.418632.
Train: 2018-07-31T23:58:36.318843: step 83, loss 0.523175.
Train: 2018-07-31T23:58:36.506301: step 84, loss 0.676268.
Train: 2018-07-31T23:58:36.693755: step 85, loss 0.534547.
Train: 2018-07-31T23:58:36.881212: step 86, loss 0.63342.
Train: 2018-07-31T23:58:37.053052: step 87, loss 0.439909.
Train: 2018-07-31T23:58:37.240508: step 88, loss 0.606757.
Train: 2018-07-31T23:58:37.427964: step 89, loss 0.487266.
Train: 2018-07-31T23:58:37.615420: step 90, loss 0.511589.
Test: 2018-07-31T23:58:38.099682: step 90, loss 0.563304.
Train: 2018-07-31T23:58:38.287141: step 91, loss 0.609583.
Train: 2018-07-31T23:58:38.474563: step 92, loss 0.616223.
Train: 2018-07-31T23:58:38.662053: step 93, loss 0.50914.
Train: 2018-07-31T23:58:38.849505: step 94, loss 0.572698.
Train: 2018-07-31T23:58:39.036965: step 95, loss 0.52992.
Train: 2018-07-31T23:58:39.224388: step 96, loss 0.528995.
Train: 2018-07-31T23:58:39.396223: step 97, loss 0.661191.
Train: 2018-07-31T23:58:39.599331: step 98, loss 0.653262.
Train: 2018-07-31T23:58:39.771165: step 99, loss 0.624712.
Train: 2018-07-31T23:58:39.958592: step 100, loss 0.558901.
Test: 2018-07-31T23:58:40.442852: step 100, loss 0.56202.
Train: 2018-07-31T23:58:41.223919: step 101, loss 0.517556.
Train: 2018-07-31T23:58:41.411409: step 102, loss 0.574517.
Train: 2018-07-31T23:58:41.598856: step 103, loss 0.581701.
Train: 2018-07-31T23:58:41.786321: step 104, loss 0.533945.
Train: 2018-07-31T23:58:41.973744: step 105, loss 0.574325.
Train: 2018-07-31T23:58:42.176823: step 106, loss 0.505596.
Train: 2018-07-31T23:58:42.364302: step 107, loss 0.579212.
Train: 2018-07-31T23:58:42.551764: step 108, loss 0.609071.
Train: 2018-07-31T23:58:42.739220: step 109, loss 0.696953.
Train: 2018-07-31T23:58:42.926646: step 110, loss 0.597616.
Test: 2018-07-31T23:58:43.395286: step 110, loss 0.558601.
Train: 2018-07-31T23:58:43.582772: step 111, loss 0.449797.
Train: 2018-07-31T23:58:43.770228: step 112, loss 0.536179.
Train: 2018-07-31T23:58:43.957655: step 113, loss 0.666527.
Train: 2018-07-31T23:58:44.129522: step 114, loss 0.559554.
Train: 2018-07-31T23:58:44.316945: step 115, loss 0.49394.
Train: 2018-07-31T23:58:44.504401: step 116, loss 0.539351.
Train: 2018-07-31T23:58:44.691888: step 117, loss 0.642816.
Train: 2018-07-31T23:58:44.879344: step 118, loss 0.567289.
Train: 2018-07-31T23:58:45.066800: step 119, loss 0.528695.
Train: 2018-07-31T23:58:45.254226: step 120, loss 0.490471.
Test: 2018-07-31T23:58:45.722867: step 120, loss 0.555646.
Train: 2018-07-31T23:58:45.910355: step 121, loss 0.599465.
Train: 2018-07-31T23:58:46.097808: step 122, loss 0.599954.
Train: 2018-07-31T23:58:46.285259: step 123, loss 0.61312.
Train: 2018-07-31T23:58:46.472690: step 124, loss 0.576123.
Train: 2018-07-31T23:58:46.660146: step 125, loss 0.475227.
Train: 2018-07-31T23:58:46.847635: step 126, loss 0.647124.
Train: 2018-07-31T23:58:47.035092: step 127, loss 0.542682.
Train: 2018-07-31T23:58:47.222515: step 128, loss 0.576223.
Train: 2018-07-31T23:58:47.410005: step 129, loss 0.518217.
Train: 2018-07-31T23:58:47.613078: step 130, loss 0.599406.
Test: 2018-07-31T23:58:48.081720: step 130, loss 0.554476.
Train: 2018-07-31T23:58:48.253524: step 131, loss 0.568305.
Train: 2018-07-31T23:58:48.456627: step 132, loss 0.605704.
Train: 2018-07-31T23:58:48.644081: step 133, loss 0.522867.
Train: 2018-07-31T23:58:48.831543: step 134, loss 0.640163.
Train: 2018-07-31T23:58:49.003349: step 135, loss 0.601892.
Train: 2018-07-31T23:58:49.190835: step 136, loss 0.660925.
Train: 2018-07-31T23:58:49.378285: step 137, loss 0.479451.
Train: 2018-07-31T23:58:49.581338: step 138, loss 0.689495.
Train: 2018-07-31T23:58:49.784417: step 139, loss 0.539161.
Train: 2018-07-31T23:58:49.987519: step 140, loss 0.516485.
Test: 2018-07-31T23:58:50.471784: step 140, loss 0.557052.
Train: 2018-07-31T23:58:50.674856: step 141, loss 0.586784.
Train: 2018-07-31T23:58:50.862317: step 142, loss 0.673372.
Train: 2018-07-31T23:58:51.049746: step 143, loss 0.542451.
Train: 2018-07-31T23:58:51.237230: step 144, loss 0.58133.
Train: 2018-07-31T23:58:51.424686: step 145, loss 0.606193.
Train: 2018-07-31T23:58:51.612137: step 146, loss 0.515255.
Train: 2018-07-31T23:58:51.799598: step 147, loss 0.552818.
Train: 2018-07-31T23:58:51.987054: step 148, loss 0.639789.
Train: 2018-07-31T23:58:52.174510: step 149, loss 0.549334.
Train: 2018-07-31T23:58:52.361967: step 150, loss 0.787174.
Test: 2018-07-31T23:58:52.846205: step 150, loss 0.55612.
Train: 2018-07-31T23:58:53.064897: step 151, loss 0.535333.
Train: 2018-07-31T23:58:53.299218: step 152, loss 0.700509.
Train: 2018-07-31T23:58:53.486703: step 153, loss 0.560217.
Train: 2018-07-31T23:58:53.689776: step 154, loss 0.624242.
Train: 2018-07-31T23:58:53.877237: step 155, loss 0.497649.
Train: 2018-07-31T23:58:54.064693: step 156, loss 0.492006.
Train: 2018-07-31T23:58:54.267770: step 157, loss 0.486354.
Train: 2018-07-31T23:58:54.455227: step 158, loss 0.614036.
Train: 2018-07-31T23:58:54.642652: step 159, loss 0.519132.
Train: 2018-07-31T23:58:54.845731: step 160, loss 0.547927.
Test: 2018-07-31T23:58:55.330022: step 160, loss 0.553702.
Train: 2018-07-31T23:58:55.533069: step 161, loss 0.663882.
Train: 2018-07-31T23:58:55.720561: step 162, loss 0.571678.
Train: 2018-07-31T23:58:55.908015: step 163, loss 0.560453.
Train: 2018-07-31T23:58:56.111089: step 164, loss 0.615607.
Train: 2018-07-31T23:58:56.298514: step 165, loss 0.681797.
Train: 2018-07-31T23:58:56.486001: step 166, loss 0.498915.
Train: 2018-07-31T23:58:56.689050: step 167, loss 0.527046.
Train: 2018-07-31T23:58:56.876504: step 168, loss 0.594678.
Train: 2018-07-31T23:58:57.095203: step 169, loss 0.453563.
Train: 2018-07-31T23:58:57.298311: step 170, loss 0.697327.
Test: 2018-07-31T23:58:57.782543: step 170, loss 0.551826.
Train: 2018-07-31T23:58:57.985650: step 171, loss 0.567733.
Train: 2018-07-31T23:58:58.173107: step 172, loss 0.497206.
Train: 2018-07-31T23:58:58.376157: step 173, loss 0.682402.
Train: 2018-07-31T23:58:58.563609: step 174, loss 0.554017.
Train: 2018-07-31T23:58:58.766714: step 175, loss 0.667989.
Train: 2018-07-31T23:58:58.954168: step 176, loss 0.489253.
Train: 2018-07-31T23:58:59.157246: step 177, loss 0.542247.
Train: 2018-07-31T23:58:59.344695: step 178, loss 0.539914.
Train: 2018-07-31T23:58:59.532167: step 179, loss 0.630102.
Train: 2018-07-31T23:58:59.735210: step 180, loss 0.492769.
Test: 2018-07-31T23:59:00.219473: step 180, loss 0.55125.
Train: 2018-07-31T23:59:00.406953: step 181, loss 0.637264.
Train: 2018-07-31T23:59:00.625656: step 182, loss 0.597504.
Train: 2018-07-31T23:59:00.844350: step 183, loss 0.564343.
Train: 2018-07-31T23:59:01.047432: step 184, loss 0.522361.
Train: 2018-07-31T23:59:01.234890: step 185, loss 0.69159.
Train: 2018-07-31T23:59:01.422345: step 186, loss 0.555557.
Train: 2018-07-31T23:59:01.625419: step 187, loss 0.695298.
Train: 2018-07-31T23:59:01.812877: step 188, loss 0.676689.
Train: 2018-07-31T23:59:02.015927: step 189, loss 0.475153.
Train: 2018-07-31T23:59:02.203412: step 190, loss 0.579205.
Test: 2018-07-31T23:59:02.703265: step 190, loss 0.555228.
Train: 2018-07-31T23:59:02.890752: step 191, loss 0.552981.
Train: 2018-07-31T23:59:03.078207: step 192, loss 0.575361.
Train: 2018-07-31T23:59:03.265634: step 193, loss 0.564985.
Train: 2018-07-31T23:59:03.453090: step 194, loss 0.580068.
Train: 2018-07-31T23:59:03.640545: step 195, loss 0.517707.
Train: 2018-07-31T23:59:03.828001: step 196, loss 0.595592.
Train: 2018-07-31T23:59:04.015488: step 197, loss 0.530586.
Train: 2018-07-31T23:59:04.202914: step 198, loss 0.658668.
Train: 2018-07-31T23:59:04.390399: step 199, loss 0.599871.
Train: 2018-07-31T23:59:04.577856: step 200, loss 0.494113.
Test: 2018-07-31T23:59:05.046496: step 200, loss 0.552228.
Train: 2018-07-31T23:59:05.765078: step 201, loss 0.564263.
Train: 2018-07-31T23:59:05.952504: step 202, loss 0.583681.
Train: 2018-07-31T23:59:06.139990: step 203, loss 0.501714.
Train: 2018-07-31T23:59:06.327447: step 204, loss 0.457912.
Train: 2018-07-31T23:59:06.514872: step 205, loss 0.554107.
Train: 2018-07-31T23:59:06.702359: step 206, loss 0.570111.
Train: 2018-07-31T23:59:06.889815: step 207, loss 0.620407.
Train: 2018-07-31T23:59:07.077265: step 208, loss 0.523753.
Train: 2018-07-31T23:59:07.264698: step 209, loss 0.57753.
Train: 2018-07-31T23:59:07.452152: step 210, loss 0.514094.
Test: 2018-07-31T23:59:07.936444: step 210, loss 0.550203.
Train: 2018-07-31T23:59:08.123900: step 211, loss 0.526047.
Train: 2018-07-31T23:59:08.295737: step 212, loss 0.578699.
Train: 2018-07-31T23:59:08.498813: step 213, loss 0.537289.
Train: 2018-07-31T23:59:08.686270: step 214, loss 0.569945.
Train: 2018-07-31T23:59:08.873725: step 215, loss 0.631784.
Train: 2018-07-31T23:59:09.076772: step 216, loss 0.51811.
Train: 2018-07-31T23:59:09.264258: step 217, loss 0.686897.
Train: 2018-07-31T23:59:09.436094: step 218, loss 0.618814.
Train: 2018-07-31T23:59:09.623544: step 219, loss 0.559256.
Train: 2018-07-31T23:59:09.810976: step 220, loss 0.577325.
Test: 2018-07-31T23:59:10.279649: step 220, loss 0.551466.
Train: 2018-07-31T23:59:10.467097: step 221, loss 0.623912.
Train: 2018-07-31T23:59:10.654561: step 222, loss 0.549919.
Train: 2018-07-31T23:59:10.841984: step 223, loss 0.616891.
Train: 2018-07-31T23:59:11.029474: step 224, loss 0.599085.
Train: 2018-07-31T23:59:11.216897: step 225, loss 0.554688.
Train: 2018-07-31T23:59:11.404382: step 226, loss 0.553885.
Train: 2018-07-31T23:59:11.607433: step 227, loss 0.667858.
Train: 2018-07-31T23:59:11.794916: step 228, loss 0.639116.
Train: 2018-07-31T23:59:11.982368: step 229, loss 0.59609.
Train: 2018-07-31T23:59:12.185419: step 230, loss 0.561381.
Test: 2018-07-31T23:59:12.654059: step 230, loss 0.558808.
Train: 2018-07-31T23:59:12.857151: step 231, loss 0.583262.
Train: 2018-07-31T23:59:13.044619: step 232, loss 0.576723.
Train: 2018-07-31T23:59:13.247671: step 233, loss 0.592053.
Train: 2018-07-31T23:59:13.435157: step 234, loss 0.63056.
Train: 2018-07-31T23:59:13.622583: step 235, loss 0.545656.
Train: 2018-07-31T23:59:13.810069: step 236, loss 0.62234.
Train: 2018-07-31T23:59:13.997495: step 237, loss 0.678569.
Train: 2018-07-31T23:59:14.200572: step 238, loss 0.59713.
Train: 2018-07-31T23:59:14.372437: step 239, loss 0.531251.
Train: 2018-07-31T23:59:14.575509: step 240, loss 0.580035.
Test: 2018-07-31T23:59:15.059777: step 240, loss 0.558009.
Train: 2018-07-31T23:59:15.247203: step 241, loss 0.575975.
Train: 2018-07-31T23:59:15.434683: step 242, loss 0.595881.
Train: 2018-07-31T23:59:15.637766: step 243, loss 0.63945.
Train: 2018-07-31T23:59:15.856435: step 244, loss 0.59515.
Train: 2018-07-31T23:59:16.043916: step 245, loss 0.46849.
Train: 2018-07-31T23:59:16.246968: step 246, loss 0.577267.
Train: 2018-07-31T23:59:16.434456: step 247, loss 0.611547.
Train: 2018-07-31T23:59:16.621882: step 248, loss 0.558636.
Train: 2018-07-31T23:59:16.809367: step 249, loss 0.53995.
Train: 2018-07-31T23:59:16.996793: step 250, loss 0.592079.
Test: 2018-07-31T23:59:17.465463: step 250, loss 0.552302.
Train: 2018-07-31T23:59:17.652889: step 251, loss 0.476357.
Train: 2018-07-31T23:59:17.855997: step 252, loss 0.558132.
Train: 2018-07-31T23:59:18.043424: step 253, loss 0.607464.
Train: 2018-07-31T23:59:18.230910: step 254, loss 0.638935.
Train: 2018-07-31T23:59:18.418366: step 255, loss 0.499695.
Train: 2018-07-31T23:59:18.605816: step 256, loss 0.517185.
Train: 2018-07-31T23:59:18.793247: step 257, loss 0.531603.
Train: 2018-07-31T23:59:18.980729: step 258, loss 0.460642.
Train: 2018-07-31T23:59:19.183782: step 259, loss 0.577824.
Train: 2018-07-31T23:59:19.371236: step 260, loss 0.538895.
Test: 2018-07-31T23:59:19.839908: step 260, loss 0.549074.
Train: 2018-07-31T23:59:20.011736: step 261, loss 0.494764.
Train: 2018-07-31T23:59:20.199198: step 262, loss 0.519842.
Train: 2018-07-31T23:59:20.386654: step 263, loss 0.573238.
Train: 2018-07-31T23:59:20.558491: step 264, loss 0.720043.
Train: 2018-07-31T23:59:20.745945: step 265, loss 0.513863.
Train: 2018-07-31T23:59:20.917780: step 266, loss 0.625029.
Train: 2018-07-31T23:59:21.105205: step 267, loss 0.556211.
Train: 2018-07-31T23:59:21.277074: step 268, loss 0.56535.
Train: 2018-07-31T23:59:21.464498: step 269, loss 0.548372.
Train: 2018-07-31T23:59:21.636356: step 270, loss 0.663581.
Test: 2018-07-31T23:59:22.120618: step 270, loss 0.549005.
Train: 2018-07-31T23:59:22.292457: step 271, loss 0.57408.
Train: 2018-07-31T23:59:22.479884: step 272, loss 0.533726.
Train: 2018-07-31T23:59:22.651719: step 273, loss 0.512678.
Train: 2018-07-31T23:59:22.839208: step 274, loss 0.605461.
Train: 2018-07-31T23:59:23.011039: step 275, loss 0.544276.
Train: 2018-07-31T23:59:23.182874: step 276, loss 0.667649.
Train: 2018-07-31T23:59:23.370330: step 277, loss 0.525645.
Train: 2018-07-31T23:59:23.542165: step 278, loss 0.577453.
Train: 2018-07-31T23:59:23.729625: step 279, loss 0.6176.
Train: 2018-07-31T23:59:23.901455: step 280, loss 0.561851.
Test: 2018-07-31T23:59:24.385715: step 280, loss 0.551258.
Train: 2018-07-31T23:59:24.557523: step 281, loss 0.622747.
Train: 2018-07-31T23:59:24.729358: step 282, loss 0.557862.
Train: 2018-07-31T23:59:24.901225: step 283, loss 0.570154.
Train: 2018-07-31T23:59:25.073027: step 284, loss 0.535558.
Train: 2018-07-31T23:59:25.244861: step 285, loss 0.532079.
Train: 2018-07-31T23:59:25.416726: step 286, loss 0.51678.
Train: 2018-07-31T23:59:25.604183: step 287, loss 0.550075.
Train: 2018-07-31T23:59:25.775986: step 288, loss 0.51864.
Train: 2018-07-31T23:59:25.947821: step 289, loss 0.461921.
Train: 2018-07-31T23:59:26.119657: step 290, loss 0.572318.
Test: 2018-07-31T23:59:26.603920: step 290, loss 0.549196.
Train: 2018-07-31T23:59:26.775753: step 291, loss 0.606165.
Train: 2018-07-31T23:59:27.041318: step 292, loss 0.532392.
Train: 2018-07-31T23:59:27.306880: step 293, loss 0.564657.
Train: 2018-07-31T23:59:27.509982: step 294, loss 0.490076.
Train: 2018-07-31T23:59:27.697412: step 295, loss 0.493914.
Train: 2018-07-31T23:59:27.853655: step 296, loss 0.519722.
Train: 2018-07-31T23:59:28.056729: step 297, loss 0.575196.
Train: 2018-07-31T23:59:28.259783: step 298, loss 0.601219.
Train: 2018-07-31T23:59:28.462859: step 299, loss 0.570586.
Train: 2018-07-31T23:59:28.665936: step 300, loss 0.588991.
Test: 2018-07-31T23:59:29.134606: step 300, loss 0.548865.
Train: 2018-07-31T23:59:29.962532: step 301, loss 0.473509.
Train: 2018-07-31T23:59:30.134367: step 302, loss 0.59809.
Train: 2018-07-31T23:59:30.306201: step 303, loss 0.529229.
Train: 2018-07-31T23:59:30.462423: step 304, loss 0.602992.
Train: 2018-07-31T23:59:30.634257: step 305, loss 0.499496.
Train: 2018-07-31T23:59:30.790468: step 306, loss 0.642317.
Train: 2018-07-31T23:59:30.962303: step 307, loss 0.527543.
Train: 2018-07-31T23:59:31.118513: step 308, loss 0.717074.
Train: 2018-07-31T23:59:31.274733: step 309, loss 0.631419.
Train: 2018-07-31T23:59:31.446534: step 310, loss 0.61043.
Test: 2018-07-31T23:59:31.915205: step 310, loss 0.54995.
Train: 2018-07-31T23:59:32.071388: step 311, loss 0.593779.
Train: 2018-07-31T23:59:32.243253: step 312, loss 0.616158.
Train: 2018-07-31T23:59:32.399470: step 313, loss 0.616791.
Train: 2018-07-31T23:59:32.555650: step 314, loss 0.483931.
Train: 2018-07-31T23:59:32.727510: step 315, loss 0.566163.
Train: 2018-07-31T23:59:32.883732: step 316, loss 0.561439.
Train: 2018-07-31T23:59:33.039941: step 317, loss 0.601513.
Train: 2018-07-31T23:59:33.211746: step 318, loss 0.540671.
Train: 2018-07-31T23:59:33.363849: step 319, loss 0.570754.
Train: 2018-07-31T23:59:33.520063: step 320, loss 0.578335.
Test: 2018-07-31T23:59:34.004358: step 320, loss 0.552847.
Train: 2018-07-31T23:59:34.160539: step 321, loss 0.562025.
Train: 2018-07-31T23:59:34.332403: step 322, loss 0.531293.
Train: 2018-07-31T23:59:34.488617: step 323, loss 0.587112.
Train: 2018-07-31T23:59:34.644831: step 324, loss 0.523518.
Train: 2018-07-31T23:59:34.816635: step 325, loss 0.588405.
Train: 2018-07-31T23:59:34.972884: step 326, loss 0.610226.
Train: 2018-07-31T23:59:35.144714: step 327, loss 0.635326.
Train: 2018-07-31T23:59:35.300927: step 328, loss 0.529542.
Train: 2018-07-31T23:59:35.457109: step 329, loss 0.60519.
Train: 2018-07-31T23:59:35.628974: step 330, loss 0.600413.
Test: 2018-07-31T23:59:36.097585: step 330, loss 0.550378.
Train: 2018-07-31T23:59:36.253822: step 331, loss 0.625969.
Train: 2018-07-31T23:59:36.410036: step 332, loss 0.646146.
Train: 2018-07-31T23:59:36.566250: step 333, loss 0.577145.
Train: 2018-07-31T23:59:36.738059: step 334, loss 0.509651.
Train: 2018-07-31T23:59:36.894273: step 335, loss 0.553363.
Train: 2018-07-31T23:59:37.050518: step 336, loss 0.613472.
Train: 2018-07-31T23:59:37.206724: step 337, loss 0.641798.
Train: 2018-07-31T23:59:37.362937: step 338, loss 0.610858.
Train: 2018-07-31T23:59:37.519158: step 339, loss 0.599247.
Train: 2018-07-31T23:59:37.690992: step 340, loss 0.505654.
Test: 2018-07-31T23:59:38.159631: step 340, loss 0.552387.
Train: 2018-07-31T23:59:38.315848: step 341, loss 0.525532.
Train: 2018-07-31T23:59:38.487680: step 342, loss 0.592359.
Train: 2018-07-31T23:59:38.643887: step 343, loss 0.571237.
Train: 2018-07-31T23:59:38.800076: step 344, loss 0.571347.
Train: 2018-07-31T23:59:38.956290: step 345, loss 0.514959.
Train: 2018-07-31T23:59:39.112504: step 346, loss 0.637576.
Train: 2018-07-31T23:59:39.284339: step 347, loss 0.486902.
Train: 2018-07-31T23:59:39.456173: step 348, loss 0.657715.
Train: 2018-07-31T23:59:39.643630: step 349, loss 0.534042.
Train: 2018-07-31T23:59:39.815464: step 350, loss 0.68487.
Test: 2018-07-31T23:59:40.284130: step 350, loss 0.550263.
Train: 2018-07-31T23:59:40.471559: step 351, loss 0.520333.
Train: 2018-07-31T23:59:40.659017: step 352, loss 0.547286.
Train: 2018-07-31T23:59:40.815231: step 353, loss 0.527298.
Train: 2018-07-31T23:59:40.987089: step 354, loss 0.549103.
Train: 2018-07-31T23:59:41.143303: step 355, loss 0.622006.
Train: 2018-07-31T23:59:41.330735: step 356, loss 0.58237.
Train: 2018-07-31T23:59:41.549435: step 357, loss 0.580847.
Train: 2018-07-31T23:59:41.705646: step 358, loss 0.515772.
Train: 2018-07-31T23:59:41.877512: step 359, loss 0.666005.
Train: 2018-07-31T23:59:42.049347: step 360, loss 0.486896.
Test: 2018-07-31T23:59:42.517986: step 360, loss 0.549159.
Train: 2018-07-31T23:59:42.674170: step 361, loss 0.443423.
Train: 2018-07-31T23:59:42.830396: step 362, loss 0.660227.
Train: 2018-07-31T23:59:42.986620: step 363, loss 0.648513.
Train: 2018-07-31T23:59:43.158430: step 364, loss 0.593607.
Train: 2018-07-31T23:59:43.314675: step 365, loss 0.47939.
Train: 2018-07-31T23:59:43.470888: step 366, loss 0.659571.
Train: 2018-07-31T23:59:43.642693: step 367, loss 0.536368.
Train: 2018-07-31T23:59:43.798907: step 368, loss 0.513365.
Train: 2018-07-31T23:59:43.970740: step 369, loss 0.510007.
Train: 2018-07-31T23:59:44.142575: step 370, loss 0.484121.
Test: 2018-07-31T23:59:44.611247: step 370, loss 0.54885.
Train: 2018-07-31T23:59:44.783062: step 371, loss 0.642881.
Train: 2018-07-31T23:59:44.954911: step 372, loss 0.617068.
Train: 2018-07-31T23:59:45.111130: step 373, loss 0.501745.
Train: 2018-07-31T23:59:45.267313: step 374, loss 0.470886.
Train: 2018-07-31T23:59:45.439178: step 375, loss 0.474574.
Train: 2018-07-31T23:59:45.595362: step 376, loss 0.492101.
Train: 2018-07-31T23:59:45.767196: step 377, loss 0.521904.
Train: 2018-07-31T23:59:45.939060: step 378, loss 0.593703.
Train: 2018-07-31T23:59:46.110864: step 379, loss 0.561507.
Train: 2018-07-31T23:59:46.267108: step 380, loss 0.590188.
Test: 2018-07-31T23:59:46.751370: step 380, loss 0.548337.
Train: 2018-07-31T23:59:46.907553: step 381, loss 0.604376.
Train: 2018-07-31T23:59:47.063803: step 382, loss 0.52204.
Train: 2018-07-31T23:59:47.235601: step 383, loss 0.633232.
Train: 2018-07-31T23:59:47.391845: step 384, loss 0.642753.
Train: 2018-07-31T23:59:47.548053: step 385, loss 0.704826.
Train: 2018-07-31T23:59:47.704242: step 386, loss 0.523853.
Train: 2018-07-31T23:59:47.860455: step 387, loss 0.589373.
Train: 2018-07-31T23:59:48.016698: step 388, loss 0.623868.
Train: 2018-07-31T23:59:48.188503: step 389, loss 0.603335.
Train: 2018-07-31T23:59:48.344747: step 390, loss 0.562826.
Test: 2018-07-31T23:59:48.829008: step 390, loss 0.549745.
Train: 2018-07-31T23:59:48.985216: step 391, loss 0.641016.
Train: 2018-07-31T23:59:49.141435: step 392, loss 0.438591.
Train: 2018-07-31T23:59:49.297618: step 393, loss 0.599616.
Train: 2018-07-31T23:59:49.453831: step 394, loss 0.666204.
Train: 2018-07-31T23:59:49.610045: step 395, loss 0.571188.
Train: 2018-07-31T23:59:49.797533: step 396, loss 0.54189.
Train: 2018-07-31T23:59:49.953739: step 397, loss 0.49259.
Train: 2018-07-31T23:59:50.125580: step 398, loss 0.515236.
Train: 2018-07-31T23:59:50.281788: step 399, loss 0.591383.
Train: 2018-07-31T23:59:50.453622: step 400, loss 0.565065.
Test: 2018-07-31T23:59:50.937860: step 400, loss 0.551852.
Train: 2018-07-31T23:59:51.609607: step 401, loss 0.544479.
Train: 2018-07-31T23:59:51.781412: step 402, loss 0.579327.
Train: 2018-07-31T23:59:51.937650: step 403, loss 0.621203.
Train: 2018-07-31T23:59:52.093838: step 404, loss 0.544506.
Train: 2018-07-31T23:59:52.250077: step 405, loss 0.536282.
Train: 2018-07-31T23:59:52.421911: step 406, loss 0.516893.
Train: 2018-07-31T23:59:52.578126: step 407, loss 0.594838.
Train: 2018-07-31T23:59:52.734344: step 408, loss 0.482329.
Train: 2018-07-31T23:59:52.890528: step 409, loss 0.539378.
Train: 2018-07-31T23:59:53.046772: step 410, loss 0.619015.
Test: 2018-07-31T23:59:53.531035: step 410, loss 0.549226.
Train: 2018-07-31T23:59:53.687216: step 411, loss 0.562973.
Train: 2018-07-31T23:59:53.843428: step 412, loss 0.515793.
Train: 2018-07-31T23:59:54.015263: step 413, loss 0.598258.
Train: 2018-07-31T23:59:54.171508: step 414, loss 0.552668.
Train: 2018-07-31T23:59:54.327690: step 415, loss 0.689698.
Train: 2018-07-31T23:59:54.483903: step 416, loss 0.700983.
Train: 2018-07-31T23:59:54.640117: step 417, loss 0.518909.
Train: 2018-07-31T23:59:54.796362: step 418, loss 0.62875.
Train: 2018-07-31T23:59:54.952568: step 419, loss 0.570218.
Train: 2018-07-31T23:59:55.108794: step 420, loss 0.626822.
Test: 2018-07-31T23:59:55.577428: step 420, loss 0.549302.
Train: 2018-07-31T23:59:55.733641: step 421, loss 0.465485.
Train: 2018-07-31T23:59:55.905476: step 422, loss 0.47843.
Train: 2018-07-31T23:59:56.061659: step 423, loss 0.548492.
Train: 2018-07-31T23:59:56.217872: step 424, loss 0.578106.
Train: 2018-07-31T23:59:56.374116: step 425, loss 0.523804.
Train: 2018-07-31T23:59:56.530324: step 426, loss 0.626989.
Train: 2018-07-31T23:59:56.686544: step 427, loss 0.598622.
Train: 2018-07-31T23:59:56.842751: step 428, loss 0.5839.
Train: 2018-07-31T23:59:57.014592: step 429, loss 0.589373.
Train: 2018-07-31T23:59:57.170775: step 430, loss 0.571518.
Test: 2018-07-31T23:59:57.639446: step 430, loss 0.549454.
Train: 2018-07-31T23:59:57.795660: step 431, loss 0.606854.
Train: 2018-07-31T23:59:57.951872: step 432, loss 0.60771.
Train: 2018-07-31T23:59:58.123677: step 433, loss 0.539268.
Train: 2018-07-31T23:59:58.279890: step 434, loss 0.577855.
Train: 2018-07-31T23:59:58.420482: step 435, loss 0.617712.
Train: 2018-07-31T23:59:58.592347: step 436, loss 0.550101.
Train: 2018-07-31T23:59:58.748530: step 437, loss 0.649853.
Train: 2018-07-31T23:59:58.904769: step 438, loss 0.50519.
Train: 2018-07-31T23:59:59.060958: step 439, loss 0.58271.
Train: 2018-07-31T23:59:59.217170: step 440, loss 0.502496.
Test: 2018-07-31T23:59:59.717052: step 440, loss 0.5506.
Train: 2018-07-31T23:59:59.873267: step 441, loss 0.583448.
Train: 2018-08-01T00:00:00.029481: step 442, loss 0.560021.
Train: 2018-08-01T00:00:00.201346: step 443, loss 0.545697.
Train: 2018-08-01T00:00:00.357545: step 444, loss 0.579559.
Train: 2018-08-01T00:00:00.529396: step 445, loss 0.631885.
Train: 2018-08-01T00:00:00.701204: step 446, loss 0.59291.
Train: 2018-08-01T00:00:00.857436: step 447, loss 0.604522.
Train: 2018-08-01T00:00:01.029246: step 448, loss 0.508358.
Train: 2018-08-01T00:00:01.185460: step 449, loss 0.639904.
Train: 2018-08-01T00:00:01.341673: step 450, loss 0.564741.
Test: 2018-08-01T00:00:01.810344: step 450, loss 0.550457.
Train: 2018-08-01T00:00:01.966526: step 451, loss 0.50623.
Train: 2018-08-01T00:00:02.138362: step 452, loss 0.645619.
Train: 2018-08-01T00:00:02.294574: step 453, loss 0.549793.
Train: 2018-08-01T00:00:02.466439: step 454, loss 0.56941.
Train: 2018-08-01T00:00:02.622623: step 455, loss 0.44839.
Train: 2018-08-01T00:00:02.778837: step 456, loss 0.600831.
Train: 2018-08-01T00:00:02.935081: step 457, loss 0.531264.
Train: 2018-08-01T00:00:03.106911: step 458, loss 0.555722.
Train: 2018-08-01T00:00:03.263099: step 459, loss 0.606825.
Train: 2018-08-01T00:00:03.434971: step 460, loss 0.537433.
Test: 2018-08-01T00:00:03.919229: step 460, loss 0.549487.
Train: 2018-08-01T00:00:04.075408: step 461, loss 0.634668.
Train: 2018-08-01T00:00:04.247273: step 462, loss 0.604573.
Train: 2018-08-01T00:00:04.403455: step 463, loss 0.453307.
Train: 2018-08-01T00:00:04.575291: step 464, loss 0.563193.
Train: 2018-08-01T00:00:04.731535: step 465, loss 0.53521.
Train: 2018-08-01T00:00:04.887719: step 466, loss 0.63462.
Train: 2018-08-01T00:00:05.059552: step 467, loss 0.557334.
Train: 2018-08-01T00:00:05.215796: step 468, loss 0.609086.
Train: 2018-08-01T00:00:05.371980: step 469, loss 0.562554.
Train: 2018-08-01T00:00:05.528192: step 470, loss 0.594758.
Test: 2018-08-01T00:00:05.996833: step 470, loss 0.549106.
Train: 2018-08-01T00:00:06.168699: step 471, loss 0.534983.
Train: 2018-08-01T00:00:06.324911: step 472, loss 0.41341.
Train: 2018-08-01T00:00:06.481124: step 473, loss 0.663241.
Train: 2018-08-01T00:00:06.637337: step 474, loss 0.556768.
Train: 2018-08-01T00:00:06.809166: step 475, loss 0.60152.
Train: 2018-08-01T00:00:06.965356: step 476, loss 0.590749.
Train: 2018-08-01T00:00:07.105978: step 477, loss 0.624262.
Train: 2018-08-01T00:00:07.277784: step 478, loss 0.497241.
Train: 2018-08-01T00:00:07.434030: step 479, loss 0.542264.
Train: 2018-08-01T00:00:07.605831: step 480, loss 0.567079.
Test: 2018-08-01T00:00:08.074470: step 480, loss 0.548806.
Train: 2018-08-01T00:00:08.246338: step 481, loss 0.654026.
Train: 2018-08-01T00:00:08.402549: step 482, loss 0.494787.
Train: 2018-08-01T00:00:08.574355: step 483, loss 0.627214.
Train: 2018-08-01T00:00:08.730577: step 484, loss 0.542841.
Train: 2018-08-01T00:00:08.902402: step 485, loss 0.466548.
Train: 2018-08-01T00:00:09.058617: step 486, loss 0.687911.
Train: 2018-08-01T00:00:09.214831: step 487, loss 0.49289.
Train: 2018-08-01T00:00:09.386664: step 488, loss 0.640177.
Train: 2018-08-01T00:00:09.542877: step 489, loss 0.559626.
Train: 2018-08-01T00:00:09.699092: step 490, loss 0.618783.
Test: 2018-08-01T00:00:10.183383: step 490, loss 0.549152.
Train: 2018-08-01T00:00:10.355218: step 491, loss 0.663706.
Train: 2018-08-01T00:00:10.573885: step 492, loss 0.558432.
Train: 2018-08-01T00:00:10.730099: step 493, loss 0.577846.
Train: 2018-08-01T00:00:10.886313: step 494, loss 0.56423.
Train: 2018-08-01T00:00:11.042525: step 495, loss 0.623806.
Train: 2018-08-01T00:00:11.198739: step 496, loss 0.489435.
Train: 2018-08-01T00:00:11.354952: step 497, loss 0.617578.
Train: 2018-08-01T00:00:11.511196: step 498, loss 0.508357.
Train: 2018-08-01T00:00:11.667380: step 499, loss 0.64076.
Train: 2018-08-01T00:00:11.823595: step 500, loss 0.530368.
Test: 2018-08-01T00:00:12.307886: step 500, loss 0.550573.
Train: 2018-08-01T00:00:13.073327: step 501, loss 0.616821.
Train: 2018-08-01T00:00:13.229545: step 502, loss 0.474025.
Train: 2018-08-01T00:00:13.385758: step 503, loss 0.582597.
Train: 2018-08-01T00:00:13.557593: step 504, loss 0.471892.
Train: 2018-08-01T00:00:13.713806: step 505, loss 0.599038.
Train: 2018-08-01T00:00:13.870026: step 506, loss 0.544737.
Train: 2018-08-01T00:00:14.026228: step 507, loss 0.501042.
Train: 2018-08-01T00:00:14.198068: step 508, loss 0.64119.
Train: 2018-08-01T00:00:14.354255: step 509, loss 0.53753.
Train: 2018-08-01T00:00:14.510494: step 510, loss 0.545407.
Test: 2018-08-01T00:00:14.994761: step 510, loss 0.548947.
Train: 2018-08-01T00:00:15.150973: step 511, loss 0.452841.
Train: 2018-08-01T00:00:15.307166: step 512, loss 0.459932.
Train: 2018-08-01T00:00:15.463367: step 513, loss 0.515443.
Train: 2018-08-01T00:00:15.619609: step 514, loss 0.678113.
Train: 2018-08-01T00:00:15.775794: step 515, loss 0.47001.
Train: 2018-08-01T00:00:15.947627: step 516, loss 0.507683.
Train: 2018-08-01T00:00:16.119462: step 517, loss 0.523539.
Train: 2018-08-01T00:00:16.275700: step 518, loss 0.593915.
Train: 2018-08-01T00:00:16.447510: step 519, loss 0.622694.
Train: 2018-08-01T00:00:16.603754: step 520, loss 0.551443.
Test: 2018-08-01T00:00:17.072364: step 520, loss 0.548033.
Train: 2018-08-01T00:00:17.228608: step 521, loss 0.535788.
Train: 2018-08-01T00:00:17.400437: step 522, loss 0.547508.
Train: 2018-08-01T00:00:17.556657: step 523, loss 0.483509.
Train: 2018-08-01T00:00:17.728464: step 524, loss 0.509232.
Train: 2018-08-01T00:00:17.884704: step 525, loss 0.508605.
Train: 2018-08-01T00:00:18.040887: step 526, loss 0.50857.
Train: 2018-08-01T00:00:18.197132: step 527, loss 0.674265.
Train: 2018-08-01T00:00:18.353315: step 528, loss 0.571948.
Train: 2018-08-01T00:00:18.509552: step 529, loss 0.51697.
Train: 2018-08-01T00:00:18.665741: step 530, loss 0.609299.
Test: 2018-08-01T00:00:19.150033: step 530, loss 0.548141.
Train: 2018-08-01T00:00:19.321837: step 531, loss 0.624984.
Train: 2018-08-01T00:00:19.478081: step 532, loss 0.503675.
Train: 2018-08-01T00:00:19.634265: step 533, loss 0.556866.
Train: 2018-08-01T00:00:19.790502: step 534, loss 0.522187.
Train: 2018-08-01T00:00:19.962338: step 535, loss 0.521989.
Train: 2018-08-01T00:00:20.118556: step 536, loss 0.530325.
Train: 2018-08-01T00:00:20.274740: step 537, loss 0.603299.
Train: 2018-08-01T00:00:20.446575: step 538, loss 0.510782.
Train: 2018-08-01T00:00:20.602818: step 539, loss 0.607443.
Train: 2018-08-01T00:00:20.774624: step 540, loss 0.619217.
Test: 2018-08-01T00:00:21.258884: step 540, loss 0.548037.
Train: 2018-08-01T00:00:21.555690: step 541, loss 0.574156.
Train: 2018-08-01T00:00:21.711905: step 542, loss 0.580009.
Train: 2018-08-01T00:00:21.899359: step 543, loss 0.582005.
Train: 2018-08-01T00:00:22.039983: step 544, loss 0.509829.
Train: 2018-08-01T00:00:22.211812: step 545, loss 0.457733.
Train: 2018-08-01T00:00:22.368029: step 546, loss 0.534907.
Train: 2018-08-01T00:00:22.524213: step 547, loss 0.614753.
Train: 2018-08-01T00:00:22.680425: step 548, loss 0.618193.
Train: 2018-08-01T00:00:22.852260: step 549, loss 0.565111.
Train: 2018-08-01T00:00:23.008474: step 550, loss 0.542642.
Test: 2018-08-01T00:00:23.492767: step 550, loss 0.548877.
Train: 2018-08-01T00:00:23.648949: step 551, loss 0.497583.
Train: 2018-08-01T00:00:23.805194: step 552, loss 0.601392.
Train: 2018-08-01T00:00:23.977027: step 553, loss 0.50606.
Train: 2018-08-01T00:00:24.133235: step 554, loss 0.585739.
Train: 2018-08-01T00:00:24.289455: step 555, loss 0.549723.
Train: 2018-08-01T00:00:24.445668: step 556, loss 0.59426.
Train: 2018-08-01T00:00:24.601881: step 557, loss 0.461196.
Train: 2018-08-01T00:00:24.758095: step 558, loss 0.564866.
Train: 2018-08-01T00:00:24.914315: step 559, loss 0.547449.
Train: 2018-08-01T00:00:25.086112: step 560, loss 0.575496.
Test: 2018-08-01T00:00:25.570373: step 560, loss 0.5485.
Train: 2018-08-01T00:00:25.710967: step 561, loss 0.500716.
Train: 2018-08-01T00:00:25.882800: step 562, loss 0.610231.
Train: 2018-08-01T00:00:26.039051: step 563, loss 0.531789.
Train: 2018-08-01T00:00:26.195229: step 564, loss 0.546073.
Train: 2018-08-01T00:00:26.351472: step 565, loss 0.543534.
Train: 2018-08-01T00:00:26.507685: step 566, loss 0.514362.
Train: 2018-08-01T00:00:26.663868: step 567, loss 0.47881.
Train: 2018-08-01T00:00:26.820081: step 568, loss 0.529953.
Train: 2018-08-01T00:00:26.976326: step 569, loss 0.577014.
Train: 2018-08-01T00:00:27.148161: step 570, loss 0.49805.
Test: 2018-08-01T00:00:27.632390: step 570, loss 0.547915.
Train: 2018-08-01T00:00:27.788636: step 571, loss 0.513222.
Train: 2018-08-01T00:00:27.944848: step 572, loss 0.606282.
Train: 2018-08-01T00:00:28.101055: step 573, loss 0.606365.
Train: 2018-08-01T00:00:28.257269: step 574, loss 0.529986.
Train: 2018-08-01T00:00:28.413500: step 575, loss 0.393108.
Train: 2018-08-01T00:00:28.569696: step 576, loss 0.559711.
Train: 2018-08-01T00:00:28.725885: step 577, loss 0.6096.
Train: 2018-08-01T00:00:28.897720: step 578, loss 0.582185.
Train: 2018-08-01T00:00:29.053932: step 579, loss 0.53009.
Train: 2018-08-01T00:00:29.210179: step 580, loss 0.517542.
Test: 2018-08-01T00:00:29.694411: step 580, loss 0.548047.
Train: 2018-08-01T00:00:29.850622: step 581, loss 0.60537.
Train: 2018-08-01T00:00:30.006866: step 582, loss 0.503389.
Train: 2018-08-01T00:00:30.163080: step 583, loss 0.609246.
Train: 2018-08-01T00:00:30.319286: step 584, loss 0.584239.
Train: 2018-08-01T00:00:30.475509: step 585, loss 0.56722.
Train: 2018-08-01T00:00:30.631719: step 586, loss 0.712469.
Train: 2018-08-01T00:00:30.803525: step 587, loss 0.514283.
Train: 2018-08-01T00:00:30.959762: step 588, loss 0.536154.
Train: 2018-08-01T00:00:31.115980: step 589, loss 0.53225.
Train: 2018-08-01T00:00:31.272194: step 590, loss 0.579659.
Test: 2018-08-01T00:00:31.740834: step 590, loss 0.548036.
Train: 2018-08-01T00:00:31.897047: step 591, loss 0.465205.
Train: 2018-08-01T00:00:32.053256: step 592, loss 0.561822.
Train: 2018-08-01T00:00:32.209475: step 593, loss 0.497902.
Train: 2018-08-01T00:00:32.381280: step 594, loss 0.439742.
Train: 2018-08-01T00:00:32.537493: step 595, loss 0.657727.
Train: 2018-08-01T00:00:32.693706: step 596, loss 0.563598.
Train: 2018-08-01T00:00:32.849950: step 597, loss 0.514338.
Train: 2018-08-01T00:00:33.021753: step 598, loss 0.543647.
Train: 2018-08-01T00:00:33.162346: step 599, loss 0.561842.
Train: 2018-08-01T00:00:33.334180: step 600, loss 0.53131.
Test: 2018-08-01T00:00:33.802820: step 600, loss 0.548045.
Train: 2018-08-01T00:00:34.490161: step 601, loss 0.52346.
Train: 2018-08-01T00:00:34.646399: step 602, loss 0.527763.
Train: 2018-08-01T00:00:34.818238: step 603, loss 0.562626.
Train: 2018-08-01T00:00:34.974421: step 604, loss 0.564217.
Train: 2018-08-01T00:00:35.130665: step 605, loss 0.65879.
Train: 2018-08-01T00:00:35.286880: step 606, loss 0.685503.
Train: 2018-08-01T00:00:35.443062: step 607, loss 0.561611.
Train: 2018-08-01T00:00:35.599277: step 608, loss 0.525397.
Train: 2018-08-01T00:00:35.755488: step 609, loss 0.499176.
Train: 2018-08-01T00:00:35.911734: step 610, loss 0.614802.
Test: 2018-08-01T00:00:36.395963: step 610, loss 0.548247.
Train: 2018-08-01T00:00:36.552210: step 611, loss 0.62796.
Train: 2018-08-01T00:00:36.724042: step 612, loss 0.620218.
Train: 2018-08-01T00:00:36.880256: step 613, loss 0.526149.
Train: 2018-08-01T00:00:37.036470: step 614, loss 0.54913.
Train: 2018-08-01T00:00:37.192654: step 615, loss 0.530162.
Train: 2018-08-01T00:00:37.364517: step 616, loss 0.543758.
Train: 2018-08-01T00:00:37.520732: step 617, loss 0.461703.
Train: 2018-08-01T00:00:37.676914: step 618, loss 0.496131.
Train: 2018-08-01T00:00:37.833127: step 619, loss 0.597871.
Train: 2018-08-01T00:00:38.004962: step 620, loss 0.695582.
Test: 2018-08-01T00:00:38.473632: step 620, loss 0.548557.
Train: 2018-08-01T00:00:38.629852: step 621, loss 0.478506.
Train: 2018-08-01T00:00:38.786029: step 622, loss 0.600947.
Train: 2018-08-01T00:00:38.942243: step 623, loss 0.578755.
Train: 2018-08-01T00:00:39.098456: step 624, loss 0.509371.
Train: 2018-08-01T00:00:39.254700: step 625, loss 0.561849.
Train: 2018-08-01T00:00:39.410914: step 626, loss 0.506863.
Train: 2018-08-01T00:00:39.567127: step 627, loss 0.495756.
Train: 2018-08-01T00:00:39.738961: step 628, loss 0.547616.
Train: 2018-08-01T00:00:39.895145: step 629, loss 0.525206.
Train: 2018-08-01T00:00:40.051389: step 630, loss 0.581268.
Test: 2018-08-01T00:00:40.520029: step 630, loss 0.548043.
Train: 2018-08-01T00:00:40.676243: step 631, loss 0.58329.
Train: 2018-08-01T00:00:40.848046: step 632, loss 0.523117.
Train: 2018-08-01T00:00:41.004290: step 633, loss 0.54656.
Train: 2018-08-01T00:00:41.160504: step 634, loss 0.55965.
Train: 2018-08-01T00:00:41.316717: step 635, loss 0.694646.
Train: 2018-08-01T00:00:41.472931: step 636, loss 0.615241.
Train: 2018-08-01T00:00:41.629117: step 637, loss 0.510975.
Train: 2018-08-01T00:00:41.785327: step 638, loss 0.516951.
Train: 2018-08-01T00:00:41.957161: step 639, loss 0.636258.
Train: 2018-08-01T00:00:42.113374: step 640, loss 0.563528.
Test: 2018-08-01T00:00:42.582045: step 640, loss 0.547973.
Train: 2018-08-01T00:00:42.738229: step 641, loss 0.564692.
Train: 2018-08-01T00:00:42.910095: step 642, loss 0.54743.
Train: 2018-08-01T00:00:43.066307: step 643, loss 0.606522.
Train: 2018-08-01T00:00:43.222520: step 644, loss 0.603119.
Train: 2018-08-01T00:00:43.378734: step 645, loss 0.491025.
Train: 2018-08-01T00:00:43.534942: step 646, loss 0.500998.
Train: 2018-08-01T00:00:43.706776: step 647, loss 0.480593.
Train: 2018-08-01T00:00:43.862990: step 648, loss 0.508609.
Train: 2018-08-01T00:00:44.019217: step 649, loss 0.55026.
Train: 2018-08-01T00:00:44.175392: step 650, loss 0.53096.
Test: 2018-08-01T00:00:44.644032: step 650, loss 0.547951.
Train: 2018-08-01T00:00:44.800247: step 651, loss 0.56408.
Train: 2018-08-01T00:00:44.956489: step 652, loss 0.543404.
Train: 2018-08-01T00:00:45.112697: step 653, loss 0.576092.
Train: 2018-08-01T00:00:45.284539: step 654, loss 0.595443.
Train: 2018-08-01T00:00:45.425130: step 655, loss 0.524997.
Train: 2018-08-01T00:00:45.596964: step 656, loss 0.66558.
Train: 2018-08-01T00:00:45.753178: step 657, loss 0.59327.
Train: 2018-08-01T00:00:45.909363: step 658, loss 0.532749.
Train: 2018-08-01T00:00:46.081220: step 659, loss 0.61432.
Train: 2018-08-01T00:00:46.237439: step 660, loss 0.588928.
Test: 2018-08-01T00:00:46.706079: step 660, loss 0.547943.
Train: 2018-08-01T00:00:46.862293: step 661, loss 0.44901.
Train: 2018-08-01T00:00:47.034129: step 662, loss 0.587724.
Train: 2018-08-01T00:00:47.190342: step 663, loss 0.602992.
Train: 2018-08-01T00:00:47.346524: step 664, loss 0.547666.
Train: 2018-08-01T00:00:47.502768: step 665, loss 0.598165.
Train: 2018-08-01T00:00:47.658983: step 666, loss 0.584762.
Train: 2018-08-01T00:00:47.815165: step 667, loss 0.528446.
Train: 2018-08-01T00:00:47.971380: step 668, loss 0.589004.
Train: 2018-08-01T00:00:48.127591: step 669, loss 0.497278.
Train: 2018-08-01T00:00:48.283806: step 670, loss 0.657639.
Test: 2018-08-01T00:00:48.768097: step 670, loss 0.548346.
Train: 2018-08-01T00:00:48.924281: step 671, loss 0.516547.
Train: 2018-08-01T00:00:49.080524: step 672, loss 0.446104.
Train: 2018-08-01T00:00:49.252329: step 673, loss 0.515746.
Train: 2018-08-01T00:00:49.408573: step 674, loss 0.493118.
Train: 2018-08-01T00:00:49.564786: step 675, loss 0.57917.
Train: 2018-08-01T00:00:49.720999: step 676, loss 0.566717.
Train: 2018-08-01T00:00:49.877213: step 677, loss 0.578018.
Train: 2018-08-01T00:00:50.033397: step 678, loss 0.560797.
Train: 2018-08-01T00:00:50.189610: step 679, loss 0.489883.
Train: 2018-08-01T00:00:50.361458: step 680, loss 0.546681.
Test: 2018-08-01T00:00:50.830086: step 680, loss 0.547992.
Train: 2018-08-01T00:00:50.986327: step 681, loss 0.459676.
Train: 2018-08-01T00:00:51.142541: step 682, loss 0.548493.
Train: 2018-08-01T00:00:51.298755: step 683, loss 0.572442.
Train: 2018-08-01T00:00:51.454968: step 684, loss 0.528544.
Train: 2018-08-01T00:00:51.611151: step 685, loss 0.562641.
Train: 2018-08-01T00:00:51.767365: step 686, loss 0.593689.
Train: 2018-08-01T00:00:51.923603: step 687, loss 0.527642.
Train: 2018-08-01T00:00:52.079791: step 688, loss 0.622088.
Train: 2018-08-01T00:00:52.236035: step 689, loss 0.565677.
Train: 2018-08-01T00:00:52.392248: step 690, loss 0.595582.
Test: 2018-08-01T00:00:52.876480: step 690, loss 0.54781.
Train: 2018-08-01T00:00:53.032694: step 691, loss 0.606925.
Train: 2018-08-01T00:00:53.204552: step 692, loss 0.527922.
Train: 2018-08-01T00:00:53.360771: step 693, loss 0.533115.
Train: 2018-08-01T00:00:53.516954: step 694, loss 0.524235.
Train: 2018-08-01T00:00:53.673193: step 695, loss 0.494759.
Train: 2018-08-01T00:00:53.829381: step 696, loss 0.597213.
Train: 2018-08-01T00:00:53.985625: step 697, loss 0.495152.
Train: 2018-08-01T00:00:54.141839: step 698, loss 0.524817.
Train: 2018-08-01T00:00:54.298053: step 699, loss 0.523826.
Train: 2018-08-01T00:00:54.454235: step 700, loss 0.561419.
Test: 2018-08-01T00:00:54.938527: step 700, loss 0.547839.
Train: 2018-08-01T00:00:55.688321: step 701, loss 0.530702.
Train: 2018-08-01T00:00:55.844535: step 702, loss 0.59186.
Train: 2018-08-01T00:00:56.016400: step 703, loss 0.640204.
Train: 2018-08-01T00:00:56.172614: step 704, loss 0.505667.
Train: 2018-08-01T00:00:56.328796: step 705, loss 0.488426.
Train: 2018-08-01T00:00:56.500630: step 706, loss 0.630156.
Train: 2018-08-01T00:00:56.656869: step 707, loss 0.562109.
Train: 2018-08-01T00:00:56.828710: step 708, loss 0.584329.
Train: 2018-08-01T00:00:56.984925: step 709, loss 0.525462.
Train: 2018-08-01T00:00:57.141136: step 710, loss 0.451313.
Test: 2018-08-01T00:00:57.640989: step 710, loss 0.547889.
Train: 2018-08-01T00:00:57.797202: step 711, loss 0.541838.
Train: 2018-08-01T00:00:57.953446: step 712, loss 0.507255.
Train: 2018-08-01T00:00:58.109655: step 713, loss 0.576238.
Train: 2018-08-01T00:00:58.343950: step 714, loss 0.51247.
Train: 2018-08-01T00:00:58.593894: step 715, loss 0.578564.
Train: 2018-08-01T00:00:58.781348: step 716, loss 0.512848.
Train: 2018-08-01T00:00:58.953207: step 717, loss 0.541494.
Train: 2018-08-01T00:00:59.109426: step 718, loss 0.512776.
Train: 2018-08-01T00:00:59.265609: step 719, loss 0.638346.
Train: 2018-08-01T00:00:59.437474: step 720, loss 0.580171.
Test: 2018-08-01T00:00:59.906084: step 720, loss 0.547795.
Train: 2018-08-01T00:01:00.093540: step 721, loss 0.598517.
Train: 2018-08-01T00:01:00.265375: step 722, loss 0.581251.
Train: 2018-08-01T00:01:00.421588: step 723, loss 0.689129.
Train: 2018-08-01T00:01:00.577826: step 724, loss 0.529405.
Train: 2018-08-01T00:01:00.734039: step 725, loss 0.580494.
Train: 2018-08-01T00:01:00.890253: step 726, loss 0.634212.
Train: 2018-08-01T00:01:01.062093: step 727, loss 0.568143.
Train: 2018-08-01T00:01:01.218306: step 728, loss 0.56292.
Train: 2018-08-01T00:01:01.374491: step 729, loss 0.629656.
Train: 2018-08-01T00:01:01.530703: step 730, loss 0.551649.
Test: 2018-08-01T00:01:02.014994: step 730, loss 0.548542.
Train: 2018-08-01T00:01:02.186830: step 731, loss 0.530413.
Train: 2018-08-01T00:01:02.343043: step 732, loss 0.577578.
Train: 2018-08-01T00:01:02.514847: step 733, loss 0.633341.
Train: 2018-08-01T00:01:02.671092: step 734, loss 0.512546.
Train: 2018-08-01T00:01:02.827305: step 735, loss 0.594217.
Train: 2018-08-01T00:01:02.967866: step 736, loss 0.612893.
Train: 2018-08-01T00:01:03.124111: step 737, loss 0.567768.
Train: 2018-08-01T00:01:03.295940: step 738, loss 0.591155.
Train: 2018-08-01T00:01:03.452155: step 739, loss 0.587669.
Train: 2018-08-01T00:01:03.608341: step 740, loss 0.578986.
Test: 2018-08-01T00:01:04.076981: step 740, loss 0.550304.
Train: 2018-08-01T00:01:04.233220: step 741, loss 0.544343.
Train: 2018-08-01T00:01:04.389409: step 742, loss 0.546667.
Train: 2018-08-01T00:01:04.545622: step 743, loss 0.496079.
Train: 2018-08-01T00:01:04.701837: step 744, loss 0.579122.
Train: 2018-08-01T00:01:04.858079: step 745, loss 0.549797.
Train: 2018-08-01T00:01:05.014262: step 746, loss 0.597097.
Train: 2018-08-01T00:01:05.170507: step 747, loss 0.516111.
Train: 2018-08-01T00:01:05.326690: step 748, loss 0.568877.
Train: 2018-08-01T00:01:05.482927: step 749, loss 0.532055.
Train: 2018-08-01T00:01:05.639145: step 750, loss 0.499687.
Test: 2018-08-01T00:01:06.107785: step 750, loss 0.549353.
Train: 2018-08-01T00:01:06.264007: step 751, loss 0.592213.
Train: 2018-08-01T00:01:06.435805: step 752, loss 0.53071.
Train: 2018-08-01T00:01:06.592018: step 753, loss 0.514445.
Train: 2018-08-01T00:01:06.763882: step 754, loss 0.753682.
Train: 2018-08-01T00:01:06.920067: step 755, loss 0.516913.
Train: 2018-08-01T00:01:07.076309: step 756, loss 0.584672.
Train: 2018-08-01T00:01:07.232523: step 757, loss 0.650319.
Train: 2018-08-01T00:01:07.388707: step 758, loss 0.580647.
Train: 2018-08-01T00:01:07.560546: step 759, loss 0.495267.
Train: 2018-08-01T00:01:07.716785: step 760, loss 0.546808.
Test: 2018-08-01T00:01:08.185425: step 760, loss 0.548867.
Train: 2018-08-01T00:01:08.341608: step 761, loss 0.661764.
Train: 2018-08-01T00:01:08.497847: step 762, loss 0.620025.
Train: 2018-08-01T00:01:08.669688: step 763, loss 0.51621.
Train: 2018-08-01T00:01:08.825869: step 764, loss 0.579877.
Train: 2018-08-01T00:01:08.982083: step 765, loss 0.576247.
Train: 2018-08-01T00:01:09.138321: step 766, loss 0.563208.
Train: 2018-08-01T00:01:09.278920: step 767, loss 0.506529.
Train: 2018-08-01T00:01:09.435133: step 768, loss 0.565916.
Train: 2018-08-01T00:01:09.591345: step 769, loss 0.470117.
Train: 2018-08-01T00:01:09.763180: step 770, loss 0.615191.
Test: 2018-08-01T00:01:10.231789: step 770, loss 0.548974.
Train: 2018-08-01T00:01:10.388005: step 771, loss 0.580861.
Train: 2018-08-01T00:01:10.559863: step 772, loss 0.571021.
Train: 2018-08-01T00:01:10.716053: step 773, loss 0.563907.
Train: 2018-08-01T00:01:10.872295: step 774, loss 0.628328.
Train: 2018-08-01T00:01:11.028480: step 775, loss 0.695273.
Train: 2018-08-01T00:01:11.200314: step 776, loss 0.63036.
Train: 2018-08-01T00:01:11.356527: step 777, loss 0.543621.
Train: 2018-08-01T00:01:11.512771: step 778, loss 0.563062.
Train: 2018-08-01T00:01:11.668985: step 779, loss 0.578232.
Train: 2018-08-01T00:01:11.825198: step 780, loss 0.565839.
Test: 2018-08-01T00:01:12.309436: step 780, loss 0.549946.
Train: 2018-08-01T00:01:12.465673: step 781, loss 0.597734.
Train: 2018-08-01T00:01:12.621886: step 782, loss 0.577042.
Train: 2018-08-01T00:01:12.778101: step 783, loss 0.625751.
Train: 2018-08-01T00:01:12.934283: step 784, loss 0.487946.
Train: 2018-08-01T00:01:13.090527: step 785, loss 0.540553.
Train: 2018-08-01T00:01:13.246740: step 786, loss 0.521382.
Train: 2018-08-01T00:01:13.402922: step 787, loss 0.470019.
Train: 2018-08-01T00:01:13.559137: step 788, loss 0.579949.
Train: 2018-08-01T00:01:13.731001: step 789, loss 0.595269.
Train: 2018-08-01T00:01:13.887210: step 790, loss 0.531779.
Test: 2018-08-01T00:01:14.371477: step 790, loss 0.549615.
Train: 2018-08-01T00:01:14.527696: step 791, loss 0.575774.
Train: 2018-08-01T00:01:14.683904: step 792, loss 0.583543.
Train: 2018-08-01T00:01:14.855732: step 793, loss 0.478745.
Train: 2018-08-01T00:01:15.011945: step 794, loss 0.662563.
Train: 2018-08-01T00:01:15.168165: step 795, loss 0.560199.
Train: 2018-08-01T00:01:15.324379: step 796, loss 0.564662.
Train: 2018-08-01T00:01:15.480592: step 797, loss 0.61591.
Train: 2018-08-01T00:01:15.652428: step 798, loss 0.623469.
Train: 2018-08-01T00:01:15.808610: step 799, loss 0.463341.
Train: 2018-08-01T00:01:15.964822: step 800, loss 0.541435.
Test: 2018-08-01T00:01:16.433463: step 800, loss 0.54872.
Train: 2018-08-01T00:01:17.167698: step 801, loss 0.54928.
Train: 2018-08-01T00:01:17.323910: step 802, loss 0.580269.
Train: 2018-08-01T00:01:17.480118: step 803, loss 0.559251.
Train: 2018-08-01T00:01:17.636307: step 804, loss 0.614835.
Train: 2018-08-01T00:01:17.792551: step 805, loss 0.550316.
Train: 2018-08-01T00:01:17.948758: step 806, loss 0.607848.
Train: 2018-08-01T00:01:18.104973: step 807, loss 0.548857.
Train: 2018-08-01T00:01:18.261160: step 808, loss 0.580398.
Train: 2018-08-01T00:01:18.417398: step 809, loss 0.443292.
Train: 2018-08-01T00:01:18.573623: step 810, loss 0.528411.
Test: 2018-08-01T00:01:19.057879: step 810, loss 0.548284.
Train: 2018-08-01T00:01:19.214092: step 811, loss 0.490223.
Train: 2018-08-01T00:01:19.370306: step 812, loss 0.563813.
Train: 2018-08-01T00:01:19.526515: step 813, loss 0.551194.
Train: 2018-08-01T00:01:19.682733: step 814, loss 0.672288.
Train: 2018-08-01T00:01:19.838947: step 815, loss 0.574532.
Train: 2018-08-01T00:01:20.010765: step 816, loss 0.510343.
Train: 2018-08-01T00:01:20.166995: step 817, loss 0.549765.
Train: 2018-08-01T00:01:20.323208: step 818, loss 0.563637.
Train: 2018-08-01T00:01:20.479415: step 819, loss 0.561579.
Train: 2018-08-01T00:01:20.635629: step 820, loss 0.529752.
Test: 2018-08-01T00:01:21.119865: step 820, loss 0.547908.
Train: 2018-08-01T00:01:21.276079: step 821, loss 0.492024.
Train: 2018-08-01T00:01:21.432293: step 822, loss 0.525947.
Train: 2018-08-01T00:01:21.588537: step 823, loss 0.551847.
Train: 2018-08-01T00:01:21.760371: step 824, loss 0.598439.
Train: 2018-08-01T00:01:21.916554: step 825, loss 0.538118.
Train: 2018-08-01T00:01:22.088389: step 826, loss 0.474205.
Train: 2018-08-01T00:01:22.244604: step 827, loss 0.702233.
Train: 2018-08-01T00:01:22.400819: step 828, loss 0.545368.
Train: 2018-08-01T00:01:22.572682: step 829, loss 0.561632.
Train: 2018-08-01T00:01:22.744486: step 830, loss 0.522075.
Test: 2018-08-01T00:01:23.228773: step 830, loss 0.547764.
Train: 2018-08-01T00:01:23.384991: step 831, loss 0.635813.
Train: 2018-08-01T00:01:23.541205: step 832, loss 0.591572.
Train: 2018-08-01T00:01:23.697387: step 833, loss 0.598317.
Train: 2018-08-01T00:01:23.869222: step 834, loss 0.726157.
Train: 2018-08-01T00:01:24.025437: step 835, loss 0.4916.
Train: 2018-08-01T00:01:24.181650: step 836, loss 0.583792.
Train: 2018-08-01T00:01:24.353484: step 837, loss 0.550404.
Train: 2018-08-01T00:01:24.509727: step 838, loss 0.442996.
Train: 2018-08-01T00:01:24.665942: step 839, loss 0.59993.
Train: 2018-08-01T00:01:24.822123: step 840, loss 0.576209.
Test: 2018-08-01T00:01:25.306416: step 840, loss 0.548242.
Train: 2018-08-01T00:01:25.462631: step 841, loss 0.574335.
Train: 2018-08-01T00:01:25.618842: step 842, loss 0.637641.
Train: 2018-08-01T00:01:25.790674: step 843, loss 0.542775.
Train: 2018-08-01T00:01:25.946891: step 844, loss 0.57892.
Train: 2018-08-01T00:01:26.103104: step 845, loss 0.565806.
Train: 2018-08-01T00:01:26.259317: step 846, loss 0.528464.
Train: 2018-08-01T00:01:26.431150: step 847, loss 0.596103.
Train: 2018-08-01T00:01:26.587366: step 848, loss 0.577886.
Train: 2018-08-01T00:01:26.743549: step 849, loss 0.514582.
Train: 2018-08-01T00:01:26.915414: step 850, loss 0.542224.
Test: 2018-08-01T00:01:27.399645: step 850, loss 0.548757.
Train: 2018-08-01T00:01:27.555859: step 851, loss 0.563858.
Train: 2018-08-01T00:01:27.712097: step 852, loss 0.527654.
Train: 2018-08-01T00:01:27.899529: step 853, loss 0.550065.
Train: 2018-08-01T00:01:28.071389: step 854, loss 0.545862.
Train: 2018-08-01T00:01:28.227577: step 855, loss 0.524577.
Train: 2018-08-01T00:01:28.399425: step 856, loss 0.583418.
Train: 2018-08-01T00:01:28.555624: step 857, loss 0.563285.
Train: 2018-08-01T00:01:28.727490: step 858, loss 0.733528.
Train: 2018-08-01T00:01:28.883710: step 859, loss 0.666057.
Train: 2018-08-01T00:01:29.039889: step 860, loss 0.510333.
Test: 2018-08-01T00:01:29.508550: step 860, loss 0.548787.
Train: 2018-08-01T00:01:29.680391: step 861, loss 0.580624.
Train: 2018-08-01T00:01:29.836574: step 862, loss 0.535369.
Train: 2018-08-01T00:01:30.008435: step 863, loss 0.580854.
Train: 2018-08-01T00:01:30.164654: step 864, loss 0.430421.
Train: 2018-08-01T00:01:30.320866: step 865, loss 0.59769.
Train: 2018-08-01T00:01:30.492672: step 866, loss 0.560587.
Train: 2018-08-01T00:01:30.648914: step 867, loss 0.511956.
Train: 2018-08-01T00:01:30.805098: step 868, loss 0.544323.
Train: 2018-08-01T00:01:30.961312: step 869, loss 0.64991.
Train: 2018-08-01T00:01:31.117555: step 870, loss 0.644689.
Test: 2018-08-01T00:01:31.601815: step 870, loss 0.548817.
Train: 2018-08-01T00:01:31.758000: step 871, loss 0.628358.
Train: 2018-08-01T00:01:31.914244: step 872, loss 0.564259.
Train: 2018-08-01T00:01:32.086048: step 873, loss 0.494251.
Train: 2018-08-01T00:01:32.242291: step 874, loss 0.461531.
Train: 2018-08-01T00:01:32.398475: step 875, loss 0.567768.
Train: 2018-08-01T00:01:32.570311: step 876, loss 0.529463.
Train: 2018-08-01T00:01:32.726523: step 877, loss 0.56304.
Train: 2018-08-01T00:01:32.882735: step 878, loss 0.682301.
Train: 2018-08-01T00:01:33.048707: step 879, loss 0.580219.
Train: 2018-08-01T00:01:33.198575: step 880, loss 0.528801.
Test: 2018-08-01T00:01:33.664267: step 880, loss 0.548558.
Train: 2018-08-01T00:01:33.820481: step 881, loss 0.562682.
Train: 2018-08-01T00:01:33.976665: step 882, loss 0.673057.
Train: 2018-08-01T00:01:34.132878: step 883, loss 0.557669.
Train: 2018-08-01T00:01:34.304742: step 884, loss 0.598956.
Train: 2018-08-01T00:01:34.460926: step 885, loss 0.499856.
Train: 2018-08-01T00:01:34.632760: step 886, loss 0.532305.
Train: 2018-08-01T00:01:34.789004: step 887, loss 0.564815.
Train: 2018-08-01T00:01:34.945217: step 888, loss 0.529256.
Train: 2018-08-01T00:01:35.101400: step 889, loss 0.562221.
Train: 2018-08-01T00:01:35.257644: step 890, loss 0.532172.
Test: 2018-08-01T00:01:35.741905: step 890, loss 0.548536.
Train: 2018-08-01T00:01:35.913710: step 891, loss 0.561057.
Train: 2018-08-01T00:01:36.069923: step 892, loss 0.596756.
Train: 2018-08-01T00:01:36.226136: step 893, loss 0.465127.
Train: 2018-08-01T00:01:36.382350: step 894, loss 0.611527.
Train: 2018-08-01T00:01:36.538571: step 895, loss 0.578094.
Train: 2018-08-01T00:01:36.726020: step 896, loss 0.57069.
Train: 2018-08-01T00:01:36.882234: step 897, loss 0.446841.
Train: 2018-08-01T00:01:37.038447: step 898, loss 0.512934.
Train: 2018-08-01T00:01:37.194661: step 899, loss 0.544121.
Train: 2018-08-01T00:01:37.350874: step 900, loss 0.586645.
Test: 2018-08-01T00:01:37.835165: step 900, loss 0.548063.
Train: 2018-08-01T00:01:38.569365: step 901, loss 0.637314.
Train: 2018-08-01T00:01:38.741174: step 902, loss 0.510669.
Train: 2018-08-01T00:01:38.897417: step 903, loss 0.65649.
Train: 2018-08-01T00:01:39.053631: step 904, loss 0.456617.
Train: 2018-08-01T00:01:39.209814: step 905, loss 0.558006.
Train: 2018-08-01T00:01:39.366027: step 906, loss 0.567647.
Train: 2018-08-01T00:01:39.537892: step 907, loss 0.496333.
Train: 2018-08-01T00:01:39.694101: step 908, loss 0.578883.
Train: 2018-08-01T00:01:39.850288: step 909, loss 0.581769.
Train: 2018-08-01T00:01:40.022153: step 910, loss 0.527471.
Test: 2018-08-01T00:01:40.490763: step 910, loss 0.54795.
Train: 2018-08-01T00:01:40.662598: step 911, loss 0.56648.
Train: 2018-08-01T00:01:40.818812: step 912, loss 0.610394.
Train: 2018-08-01T00:01:40.975026: step 913, loss 0.68325.
Train: 2018-08-01T00:01:41.131238: step 914, loss 0.488574.
Train: 2018-08-01T00:01:41.303073: step 915, loss 0.561749.
Train: 2018-08-01T00:01:41.459287: step 916, loss 0.541999.
Train: 2018-08-01T00:01:41.615500: step 917, loss 0.666892.
Train: 2018-08-01T00:01:41.771714: step 918, loss 0.553715.
Train: 2018-08-01T00:01:41.927926: step 919, loss 0.543456.
Train: 2018-08-01T00:01:42.084140: step 920, loss 0.540135.
Test: 2018-08-01T00:01:42.568431: step 920, loss 0.548096.
Train: 2018-08-01T00:01:42.724640: step 921, loss 0.457982.
Train: 2018-08-01T00:01:42.880829: step 922, loss 0.570275.
Train: 2018-08-01T00:01:43.037073: step 923, loss 0.504506.
Train: 2018-08-01T00:01:43.208877: step 924, loss 0.553578.
Train: 2018-08-01T00:01:43.365090: step 925, loss 0.52758.
Train: 2018-08-01T00:01:43.536925: step 926, loss 0.672346.
Train: 2018-08-01T00:01:43.693169: step 927, loss 0.639169.
Train: 2018-08-01T00:01:43.864973: step 928, loss 0.455288.
Train: 2018-08-01T00:01:44.021187: step 929, loss 0.601298.
Train: 2018-08-01T00:01:44.177401: step 930, loss 0.525298.
Test: 2018-08-01T00:01:44.661662: step 930, loss 0.547822.
Train: 2018-08-01T00:01:44.817874: step 931, loss 0.545388.
Train: 2018-08-01T00:01:44.974119: step 932, loss 0.38635.
Train: 2018-08-01T00:01:45.145924: step 933, loss 0.584958.
Train: 2018-08-01T00:01:45.302161: step 934, loss 0.595552.
Train: 2018-08-01T00:01:45.458381: step 935, loss 0.485843.
Train: 2018-08-01T00:01:45.614593: step 936, loss 0.523615.
Train: 2018-08-01T00:01:45.786423: step 937, loss 0.603921.
Train: 2018-08-01T00:01:45.942642: step 938, loss 0.474898.
Train: 2018-08-01T00:01:46.098825: step 939, loss 0.641335.
Train: 2018-08-01T00:01:46.255069: step 940, loss 0.560571.
Test: 2018-08-01T00:01:46.739328: step 940, loss 0.547712.
Train: 2018-08-01T00:01:46.895513: step 941, loss 0.526578.
Train: 2018-08-01T00:01:47.051752: step 942, loss 0.514176.
Train: 2018-08-01T00:01:47.223595: step 943, loss 0.550594.
Train: 2018-08-01T00:01:47.379800: step 944, loss 0.544151.
Train: 2018-08-01T00:01:47.535988: step 945, loss 0.582349.
Train: 2018-08-01T00:01:47.692203: step 946, loss 0.557471.
Train: 2018-08-01T00:01:47.848415: step 947, loss 0.61249.
Train: 2018-08-01T00:01:48.020250: step 948, loss 0.627685.
Train: 2018-08-01T00:01:48.176488: step 949, loss 0.476493.
Train: 2018-08-01T00:01:48.332678: step 950, loss 0.51053.
Test: 2018-08-01T00:01:48.801349: step 950, loss 0.547717.
Train: 2018-08-01T00:01:48.957561: step 951, loss 0.605229.
Train: 2018-08-01T00:01:49.129395: step 952, loss 0.577612.
Train: 2018-08-01T00:01:49.285609: step 953, loss 0.562271.
Train: 2018-08-01T00:01:49.441792: step 954, loss 0.515335.
Train: 2018-08-01T00:01:49.598036: step 955, loss 0.50747.
Train: 2018-08-01T00:01:49.769873: step 956, loss 0.469553.
Train: 2018-08-01T00:01:49.926087: step 957, loss 0.457119.
Train: 2018-08-01T00:01:50.082297: step 958, loss 0.476026.
Train: 2018-08-01T00:01:50.238513: step 959, loss 0.548214.
Train: 2018-08-01T00:01:50.394719: step 960, loss 0.54396.
Test: 2018-08-01T00:01:50.878955: step 960, loss 0.5477.
Train: 2018-08-01T00:01:51.035171: step 961, loss 0.454276.
Train: 2018-08-01T00:01:51.207003: step 962, loss 0.52284.
Train: 2018-08-01T00:01:51.372322: step 963, loss 0.545075.
Train: 2018-08-01T00:01:51.525783: step 964, loss 0.704728.
Train: 2018-08-01T00:01:51.692170: step 965, loss 0.505108.
Train: 2018-08-01T00:01:51.843537: step 966, loss 0.515702.
Train: 2018-08-01T00:01:51.999752: step 967, loss 0.65335.
Train: 2018-08-01T00:01:52.155992: step 968, loss 0.588061.
Train: 2018-08-01T00:01:52.312210: step 969, loss 0.548383.
Train: 2018-08-01T00:01:52.468394: step 970, loss 0.554109.
Test: 2018-08-01T00:01:52.952684: step 970, loss 0.547709.
Train: 2018-08-01T00:01:53.108872: step 971, loss 0.54362.
Train: 2018-08-01T00:01:53.265114: step 972, loss 0.539158.
Train: 2018-08-01T00:01:53.421319: step 973, loss 0.561456.
Train: 2018-08-01T00:01:53.577533: step 974, loss 0.597057.
Train: 2018-08-01T00:01:53.749344: step 975, loss 0.74583.
Train: 2018-08-01T00:01:53.905585: step 976, loss 0.563284.
Train: 2018-08-01T00:01:54.061801: step 977, loss 0.548362.
Train: 2018-08-01T00:01:54.218019: step 978, loss 0.57943.
Train: 2018-08-01T00:01:54.374227: step 979, loss 0.563337.
Train: 2018-08-01T00:01:54.530441: step 980, loss 0.652423.
Test: 2018-08-01T00:01:55.014702: step 980, loss 0.548053.
Train: 2018-08-01T00:01:55.170885: step 981, loss 0.51219.
Train: 2018-08-01T00:01:55.342748: step 982, loss 0.569959.
Train: 2018-08-01T00:01:55.498958: step 983, loss 0.533765.
Train: 2018-08-01T00:01:55.655177: step 984, loss 0.582129.
Train: 2018-08-01T00:01:55.826981: step 985, loss 0.531209.
Train: 2018-08-01T00:01:55.983195: step 986, loss 0.577927.
Train: 2018-08-01T00:01:56.139408: step 987, loss 0.62817.
Train: 2018-08-01T00:01:56.295623: step 988, loss 0.477257.
Train: 2018-08-01T00:01:56.451836: step 989, loss 0.5617.
Train: 2018-08-01T00:01:56.608073: step 990, loss 0.711042.
Test: 2018-08-01T00:01:57.076715: step 990, loss 0.549006.
Train: 2018-08-01T00:01:57.248523: step 991, loss 0.578282.
Train: 2018-08-01T00:01:57.404765: step 992, loss 0.645057.
Train: 2018-08-01T00:01:57.576573: step 993, loss 0.464424.
Train: 2018-08-01T00:01:57.746488: step 994, loss 0.563891.
Train: 2018-08-01T00:01:57.906150: step 995, loss 0.514982.
Train: 2018-08-01T00:01:58.066824: step 996, loss 0.529948.
Train: 2018-08-01T00:01:58.233122: step 997, loss 0.543826.
Train: 2018-08-01T00:01:58.390254: step 998, loss 0.464441.
Train: 2018-08-01T00:01:58.546496: step 999, loss 0.594462.
Train: 2018-08-01T00:01:58.702710: step 1000, loss 0.59939.
Test: 2018-08-01T00:01:59.202574: step 1000, loss 0.54903.
Train: 2018-08-01T00:01:59.952412: step 1001, loss 0.630497.
Train: 2018-08-01T00:02:00.108600: step 1002, loss 0.47861.
Train: 2018-08-01T00:02:00.264813: step 1003, loss 0.742611.
Train: 2018-08-01T00:02:00.421027: step 1004, loss 0.498145.
Train: 2018-08-01T00:02:00.592862: step 1005, loss 0.610385.
Train: 2018-08-01T00:02:00.749109: step 1006, loss 0.592245.
Train: 2018-08-01T00:02:00.920936: step 1007, loss 0.545911.
Train: 2018-08-01T00:02:01.092771: step 1008, loss 0.62598.
Train: 2018-08-01T00:02:01.248959: step 1009, loss 0.546479.
Train: 2018-08-01T00:02:01.405171: step 1010, loss 0.596961.
Test: 2018-08-01T00:02:01.889463: step 1010, loss 0.549028.
Train: 2018-08-01T00:02:02.045647: step 1011, loss 0.576539.
Train: 2018-08-01T00:02:02.217511: step 1012, loss 0.615722.
Train: 2018-08-01T00:02:02.373720: step 1013, loss 0.545446.
Train: 2018-08-01T00:02:02.545529: step 1014, loss 0.628769.
Train: 2018-08-01T00:02:02.701773: step 1015, loss 0.59453.
Train: 2018-08-01T00:02:02.873577: step 1016, loss 0.545965.
Train: 2018-08-01T00:02:03.029824: step 1017, loss 0.575996.
Train: 2018-08-01T00:02:03.186030: step 1018, loss 0.498361.
Train: 2018-08-01T00:02:03.357841: step 1019, loss 0.578825.
Train: 2018-08-01T00:02:03.514053: step 1020, loss 0.547997.
Test: 2018-08-01T00:02:03.982692: step 1020, loss 0.549257.
Train: 2018-08-01T00:02:04.138930: step 1021, loss 0.54606.
Train: 2018-08-01T00:02:04.310742: step 1022, loss 0.513641.
Train: 2018-08-01T00:02:04.482576: step 1023, loss 0.496808.
Train: 2018-08-01T00:02:04.638822: step 1024, loss 0.679248.
Train: 2018-08-01T00:02:04.810654: step 1025, loss 0.465635.
Train: 2018-08-01T00:02:04.966868: step 1026, loss 0.527101.
Train: 2018-08-01T00:02:05.123075: step 1027, loss 0.545135.
Train: 2018-08-01T00:02:05.279265: step 1028, loss 0.445141.
Train: 2018-08-01T00:02:05.435478: step 1029, loss 0.51363.
Train: 2018-08-01T00:02:05.591721: step 1030, loss 0.513358.
Test: 2018-08-01T00:02:06.091577: step 1030, loss 0.548173.
Train: 2018-08-01T00:02:06.247812: step 1031, loss 0.510391.
Train: 2018-08-01T00:02:06.419622: step 1032, loss 0.59868.
Train: 2018-08-01T00:02:06.591482: step 1033, loss 0.579628.
Train: 2018-08-01T00:02:06.747695: step 1034, loss 0.581065.
Train: 2018-08-01T00:02:06.903917: step 1035, loss 0.456725.
Train: 2018-08-01T00:02:07.060097: step 1036, loss 0.586082.
Train: 2018-08-01T00:02:07.231933: step 1037, loss 0.506485.
Train: 2018-08-01T00:02:07.397278: step 1038, loss 0.568549.
Train: 2018-08-01T00:02:07.554020: step 1039, loss 0.52718.
Train: 2018-08-01T00:02:07.717118: step 1040, loss 0.489238.
Test: 2018-08-01T00:02:08.183971: step 1040, loss 0.547675.
Train: 2018-08-01T00:02:08.340184: step 1041, loss 0.538126.
Train: 2018-08-01T00:02:08.496369: step 1042, loss 0.708084.
Train: 2018-08-01T00:02:08.652607: step 1043, loss 0.507623.
Train: 2018-08-01T00:02:08.808796: step 1044, loss 0.50645.
Train: 2018-08-01T00:02:08.980630: step 1045, loss 0.467057.
Train: 2018-08-01T00:02:09.136867: step 1046, loss 0.599903.
Train: 2018-08-01T00:02:09.293057: step 1047, loss 0.58438.
Train: 2018-08-01T00:02:09.464891: step 1048, loss 0.541943.
Train: 2018-08-01T00:02:09.621137: step 1049, loss 0.605784.
Train: 2018-08-01T00:02:09.777349: step 1050, loss 0.487692.
Test: 2018-08-01T00:02:10.261609: step 1050, loss 0.547742.
Train: 2018-08-01T00:02:10.417817: step 1051, loss 0.454061.
Train: 2018-08-01T00:02:10.589658: step 1052, loss 0.599154.
Train: 2018-08-01T00:02:10.761492: step 1053, loss 0.4882.
Train: 2018-08-01T00:02:10.933297: step 1054, loss 0.639207.
Train: 2018-08-01T00:02:11.089542: step 1055, loss 0.578315.
Train: 2018-08-01T00:02:11.261346: step 1056, loss 0.54341.
Train: 2018-08-01T00:02:11.401937: step 1057, loss 0.728398.
Train: 2018-08-01T00:02:11.573773: step 1058, loss 0.515716.
Train: 2018-08-01T00:02:11.729986: step 1059, loss 0.491364.
Train: 2018-08-01T00:02:11.901854: step 1060, loss 0.599215.
Test: 2018-08-01T00:02:12.370491: step 1060, loss 0.547677.
Train: 2018-08-01T00:02:12.636037: step 1061, loss 0.489956.
Train: 2018-08-01T00:02:12.792267: step 1062, loss 0.543498.
Train: 2018-08-01T00:02:12.948450: step 1063, loss 0.52568.
Train: 2018-08-01T00:02:13.104694: step 1064, loss 0.561134.
Train: 2018-08-01T00:02:13.260907: step 1065, loss 0.526199.
Train: 2018-08-01T00:02:13.432743: step 1066, loss 0.472673.
Train: 2018-08-01T00:02:13.588955: step 1067, loss 0.564563.
Train: 2018-08-01T00:02:13.745171: step 1068, loss 0.611848.
Train: 2018-08-01T00:02:13.901383: step 1069, loss 0.679296.
Train: 2018-08-01T00:02:14.057596: step 1070, loss 0.559108.
Test: 2018-08-01T00:02:14.526257: step 1070, loss 0.547667.
Train: 2018-08-01T00:02:14.698041: step 1071, loss 0.603834.
Train: 2018-08-01T00:02:14.854293: step 1072, loss 0.544465.
Train: 2018-08-01T00:02:15.026749: step 1073, loss 0.488335.
Train: 2018-08-01T00:02:15.180101: step 1074, loss 0.633345.
Train: 2018-08-01T00:02:15.336761: step 1075, loss 0.614181.
Train: 2018-08-01T00:02:15.496691: step 1076, loss 0.595005.
Train: 2018-08-01T00:02:15.655937: step 1077, loss 0.599085.
Train: 2018-08-01T00:02:15.812150: step 1078, loss 0.564556.
Train: 2018-08-01T00:02:15.968381: step 1079, loss 0.511062.
Train: 2018-08-01T00:02:16.140199: step 1080, loss 0.52845.
Test: 2018-08-01T00:02:16.608839: step 1080, loss 0.548012.
Train: 2018-08-01T00:02:16.780704: step 1081, loss 0.492267.
Train: 2018-08-01T00:02:16.936918: step 1082, loss 0.513611.
Train: 2018-08-01T00:02:17.093112: step 1083, loss 0.51015.
Train: 2018-08-01T00:02:17.249315: step 1084, loss 0.558977.
Train: 2018-08-01T00:02:17.421179: step 1085, loss 0.546539.
Train: 2018-08-01T00:02:17.577393: step 1086, loss 0.612931.
Train: 2018-08-01T00:02:17.733606: step 1087, loss 0.61325.
Train: 2018-08-01T00:02:17.889821: step 1088, loss 0.54491.
Train: 2018-08-01T00:02:18.046034: step 1089, loss 0.614313.
Train: 2018-08-01T00:02:18.217862: step 1090, loss 0.558247.
Test: 2018-08-01T00:02:18.686479: step 1090, loss 0.548015.
Train: 2018-08-01T00:02:18.858313: step 1091, loss 0.666117.
Train: 2018-08-01T00:02:19.014526: step 1092, loss 0.612601.
Train: 2018-08-01T00:02:19.170739: step 1093, loss 0.527784.
Train: 2018-08-01T00:02:19.326952: step 1094, loss 0.529348.
Train: 2018-08-01T00:02:19.498818: step 1095, loss 0.667755.
Train: 2018-08-01T00:02:19.655001: step 1096, loss 0.647844.
Train: 2018-08-01T00:02:19.811214: step 1097, loss 0.563573.
Train: 2018-08-01T00:02:19.967428: step 1098, loss 0.447178.
Train: 2018-08-01T00:02:20.123640: step 1099, loss 0.530564.
Train: 2018-08-01T00:02:20.279854: step 1100, loss 0.545085.
Test: 2018-08-01T00:02:20.764144: step 1100, loss 0.548608.
Train: 2018-08-01T00:02:21.513940: step 1101, loss 0.682842.
Train: 2018-08-01T00:02:21.685775: step 1102, loss 0.49724.
Train: 2018-08-01T00:02:21.841988: step 1103, loss 0.564141.
Train: 2018-08-01T00:02:21.998202: step 1104, loss 0.561281.
Train: 2018-08-01T00:02:22.154441: step 1105, loss 0.598662.
Train: 2018-08-01T00:02:22.326280: step 1106, loss 0.581989.
Train: 2018-08-01T00:02:22.482465: step 1107, loss 0.562529.
Train: 2018-08-01T00:02:22.638678: step 1108, loss 0.545992.
Train: 2018-08-01T00:02:22.794891: step 1109, loss 0.676777.
Train: 2018-08-01T00:02:22.966755: step 1110, loss 0.529918.
Test: 2018-08-01T00:02:23.450986: step 1110, loss 0.549027.
Train: 2018-08-01T00:02:23.622852: step 1111, loss 0.562407.
Train: 2018-08-01T00:02:23.779059: step 1112, loss 0.561532.
Train: 2018-08-01T00:02:23.935279: step 1113, loss 0.596875.
Train: 2018-08-01T00:02:24.107114: step 1114, loss 0.598202.
Train: 2018-08-01T00:02:24.263298: step 1115, loss 0.577907.
Train: 2018-08-01T00:02:24.419540: step 1116, loss 0.658508.
Train: 2018-08-01T00:02:24.591369: step 1117, loss 0.547551.
Train: 2018-08-01T00:02:24.747588: step 1118, loss 0.563433.
Train: 2018-08-01T00:02:24.919423: step 1119, loss 0.595144.
Train: 2018-08-01T00:02:25.075636: step 1120, loss 0.561857.
Test: 2018-08-01T00:02:25.544247: step 1120, loss 0.549546.
Train: 2018-08-01T00:02:25.700491: step 1121, loss 0.52999.
Train: 2018-08-01T00:02:25.856674: step 1122, loss 0.545511.
Train: 2018-08-01T00:02:26.028538: step 1123, loss 0.467527.
Train: 2018-08-01T00:02:26.200343: step 1124, loss 0.546365.
Train: 2018-08-01T00:02:26.356556: step 1125, loss 0.562687.
Train: 2018-08-01T00:02:26.512802: step 1126, loss 0.628135.
Train: 2018-08-01T00:02:26.668983: step 1127, loss 0.562299.
Train: 2018-08-01T00:02:26.825229: step 1128, loss 0.513659.
Train: 2018-08-01T00:02:26.997062: step 1129, loss 0.596372.
Train: 2018-08-01T00:02:27.153246: step 1130, loss 0.693703.
Test: 2018-08-01T00:02:27.637506: step 1130, loss 0.549018.
Train: 2018-08-01T00:02:27.793750: step 1131, loss 0.495737.
Train: 2018-08-01T00:02:27.949933: step 1132, loss 0.628216.
Train: 2018-08-01T00:02:28.121768: step 1133, loss 0.564248.
Train: 2018-08-01T00:02:28.262392: step 1134, loss 0.512627.
Train: 2018-08-01T00:02:28.434195: step 1135, loss 0.613163.
Train: 2018-08-01T00:02:28.590409: step 1136, loss 0.494986.
Train: 2018-08-01T00:02:28.746646: step 1137, loss 0.580235.
Train: 2018-08-01T00:02:28.918487: step 1138, loss 0.624787.
Train: 2018-08-01T00:02:29.074696: step 1139, loss 0.578463.
Train: 2018-08-01T00:02:29.230919: step 1140, loss 0.546597.
Test: 2018-08-01T00:02:29.715171: step 1140, loss 0.548778.
Train: 2018-08-01T00:02:29.886980: step 1141, loss 0.532026.
Train: 2018-08-01T00:02:30.043219: step 1142, loss 0.559667.
Train: 2018-08-01T00:02:30.199407: step 1143, loss 0.595324.
Train: 2018-08-01T00:02:30.371269: step 1144, loss 0.633598.
Train: 2018-08-01T00:02:30.527485: step 1145, loss 0.462827.
Train: 2018-08-01T00:02:30.683699: step 1146, loss 0.51082.
Train: 2018-08-01T00:02:30.855529: step 1147, loss 0.66111.
Train: 2018-08-01T00:02:31.011749: step 1148, loss 0.462921.
Train: 2018-08-01T00:02:31.167954: step 1149, loss 0.547394.
Train: 2018-08-01T00:02:31.324148: step 1150, loss 0.581538.
Test: 2018-08-01T00:02:31.808406: step 1150, loss 0.548338.
Train: 2018-08-01T00:02:31.980269: step 1151, loss 0.495064.
Train: 2018-08-01T00:02:32.136486: step 1152, loss 0.529555.
Train: 2018-08-01T00:02:32.308318: step 1153, loss 0.614954.
Train: 2018-08-01T00:02:32.464532: step 1154, loss 0.629966.
Train: 2018-08-01T00:02:32.636368: step 1155, loss 0.509607.
Train: 2018-08-01T00:02:32.808202: step 1156, loss 0.495941.
Train: 2018-08-01T00:02:32.980007: step 1157, loss 0.510057.
Train: 2018-08-01T00:02:33.136252: step 1158, loss 0.493023.
Train: 2018-08-01T00:02:33.308054: step 1159, loss 0.600968.
Train: 2018-08-01T00:02:33.464297: step 1160, loss 0.475196.
Test: 2018-08-01T00:02:33.944450: step 1160, loss 0.547834.
Train: 2018-08-01T00:02:34.116319: step 1161, loss 0.529057.
Train: 2018-08-01T00:02:34.272521: step 1162, loss 0.631039.
Train: 2018-08-01T00:02:34.447438: step 1163, loss 0.526132.
Train: 2018-08-01T00:02:34.607429: step 1164, loss 0.489932.
Train: 2018-08-01T00:02:34.767452: step 1165, loss 0.527173.
Train: 2018-08-01T00:02:34.917474: step 1166, loss 0.616135.
Train: 2018-08-01T00:02:35.074514: step 1167, loss 0.451297.
Train: 2018-08-01T00:02:35.246346: step 1168, loss 0.575849.
Train: 2018-08-01T00:02:35.402529: step 1169, loss 0.675639.
Train: 2018-08-01T00:02:35.558742: step 1170, loss 0.544847.
Test: 2018-08-01T00:02:36.043004: step 1170, loss 0.547637.
Train: 2018-08-01T00:02:36.214869: step 1171, loss 0.580734.
Train: 2018-08-01T00:02:36.371077: step 1172, loss 0.542521.
Train: 2018-08-01T00:02:36.558508: step 1173, loss 0.634812.
Train: 2018-08-01T00:02:36.761589: step 1174, loss 0.650538.
Train: 2018-08-01T00:02:37.027151: step 1175, loss 0.614136.
Train: 2018-08-01T00:02:37.230226: step 1176, loss 0.544054.
Train: 2018-08-01T00:02:37.386439: step 1177, loss 0.48742.
Train: 2018-08-01T00:02:37.542678: step 1178, loss 0.578692.
Train: 2018-08-01T00:02:37.698899: step 1179, loss 0.631721.
Train: 2018-08-01T00:02:37.855104: step 1180, loss 0.65534.
Test: 2018-08-01T00:02:38.339371: step 1180, loss 0.547761.
Train: 2018-08-01T00:02:38.495584: step 1181, loss 0.545672.
Train: 2018-08-01T00:02:38.667390: step 1182, loss 0.635056.
Train: 2018-08-01T00:02:38.823636: step 1183, loss 0.615796.
Train: 2018-08-01T00:02:38.979817: step 1184, loss 0.56326.
Train: 2018-08-01T00:02:39.136055: step 1185, loss 0.632254.
Train: 2018-08-01T00:02:39.292277: step 1186, loss 0.54512.
Train: 2018-08-01T00:02:39.448490: step 1187, loss 0.56197.
Train: 2018-08-01T00:02:39.604700: step 1188, loss 0.562087.
Train: 2018-08-01T00:02:39.776505: step 1189, loss 0.599724.
Train: 2018-08-01T00:02:39.932746: step 1190, loss 0.530025.
Test: 2018-08-01T00:02:40.401357: step 1190, loss 0.548799.
Train: 2018-08-01T00:02:40.557573: step 1191, loss 0.559707.
Train: 2018-08-01T00:02:40.729406: step 1192, loss 0.762357.
Train: 2018-08-01T00:02:40.885650: step 1193, loss 0.563557.
Train: 2018-08-01T00:02:41.041833: step 1194, loss 0.593212.
Train: 2018-08-01T00:02:41.198080: step 1195, loss 0.611311.
Train: 2018-08-01T00:02:41.369881: step 1196, loss 0.608327.
Train: 2018-08-01T00:02:41.541717: step 1197, loss 0.579697.
Train: 2018-08-01T00:02:41.697962: step 1198, loss 0.500873.
Train: 2018-08-01T00:02:41.869794: step 1199, loss 0.514577.
Train: 2018-08-01T00:02:42.041619: step 1200, loss 0.529498.
Test: 2018-08-01T00:02:42.510238: step 1200, loss 0.550085.
Train: 2018-08-01T00:02:43.270580: step 1201, loss 0.639258.
Train: 2018-08-01T00:02:43.434623: step 1202, loss 0.517073.
Train: 2018-08-01T00:02:43.606489: step 1203, loss 0.578594.
Train: 2018-08-01T00:02:43.762697: step 1204, loss 0.594403.
Train: 2018-08-01T00:02:43.934537: step 1205, loss 0.68779.
Train: 2018-08-01T00:02:44.106359: step 1206, loss 0.563717.
Train: 2018-08-01T00:02:44.262555: step 1207, loss 0.611874.
Train: 2018-08-01T00:02:44.434389: step 1208, loss 0.563234.
Train: 2018-08-01T00:02:44.590628: step 1209, loss 0.593857.
Train: 2018-08-01T00:02:44.746816: step 1210, loss 0.566541.
Test: 2018-08-01T00:02:45.231108: step 1210, loss 0.550271.
Train: 2018-08-01T00:02:45.402939: step 1211, loss 0.501852.
Train: 2018-08-01T00:02:45.574752: step 1212, loss 0.581892.
Train: 2018-08-01T00:02:45.730962: step 1213, loss 0.609587.
Train: 2018-08-01T00:02:45.887199: step 1214, loss 0.612693.
Train: 2018-08-01T00:02:46.059010: step 1215, loss 0.549532.
Train: 2018-08-01T00:02:46.215222: step 1216, loss 0.502255.
Train: 2018-08-01T00:02:46.402678: step 1217, loss 0.580016.
Train: 2018-08-01T00:02:46.574514: step 1218, loss 0.612135.
Train: 2018-08-01T00:02:46.730726: step 1219, loss 0.559659.
Train: 2018-08-01T00:02:46.886942: step 1220, loss 0.655284.
Test: 2018-08-01T00:02:47.355611: step 1220, loss 0.550256.
Train: 2018-08-01T00:02:47.527417: step 1221, loss 0.535026.
Train: 2018-08-01T00:02:47.668037: step 1222, loss 0.67321.
Train: 2018-08-01T00:02:47.839875: step 1223, loss 0.562423.
Train: 2018-08-01T00:02:47.996087: step 1224, loss 0.623818.
Train: 2018-08-01T00:02:48.152268: step 1225, loss 0.564283.
Train: 2018-08-01T00:02:48.308513: step 1226, loss 0.560964.
Train: 2018-08-01T00:02:48.464728: step 1227, loss 0.546894.
Train: 2018-08-01T00:02:48.636530: step 1228, loss 0.593674.
Train: 2018-08-01T00:02:48.808365: step 1229, loss 0.674796.
Train: 2018-08-01T00:02:48.964583: step 1230, loss 0.546569.
Test: 2018-08-01T00:02:49.448874: step 1230, loss 0.550596.
Train: 2018-08-01T00:02:49.605059: step 1231, loss 0.579975.
Train: 2018-08-01T00:02:49.761267: step 1232, loss 0.640174.
Train: 2018-08-01T00:02:49.917506: step 1233, loss 0.546471.
Train: 2018-08-01T00:02:50.073727: step 1234, loss 0.531261.
Train: 2018-08-01T00:02:50.229913: step 1235, loss 0.439783.
Train: 2018-08-01T00:02:50.401743: step 1236, loss 0.54726.
Train: 2018-08-01T00:02:50.557956: step 1237, loss 0.5035.
Train: 2018-08-01T00:02:50.714202: step 1238, loss 0.517016.
Train: 2018-08-01T00:02:50.870383: step 1239, loss 0.568128.
Train: 2018-08-01T00:02:51.042218: step 1240, loss 0.591163.
Test: 2018-08-01T00:02:51.510887: step 1240, loss 0.549563.
Train: 2018-08-01T00:02:51.667095: step 1241, loss 0.499809.
Train: 2018-08-01T00:02:51.823315: step 1242, loss 0.59414.
Train: 2018-08-01T00:02:51.995119: step 1243, loss 0.612803.
Train: 2018-08-01T00:02:52.166955: step 1244, loss 0.625803.
Train: 2018-08-01T00:02:52.320866: step 1245, loss 0.51398.
Train: 2018-08-01T00:02:52.470455: step 1246, loss 0.630841.
Train: 2018-08-01T00:02:52.630266: step 1247, loss 0.479394.
Train: 2018-08-01T00:02:52.790928: step 1248, loss 0.566658.
Train: 2018-08-01T00:02:52.947146: step 1249, loss 0.595919.
Train: 2018-08-01T00:02:53.103359: step 1250, loss 0.532581.
Test: 2018-08-01T00:02:53.587650: step 1250, loss 0.548628.
Train: 2018-08-01T00:02:53.743865: step 1251, loss 0.551687.
Train: 2018-08-01T00:02:53.915668: step 1252, loss 0.529848.
Train: 2018-08-01T00:02:54.071913: step 1253, loss 0.513084.
Train: 2018-08-01T00:02:54.243748: step 1254, loss 0.528312.
Train: 2018-08-01T00:02:54.399964: step 1255, loss 0.562687.
Train: 2018-08-01T00:02:54.556143: step 1256, loss 0.527908.
Train: 2018-08-01T00:02:54.727979: step 1257, loss 0.64607.
Train: 2018-08-01T00:02:54.884193: step 1258, loss 0.443096.
Train: 2018-08-01T00:02:55.040436: step 1259, loss 0.56405.
Train: 2018-08-01T00:02:55.212242: step 1260, loss 0.611208.
Test: 2018-08-01T00:02:55.680045: step 1260, loss 0.54801.
Train: 2018-08-01T00:02:55.851847: step 1261, loss 0.580496.
Train: 2018-08-01T00:02:56.028851: step 1262, loss 0.544483.
Train: 2018-08-01T00:02:56.185166: step 1263, loss 0.556954.
Train: 2018-08-01T00:02:56.358298: step 1264, loss 0.531401.
Train: 2018-08-01T00:02:56.514839: step 1265, loss 0.509071.
Train: 2018-08-01T00:02:56.667761: step 1266, loss 0.601663.
Train: 2018-08-01T00:02:56.839566: step 1267, loss 0.59407.
Train: 2018-08-01T00:02:56.995778: step 1268, loss 0.547028.
Train: 2018-08-01T00:02:57.152022: step 1269, loss 0.425131.
Train: 2018-08-01T00:02:57.308234: step 1270, loss 0.474561.
Test: 2018-08-01T00:02:57.776874: step 1270, loss 0.547735.
Train: 2018-08-01T00:02:57.933089: step 1271, loss 0.455862.
Train: 2018-08-01T00:02:58.089302: step 1272, loss 0.457513.
Train: 2018-08-01T00:02:58.261137: step 1273, loss 0.493946.
Train: 2018-08-01T00:02:58.417320: step 1274, loss 0.378003.
Train: 2018-08-01T00:02:58.573533: step 1275, loss 0.455111.
Train: 2018-08-01T00:02:58.729779: step 1276, loss 0.566082.
Train: 2018-08-01T00:02:58.885961: step 1277, loss 0.674498.
Train: 2018-08-01T00:02:59.057794: step 1278, loss 0.643205.
Train: 2018-08-01T00:02:59.214041: step 1279, loss 0.620518.
Train: 2018-08-01T00:02:59.370246: step 1280, loss 0.548326.
Test: 2018-08-01T00:02:59.838891: step 1280, loss 0.547825.
Train: 2018-08-01T00:02:59.995100: step 1281, loss 0.593025.
Train: 2018-08-01T00:03:00.166940: step 1282, loss 0.481489.
Train: 2018-08-01T00:03:00.323123: step 1283, loss 0.585193.
Train: 2018-08-01T00:03:00.494988: step 1284, loss 0.527835.
Train: 2018-08-01T00:03:00.651202: step 1285, loss 0.67955.
Train: 2018-08-01T00:03:00.823037: step 1286, loss 0.560695.
Train: 2018-08-01T00:03:00.979253: step 1287, loss 0.452157.
Train: 2018-08-01T00:03:01.151054: step 1288, loss 0.565326.
Train: 2018-08-01T00:03:01.307297: step 1289, loss 0.601556.
Train: 2018-08-01T00:03:01.463482: step 1290, loss 0.465833.
Test: 2018-08-01T00:03:01.947743: step 1290, loss 0.54769.
Train: 2018-08-01T00:03:02.119608: step 1291, loss 0.617549.
Train: 2018-08-01T00:03:02.291413: step 1292, loss 0.490499.
Train: 2018-08-01T00:03:02.447625: step 1293, loss 0.507891.
Train: 2018-08-01T00:03:02.619491: step 1294, loss 0.557475.
Train: 2018-08-01T00:03:02.775673: step 1295, loss 0.618513.
Train: 2018-08-01T00:03:02.931917: step 1296, loss 0.743055.
Train: 2018-08-01T00:03:03.088126: step 1297, loss 0.510015.
Train: 2018-08-01T00:03:03.259965: step 1298, loss 0.564531.
Train: 2018-08-01T00:03:03.416173: step 1299, loss 0.511137.
Train: 2018-08-01T00:03:03.572400: step 1300, loss 0.577546.
Test: 2018-08-01T00:03:04.056655: step 1300, loss 0.547637.
Train: 2018-08-01T00:03:04.837692: step 1301, loss 0.724472.
Train: 2018-08-01T00:03:04.993905: step 1302, loss 0.490236.
Train: 2018-08-01T00:03:05.165765: step 1303, loss 0.615701.
Train: 2018-08-01T00:03:05.321977: step 1304, loss 0.599423.
Train: 2018-08-01T00:03:05.493811: step 1305, loss 0.511432.
Train: 2018-08-01T00:03:05.650001: step 1306, loss 0.633116.
Train: 2018-08-01T00:03:05.806214: step 1307, loss 0.652471.
Train: 2018-08-01T00:03:05.962456: step 1308, loss 0.545965.
Train: 2018-08-01T00:03:06.118641: step 1309, loss 0.509431.
Train: 2018-08-01T00:03:06.290476: step 1310, loss 0.528974.
Test: 2018-08-01T00:03:06.774736: step 1310, loss 0.548284.
Train: 2018-08-01T00:03:06.930982: step 1311, loss 0.544814.
Train: 2018-08-01T00:03:07.087164: step 1312, loss 0.46233.
Train: 2018-08-01T00:03:07.259001: step 1313, loss 0.632062.
Train: 2018-08-01T00:03:07.430858: step 1314, loss 0.596569.
Train: 2018-08-01T00:03:07.587072: step 1315, loss 0.49415.
Train: 2018-08-01T00:03:07.743292: step 1316, loss 0.579085.
Train: 2018-08-01T00:03:07.899475: step 1317, loss 0.595676.
Train: 2018-08-01T00:03:08.071311: step 1318, loss 0.647837.
Train: 2018-08-01T00:03:08.249952: step 1319, loss 0.529523.
Train: 2018-08-01T00:03:08.410028: step 1320, loss 0.495214.
Test: 2018-08-01T00:03:08.887967: step 1320, loss 0.548571.
Train: 2018-08-01T00:03:09.059819: step 1321, loss 0.563372.
Train: 2018-08-01T00:03:09.216037: step 1322, loss 0.512764.
Train: 2018-08-01T00:03:09.372220: step 1323, loss 0.528756.
Train: 2018-08-01T00:03:09.528464: step 1324, loss 0.444912.
Train: 2018-08-01T00:03:09.684678: step 1325, loss 0.613393.
Train: 2018-08-01T00:03:09.856516: step 1326, loss 0.58026.
Train: 2018-08-01T00:03:10.012730: step 1327, loss 0.478766.
Train: 2018-08-01T00:03:10.168911: step 1328, loss 0.478644.
Train: 2018-08-01T00:03:10.325124: step 1329, loss 0.512377.
Train: 2018-08-01T00:03:10.481337: step 1330, loss 0.629658.
Test: 2018-08-01T00:03:10.965597: step 1330, loss 0.548094.
Train: 2018-08-01T00:03:11.137457: step 1331, loss 0.580402.
Train: 2018-08-01T00:03:11.309291: step 1332, loss 0.529225.
Train: 2018-08-01T00:03:11.465512: step 1333, loss 0.494457.
Train: 2018-08-01T00:03:11.621694: step 1334, loss 0.562419.
Train: 2018-08-01T00:03:11.777907: step 1335, loss 0.631428.
Train: 2018-08-01T00:03:11.934147: step 1336, loss 0.788523.
Train: 2018-08-01T00:03:12.105980: step 1337, loss 0.648935.
Train: 2018-08-01T00:03:12.262194: step 1338, loss 0.562048.
Train: 2018-08-01T00:03:12.418383: step 1339, loss 0.579172.
Train: 2018-08-01T00:03:12.574596: step 1340, loss 0.596905.
Test: 2018-08-01T00:03:13.043267: step 1340, loss 0.548145.
Train: 2018-08-01T00:03:13.215102: step 1341, loss 0.528705.
Train: 2018-08-01T00:03:13.371309: step 1342, loss 0.562375.
Train: 2018-08-01T00:03:13.527497: step 1343, loss 0.477906.
Train: 2018-08-01T00:03:13.683737: step 1344, loss 0.613267.
Train: 2018-08-01T00:03:13.839926: step 1345, loss 0.544939.
Train: 2018-08-01T00:03:13.996139: step 1346, loss 0.646771.
Train: 2018-08-01T00:03:14.167973: step 1347, loss 0.595442.
Train: 2018-08-01T00:03:14.324211: step 1348, loss 0.427937.
Train: 2018-08-01T00:03:14.480430: step 1349, loss 0.478023.
Train: 2018-08-01T00:03:14.636647: step 1350, loss 0.613426.
Test: 2018-08-01T00:03:15.105252: step 1350, loss 0.548293.
Train: 2018-08-01T00:03:15.261468: step 1351, loss 0.579797.
Train: 2018-08-01T00:03:15.433302: step 1352, loss 0.681076.
Train: 2018-08-01T00:03:15.573924: step 1353, loss 0.47802.
Train: 2018-08-01T00:03:15.745728: step 1354, loss 0.595748.
Train: 2018-08-01T00:03:15.901943: step 1355, loss 0.562227.
Train: 2018-08-01T00:03:16.058181: step 1356, loss 0.562999.
Train: 2018-08-01T00:03:16.214399: step 1357, loss 0.545574.
Train: 2018-08-01T00:03:16.386205: step 1358, loss 0.511436.
Train: 2018-08-01T00:03:16.542442: step 1359, loss 0.528157.
Train: 2018-08-01T00:03:16.698660: step 1360, loss 0.596468.
Test: 2018-08-01T00:03:17.167269: step 1360, loss 0.548253.
Train: 2018-08-01T00:03:17.323483: step 1361, loss 0.52877.
Train: 2018-08-01T00:03:17.479697: step 1362, loss 0.47838.
Train: 2018-08-01T00:03:17.651531: step 1363, loss 0.561999.
Train: 2018-08-01T00:03:17.807745: step 1364, loss 0.460355.
Train: 2018-08-01T00:03:17.963958: step 1365, loss 0.580073.
Train: 2018-08-01T00:03:18.135822: step 1366, loss 0.476335.
Train: 2018-08-01T00:03:18.292037: step 1367, loss 0.596831.
Train: 2018-08-01T00:03:18.448251: step 1368, loss 0.47519.
Train: 2018-08-01T00:03:18.604434: step 1369, loss 0.65017.
Train: 2018-08-01T00:03:18.760682: step 1370, loss 0.578467.
Test: 2018-08-01T00:03:19.229318: step 1370, loss 0.547814.
Train: 2018-08-01T00:03:19.385502: step 1371, loss 0.562191.
Train: 2018-08-01T00:03:19.557335: step 1372, loss 0.54425.
Train: 2018-08-01T00:03:19.729171: step 1373, loss 0.562737.
Train: 2018-08-01T00:03:19.885384: step 1374, loss 0.564195.
Train: 2018-08-01T00:03:20.041597: step 1375, loss 0.615627.
Train: 2018-08-01T00:03:20.197841: step 1376, loss 0.615834.
Train: 2018-08-01T00:03:20.354049: step 1377, loss 0.526666.
Train: 2018-08-01T00:03:20.541481: step 1378, loss 0.441309.
Train: 2018-08-01T00:03:20.699962: step 1379, loss 0.492054.
Train: 2018-08-01T00:03:20.859785: step 1380, loss 0.544641.
Test: 2018-08-01T00:03:21.335164: step 1380, loss 0.547714.
Train: 2018-08-01T00:03:21.491349: step 1381, loss 0.49085.
Train: 2018-08-01T00:03:21.663213: step 1382, loss 0.615366.
Train: 2018-08-01T00:03:21.819397: step 1383, loss 0.616881.
Train: 2018-08-01T00:03:21.975611: step 1384, loss 0.545276.
Train: 2018-08-01T00:03:22.131823: step 1385, loss 0.545788.
Train: 2018-08-01T00:03:22.288037: step 1386, loss 0.563807.
Train: 2018-08-01T00:03:22.444281: step 1387, loss 0.561838.
Train: 2018-08-01T00:03:22.616085: step 1388, loss 0.509203.
Train: 2018-08-01T00:03:22.756710: step 1389, loss 0.652794.
Train: 2018-08-01T00:03:22.928545: step 1390, loss 0.544738.
Test: 2018-08-01T00:03:23.412774: step 1390, loss 0.547672.
Train: 2018-08-01T00:03:23.568988: step 1391, loss 0.544089.
Train: 2018-08-01T00:03:23.725230: step 1392, loss 0.527174.
Train: 2018-08-01T00:03:23.881414: step 1393, loss 0.545981.
Train: 2018-08-01T00:03:24.037626: step 1394, loss 0.599287.
Train: 2018-08-01T00:03:24.209462: step 1395, loss 0.616551.
Train: 2018-08-01T00:03:24.365675: step 1396, loss 0.491306.
Train: 2018-08-01T00:03:24.521888: step 1397, loss 0.669006.
Train: 2018-08-01T00:03:24.678132: step 1398, loss 0.545039.
Train: 2018-08-01T00:03:24.834315: step 1399, loss 0.59748.
Train: 2018-08-01T00:03:25.006150: step 1400, loss 0.509169.
Test: 2018-08-01T00:03:25.474789: step 1400, loss 0.547767.
Train: 2018-08-01T00:03:26.177751: step 1401, loss 0.615303.
Train: 2018-08-01T00:03:26.349586: step 1402, loss 0.598395.
Train: 2018-08-01T00:03:26.505799: step 1403, loss 0.510207.
Train: 2018-08-01T00:03:26.662013: step 1404, loss 0.544677.
Train: 2018-08-01T00:03:26.833847: step 1405, loss 0.545183.
Train: 2018-08-01T00:03:27.005682: step 1406, loss 0.562704.
Train: 2018-08-01T00:03:27.161925: step 1407, loss 0.562356.
Train: 2018-08-01T00:03:27.318139: step 1408, loss 0.492886.
Train: 2018-08-01T00:03:27.474323: step 1409, loss 0.597628.
Train: 2018-08-01T00:03:27.630568: step 1410, loss 0.510044.
Test: 2018-08-01T00:03:28.099205: step 1410, loss 0.54788.
Train: 2018-08-01T00:03:28.255414: step 1411, loss 0.47488.
Train: 2018-08-01T00:03:28.427254: step 1412, loss 0.475283.
Train: 2018-08-01T00:03:28.599063: step 1413, loss 0.544002.
Train: 2018-08-01T00:03:28.755272: step 1414, loss 0.649919.
Train: 2018-08-01T00:03:28.927107: step 1415, loss 0.650113.
Train: 2018-08-01T00:03:29.083320: step 1416, loss 0.562712.
Train: 2018-08-01T00:03:29.239533: step 1417, loss 0.510139.
Train: 2018-08-01T00:03:29.395781: step 1418, loss 0.457294.
Train: 2018-08-01T00:03:29.551991: step 1419, loss 0.526702.
Train: 2018-08-01T00:03:29.708174: step 1420, loss 0.56341.
Test: 2018-08-01T00:03:30.192435: step 1420, loss 0.547728.
Train: 2018-08-01T00:03:30.348649: step 1421, loss 0.614985.
Train: 2018-08-01T00:03:30.520483: step 1422, loss 0.473753.
Train: 2018-08-01T00:03:30.676697: step 1423, loss 0.616113.
Train: 2018-08-01T00:03:30.832910: step 1424, loss 0.686771.
Train: 2018-08-01T00:03:30.989124: step 1425, loss 0.633532.
Train: 2018-08-01T00:03:31.145337: step 1426, loss 0.510184.
Train: 2018-08-01T00:03:31.301550: step 1427, loss 0.651.
Train: 2018-08-01T00:03:31.457764: step 1428, loss 0.527949.
Train: 2018-08-01T00:03:31.614002: step 1429, loss 0.474498.
Train: 2018-08-01T00:03:31.770224: step 1430, loss 0.597537.
Test: 2018-08-01T00:03:32.254482: step 1430, loss 0.547818.
Train: 2018-08-01T00:03:32.410696: step 1431, loss 0.5965.
Train: 2018-08-01T00:03:32.566913: step 1432, loss 0.667671.
Train: 2018-08-01T00:03:32.738739: step 1433, loss 0.684077.
Train: 2018-08-01T00:03:32.902002: step 1434, loss 0.5101.
Train: 2018-08-01T00:03:33.057483: step 1435, loss 0.510861.
Train: 2018-08-01T00:03:33.217968: step 1436, loss 0.527616.
Train: 2018-08-01T00:03:33.368192: step 1437, loss 0.528872.
Train: 2018-08-01T00:03:33.532528: step 1438, loss 0.51025.
Train: 2018-08-01T00:03:33.688718: step 1439, loss 0.528519.
Train: 2018-08-01T00:03:33.844964: step 1440, loss 0.631036.
Test: 2018-08-01T00:03:34.313571: step 1440, loss 0.548062.
Train: 2018-08-01T00:03:34.469817: step 1441, loss 0.57916.
Train: 2018-08-01T00:03:34.625998: step 1442, loss 0.647929.
Train: 2018-08-01T00:03:34.782241: step 1443, loss 0.494237.
Train: 2018-08-01T00:03:34.954045: step 1444, loss 0.545585.
Train: 2018-08-01T00:03:35.110259: step 1445, loss 0.442796.
Train: 2018-08-01T00:03:35.266472: step 1446, loss 0.596548.
Train: 2018-08-01T00:03:35.440556: step 1447, loss 0.544636.
Train: 2018-08-01T00:03:35.594355: step 1448, loss 0.647558.
Train: 2018-08-01T00:03:35.754096: step 1449, loss 0.664491.
Train: 2018-08-01T00:03:35.914172: step 1450, loss 0.579502.
Test: 2018-08-01T00:03:36.390367: step 1450, loss 0.548126.
Train: 2018-08-01T00:03:36.546580: step 1451, loss 0.494422.
Train: 2018-08-01T00:03:36.702794: step 1452, loss 0.527956.
Train: 2018-08-01T00:03:36.859039: step 1453, loss 0.699408.
Train: 2018-08-01T00:03:37.015246: step 1454, loss 0.546096.
Train: 2018-08-01T00:03:37.187055: step 1455, loss 0.510828.
Train: 2018-08-01T00:03:37.327680: step 1456, loss 0.528931.
Train: 2018-08-01T00:03:37.499482: step 1457, loss 0.595612.
Train: 2018-08-01T00:03:37.655726: step 1458, loss 0.579212.
Train: 2018-08-01T00:03:37.811928: step 1459, loss 0.647176.
Train: 2018-08-01T00:03:37.983744: step 1460, loss 0.631088.
Test: 2018-08-01T00:03:38.452384: step 1460, loss 0.548319.
Train: 2018-08-01T00:03:38.608597: step 1461, loss 0.595461.
Train: 2018-08-01T00:03:38.780432: step 1462, loss 0.511311.
Train: 2018-08-01T00:03:38.936675: step 1463, loss 0.579598.
Train: 2018-08-01T00:03:39.092891: step 1464, loss 0.579568.
Train: 2018-08-01T00:03:39.264724: step 1465, loss 0.511871.
Train: 2018-08-01T00:03:39.420907: step 1466, loss 0.580297.
Train: 2018-08-01T00:03:39.577121: step 1467, loss 0.57922.
Train: 2018-08-01T00:03:39.733334: step 1468, loss 0.546658.
Train: 2018-08-01T00:03:39.889577: step 1469, loss 0.611223.
Train: 2018-08-01T00:03:40.045762: step 1470, loss 0.630154.
Test: 2018-08-01T00:03:40.514430: step 1470, loss 0.548632.
Train: 2018-08-01T00:03:40.686266: step 1471, loss 0.679042.
Train: 2018-08-01T00:03:40.842473: step 1472, loss 0.579589.
Train: 2018-08-01T00:03:41.014309: step 1473, loss 0.546316.
Train: 2018-08-01T00:03:41.186120: step 1474, loss 0.595729.
Train: 2018-08-01T00:03:41.342364: step 1475, loss 0.562274.
Train: 2018-08-01T00:03:41.498546: step 1476, loss 0.595845.
Train: 2018-08-01T00:03:41.670382: step 1477, loss 0.628031.
Train: 2018-08-01T00:03:41.826600: step 1478, loss 0.481865.
Train: 2018-08-01T00:03:41.982808: step 1479, loss 0.530174.
Train: 2018-08-01T00:03:42.139051: step 1480, loss 0.530941.
Test: 2018-08-01T00:03:42.607662: step 1480, loss 0.549246.
Train: 2018-08-01T00:03:42.779495: step 1481, loss 0.530442.
Train: 2018-08-01T00:03:42.936292: step 1482, loss 0.59485.
Train: 2018-08-01T00:03:43.096542: step 1483, loss 0.579196.
Train: 2018-08-01T00:03:43.262949: step 1484, loss 0.497962.
Train: 2018-08-01T00:03:43.423283: step 1485, loss 0.563227.
Train: 2018-08-01T00:03:43.579530: step 1486, loss 0.546307.
Train: 2018-08-01T00:03:43.735712: step 1487, loss 0.611553.
Train: 2018-08-01T00:03:43.891959: step 1488, loss 0.563501.
Train: 2018-08-01T00:03:44.048170: step 1489, loss 0.530057.
Train: 2018-08-01T00:03:44.219975: step 1490, loss 0.660835.
Test: 2018-08-01T00:03:44.688614: step 1490, loss 0.548952.
Train: 2018-08-01T00:03:44.844852: step 1491, loss 0.628413.
Train: 2018-08-01T00:03:45.001041: step 1492, loss 0.529972.
Train: 2018-08-01T00:03:45.157256: step 1493, loss 0.628303.
Train: 2018-08-01T00:03:45.313494: step 1494, loss 0.51389.
Train: 2018-08-01T00:03:45.469707: step 1495, loss 0.464966.
Train: 2018-08-01T00:03:45.625928: step 1496, loss 0.448281.
Train: 2018-08-01T00:03:45.782137: step 1497, loss 0.546034.
Train: 2018-08-01T00:03:45.938352: step 1498, loss 0.661256.
Train: 2018-08-01T00:03:46.094535: step 1499, loss 0.479986.
Train: 2018-08-01T00:03:46.266403: step 1500, loss 0.62894.
Test: 2018-08-01T00:03:46.750631: step 1500, loss 0.548621.
Train: 2018-08-01T00:03:47.453623: step 1501, loss 0.57882.
Train: 2018-08-01T00:03:47.594215: step 1502, loss 0.612193.
Train: 2018-08-01T00:03:47.750430: step 1503, loss 0.562455.
Train: 2018-08-01T00:03:47.922232: step 1504, loss 0.545563.
Train: 2018-08-01T00:03:48.062825: step 1505, loss 0.491271.
Train: 2018-08-01T00:03:48.219068: step 1506, loss 0.545882.
Train: 2018-08-01T00:03:48.390873: step 1507, loss 0.562015.
Train: 2018-08-01T00:03:48.547111: step 1508, loss 0.529078.
Train: 2018-08-01T00:03:48.703335: step 1509, loss 0.47828.
Train: 2018-08-01T00:03:48.859514: step 1510, loss 0.630477.
Test: 2018-08-01T00:03:49.328184: step 1510, loss 0.548214.
Train: 2018-08-01T00:03:49.484367: step 1511, loss 0.579218.
Train: 2018-08-01T00:03:49.640613: step 1512, loss 0.511628.
Train: 2018-08-01T00:03:49.796818: step 1513, loss 0.494123.
Train: 2018-08-01T00:03:49.953006: step 1514, loss 0.545514.
Train: 2018-08-01T00:03:50.109250: step 1515, loss 0.699946.
Train: 2018-08-01T00:03:50.265466: step 1516, loss 0.528088.
Train: 2018-08-01T00:03:50.421648: step 1517, loss 0.648273.
Train: 2018-08-01T00:03:50.577861: step 1518, loss 0.57947.
Train: 2018-08-01T00:03:50.734105: step 1519, loss 0.614313.
Train: 2018-08-01T00:03:50.890320: step 1520, loss 0.527951.
Test: 2018-08-01T00:03:51.358928: step 1520, loss 0.548045.
Train: 2018-08-01T00:03:51.530787: step 1521, loss 0.614082.
Train: 2018-08-01T00:03:51.695965: step 1522, loss 0.544743.
Train: 2018-08-01T00:03:51.845162: step 1523, loss 0.562668.
Train: 2018-08-01T00:03:52.001615: step 1524, loss 0.579554.
Train: 2018-08-01T00:03:52.161772: step 1525, loss 0.562509.
Train: 2018-08-01T00:03:52.308620: step 1526, loss 0.511342.
Train: 2018-08-01T00:03:52.480485: step 1527, loss 0.613647.
Train: 2018-08-01T00:03:52.636669: step 1528, loss 0.443132.
Train: 2018-08-01T00:03:52.792906: step 1529, loss 0.61366.
Train: 2018-08-01T00:03:52.949131: step 1530, loss 0.648141.
Test: 2018-08-01T00:03:53.433357: step 1530, loss 0.548138.
Train: 2018-08-01T00:03:53.589570: step 1531, loss 0.647948.
Train: 2018-08-01T00:03:53.745783: step 1532, loss 0.596203.
Train: 2018-08-01T00:03:53.902022: step 1533, loss 0.426776.
Train: 2018-08-01T00:03:54.058235: step 1534, loss 0.579482.
Train: 2018-08-01T00:03:54.214424: step 1535, loss 0.443685.
Train: 2018-08-01T00:03:54.370662: step 1536, loss 0.528908.
Train: 2018-08-01T00:03:54.526851: step 1537, loss 0.477083.
Train: 2018-08-01T00:03:54.683065: step 1538, loss 0.511482.
Train: 2018-08-01T00:03:54.839279: step 1539, loss 0.5795.
Train: 2018-08-01T00:03:55.011142: step 1540, loss 0.579805.
Test: 2018-08-01T00:03:55.495375: step 1540, loss 0.547988.
Train: 2018-08-01T00:03:55.651619: step 1541, loss 0.648703.
Train: 2018-08-01T00:03:55.823422: step 1542, loss 0.528155.
Train: 2018-08-01T00:03:55.979636: step 1543, loss 0.510466.
Train: 2018-08-01T00:03:56.151472: step 1544, loss 0.666164.
Train: 2018-08-01T00:03:56.338952: step 1545, loss 0.475991.
Train: 2018-08-01T00:03:56.542004: step 1546, loss 0.527921.
Train: 2018-08-01T00:03:56.760703: step 1547, loss 0.54482.
Train: 2018-08-01T00:03:56.948159: step 1548, loss 0.527135.
Train: 2018-08-01T00:03:57.088752: step 1549, loss 0.649715.
Train: 2018-08-01T00:03:57.244965: step 1550, loss 0.544988.
Test: 2018-08-01T00:03:57.713634: step 1550, loss 0.547838.
Train: 2018-08-01T00:03:57.869818: step 1551, loss 0.614487.
Train: 2018-08-01T00:03:58.041652: step 1552, loss 0.667226.
Train: 2018-08-01T00:03:58.197865: step 1553, loss 0.56245.
Train: 2018-08-01T00:03:58.354118: step 1554, loss 0.544924.
Train: 2018-08-01T00:03:58.510327: step 1555, loss 0.475951.
Train: 2018-08-01T00:03:58.682158: step 1556, loss 0.684502.
Train: 2018-08-01T00:03:58.838342: step 1557, loss 0.476358.
Train: 2018-08-01T00:03:58.994555: step 1558, loss 0.528143.
Train: 2018-08-01T00:03:59.150799: step 1559, loss 0.580222.
Train: 2018-08-01T00:03:59.322603: step 1560, loss 0.510662.
Test: 2018-08-01T00:03:59.806894: step 1560, loss 0.547931.
Train: 2018-08-01T00:03:59.963103: step 1561, loss 0.596795.
Train: 2018-08-01T00:04:00.119321: step 1562, loss 0.493783.
Train: 2018-08-01T00:04:00.275529: step 1563, loss 0.475441.
Train: 2018-08-01T00:04:00.431748: step 1564, loss 0.631957.
Train: 2018-08-01T00:04:00.587932: step 1565, loss 0.632106.
Train: 2018-08-01T00:04:00.744175: step 1566, loss 0.596724.
Train: 2018-08-01T00:04:00.931602: step 1567, loss 0.614571.
Train: 2018-08-01T00:04:01.087814: step 1568, loss 0.493083.
Train: 2018-08-01T00:04:01.244028: step 1569, loss 0.406962.
Train: 2018-08-01T00:04:01.415863: step 1570, loss 0.579792.
Test: 2018-08-01T00:04:01.884503: step 1570, loss 0.54789.
Train: 2018-08-01T00:04:02.040717: step 1571, loss 0.666586.
Train: 2018-08-01T00:04:02.196959: step 1572, loss 0.527751.
Train: 2018-08-01T00:04:02.353143: step 1573, loss 0.57965.
Train: 2018-08-01T00:04:02.524979: step 1574, loss 0.544982.
Train: 2018-08-01T00:04:02.681221: step 1575, loss 0.562151.
Train: 2018-08-01T00:04:02.837404: step 1576, loss 0.52754.
Train: 2018-08-01T00:04:02.993643: step 1577, loss 0.614721.
Train: 2018-08-01T00:04:03.149857: step 1578, loss 0.527508.
Train: 2018-08-01T00:04:03.321692: step 1579, loss 0.440754.
Train: 2018-08-01T00:04:03.477911: step 1580, loss 0.475286.
Test: 2018-08-01T00:04:03.946549: step 1580, loss 0.547828.
Train: 2018-08-01T00:04:04.118354: step 1581, loss 0.614657.
Train: 2018-08-01T00:04:04.274570: step 1582, loss 0.509866.
Train: 2018-08-01T00:04:04.430782: step 1583, loss 0.510539.
Train: 2018-08-01T00:04:04.586994: step 1584, loss 0.4927.
Train: 2018-08-01T00:04:04.743233: step 1585, loss 0.650844.
Train: 2018-08-01T00:04:04.899446: step 1586, loss 0.474219.
Train: 2018-08-01T00:04:05.055665: step 1587, loss 0.52668.
Train: 2018-08-01T00:04:05.211873: step 1588, loss 0.598301.
Train: 2018-08-01T00:04:05.368063: step 1589, loss 0.616468.
Train: 2018-08-01T00:04:05.524275: step 1590, loss 0.634123.
Test: 2018-08-01T00:04:06.008570: step 1590, loss 0.547658.
Train: 2018-08-01T00:04:06.180371: step 1591, loss 0.54468.
Train: 2018-08-01T00:04:06.336615: step 1592, loss 0.669792.
Train: 2018-08-01T00:04:06.492799: step 1593, loss 0.562916.
Train: 2018-08-01T00:04:06.649012: step 1594, loss 0.633139.
Train: 2018-08-01T00:04:06.820869: step 1595, loss 0.562425.
Train: 2018-08-01T00:04:06.977090: step 1596, loss 0.57985.
Train: 2018-08-01T00:04:07.133304: step 1597, loss 0.509514.
Train: 2018-08-01T00:04:07.305109: step 1598, loss 0.615357.
Train: 2018-08-01T00:04:07.461346: step 1599, loss 0.614539.
Train: 2018-08-01T00:04:07.617560: step 1600, loss 0.614806.
Test: 2018-08-01T00:04:08.101796: step 1600, loss 0.547871.
Train: 2018-08-01T00:04:08.851651: step 1601, loss 0.457786.
Train: 2018-08-01T00:04:09.007866: step 1602, loss 0.56255.
Train: 2018-08-01T00:04:09.226535: step 1603, loss 0.545353.
Train: 2018-08-01T00:04:09.411758: step 1604, loss 0.59675.
Train: 2018-08-01T00:04:09.571164: step 1605, loss 0.614802.
Train: 2018-08-01T00:04:09.730963: step 1606, loss 0.579726.
Train: 2018-08-01T00:04:09.907097: step 1607, loss 0.45929.
Train: 2018-08-01T00:04:10.063331: step 1608, loss 0.459576.
Train: 2018-08-01T00:04:10.219534: step 1609, loss 0.54528.
Train: 2018-08-01T00:04:10.391404: step 1610, loss 0.52801.
Test: 2018-08-01T00:04:10.875621: step 1610, loss 0.547967.
Train: 2018-08-01T00:04:11.031864: step 1611, loss 0.527555.
Train: 2018-08-01T00:04:11.297428: step 1612, loss 0.493043.
Train: 2018-08-01T00:04:11.453641: step 1613, loss 0.475594.
Train: 2018-08-01T00:04:11.609856: step 1614, loss 0.510369.
Train: 2018-08-01T00:04:11.750449: step 1615, loss 0.562512.
Train: 2018-08-01T00:04:11.922276: step 1616, loss 0.632776.
Train: 2018-08-01T00:04:12.078495: step 1617, loss 0.544811.
Train: 2018-08-01T00:04:12.234702: step 1618, loss 0.6866.
Train: 2018-08-01T00:04:12.390921: step 1619, loss 0.650771.
Train: 2018-08-01T00:04:12.547135: step 1620, loss 0.650722.
Test: 2018-08-01T00:04:13.031367: step 1620, loss 0.547777.
Train: 2018-08-01T00:04:13.234477: step 1621, loss 0.474291.
Train: 2018-08-01T00:04:13.390658: step 1622, loss 0.50991.
Train: 2018-08-01T00:04:13.546899: step 1623, loss 0.562874.
Train: 2018-08-01T00:04:13.703114: step 1624, loss 0.597469.
Train: 2018-08-01T00:04:13.859330: step 1625, loss 0.545007.
Train: 2018-08-01T00:04:14.015541: step 1626, loss 0.527646.
Train: 2018-08-01T00:04:14.171758: step 1627, loss 0.475123.
Train: 2018-08-01T00:04:14.327967: step 1628, loss 0.631879.
Train: 2018-08-01T00:04:14.484181: step 1629, loss 0.667493.
Train: 2018-08-01T00:04:14.640365: step 1630, loss 0.59736.
Test: 2018-08-01T00:04:15.124654: step 1630, loss 0.547853.
Train: 2018-08-01T00:04:15.280869: step 1631, loss 0.509992.
Train: 2018-08-01T00:04:15.437052: step 1632, loss 0.562314.
Train: 2018-08-01T00:04:15.593298: step 1633, loss 0.632207.
Train: 2018-08-01T00:04:15.765101: step 1634, loss 0.562581.
Train: 2018-08-01T00:04:15.921314: step 1635, loss 0.562704.
Train: 2018-08-01T00:04:16.077557: step 1636, loss 0.476359.
Train: 2018-08-01T00:04:16.233742: step 1637, loss 0.579869.
Train: 2018-08-01T00:04:16.389956: step 1638, loss 0.527806.
Train: 2018-08-01T00:04:16.561789: step 1639, loss 0.683333.
Train: 2018-08-01T00:04:16.718034: step 1640, loss 0.631333.
Test: 2018-08-01T00:04:17.217916: step 1640, loss 0.54804.
Train: 2018-08-01T00:04:17.374132: step 1641, loss 0.493465.
Train: 2018-08-01T00:04:17.530312: step 1642, loss 0.493975.
Train: 2018-08-01T00:04:17.686556: step 1643, loss 0.528225.
Train: 2018-08-01T00:04:17.842769: step 1644, loss 0.528089.
Train: 2018-08-01T00:04:17.998953: step 1645, loss 0.579528.
Train: 2018-08-01T00:04:18.155197: step 1646, loss 0.562584.
Train: 2018-08-01T00:04:18.327031: step 1647, loss 0.579558.
Train: 2018-08-01T00:04:18.483245: step 1648, loss 0.545166.
Train: 2018-08-01T00:04:18.639453: step 1649, loss 0.510713.
Train: 2018-08-01T00:04:18.795641: step 1650, loss 0.51081.
Test: 2018-08-01T00:04:19.295554: step 1650, loss 0.547988.
Train: 2018-08-01T00:04:19.451737: step 1651, loss 0.544888.
Train: 2018-08-01T00:04:19.607951: step 1652, loss 0.527796.
Train: 2018-08-01T00:04:19.795407: step 1653, loss 0.579417.
Train: 2018-08-01T00:04:19.967242: step 1654, loss 0.441087.
Train: 2018-08-01T00:04:20.123455: step 1655, loss 0.63212.
Train: 2018-08-01T00:04:20.310912: step 1656, loss 0.475197.
Train: 2018-08-01T00:04:20.482747: step 1657, loss 0.597557.
Train: 2018-08-01T00:04:20.638960: step 1658, loss 0.509531.
Train: 2018-08-01T00:04:20.810796: step 1659, loss 0.580066.
Train: 2018-08-01T00:04:20.967039: step 1660, loss 0.579757.
Test: 2018-08-01T00:04:21.451269: step 1660, loss 0.54773.
Train: 2018-08-01T00:04:21.623137: step 1661, loss 0.668586.
Train: 2018-08-01T00:04:21.779347: step 1662, loss 0.50975.
Train: 2018-08-01T00:04:21.935532: step 1663, loss 0.597875.
Train: 2018-08-01T00:04:22.091744: step 1664, loss 0.527333.
Train: 2018-08-01T00:04:22.263579: step 1665, loss 0.59776.
Train: 2018-08-01T00:04:22.419793: step 1666, loss 0.56221.
Train: 2018-08-01T00:04:22.576006: step 1667, loss 0.738842.
Train: 2018-08-01T00:04:22.747866: step 1668, loss 0.527371.
Train: 2018-08-01T00:04:22.919705: step 1669, loss 0.579481.
Train: 2018-08-01T00:04:23.075919: step 1670, loss 0.545149.
Test: 2018-08-01T00:04:23.560151: step 1670, loss 0.547837.
Train: 2018-08-01T00:04:23.716364: step 1671, loss 0.579916.
Train: 2018-08-01T00:04:23.872577: step 1672, loss 0.545037.
Train: 2018-08-01T00:04:24.028821: step 1673, loss 0.458139.
Train: 2018-08-01T00:04:24.185004: step 1674, loss 0.562231.
Train: 2018-08-01T00:04:24.341218: step 1675, loss 0.528084.
Train: 2018-08-01T00:04:24.513054: step 1676, loss 0.614776.
Train: 2018-08-01T00:04:24.669266: step 1677, loss 0.493175.
Train: 2018-08-01T00:04:24.841103: step 1678, loss 0.475495.
Train: 2018-08-01T00:04:25.012935: step 1679, loss 0.545084.
Train: 2018-08-01T00:04:25.200391: step 1680, loss 0.562016.
Test: 2018-08-01T00:04:25.684653: step 1680, loss 0.547815.
Train: 2018-08-01T00:04:25.840867: step 1681, loss 0.510245.
Train: 2018-08-01T00:04:25.997113: step 1682, loss 0.597347.
Train: 2018-08-01T00:04:26.153323: step 1683, loss 0.650508.
Train: 2018-08-01T00:04:26.309531: step 1684, loss 0.61548.
Train: 2018-08-01T00:04:26.481372: step 1685, loss 0.422366.
Train: 2018-08-01T00:04:26.637585: step 1686, loss 0.61501.
Train: 2018-08-01T00:04:26.793799: step 1687, loss 0.632439.
Train: 2018-08-01T00:04:26.949981: step 1688, loss 0.614984.
Train: 2018-08-01T00:04:27.106225: step 1689, loss 0.509918.
Train: 2018-08-01T00:04:27.262440: step 1690, loss 0.562747.
Test: 2018-08-01T00:04:27.746703: step 1690, loss 0.547831.
Train: 2018-08-01T00:04:27.918530: step 1691, loss 0.492578.
Train: 2018-08-01T00:04:28.074748: step 1692, loss 0.59719.
Train: 2018-08-01T00:04:28.230932: step 1693, loss 0.562077.
Train: 2018-08-01T00:04:28.387145: step 1694, loss 0.579853.
Train: 2018-08-01T00:04:28.558981: step 1695, loss 0.614735.
Train: 2018-08-01T00:04:28.715224: step 1696, loss 0.527755.
Train: 2018-08-01T00:04:28.871407: step 1697, loss 0.562733.
Train: 2018-08-01T00:04:29.043271: step 1698, loss 0.545265.
Train: 2018-08-01T00:04:29.199480: step 1699, loss 0.56263.
Train: 2018-08-01T00:04:29.355670: step 1700, loss 0.632338.
Test: 2018-08-01T00:04:29.824333: step 1700, loss 0.547915.
Train: 2018-08-01T00:04:30.527299: step 1701, loss 0.683764.
Train: 2018-08-01T00:04:30.683482: step 1702, loss 0.562404.
Train: 2018-08-01T00:04:30.855349: step 1703, loss 0.631279.
Train: 2018-08-01T00:04:31.011530: step 1704, loss 0.528222.
Train: 2018-08-01T00:04:31.171917: step 1705, loss 0.562299.
Train: 2018-08-01T00:04:31.327480: step 1706, loss 0.562392.
Train: 2018-08-01T00:04:31.487152: step 1707, loss 0.528548.
Train: 2018-08-01T00:04:31.638611: step 1708, loss 0.562324.
Train: 2018-08-01T00:04:31.794857: step 1709, loss 0.494492.
Train: 2018-08-01T00:04:31.966700: step 1710, loss 0.528405.
Test: 2018-08-01T00:04:32.435332: step 1710, loss 0.548232.
Train: 2018-08-01T00:04:32.607137: step 1711, loss 0.562369.
Train: 2018-08-01T00:04:32.763386: step 1712, loss 0.562489.
Train: 2018-08-01T00:04:32.935185: step 1713, loss 0.477646.
Train: 2018-08-01T00:04:33.091431: step 1714, loss 0.596526.
Train: 2018-08-01T00:04:33.247611: step 1715, loss 0.494186.
Train: 2018-08-01T00:04:33.403828: step 1716, loss 0.562212.
Train: 2018-08-01T00:04:33.560039: step 1717, loss 0.596713.
Train: 2018-08-01T00:04:33.731903: step 1718, loss 0.545149.
Train: 2018-08-01T00:04:33.888111: step 1719, loss 0.562542.
Train: 2018-08-01T00:04:34.044324: step 1720, loss 0.528149.
Test: 2018-08-01T00:04:34.512975: step 1720, loss 0.548015.
Train: 2018-08-01T00:04:34.684776: step 1721, loss 0.545277.
Train: 2018-08-01T00:04:34.841021: step 1722, loss 0.545462.
Train: 2018-08-01T00:04:34.997232: step 1723, loss 0.527967.
Train: 2018-08-01T00:04:35.169064: step 1724, loss 0.596839.
Train: 2018-08-01T00:04:35.325280: step 1725, loss 0.597231.
Train: 2018-08-01T00:04:35.481464: step 1726, loss 0.44124.
Train: 2018-08-01T00:04:35.637707: step 1727, loss 0.510325.
Train: 2018-08-01T00:04:35.793915: step 1728, loss 0.57994.
Train: 2018-08-01T00:04:35.965749: step 1729, loss 0.492672.
Train: 2018-08-01T00:04:36.121968: step 1730, loss 0.685148.
Test: 2018-08-01T00:04:36.590612: step 1730, loss 0.547786.
Train: 2018-08-01T00:04:36.746792: step 1731, loss 0.562559.
Train: 2018-08-01T00:04:36.903030: step 1732, loss 0.667493.
Train: 2018-08-01T00:04:37.074840: step 1733, loss 0.509678.
Train: 2018-08-01T00:04:37.231084: step 1734, loss 0.562381.
Train: 2018-08-01T00:04:37.387297: step 1735, loss 0.719541.
Train: 2018-08-01T00:04:37.543480: step 1736, loss 0.631971.
Train: 2018-08-01T00:04:37.699724: step 1737, loss 0.492631.
Train: 2018-08-01T00:04:37.855932: step 1738, loss 0.510377.
Train: 2018-08-01T00:04:38.012151: step 1739, loss 0.597178.
Train: 2018-08-01T00:04:38.183986: step 1740, loss 0.579904.
Test: 2018-08-01T00:04:38.652595: step 1740, loss 0.547938.
Train: 2018-08-01T00:04:38.824430: step 1741, loss 0.596913.
Train: 2018-08-01T00:04:38.980674: step 1742, loss 0.56206.
Train: 2018-08-01T00:04:39.136888: step 1743, loss 0.545551.
Train: 2018-08-01T00:04:39.293071: step 1744, loss 0.57954.
Train: 2018-08-01T00:04:39.449317: step 1745, loss 0.476542.
Train: 2018-08-01T00:04:39.605528: step 1746, loss 0.579526.
Train: 2018-08-01T00:04:39.777357: step 1747, loss 0.545174.
Train: 2018-08-01T00:04:39.933546: step 1748, loss 0.631084.
Train: 2018-08-01T00:04:40.089784: step 1749, loss 0.648053.
Train: 2018-08-01T00:04:40.246003: step 1750, loss 0.59676.
Test: 2018-08-01T00:04:40.730264: step 1750, loss 0.548136.
Train: 2018-08-01T00:04:40.886478: step 1751, loss 0.630545.
Train: 2018-08-01T00:04:41.042692: step 1752, loss 0.579116.
Train: 2018-08-01T00:04:41.198905: step 1753, loss 0.494902.
Train: 2018-08-01T00:04:41.370709: step 1754, loss 0.562449.
Train: 2018-08-01T00:04:41.526923: step 1755, loss 0.595841.
Train: 2018-08-01T00:04:41.683166: step 1756, loss 0.612837.
Train: 2018-08-01T00:04:41.854970: step 1757, loss 0.562545.
Train: 2018-08-01T00:04:42.011215: step 1758, loss 0.595974.
Train: 2018-08-01T00:04:42.183018: step 1759, loss 0.528727.
Train: 2018-08-01T00:04:42.339265: step 1760, loss 0.545715.
Test: 2018-08-01T00:04:42.807903: step 1760, loss 0.548532.
Train: 2018-08-01T00:04:42.964086: step 1761, loss 0.545591.
Train: 2018-08-01T00:04:43.120299: step 1762, loss 0.529162.
Train: 2018-08-01T00:04:43.276513: step 1763, loss 0.562353.
Train: 2018-08-01T00:04:43.432726: step 1764, loss 0.61308.
Train: 2018-08-01T00:04:43.588940: step 1765, loss 0.612759.
Train: 2018-08-01T00:04:43.760805: step 1766, loss 0.429055.
Train: 2018-08-01T00:04:43.916988: step 1767, loss 0.528939.
Train: 2018-08-01T00:04:44.073235: step 1768, loss 0.595869.
Train: 2018-08-01T00:04:44.245066: step 1769, loss 0.612934.
Train: 2018-08-01T00:04:44.401251: step 1770, loss 0.529303.
Test: 2018-08-01T00:04:44.885541: step 1770, loss 0.548445.
Train: 2018-08-01T00:04:45.041724: step 1771, loss 0.512363.
Train: 2018-08-01T00:04:45.197938: step 1772, loss 0.52894.
Train: 2018-08-01T00:04:45.369803: step 1773, loss 0.512402.
Train: 2018-08-01T00:04:45.526017: step 1774, loss 0.478036.
Train: 2018-08-01T00:04:45.682200: step 1775, loss 0.461386.
Train: 2018-08-01T00:04:45.838446: step 1776, loss 0.544922.
Train: 2018-08-01T00:04:45.994656: step 1777, loss 0.596736.
Train: 2018-08-01T00:04:46.150871: step 1778, loss 0.682599.
Train: 2018-08-01T00:04:46.322674: step 1779, loss 0.648594.
Train: 2018-08-01T00:04:46.478888: step 1780, loss 0.630737.
Test: 2018-08-01T00:04:46.947529: step 1780, loss 0.548013.
Train: 2018-08-01T00:04:47.103743: step 1781, loss 0.510599.
Train: 2018-08-01T00:04:47.259955: step 1782, loss 0.545777.
Train: 2018-08-01T00:04:47.416168: step 1783, loss 0.562105.
Train: 2018-08-01T00:04:47.572382: step 1784, loss 0.562872.
Train: 2018-08-01T00:04:47.728625: step 1785, loss 0.528099.
Train: 2018-08-01T00:04:47.884839: step 1786, loss 0.631115.
Train: 2018-08-01T00:04:48.041022: step 1787, loss 0.597275.
Train: 2018-08-01T00:04:48.197247: step 1788, loss 0.665692.
Train: 2018-08-01T00:04:48.353480: step 1789, loss 0.528322.
Train: 2018-08-01T00:04:48.525314: step 1790, loss 0.528378.
Test: 2018-08-01T00:04:49.009546: step 1790, loss 0.548115.
Train: 2018-08-01T00:04:49.165759: step 1791, loss 0.54541.
Train: 2018-08-01T00:04:49.322005: step 1792, loss 0.66461.
Train: 2018-08-01T00:04:49.478216: step 1793, loss 0.545335.
Train: 2018-08-01T00:04:49.634429: step 1794, loss 0.630606.
Train: 2018-08-01T00:04:49.790643: step 1795, loss 0.663661.
Train: 2018-08-01T00:04:49.946857: step 1796, loss 0.528741.
Train: 2018-08-01T00:04:50.103070: step 1797, loss 0.528695.
Train: 2018-08-01T00:04:50.259283: step 1798, loss 0.545517.
Train: 2018-08-01T00:04:50.415466: step 1799, loss 0.528881.
Train: 2018-08-01T00:04:50.571679: step 1800, loss 0.562404.
Test: 2018-08-01T00:04:51.040350: step 1800, loss 0.548455.
Train: 2018-08-01T00:04:51.774554: step 1801, loss 0.612657.
Train: 2018-08-01T00:04:51.930767: step 1802, loss 0.563003.
Train: 2018-08-01T00:04:52.086949: step 1803, loss 0.579204.
Train: 2018-08-01T00:04:52.258784: step 1804, loss 0.579019.
Train: 2018-08-01T00:04:52.415031: step 1805, loss 0.579368.
Train: 2018-08-01T00:04:52.571212: step 1806, loss 0.420615.
Train: 2018-08-01T00:04:52.743070: step 1807, loss 0.595569.
Train: 2018-08-01T00:04:52.899260: step 1808, loss 0.495946.
Train: 2018-08-01T00:04:53.055503: step 1809, loss 0.512513.
Train: 2018-08-01T00:04:53.211720: step 1810, loss 0.629682.
Test: 2018-08-01T00:04:53.695978: step 1810, loss 0.548417.
Train: 2018-08-01T00:04:53.852195: step 1811, loss 0.679968.
Train: 2018-08-01T00:04:54.024021: step 1812, loss 0.528726.
Train: 2018-08-01T00:04:54.180238: step 1813, loss 0.529076.
Train: 2018-08-01T00:04:54.336449: step 1814, loss 0.646305.
Train: 2018-08-01T00:04:54.492661: step 1815, loss 0.444987.
Train: 2018-08-01T00:04:54.648880: step 1816, loss 0.562417.
Train: 2018-08-01T00:04:54.805063: step 1817, loss 0.579343.
Train: 2018-08-01T00:04:54.961278: step 1818, loss 0.545626.
Train: 2018-08-01T00:04:55.117515: step 1819, loss 0.512159.
Train: 2018-08-01T00:04:55.273734: step 1820, loss 0.57934.
Test: 2018-08-01T00:04:55.757995: step 1820, loss 0.548277.
Train: 2018-08-01T00:04:55.914178: step 1821, loss 0.629981.
Train: 2018-08-01T00:04:56.070392: step 1822, loss 0.680846.
Train: 2018-08-01T00:04:56.226639: step 1823, loss 0.562357.
Train: 2018-08-01T00:04:56.382854: step 1824, loss 0.579468.
Train: 2018-08-01T00:04:56.539068: step 1825, loss 0.528746.
Train: 2018-08-01T00:04:56.695270: step 1826, loss 0.545461.
Train: 2018-08-01T00:04:56.851490: step 1827, loss 0.528832.
Train: 2018-08-01T00:04:57.023324: step 1828, loss 0.478376.
Train: 2018-08-01T00:04:57.179532: step 1829, loss 0.613134.
Train: 2018-08-01T00:04:57.351343: step 1830, loss 0.545675.
Test: 2018-08-01T00:04:57.820012: step 1830, loss 0.54829.
Train: 2018-08-01T00:04:57.960608: step 1831, loss 0.562362.
Train: 2018-08-01T00:04:58.132439: step 1832, loss 0.511696.
Train: 2018-08-01T00:04:58.288646: step 1833, loss 0.630052.
Train: 2018-08-01T00:04:58.444866: step 1834, loss 0.375999.
Train: 2018-08-01T00:04:58.601074: step 1835, loss 0.596474.
Train: 2018-08-01T00:04:58.757293: step 1836, loss 0.528358.
Train: 2018-08-01T00:04:58.913507: step 1837, loss 0.596525.
Train: 2018-08-01T00:04:59.085335: step 1838, loss 0.613714.
Train: 2018-08-01T00:04:59.241549: step 1839, loss 0.493831.
Train: 2018-08-01T00:04:59.397768: step 1840, loss 0.510849.
Test: 2018-08-01T00:04:59.897651: step 1840, loss 0.54797.
Train: 2018-08-01T00:05:00.053834: step 1841, loss 0.596729.
Train: 2018-08-01T00:05:00.210072: step 1842, loss 0.5625.
Train: 2018-08-01T00:05:00.366292: step 1843, loss 0.458454.
Train: 2018-08-01T00:05:00.522505: step 1844, loss 0.562394.
Train: 2018-08-01T00:05:00.678687: step 1845, loss 0.579806.
Train: 2018-08-01T00:05:00.834901: step 1846, loss 0.632376.
Train: 2018-08-01T00:05:00.991114: step 1847, loss 0.57949.
Train: 2018-08-01T00:05:01.147328: step 1848, loss 0.597165.
Train: 2018-08-01T00:05:01.319163: step 1849, loss 0.47516.
Train: 2018-08-01T00:05:01.475376: step 1850, loss 0.59747.
Test: 2018-08-01T00:05:01.944046: step 1850, loss 0.547803.
Train: 2018-08-01T00:05:02.100260: step 1851, loss 0.544955.
Train: 2018-08-01T00:05:02.256469: step 1852, loss 0.527422.
Train: 2018-08-01T00:05:02.428278: step 1853, loss 0.474801.
Train: 2018-08-01T00:05:02.584525: step 1854, loss 0.527442.
Train: 2018-08-01T00:05:02.740735: step 1855, loss 0.59807.
Train: 2018-08-01T00:05:02.896952: step 1856, loss 0.5804.
Train: 2018-08-01T00:05:03.068777: step 1857, loss 0.580076.
Train: 2018-08-01T00:05:03.224992: step 1858, loss 0.633184.
Train: 2018-08-01T00:05:03.381210: step 1859, loss 0.439024.
Train: 2018-08-01T00:05:03.553015: step 1860, loss 0.544522.
Test: 2018-08-01T00:05:04.021654: step 1860, loss 0.547708.
Train: 2018-08-01T00:05:04.177899: step 1861, loss 0.597714.
Train: 2018-08-01T00:05:04.349727: step 1862, loss 0.509346.
Train: 2018-08-01T00:05:04.505948: step 1863, loss 0.509526.
Train: 2018-08-01T00:05:04.662155: step 1864, loss 0.580113.
Train: 2018-08-01T00:05:04.818344: step 1865, loss 0.526957.
Train: 2018-08-01T00:05:04.974581: step 1866, loss 0.509027.
Train: 2018-08-01T00:05:05.130771: step 1867, loss 0.544604.
Train: 2018-08-01T00:05:05.287019: step 1868, loss 0.527202.
Train: 2018-08-01T00:05:05.443230: step 1869, loss 0.544239.
Train: 2018-08-01T00:05:05.615056: step 1870, loss 0.491159.
Test: 2018-08-01T00:05:06.099323: step 1870, loss 0.547607.
Train: 2018-08-01T00:05:06.255538: step 1871, loss 0.544358.
Train: 2018-08-01T00:05:06.411751: step 1872, loss 0.76145.
Train: 2018-08-01T00:05:06.583554: step 1873, loss 0.581179.
Train: 2018-08-01T00:05:06.739769: step 1874, loss 0.635109.
Train: 2018-08-01T00:05:06.895983: step 1875, loss 0.562224.
Train: 2018-08-01T00:05:07.052226: step 1876, loss 0.54469.
Train: 2018-08-01T00:05:07.224030: step 1877, loss 0.562442.
Train: 2018-08-01T00:05:07.380243: step 1878, loss 0.508519.
Train: 2018-08-01T00:05:07.536482: step 1879, loss 0.651375.
Train: 2018-08-01T00:05:07.692703: step 1880, loss 0.686868.
Test: 2018-08-01T00:05:08.176962: step 1880, loss 0.547693.
Train: 2018-08-01T00:05:08.348797: step 1881, loss 0.544941.
Train: 2018-08-01T00:05:08.505011: step 1882, loss 0.615444.
Train: 2018-08-01T00:05:08.661227: step 1883, loss 0.544398.
Train: 2018-08-01T00:05:08.817432: step 1884, loss 0.579934.
Train: 2018-08-01T00:05:08.973645: step 1885, loss 0.545133.
Train: 2018-08-01T00:05:09.129868: step 1886, loss 0.544938.
Train: 2018-08-01T00:05:09.301699: step 1887, loss 0.614303.
Train: 2018-08-01T00:05:09.457911: step 1888, loss 0.562612.
Train: 2018-08-01T00:05:09.629749: step 1889, loss 0.562239.
Train: 2018-08-01T00:05:09.785935: step 1890, loss 0.768671.
Test: 2018-08-01T00:05:10.270223: step 1890, loss 0.548071.
Train: 2018-08-01T00:05:10.426420: step 1891, loss 0.528317.
Train: 2018-08-01T00:05:10.598241: step 1892, loss 0.562333.
Train: 2018-08-01T00:05:10.754453: step 1893, loss 0.647154.
Train: 2018-08-01T00:05:10.910691: step 1894, loss 0.57924.
Train: 2018-08-01T00:05:11.066913: step 1895, loss 0.478757.
Train: 2018-08-01T00:05:11.223124: step 1896, loss 0.51227.
Train: 2018-08-01T00:05:11.410576: step 1897, loss 0.478996.
Train: 2018-08-01T00:05:11.582386: step 1898, loss 0.545927.
Train: 2018-08-01T00:05:11.738598: step 1899, loss 0.47878.
Train: 2018-08-01T00:05:11.894811: step 1900, loss 0.596045.
Test: 2018-08-01T00:05:12.363482: step 1900, loss 0.548395.
Train: 2018-08-01T00:05:13.066413: step 1901, loss 0.612846.
Train: 2018-08-01T00:05:13.222625: step 1902, loss 0.562579.
Train: 2018-08-01T00:05:13.394490: step 1903, loss 0.545574.
Train: 2018-08-01T00:05:13.550703: step 1904, loss 0.545544.
Train: 2018-08-01T00:05:13.706920: step 1905, loss 0.612873.
Train: 2018-08-01T00:05:13.863102: step 1906, loss 0.562336.
Train: 2018-08-01T00:05:14.019314: step 1907, loss 0.579238.
Train: 2018-08-01T00:05:14.175557: step 1908, loss 0.461468.
Train: 2018-08-01T00:05:14.331774: step 1909, loss 0.529063.
Train: 2018-08-01T00:05:14.503600: step 1910, loss 0.680577.
Test: 2018-08-01T00:05:14.987867: step 1910, loss 0.548284.
Train: 2018-08-01T00:05:15.146237: step 1911, loss 0.528726.
Train: 2018-08-01T00:05:15.302483: step 1912, loss 0.613007.
Train: 2018-08-01T00:05:15.458688: step 1913, loss 0.528641.
Train: 2018-08-01T00:05:15.614909: step 1914, loss 0.461269.
Train: 2018-08-01T00:05:15.771121: step 1915, loss 0.545403.
Train: 2018-08-01T00:05:15.927337: step 1916, loss 0.630542.
Train: 2018-08-01T00:05:16.083547: step 1917, loss 0.511529.
Train: 2018-08-01T00:05:16.239731: step 1918, loss 0.477232.
Train: 2018-08-01T00:05:16.411566: step 1919, loss 0.665002.
Train: 2018-08-01T00:05:16.567780: step 1920, loss 0.545172.
Test: 2018-08-01T00:05:17.036420: step 1920, loss 0.548078.
Train: 2018-08-01T00:05:17.208255: step 1921, loss 0.477011.
Train: 2018-08-01T00:05:17.364468: step 1922, loss 0.562452.
Train: 2018-08-01T00:05:17.536303: step 1923, loss 0.682318.
Train: 2018-08-01T00:05:17.692541: step 1924, loss 0.545279.
Train: 2018-08-01T00:05:17.848730: step 1925, loss 0.665428.
Train: 2018-08-01T00:05:18.004973: step 1926, loss 0.613693.
Train: 2018-08-01T00:05:18.161188: step 1927, loss 0.544954.
Train: 2018-08-01T00:05:18.317371: step 1928, loss 0.562807.
Train: 2018-08-01T00:05:18.473583: step 1929, loss 0.528493.
Train: 2018-08-01T00:05:18.645444: step 1930, loss 0.665334.
Test: 2018-08-01T00:05:19.129678: step 1930, loss 0.548141.
Train: 2018-08-01T00:05:19.285892: step 1931, loss 0.511355.
Train: 2018-08-01T00:05:19.442137: step 1932, loss 0.494294.
Train: 2018-08-01T00:05:19.598319: step 1933, loss 0.613561.
Train: 2018-08-01T00:05:19.754533: step 1934, loss 0.545638.
Train: 2018-08-01T00:05:19.910747: step 1935, loss 0.545718.
Train: 2018-08-01T00:05:20.082611: step 1936, loss 0.613254.
Train: 2018-08-01T00:05:20.238825: step 1937, loss 0.545423.
Train: 2018-08-01T00:05:20.410663: step 1938, loss 0.477617.
Train: 2018-08-01T00:05:20.566843: step 1939, loss 0.545468.
Train: 2018-08-01T00:05:20.723057: step 1940, loss 0.511629.
Test: 2018-08-01T00:05:21.191697: step 1940, loss 0.548147.
Train: 2018-08-01T00:05:21.363531: step 1941, loss 0.579549.
Train: 2018-08-01T00:05:21.519745: step 1942, loss 0.596604.
Train: 2018-08-01T00:05:21.691610: step 1943, loss 0.494258.
Train: 2018-08-01T00:05:21.847793: step 1944, loss 0.579471.
Train: 2018-08-01T00:05:21.988415: step 1945, loss 0.527984.
Train: 2018-08-01T00:05:22.160220: step 1946, loss 0.596806.
Train: 2018-08-01T00:05:22.316433: step 1947, loss 0.545236.
Train: 2018-08-01T00:05:22.472663: step 1948, loss 0.545351.
Train: 2018-08-01T00:05:22.628860: step 1949, loss 0.648316.
Train: 2018-08-01T00:05:22.785074: step 1950, loss 0.493404.
Test: 2018-08-01T00:05:23.253744: step 1950, loss 0.547982.
Train: 2018-08-01T00:05:23.409928: step 1951, loss 0.510823.
Train: 2018-08-01T00:05:23.581763: step 1952, loss 0.511094.
Train: 2018-08-01T00:05:23.753621: step 1953, loss 0.579903.
Train: 2018-08-01T00:05:23.909841: step 1954, loss 0.596894.
Train: 2018-08-01T00:05:24.066024: step 1955, loss 0.579487.
Train: 2018-08-01T00:05:24.222236: step 1956, loss 0.562442.
Train: 2018-08-01T00:05:24.378451: step 1957, loss 0.544989.
Train: 2018-08-01T00:05:24.534664: step 1958, loss 0.458245.
Train: 2018-08-01T00:05:24.690878: step 1959, loss 0.5974.
Train: 2018-08-01T00:05:24.847090: step 1960, loss 0.492753.
Test: 2018-08-01T00:05:25.331351: step 1960, loss 0.547815.
Train: 2018-08-01T00:05:25.487565: step 1961, loss 0.544788.
Train: 2018-08-01T00:05:25.643779: step 1962, loss 0.457403.
Train: 2018-08-01T00:05:25.799992: step 1963, loss 0.650457.
Train: 2018-08-01T00:05:25.956205: step 1964, loss 0.632864.
Train: 2018-08-01T00:05:26.112451: step 1965, loss 0.562525.
Train: 2018-08-01T00:05:26.268632: step 1966, loss 0.685411.
Train: 2018-08-01T00:05:26.424872: step 1967, loss 0.562556.
Train: 2018-08-01T00:05:26.581096: step 1968, loss 0.615039.
Train: 2018-08-01T00:05:26.737303: step 1969, loss 0.527099.
Train: 2018-08-01T00:05:26.893518: step 1970, loss 0.527611.
Test: 2018-08-01T00:05:27.377748: step 1970, loss 0.547814.
Train: 2018-08-01T00:05:27.533962: step 1971, loss 0.510045.
Train: 2018-08-01T00:05:27.690175: step 1972, loss 0.492798.
Train: 2018-08-01T00:05:27.846389: step 1973, loss 0.649714.
Train: 2018-08-01T00:05:28.002601: step 1974, loss 0.650038.
Train: 2018-08-01T00:05:28.174436: step 1975, loss 0.614542.
Train: 2018-08-01T00:05:28.330649: step 1976, loss 0.580036.
Train: 2018-08-01T00:05:28.486894: step 1977, loss 0.614237.
Train: 2018-08-01T00:05:28.643115: step 1978, loss 0.510242.
Train: 2018-08-01T00:05:28.799290: step 1979, loss 0.562571.
Train: 2018-08-01T00:05:28.955528: step 1980, loss 0.528062.
Test: 2018-08-01T00:05:29.424177: step 1980, loss 0.548007.
Train: 2018-08-01T00:05:29.580358: step 1981, loss 0.52809.
Train: 2018-08-01T00:05:29.736570: step 1982, loss 0.61408.
Train: 2018-08-01T00:05:29.892814: step 1983, loss 0.562583.
Train: 2018-08-01T00:05:30.049031: step 1984, loss 0.510987.
Train: 2018-08-01T00:05:30.205210: step 1985, loss 0.579514.
Train: 2018-08-01T00:05:30.377046: step 1986, loss 0.510931.
Train: 2018-08-01T00:05:30.533260: step 1987, loss 0.459617.
Train: 2018-08-01T00:05:30.689502: step 1988, loss 0.493656.
Train: 2018-08-01T00:05:30.845685: step 1989, loss 0.510957.
Train: 2018-08-01T00:05:31.001898: step 1990, loss 0.545006.
Test: 2018-08-01T00:05:31.470540: step 1990, loss 0.547907.
Train: 2018-08-01T00:05:31.626754: step 1991, loss 0.475496.
Train: 2018-08-01T00:05:31.798621: step 1992, loss 0.614608.
Train: 2018-08-01T00:05:31.954831: step 1993, loss 0.527105.
Train: 2018-08-01T00:05:32.111014: step 1994, loss 0.684864.
Train: 2018-08-01T00:05:32.267227: step 1995, loss 0.54522.
Train: 2018-08-01T00:05:32.423441: step 1996, loss 0.667094.
Train: 2018-08-01T00:05:32.579685: step 1997, loss 0.597909.
Train: 2018-08-01T00:05:32.735898: step 1998, loss 0.545392.
Train: 2018-08-01T00:05:32.892081: step 1999, loss 0.52765.
Train: 2018-08-01T00:05:33.048329: step 2000, loss 0.597355.
Test: 2018-08-01T00:05:33.542638: step 2000, loss 0.54781.
Train: 2018-08-01T00:05:34.247987: step 2001, loss 0.527275.
Train: 2018-08-01T00:05:34.404167: step 2002, loss 0.580028.
Train: 2018-08-01T00:05:34.560381: step 2003, loss 0.77148.
Train: 2018-08-01T00:05:34.716624: step 2004, loss 0.562402.
Train: 2018-08-01T00:05:34.872808: step 2005, loss 0.596787.
Train: 2018-08-01T00:05:35.029051: step 2006, loss 0.51072.
Train: 2018-08-01T00:05:35.185234: step 2007, loss 0.493548.
Train: 2018-08-01T00:05:35.357069: step 2008, loss 0.493465.
Train: 2018-08-01T00:05:35.528904: step 2009, loss 0.579536.
Train: 2018-08-01T00:05:35.687635: step 2010, loss 0.562312.
Test: 2018-08-01T00:05:36.153314: step 2010, loss 0.548017.
Train: 2018-08-01T00:05:36.309529: step 2011, loss 0.493841.
Train: 2018-08-01T00:05:36.465712: step 2012, loss 0.545508.
Train: 2018-08-01T00:05:36.621926: step 2013, loss 0.528059.
Train: 2018-08-01T00:05:36.778169: step 2014, loss 0.458612.
Train: 2018-08-01T00:05:36.934382: step 2015, loss 0.614762.
Train: 2018-08-01T00:05:37.090566: step 2016, loss 0.527748.
Train: 2018-08-01T00:05:37.246808: step 2017, loss 0.562409.
Train: 2018-08-01T00:05:37.402992: step 2018, loss 0.510303.
Train: 2018-08-01T00:05:37.559236: step 2019, loss 0.649139.
Train: 2018-08-01T00:05:37.731040: step 2020, loss 0.405361.
Test: 2018-08-01T00:05:38.199710: step 2020, loss 0.547793.
Train: 2018-08-01T00:05:38.371532: step 2021, loss 0.614329.
Train: 2018-08-01T00:05:38.527753: step 2022, loss 0.492217.
Train: 2018-08-01T00:05:38.699563: step 2023, loss 0.509656.
Train: 2018-08-01T00:05:38.855807: step 2024, loss 0.474471.
Train: 2018-08-01T00:05:39.011990: step 2025, loss 0.526905.
Train: 2018-08-01T00:05:39.168234: step 2026, loss 0.580214.
Train: 2018-08-01T00:05:39.340038: step 2027, loss 0.545108.
Train: 2018-08-01T00:05:39.496281: step 2028, loss 0.508747.
Train: 2018-08-01T00:05:39.652496: step 2029, loss 0.68886.
Train: 2018-08-01T00:05:39.808712: step 2030, loss 0.580011.
Test: 2018-08-01T00:05:40.292970: step 2030, loss 0.547595.
Train: 2018-08-01T00:05:40.449153: step 2031, loss 0.56297.
Train: 2018-08-01T00:05:40.605398: step 2032, loss 0.526103.
Train: 2018-08-01T00:05:40.761581: step 2033, loss 0.5625.
Train: 2018-08-01T00:05:40.917794: step 2034, loss 0.400641.
Train: 2018-08-01T00:05:41.058387: step 2035, loss 0.59903.
Train: 2018-08-01T00:05:41.214600: step 2036, loss 0.617948.
Train: 2018-08-01T00:05:41.370845: step 2037, loss 0.61763.
Train: 2018-08-01T00:05:41.527056: step 2038, loss 0.707528.
Train: 2018-08-01T00:05:41.683265: step 2039, loss 0.599039.
Train: 2018-08-01T00:05:41.839453: step 2040, loss 0.543977.
Test: 2018-08-01T00:05:42.323745: step 2040, loss 0.547613.
Train: 2018-08-01T00:05:42.479959: step 2041, loss 0.454567.
Train: 2018-08-01T00:05:42.636141: step 2042, loss 0.598951.
Train: 2018-08-01T00:05:42.792355: step 2043, loss 0.526942.
Train: 2018-08-01T00:05:42.948568: step 2044, loss 0.580076.
Train: 2018-08-01T00:05:43.104782: step 2045, loss 0.634267.
Train: 2018-08-01T00:05:43.276647: step 2046, loss 0.491272.
Train: 2018-08-01T00:05:43.432861: step 2047, loss 0.455701.
Train: 2018-08-01T00:05:43.589076: step 2048, loss 0.545752.
Train: 2018-08-01T00:05:43.745258: step 2049, loss 0.561883.
Train: 2018-08-01T00:05:43.901501: step 2050, loss 0.545215.
Test: 2018-08-01T00:05:44.370143: step 2050, loss 0.547663.
Train: 2018-08-01T00:05:44.526354: step 2051, loss 0.526945.
Train: 2018-08-01T00:05:44.682538: step 2052, loss 0.579769.
Train: 2018-08-01T00:05:44.838751: step 2053, loss 0.58004.
Train: 2018-08-01T00:05:44.994965: step 2054, loss 0.650309.
Train: 2018-08-01T00:05:45.151208: step 2055, loss 0.527099.
Train: 2018-08-01T00:05:45.323036: step 2056, loss 0.57999.
Train: 2018-08-01T00:05:45.479227: step 2057, loss 0.545024.
Train: 2018-08-01T00:05:45.635467: step 2058, loss 0.580603.
Train: 2018-08-01T00:05:45.791652: step 2059, loss 0.597938.
Train: 2018-08-01T00:05:45.947866: step 2060, loss 0.526916.
Test: 2018-08-01T00:05:46.432127: step 2060, loss 0.547715.
Train: 2018-08-01T00:05:46.603963: step 2061, loss 0.597925.
Train: 2018-08-01T00:05:46.760204: step 2062, loss 0.579795.
Train: 2018-08-01T00:05:46.916389: step 2063, loss 0.580849.
Train: 2018-08-01T00:05:47.072603: step 2064, loss 0.632888.
Train: 2018-08-01T00:05:47.228816: step 2065, loss 0.649281.
Train: 2018-08-01T00:05:47.385061: step 2066, loss 0.544468.
Train: 2018-08-01T00:05:47.541268: step 2067, loss 0.562356.
Train: 2018-08-01T00:05:47.713108: step 2068, loss 0.544957.
Train: 2018-08-01T00:05:47.869291: step 2069, loss 0.493795.
Train: 2018-08-01T00:05:48.025504: step 2070, loss 0.442327.
Test: 2018-08-01T00:05:48.494144: step 2070, loss 0.547975.
Train: 2018-08-01T00:05:48.650358: step 2071, loss 0.682372.
Train: 2018-08-01T00:05:48.806571: step 2072, loss 0.579359.
Train: 2018-08-01T00:05:48.962815: step 2073, loss 0.597396.
Train: 2018-08-01T00:05:49.119022: step 2074, loss 0.5962.
Train: 2018-08-01T00:05:49.275212: step 2075, loss 0.545846.
Train: 2018-08-01T00:05:49.431425: step 2076, loss 0.630334.
Train: 2018-08-01T00:05:49.587639: step 2077, loss 0.545269.
Train: 2018-08-01T00:05:49.743877: step 2078, loss 0.494515.
Train: 2018-08-01T00:05:49.915687: step 2079, loss 0.545422.
Train: 2018-08-01T00:05:50.071901: step 2080, loss 0.647199.
Test: 2018-08-01T00:05:50.540570: step 2080, loss 0.548223.
Train: 2018-08-01T00:05:50.696755: step 2081, loss 0.596499.
Train: 2018-08-01T00:05:50.852998: step 2082, loss 0.545319.
Train: 2018-08-01T00:05:51.024833: step 2083, loss 0.562529.
Train: 2018-08-01T00:05:51.181046: step 2084, loss 0.545214.
Train: 2018-08-01T00:05:51.337230: step 2085, loss 0.629897.
Train: 2018-08-01T00:05:51.493479: step 2086, loss 0.528196.
Train: 2018-08-01T00:05:51.649686: step 2087, loss 0.512209.
Train: 2018-08-01T00:05:51.805893: step 2088, loss 0.511757.
Train: 2018-08-01T00:05:51.962118: step 2089, loss 0.663216.
Train: 2018-08-01T00:05:52.118296: step 2090, loss 0.52877.
Test: 2018-08-01T00:05:52.602589: step 2090, loss 0.548349.
Train: 2018-08-01T00:05:52.758771: step 2091, loss 0.495857.
Train: 2018-08-01T00:05:52.914984: step 2092, loss 0.713837.
Train: 2018-08-01T00:05:53.071197: step 2093, loss 0.663462.
Train: 2018-08-01T00:05:53.227442: step 2094, loss 0.562839.
Train: 2018-08-01T00:05:53.399282: step 2095, loss 0.529276.
Train: 2018-08-01T00:05:53.555484: step 2096, loss 0.579031.
Train: 2018-08-01T00:05:53.711674: step 2097, loss 0.57884.
Train: 2018-08-01T00:05:53.867886: step 2098, loss 0.545746.
Train: 2018-08-01T00:05:54.024099: step 2099, loss 0.562366.
Train: 2018-08-01T00:05:54.164722: step 2100, loss 0.579516.
Test: 2018-08-01T00:05:54.664574: step 2100, loss 0.548627.
Train: 2018-08-01T00:05:55.430051: step 2101, loss 0.545814.
Train: 2018-08-01T00:05:55.586233: step 2102, loss 0.595802.
Train: 2018-08-01T00:05:55.742448: step 2103, loss 0.562536.
Train: 2018-08-01T00:05:55.898691: step 2104, loss 0.645396.
Train: 2018-08-01T00:05:56.054905: step 2105, loss 0.628884.
Train: 2018-08-01T00:05:56.226740: step 2106, loss 0.496496.
Train: 2018-08-01T00:05:56.382922: step 2107, loss 0.492138.
Train: 2018-08-01T00:05:56.539166: step 2108, loss 0.545855.
Train: 2018-08-01T00:05:56.695380: step 2109, loss 0.529388.
Train: 2018-08-01T00:05:56.867214: step 2110, loss 0.529876.
Test: 2018-08-01T00:05:57.335854: step 2110, loss 0.548693.
Train: 2018-08-01T00:05:57.492062: step 2111, loss 0.612251.
Train: 2018-08-01T00:05:57.648252: step 2112, loss 0.546054.
Train: 2018-08-01T00:05:57.820111: step 2113, loss 0.529469.
Train: 2018-08-01T00:05:57.976299: step 2114, loss 0.52958.
Train: 2018-08-01T00:05:58.132512: step 2115, loss 0.712026.
Train: 2018-08-01T00:05:58.288726: step 2116, loss 0.445673.
Train: 2018-08-01T00:05:58.444970: step 2117, loss 0.579575.
Train: 2018-08-01T00:05:58.601190: step 2118, loss 0.495705.
Train: 2018-08-01T00:05:58.757398: step 2119, loss 0.528829.
Train: 2018-08-01T00:05:58.929201: step 2120, loss 0.59519.
Test: 2018-08-01T00:05:59.397872: step 2120, loss 0.548322.
Train: 2018-08-01T00:05:59.569687: step 2121, loss 0.478296.
Train: 2018-08-01T00:05:59.725889: step 2122, loss 0.511614.
Train: 2018-08-01T00:05:59.882103: step 2123, loss 0.54504.
Train: 2018-08-01T00:06:00.038318: step 2124, loss 0.562185.
Train: 2018-08-01T00:06:00.194555: step 2125, loss 0.527701.
Train: 2018-08-01T00:06:00.350773: step 2126, loss 0.579885.
Train: 2018-08-01T00:06:00.506988: step 2127, loss 0.458036.
Train: 2018-08-01T00:06:00.663200: step 2128, loss 0.511183.
Train: 2018-08-01T00:06:00.819383: step 2129, loss 0.527833.
Train: 2018-08-01T00:06:00.975627: step 2130, loss 0.526791.
Test: 2018-08-01T00:06:01.459859: step 2130, loss 0.547709.
Train: 2018-08-01T00:06:01.616104: step 2131, loss 0.474326.
Train: 2018-08-01T00:06:01.772316: step 2132, loss 0.59819.
Train: 2018-08-01T00:06:01.928500: step 2133, loss 0.563581.
Train: 2018-08-01T00:06:02.084712: step 2134, loss 0.616301.
Train: 2018-08-01T00:06:02.240925: step 2135, loss 0.418848.
Train: 2018-08-01T00:06:02.397139: step 2136, loss 0.724251.
Train: 2018-08-01T00:06:02.553352: step 2137, loss 0.599114.
Train: 2018-08-01T00:06:02.709591: step 2138, loss 0.634684.
Train: 2018-08-01T00:06:02.881432: step 2139, loss 0.672773.
Train: 2018-08-01T00:06:03.037617: step 2140, loss 0.636536.
Test: 2018-08-01T00:06:03.521876: step 2140, loss 0.547624.
Train: 2018-08-01T00:06:03.678119: step 2141, loss 0.635474.
Train: 2018-08-01T00:06:03.834303: step 2142, loss 0.508793.
Train: 2018-08-01T00:06:03.990517: step 2143, loss 0.562149.
Train: 2018-08-01T00:06:04.146754: step 2144, loss 0.510091.
Train: 2018-08-01T00:06:04.302973: step 2145, loss 0.597234.
Train: 2018-08-01T00:06:04.474808: step 2146, loss 0.422141.
Train: 2018-08-01T00:06:04.630991: step 2147, loss 0.597845.
Train: 2018-08-01T00:06:04.787250: step 2148, loss 0.631636.
Train: 2018-08-01T00:06:04.943448: step 2149, loss 0.580308.
Train: 2018-08-01T00:06:05.099631: step 2150, loss 0.51102.
Test: 2018-08-01T00:06:05.583923: step 2150, loss 0.547898.
Train: 2018-08-01T00:06:05.740136: step 2151, loss 0.510715.
Train: 2018-08-01T00:06:05.896349: step 2152, loss 0.492942.
Train: 2018-08-01T00:06:06.052558: step 2153, loss 0.527277.
Train: 2018-08-01T00:06:06.208777: step 2154, loss 0.528215.
Train: 2018-08-01T00:06:06.364990: step 2155, loss 0.684357.
Train: 2018-08-01T00:06:06.521199: step 2156, loss 0.510299.
Train: 2018-08-01T00:06:06.693039: step 2157, loss 0.596698.
Train: 2018-08-01T00:06:06.849252: step 2158, loss 0.57922.
Train: 2018-08-01T00:06:07.005467: step 2159, loss 0.545073.
Train: 2018-08-01T00:06:07.161679: step 2160, loss 0.614575.
Test: 2018-08-01T00:06:07.661562: step 2160, loss 0.547906.
Train: 2018-08-01T00:06:07.817744: step 2161, loss 0.52799.
Train: 2018-08-01T00:06:07.973988: step 2162, loss 0.684053.
Train: 2018-08-01T00:06:08.130173: step 2163, loss 0.68337.
Train: 2018-08-01T00:06:08.302007: step 2164, loss 0.476208.
Train: 2018-08-01T00:06:08.460250: step 2165, loss 0.579618.
Train: 2018-08-01T00:06:08.610201: step 2166, loss 0.699279.
Train: 2018-08-01T00:06:08.774098: step 2167, loss 0.477273.
Train: 2018-08-01T00:06:08.930995: step 2168, loss 0.477472.
Train: 2018-08-01T00:06:09.087211: step 2169, loss 0.545436.
Train: 2018-08-01T00:06:09.243424: step 2170, loss 0.545401.
Test: 2018-08-01T00:06:09.712066: step 2170, loss 0.548213.
Train: 2018-08-01T00:06:09.883932: step 2171, loss 0.528451.
Train: 2018-08-01T00:06:10.040113: step 2172, loss 0.63044.
Train: 2018-08-01T00:06:10.196356: step 2173, loss 0.596457.
Train: 2018-08-01T00:06:10.352573: step 2174, loss 0.477814.
Train: 2018-08-01T00:06:10.508786: step 2175, loss 0.596232.
Train: 2018-08-01T00:06:10.664967: step 2176, loss 0.494772.
Train: 2018-08-01T00:06:10.821207: step 2177, loss 0.477444.
Train: 2018-08-01T00:06:10.977393: step 2178, loss 0.562534.
Train: 2018-08-01T00:06:11.133607: step 2179, loss 0.460126.
Train: 2018-08-01T00:06:11.352305: step 2180, loss 0.477176.
Test: 2018-08-01T00:06:11.820976: step 2180, loss 0.548022.
Train: 2018-08-01T00:06:11.977190: step 2181, loss 0.527953.
Train: 2018-08-01T00:06:12.133406: step 2182, loss 0.59705.
Train: 2018-08-01T00:06:12.289618: step 2183, loss 0.614463.
Train: 2018-08-01T00:06:12.461471: step 2184, loss 0.475665.
Train: 2018-08-01T00:06:12.617660: step 2185, loss 0.527555.
Train: 2018-08-01T00:06:12.792274: step 2186, loss 0.632046.
Train: 2018-08-01T00:06:12.942207: step 2187, loss 0.579812.
Train: 2018-08-01T00:06:13.101967: step 2188, loss 0.544801.
Train: 2018-08-01T00:06:13.262315: step 2189, loss 0.650428.
Train: 2018-08-01T00:06:13.414079: step 2190, loss 0.632845.
Test: 2018-08-01T00:06:13.898339: step 2190, loss 0.547767.
Train: 2018-08-01T00:06:14.101388: step 2191, loss 0.580221.
Train: 2018-08-01T00:06:14.273221: step 2192, loss 0.527601.
Train: 2018-08-01T00:06:14.429435: step 2193, loss 0.544922.
Train: 2018-08-01T00:06:14.585673: step 2194, loss 0.597388.
Train: 2018-08-01T00:06:14.741893: step 2195, loss 0.527538.
Train: 2018-08-01T00:06:14.913728: step 2196, loss 0.562517.
Train: 2018-08-01T00:06:15.069935: step 2197, loss 0.544971.
Train: 2018-08-01T00:06:15.226124: step 2198, loss 0.649605.
Train: 2018-08-01T00:06:15.382363: step 2199, loss 0.719233.
Train: 2018-08-01T00:06:15.538581: step 2200, loss 0.631961.
Test: 2018-08-01T00:06:16.022812: step 2200, loss 0.547942.
Train: 2018-08-01T00:06:16.772637: step 2201, loss 0.614103.
Train: 2018-08-01T00:06:16.944472: step 2202, loss 0.527925.
Train: 2018-08-01T00:06:17.100709: step 2203, loss 0.682332.
Train: 2018-08-01T00:06:17.272520: step 2204, loss 0.681785.
Train: 2018-08-01T00:06:17.428734: step 2205, loss 0.511682.
Train: 2018-08-01T00:06:17.600598: step 2206, loss 0.56241.
Train: 2018-08-01T00:06:17.756782: step 2207, loss 0.51224.
Train: 2018-08-01T00:06:17.928646: step 2208, loss 0.445747.
Train: 2018-08-01T00:06:18.100481: step 2209, loss 0.629124.
Train: 2018-08-01T00:06:18.256664: step 2210, loss 0.512641.
Test: 2018-08-01T00:06:18.740927: step 2210, loss 0.548589.
Train: 2018-08-01T00:06:18.897139: step 2211, loss 0.662264.
Train: 2018-08-01T00:06:19.053383: step 2212, loss 0.545922.
Train: 2018-08-01T00:06:19.209597: step 2213, loss 0.628762.
Train: 2018-08-01T00:06:19.365779: step 2214, loss 0.562525.
Train: 2018-08-01T00:06:19.537615: step 2215, loss 0.529633.
Train: 2018-08-01T00:06:19.693828: step 2216, loss 0.661362.
Train: 2018-08-01T00:06:19.850041: step 2217, loss 0.463984.
Train: 2018-08-01T00:06:20.006255: step 2218, loss 0.578994.
Train: 2018-08-01T00:06:20.162468: step 2219, loss 0.513374.
Train: 2018-08-01T00:06:20.318711: step 2220, loss 0.56266.
Test: 2018-08-01T00:06:20.787352: step 2220, loss 0.548846.
Train: 2018-08-01T00:06:20.959186: step 2221, loss 0.562615.
Train: 2018-08-01T00:06:21.115400: step 2222, loss 0.595459.
Train: 2018-08-01T00:06:21.287205: step 2223, loss 0.677714.
Train: 2018-08-01T00:06:21.443419: step 2224, loss 0.513369.
Train: 2018-08-01T00:06:21.599656: step 2225, loss 0.496982.
Train: 2018-08-01T00:06:21.755876: step 2226, loss 0.628341.
Train: 2018-08-01T00:06:21.912088: step 2227, loss 0.611902.
Train: 2018-08-01T00:06:22.083923: step 2228, loss 0.562592.
Train: 2018-08-01T00:06:22.240137: step 2229, loss 0.546199.
Train: 2018-08-01T00:06:22.396319: step 2230, loss 0.513426.
Test: 2018-08-01T00:06:22.880611: step 2230, loss 0.548867.
Train: 2018-08-01T00:06:23.036826: step 2231, loss 0.562609.
Train: 2018-08-01T00:06:23.208629: step 2232, loss 0.628334.
Train: 2018-08-01T00:06:23.364842: step 2233, loss 0.480426.
Train: 2018-08-01T00:06:23.521057: step 2234, loss 0.595591.
Train: 2018-08-01T00:06:23.677300: step 2235, loss 0.562575.
Train: 2018-08-01T00:06:23.833484: step 2236, loss 0.529605.
Train: 2018-08-01T00:06:24.005343: step 2237, loss 0.513011.
Train: 2018-08-01T00:06:24.161532: step 2238, loss 0.579122.
Train: 2018-08-01T00:06:24.317770: step 2239, loss 0.529389.
Train: 2018-08-01T00:06:24.489610: step 2240, loss 0.595746.
Test: 2018-08-01T00:06:24.958250: step 2240, loss 0.548561.
Train: 2018-08-01T00:06:25.114458: step 2241, loss 0.579166.
Train: 2018-08-01T00:06:25.286298: step 2242, loss 0.529121.
Train: 2018-08-01T00:06:25.442481: step 2243, loss 0.629374.
Train: 2018-08-01T00:06:25.598696: step 2244, loss 0.562479.
Train: 2018-08-01T00:06:25.754939: step 2245, loss 0.562462.
Train: 2018-08-01T00:06:25.911123: step 2246, loss 0.512279.
Train: 2018-08-01T00:06:26.067335: step 2247, loss 0.612705.
Train: 2018-08-01T00:06:26.223584: step 2248, loss 0.679797.
Train: 2018-08-01T00:06:26.395413: step 2249, loss 0.562462.
Train: 2018-08-01T00:06:26.551627: step 2250, loss 0.612669.
Test: 2018-08-01T00:06:27.035859: step 2250, loss 0.548481.
Train: 2018-08-01T00:06:27.192074: step 2251, loss 0.529068.
Train: 2018-08-01T00:06:27.363932: step 2252, loss 0.629277.
Train: 2018-08-01T00:06:27.520120: step 2253, loss 0.629233.
Train: 2018-08-01T00:06:27.676334: step 2254, loss 0.579093.
Train: 2018-08-01T00:06:27.832547: step 2255, loss 0.529384.
Train: 2018-08-01T00:06:27.988790: step 2256, loss 0.529388.
Train: 2018-08-01T00:06:28.176246: step 2257, loss 0.496329.
Train: 2018-08-01T00:06:28.332431: step 2258, loss 0.711643.
Train: 2018-08-01T00:06:28.488643: step 2259, loss 0.52948.
Train: 2018-08-01T00:06:28.660478: step 2260, loss 0.513037.
Test: 2018-08-01T00:06:29.129149: step 2260, loss 0.548723.
Train: 2018-08-01T00:06:29.300954: step 2261, loss 0.579092.
Train: 2018-08-01T00:06:29.457166: step 2262, loss 0.496443.
Train: 2018-08-01T00:06:29.613381: step 2263, loss 0.529474.
Train: 2018-08-01T00:06:29.769595: step 2264, loss 0.612224.
Train: 2018-08-01T00:06:29.941459: step 2265, loss 0.595707.
Train: 2018-08-01T00:06:30.097672: step 2266, loss 0.62886.
Train: 2018-08-01T00:06:30.269501: step 2267, loss 0.661946.
Train: 2018-08-01T00:06:30.425689: step 2268, loss 0.529507.
Train: 2018-08-01T00:06:30.597526: step 2269, loss 0.628709.
Train: 2018-08-01T00:06:30.753768: step 2270, loss 0.546071.
Test: 2018-08-01T00:06:31.253622: step 2270, loss 0.548798.
Train: 2018-08-01T00:06:31.456699: step 2271, loss 0.562581.
Train: 2018-08-01T00:06:31.628533: step 2272, loss 0.644826.
Train: 2018-08-01T00:06:31.784784: step 2273, loss 0.48053.
Train: 2018-08-01T00:06:31.940995: step 2274, loss 0.579004.
Train: 2018-08-01T00:06:32.112820: step 2275, loss 0.677359.
Train: 2018-08-01T00:06:32.269033: step 2276, loss 0.578978.
Train: 2018-08-01T00:06:32.425246: step 2277, loss 0.627946.
Train: 2018-08-01T00:06:32.581459: step 2278, loss 0.399904.
Train: 2018-08-01T00:06:32.737679: step 2279, loss 0.530138.
Train: 2018-08-01T00:06:32.893861: step 2280, loss 0.497502.
Test: 2018-08-01T00:06:33.388545: step 2280, loss 0.548978.
Train: 2018-08-01T00:06:33.552968: step 2281, loss 0.513637.
Train: 2018-08-01T00:06:33.712057: step 2282, loss 0.628162.
Train: 2018-08-01T00:06:33.869113: step 2283, loss 0.464118.
Train: 2018-08-01T00:06:34.025359: step 2284, loss 0.546051.
Train: 2018-08-01T00:06:34.181572: step 2285, loss 0.612112.
Train: 2018-08-01T00:06:34.337781: step 2286, loss 0.595716.
Train: 2018-08-01T00:06:34.494005: step 2287, loss 0.562511.
Train: 2018-08-01T00:06:34.650213: step 2288, loss 0.579133.
Train: 2018-08-01T00:06:34.806396: step 2289, loss 0.512562.
Train: 2018-08-01T00:06:34.978231: step 2290, loss 0.579176.
Test: 2018-08-01T00:06:35.446902: step 2290, loss 0.548486.
Train: 2018-08-01T00:06:35.618706: step 2291, loss 0.696187.
Train: 2018-08-01T00:06:35.774920: step 2292, loss 0.445635.
Train: 2018-08-01T00:06:35.931168: step 2293, loss 0.545735.
Train: 2018-08-01T00:06:36.087376: step 2294, loss 0.629479.
Train: 2018-08-01T00:06:36.243590: step 2295, loss 0.51211.
Train: 2018-08-01T00:06:36.399773: step 2296, loss 0.612728.
Train: 2018-08-01T00:06:36.556011: step 2297, loss 0.56245.
Train: 2018-08-01T00:06:36.712230: step 2298, loss 0.478421.
Train: 2018-08-01T00:06:36.868438: step 2299, loss 0.663449.
Train: 2018-08-01T00:06:37.040249: step 2300, loss 0.545543.
Test: 2018-08-01T00:06:37.508918: step 2300, loss 0.548326.
Train: 2018-08-01T00:06:38.227503: step 2301, loss 0.629808.
Train: 2018-08-01T00:06:38.414929: step 2302, loss 0.663432.
Train: 2018-08-01T00:06:38.571172: step 2303, loss 0.646573.
Train: 2018-08-01T00:06:38.727379: step 2304, loss 0.612785.
Train: 2018-08-01T00:06:38.899219: step 2305, loss 0.529155.
Train: 2018-08-01T00:06:39.055426: step 2306, loss 0.512542.
Train: 2018-08-01T00:06:39.218108: step 2307, loss 0.562547.
Train: 2018-08-01T00:06:39.371002: step 2308, loss 0.595848.
Train: 2018-08-01T00:06:39.536972: step 2309, loss 0.512773.
Train: 2018-08-01T00:06:39.697372: step 2310, loss 0.595702.
Test: 2018-08-01T00:06:40.171026: step 2310, loss 0.548655.
Train: 2018-08-01T00:06:40.327269: step 2311, loss 0.463126.
Train: 2018-08-01T00:06:40.483482: step 2312, loss 0.579135.
Train: 2018-08-01T00:06:40.639698: step 2313, loss 0.512753.
Train: 2018-08-01T00:06:40.795909: step 2314, loss 0.579157.
Train: 2018-08-01T00:06:40.967745: step 2315, loss 0.695699.
Train: 2018-08-01T00:06:41.123960: step 2316, loss 0.545826.
Train: 2018-08-01T00:06:41.280173: step 2317, loss 0.545864.
Train: 2018-08-01T00:06:41.436385: step 2318, loss 0.612365.
Train: 2018-08-01T00:06:41.592568: step 2319, loss 0.496058.
Train: 2018-08-01T00:06:41.764435: step 2320, loss 0.545889.
Test: 2018-08-01T00:06:42.233067: step 2320, loss 0.548573.
Train: 2018-08-01T00:06:42.389286: step 2321, loss 0.479314.
Train: 2018-08-01T00:06:42.545500: step 2322, loss 0.512464.
Train: 2018-08-01T00:06:42.701682: step 2323, loss 0.579174.
Train: 2018-08-01T00:06:42.873517: step 2324, loss 0.52891.
Train: 2018-08-01T00:06:43.029732: step 2325, loss 0.528871.
Train: 2018-08-01T00:06:43.188361: step 2326, loss 0.56244.
Train: 2018-08-01T00:06:43.345470: step 2327, loss 0.545514.
Train: 2018-08-01T00:06:43.500015: step 2328, loss 0.511552.
Train: 2018-08-01T00:06:43.655678: step 2329, loss 0.545456.
Train: 2018-08-01T00:06:43.798548: step 2330, loss 0.528289.
Test: 2018-08-01T00:06:44.282780: step 2330, loss 0.548059.
Train: 2018-08-01T00:06:44.454615: step 2331, loss 0.442515.
Train: 2018-08-01T00:06:44.618312: step 2332, loss 0.596767.
Train: 2018-08-01T00:06:44.777213: step 2333, loss 0.666151.
Train: 2018-08-01T00:06:44.937341: step 2334, loss 0.562397.
Train: 2018-08-01T00:06:45.097154: step 2335, loss 0.597083.
Train: 2018-08-01T00:06:45.249115: step 2336, loss 0.649219.
Train: 2018-08-01T00:06:45.405322: step 2337, loss 0.649159.
Train: 2018-08-01T00:06:45.561542: step 2338, loss 0.527786.
Train: 2018-08-01T00:06:45.733347: step 2339, loss 0.527817.
Train: 2018-08-01T00:06:45.889560: step 2340, loss 0.545073.
Test: 2018-08-01T00:06:46.358230: step 2340, loss 0.547928.
Train: 2018-08-01T00:06:46.514443: step 2341, loss 0.510523.
Train: 2018-08-01T00:06:46.670651: step 2342, loss 0.562362.
Train: 2018-08-01T00:06:46.826876: step 2343, loss 0.545087.
Train: 2018-08-01T00:06:46.983053: step 2344, loss 0.458462.
Train: 2018-08-01T00:06:47.139267: step 2345, loss 0.614481.
Train: 2018-08-01T00:06:47.295480: step 2346, loss 0.475489.
Train: 2018-08-01T00:06:47.451724: step 2347, loss 0.579867.
Train: 2018-08-01T00:06:47.607942: step 2348, loss 0.544949.
Train: 2018-08-01T00:06:47.764156: step 2349, loss 0.562516.
Train: 2018-08-01T00:06:47.935979: step 2350, loss 0.615002.
Test: 2018-08-01T00:06:48.404625: step 2350, loss 0.547786.
Train: 2018-08-01T00:06:48.560808: step 2351, loss 0.562419.
Train: 2018-08-01T00:06:48.717023: step 2352, loss 0.615024.
Train: 2018-08-01T00:06:48.873235: step 2353, loss 0.527499.
Train: 2018-08-01T00:06:49.029474: step 2354, loss 0.544919.
Train: 2018-08-01T00:06:49.201283: step 2355, loss 0.544928.
Train: 2018-08-01T00:06:49.341909: step 2356, loss 0.614952.
Train: 2018-08-01T00:06:49.498120: step 2357, loss 0.492395.
Train: 2018-08-01T00:06:49.654334: step 2358, loss 0.492376.
Train: 2018-08-01T00:06:49.826137: step 2359, loss 0.544947.
Train: 2018-08-01T00:06:49.982381: step 2360, loss 0.562462.
Test: 2018-08-01T00:06:50.451021: step 2360, loss 0.547745.
Train: 2018-08-01T00:06:50.607205: step 2361, loss 0.632807.
Train: 2018-08-01T00:06:50.763419: step 2362, loss 0.562486.
Train: 2018-08-01T00:06:50.919662: step 2363, loss 0.650389.
Train: 2018-08-01T00:06:51.091496: step 2364, loss 0.474662.
Train: 2018-08-01T00:06:51.247679: step 2365, loss 0.544945.
Train: 2018-08-01T00:06:51.403893: step 2366, loss 0.492238.
Train: 2018-08-01T00:06:51.560106: step 2367, loss 0.597623.
Train: 2018-08-01T00:06:51.716350: step 2368, loss 0.562464.
Train: 2018-08-01T00:06:51.872533: step 2369, loss 0.597563.
Train: 2018-08-01T00:06:52.028746: step 2370, loss 0.562497.
Test: 2018-08-01T00:06:52.513007: step 2370, loss 0.547753.
Train: 2018-08-01T00:06:52.669221: step 2371, loss 0.457115.
Train: 2018-08-01T00:06:52.825460: step 2372, loss 0.544869.
Train: 2018-08-01T00:06:52.981679: step 2373, loss 0.544863.
Train: 2018-08-01T00:06:53.137861: step 2374, loss 0.562481.
Train: 2018-08-01T00:06:53.294106: step 2375, loss 0.491955.
Train: 2018-08-01T00:06:53.450290: step 2376, loss 0.544833.
Train: 2018-08-01T00:06:53.622127: step 2377, loss 0.562474.
Train: 2018-08-01T00:06:53.799456: step 2378, loss 0.562555.
Train: 2018-08-01T00:06:53.958673: step 2379, loss 0.491567.
Train: 2018-08-01T00:06:54.111888: step 2380, loss 0.598161.
Test: 2018-08-01T00:06:54.581530: step 2380, loss 0.54765.
Train: 2018-08-01T00:06:54.737745: step 2381, loss 0.580344.
Train: 2018-08-01T00:06:54.909609: step 2382, loss 0.616035.
Train: 2018-08-01T00:06:55.065824: step 2383, loss 0.509145.
Train: 2018-08-01T00:06:55.222036: step 2384, loss 0.473499.
Train: 2018-08-01T00:06:55.378253: step 2385, loss 0.473371.
Train: 2018-08-01T00:06:55.534463: step 2386, loss 0.5626.
Train: 2018-08-01T00:06:55.690646: step 2387, loss 0.670141.
Train: 2018-08-01T00:06:55.846860: step 2388, loss 0.490936.
Train: 2018-08-01T00:06:56.003073: step 2389, loss 0.54469.
Train: 2018-08-01T00:06:56.159311: step 2390, loss 0.616527.
Test: 2018-08-01T00:06:56.627926: step 2390, loss 0.547606.
Train: 2018-08-01T00:06:56.784171: step 2391, loss 0.544731.
Train: 2018-08-01T00:06:56.956005: step 2392, loss 0.562611.
Train: 2018-08-01T00:06:57.112218: step 2393, loss 0.598596.
Train: 2018-08-01T00:06:57.268426: step 2394, loss 0.56263.
Train: 2018-08-01T00:06:57.424647: step 2395, loss 0.490914.
Train: 2018-08-01T00:06:57.580831: step 2396, loss 0.59853.
Train: 2018-08-01T00:06:57.752663: step 2397, loss 0.580592.
Train: 2018-08-01T00:06:57.899909: step 2398, loss 0.419287.
Train: 2018-08-01T00:06:58.059553: step 2399, loss 0.598496.
Train: 2018-08-01T00:06:58.216161: step 2400, loss 0.56266.
Test: 2018-08-01T00:06:58.689478: step 2400, loss 0.547611.
Train: 2018-08-01T00:06:59.361193: step 2401, loss 0.580574.
Train: 2018-08-01T00:06:59.532997: step 2402, loss 0.455016.
Train: 2018-08-01T00:06:59.689210: step 2403, loss 0.616514.
Train: 2018-08-01T00:06:59.845424: step 2404, loss 0.436954.
Train: 2018-08-01T00:07:00.017260: step 2405, loss 0.634603.
Train: 2018-08-01T00:07:00.173502: step 2406, loss 0.54465.
Train: 2018-08-01T00:07:00.314094: step 2407, loss 0.652606.
Train: 2018-08-01T00:07:00.470308: step 2408, loss 0.466782.
Train: 2018-08-01T00:07:00.626490: step 2409, loss 0.49071.
Train: 2018-08-01T00:07:00.798327: step 2410, loss 0.580674.
Test: 2018-08-01T00:07:01.282586: step 2410, loss 0.547595.
Train: 2018-08-01T00:07:01.438801: step 2411, loss 0.706758.
Train: 2018-08-01T00:07:01.610673: step 2412, loss 0.544658.
Train: 2018-08-01T00:07:01.766878: step 2413, loss 0.526713.
Train: 2018-08-01T00:07:01.923062: step 2414, loss 0.52672.
Train: 2018-08-01T00:07:02.079277: step 2415, loss 0.508805.
Train: 2018-08-01T00:07:02.235490: step 2416, loss 0.688228.
Train: 2018-08-01T00:07:02.391732: step 2417, loss 0.526807.
Train: 2018-08-01T00:07:02.547946: step 2418, loss 0.52688.
Train: 2018-08-01T00:07:02.704153: step 2419, loss 0.491086.
Train: 2018-08-01T00:07:02.860342: step 2420, loss 0.580489.
Test: 2018-08-01T00:07:03.344603: step 2420, loss 0.547627.
Train: 2018-08-01T00:07:03.500818: step 2421, loss 0.509025.
Train: 2018-08-01T00:07:03.657061: step 2422, loss 0.598443.
Train: 2018-08-01T00:07:03.813244: step 2423, loss 0.455358.
Train: 2018-08-01T00:07:03.985103: step 2424, loss 0.562602.
Train: 2018-08-01T00:07:04.141294: step 2425, loss 0.526802.
Train: 2018-08-01T00:07:04.297531: step 2426, loss 0.616431.
Train: 2018-08-01T00:07:04.453746: step 2427, loss 0.59852.
Train: 2018-08-01T00:07:04.609957: step 2428, loss 0.544698.
Train: 2018-08-01T00:07:04.781778: step 2429, loss 0.562645.
Train: 2018-08-01T00:07:04.937980: step 2430, loss 0.652196.
Test: 2018-08-01T00:07:05.422242: step 2430, loss 0.547627.
Train: 2018-08-01T00:07:05.578486: step 2431, loss 0.562597.
Train: 2018-08-01T00:07:05.734700: step 2432, loss 0.633969.
Train: 2018-08-01T00:07:05.890883: step 2433, loss 0.633754.
Train: 2018-08-01T00:07:06.047127: step 2434, loss 0.52706.
Train: 2018-08-01T00:07:06.203311: step 2435, loss 0.527147.
Train: 2018-08-01T00:07:06.359523: step 2436, loss 0.562491.
Train: 2018-08-01T00:07:06.515767: step 2437, loss 0.56247.
Train: 2018-08-01T00:07:06.671980: step 2438, loss 0.457011.
Train: 2018-08-01T00:07:06.843814: step 2439, loss 0.562463.
Train: 2018-08-01T00:07:07.000031: step 2440, loss 0.56247.
Test: 2018-08-01T00:07:07.468639: step 2440, loss 0.547758.
Train: 2018-08-01T00:07:07.624852: step 2441, loss 0.597581.
Train: 2018-08-01T00:07:07.796716: step 2442, loss 0.650164.
Train: 2018-08-01T00:07:07.952932: step 2443, loss 0.614956.
Train: 2018-08-01T00:07:08.109144: step 2444, loss 0.597342.
Train: 2018-08-01T00:07:08.265328: step 2445, loss 0.527618.
Train: 2018-08-01T00:07:08.421571: step 2446, loss 0.666585.
Train: 2018-08-01T00:07:08.577784: step 2447, loss 0.510511.
Train: 2018-08-01T00:07:08.749588: step 2448, loss 0.562403.
Train: 2018-08-01T00:07:08.905832: step 2449, loss 0.596829.
Train: 2018-08-01T00:07:09.077661: step 2450, loss 0.579569.
Test: 2018-08-01T00:07:09.561928: step 2450, loss 0.548059.
Train: 2018-08-01T00:07:09.718112: step 2451, loss 0.52815.
Train: 2018-08-01T00:07:09.889981: step 2452, loss 0.494027.
Train: 2018-08-01T00:07:10.046186: step 2453, loss 0.545318.
Train: 2018-08-01T00:07:10.202399: step 2454, loss 0.664869.
Train: 2018-08-01T00:07:10.358625: step 2455, loss 0.494214.
Train: 2018-08-01T00:07:10.530452: step 2456, loss 0.443138.
Train: 2018-08-01T00:07:10.686665: step 2457, loss 0.562403.
Train: 2018-08-01T00:07:10.842848: step 2458, loss 0.528239.
Train: 2018-08-01T00:07:10.999087: step 2459, loss 0.647942.
Train: 2018-08-01T00:07:11.155275: step 2460, loss 0.545288.
Test: 2018-08-01T00:07:11.639571: step 2460, loss 0.548065.
Train: 2018-08-01T00:07:11.795750: step 2461, loss 0.511043.
Train: 2018-08-01T00:07:11.951994: step 2462, loss 0.510983.
Train: 2018-08-01T00:07:12.108207: step 2463, loss 0.51089.
Train: 2018-08-01T00:07:12.264420: step 2464, loss 0.631242.
Train: 2018-08-01T00:07:12.420605: step 2465, loss 0.476252.
Train: 2018-08-01T00:07:12.576817: step 2466, loss 0.406986.
Train: 2018-08-01T00:07:12.733030: step 2467, loss 0.562412.
Train: 2018-08-01T00:07:12.904895: step 2468, loss 0.475382.
Train: 2018-08-01T00:07:13.061080: step 2469, loss 0.544953.
Train: 2018-08-01T00:07:13.217292: step 2470, loss 0.492207.
Test: 2018-08-01T00:07:13.685962: step 2470, loss 0.547713.
Train: 2018-08-01T00:07:13.857768: step 2471, loss 0.456605.
Train: 2018-08-01T00:07:14.014015: step 2472, loss 0.633524.
Train: 2018-08-01T00:07:14.170218: step 2473, loss 0.526929.
Train: 2018-08-01T00:07:14.326438: step 2474, loss 0.580492.
Train: 2018-08-01T00:07:14.482651: step 2475, loss 0.61647.
Train: 2018-08-01T00:07:14.638834: step 2476, loss 0.616597.
Train: 2018-08-01T00:07:14.795048: step 2477, loss 0.418702.
Train: 2018-08-01T00:07:14.966913: step 2478, loss 0.49053.
Train: 2018-08-01T00:07:15.123096: step 2479, loss 0.562736.
Train: 2018-08-01T00:07:15.279340: step 2480, loss 0.671642.
Test: 2018-08-01T00:07:15.763600: step 2480, loss 0.547575.
Train: 2018-08-01T00:07:15.935437: step 2481, loss 0.435672.
Train: 2018-08-01T00:07:16.091644: step 2482, loss 0.617403.
Train: 2018-08-01T00:07:16.247858: step 2483, loss 0.526393.
Train: 2018-08-01T00:07:16.404076: step 2484, loss 0.544605.
Train: 2018-08-01T00:07:16.575911: step 2485, loss 0.617636.
Train: 2018-08-01T00:07:16.732124: step 2486, loss 0.544601.
Train: 2018-08-01T00:07:16.888342: step 2487, loss 0.581127.
Train: 2018-08-01T00:07:17.044521: step 2488, loss 0.471573.
Train: 2018-08-01T00:07:17.200734: step 2489, loss 0.526329.
Train: 2018-08-01T00:07:17.372571: step 2490, loss 0.709178.
Test: 2018-08-01T00:07:17.841239: step 2490, loss 0.547571.
Train: 2018-08-01T00:07:18.013079: step 2491, loss 0.453284.
Train: 2018-08-01T00:07:18.169291: step 2492, loss 0.508071.
Train: 2018-08-01T00:07:18.325501: step 2493, loss 0.544599.
Train: 2018-08-01T00:07:18.481709: step 2494, loss 0.636024.
Train: 2018-08-01T00:07:18.637927: step 2495, loss 0.599419.
Train: 2018-08-01T00:07:18.794142: step 2496, loss 0.617605.
Train: 2018-08-01T00:07:18.950326: step 2497, loss 0.54461.
Train: 2018-08-01T00:07:19.122190: step 2498, loss 0.508256.
Train: 2018-08-01T00:07:19.278373: step 2499, loss 0.544622.
Train: 2018-08-01T00:07:19.434586: step 2500, loss 0.490194.
Test: 2018-08-01T00:07:19.918878: step 2500, loss 0.547576.
Train: 2018-08-01T00:07:20.606217: step 2501, loss 0.580911.
Train: 2018-08-01T00:07:20.778052: step 2502, loss 0.599031.
Train: 2018-08-01T00:07:20.934266: step 2503, loss 0.598977.
Train: 2018-08-01T00:07:21.090448: step 2504, loss 0.526556.
Train: 2018-08-01T00:07:21.246692: step 2505, loss 0.526584.
Train: 2018-08-01T00:07:21.402905: step 2506, loss 0.526601.
Train: 2018-08-01T00:07:21.559120: step 2507, loss 0.616835.
Train: 2018-08-01T00:07:21.730948: step 2508, loss 0.562685.
Train: 2018-08-01T00:07:21.887161: step 2509, loss 0.580672.
Train: 2018-08-01T00:07:22.043381: step 2510, loss 0.670501.
Test: 2018-08-01T00:07:22.527612: step 2510, loss 0.547615.
Train: 2018-08-01T00:07:22.683850: step 2511, loss 0.652228.
Train: 2018-08-01T00:07:22.840069: step 2512, loss 0.59828.
Train: 2018-08-01T00:07:22.996285: step 2513, loss 0.473678.
Train: 2018-08-01T00:07:23.152466: step 2514, loss 0.544797.
Train: 2018-08-01T00:07:23.308710: step 2515, loss 0.597871.
Train: 2018-08-01T00:07:23.464917: step 2516, loss 0.650664.
Train: 2018-08-01T00:07:23.621106: step 2517, loss 0.685449.
Train: 2018-08-01T00:07:23.792942: step 2518, loss 0.562438.
Train: 2018-08-01T00:07:23.949153: step 2519, loss 0.545026.
Train: 2018-08-01T00:07:24.105397: step 2520, loss 0.545086.
Test: 2018-08-01T00:07:24.589659: step 2520, loss 0.547947.
Train: 2018-08-01T00:07:24.745872: step 2521, loss 0.579666.
Train: 2018-08-01T00:07:24.902087: step 2522, loss 0.493585.
Train: 2018-08-01T00:07:25.058300: step 2523, loss 0.613901.
Train: 2018-08-01T00:07:25.230135: step 2524, loss 0.511033.
Train: 2018-08-01T00:07:25.386347: step 2525, loss 0.579494.
Train: 2018-08-01T00:07:25.542561: step 2526, loss 0.545337.
Train: 2018-08-01T00:07:25.698775: step 2527, loss 0.613534.
Train: 2018-08-01T00:07:25.854959: step 2528, loss 0.579418.
Train: 2018-08-01T00:07:26.011172: step 2529, loss 0.562411.
Train: 2018-08-01T00:07:26.167415: step 2530, loss 0.613264.
Test: 2018-08-01T00:07:26.651645: step 2530, loss 0.548261.
Train: 2018-08-01T00:07:26.823495: step 2531, loss 0.511689.
Train: 2018-08-01T00:07:26.979694: step 2532, loss 0.477974.
Train: 2018-08-01T00:07:27.135909: step 2533, loss 0.545531.
Train: 2018-08-01T00:07:27.292147: step 2534, loss 0.54552.
Train: 2018-08-01T00:07:27.448334: step 2535, loss 0.545504.
Train: 2018-08-01T00:07:27.604580: step 2536, loss 0.680955.
Train: 2018-08-01T00:07:27.760791: step 2537, loss 0.528581.
Train: 2018-08-01T00:07:27.932626: step 2538, loss 0.596253.
Train: 2018-08-01T00:07:28.088841: step 2539, loss 0.494803.
Train: 2018-08-01T00:07:28.245053: step 2540, loss 0.460941.
Test: 2018-08-01T00:07:28.729315: step 2540, loss 0.548223.
Train: 2018-08-01T00:07:28.885499: step 2541, loss 0.596311.
Train: 2018-08-01T00:07:29.041713: step 2542, loss 0.596354.
Train: 2018-08-01T00:07:29.213577: step 2543, loss 0.56241.
Train: 2018-08-01T00:07:29.369792: step 2544, loss 0.511421.
Train: 2018-08-01T00:07:29.525974: step 2545, loss 0.511345.
Train: 2018-08-01T00:07:29.682217: step 2546, loss 0.596514.
Train: 2018-08-01T00:07:29.838430: step 2547, loss 0.562401.
Train: 2018-08-01T00:07:30.010264: step 2548, loss 0.476895.
Train: 2018-08-01T00:07:30.166479: step 2549, loss 0.528114.
Train: 2018-08-01T00:07:30.322661: step 2550, loss 0.476457.
Test: 2018-08-01T00:07:30.806923: step 2550, loss 0.547956.
Train: 2018-08-01T00:07:30.963168: step 2551, loss 0.527899.
Train: 2018-08-01T00:07:31.119350: step 2552, loss 0.475824.
Train: 2018-08-01T00:07:31.275590: step 2553, loss 0.51023.
Train: 2018-08-01T00:07:31.431807: step 2554, loss 0.544957.
Train: 2018-08-01T00:07:31.603642: step 2555, loss 0.667825.
Train: 2018-08-01T00:07:31.759855: step 2556, loss 0.562475.
Train: 2018-08-01T00:07:31.916039: step 2557, loss 0.580131.
Train: 2018-08-01T00:07:32.072288: step 2558, loss 0.544829.
Train: 2018-08-01T00:07:32.228496: step 2559, loss 0.562511.
Train: 2018-08-01T00:07:32.384714: step 2560, loss 0.509355.
Test: 2018-08-01T00:07:32.868939: step 2560, loss 0.547668.
Train: 2018-08-01T00:07:33.025188: step 2561, loss 0.580289.
Train: 2018-08-01T00:07:33.181368: step 2562, loss 0.598099.
Train: 2018-08-01T00:07:33.337581: step 2563, loss 0.669268.
Train: 2018-08-01T00:07:33.509415: step 2564, loss 0.633607.
Train: 2018-08-01T00:07:33.665653: step 2565, loss 0.562524.
Train: 2018-08-01T00:07:33.821872: step 2566, loss 0.597897.
Train: 2018-08-01T00:07:33.978085: step 2567, loss 0.580143.
Train: 2018-08-01T00:07:34.134269: step 2568, loss 0.527262.
Train: 2018-08-01T00:07:34.290482: step 2569, loss 0.544891.
Train: 2018-08-01T00:07:34.462318: step 2570, loss 0.615102.
Test: 2018-08-01T00:07:34.930988: step 2570, loss 0.547784.
Train: 2018-08-01T00:07:35.087202: step 2571, loss 0.737546.
Train: 2018-08-01T00:07:35.259031: step 2572, loss 0.597289.
Train: 2018-08-01T00:07:35.415250: step 2573, loss 0.545063.
Train: 2018-08-01T00:07:35.571432: step 2574, loss 0.614247.
Train: 2018-08-01T00:07:35.727671: step 2575, loss 0.545194.
Train: 2018-08-01T00:07:35.883859: step 2576, loss 0.562399.
Train: 2018-08-01T00:07:36.040073: step 2577, loss 0.613651.
Train: 2018-08-01T00:07:36.211937: step 2578, loss 0.613462.
Train: 2018-08-01T00:07:36.383767: step 2579, loss 0.494624.
Train: 2018-08-01T00:07:36.539980: step 2580, loss 0.61313.
Test: 2018-08-01T00:07:37.024274: step 2580, loss 0.548326.
Train: 2018-08-01T00:07:37.180461: step 2581, loss 0.461341.
Train: 2018-08-01T00:07:37.336674: step 2582, loss 0.596097.
Train: 2018-08-01T00:07:37.492858: step 2583, loss 0.612853.
Train: 2018-08-01T00:07:37.664725: step 2584, loss 0.579224.
Train: 2018-08-01T00:07:37.820936: step 2585, loss 0.46208.
Train: 2018-08-01T00:07:37.977150: step 2586, loss 0.679562.
Train: 2018-08-01T00:07:38.133362: step 2587, loss 0.529091.
Train: 2018-08-01T00:07:38.289571: step 2588, loss 0.612516.
Train: 2018-08-01T00:07:38.445760: step 2589, loss 0.562499.
Train: 2018-08-01T00:07:38.601972: step 2590, loss 0.645625.
Test: 2018-08-01T00:07:39.086265: step 2590, loss 0.548641.
Train: 2018-08-01T00:07:39.242476: step 2591, loss 0.562526.
Train: 2018-08-01T00:07:39.398691: step 2592, loss 0.562543.
Train: 2018-08-01T00:07:39.554905: step 2593, loss 0.579073.
Train: 2018-08-01T00:07:39.711089: step 2594, loss 0.562572.
Train: 2018-08-01T00:07:39.867302: step 2595, loss 0.513196.
Train: 2018-08-01T00:07:40.039136: step 2596, loss 0.546131.
Train: 2018-08-01T00:07:40.195349: step 2597, loss 0.414465.
Train: 2018-08-01T00:07:40.367212: step 2598, loss 0.562565.
Train: 2018-08-01T00:07:40.523429: step 2599, loss 0.562545.
Train: 2018-08-01T00:07:40.679642: step 2600, loss 0.628849.
Test: 2018-08-01T00:07:41.148282: step 2600, loss 0.548618.
Train: 2018-08-01T00:07:41.898106: step 2601, loss 0.628918.
Train: 2018-08-01T00:07:42.069942: step 2602, loss 0.579119.
Train: 2018-08-01T00:07:42.226154: step 2603, loss 0.59572.
Train: 2018-08-01T00:07:42.382367: step 2604, loss 0.579114.
Train: 2018-08-01T00:07:42.538582: step 2605, loss 0.545941.
Train: 2018-08-01T00:07:42.694765: step 2606, loss 0.562526.
Train: 2018-08-01T00:07:42.851008: step 2607, loss 0.545944.
Train: 2018-08-01T00:07:43.007192: step 2608, loss 0.628877.
Train: 2018-08-01T00:07:43.163441: step 2609, loss 0.579106.
Train: 2018-08-01T00:07:43.319619: step 2610, loss 0.562532.
Test: 2018-08-01T00:07:43.803910: step 2610, loss 0.54867.
Train: 2018-08-01T00:07:43.960123: step 2611, loss 0.595655.
Train: 2018-08-01T00:07:44.116337: step 2612, loss 0.628724.
Train: 2018-08-01T00:07:44.272544: step 2613, loss 0.529522.
Train: 2018-08-01T00:07:44.444379: step 2614, loss 0.562564.
Train: 2018-08-01T00:07:44.584977: step 2615, loss 0.480109.
Train: 2018-08-01T00:07:44.741191: step 2616, loss 0.529549.
Train: 2018-08-01T00:07:44.912994: step 2617, loss 0.496427.
Train: 2018-08-01T00:07:45.084854: step 2618, loss 0.56253.
Train: 2018-08-01T00:07:45.241044: step 2619, loss 0.512679.
Train: 2018-08-01T00:07:45.397257: step 2620, loss 0.529169.
Test: 2018-08-01T00:07:45.881552: step 2620, loss 0.548474.
Train: 2018-08-01T00:07:46.037756: step 2621, loss 0.562473.
Train: 2018-08-01T00:07:46.209602: step 2622, loss 0.595995.
Train: 2018-08-01T00:07:46.365804: step 2623, loss 0.461593.
Train: 2018-08-01T00:07:46.521994: step 2624, loss 0.478073.
Train: 2018-08-01T00:07:46.678206: step 2625, loss 0.528513.
Train: 2018-08-01T00:07:46.834450: step 2626, loss 0.562404.
Train: 2018-08-01T00:07:46.990666: step 2627, loss 0.630819.
Train: 2018-08-01T00:07:47.146878: step 2628, loss 0.545245.
Train: 2018-08-01T00:07:47.303092: step 2629, loss 0.579601.
Train: 2018-08-01T00:07:47.474928: step 2630, loss 0.562401.
Test: 2018-08-01T00:07:47.959157: step 2630, loss 0.547938.
Train: 2018-08-01T00:07:48.115404: step 2631, loss 0.545128.
Train: 2018-08-01T00:07:48.287205: step 2632, loss 0.631649.
Train: 2018-08-01T00:07:48.443448: step 2633, loss 0.510437.
Train: 2018-08-01T00:07:48.615254: step 2634, loss 0.545063.
Train: 2018-08-01T00:07:48.771497: step 2635, loss 0.492917.
Train: 2018-08-01T00:07:48.927705: step 2636, loss 0.510178.
Train: 2018-08-01T00:07:49.099544: step 2637, loss 0.562434.
Train: 2018-08-01T00:07:49.255727: step 2638, loss 0.579952.
Train: 2018-08-01T00:07:49.411966: step 2639, loss 0.597534.
Train: 2018-08-01T00:07:49.568179: step 2640, loss 0.615138.
Test: 2018-08-01T00:07:50.052416: step 2640, loss 0.547755.
Train: 2018-08-01T00:07:50.208660: step 2641, loss 0.509774.
Train: 2018-08-01T00:07:50.364843: step 2642, loss 0.509735.
Train: 2018-08-01T00:07:50.521088: step 2643, loss 0.580076.
Train: 2018-08-01T00:07:50.677271: step 2644, loss 0.703428.
Train: 2018-08-01T00:07:50.833516: step 2645, loss 0.668051.
Train: 2018-08-01T00:07:50.989727: step 2646, loss 0.667751.
Train: 2018-08-01T00:07:51.161531: step 2647, loss 0.632352.
Train: 2018-08-01T00:07:51.317775: step 2648, loss 0.510231.
Train: 2018-08-01T00:07:51.473958: step 2649, loss 0.59708.
Train: 2018-08-01T00:07:51.630202: step 2650, loss 0.527863.
Test: 2018-08-01T00:07:52.114444: step 2650, loss 0.54798.
Train: 2018-08-01T00:07:52.270647: step 2651, loss 0.5624.
Train: 2018-08-01T00:07:52.426860: step 2652, loss 0.528048.
Train: 2018-08-01T00:07:52.567452: step 2653, loss 0.63097.
Train: 2018-08-01T00:07:52.723666: step 2654, loss 0.494012.
Train: 2018-08-01T00:07:52.879879: step 2655, loss 0.44289.
Train: 2018-08-01T00:07:53.036092: step 2656, loss 0.511152.
Train: 2018-08-01T00:07:53.192306: step 2657, loss 0.579504.
Train: 2018-08-01T00:07:53.364170: step 2658, loss 0.579519.
Train: 2018-08-01T00:07:53.535975: step 2659, loss 0.596659.
Train: 2018-08-01T00:07:53.692190: step 2660, loss 0.613789.
Test: 2018-08-01T00:07:54.176481: step 2660, loss 0.548065.
Train: 2018-08-01T00:07:54.332694: step 2661, loss 0.579516.
Train: 2018-08-01T00:07:54.488878: step 2662, loss 0.665008.
Train: 2018-08-01T00:07:54.645090: step 2663, loss 0.52828.
Train: 2018-08-01T00:07:54.801304: step 2664, loss 0.54537.
Train: 2018-08-01T00:07:54.957517: step 2665, loss 0.562406.
Train: 2018-08-01T00:07:55.113756: step 2666, loss 0.562408.
Train: 2018-08-01T00:07:55.269975: step 2667, loss 0.528448.
Train: 2018-08-01T00:07:55.435621: step 2668, loss 0.613341.
Train: 2018-08-01T00:07:55.591864: step 2669, loss 0.562413.
Train: 2018-08-01T00:07:55.748048: step 2670, loss 0.494629.
Test: 2018-08-01T00:07:56.232308: step 2670, loss 0.548219.
Train: 2018-08-01T00:07:56.404145: step 2671, loss 0.545462.
Train: 2018-08-01T00:07:56.544738: step 2672, loss 0.630262.
Train: 2018-08-01T00:07:56.700950: step 2673, loss 0.630232.
Train: 2018-08-01T00:07:56.872818: step 2674, loss 0.528556.
Train: 2018-08-01T00:07:57.028997: step 2675, loss 0.545501.
Train: 2018-08-01T00:07:57.185212: step 2676, loss 0.528595.
Train: 2018-08-01T00:07:57.357079: step 2677, loss 0.545502.
Train: 2018-08-01T00:07:57.513289: step 2678, loss 0.528564.
Train: 2018-08-01T00:07:57.669506: step 2679, loss 0.647142.
Train: 2018-08-01T00:07:57.825716: step 2680, loss 0.596296.
Test: 2018-08-01T00:07:58.309948: step 2680, loss 0.548243.
Train: 2018-08-01T00:07:58.466186: step 2681, loss 0.663983.
Train: 2018-08-01T00:07:58.622400: step 2682, loss 0.545535.
Train: 2018-08-01T00:07:58.778590: step 2683, loss 0.579294.
Train: 2018-08-01T00:07:58.934832: step 2684, loss 0.596105.
Train: 2018-08-01T00:07:59.091045: step 2685, loss 0.495247.
Train: 2018-08-01T00:07:59.247259: step 2686, loss 0.646393.
Train: 2018-08-01T00:07:59.419096: step 2687, loss 0.478671.
Train: 2018-08-01T00:07:59.575308: step 2688, loss 0.61272.
Train: 2018-08-01T00:07:59.731520: step 2689, loss 0.512254.
Train: 2018-08-01T00:07:59.903325: step 2690, loss 0.579203.
Test: 2018-08-01T00:08:00.371994: step 2690, loss 0.548453.
Train: 2018-08-01T00:08:00.528202: step 2691, loss 0.545732.
Train: 2018-08-01T00:08:00.684422: step 2692, loss 0.662896.
Train: 2018-08-01T00:08:00.840606: step 2693, loss 0.512323.
Train: 2018-08-01T00:08:00.996818: step 2694, loss 0.428782.
Train: 2018-08-01T00:08:01.153031: step 2695, loss 0.528976.
Train: 2018-08-01T00:08:01.309245: step 2696, loss 0.495319.
Train: 2018-08-01T00:08:01.465459: step 2697, loss 0.528762.
Train: 2018-08-01T00:08:01.621697: step 2698, loss 0.494839.
Train: 2018-08-01T00:08:01.777886: step 2699, loss 0.562412.
Train: 2018-08-01T00:08:01.934129: step 2700, loss 0.494273.
Test: 2018-08-01T00:08:02.418393: step 2700, loss 0.548072.
Train: 2018-08-01T00:08:03.168203: step 2701, loss 0.52818.
Train: 2018-08-01T00:08:03.324429: step 2702, loss 0.562398.
Train: 2018-08-01T00:08:03.496258: step 2703, loss 0.614173.
Train: 2018-08-01T00:08:03.652477: step 2704, loss 0.614326.
Train: 2018-08-01T00:08:03.808686: step 2705, loss 0.579748.
Train: 2018-08-01T00:08:03.980521: step 2706, loss 0.562414.
Train: 2018-08-01T00:08:04.136709: step 2707, loss 0.545037.
Train: 2018-08-01T00:08:04.292955: step 2708, loss 0.632025.
Train: 2018-08-01T00:08:04.464756: step 2709, loss 0.580983.
Train: 2018-08-01T00:08:04.620994: step 2710, loss 0.527626.
Test: 2018-08-01T00:08:05.105231: step 2710, loss 0.54785.
Train: 2018-08-01T00:08:05.261475: step 2711, loss 0.54502.
Train: 2018-08-01T00:08:05.417659: step 2712, loss 0.562422.
Train: 2018-08-01T00:08:05.573902: step 2713, loss 0.54501.
Train: 2018-08-01T00:08:05.730085: step 2714, loss 0.405633.
Train: 2018-08-01T00:08:05.886329: step 2715, loss 0.59737.
Train: 2018-08-01T00:08:06.042545: step 2716, loss 0.649941.
Train: 2018-08-01T00:08:06.214346: step 2717, loss 0.614959.
Train: 2018-08-01T00:08:06.370560: step 2718, loss 0.527451.
Train: 2018-08-01T00:08:06.526799: step 2719, loss 0.544947.
Train: 2018-08-01T00:08:06.683012: step 2720, loss 0.544945.
Test: 2018-08-01T00:08:07.167278: step 2720, loss 0.547787.
Train: 2018-08-01T00:08:07.323462: step 2721, loss 0.509936.
Train: 2018-08-01T00:08:07.479711: step 2722, loss 0.544929.
Train: 2018-08-01T00:08:07.651511: step 2723, loss 0.632606.
Train: 2018-08-01T00:08:07.807723: step 2724, loss 0.492309.
Train: 2018-08-01T00:08:07.979558: step 2725, loss 0.509806.
Train: 2018-08-01T00:08:08.135772: step 2726, loss 0.54489.
Train: 2018-08-01T00:08:08.307609: step 2727, loss 0.720878.
Train: 2018-08-01T00:08:08.479442: step 2728, loss 0.562467.
Train: 2018-08-01T00:08:08.651277: step 2729, loss 0.527333.
Train: 2018-08-01T00:08:08.823138: step 2730, loss 0.562459.
Test: 2018-08-01T00:08:09.307402: step 2730, loss 0.547763.
Train: 2018-08-01T00:08:09.463596: step 2731, loss 0.404542.
Train: 2018-08-01T00:08:09.619801: step 2732, loss 0.544889.
Train: 2018-08-01T00:08:09.791640: step 2733, loss 0.49205.
Train: 2018-08-01T00:08:09.947878: step 2734, loss 0.686036.
Train: 2018-08-01T00:08:10.119687: step 2735, loss 0.474214.
Train: 2018-08-01T00:08:10.275897: step 2736, loss 0.63323.
Train: 2018-08-01T00:08:10.432126: step 2737, loss 0.474075.
Train: 2018-08-01T00:08:10.588348: step 2738, loss 0.544805.
Train: 2018-08-01T00:08:10.760158: step 2739, loss 0.544791.
Train: 2018-08-01T00:08:10.916371: step 2740, loss 0.491504.
Test: 2018-08-01T00:08:11.385041: step 2740, loss 0.547652.
Train: 2018-08-01T00:08:11.541258: step 2741, loss 0.509168.
Train: 2018-08-01T00:08:11.759953: step 2742, loss 0.580416.
Train: 2018-08-01T00:08:11.916170: step 2743, loss 0.580467.
Train: 2018-08-01T00:08:12.072351: step 2744, loss 0.54471.
Train: 2018-08-01T00:08:12.244187: step 2745, loss 0.5447.
Train: 2018-08-01T00:08:12.400424: step 2746, loss 0.472921.
Train: 2018-08-01T00:08:12.556642: step 2747, loss 0.544675.
Train: 2018-08-01T00:08:12.728471: step 2748, loss 0.544662.
Train: 2018-08-01T00:08:12.884690: step 2749, loss 0.50854.
Train: 2018-08-01T00:08:13.040873: step 2750, loss 0.562734.
Test: 2018-08-01T00:08:13.525135: step 2750, loss 0.547576.
Train: 2018-08-01T00:08:13.681379: step 2751, loss 0.599022.
Train: 2018-08-01T00:08:13.837564: step 2752, loss 0.562773.
Train: 2018-08-01T00:08:14.009422: step 2753, loss 0.599112.
Train: 2018-08-01T00:08:14.165644: step 2754, loss 0.453796.
Train: 2018-08-01T00:08:14.337475: step 2755, loss 0.58099.
Train: 2018-08-01T00:08:14.509280: step 2756, loss 0.599215.
Train: 2018-08-01T00:08:14.665531: step 2757, loss 0.562812.
Train: 2018-08-01T00:08:14.821736: step 2758, loss 0.453628.
Train: 2018-08-01T00:08:14.977944: step 2759, loss 0.526392.
Train: 2018-08-01T00:08:15.134157: step 2760, loss 0.690517.
Test: 2018-08-01T00:08:15.618424: step 2760, loss 0.54757.
Train: 2018-08-01T00:08:15.821503: step 2761, loss 0.599282.
Train: 2018-08-01T00:08:15.977719: step 2762, loss 0.45361.
Train: 2018-08-01T00:08:16.149521: step 2763, loss 0.508209.
Train: 2018-08-01T00:08:16.305737: step 2764, loss 0.489976.
Train: 2018-08-01T00:08:16.461977: step 2765, loss 0.508135.
Train: 2018-08-01T00:08:16.618196: step 2766, loss 0.672455.
Train: 2018-08-01T00:08:16.789997: step 2767, loss 0.508074.
Train: 2018-08-01T00:08:16.977452: step 2768, loss 0.434979.
Train: 2018-08-01T00:08:17.196152: step 2769, loss 0.507986.
Train: 2018-08-01T00:08:17.414852: step 2770, loss 0.709678.
Test: 2018-08-01T00:08:17.899110: step 2770, loss 0.547571.
Train: 2018-08-01T00:08:18.070973: step 2771, loss 0.544589.
Train: 2018-08-01T00:08:18.227161: step 2772, loss 0.581264.
Train: 2018-08-01T00:08:18.383372: step 2773, loss 0.59957.
Train: 2018-08-01T00:08:18.555208: step 2774, loss 0.544593.
Train: 2018-08-01T00:08:18.711421: step 2775, loss 0.59945.
Train: 2018-08-01T00:08:18.867664: step 2776, loss 0.471583.
Train: 2018-08-01T00:08:19.023848: step 2777, loss 0.635831.
Train: 2018-08-01T00:08:19.180060: step 2778, loss 0.544608.
Train: 2018-08-01T00:08:19.336273: step 2779, loss 0.50823.
Train: 2018-08-01T00:08:19.492488: step 2780, loss 0.617329.
Test: 2018-08-01T00:08:19.961159: step 2780, loss 0.547574.
Train: 2018-08-01T00:08:20.132993: step 2781, loss 0.562773.
Train: 2018-08-01T00:08:20.289177: step 2782, loss 0.490267.
Train: 2018-08-01T00:08:20.445390: step 2783, loss 0.635181.
Train: 2018-08-01T00:08:20.601633: step 2784, loss 0.598878.
Train: 2018-08-01T00:08:20.757846: step 2785, loss 0.652886.
Train: 2018-08-01T00:08:20.914029: step 2786, loss 0.454789.
Train: 2018-08-01T00:08:21.070279: step 2787, loss 0.49085.
Train: 2018-08-01T00:08:21.226487: step 2788, loss 0.688161.
Train: 2018-08-01T00:08:21.382671: step 2789, loss 0.669931.
Train: 2018-08-01T00:08:21.538883: step 2790, loss 0.526927.
Test: 2018-08-01T00:08:22.007554: step 2790, loss 0.547663.
Train: 2018-08-01T00:08:22.163770: step 2791, loss 0.633591.
Train: 2018-08-01T00:08:22.319980: step 2792, loss 0.562508.
Train: 2018-08-01T00:08:22.491785: step 2793, loss 0.562483.
Train: 2018-08-01T00:08:22.632409: step 2794, loss 0.509756.
Train: 2018-08-01T00:08:22.788623: step 2795, loss 0.632558.
Train: 2018-08-01T00:08:22.960425: step 2796, loss 0.597376.
Train: 2018-08-01T00:08:23.116669: step 2797, loss 0.562422.
Train: 2018-08-01T00:08:23.272883: step 2798, loss 0.510351.
Train: 2018-08-01T00:08:23.429065: step 2799, loss 0.562407.
Train: 2018-08-01T00:08:23.600925: step 2800, loss 0.545122.
Test: 2018-08-01T00:08:24.069570: step 2800, loss 0.547952.
Train: 2018-08-01T00:08:24.756880: step 2801, loss 0.631421.
Train: 2018-08-01T00:08:24.928744: step 2802, loss 0.63125.
Train: 2018-08-01T00:08:25.100580: step 2803, loss 0.682496.
Train: 2018-08-01T00:08:25.256793: step 2804, loss 0.613628.
Train: 2018-08-01T00:08:25.412976: step 2805, loss 0.494447.
Train: 2018-08-01T00:08:25.553600: step 2806, loss 0.630143.
Train: 2018-08-01T00:08:25.709812: step 2807, loss 0.613015.
Train: 2018-08-01T00:08:25.865996: step 2808, loss 0.545664.
Train: 2018-08-01T00:08:26.022238: step 2809, loss 0.478848.
Train: 2018-08-01T00:08:26.178446: step 2810, loss 0.579173.
Test: 2018-08-01T00:08:26.662683: step 2810, loss 0.548542.
Train: 2018-08-01T00:08:26.818896: step 2811, loss 0.545833.
Train: 2018-08-01T00:08:26.975110: step 2812, loss 0.545864.
Train: 2018-08-01T00:08:27.131354: step 2813, loss 0.529261.
Train: 2018-08-01T00:08:27.287570: step 2814, loss 0.662235.
Train: 2018-08-01T00:08:27.443781: step 2815, loss 0.595709.
Train: 2018-08-01T00:08:27.599964: step 2816, loss 0.545969.
Train: 2018-08-01T00:08:27.756177: step 2817, loss 0.579086.
Train: 2018-08-01T00:08:27.928042: step 2818, loss 0.595596.
Train: 2018-08-01T00:08:28.084249: step 2819, loss 0.463595.
Train: 2018-08-01T00:08:28.240469: step 2820, loss 0.645067.
Test: 2018-08-01T00:08:28.740330: step 2820, loss 0.548767.
Train: 2018-08-01T00:08:28.896569: step 2821, loss 0.5296.
Train: 2018-08-01T00:08:29.052775: step 2822, loss 0.49664.
Train: 2018-08-01T00:08:29.208992: step 2823, loss 0.628568.
Train: 2018-08-01T00:08:29.380798: step 2824, loss 0.595567.
Train: 2018-08-01T00:08:29.537035: step 2825, loss 0.529575.
Train: 2018-08-01T00:08:29.693224: step 2826, loss 0.628569.
Train: 2018-08-01T00:08:29.849437: step 2827, loss 0.463622.
Train: 2018-08-01T00:08:30.005676: step 2828, loss 0.628601.
Train: 2018-08-01T00:08:30.161888: step 2829, loss 0.479995.
Train: 2018-08-01T00:08:30.318102: step 2830, loss 0.661777.
Test: 2018-08-01T00:08:30.786750: step 2830, loss 0.548697.
Train: 2018-08-01T00:08:30.942961: step 2831, loss 0.579083.
Train: 2018-08-01T00:08:31.099175: step 2832, loss 0.562547.
Train: 2018-08-01T00:08:31.271009: step 2833, loss 0.512944.
Train: 2018-08-01T00:08:31.427223: step 2834, loss 0.512893.
Train: 2018-08-01T00:08:31.583436: step 2835, loss 0.529372.
Train: 2018-08-01T00:08:31.739650: step 2836, loss 0.446212.
Train: 2018-08-01T00:08:31.895863: step 2837, loss 0.679242.
Train: 2018-08-01T00:08:32.052047: step 2838, loss 0.562475.
Train: 2018-08-01T00:08:32.208284: step 2839, loss 0.646152.
Train: 2018-08-01T00:08:32.364473: step 2840, loss 0.579206.
Test: 2018-08-01T00:08:32.833139: step 2840, loss 0.548442.
Train: 2018-08-01T00:08:33.004979: step 2841, loss 0.579207.
Train: 2018-08-01T00:08:33.161195: step 2842, loss 0.562464.
Train: 2018-08-01T00:08:33.317376: step 2843, loss 0.52898.
Train: 2018-08-01T00:08:33.489240: step 2844, loss 0.595965.
Train: 2018-08-01T00:08:33.645456: step 2845, loss 0.512199.
Train: 2018-08-01T00:08:33.817283: step 2846, loss 0.663074.
Train: 2018-08-01T00:08:33.973472: step 2847, loss 0.663014.
Train: 2018-08-01T00:08:34.145334: step 2848, loss 0.411947.
Train: 2018-08-01T00:08:34.301549: step 2849, loss 0.562466.
Train: 2018-08-01T00:08:34.457757: step 2850, loss 0.662932.
Test: 2018-08-01T00:08:34.925768: step 2850, loss 0.548459.
Train: 2018-08-01T00:08:35.081982: step 2851, loss 0.495551.
Train: 2018-08-01T00:08:35.238196: step 2852, loss 0.662872.
Train: 2018-08-01T00:08:35.394409: step 2853, loss 0.512331.
Train: 2018-08-01T00:08:35.550647: step 2854, loss 0.612605.
Train: 2018-08-01T00:08:35.706861: step 2855, loss 0.445613.
Train: 2018-08-01T00:08:35.863075: step 2856, loss 0.562473.
Train: 2018-08-01T00:08:36.019293: step 2857, loss 0.679593.
Train: 2018-08-01T00:08:36.175502: step 2858, loss 0.529032.
Train: 2018-08-01T00:08:36.331720: step 2859, loss 0.529035.
Train: 2018-08-01T00:08:36.487927: step 2860, loss 0.646106.
Test: 2018-08-01T00:08:36.972194: step 2860, loss 0.548475.
Train: 2018-08-01T00:08:37.128408: step 2861, loss 0.495611.
Train: 2018-08-01T00:08:37.300215: step 2862, loss 0.56247.
Train: 2018-08-01T00:08:37.487670: step 2863, loss 0.579199.
Train: 2018-08-01T00:08:37.659537: step 2864, loss 0.595939.
Train: 2018-08-01T00:08:37.815718: step 2865, loss 0.528998.
Train: 2018-08-01T00:08:37.971931: step 2866, loss 0.646172.
Train: 2018-08-01T00:08:38.128144: step 2867, loss 0.612652.
Train: 2018-08-01T00:08:38.284358: step 2868, loss 0.595885.
Train: 2018-08-01T00:08:38.503056: step 2869, loss 0.645864.
Train: 2018-08-01T00:08:38.659269: step 2870, loss 0.562505.
Test: 2018-08-01T00:08:39.127940: step 2870, loss 0.54863.
Train: 2018-08-01T00:08:39.299775: step 2871, loss 0.595701.
Train: 2018-08-01T00:08:39.455988: step 2872, loss 0.529447.
Train: 2018-08-01T00:08:39.627823: step 2873, loss 0.579074.
Train: 2018-08-01T00:08:39.784041: step 2874, loss 0.529583.
Train: 2018-08-01T00:08:39.940250: step 2875, loss 0.513137.
Train: 2018-08-01T00:08:40.112085: step 2876, loss 0.595539.
Train: 2018-08-01T00:08:40.268298: step 2877, loss 0.644972.
Train: 2018-08-01T00:08:40.424482: step 2878, loss 0.54613.
Train: 2018-08-01T00:08:40.580726: step 2879, loss 0.513264.
Train: 2018-08-01T00:08:40.721311: step 2880, loss 0.529699.
Test: 2018-08-01T00:08:41.205548: step 2880, loss 0.548801.
Train: 2018-08-01T00:08:41.361763: step 2881, loss 0.677811.
Train: 2018-08-01T00:08:41.517976: step 2882, loss 0.595484.
Train: 2018-08-01T00:08:41.689840: step 2883, loss 0.496904.
Train: 2018-08-01T00:08:41.830433: step 2884, loss 0.52975.
Train: 2018-08-01T00:08:42.002267: step 2885, loss 0.611915.
Train: 2018-08-01T00:08:42.158450: step 2886, loss 0.529715.
Train: 2018-08-01T00:08:42.314689: step 2887, loss 0.611947.
Train: 2018-08-01T00:08:42.486499: step 2888, loss 0.562589.
Train: 2018-08-01T00:08:42.642736: step 2889, loss 0.529678.
Train: 2018-08-01T00:08:42.798960: step 2890, loss 0.529645.
Test: 2018-08-01T00:08:43.267596: step 2890, loss 0.548759.
Train: 2018-08-01T00:08:43.439400: step 2891, loss 0.546077.
Train: 2018-08-01T00:08:43.595613: step 2892, loss 0.74426.
Train: 2018-08-01T00:08:43.736205: step 2893, loss 0.496576.
Train: 2018-08-01T00:08:43.908073: step 2894, loss 0.628557.
Train: 2018-08-01T00:08:44.111121: step 2895, loss 0.54609.
Train: 2018-08-01T00:08:44.267361: step 2896, loss 0.628483.
Train: 2018-08-01T00:08:44.423579: step 2897, loss 0.546132.
Train: 2018-08-01T00:08:44.579788: step 2898, loss 0.579038.
Train: 2018-08-01T00:08:44.735973: step 2899, loss 0.546171.
Train: 2018-08-01T00:08:44.907839: step 2900, loss 0.529753.
Test: 2018-08-01T00:08:45.376448: step 2900, loss 0.54884.
Train: 2018-08-01T00:08:46.204378: step 2901, loss 0.611897.
Train: 2018-08-01T00:08:46.423079: step 2902, loss 0.496891.
Train: 2018-08-01T00:08:46.594913: step 2903, loss 0.595482.
Train: 2018-08-01T00:08:46.782392: step 2904, loss 0.595493.
Train: 2018-08-01T00:08:46.985445: step 2905, loss 0.496778.
Train: 2018-08-01T00:08:47.157283: step 2906, loss 0.546104.
Train: 2018-08-01T00:08:47.329145: step 2907, loss 0.49657.
Train: 2018-08-01T00:08:47.500973: step 2908, loss 0.579085.
Train: 2018-08-01T00:08:47.672784: step 2909, loss 0.496218.
Train: 2018-08-01T00:08:47.828997: step 2910, loss 0.529246.
Test: 2018-08-01T00:08:48.313288: step 2910, loss 0.54851.
Train: 2018-08-01T00:08:48.469497: step 2911, loss 0.545796.
Train: 2018-08-01T00:08:48.641307: step 2912, loss 0.528975.
Train: 2018-08-01T00:08:48.781900: step 2913, loss 0.461609.
Train: 2018-08-01T00:08:48.938143: step 2914, loss 0.494868.
Train: 2018-08-01T00:08:49.109948: step 2915, loss 0.579391.
Train: 2018-08-01T00:08:49.266162: step 2916, loss 0.613588.
Train: 2018-08-01T00:08:49.422404: step 2917, loss 0.459666.
Train: 2018-08-01T00:08:49.594239: step 2918, loss 0.493592.
Train: 2018-08-01T00:08:49.750422: step 2919, loss 0.562404.
Train: 2018-08-01T00:08:49.906669: step 2920, loss 0.475562.
Test: 2018-08-01T00:08:50.375276: step 2920, loss 0.54781.
Train: 2018-08-01T00:08:50.531490: step 2921, loss 0.440189.
Train: 2018-08-01T00:08:50.687703: step 2922, loss 0.527312.
Train: 2018-08-01T00:08:50.843947: step 2923, loss 0.509447.
Train: 2018-08-01T00:08:51.000131: step 2924, loss 0.544758.
Train: 2018-08-01T00:08:51.172000: step 2925, loss 0.580502.
Train: 2018-08-01T00:08:51.328178: step 2926, loss 0.526695.
Train: 2018-08-01T00:08:51.500013: step 2927, loss 0.580771.
Train: 2018-08-01T00:08:51.671878: step 2928, loss 0.435859.
Train: 2018-08-01T00:08:51.828091: step 2929, loss 0.617468.
Train: 2018-08-01T00:08:51.968653: step 2930, loss 0.489767.
Test: 2018-08-01T00:08:52.468566: step 2930, loss 0.547571.
Train: 2018-08-01T00:08:52.624779: step 2931, loss 0.599626.
Train: 2018-08-01T00:08:52.796584: step 2932, loss 0.452605.
Train: 2018-08-01T00:08:52.952830: step 2933, loss 0.655356.
Train: 2018-08-01T00:08:53.109041: step 2934, loss 0.507588.
Train: 2018-08-01T00:08:53.265250: step 2935, loss 0.618724.
Train: 2018-08-01T00:08:53.437084: step 2936, loss 0.618796.
Train: 2018-08-01T00:08:53.593302: step 2937, loss 0.526031.
Train: 2018-08-01T00:08:53.749517: step 2938, loss 0.544582.
Train: 2018-08-01T00:08:53.905699: step 2939, loss 0.581695.
Train: 2018-08-01T00:08:54.061912: step 2940, loss 0.655877.
Test: 2018-08-01T00:08:54.546173: step 2940, loss 0.547592.
Train: 2018-08-01T00:08:54.702420: step 2941, loss 0.507548.
Train: 2018-08-01T00:08:54.858631: step 2942, loss 0.563076.
Train: 2018-08-01T00:08:55.030466: step 2943, loss 0.470692.
Train: 2018-08-01T00:08:55.186679: step 2944, loss 0.489174.
Train: 2018-08-01T00:08:55.342888: step 2945, loss 0.544581.
Train: 2018-08-01T00:08:55.499107: step 2946, loss 0.544581.
Train: 2018-08-01T00:08:55.655290: step 2947, loss 0.489091.
Train: 2018-08-01T00:08:55.827148: step 2948, loss 0.526064.
Train: 2018-08-01T00:08:55.983337: step 2949, loss 0.544582.
Train: 2018-08-01T00:08:56.139581: step 2950, loss 0.544583.
Test: 2018-08-01T00:08:56.608221: step 2950, loss 0.547605.
Train: 2018-08-01T00:08:56.780027: step 2951, loss 0.618897.
Train: 2018-08-01T00:08:56.936270: step 2952, loss 0.581737.
Train: 2018-08-01T00:08:57.092483: step 2953, loss 0.563149.
Train: 2018-08-01T00:08:57.248697: step 2954, loss 0.451822.
Train: 2018-08-01T00:08:57.404910: step 2955, loss 0.711633.
Train: 2018-08-01T00:08:57.561123: step 2956, loss 0.60017.
Train: 2018-08-01T00:08:57.717336: step 2957, loss 0.618533.
Train: 2018-08-01T00:08:57.889141: step 2958, loss 0.581448.
Train: 2018-08-01T00:08:58.045355: step 2959, loss 0.544585.
Train: 2018-08-01T00:08:58.201568: step 2960, loss 0.54459.
Test: 2018-08-01T00:08:58.685860: step 2960, loss 0.547569.
Train: 2018-08-01T00:08:58.842043: step 2961, loss 0.52632.
Train: 2018-08-01T00:08:58.998289: step 2962, loss 0.453402.
Train: 2018-08-01T00:08:59.154500: step 2963, loss 0.635755.
Train: 2018-08-01T00:08:59.310684: step 2964, loss 0.653809.
Train: 2018-08-01T00:08:59.466927: step 2965, loss 0.544623.
Train: 2018-08-01T00:08:59.638762: step 2966, loss 0.598938.
Train: 2018-08-01T00:08:59.794946: step 2967, loss 0.544652.
Train: 2018-08-01T00:08:59.966781: step 2968, loss 0.634672.
Train: 2018-08-01T00:09:00.123024: step 2969, loss 0.526753.
Train: 2018-08-01T00:09:00.279239: step 2970, loss 0.508936.
Test: 2018-08-01T00:09:00.747878: step 2970, loss 0.547632.
Train: 2018-08-01T00:09:00.904090: step 2971, loss 0.616145.
Train: 2018-08-01T00:09:01.075895: step 2972, loss 0.437904.
Train: 2018-08-01T00:09:01.232139: step 2973, loss 0.580347.
Train: 2018-08-01T00:09:01.388352: step 2974, loss 0.651425.
Train: 2018-08-01T00:09:01.560158: step 2975, loss 0.509318.
Train: 2018-08-01T00:09:01.732016: step 2976, loss 0.597936.
Train: 2018-08-01T00:09:01.888230: step 2977, loss 0.580178.
Train: 2018-08-01T00:09:02.044452: step 2978, loss 0.527204.
Train: 2018-08-01T00:09:02.200662: step 2979, loss 0.527246.
Train: 2018-08-01T00:09:02.356875: step 2980, loss 0.615273.
Test: 2018-08-01T00:09:02.841107: step 2980, loss 0.547749.
Train: 2018-08-01T00:09:02.997320: step 2981, loss 0.474605.
Train: 2018-08-01T00:09:03.153565: step 2982, loss 0.562461.
Train: 2018-08-01T00:09:03.309747: step 2983, loss 0.580019.
Train: 2018-08-01T00:09:03.465990: step 2984, loss 0.720395.
Train: 2018-08-01T00:09:03.622205: step 2985, loss 0.544944.
Train: 2018-08-01T00:09:03.778420: step 2986, loss 0.562431.
Train: 2018-08-01T00:09:03.950253: step 2987, loss 0.492758.
Train: 2018-08-01T00:09:04.106466: step 2988, loss 0.597215.
Train: 2018-08-01T00:09:04.247029: step 2989, loss 0.510301.
Train: 2018-08-01T00:09:04.418862: step 2990, loss 0.597133.
Test: 2018-08-01T00:09:04.887532: step 2990, loss 0.54789.
Train: 2018-08-01T00:09:05.043742: step 2991, loss 0.614431.
Train: 2018-08-01T00:09:05.199930: step 2992, loss 0.475862.
Train: 2018-08-01T00:09:05.356143: step 2993, loss 0.597009.
Train: 2018-08-01T00:09:05.512357: step 2994, loss 0.631549.
Train: 2018-08-01T00:09:05.668599: step 2995, loss 0.545146.
Train: 2018-08-01T00:09:05.824784: step 2996, loss 0.683008.
Train: 2018-08-01T00:09:05.981028: step 2997, loss 0.648281.
Train: 2018-08-01T00:09:06.152862: step 2998, loss 0.733469.
Train: 2018-08-01T00:09:06.309075: step 2999, loss 0.511402.
Train: 2018-08-01T00:09:06.480879: step 3000, loss 0.545499.
Test: 2018-08-01T00:09:06.949520: step 3000, loss 0.548322.
Train: 2018-08-01T00:09:07.683753: step 3001, loss 0.545582.
Train: 2018-08-01T00:09:07.839970: step 3002, loss 0.596037.
Train: 2018-08-01T00:09:07.996181: step 3003, loss 0.462044.
Train: 2018-08-01T00:09:08.152393: step 3004, loss 0.595898.
Train: 2018-08-01T00:09:08.308577: step 3005, loss 0.512436.
Train: 2018-08-01T00:09:08.464820: step 3006, loss 0.579159.
Train: 2018-08-01T00:09:08.621034: step 3007, loss 0.595808.
Train: 2018-08-01T00:09:08.777217: step 3008, loss 0.595778.
Train: 2018-08-01T00:09:08.933455: step 3009, loss 0.662197.
Train: 2018-08-01T00:09:09.089668: step 3010, loss 0.597876.
Test: 2018-08-01T00:09:09.558283: step 3010, loss 0.548721.
Train: 2018-08-01T00:09:09.730149: step 3011, loss 0.529515.
Train: 2018-08-01T00:09:09.886331: step 3012, loss 0.645003.
Train: 2018-08-01T00:09:10.042545: step 3013, loss 0.562597.
Train: 2018-08-01T00:09:10.198789: step 3014, loss 0.497041.
Train: 2018-08-01T00:09:10.355008: step 3015, loss 0.595387.
Train: 2018-08-01T00:09:10.511216: step 3016, loss 0.529935.
Train: 2018-08-01T00:09:10.667429: step 3017, loss 0.480915.
Train: 2018-08-01T00:09:10.823638: step 3018, loss 0.546276.
Train: 2018-08-01T00:09:10.979861: step 3019, loss 0.464306.
Train: 2018-08-01T00:09:11.136070: step 3020, loss 0.628341.
Test: 2018-08-01T00:09:11.604709: step 3020, loss 0.548795.
Train: 2018-08-01T00:09:11.760919: step 3021, loss 0.628441.
Train: 2018-08-01T00:09:11.932758: step 3022, loss 0.513149.
Train: 2018-08-01T00:09:12.088972: step 3023, loss 0.562563.
Train: 2018-08-01T00:09:12.245185: step 3024, loss 0.595603.
Train: 2018-08-01T00:09:12.401394: step 3025, loss 0.562543.
Train: 2018-08-01T00:09:12.557581: step 3026, loss 0.728122.
Train: 2018-08-01T00:09:12.713794: step 3027, loss 0.562548.
Train: 2018-08-01T00:09:12.870039: step 3028, loss 0.513029.
Train: 2018-08-01T00:09:13.041843: step 3029, loss 0.628582.
Train: 2018-08-01T00:09:13.198086: step 3030, loss 0.579057.
Test: 2018-08-01T00:09:13.666726: step 3030, loss 0.548793.
Train: 2018-08-01T00:09:13.822940: step 3031, loss 0.644914.
Train: 2018-08-01T00:09:13.994771: step 3032, loss 0.546172.
Train: 2018-08-01T00:09:14.150988: step 3033, loss 0.513408.
Train: 2018-08-01T00:09:14.307197: step 3034, loss 0.562622.
Train: 2018-08-01T00:09:14.463416: step 3035, loss 0.464284.
Train: 2018-08-01T00:09:14.619600: step 3036, loss 0.56261.
Train: 2018-08-01T00:09:14.775842: step 3037, loss 0.562596.
Train: 2018-08-01T00:09:14.947671: step 3038, loss 0.463801.
Train: 2018-08-01T00:09:15.103890: step 3039, loss 0.546043.
Train: 2018-08-01T00:09:15.260104: step 3040, loss 0.479701.
Test: 2018-08-01T00:09:15.744336: step 3040, loss 0.54857.
Train: 2018-08-01T00:09:15.900554: step 3041, loss 0.678959.
Train: 2018-08-01T00:09:16.072384: step 3042, loss 0.445788.
Train: 2018-08-01T00:09:16.228596: step 3043, loss 0.662874.
Train: 2018-08-01T00:09:16.384841: step 3044, loss 0.562455.
Train: 2018-08-01T00:09:16.556676: step 3045, loss 0.495257.
Train: 2018-08-01T00:09:16.712883: step 3046, loss 0.545592.
Train: 2018-08-01T00:09:16.869097: step 3047, loss 0.562424.
Train: 2018-08-01T00:09:17.025286: step 3048, loss 0.596282.
Train: 2018-08-01T00:09:17.197144: step 3049, loss 0.528484.
Train: 2018-08-01T00:09:17.353367: step 3050, loss 0.528405.
Test: 2018-08-01T00:09:17.837627: step 3050, loss 0.54813.
Train: 2018-08-01T00:09:17.993809: step 3051, loss 0.511272.
Train: 2018-08-01T00:09:18.165645: step 3052, loss 0.630778.
Train: 2018-08-01T00:09:18.337477: step 3053, loss 0.61377.
Train: 2018-08-01T00:09:18.524936: step 3054, loss 0.562397.
Train: 2018-08-01T00:09:18.712393: step 3055, loss 0.733897.
Train: 2018-08-01T00:09:18.884225: step 3056, loss 0.493927.
Train: 2018-08-01T00:09:19.056061: step 3057, loss 0.493974.
Train: 2018-08-01T00:09:19.212304: step 3058, loss 0.57951.
Train: 2018-08-01T00:09:19.368517: step 3059, loss 0.545283.
Train: 2018-08-01T00:09:19.540351: step 3060, loss 0.648004.
Test: 2018-08-01T00:09:20.008961: step 3060, loss 0.548074.
Train: 2018-08-01T00:09:20.165183: step 3061, loss 0.545292.
Train: 2018-08-01T00:09:20.383876: step 3062, loss 0.528207.
Train: 2018-08-01T00:09:20.571331: step 3063, loss 0.528207.
Train: 2018-08-01T00:09:20.790030: step 3064, loss 0.647922.
Train: 2018-08-01T00:09:20.977485: step 3065, loss 0.630764.
Train: 2018-08-01T00:09:21.149320: step 3066, loss 0.545338.
Train: 2018-08-01T00:09:21.305564: step 3067, loss 0.528321.
Train: 2018-08-01T00:09:21.461780: step 3068, loss 0.562403.
Train: 2018-08-01T00:09:21.617985: step 3069, loss 0.66453.
Train: 2018-08-01T00:09:21.789825: step 3070, loss 0.545421.
Test: 2018-08-01T00:09:22.274086: step 3070, loss 0.548208.
Train: 2018-08-01T00:09:22.430270: step 3071, loss 0.562411.
Train: 2018-08-01T00:09:22.586482: step 3072, loss 0.579355.
Train: 2018-08-01T00:09:22.742727: step 3073, loss 0.528587.
Train: 2018-08-01T00:09:22.898909: step 3074, loss 0.545517.
Train: 2018-08-01T00:09:23.055123: step 3075, loss 0.461029.
Train: 2018-08-01T00:09:23.211337: step 3076, loss 0.630102.
Train: 2018-08-01T00:09:23.367581: step 3077, loss 0.49472.
Train: 2018-08-01T00:09:23.523765: step 3078, loss 0.562414.
Train: 2018-08-01T00:09:23.679977: step 3079, loss 0.596341.
Train: 2018-08-01T00:09:23.836215: step 3080, loss 0.511485.
Test: 2018-08-01T00:09:24.320451: step 3080, loss 0.548173.
Train: 2018-08-01T00:09:24.476695: step 3081, loss 0.647393.
Train: 2018-08-01T00:09:24.632879: step 3082, loss 0.528414.
Train: 2018-08-01T00:09:24.804744: step 3083, loss 0.562406.
Train: 2018-08-01T00:09:24.960952: step 3084, loss 0.562405.
Train: 2018-08-01T00:09:25.117171: step 3085, loss 0.511344.
Train: 2018-08-01T00:09:25.273384: step 3086, loss 0.630564.
Train: 2018-08-01T00:09:25.429567: step 3087, loss 0.715779.
Train: 2018-08-01T00:09:25.585814: step 3088, loss 0.545401.
Train: 2018-08-01T00:09:25.741994: step 3089, loss 0.528459.
Train: 2018-08-01T00:09:25.898207: step 3090, loss 0.477618.
Test: 2018-08-01T00:09:26.366881: step 3090, loss 0.548204.
Train: 2018-08-01T00:09:26.523091: step 3091, loss 0.562411.
Train: 2018-08-01T00:09:26.679308: step 3092, loss 0.545436.
Train: 2018-08-01T00:09:26.835518: step 3093, loss 0.511454.
Train: 2018-08-01T00:09:26.991701: step 3094, loss 0.545396.
Train: 2018-08-01T00:09:27.163537: step 3095, loss 0.562402.
Train: 2018-08-01T00:09:27.319749: step 3096, loss 0.442984.
Train: 2018-08-01T00:09:27.475964: step 3097, loss 0.459726.
Train: 2018-08-01T00:09:27.632177: step 3098, loss 0.579583.
Train: 2018-08-01T00:09:27.788390: step 3099, loss 0.545153.
Train: 2018-08-01T00:09:27.944639: step 3100, loss 0.579712.
Test: 2018-08-01T00:09:28.428865: step 3100, loss 0.547879.
Train: 2018-08-01T00:09:29.178691: step 3101, loss 0.510345.
Train: 2018-08-01T00:09:29.334904: step 3102, loss 0.475362.
Train: 2018-08-01T00:09:29.491116: step 3103, loss 0.562438.
Train: 2018-08-01T00:09:29.647354: step 3104, loss 0.544908.
Train: 2018-08-01T00:09:29.803573: step 3105, loss 0.509653.
Train: 2018-08-01T00:09:29.959787: step 3106, loss 0.562499.
Train: 2018-08-01T00:09:30.131623: step 3107, loss 0.544792.
Train: 2018-08-01T00:09:30.287805: step 3108, loss 0.6159.
Train: 2018-08-01T00:09:30.444042: step 3109, loss 0.598199.
Train: 2018-08-01T00:09:30.600262: step 3110, loss 0.598248.
Test: 2018-08-01T00:09:31.084492: step 3110, loss 0.547635.
Train: 2018-08-01T00:09:31.240707: step 3111, loss 0.562577.
Train: 2018-08-01T00:09:31.412541: step 3112, loss 0.598273.
Train: 2018-08-01T00:09:31.568785: step 3113, loss 0.616092.
Train: 2018-08-01T00:09:31.724992: step 3114, loss 0.544746.
Train: 2018-08-01T00:09:31.881211: step 3115, loss 0.526957.
Train: 2018-08-01T00:09:32.037396: step 3116, loss 0.54476.
Train: 2018-08-01T00:09:32.193608: step 3117, loss 0.580329.
Train: 2018-08-01T00:09:32.349821: step 3118, loss 0.491459.
Train: 2018-08-01T00:09:32.506065: step 3119, loss 0.562543.
Train: 2018-08-01T00:09:32.662273: step 3120, loss 0.598097.
Test: 2018-08-01T00:09:33.146540: step 3120, loss 0.547661.
Train: 2018-08-01T00:09:33.302756: step 3121, loss 0.598075.
Train: 2018-08-01T00:09:33.458967: step 3122, loss 0.615777.
Train: 2018-08-01T00:09:33.615181: step 3123, loss 0.527083.
Train: 2018-08-01T00:09:33.771389: step 3124, loss 0.65098.
Train: 2018-08-01T00:09:33.927607: step 3125, loss 0.474235.
Train: 2018-08-01T00:09:34.083821: step 3126, loss 0.509587.
Train: 2018-08-01T00:09:34.240039: step 3127, loss 0.491975.
Train: 2018-08-01T00:09:34.396243: step 3128, loss 0.544848.
Train: 2018-08-01T00:09:34.552462: step 3129, loss 0.54484.
Train: 2018-08-01T00:09:34.724295: step 3130, loss 0.491838.
Test: 2018-08-01T00:09:35.208557: step 3130, loss 0.547691.
Train: 2018-08-01T00:09:35.364765: step 3131, loss 0.580199.
Train: 2018-08-01T00:09:35.520978: step 3132, loss 0.509377.
Train: 2018-08-01T00:09:35.677167: step 3133, loss 0.615751.
Train: 2018-08-01T00:09:35.833382: step 3134, loss 0.633541.
Train: 2018-08-01T00:09:35.989595: step 3135, loss 0.5093.
Train: 2018-08-01T00:09:36.145808: step 3136, loss 0.509294.
Train: 2018-08-01T00:09:36.302051: step 3137, loss 0.61581.
Train: 2018-08-01T00:09:36.458234: step 3138, loss 0.65131.
Train: 2018-08-01T00:09:36.614484: step 3139, loss 0.527065.
Train: 2018-08-01T00:09:36.770686: step 3140, loss 0.597937.
Test: 2018-08-01T00:09:37.254934: step 3140, loss 0.547694.
Train: 2018-08-01T00:09:37.411137: step 3141, loss 0.580189.
Train: 2018-08-01T00:09:37.567380: step 3142, loss 0.580147.
Train: 2018-08-01T00:09:37.723563: step 3143, loss 0.597725.
Train: 2018-08-01T00:09:37.879777: step 3144, loss 0.615215.
Train: 2018-08-01T00:09:38.020399: step 3145, loss 0.457256.
Train: 2018-08-01T00:09:38.176607: step 3146, loss 0.457372.
Train: 2018-08-01T00:09:38.332820: step 3147, loss 0.544928.
Train: 2018-08-01T00:09:38.473388: step 3148, loss 0.615035.
Train: 2018-08-01T00:09:38.629632: step 3149, loss 0.544925.
Train: 2018-08-01T00:09:38.785844: step 3150, loss 0.597488.
Test: 2018-08-01T00:09:39.270106: step 3150, loss 0.547783.
Train: 2018-08-01T00:09:39.426320: step 3151, loss 0.474903.
Train: 2018-08-01T00:09:39.582503: step 3152, loss 0.615001.
Train: 2018-08-01T00:09:39.738716: step 3153, loss 0.562445.
Train: 2018-08-01T00:09:39.894930: step 3154, loss 0.457404.
Train: 2018-08-01T00:09:40.051143: step 3155, loss 0.544923.
Train: 2018-08-01T00:09:40.207357: step 3156, loss 0.597549.
Train: 2018-08-01T00:09:40.379192: step 3157, loss 0.492234.
Train: 2018-08-01T00:09:40.535430: step 3158, loss 0.632785.
Train: 2018-08-01T00:09:40.691619: step 3159, loss 0.562466.
Train: 2018-08-01T00:09:40.847856: step 3160, loss 0.562466.
Test: 2018-08-01T00:09:41.332123: step 3160, loss 0.547742.
Train: 2018-08-01T00:09:41.488307: step 3161, loss 0.632798.
Train: 2018-08-01T00:09:41.644553: step 3162, loss 0.650277.
Train: 2018-08-01T00:09:41.800767: step 3163, loss 0.527403.
Train: 2018-08-01T00:09:41.956977: step 3164, loss 0.56244.
Train: 2018-08-01T00:09:42.113160: step 3165, loss 0.632297.
Train: 2018-08-01T00:09:42.285025: step 3166, loss 0.475311.
Train: 2018-08-01T00:09:42.425588: step 3167, loss 0.492801.
Train: 2018-08-01T00:09:42.581800: step 3168, loss 0.597231.
Train: 2018-08-01T00:09:42.738014: step 3169, loss 0.562419.
Train: 2018-08-01T00:09:42.894257: step 3170, loss 0.492868.
Test: 2018-08-01T00:09:43.378519: step 3170, loss 0.547851.
Train: 2018-08-01T00:09:43.534703: step 3171, loss 0.492834.
Train: 2018-08-01T00:09:43.690915: step 3172, loss 0.684368.
Train: 2018-08-01T00:09:43.847129: step 3173, loss 0.614655.
Train: 2018-08-01T00:09:44.003373: step 3174, loss 0.562417.
Train: 2018-08-01T00:09:44.159557: step 3175, loss 0.458208.
Train: 2018-08-01T00:09:44.315769: step 3176, loss 0.579789.
Train: 2018-08-01T00:09:44.472013: step 3177, loss 0.440789.
Train: 2018-08-01T00:09:44.628221: step 3178, loss 0.64945.
Train: 2018-08-01T00:09:44.784445: step 3179, loss 0.632065.
Train: 2018-08-01T00:09:44.940654: step 3180, loss 0.475435.
Test: 2018-08-01T00:09:45.409297: step 3180, loss 0.547845.
Train: 2018-08-01T00:09:45.565508: step 3181, loss 0.614636.
Train: 2018-08-01T00:09:45.721691: step 3182, loss 0.666814.
Train: 2018-08-01T00:09:45.877934: step 3183, loss 0.597146.
Train: 2018-08-01T00:09:46.034142: step 3184, loss 0.527753.
Train: 2018-08-01T00:09:46.190361: step 3185, loss 0.614307.
Train: 2018-08-01T00:09:46.346544: step 3186, loss 0.631452.
Train: 2018-08-01T00:09:46.502787: step 3187, loss 0.682875.
Train: 2018-08-01T00:09:46.659000: step 3188, loss 0.596664.
Train: 2018-08-01T00:09:46.815185: step 3189, loss 0.494179.
Train: 2018-08-01T00:09:46.971397: step 3190, loss 0.477392.
Test: 2018-08-01T00:09:47.440037: step 3190, loss 0.548192.
Train: 2018-08-01T00:09:47.611903: step 3191, loss 0.562409.
Train: 2018-08-01T00:09:47.768086: step 3192, loss 0.511545.
Train: 2018-08-01T00:09:47.924324: step 3193, loss 0.477664.
Train: 2018-08-01T00:09:48.080514: step 3194, loss 0.528476.
Train: 2018-08-01T00:09:48.236758: step 3195, loss 0.698342.
Train: 2018-08-01T00:09:48.392973: step 3196, loss 0.579389.
Train: 2018-08-01T00:09:48.549181: step 3197, loss 0.511515.
Train: 2018-08-01T00:09:48.705397: step 3198, loss 0.562411.
Train: 2018-08-01T00:09:48.877201: step 3199, loss 0.528476.
Train: 2018-08-01T00:09:49.033439: step 3200, loss 0.630319.
Test: 2018-08-01T00:09:49.517707: step 3200, loss 0.548199.
Train: 2018-08-01T00:09:50.251879: step 3201, loss 0.56241.
Train: 2018-08-01T00:09:50.408093: step 3202, loss 0.511519.
Train: 2018-08-01T00:09:50.579927: step 3203, loss 0.528465.
Train: 2018-08-01T00:09:50.736172: step 3204, loss 0.528429.
Train: 2018-08-01T00:09:50.892385: step 3205, loss 0.477337.
Train: 2018-08-01T00:09:51.048598: step 3206, loss 0.460053.
Train: 2018-08-01T00:09:51.220433: step 3207, loss 0.511024.
Train: 2018-08-01T00:09:51.360995: step 3208, loss 0.459214.
Train: 2018-08-01T00:09:51.517238: step 3209, loss 0.666137.
Train: 2018-08-01T00:09:51.673421: step 3210, loss 0.458342.
Test: 2018-08-01T00:09:52.157717: step 3210, loss 0.547836.
Train: 2018-08-01T00:09:52.313927: step 3211, loss 0.545003.
Train: 2018-08-01T00:09:52.470141: step 3212, loss 0.544948.
Train: 2018-08-01T00:09:52.641978: step 3213, loss 0.615138.
Train: 2018-08-01T00:09:52.798189: step 3214, loss 0.597686.
Train: 2018-08-01T00:09:52.954372: step 3215, loss 0.580123.
Train: 2018-08-01T00:09:53.110615: step 3216, loss 0.456531.
Train: 2018-08-01T00:09:53.266831: step 3217, loss 0.597922.
Train: 2018-08-01T00:09:53.423012: step 3218, loss 0.544789.
Train: 2018-08-01T00:09:53.563635: step 3219, loss 0.580302.
Train: 2018-08-01T00:09:53.719848: step 3220, loss 0.580331.
Test: 2018-08-01T00:09:54.219701: step 3220, loss 0.547651.
Train: 2018-08-01T00:09:54.375914: step 3221, loss 0.455778.
Train: 2018-08-01T00:09:54.516535: step 3222, loss 0.526909.
Train: 2018-08-01T00:09:54.688366: step 3223, loss 0.562589.
Train: 2018-08-01T00:09:54.828963: step 3224, loss 0.50891.
Train: 2018-08-01T00:09:54.985147: step 3225, loss 0.706133.
Train: 2018-08-01T00:09:55.141360: step 3226, loss 0.526757.
Train: 2018-08-01T00:09:55.297574: step 3227, loss 0.580569.
Train: 2018-08-01T00:09:55.453786: step 3228, loss 0.634371.
Train: 2018-08-01T00:09:55.609999: step 3229, loss 0.490964.
Train: 2018-08-01T00:09:55.766214: step 3230, loss 0.562611.
Test: 2018-08-01T00:09:56.250504: step 3230, loss 0.547618.
Train: 2018-08-01T00:09:56.406723: step 3231, loss 0.526809.
Train: 2018-08-01T00:09:56.562932: step 3232, loss 0.473115.
Train: 2018-08-01T00:09:56.719120: step 3233, loss 0.562617.
Train: 2018-08-01T00:09:56.875358: step 3234, loss 0.580556.
Train: 2018-08-01T00:09:57.031543: step 3235, loss 0.61644.
Train: 2018-08-01T00:09:57.187756: step 3236, loss 0.598476.
Train: 2018-08-01T00:09:57.343969: step 3237, loss 0.473079.
Train: 2018-08-01T00:09:57.500184: step 3238, loss 0.562611.
Train: 2018-08-01T00:09:57.672048: step 3239, loss 0.580516.
Train: 2018-08-01T00:09:57.828267: step 3240, loss 0.616296.
Test: 2018-08-01T00:09:58.296901: step 3240, loss 0.547625.
Train: 2018-08-01T00:09:58.453114: step 3241, loss 0.45535.
Train: 2018-08-01T00:09:58.609328: step 3242, loss 0.473211.
Train: 2018-08-01T00:09:58.765511: step 3243, loss 0.491011.
Train: 2018-08-01T00:09:58.921725: step 3244, loss 0.562627.
Train: 2018-08-01T00:09:59.077968: step 3245, loss 0.562644.
Train: 2018-08-01T00:09:59.234181: step 3246, loss 0.634603.
Train: 2018-08-01T00:09:59.406010: step 3247, loss 0.580646.
Train: 2018-08-01T00:09:59.546578: step 3248, loss 0.508714.
Train: 2018-08-01T00:09:59.702821: step 3249, loss 0.544673.
Train: 2018-08-01T00:09:59.859035: step 3250, loss 0.490699.
Test: 2018-08-01T00:10:00.343297: step 3250, loss 0.547592.
Train: 2018-08-01T00:10:00.499510: step 3251, loss 0.652727.
Train: 2018-08-01T00:10:00.655723: step 3252, loss 0.56267.
Train: 2018-08-01T00:10:00.811906: step 3253, loss 0.544669.
Train: 2018-08-01T00:10:00.968150: step 3254, loss 0.508695.
Train: 2018-08-01T00:10:01.124333: step 3255, loss 0.634635.
Train: 2018-08-01T00:10:01.280547: step 3256, loss 0.508722.
Train: 2018-08-01T00:10:01.436760: step 3257, loss 0.56265.
Train: 2018-08-01T00:10:01.593005: step 3258, loss 0.54468.
Train: 2018-08-01T00:10:01.749220: step 3259, loss 0.508757.
Train: 2018-08-01T00:10:01.905430: step 3260, loss 0.634524.
Test: 2018-08-01T00:10:02.389692: step 3260, loss 0.547604.
Train: 2018-08-01T00:10:02.561527: step 3261, loss 0.52673.
Train: 2018-08-01T00:10:02.717740: step 3262, loss 0.544687.
Train: 2018-08-01T00:10:02.873954: step 3263, loss 0.562633.
Train: 2018-08-01T00:10:03.030137: step 3264, loss 0.688193.
Train: 2018-08-01T00:10:03.186351: step 3265, loss 0.544708.
Train: 2018-08-01T00:10:03.342595: step 3266, loss 0.508992.
Train: 2018-08-01T00:10:03.498807: step 3267, loss 0.705349.
Train: 2018-08-01T00:10:03.655026: step 3268, loss 0.580342.
Train: 2018-08-01T00:10:03.811234: step 3269, loss 0.580261.
Train: 2018-08-01T00:10:03.967417: step 3270, loss 0.562501.
Test: 2018-08-01T00:10:04.451679: step 3270, loss 0.54772.
Train: 2018-08-01T00:10:04.607923: step 3271, loss 0.562481.
Train: 2018-08-01T00:10:04.764106: step 3272, loss 0.615201.
Train: 2018-08-01T00:10:04.935965: step 3273, loss 0.632529.
Train: 2018-08-01T00:10:05.092184: step 3274, loss 0.422836.
Train: 2018-08-01T00:10:05.248393: step 3275, loss 0.527585.
Train: 2018-08-01T00:10:05.404615: step 3276, loss 0.666818.
Train: 2018-08-01T00:10:05.560825: step 3277, loss 0.545056.
Train: 2018-08-01T00:10:05.717007: step 3278, loss 0.545087.
Train: 2018-08-01T00:10:05.873251: step 3279, loss 0.475951.
Train: 2018-08-01T00:10:06.029434: step 3280, loss 0.648833.
Test: 2018-08-01T00:10:06.513726: step 3280, loss 0.547948.
Train: 2018-08-01T00:10:06.685532: step 3281, loss 0.59692.
Train: 2018-08-01T00:10:06.841745: step 3282, loss 0.596852.
Train: 2018-08-01T00:10:06.997959: step 3283, loss 0.545208.
Train: 2018-08-01T00:10:07.154201: step 3284, loss 0.631029.
Train: 2018-08-01T00:10:07.310385: step 3285, loss 0.545284.
Train: 2018-08-01T00:10:07.466599: step 3286, loss 0.579476.
Train: 2018-08-01T00:10:07.622850: step 3287, loss 0.630566.
Train: 2018-08-01T00:10:07.779059: step 3288, loss 0.630372.
Train: 2018-08-01T00:10:07.935239: step 3289, loss 0.562416.
Train: 2018-08-01T00:10:08.091482: step 3290, loss 0.596176.
Test: 2018-08-01T00:10:08.560122: step 3290, loss 0.548358.
Train: 2018-08-01T00:10:08.731927: step 3291, loss 0.612893.
Train: 2018-08-01T00:10:08.888174: step 3292, loss 0.61272.
Train: 2018-08-01T00:10:09.044383: step 3293, loss 0.579167.
Train: 2018-08-01T00:10:09.200567: step 3294, loss 0.529268.
Train: 2018-08-01T00:10:09.356811: step 3295, loss 0.562529.
Train: 2018-08-01T00:10:09.513027: step 3296, loss 0.661734.
Train: 2018-08-01T00:10:09.669238: step 3297, loss 0.579049.
Train: 2018-08-01T00:10:09.825451: step 3298, loss 0.513372.
Train: 2018-08-01T00:10:09.981659: step 3299, loss 0.529877.
Train: 2018-08-01T00:10:10.137880: step 3300, loss 0.480862.
Test: 2018-08-01T00:10:10.606487: step 3300, loss 0.548939.
Train: 2018-08-01T00:10:11.325100: step 3301, loss 0.579003.
Train: 2018-08-01T00:10:11.496934: step 3302, loss 0.529906.
Train: 2018-08-01T00:10:11.653118: step 3303, loss 0.579011.
Train: 2018-08-01T00:10:11.824983: step 3304, loss 0.611801.
Train: 2018-08-01T00:10:11.981196: step 3305, loss 0.562622.
Train: 2018-08-01T00:10:12.137413: step 3306, loss 0.579016.
Train: 2018-08-01T00:10:12.293624: step 3307, loss 0.595412.
Train: 2018-08-01T00:10:12.449806: step 3308, loss 0.677356.
Train: 2018-08-01T00:10:12.606050: step 3309, loss 0.579001.
Train: 2018-08-01T00:10:12.762234: step 3310, loss 0.660616.
Test: 2018-08-01T00:10:13.230907: step 3310, loss 0.549072.
Train: 2018-08-01T00:10:13.387087: step 3311, loss 0.580057.
Train: 2018-08-01T00:10:13.558921: step 3312, loss 0.692532.
Train: 2018-08-01T00:10:13.715136: step 3313, loss 0.627388.
Train: 2018-08-01T00:10:13.871389: step 3314, loss 0.643195.
Train: 2018-08-01T00:10:14.043213: step 3315, loss 0.562939.
Train: 2018-08-01T00:10:14.199422: step 3316, loss 0.515325.
Train: 2018-08-01T00:10:14.355611: step 3317, loss 0.547225.
Train: 2018-08-01T00:10:14.527449: step 3318, loss 0.452481.
Train: 2018-08-01T00:10:14.683688: step 3319, loss 0.610522.
Train: 2018-08-01T00:10:14.839872: step 3320, loss 0.67369.
Test: 2018-08-01T00:10:15.308542: step 3320, loss 0.549955.
Train: 2018-08-01T00:10:15.464726: step 3321, loss 0.563155.
Train: 2018-08-01T00:10:15.652208: step 3322, loss 0.46876.
Train: 2018-08-01T00:10:15.824046: step 3323, loss 0.484446.
Train: 2018-08-01T00:10:16.011475: step 3324, loss 0.610475.
Train: 2018-08-01T00:10:16.167687: step 3325, loss 0.563112.
Train: 2018-08-01T00:10:16.355142: step 3326, loss 0.531432.
Train: 2018-08-01T00:10:16.511370: step 3327, loss 0.563049.
Train: 2018-08-01T00:10:16.667569: step 3328, loss 0.547113.
Train: 2018-08-01T00:10:16.823782: step 3329, loss 0.610794.
Train: 2018-08-01T00:10:16.995617: step 3330, loss 0.578914.
Test: 2018-08-01T00:10:17.464258: step 3330, loss 0.549528.
Train: 2018-08-01T00:10:17.729820: step 3331, loss 0.594911.
Train: 2018-08-01T00:10:17.917277: step 3332, loss 0.594931.
Train: 2018-08-01T00:10:18.151598: step 3333, loss 0.626991.
Train: 2018-08-01T00:10:18.339052: step 3334, loss 0.562899.
Train: 2018-08-01T00:10:18.510888: step 3335, loss 0.530855.
Train: 2018-08-01T00:10:18.682725: step 3336, loss 0.64306.
Train: 2018-08-01T00:10:18.823314: step 3337, loss 0.466718.
Train: 2018-08-01T00:10:18.995176: step 3338, loss 0.498655.
Train: 2018-08-01T00:10:19.167014: step 3339, loss 0.434056.
Train: 2018-08-01T00:10:19.323221: step 3340, loss 0.611295.
Test: 2018-08-01T00:10:19.791867: step 3340, loss 0.549131.
Train: 2018-08-01T00:10:19.948083: step 3341, loss 0.530256.
Train: 2018-08-01T00:10:20.119916: step 3342, loss 0.595282.
Train: 2018-08-01T00:10:20.276099: step 3343, loss 0.595355.
Train: 2018-08-01T00:10:20.432312: step 3344, loss 0.661002.
Train: 2018-08-01T00:10:20.588525: step 3345, loss 0.496966.
Train: 2018-08-01T00:10:20.744739: step 3346, loss 0.496816.
Train: 2018-08-01T00:10:20.916573: step 3347, loss 0.612048.
Train: 2018-08-01T00:10:21.088409: step 3348, loss 0.595605.
Train: 2018-08-01T00:10:21.244623: step 3349, loss 0.529436.
Train: 2018-08-01T00:10:21.416483: step 3350, loss 0.54594.
Test: 2018-08-01T00:10:21.885125: step 3350, loss 0.548592.
Train: 2018-08-01T00:10:22.041311: step 3351, loss 0.479414.
Train: 2018-08-01T00:10:22.213145: step 3352, loss 0.562486.
Train: 2018-08-01T00:10:22.369383: step 3353, loss 0.579194.
Train: 2018-08-01T00:10:22.541227: step 3354, loss 0.612762.
Train: 2018-08-01T00:10:22.697407: step 3355, loss 0.562446.
Train: 2018-08-01T00:10:22.853646: step 3356, loss 0.545617.
Train: 2018-08-01T00:10:23.009858: step 3357, loss 0.52873.
Train: 2018-08-01T00:10:23.181671: step 3358, loss 0.545537.
Train: 2018-08-01T00:10:23.337912: step 3359, loss 0.511644.
Train: 2018-08-01T00:10:23.509747: step 3360, loss 0.579382.
Test: 2018-08-01T00:10:23.993994: step 3360, loss 0.54816.
Train: 2018-08-01T00:10:24.150193: step 3361, loss 0.562405.
Train: 2018-08-01T00:10:24.322027: step 3362, loss 0.68173.
Train: 2018-08-01T00:10:24.478265: step 3363, loss 0.613547.
Train: 2018-08-01T00:10:24.650075: step 3364, loss 0.545364.
Train: 2018-08-01T00:10:24.806287: step 3365, loss 0.562402.
Train: 2018-08-01T00:10:24.962501: step 3366, loss 0.562403.
Train: 2018-08-01T00:10:25.118715: step 3367, loss 0.528354.
Train: 2018-08-01T00:10:25.274929: step 3368, loss 0.562402.
Train: 2018-08-01T00:10:25.446794: step 3369, loss 0.613512.
Train: 2018-08-01T00:10:25.602976: step 3370, loss 0.511315.
Test: 2018-08-01T00:10:26.071646: step 3370, loss 0.548136.
Train: 2018-08-01T00:10:26.227855: step 3371, loss 0.579438.
Train: 2018-08-01T00:10:26.384076: step 3372, loss 0.494248.
Train: 2018-08-01T00:10:26.540287: step 3373, loss 0.511225.
Train: 2018-08-01T00:10:26.696471: step 3374, loss 0.476948.
Train: 2018-08-01T00:10:26.868330: step 3375, loss 0.476694.
Train: 2018-08-01T00:10:27.024518: step 3376, loss 0.510773.
Train: 2018-08-01T00:10:27.180762: step 3377, loss 0.510557.
Train: 2018-08-01T00:10:27.336977: step 3378, loss 0.614495.
Train: 2018-08-01T00:10:27.493159: step 3379, loss 0.666933.
Train: 2018-08-01T00:10:27.649396: step 3380, loss 0.57987.
Test: 2018-08-01T00:10:28.133664: step 3380, loss 0.547811.
Train: 2018-08-01T00:10:28.289877: step 3381, loss 0.579891.
Train: 2018-08-01T00:10:28.446090: step 3382, loss 0.475089.
Train: 2018-08-01T00:10:28.617925: step 3383, loss 0.562441.
Train: 2018-08-01T00:10:28.774109: step 3384, loss 0.422258.
Train: 2018-08-01T00:10:28.930352: step 3385, loss 0.404241.
Train: 2018-08-01T00:10:29.086566: step 3386, loss 0.544827.
Train: 2018-08-01T00:10:29.242779: step 3387, loss 0.615787.
Train: 2018-08-01T00:10:29.398992: step 3388, loss 0.615993.
Train: 2018-08-01T00:10:29.555206: step 3389, loss 0.687524.
Train: 2018-08-01T00:10:29.727010: step 3390, loss 0.509028.
Test: 2018-08-01T00:10:30.211303: step 3390, loss 0.547629.
Train: 2018-08-01T00:10:30.367510: step 3391, loss 0.508999.
Train: 2018-08-01T00:10:30.523723: step 3392, loss 0.580482.
Train: 2018-08-01T00:10:30.695563: step 3393, loss 0.508915.
Train: 2018-08-01T00:10:30.851777: step 3394, loss 0.544699.
Train: 2018-08-01T00:10:31.007986: step 3395, loss 0.54469.
Train: 2018-08-01T00:10:31.164174: step 3396, loss 0.63449.
Train: 2018-08-01T00:10:31.320411: step 3397, loss 0.544682.
Train: 2018-08-01T00:10:31.492260: step 3398, loss 0.598566.
Train: 2018-08-01T00:10:31.632839: step 3399, loss 0.526735.
Train: 2018-08-01T00:10:31.804679: step 3400, loss 0.544687.
Test: 2018-08-01T00:10:32.273290: step 3400, loss 0.547606.
Train: 2018-08-01T00:10:32.976281: step 3401, loss 0.652362.
Train: 2018-08-01T00:10:33.148085: step 3402, loss 0.616378.
Train: 2018-08-01T00:10:33.304328: step 3403, loss 0.580477.
Train: 2018-08-01T00:10:33.460541: step 3404, loss 0.63393.
Train: 2018-08-01T00:10:33.616725: step 3405, loss 0.598109.
Train: 2018-08-01T00:10:33.772938: step 3406, loss 0.615674.
Train: 2018-08-01T00:10:33.929176: step 3407, loss 0.527193.
Train: 2018-08-01T00:10:34.085365: step 3408, loss 0.474515.
Train: 2018-08-01T00:10:34.241609: step 3409, loss 0.597578.
Train: 2018-08-01T00:10:34.413414: step 3410, loss 0.597491.
Test: 2018-08-01T00:10:34.882083: step 3410, loss 0.5478.
Train: 2018-08-01T00:10:35.053889: step 3411, loss 0.544958.
Train: 2018-08-01T00:10:35.210102: step 3412, loss 0.59731.
Train: 2018-08-01T00:10:35.350720: step 3413, loss 0.510223.
Train: 2018-08-01T00:10:35.522552: step 3414, loss 0.631905.
Train: 2018-08-01T00:10:35.678772: step 3415, loss 0.59707.
Train: 2018-08-01T00:10:35.834955: step 3416, loss 0.562402.
Train: 2018-08-01T00:10:35.991168: step 3417, loss 0.476192.
Train: 2018-08-01T00:10:36.147382: step 3418, loss 0.562398.
Train: 2018-08-01T00:10:36.303625: step 3419, loss 0.510769.
Train: 2018-08-01T00:10:36.459809: step 3420, loss 0.510771.
Test: 2018-08-01T00:10:36.928479: step 3420, loss 0.547977.
Train: 2018-08-01T00:10:37.084663: step 3421, loss 0.614062.
Train: 2018-08-01T00:10:37.240875: step 3422, loss 0.52796.
Train: 2018-08-01T00:10:37.397090: step 3423, loss 0.579624.
Train: 2018-08-01T00:10:37.553327: step 3424, loss 0.527945.
Train: 2018-08-01T00:10:37.709541: step 3425, loss 0.476216.
Train: 2018-08-01T00:10:37.865729: step 3426, loss 0.562401.
Train: 2018-08-01T00:10:38.021967: step 3427, loss 0.596991.
Train: 2018-08-01T00:10:38.178181: step 3428, loss 0.614332.
Train: 2018-08-01T00:10:38.334401: step 3429, loss 0.579714.
Train: 2018-08-01T00:10:38.490613: step 3430, loss 0.493189.
Test: 2018-08-01T00:10:38.974846: step 3430, loss 0.547906.
Train: 2018-08-01T00:10:39.131091: step 3431, loss 0.579723.
Train: 2018-08-01T00:10:39.287305: step 3432, loss 0.545084.
Train: 2018-08-01T00:10:39.443515: step 3433, loss 0.579741.
Train: 2018-08-01T00:10:39.599729: step 3434, loss 0.683761.
Train: 2018-08-01T00:10:39.755946: step 3435, loss 0.527789.
Train: 2018-08-01T00:10:39.927777: step 3436, loss 0.562403.
Train: 2018-08-01T00:10:40.083960: step 3437, loss 0.493302.
Train: 2018-08-01T00:10:40.240204: step 3438, loss 0.441456.
Train: 2018-08-01T00:10:40.396416: step 3439, loss 0.545094.
Train: 2018-08-01T00:10:40.552600: step 3440, loss 0.631789.
Test: 2018-08-01T00:10:41.036893: step 3440, loss 0.547877.
Train: 2018-08-01T00:10:41.193106: step 3441, loss 0.631839.
Train: 2018-08-01T00:10:41.364910: step 3442, loss 0.597109.
Train: 2018-08-01T00:10:41.521158: step 3443, loss 0.458409.
Train: 2018-08-01T00:10:41.677368: step 3444, loss 0.597099.
Train: 2018-08-01T00:10:41.833580: step 3445, loss 0.579755.
Train: 2018-08-01T00:10:41.989789: step 3446, loss 0.475705.
Train: 2018-08-01T00:10:42.145977: step 3447, loss 0.510337.
Train: 2018-08-01T00:10:42.302190: step 3448, loss 0.579803.
Train: 2018-08-01T00:10:42.458435: step 3449, loss 0.61464.
Train: 2018-08-01T00:10:42.614649: step 3450, loss 0.457956.
Test: 2018-08-01T00:10:43.098909: step 3450, loss 0.547823.
Train: 2018-08-01T00:10:43.270743: step 3451, loss 0.667068.
Train: 2018-08-01T00:10:43.426952: step 3452, loss 0.667062.
Train: 2018-08-01T00:10:43.583171: step 3453, loss 0.562421.
Train: 2018-08-01T00:10:43.739355: step 3454, loss 0.64934.
Train: 2018-08-01T00:10:43.895602: step 3455, loss 0.614424.
Train: 2018-08-01T00:10:44.051810: step 3456, loss 0.545119.
Train: 2018-08-01T00:10:44.223646: step 3457, loss 0.510688.
Train: 2018-08-01T00:10:44.379861: step 3458, loss 0.682856.
Train: 2018-08-01T00:10:44.536073: step 3459, loss 0.579548.
Train: 2018-08-01T00:10:44.692280: step 3460, loss 0.545301.
Test: 2018-08-01T00:10:45.160926: step 3460, loss 0.548122.
Train: 2018-08-01T00:10:45.317140: step 3461, loss 0.477143.
Train: 2018-08-01T00:10:45.473323: step 3462, loss 0.613502.
Train: 2018-08-01T00:10:45.629566: step 3463, loss 0.562405.
Train: 2018-08-01T00:10:45.785776: step 3464, loss 0.579387.
Train: 2018-08-01T00:10:45.941994: step 3465, loss 0.52851.
Train: 2018-08-01T00:10:46.113824: step 3466, loss 0.477733.
Train: 2018-08-01T00:10:46.270011: step 3467, loss 0.630196.
Train: 2018-08-01T00:10:46.426254: step 3468, loss 0.613227.
Train: 2018-08-01T00:10:46.582468: step 3469, loss 0.562418.
Train: 2018-08-01T00:10:46.738653: step 3470, loss 0.596222.
Test: 2018-08-01T00:10:47.238548: step 3470, loss 0.548294.
Train: 2018-08-01T00:10:47.394778: step 3471, loss 0.613056.
Train: 2018-08-01T00:10:47.550991: step 3472, loss 0.495061.
Train: 2018-08-01T00:10:47.707175: step 3473, loss 0.511941.
Train: 2018-08-01T00:10:47.863388: step 3474, loss 0.596108.
Train: 2018-08-01T00:10:48.019627: step 3475, loss 0.545605.
Train: 2018-08-01T00:10:48.175846: step 3476, loss 0.545603.
Train: 2018-08-01T00:10:48.332029: step 3477, loss 0.64664.
Train: 2018-08-01T00:10:48.488243: step 3478, loss 0.697051.
Train: 2018-08-01T00:10:48.644484: step 3479, loss 0.59601.
Train: 2018-08-01T00:10:48.800670: step 3480, loss 0.529007.
Test: 2018-08-01T00:10:49.284931: step 3480, loss 0.548498.
Train: 2018-08-01T00:10:49.441143: step 3481, loss 0.579174.
Train: 2018-08-01T00:10:49.597388: step 3482, loss 0.479186.
Train: 2018-08-01T00:10:49.753604: step 3483, loss 0.579148.
Train: 2018-08-01T00:10:49.909814: step 3484, loss 0.512562.
Train: 2018-08-01T00:10:50.065998: step 3485, loss 0.612451.
Train: 2018-08-01T00:10:50.222235: step 3486, loss 0.695672.
Train: 2018-08-01T00:10:50.378449: step 3487, loss 0.612339.
Train: 2018-08-01T00:10:50.534662: step 3488, loss 0.728164.
Train: 2018-08-01T00:10:50.690851: step 3489, loss 0.644976.
Train: 2018-08-01T00:10:50.847095: step 3490, loss 0.49708.
Test: 2018-08-01T00:10:51.315704: step 3490, loss 0.548999.
Train: 2018-08-01T00:10:51.471948: step 3491, loss 0.43209.
Train: 2018-08-01T00:10:51.628132: step 3492, loss 0.56268.
Train: 2018-08-01T00:10:51.784345: step 3493, loss 0.644123.
Train: 2018-08-01T00:10:51.940559: step 3494, loss 0.546458.
Train: 2018-08-01T00:10:52.096772: step 3495, loss 0.514031.
Train: 2018-08-01T00:10:52.268636: step 3496, loss 0.546501.
Train: 2018-08-01T00:10:52.424845: step 3497, loss 0.562727.
Train: 2018-08-01T00:10:52.596655: step 3498, loss 0.514.
Train: 2018-08-01T00:10:52.752903: step 3499, loss 0.595232.
Train: 2018-08-01T00:10:52.909081: step 3500, loss 0.497584.
Test: 2018-08-01T00:10:53.377722: step 3500, loss 0.549014.
Train: 2018-08-01T00:10:54.080684: step 3501, loss 0.53005.
Train: 2018-08-01T00:10:54.252547: step 3502, loss 0.611707.
Train: 2018-08-01T00:10:54.408755: step 3503, loss 0.595391.
Train: 2018-08-01T00:10:54.564975: step 3504, loss 0.48062.
Train: 2018-08-01T00:10:54.721187: step 3505, loss 0.546154.
Train: 2018-08-01T00:10:54.877371: step 3506, loss 0.546086.
Train: 2018-08-01T00:10:55.049205: step 3507, loss 0.529486.
Train: 2018-08-01T00:10:55.205446: step 3508, loss 0.612273.
Train: 2018-08-01T00:10:55.361632: step 3509, loss 0.545889.
Train: 2018-08-01T00:10:55.517876: step 3510, loss 0.545835.
Test: 2018-08-01T00:10:56.002137: step 3510, loss 0.548494.
Train: 2018-08-01T00:10:56.158321: step 3511, loss 0.545779.
Train: 2018-08-01T00:10:56.330185: step 3512, loss 0.562463.
Train: 2018-08-01T00:10:56.486393: step 3513, loss 0.41142.
Train: 2018-08-01T00:10:56.642583: step 3514, loss 0.478143.
Train: 2018-08-01T00:10:56.798796: step 3515, loss 0.494616.
Train: 2018-08-01T00:10:56.955010: step 3516, loss 0.61355.
Train: 2018-08-01T00:10:57.126874: step 3517, loss 0.648035.
Train: 2018-08-01T00:10:57.283082: step 3518, loss 0.6311.
Train: 2018-08-01T00:10:57.439301: step 3519, loss 0.527994.
Train: 2018-08-01T00:10:57.595484: step 3520, loss 0.562398.
Test: 2018-08-01T00:10:58.079747: step 3520, loss 0.547945.
Train: 2018-08-01T00:10:58.235985: step 3521, loss 0.5624.
Train: 2018-08-01T00:10:58.392202: step 3522, loss 0.510541.
Train: 2018-08-01T00:10:58.548411: step 3523, loss 0.562407.
Train: 2018-08-01T00:10:58.704630: step 3524, loss 0.597119.
Train: 2018-08-01T00:10:58.860838: step 3525, loss 0.545041.
Train: 2018-08-01T00:10:59.017056: step 3526, loss 0.597205.
Train: 2018-08-01T00:10:59.173269: step 3527, loss 0.579822.
Train: 2018-08-01T00:10:59.329483: step 3528, loss 0.440583.
Train: 2018-08-01T00:10:59.485697: step 3529, loss 0.61474.
Train: 2018-08-01T00:10:59.641881: step 3530, loss 0.579883.
Test: 2018-08-01T00:11:00.126169: step 3530, loss 0.54781.
Train: 2018-08-01T00:11:00.282356: step 3531, loss 0.52751.
Train: 2018-08-01T00:11:00.454220: step 3532, loss 0.527483.
Train: 2018-08-01T00:11:00.610404: step 3533, loss 0.614933.
Train: 2018-08-01T00:11:00.766617: step 3534, loss 0.737465.
Train: 2018-08-01T00:11:00.922860: step 3535, loss 0.527508.
Train: 2018-08-01T00:11:01.079044: step 3536, loss 0.579859.
Train: 2018-08-01T00:11:01.235282: step 3537, loss 0.614625.
Train: 2018-08-01T00:11:01.391500: step 3538, loss 0.510332.
Train: 2018-08-01T00:11:01.547709: step 3539, loss 0.475734.
Train: 2018-08-01T00:11:01.719518: step 3540, loss 0.423742.
Test: 2018-08-01T00:11:02.188158: step 3540, loss 0.547871.
Train: 2018-08-01T00:11:02.344397: step 3541, loss 0.597145.
Train: 2018-08-01T00:11:02.500587: step 3542, loss 0.684121.
Train: 2018-08-01T00:11:02.656830: step 3543, loss 0.492921.
Train: 2018-08-01T00:11:02.828665: step 3544, loss 0.545037.
Train: 2018-08-01T00:11:02.969257: step 3545, loss 0.614575.
Train: 2018-08-01T00:11:03.141095: step 3546, loss 0.527656.
Train: 2018-08-01T00:11:03.297275: step 3547, loss 0.631942.
Train: 2018-08-01T00:11:03.469109: step 3548, loss 0.475586.
Train: 2018-08-01T00:11:03.609731: step 3549, loss 0.52767.
Train: 2018-08-01T00:11:03.781566: step 3550, loss 0.684114.
Test: 2018-08-01T00:11:04.250176: step 3550, loss 0.547871.
Train: 2018-08-01T00:11:04.406389: step 3551, loss 0.57978.
Train: 2018-08-01T00:11:04.562633: step 3552, loss 0.649132.
Train: 2018-08-01T00:11:04.718846: step 3553, loss 0.389382.
Train: 2018-08-01T00:11:04.875060: step 3554, loss 0.700863.
Train: 2018-08-01T00:11:05.031274: step 3555, loss 0.545125.
Train: 2018-08-01T00:11:05.187487: step 3556, loss 0.596906.
Train: 2018-08-01T00:11:05.343701: step 3557, loss 0.579621.
Train: 2018-08-01T00:11:05.515534: step 3558, loss 0.545206.
Train: 2018-08-01T00:11:05.656128: step 3559, loss 0.510897.
Train: 2018-08-01T00:11:05.827931: step 3560, loss 0.562396.
Test: 2018-08-01T00:11:06.312223: step 3560, loss 0.548036.
Train: 2018-08-01T00:11:06.468407: step 3561, loss 0.579546.
Train: 2018-08-01T00:11:06.624650: step 3562, loss 0.493845.
Train: 2018-08-01T00:11:06.796454: step 3563, loss 0.493817.
Train: 2018-08-01T00:11:06.952700: step 3564, loss 0.579565.
Train: 2018-08-01T00:11:07.108912: step 3565, loss 0.47647.
Train: 2018-08-01T00:11:07.265119: step 3566, loss 0.596842.
Train: 2018-08-01T00:11:07.421339: step 3567, loss 0.51066.
Train: 2018-08-01T00:11:07.577522: step 3568, loss 0.596964.
Train: 2018-08-01T00:11:07.733735: step 3569, loss 0.579707.
Train: 2018-08-01T00:11:07.889978: step 3570, loss 0.510452.
Test: 2018-08-01T00:11:08.358619: step 3570, loss 0.547886.
Train: 2018-08-01T00:11:08.514832: step 3571, loss 0.56241.
Train: 2018-08-01T00:11:08.671046: step 3572, loss 0.562413.
Train: 2018-08-01T00:11:08.842851: step 3573, loss 0.562416.
Train: 2018-08-01T00:11:08.999094: step 3574, loss 0.632034.
Train: 2018-08-01T00:11:09.155303: step 3575, loss 0.562419.
Train: 2018-08-01T00:11:09.311521: step 3576, loss 0.666803.
Train: 2018-08-01T00:11:09.467705: step 3577, loss 0.579781.
Train: 2018-08-01T00:11:09.639549: step 3578, loss 0.527737.
Train: 2018-08-01T00:11:09.795752: step 3579, loss 0.57972.
Train: 2018-08-01T00:11:09.951966: step 3580, loss 0.579694.
Test: 2018-08-01T00:11:10.420664: step 3580, loss 0.547943.
Train: 2018-08-01T00:11:10.592441: step 3581, loss 0.562401.
Train: 2018-08-01T00:11:10.748654: step 3582, loss 0.631364.
Train: 2018-08-01T00:11:10.920491: step 3583, loss 0.476386.
Train: 2018-08-01T00:11:11.076727: step 3584, loss 0.528019.
Train: 2018-08-01T00:11:11.264160: step 3585, loss 0.562396.
Train: 2018-08-01T00:11:11.420403: step 3586, loss 0.579578.
Train: 2018-08-01T00:11:11.592208: step 3587, loss 0.493699.
Train: 2018-08-01T00:11:11.748445: step 3588, loss 0.631137.
Train: 2018-08-01T00:11:11.920274: step 3589, loss 0.613928.
Train: 2018-08-01T00:11:12.076504: step 3590, loss 0.545239.
Test: 2018-08-01T00:11:12.545139: step 3590, loss 0.548041.
Train: 2018-08-01T00:11:12.716945: step 3591, loss 0.596682.
Train: 2018-08-01T00:11:12.873157: step 3592, loss 0.562397.
Train: 2018-08-01T00:11:13.044991: step 3593, loss 0.613705.
Train: 2018-08-01T00:11:13.201204: step 3594, loss 0.494108.
Train: 2018-08-01T00:11:13.341834: step 3595, loss 0.494146.
Train: 2018-08-01T00:11:13.513633: step 3596, loss 0.51118.
Train: 2018-08-01T00:11:13.669846: step 3597, loss 0.511113.
Train: 2018-08-01T00:11:13.826089: step 3598, loss 0.459629.
Train: 2018-08-01T00:11:13.997926: step 3599, loss 0.528029.
Train: 2018-08-01T00:11:14.154107: step 3600, loss 0.596885.
Test: 2018-08-01T00:11:14.622780: step 3600, loss 0.547927.
Train: 2018-08-01T00:11:15.372604: step 3601, loss 0.493254.
Train: 2018-08-01T00:11:15.528815: step 3602, loss 0.666472.
Train: 2018-08-01T00:11:15.700620: step 3603, loss 0.614517.
Train: 2018-08-01T00:11:15.872484: step 3604, loss 0.475534.
Train: 2018-08-01T00:11:16.028693: step 3605, loss 0.56242.
Train: 2018-08-01T00:11:16.184912: step 3606, loss 0.492709.
Train: 2018-08-01T00:11:16.341126: step 3607, loss 0.614836.
Train: 2018-08-01T00:11:16.512929: step 3608, loss 0.527461.
Train: 2018-08-01T00:11:16.669142: step 3609, loss 0.509901.
Train: 2018-08-01T00:11:16.825381: step 3610, loss 0.667757.
Test: 2018-08-01T00:11:17.294026: step 3610, loss 0.547757.
Train: 2018-08-01T00:11:17.450240: step 3611, loss 0.457128.
Train: 2018-08-01T00:11:17.622074: step 3612, loss 0.562466.
Train: 2018-08-01T00:11:17.793880: step 3613, loss 0.527258.
Train: 2018-08-01T00:11:17.934471: step 3614, loss 0.650672.
Train: 2018-08-01T00:11:18.090686: step 3615, loss 0.456642.
Train: 2018-08-01T00:11:18.246898: step 3616, loss 0.491825.
Train: 2018-08-01T00:11:18.418758: step 3617, loss 0.456264.
Train: 2018-08-01T00:11:18.574946: step 3618, loss 0.491465.
Train: 2018-08-01T00:11:18.731190: step 3619, loss 0.580412.
Train: 2018-08-01T00:11:18.902994: step 3620, loss 0.562604.
Test: 2018-08-01T00:11:19.371665: step 3620, loss 0.547607.
Train: 2018-08-01T00:11:19.543500: step 3621, loss 0.562632.
Train: 2018-08-01T00:11:19.699708: step 3622, loss 0.562657.
Train: 2018-08-01T00:11:19.855927: step 3623, loss 0.490608.
Train: 2018-08-01T00:11:20.027732: step 3624, loss 0.50852.
Train: 2018-08-01T00:11:20.183975: step 3625, loss 0.617085.
Train: 2018-08-01T00:11:20.340188: step 3626, loss 0.562766.
Train: 2018-08-01T00:11:20.496405: step 3627, loss 0.544617.
Train: 2018-08-01T00:11:20.652620: step 3628, loss 0.508236.
Train: 2018-08-01T00:11:20.808828: step 3629, loss 0.544606.
Train: 2018-08-01T00:11:20.980664: step 3630, loss 0.599337.
Test: 2018-08-01T00:11:21.449274: step 3630, loss 0.547568.
Train: 2018-08-01T00:11:21.605487: step 3631, loss 0.544599.
Train: 2018-08-01T00:11:21.761701: step 3632, loss 0.599405.
Train: 2018-08-01T00:11:21.917944: step 3633, loss 0.562865.
Train: 2018-08-01T00:11:22.089784: step 3634, loss 0.544598.
Train: 2018-08-01T00:11:22.245995: step 3635, loss 0.599374.
Train: 2018-08-01T00:11:22.402205: step 3636, loss 0.526359.
Train: 2018-08-01T00:11:22.558418: step 3637, loss 0.708703.
Train: 2018-08-01T00:11:22.714632: step 3638, loss 0.562799.
Train: 2018-08-01T00:11:22.870848: step 3639, loss 0.599046.
Train: 2018-08-01T00:11:23.027055: step 3640, loss 0.598902.
Test: 2018-08-01T00:11:23.495699: step 3640, loss 0.547589.
Train: 2018-08-01T00:11:23.667535: step 3641, loss 0.580714.
Train: 2018-08-01T00:11:23.823748: step 3642, loss 0.544679.
Train: 2018-08-01T00:11:23.979961: step 3643, loss 0.526786.
Train: 2018-08-01T00:11:24.151796: step 3644, loss 0.562591.
Train: 2018-08-01T00:11:24.308009: step 3645, loss 0.6874.
Train: 2018-08-01T00:11:24.464193: step 3646, loss 0.509245.
Train: 2018-08-01T00:11:24.620407: step 3647, loss 0.544801.
Train: 2018-08-01T00:11:24.792274: step 3648, loss 0.509486.
Train: 2018-08-01T00:11:24.948453: step 3649, loss 0.544844.
Train: 2018-08-01T00:11:25.120288: step 3650, loss 0.615341.
Test: 2018-08-01T00:11:25.588959: step 3650, loss 0.54774.
Train: 2018-08-01T00:11:25.745142: step 3651, loss 0.615226.
Train: 2018-08-01T00:11:25.901387: step 3652, loss 0.597534.
Train: 2018-08-01T00:11:26.073192: step 3653, loss 0.49248.
Train: 2018-08-01T00:11:26.229429: step 3654, loss 0.527511.
Train: 2018-08-01T00:11:26.369997: step 3655, loss 0.579868.
Train: 2018-08-01T00:11:26.541832: step 3656, loss 0.614679.
Train: 2018-08-01T00:11:26.698074: step 3657, loss 0.579801.
Train: 2018-08-01T00:11:26.854257: step 3658, loss 0.579759.
Train: 2018-08-01T00:11:27.010471: step 3659, loss 0.527782.
Train: 2018-08-01T00:11:27.182330: step 3660, loss 0.579689.
Test: 2018-08-01T00:11:27.650946: step 3660, loss 0.547948.
Train: 2018-08-01T00:11:27.807160: step 3661, loss 0.545142.
Train: 2018-08-01T00:11:27.963373: step 3662, loss 0.596874.
Train: 2018-08-01T00:11:28.119587: step 3663, loss 0.579607.
Train: 2018-08-01T00:11:28.275824: step 3664, loss 0.613936.
Train: 2018-08-01T00:11:28.432044: step 3665, loss 0.510976.
Train: 2018-08-01T00:11:28.603881: step 3666, loss 0.613748.
Train: 2018-08-01T00:11:28.760061: step 3667, loss 0.630733.
Train: 2018-08-01T00:11:28.916306: step 3668, loss 0.647583.
Train: 2018-08-01T00:11:29.072521: step 3669, loss 0.613325.
Train: 2018-08-01T00:11:29.228702: step 3670, loss 0.41031.
Test: 2018-08-01T00:11:29.712993: step 3670, loss 0.548292.
Train: 2018-08-01T00:11:29.869176: step 3671, loss 0.511791.
Train: 2018-08-01T00:11:30.025421: step 3672, loss 0.562427.
Train: 2018-08-01T00:11:30.181605: step 3673, loss 0.579295.
Train: 2018-08-01T00:11:30.353468: step 3674, loss 0.545571.
Train: 2018-08-01T00:11:30.509677: step 3675, loss 0.646718.
Train: 2018-08-01T00:11:30.665865: step 3676, loss 0.528766.
Train: 2018-08-01T00:11:30.822079: step 3677, loss 0.545614.
Train: 2018-08-01T00:11:30.993915: step 3678, loss 0.579261.
Train: 2018-08-01T00:11:31.150126: step 3679, loss 0.495184.
Train: 2018-08-01T00:11:31.306366: step 3680, loss 0.646573.
Test: 2018-08-01T00:11:31.790602: step 3680, loss 0.548357.
Train: 2018-08-01T00:11:31.946815: step 3681, loss 0.461534.
Train: 2018-08-01T00:11:32.118674: step 3682, loss 0.663457.
Train: 2018-08-01T00:11:32.274863: step 3683, loss 0.629753.
Train: 2018-08-01T00:11:32.431076: step 3684, loss 0.562444.
Train: 2018-08-01T00:11:32.587321: step 3685, loss 0.52888.
Train: 2018-08-01T00:11:32.743503: step 3686, loss 0.596005.
Train: 2018-08-01T00:11:32.899748: step 3687, loss 0.51217.
Train: 2018-08-01T00:11:33.071554: step 3688, loss 0.461877.
Train: 2018-08-01T00:11:33.227796: step 3689, loss 0.596031.
Train: 2018-08-01T00:11:33.384013: step 3690, loss 0.579253.
Test: 2018-08-01T00:11:33.852648: step 3690, loss 0.548351.
Train: 2018-08-01T00:11:34.024484: step 3691, loss 0.511968.
Train: 2018-08-01T00:11:34.180667: step 3692, loss 0.629832.
Train: 2018-08-01T00:11:34.336880: step 3693, loss 0.495003.
Train: 2018-08-01T00:11:34.493118: step 3694, loss 0.511779.
Train: 2018-08-01T00:11:34.649337: step 3695, loss 0.545499.
Train: 2018-08-01T00:11:34.805545: step 3696, loss 0.596325.
Train: 2018-08-01T00:11:34.977380: step 3697, loss 0.545425.
Train: 2018-08-01T00:11:35.130008: step 3698, loss 0.562404.
Train: 2018-08-01T00:11:35.286222: step 3699, loss 0.647591.
Train: 2018-08-01T00:11:35.458051: step 3700, loss 0.579441.
Test: 2018-08-01T00:11:35.926697: step 3700, loss 0.548134.
Train: 2018-08-01T00:11:36.676521: step 3701, loss 0.579439.
Train: 2018-08-01T00:11:36.832734: step 3702, loss 0.613497.
Train: 2018-08-01T00:11:36.988943: step 3703, loss 0.596431.
Train: 2018-08-01T00:11:37.145132: step 3704, loss 0.545418.
Train: 2018-08-01T00:11:37.301370: step 3705, loss 0.579381.
Train: 2018-08-01T00:11:37.457594: step 3706, loss 0.613269.
Train: 2018-08-01T00:11:37.613772: step 3707, loss 0.57934.
Train: 2018-08-01T00:11:37.770016: step 3708, loss 0.562423.
Train: 2018-08-01T00:11:37.926226: step 3709, loss 0.511833.
Train: 2018-08-01T00:11:38.082437: step 3710, loss 0.663565.
Test: 2018-08-01T00:11:38.566703: step 3710, loss 0.548353.
Train: 2018-08-01T00:11:38.722917: step 3711, loss 0.511975.
Train: 2018-08-01T00:11:38.879125: step 3712, loss 0.612859.
Train: 2018-08-01T00:11:39.050967: step 3713, loss 0.57923.
Train: 2018-08-01T00:11:39.207179: step 3714, loss 0.56246.
Train: 2018-08-01T00:11:39.363392: step 3715, loss 0.462099.
Train: 2018-08-01T00:11:39.519607: step 3716, loss 0.595935.
Train: 2018-08-01T00:11:39.675821: step 3717, loss 0.646136.
Train: 2018-08-01T00:11:39.847623: step 3718, loss 0.579185.
Train: 2018-08-01T00:11:40.003837: step 3719, loss 0.512409.
Train: 2018-08-01T00:11:40.160081: step 3720, loss 0.562482.
Test: 2018-08-01T00:11:40.644312: step 3720, loss 0.548514.
Train: 2018-08-01T00:11:40.800559: step 3721, loss 0.512437.
Train: 2018-08-01T00:11:40.956769: step 3722, loss 0.479007.
Train: 2018-08-01T00:11:41.112982: step 3723, loss 0.529009.
Train: 2018-08-01T00:11:41.284818: step 3724, loss 0.545683.
Train: 2018-08-01T00:11:41.441001: step 3725, loss 0.629694.
Train: 2018-08-01T00:11:41.597213: step 3726, loss 0.511929.
Train: 2018-08-01T00:11:41.753452: step 3727, loss 0.545558.
Train: 2018-08-01T00:11:41.909669: step 3728, loss 0.528608.
Train: 2018-08-01T00:11:42.081475: step 3729, loss 0.613258.
Train: 2018-08-01T00:11:42.237719: step 3730, loss 0.562409.
Test: 2018-08-01T00:11:42.721950: step 3730, loss 0.548172.
Train: 2018-08-01T00:11:42.878164: step 3731, loss 0.562406.
Train: 2018-08-01T00:11:43.034403: step 3732, loss 0.511344.
Train: 2018-08-01T00:11:43.190626: step 3733, loss 0.630613.
Train: 2018-08-01T00:11:43.346840: step 3734, loss 0.511202.
Train: 2018-08-01T00:11:43.503048: step 3735, loss 0.528216.
Train: 2018-08-01T00:11:43.674853: step 3736, loss 0.545274.
Train: 2018-08-01T00:11:43.846724: step 3737, loss 0.596707.
Train: 2018-08-01T00:11:44.002933: step 3738, loss 0.510867.
Train: 2018-08-01T00:11:44.174766: step 3739, loss 0.493563.
Train: 2018-08-01T00:11:44.330949: step 3740, loss 0.579654.
Test: 2018-08-01T00:11:44.799589: step 3740, loss 0.547923.
Train: 2018-08-01T00:11:44.955833: step 3741, loss 0.527819.
Train: 2018-08-01T00:11:45.127638: step 3742, loss 0.493074.
Train: 2018-08-01T00:11:45.283881: step 3743, loss 0.52764.
Train: 2018-08-01T00:11:45.440091: step 3744, loss 0.579873.
Train: 2018-08-01T00:11:45.596307: step 3745, loss 0.405014.
Train: 2018-08-01T00:11:45.752515: step 3746, loss 0.597606.
Train: 2018-08-01T00:11:45.908704: step 3747, loss 0.544849.
Train: 2018-08-01T00:11:46.064942: step 3748, loss 0.527121.
Train: 2018-08-01T00:11:46.221161: step 3749, loss 0.544779.
Train: 2018-08-01T00:11:46.377374: step 3750, loss 0.615983.
Test: 2018-08-01T00:11:46.845984: step 3750, loss 0.547634.
Train: 2018-08-01T00:11:47.017856: step 3751, loss 0.616106.
Train: 2018-08-01T00:11:47.174064: step 3752, loss 0.526865.
Train: 2018-08-01T00:11:47.330270: step 3753, loss 0.526835.
Train: 2018-08-01T00:11:47.486460: step 3754, loss 0.490987.
Train: 2018-08-01T00:11:47.658319: step 3755, loss 0.544688.
Train: 2018-08-01T00:11:47.814508: step 3756, loss 0.526695.
Train: 2018-08-01T00:11:47.970751: step 3757, loss 0.45457.
Train: 2018-08-01T00:11:48.126965: step 3758, loss 0.598871.
Train: 2018-08-01T00:11:48.283178: step 3759, loss 0.435928.
Train: 2018-08-01T00:11:48.439392: step 3760, loss 0.544614.
Test: 2018-08-01T00:11:48.908002: step 3760, loss 0.547568.
Train: 2018-08-01T00:11:49.079867: step 3761, loss 0.617562.
Train: 2018-08-01T00:11:49.236080: step 3762, loss 0.544596.
Train: 2018-08-01T00:11:49.392264: step 3763, loss 0.453044.
Train: 2018-08-01T00:11:49.548501: step 3764, loss 0.618033.
Train: 2018-08-01T00:11:49.704721: step 3765, loss 0.581367.
Train: 2018-08-01T00:11:49.860933: step 3766, loss 0.599813.
Train: 2018-08-01T00:11:50.001526: step 3767, loss 0.618237.
Train: 2018-08-01T00:11:50.173360: step 3768, loss 0.507783.
Train: 2018-08-01T00:11:50.329569: step 3769, loss 0.434208.
Train: 2018-08-01T00:11:50.485782: step 3770, loss 0.526162.
Test: 2018-08-01T00:11:50.970055: step 3770, loss 0.54758.
Train: 2018-08-01T00:11:51.126262: step 3771, loss 0.618361.
Train: 2018-08-01T00:11:51.282477: step 3772, loss 0.54458.
Train: 2018-08-01T00:11:51.438660: step 3773, loss 0.618404.
Train: 2018-08-01T00:11:51.594873: step 3774, loss 0.599909.
Train: 2018-08-01T00:11:51.766707: step 3775, loss 0.526163.
Train: 2018-08-01T00:11:51.922945: step 3776, loss 0.45258.
Train: 2018-08-01T00:11:52.079164: step 3777, loss 0.599803.
Train: 2018-08-01T00:11:52.235348: step 3778, loss 0.74698.
Train: 2018-08-01T00:11:52.391592: step 3779, loss 0.526242.
Train: 2018-08-01T00:11:52.547805: step 3780, loss 0.507991.
Test: 2018-08-01T00:11:53.032035: step 3780, loss 0.547568.
Train: 2018-08-01T00:11:53.188250: step 3781, loss 0.526327.
Train: 2018-08-01T00:11:53.360120: step 3782, loss 0.508105.
Train: 2018-08-01T00:11:53.516298: step 3783, loss 0.489891.
Train: 2018-08-01T00:11:53.672536: step 3784, loss 0.562843.
Train: 2018-08-01T00:11:53.828755: step 3785, loss 0.635813.
Train: 2018-08-01T00:11:53.984962: step 3786, loss 0.489941.
Train: 2018-08-01T00:11:54.141151: step 3787, loss 0.599257.
Train: 2018-08-01T00:11:54.297364: step 3788, loss 0.653811.
Train: 2018-08-01T00:11:54.453608: step 3789, loss 0.562779.
Train: 2018-08-01T00:11:54.609822: step 3790, loss 0.490269.
Test: 2018-08-01T00:11:55.094085: step 3790, loss 0.547578.
Train: 2018-08-01T00:11:55.250297: step 3791, loss 0.598931.
Train: 2018-08-01T00:11:55.406480: step 3792, loss 0.689183.
Train: 2018-08-01T00:11:55.562725: step 3793, loss 0.598681.
Train: 2018-08-01T00:11:55.718937: step 3794, loss 0.616442.
Train: 2018-08-01T00:11:55.875151: step 3795, loss 0.580446.
Train: 2018-08-01T00:11:56.031364: step 3796, loss 0.615902.
Train: 2018-08-01T00:11:56.187582: step 3797, loss 0.615614.
Train: 2018-08-01T00:11:56.343788: step 3798, loss 0.474419.
Train: 2018-08-01T00:11:56.500012: step 3799, loss 0.509804.
Train: 2018-08-01T00:11:56.656187: step 3800, loss 0.544935.
Test: 2018-08-01T00:11:57.124828: step 3800, loss 0.547803.
Train: 2018-08-01T00:11:57.937169: step 3801, loss 0.649797.
Train: 2018-08-01T00:11:58.124628: step 3802, loss 0.57984.
Train: 2018-08-01T00:11:58.296458: step 3803, loss 0.475598.
Train: 2018-08-01T00:11:58.452672: step 3804, loss 0.631749.
Train: 2018-08-01T00:11:58.608855: step 3805, loss 0.579695.
Train: 2018-08-01T00:11:58.765094: step 3806, loss 0.579647.
Train: 2018-08-01T00:11:58.921312: step 3807, loss 0.596804.
Train: 2018-08-01T00:11:59.077526: step 3808, loss 0.596706.
Train: 2018-08-01T00:11:59.233710: step 3809, loss 0.528193.
Train: 2018-08-01T00:11:59.389953: step 3810, loss 0.61359.
Test: 2018-08-01T00:11:59.874214: step 3810, loss 0.548155.
Train: 2018-08-01T00:12:00.046019: step 3811, loss 0.562404.
Train: 2018-08-01T00:12:00.202262: step 3812, loss 0.562409.
Train: 2018-08-01T00:12:00.358477: step 3813, loss 0.528543.
Train: 2018-08-01T00:12:00.514683: step 3814, loss 0.477861.
Train: 2018-08-01T00:12:00.686523: step 3815, loss 0.545506.
Train: 2018-08-01T00:12:00.842706: step 3816, loss 0.630095.
Train: 2018-08-01T00:12:00.998958: step 3817, loss 0.511695.
Train: 2018-08-01T00:12:01.155170: step 3818, loss 0.579331.
Train: 2018-08-01T00:12:01.311347: step 3819, loss 0.596244.
Train: 2018-08-01T00:12:01.451970: step 3820, loss 0.56242.
Test: 2018-08-01T00:12:01.936231: step 3820, loss 0.548272.
Train: 2018-08-01T00:12:02.092415: step 3821, loss 0.613116.
Train: 2018-08-01T00:12:02.248628: step 3822, loss 0.646825.
Train: 2018-08-01T00:12:02.404872: step 3823, loss 0.478222.
Train: 2018-08-01T00:12:02.561054: step 3824, loss 0.511941.
Train: 2018-08-01T00:12:02.717298: step 3825, loss 0.646619.
Train: 2018-08-01T00:12:02.873482: step 3826, loss 0.461518.
Train: 2018-08-01T00:12:03.029728: step 3827, loss 0.562436.
Train: 2018-08-01T00:12:03.201560: step 3828, loss 0.629816.
Train: 2018-08-01T00:12:03.357743: step 3829, loss 0.511914.
Train: 2018-08-01T00:12:03.513988: step 3830, loss 0.663532.
Test: 2018-08-01T00:12:03.982626: step 3830, loss 0.548341.
Train: 2018-08-01T00:12:04.138810: step 3831, loss 0.579269.
Train: 2018-08-01T00:12:04.295055: step 3832, loss 0.528812.
Train: 2018-08-01T00:12:04.451268: step 3833, loss 0.545635.
Train: 2018-08-01T00:12:04.607480: step 3834, loss 0.495213.
Train: 2018-08-01T00:12:04.763663: step 3835, loss 0.528786.
Train: 2018-08-01T00:12:04.919902: step 3836, loss 0.49502.
Train: 2018-08-01T00:12:05.076124: step 3837, loss 0.545526.
Train: 2018-08-01T00:12:05.247956: step 3838, loss 0.596294.
Train: 2018-08-01T00:12:05.404169: step 3839, loss 0.562409.
Train: 2018-08-01T00:12:05.560383: step 3840, loss 0.562405.
Test: 2018-08-01T00:12:06.044643: step 3840, loss 0.548145.
Train: 2018-08-01T00:12:06.200858: step 3841, loss 0.681589.
Train: 2018-08-01T00:12:06.357041: step 3842, loss 0.528363.
Train: 2018-08-01T00:12:06.513285: step 3843, loss 0.579426.
Train: 2018-08-01T00:12:06.669492: step 3844, loss 0.528359.
Train: 2018-08-01T00:12:06.825681: step 3845, loss 0.545371.
Train: 2018-08-01T00:12:06.981895: step 3846, loss 0.528315.
Train: 2018-08-01T00:12:07.138108: step 3847, loss 0.647717.
Train: 2018-08-01T00:12:07.294321: step 3848, loss 0.545339.
Train: 2018-08-01T00:12:07.450565: step 3849, loss 0.511214.
Train: 2018-08-01T00:12:07.606747: step 3850, loss 0.562398.
Test: 2018-08-01T00:12:08.075418: step 3850, loss 0.548086.
Train: 2018-08-01T00:12:08.247253: step 3851, loss 0.682033.
Train: 2018-08-01T00:12:08.403467: step 3852, loss 0.425819.
Train: 2018-08-01T00:12:08.559649: step 3853, loss 0.562398.
Train: 2018-08-01T00:12:08.715893: step 3854, loss 0.630834.
Train: 2018-08-01T00:12:08.872115: step 3855, loss 0.562397.
Train: 2018-08-01T00:12:09.028316: step 3856, loss 0.562397.
Train: 2018-08-01T00:12:09.184534: step 3857, loss 0.562397.
Train: 2018-08-01T00:12:09.356339: step 3858, loss 0.596605.
Train: 2018-08-01T00:12:09.512552: step 3859, loss 0.545303.
Train: 2018-08-01T00:12:09.653143: step 3860, loss 0.630761.
Test: 2018-08-01T00:12:10.137432: step 3860, loss 0.548105.
Train: 2018-08-01T00:12:10.293649: step 3861, loss 0.562399.
Train: 2018-08-01T00:12:10.465484: step 3862, loss 0.511246.
Train: 2018-08-01T00:12:10.621692: step 3863, loss 0.511256.
Train: 2018-08-01T00:12:10.777911: step 3864, loss 0.630636.
Train: 2018-08-01T00:12:10.949716: step 3865, loss 0.630606.
Train: 2018-08-01T00:12:11.105959: step 3866, loss 0.630512.
Train: 2018-08-01T00:12:11.262173: step 3867, loss 0.44349.
Train: 2018-08-01T00:12:11.418356: step 3868, loss 0.596377.
Train: 2018-08-01T00:12:11.574569: step 3869, loss 0.579382.
Train: 2018-08-01T00:12:11.746404: step 3870, loss 0.596329.
Test: 2018-08-01T00:12:12.277529: step 3870, loss 0.548231.
Train: 2018-08-01T00:12:12.464985: step 3871, loss 0.528538.
Train: 2018-08-01T00:12:12.605607: step 3872, loss 0.562416.
Train: 2018-08-01T00:12:12.761827: step 3873, loss 0.528575.
Train: 2018-08-01T00:12:12.933651: step 3874, loss 0.49472.
Train: 2018-08-01T00:12:13.121084: step 3875, loss 0.545468.
Train: 2018-08-01T00:12:13.277298: step 3876, loss 0.732106.
Train: 2018-08-01T00:12:13.480374: step 3877, loss 0.545465.
Train: 2018-08-01T00:12:13.652209: step 3878, loss 0.596282.
Train: 2018-08-01T00:12:13.808421: step 3879, loss 0.596243.
Train: 2018-08-01T00:12:13.964637: step 3880, loss 0.596194.
Test: 2018-08-01T00:12:14.464544: step 3880, loss 0.54832.
Train: 2018-08-01T00:12:14.651974: step 3881, loss 0.579284.
Train: 2018-08-01T00:12:14.808216: step 3882, loss 0.56244.
Train: 2018-08-01T00:12:14.964432: step 3883, loss 0.562447.
Train: 2018-08-01T00:12:15.120613: step 3884, loss 0.595989.
Train: 2018-08-01T00:12:15.276826: step 3885, loss 0.545725.
Train: 2018-08-01T00:12:15.448662: step 3886, loss 0.56247.
Train: 2018-08-01T00:12:15.620496: step 3887, loss 0.512374.
Train: 2018-08-01T00:12:15.839200: step 3888, loss 0.529075.
Train: 2018-08-01T00:12:15.979813: step 3889, loss 0.495629.
Train: 2018-08-01T00:12:16.151646: step 3890, loss 0.579203.
Test: 2018-08-01T00:12:16.620261: step 3890, loss 0.54842.
Train: 2018-08-01T00:12:16.792100: step 3891, loss 0.51217.
Train: 2018-08-01T00:12:17.010798: step 3892, loss 0.512054.
Train: 2018-08-01T00:12:17.213876: step 3893, loss 0.528747.
Train: 2018-08-01T00:12:17.370117: step 3894, loss 0.477947.
Train: 2018-08-01T00:12:17.526301: step 3895, loss 0.630269.
Train: 2018-08-01T00:12:17.682546: step 3896, loss 0.562404.
Train: 2018-08-01T00:12:17.838729: step 3897, loss 0.579452.
Train: 2018-08-01T00:12:18.026183: step 3898, loss 0.647822.
Train: 2018-08-01T00:12:18.166776: step 3899, loss 0.596583.
Train: 2018-08-01T00:12:18.354232: step 3900, loss 0.459852.
Test: 2018-08-01T00:12:18.822901: step 3900, loss 0.548063.
Train: 2018-08-01T00:12:19.588317: step 3901, loss 0.630862.
Train: 2018-08-01T00:12:19.744561: step 3902, loss 0.476788.
Train: 2018-08-01T00:12:19.900770: step 3903, loss 0.613842.
Train: 2018-08-01T00:12:20.056982: step 3904, loss 0.648196.
Train: 2018-08-01T00:12:20.213202: step 3905, loss 0.528101.
Train: 2018-08-01T00:12:20.369409: step 3906, loss 0.528105.
Train: 2018-08-01T00:12:20.525598: step 3907, loss 0.596701.
Train: 2018-08-01T00:12:20.697433: step 3908, loss 0.579546.
Train: 2018-08-01T00:12:20.869268: step 3909, loss 0.545253.
Train: 2018-08-01T00:12:21.025481: step 3910, loss 0.562396.
Test: 2018-08-01T00:12:21.509773: step 3910, loss 0.548043.
Train: 2018-08-01T00:12:21.665957: step 3911, loss 0.579536.
Train: 2018-08-01T00:12:21.869033: step 3912, loss 0.510992.
Train: 2018-08-01T00:12:22.025282: step 3913, loss 0.635539.
Train: 2018-08-01T00:12:22.181485: step 3914, loss 0.579528.
Train: 2018-08-01T00:12:22.337698: step 3915, loss 0.425462.
Train: 2018-08-01T00:12:22.509539: step 3916, loss 0.579535.
Train: 2018-08-01T00:12:22.665752: step 3917, loss 0.596707.
Train: 2018-08-01T00:12:22.853181: step 3918, loss 0.545235.
Train: 2018-08-01T00:12:22.993769: step 3919, loss 0.562396.
Train: 2018-08-01T00:12:23.165606: step 3920, loss 0.545217.
Test: 2018-08-01T00:12:23.649896: step 3920, loss 0.548001.
Train: 2018-08-01T00:12:23.821702: step 3921, loss 0.545206.
Train: 2018-08-01T00:12:23.977915: step 3922, loss 0.579602.
Train: 2018-08-01T00:12:24.149780: step 3923, loss 0.562397.
Train: 2018-08-01T00:12:24.368448: step 3924, loss 0.51073.
Train: 2018-08-01T00:12:24.524662: step 3925, loss 0.510671.
Train: 2018-08-01T00:12:24.680875: step 3926, loss 0.527853.
Train: 2018-08-01T00:12:24.852710: step 3927, loss 0.648959.
Train: 2018-08-01T00:12:25.008954: step 3928, loss 0.545085.
Train: 2018-08-01T00:12:25.165167: step 3929, loss 0.649078.
Train: 2018-08-01T00:12:25.321374: step 3930, loss 0.562406.
Test: 2018-08-01T00:12:25.805641: step 3930, loss 0.547908.
Train: 2018-08-01T00:12:25.961851: step 3931, loss 0.527781.
Train: 2018-08-01T00:12:26.118069: step 3932, loss 0.666271.
Train: 2018-08-01T00:12:26.274277: step 3933, loss 0.493271.
Train: 2018-08-01T00:12:26.446118: step 3934, loss 0.527852.
Train: 2018-08-01T00:12:26.602330: step 3935, loss 0.545125.
Train: 2018-08-01T00:12:26.758549: step 3936, loss 0.614245.
Train: 2018-08-01T00:12:26.914753: step 3937, loss 0.545129.
Train: 2018-08-01T00:12:27.070940: step 3938, loss 0.49333.
Train: 2018-08-01T00:12:27.227200: step 3939, loss 0.562402.
Train: 2018-08-01T00:12:27.383402: step 3940, loss 0.510523.
Test: 2018-08-01T00:12:27.852037: step 3940, loss 0.547905.
Train: 2018-08-01T00:12:28.008251: step 3941, loss 0.59704.
Train: 2018-08-01T00:12:28.164435: step 3942, loss 0.562407.
Train: 2018-08-01T00:12:28.336268: step 3943, loss 0.54507.
Train: 2018-08-01T00:12:28.492481: step 3944, loss 0.527707.
Train: 2018-08-01T00:12:28.648695: step 3945, loss 0.614529.
Train: 2018-08-01T00:12:28.804934: step 3946, loss 0.545039.
Train: 2018-08-01T00:12:28.961122: step 3947, loss 0.510267.
Train: 2018-08-01T00:12:29.132988: step 3948, loss 0.527615.
Train: 2018-08-01T00:12:29.289204: step 3949, loss 0.544997.
Train: 2018-08-01T00:12:29.445414: step 3950, loss 0.527523.
Test: 2018-08-01T00:12:29.929648: step 3950, loss 0.547795.
Train: 2018-08-01T00:12:30.117102: step 3951, loss 0.405071.
Train: 2018-08-01T00:12:30.273317: step 3952, loss 0.474692.
Train: 2018-08-01T00:12:30.429532: step 3953, loss 0.633022.
Train: 2018-08-01T00:12:30.601393: step 3954, loss 0.615571.
Train: 2018-08-01T00:12:30.773223: step 3955, loss 0.597963.
Train: 2018-08-01T00:12:30.929411: step 3956, loss 0.562527.
Train: 2018-08-01T00:12:31.085625: step 3957, loss 0.527019.
Train: 2018-08-01T00:12:31.257460: step 3958, loss 0.580321.
Train: 2018-08-01T00:12:31.413703: step 3959, loss 0.562549.
Train: 2018-08-01T00:12:31.569911: step 3960, loss 0.59815.
Test: 2018-08-01T00:12:32.038527: step 3960, loss 0.54765.
Train: 2018-08-01T00:12:32.194740: step 3961, loss 0.687117.
Train: 2018-08-01T00:12:32.350984: step 3962, loss 0.562534.
Train: 2018-08-01T00:12:32.507191: step 3963, loss 0.491624.
Train: 2018-08-01T00:12:32.663410: step 3964, loss 0.597928.
Train: 2018-08-01T00:12:32.835248: step 3965, loss 0.615552.
Train: 2018-08-01T00:12:32.991428: step 3966, loss 0.650717.
Train: 2018-08-01T00:12:33.147673: step 3967, loss 0.544879.
Train: 2018-08-01T00:12:33.303886: step 3968, loss 0.544913.
Train: 2018-08-01T00:12:33.460093: step 3969, loss 0.667428.
Train: 2018-08-01T00:12:33.631903: step 3970, loss 0.614724.
Test: 2018-08-01T00:12:34.116165: step 3970, loss 0.547875.
Train: 2018-08-01T00:12:34.272379: step 3971, loss 0.44089.
Train: 2018-08-01T00:12:34.428605: step 3972, loss 0.545081.
Train: 2018-08-01T00:12:34.584836: step 3973, loss 0.579701.
Train: 2018-08-01T00:12:34.756667: step 3974, loss 0.614205.
Train: 2018-08-01T00:12:34.928477: step 3975, loss 0.614081.
Train: 2018-08-01T00:12:35.084689: step 3976, loss 0.665461.
Train: 2018-08-01T00:12:35.240902: step 3977, loss 0.47687.
Train: 2018-08-01T00:12:35.397147: step 3978, loss 0.511209.
Train: 2018-08-01T00:12:35.553359: step 3979, loss 0.562401.
Train: 2018-08-01T00:12:35.725195: step 3980, loss 0.511351.
Test: 2018-08-01T00:12:36.193806: step 3980, loss 0.548158.
Train: 2018-08-01T00:12:36.350048: step 3981, loss 0.562404.
Train: 2018-08-01T00:12:36.521877: step 3982, loss 0.59642.
Train: 2018-08-01T00:12:36.678095: step 3983, loss 0.528415.
Train: 2018-08-01T00:12:36.834309: step 3984, loss 0.5794.
Train: 2018-08-01T00:12:36.990523: step 3985, loss 0.562407.
Train: 2018-08-01T00:12:37.146736: step 3986, loss 0.545423.
Train: 2018-08-01T00:12:37.302918: step 3987, loss 0.528437.
Train: 2018-08-01T00:12:37.459132: step 3988, loss 0.477426.
Train: 2018-08-01T00:12:37.630967: step 3989, loss 0.545374.
Train: 2018-08-01T00:12:37.787211: step 3990, loss 0.511211.
Test: 2018-08-01T00:12:38.255847: step 3990, loss 0.548071.
Train: 2018-08-01T00:12:38.427659: step 3991, loss 0.545289.
Train: 2018-08-01T00:12:38.599493: step 3992, loss 0.562396.
Train: 2018-08-01T00:12:38.755704: step 3993, loss 0.579589.
Train: 2018-08-01T00:12:38.911917: step 3994, loss 0.579622.
Train: 2018-08-01T00:12:39.068131: step 3995, loss 0.545151.
Train: 2018-08-01T00:12:39.224345: step 3996, loss 0.562401.
Train: 2018-08-01T00:12:39.380558: step 3997, loss 0.545107.
Train: 2018-08-01T00:12:39.552393: step 3998, loss 0.545085.
Train: 2018-08-01T00:12:39.708636: step 3999, loss 0.701187.
Train: 2018-08-01T00:12:39.864849: step 4000, loss 0.475738.
Test: 2018-08-01T00:12:40.333459: step 4000, loss 0.547886.
Train: 2018-08-01T00:12:41.083310: step 4001, loss 0.579753.
Train: 2018-08-01T00:12:41.239497: step 4002, loss 0.545062.
Train: 2018-08-01T00:12:41.395712: step 4003, loss 0.562411.
Train: 2018-08-01T00:12:41.551955: step 4004, loss 0.527691.
Train: 2018-08-01T00:12:41.723759: step 4005, loss 0.579788.
Train: 2018-08-01T00:12:41.879973: step 4006, loss 0.545034.
Train: 2018-08-01T00:12:42.036215: step 4007, loss 0.527635.
Train: 2018-08-01T00:12:42.208061: step 4008, loss 0.545012.
Train: 2018-08-01T00:12:42.379855: step 4009, loss 0.579851.
Train: 2018-08-01T00:12:42.536068: step 4010, loss 0.597305.
Test: 2018-08-01T00:12:43.020355: step 4010, loss 0.547823.
Train: 2018-08-01T00:12:43.176543: step 4011, loss 0.649625.
Train: 2018-08-01T00:12:43.348378: step 4012, loss 0.475338.
Train: 2018-08-01T00:12:43.535836: step 4013, loss 0.614675.
Train: 2018-08-01T00:12:43.692048: step 4014, loss 0.579823.
Train: 2018-08-01T00:12:43.848263: step 4015, loss 0.545029.
Train: 2018-08-01T00:12:44.004475: step 4016, loss 0.631912.
Train: 2018-08-01T00:12:44.160689: step 4017, loss 0.597099.
Train: 2018-08-01T00:12:44.316932: step 4018, loss 0.545096.
Train: 2018-08-01T00:12:44.473114: step 4019, loss 0.545122.
Train: 2018-08-01T00:12:44.629328: step 4020, loss 0.614173.
Test: 2018-08-01T00:12:45.097969: step 4020, loss 0.547974.
Train: 2018-08-01T00:12:45.254213: step 4021, loss 0.476276.
Train: 2018-08-01T00:12:45.426047: step 4022, loss 0.476315.
Train: 2018-08-01T00:12:45.582261: step 4023, loss 0.527934.
Train: 2018-08-01T00:12:45.738474: step 4024, loss 0.614162.
Train: 2018-08-01T00:12:45.894658: step 4025, loss 0.476097.
Train: 2018-08-01T00:12:46.050870: step 4026, loss 0.683423.
Train: 2018-08-01T00:12:46.207083: step 4027, loss 0.596965.
Train: 2018-08-01T00:12:46.363298: step 4028, loss 0.665997.
Train: 2018-08-01T00:12:46.535162: step 4029, loss 0.579622.
Train: 2018-08-01T00:12:46.691346: step 4030, loss 0.510848.
Test: 2018-08-01T00:12:47.160016: step 4030, loss 0.548028.
Train: 2018-08-01T00:12:47.316229: step 4031, loss 0.562396.
Train: 2018-08-01T00:12:47.472413: step 4032, loss 0.528123.
Train: 2018-08-01T00:12:47.644278: step 4033, loss 0.51102.
Train: 2018-08-01T00:12:47.800491: step 4034, loss 0.579526.
Train: 2018-08-01T00:12:47.956705: step 4035, loss 0.613782.
Train: 2018-08-01T00:12:48.112913: step 4036, loss 0.545282.
Train: 2018-08-01T00:12:48.269132: step 4037, loss 0.59661.
Train: 2018-08-01T00:12:48.425345: step 4038, loss 0.596578.
Train: 2018-08-01T00:12:48.581558: step 4039, loss 0.6648.
Train: 2018-08-01T00:12:48.753394: step 4040, loss 0.562403.
Test: 2018-08-01T00:12:49.237654: step 4040, loss 0.548192.
Train: 2018-08-01T00:12:49.393869: step 4041, loss 0.511478.
Train: 2018-08-01T00:12:49.550081: step 4042, loss 0.494602.
Train: 2018-08-01T00:12:49.706289: step 4043, loss 0.443765.
Train: 2018-08-01T00:12:49.878141: step 4044, loss 0.460533.
Train: 2018-08-01T00:12:50.034312: step 4045, loss 0.477234.
Train: 2018-08-01T00:12:50.190556: step 4046, loss 0.613712.
Train: 2018-08-01T00:12:50.362363: step 4047, loss 0.528083.
Train: 2018-08-01T00:12:50.502984: step 4048, loss 0.527974.
Train: 2018-08-01T00:12:50.674818: step 4049, loss 0.51059.
Train: 2018-08-01T00:12:50.831031: step 4050, loss 0.510401.
Test: 2018-08-01T00:12:51.299668: step 4050, loss 0.547843.
Train: 2018-08-01T00:12:51.455885: step 4051, loss 0.527604.
Train: 2018-08-01T00:12:51.612098: step 4052, loss 0.63236.
Train: 2018-08-01T00:12:51.768312: step 4053, loss 0.527393.
Train: 2018-08-01T00:12:51.924525: step 4054, loss 0.544886.
Train: 2018-08-01T00:12:52.096354: step 4055, loss 0.474355.
Train: 2018-08-01T00:12:52.252579: step 4056, loss 0.544815.
Train: 2018-08-01T00:12:52.408792: step 4057, loss 0.580279.
Train: 2018-08-01T00:12:52.549373: step 4058, loss 0.544755.
Train: 2018-08-01T00:12:52.721214: step 4059, loss 0.526891.
Train: 2018-08-01T00:12:52.877397: step 4060, loss 0.491043.
Test: 2018-08-01T00:12:53.346039: step 4060, loss 0.547605.
Train: 2018-08-01T00:12:53.517873: step 4061, loss 0.580582.
Train: 2018-08-01T00:12:53.674116: step 4062, loss 0.544669.
Train: 2018-08-01T00:12:53.830300: step 4063, loss 0.544654.
Train: 2018-08-01T00:12:54.002158: step 4064, loss 0.562717.
Train: 2018-08-01T00:12:54.158378: step 4065, loss 0.56274.
Train: 2018-08-01T00:12:54.314590: step 4066, loss 0.435824.
Train: 2018-08-01T00:12:54.486396: step 4067, loss 0.544613.
Train: 2018-08-01T00:12:54.642640: step 4068, loss 0.635767.
Train: 2018-08-01T00:12:54.814448: step 4069, loss 0.526345.
Train: 2018-08-01T00:12:54.970688: step 4070, loss 0.581151.
Test: 2018-08-01T00:12:55.451000: step 4070, loss 0.547568.
Train: 2018-08-01T00:12:55.607248: step 4071, loss 0.50801.
Train: 2018-08-01T00:12:55.779049: step 4072, loss 0.54459.
Train: 2018-08-01T00:12:55.935293: step 4073, loss 0.617923.
Train: 2018-08-01T00:12:56.107121: step 4074, loss 0.471251.
Train: 2018-08-01T00:12:56.263310: step 4075, loss 0.489525.
Train: 2018-08-01T00:12:56.419523: step 4076, loss 0.452659.
Train: 2018-08-01T00:12:56.575737: step 4077, loss 0.563016.
Train: 2018-08-01T00:12:56.747602: step 4078, loss 0.581534.
Train: 2018-08-01T00:12:56.919437: step 4079, loss 0.526073.
Train: 2018-08-01T00:12:57.075636: step 4080, loss 0.414828.
Test: 2018-08-01T00:12:57.544261: step 4080, loss 0.547607.
Train: 2018-08-01T00:12:57.700499: step 4081, loss 0.656151.
Train: 2018-08-01T00:12:57.872314: step 4082, loss 0.544586.
Train: 2018-08-01T00:12:58.028552: step 4083, loss 0.675082.
Train: 2018-08-01T00:12:58.200382: step 4084, loss 0.563217.
Train: 2018-08-01T00:12:58.356571: step 4085, loss 0.544585.
Train: 2018-08-01T00:12:58.512815: step 4086, loss 0.581782.
Train: 2018-08-01T00:12:58.684647: step 4087, loss 0.526006.
Train: 2018-08-01T00:12:58.887697: step 4088, loss 0.693062.
Train: 2018-08-01T00:12:59.059532: step 4089, loss 0.618616.
Train: 2018-08-01T00:12:59.215769: step 4090, loss 0.655252.
Test: 2018-08-01T00:12:59.684414: step 4090, loss 0.547571.
Train: 2018-08-01T00:12:59.856252: step 4091, loss 0.507863.
Train: 2018-08-01T00:13:00.012463: step 4092, loss 0.562887.
Train: 2018-08-01T00:13:00.184291: step 4093, loss 0.708679.
Train: 2018-08-01T00:13:00.340480: step 4094, loss 0.562759.
Train: 2018-08-01T00:13:00.496695: step 4095, loss 0.652911.
Train: 2018-08-01T00:13:00.668529: step 4096, loss 0.562627.
Train: 2018-08-01T00:13:00.824773: step 4097, loss 0.598247.
Train: 2018-08-01T00:13:00.980980: step 4098, loss 0.52705.
Train: 2018-08-01T00:13:01.137201: step 4099, loss 0.633105.
Train: 2018-08-01T00:13:01.309028: step 4100, loss 0.650252.
Test: 2018-08-01T00:13:01.777650: step 4100, loss 0.547816.
Train: 2018-08-01T00:13:02.543120: step 4101, loss 0.789277.
Train: 2018-08-01T00:13:02.699337: step 4102, loss 0.614283.
Train: 2018-08-01T00:13:02.855551: step 4103, loss 0.613812.
Train: 2018-08-01T00:13:03.027352: step 4104, loss 0.545421.
Train: 2018-08-01T00:13:03.183565: step 4105, loss 0.612992.
Train: 2018-08-01T00:13:03.339777: step 4106, loss 0.646079.
Train: 2018-08-01T00:13:03.480395: step 4107, loss 0.612272.
Train: 2018-08-01T00:13:03.636584: step 4108, loss 0.529699.
Train: 2018-08-01T00:13:03.808448: step 4109, loss 0.529988.
Train: 2018-08-01T00:13:03.964631: step 4110, loss 0.448996.
Test: 2018-08-01T00:13:04.448921: step 4110, loss 0.549184.
Train: 2018-08-01T00:13:04.605141: step 4111, loss 0.595152.
Train: 2018-08-01T00:13:04.776942: step 4112, loss 0.643558.
Train: 2018-08-01T00:13:04.933186: step 4113, loss 0.562835.
Train: 2018-08-01T00:13:05.089369: step 4114, loss 0.498706.
Train: 2018-08-01T00:13:05.261203: step 4115, loss 0.610956.
Train: 2018-08-01T00:13:05.417447: step 4116, loss 0.530951.
Train: 2018-08-01T00:13:05.573663: step 4117, loss 0.690726.
Train: 2018-08-01T00:13:05.729843: step 4118, loss 0.49927.
Train: 2018-08-01T00:13:05.901705: step 4119, loss 0.547091.
Train: 2018-08-01T00:13:06.057923: step 4120, loss 0.578911.
Test: 2018-08-01T00:13:06.526532: step 4120, loss 0.549705.
Train: 2018-08-01T00:13:06.682746: step 4121, loss 0.499434.
Train: 2018-08-01T00:13:06.854613: step 4122, loss 0.531177.
Train: 2018-08-01T00:13:07.010794: step 4123, loss 0.547034.
Train: 2018-08-01T00:13:07.167038: step 4124, loss 0.515023.
Train: 2018-08-01T00:13:07.338843: step 4125, loss 0.450755.
Train: 2018-08-01T00:13:07.495055: step 4126, loss 0.514536.
Train: 2018-08-01T00:13:07.651299: step 4127, loss 0.530391.
Train: 2018-08-01T00:13:07.854346: step 4128, loss 0.578973.
Train: 2018-08-01T00:13:08.026183: step 4129, loss 0.595357.
Train: 2018-08-01T00:13:08.198016: step 4130, loss 0.59545.
Test: 2018-08-01T00:13:08.666697: step 4130, loss 0.548778.
Train: 2018-08-01T00:13:08.838493: step 4131, loss 0.562575.
Train: 2018-08-01T00:13:09.025947: step 4132, loss 0.562549.
Train: 2018-08-01T00:13:09.197783: step 4133, loss 0.545953.
Train: 2018-08-01T00:13:09.369646: step 4134, loss 0.595752.
Train: 2018-08-01T00:13:09.525829: step 4135, loss 0.595812.
Train: 2018-08-01T00:13:09.682043: step 4136, loss 0.662601.
Train: 2018-08-01T00:13:09.838286: step 4137, loss 0.545796.
Train: 2018-08-01T00:13:09.994500: step 4138, loss 0.57917.
Train: 2018-08-01T00:13:10.150714: step 4139, loss 0.629245.
Train: 2018-08-01T00:13:10.322543: step 4140, loss 0.662543.
Test: 2018-08-01T00:13:10.806810: step 4140, loss 0.548568.
Train: 2018-08-01T00:13:10.978616: step 4141, loss 0.579138.
Train: 2018-08-01T00:13:11.166070: step 4142, loss 0.529314.
Train: 2018-08-01T00:13:11.337906: step 4143, loss 0.579103.
Train: 2018-08-01T00:13:11.509741: step 4144, loss 0.545981.
Train: 2018-08-01T00:13:11.681576: step 4145, loss 0.645245.
Train: 2018-08-01T00:13:11.853410: step 4146, loss 0.595574.
Train: 2018-08-01T00:13:12.009623: step 4147, loss 0.463751.
Train: 2018-08-01T00:13:12.197103: step 4148, loss 0.661385.
Train: 2018-08-01T00:13:12.353348: step 4149, loss 0.611915.
Train: 2018-08-01T00:13:12.509530: step 4150, loss 0.464188.
Test: 2018-08-01T00:13:12.993768: step 4150, loss 0.548882.
Train: 2018-08-01T00:13:13.165604: step 4151, loss 0.480608.
Train: 2018-08-01T00:13:13.321818: step 4152, loss 0.546179.
Train: 2018-08-01T00:13:13.493680: step 4153, loss 0.496783.
Train: 2018-08-01T00:13:13.649896: step 4154, loss 0.579061.
Train: 2018-08-01T00:13:13.821699: step 4155, loss 0.496409.
Train: 2018-08-01T00:13:13.977912: step 4156, loss 0.512755.
Train: 2018-08-01T00:13:14.134126: step 4157, loss 0.612452.
Train: 2018-08-01T00:13:14.290339: step 4158, loss 0.612573.
Train: 2018-08-01T00:13:14.446552: step 4159, loss 0.545738.
Train: 2018-08-01T00:13:14.618411: step 4160, loss 0.595978.
Test: 2018-08-01T00:13:15.087060: step 4160, loss 0.548396.
Train: 2018-08-01T00:13:15.243270: step 4161, loss 0.579233.
Train: 2018-08-01T00:13:15.399484: step 4162, loss 0.528846.
Train: 2018-08-01T00:13:15.571289: step 4163, loss 0.629737.
Train: 2018-08-01T00:13:15.711911: step 4164, loss 0.528776.
Train: 2018-08-01T00:13:15.883745: step 4165, loss 0.49505.
Train: 2018-08-01T00:13:16.039929: step 4166, loss 0.629939.
Train: 2018-08-01T00:13:16.196173: step 4167, loss 0.562423.
Train: 2018-08-01T00:13:16.352356: step 4168, loss 0.61313.
Train: 2018-08-01T00:13:16.508605: step 4169, loss 0.562421.
Train: 2018-08-01T00:13:16.664782: step 4170, loss 0.630025.
Test: 2018-08-01T00:13:17.149074: step 4170, loss 0.548286.
Train: 2018-08-01T00:13:17.305288: step 4171, loss 0.528657.
Train: 2018-08-01T00:13:17.477093: step 4172, loss 0.444281.
Train: 2018-08-01T00:13:17.633337: step 4173, loss 0.494801.
Train: 2018-08-01T00:13:17.789550: step 4174, loss 0.630204.
Train: 2018-08-01T00:13:17.945763: step 4175, loss 0.596348.
Train: 2018-08-01T00:13:18.117569: step 4176, loss 0.579388.
Train: 2018-08-01T00:13:18.258190: step 4177, loss 0.511447.
Train: 2018-08-01T00:13:18.429996: step 4178, loss 0.511386.
Train: 2018-08-01T00:13:18.586207: step 4179, loss 0.596476.
Train: 2018-08-01T00:13:18.742446: step 4180, loss 0.511227.
Test: 2018-08-01T00:13:19.211077: step 4180, loss 0.548087.
Train: 2018-08-01T00:13:19.382926: step 4181, loss 0.630753.
Train: 2018-08-01T00:13:19.539139: step 4182, loss 0.545297.
Train: 2018-08-01T00:13:19.695323: step 4183, loss 0.545282.
Train: 2018-08-01T00:13:19.851571: step 4184, loss 0.528133.
Train: 2018-08-01T00:13:20.007783: step 4185, loss 0.596709.
Train: 2018-08-01T00:13:20.163987: step 4186, loss 0.596736.
Train: 2018-08-01T00:13:20.320201: step 4187, loss 0.613915.
Train: 2018-08-01T00:13:20.476415: step 4188, loss 0.510909.
Train: 2018-08-01T00:13:20.648255: step 4189, loss 0.579562.
Train: 2018-08-01T00:13:20.804468: step 4190, loss 0.665386.
Test: 2018-08-01T00:13:21.257458: step 4190, loss 0.548046.
Train: 2018-08-01T00:13:21.413701: step 4191, loss 0.613807.
Train: 2018-08-01T00:13:21.585507: step 4192, loss 0.5282.
Train: 2018-08-01T00:13:21.741755: step 4193, loss 0.545325.
Train: 2018-08-01T00:13:21.897962: step 4194, loss 0.545345.
Train: 2018-08-01T00:13:22.054145: step 4195, loss 0.528314.
Train: 2018-08-01T00:13:22.210389: step 4196, loss 0.698741.
Train: 2018-08-01T00:13:22.382194: step 4197, loss 0.477373.
Train: 2018-08-01T00:13:22.538433: step 4198, loss 0.511416.
Train: 2018-08-01T00:13:22.694620: step 4199, loss 0.477397.
Train: 2018-08-01T00:13:22.850868: step 4200, loss 0.613489.
Test: 2018-08-01T00:13:23.335125: step 4200, loss 0.548131.
Train: 2018-08-01T00:13:24.084950: step 4201, loss 0.647605.
Train: 2018-08-01T00:13:24.256755: step 4202, loss 0.460225.
Train: 2018-08-01T00:13:24.412998: step 4203, loss 0.460121.
Train: 2018-08-01T00:13:24.569213: step 4204, loss 0.579486.
Train: 2018-08-01T00:13:24.725396: step 4205, loss 0.476781.
Train: 2018-08-01T00:13:24.881608: step 4206, loss 0.562396.
Train: 2018-08-01T00:13:25.037856: step 4207, loss 0.579621.
Train: 2018-08-01T00:13:25.209691: step 4208, loss 0.545138.
Train: 2018-08-01T00:13:25.365900: step 4209, loss 0.631605.
Train: 2018-08-01T00:13:25.522083: step 4210, loss 0.579722.
Test: 2018-08-01T00:13:26.006375: step 4210, loss 0.547898.
Train: 2018-08-01T00:13:26.162588: step 4211, loss 0.527754.
Train: 2018-08-01T00:13:26.334424: step 4212, loss 0.562409.
Train: 2018-08-01T00:13:26.490637: step 4213, loss 0.614485.
Train: 2018-08-01T00:13:26.646850: step 4214, loss 0.59944.
Train: 2018-08-01T00:13:26.818685: step 4215, loss 0.510371.
Train: 2018-08-01T00:13:26.974870: step 4216, loss 0.545061.
Train: 2018-08-01T00:13:27.146727: step 4217, loss 0.5277.
Train: 2018-08-01T00:13:27.302944: step 4218, loss 0.527674.
Train: 2018-08-01T00:13:27.459160: step 4219, loss 0.510246.
Train: 2018-08-01T00:13:27.630996: step 4220, loss 0.545001.
Test: 2018-08-01T00:13:28.099604: step 4220, loss 0.547814.
Train: 2018-08-01T00:13:28.255850: step 4221, loss 0.562429.
Train: 2018-08-01T00:13:28.412068: step 4222, loss 0.544955.
Train: 2018-08-01T00:13:28.568245: step 4223, loss 0.544934.
Train: 2018-08-01T00:13:28.724492: step 4224, loss 0.492299.
Train: 2018-08-01T00:13:28.880672: step 4225, loss 0.615207.
Train: 2018-08-01T00:13:29.036885: step 4226, loss 0.456848.
Train: 2018-08-01T00:13:29.193098: step 4227, loss 0.544838.
Train: 2018-08-01T00:13:29.349312: step 4228, loss 0.474032.
Train: 2018-08-01T00:13:29.505526: step 4229, loss 0.562533.
Train: 2018-08-01T00:13:29.661739: step 4230, loss 0.562558.
Test: 2018-08-01T00:13:30.146026: step 4230, loss 0.547631.
Train: 2018-08-01T00:13:30.302215: step 4231, loss 0.633994.
Train: 2018-08-01T00:13:30.442838: step 4232, loss 0.616212.
Train: 2018-08-01T00:13:30.614671: step 4233, loss 0.508965.
Train: 2018-08-01T00:13:30.770855: step 4234, loss 0.473155.
Train: 2018-08-01T00:13:30.927098: step 4235, loss 0.59846.
Train: 2018-08-01T00:13:31.098903: step 4236, loss 0.598503.
Train: 2018-08-01T00:13:31.255142: step 4237, loss 0.526748.
Train: 2018-08-01T00:13:31.426981: step 4238, loss 0.580587.
Train: 2018-08-01T00:13:31.583192: step 4239, loss 0.562637.
Train: 2018-08-01T00:13:31.739407: step 4240, loss 0.580587.
Test: 2018-08-01T00:13:32.223638: step 4240, loss 0.547606.
Train: 2018-08-01T00:13:32.379852: step 4241, loss 0.562631.
Train: 2018-08-01T00:13:32.551717: step 4242, loss 0.472964.
Train: 2018-08-01T00:13:32.707933: step 4243, loss 0.437032.
Train: 2018-08-01T00:13:32.864145: step 4244, loss 0.67054.
Train: 2018-08-01T00:13:33.035948: step 4245, loss 0.526686.
Train: 2018-08-01T00:13:33.192163: step 4246, loss 0.652644.
Train: 2018-08-01T00:13:33.348400: step 4247, loss 0.616594.
Train: 2018-08-01T00:13:33.504627: step 4248, loss 0.562635.
Train: 2018-08-01T00:13:33.660833: step 4249, loss 0.580536.
Train: 2018-08-01T00:13:33.832670: step 4250, loss 0.598367.
Test: 2018-08-01T00:13:34.301276: step 4250, loss 0.547634.
Train: 2018-08-01T00:13:34.457516: step 4251, loss 0.687472.
Train: 2018-08-01T00:13:34.613735: step 4252, loss 0.491457.
Train: 2018-08-01T00:13:34.769949: step 4253, loss 0.597962.
Train: 2018-08-01T00:13:34.941752: step 4254, loss 0.438825.
Train: 2018-08-01T00:13:35.097999: step 4255, loss 0.580135.
Train: 2018-08-01T00:13:35.254210: step 4256, loss 0.597726.
Train: 2018-08-01T00:13:35.410422: step 4257, loss 0.58006.
Train: 2018-08-01T00:13:35.566638: step 4258, loss 0.5449.
Train: 2018-08-01T00:13:35.722819: step 4259, loss 0.615035.
Train: 2018-08-01T00:13:35.879064: step 4260, loss 0.667369.
Test: 2018-08-01T00:13:36.347707: step 4260, loss 0.547832.
Train: 2018-08-01T00:13:36.503888: step 4261, loss 0.562423.
Train: 2018-08-01T00:13:36.660131: step 4262, loss 0.545047.
Train: 2018-08-01T00:13:36.831935: step 4263, loss 0.493138.
Train: 2018-08-01T00:13:36.988148: step 4264, loss 0.579693.
Train: 2018-08-01T00:13:37.144392: step 4265, loss 0.631444.
Train: 2018-08-01T00:13:37.316226: step 4266, loss 0.631264.
Train: 2018-08-01T00:13:37.472435: step 4267, loss 0.528078.
Train: 2018-08-01T00:13:37.628648: step 4268, loss 0.596627.
Train: 2018-08-01T00:13:37.784868: step 4269, loss 0.630669.
Train: 2018-08-01T00:13:37.941051: step 4270, loss 0.511384.
Test: 2018-08-01T00:13:38.440964: step 4270, loss 0.548202.
Train: 2018-08-01T00:13:38.612768: step 4271, loss 0.511511.
Train: 2018-08-01T00:13:38.769007: step 4272, loss 0.494638.
Train: 2018-08-01T00:13:38.940816: step 4273, loss 0.579356.
Train: 2018-08-01T00:13:39.097030: step 4274, loss 0.6471.
Train: 2018-08-01T00:13:39.253242: step 4275, loss 0.528597.
Train: 2018-08-01T00:13:39.425079: step 4276, loss 0.46104.
Train: 2018-08-01T00:13:39.596913: step 4277, loss 0.477857.
Train: 2018-08-01T00:13:39.753125: step 4278, loss 0.511564.
Train: 2018-08-01T00:13:39.956203: step 4279, loss 0.562406.
Train: 2018-08-01T00:13:40.112417: step 4280, loss 0.613521.
Test: 2018-08-01T00:13:40.581087: step 4280, loss 0.548108.
Train: 2018-08-01T00:13:40.737270: step 4281, loss 0.477069.
Train: 2018-08-01T00:13:40.893514: step 4282, loss 0.562396.
Train: 2018-08-01T00:13:41.049728: step 4283, loss 0.510935.
Train: 2018-08-01T00:13:41.221532: step 4284, loss 0.61401.
Train: 2018-08-01T00:13:41.377776: step 4285, loss 0.579635.
Train: 2018-08-01T00:13:41.533959: step 4286, loss 0.614183.
Train: 2018-08-01T00:13:41.690203: step 4287, loss 0.562401.
Train: 2018-08-01T00:13:41.846386: step 4288, loss 0.527849.
Train: 2018-08-01T00:13:42.002629: step 4289, loss 0.545112.
Train: 2018-08-01T00:13:42.174464: step 4290, loss 0.631636.
Test: 2018-08-01T00:13:42.643104: step 4290, loss 0.547913.
Train: 2018-08-01T00:13:42.799317: step 4291, loss 0.493184.
Train: 2018-08-01T00:13:42.955531: step 4292, loss 0.562406.
Train: 2018-08-01T00:13:43.111739: step 4293, loss 0.597072.
Train: 2018-08-01T00:13:43.283574: step 4294, loss 0.579742.
Train: 2018-08-01T00:13:43.439800: step 4295, loss 0.579738.
Train: 2018-08-01T00:13:43.611630: step 4296, loss 0.527761.
Train: 2018-08-01T00:13:43.767835: step 4297, loss 0.562406.
Train: 2018-08-01T00:13:43.908403: step 4298, loss 0.579731.
Train: 2018-08-01T00:13:44.064641: step 4299, loss 0.597045.
Train: 2018-08-01T00:13:44.220863: step 4300, loss 0.493181.
Test: 2018-08-01T00:13:44.705124: step 4300, loss 0.547909.
Train: 2018-08-01T00:13:45.439295: step 4301, loss 0.614337.
Train: 2018-08-01T00:13:45.595542: step 4302, loss 0.579705.
Train: 2018-08-01T00:13:45.767373: step 4303, loss 0.510539.
Train: 2018-08-01T00:13:45.923557: step 4304, loss 0.579691.
Train: 2018-08-01T00:13:46.079802: step 4305, loss 0.545117.
Train: 2018-08-01T00:13:46.236007: step 4306, loss 0.579687.
Train: 2018-08-01T00:13:46.392197: step 4307, loss 0.458721.
Train: 2018-08-01T00:13:46.548434: step 4308, loss 0.527799.
Train: 2018-08-01T00:13:46.704624: step 4309, loss 0.510414.
Train: 2018-08-01T00:13:46.860867: step 4310, loss 0.510303.
Test: 2018-08-01T00:13:47.345099: step 4310, loss 0.547836.
Train: 2018-08-01T00:13:47.516963: step 4311, loss 0.562422.
Train: 2018-08-01T00:13:47.673146: step 4312, loss 0.649729.
Train: 2018-08-01T00:13:47.844982: step 4313, loss 0.54496.
Train: 2018-08-01T00:13:48.001194: step 4314, loss 0.597418.
Train: 2018-08-01T00:13:48.188653: step 4315, loss 0.562439.
Train: 2018-08-01T00:13:48.376108: step 4316, loss 0.509948.
Train: 2018-08-01T00:13:48.547943: step 4317, loss 0.650005.
Train: 2018-08-01T00:13:48.719802: step 4318, loss 0.719958.
Train: 2018-08-01T00:13:48.891611: step 4319, loss 0.632232.
Train: 2018-08-01T00:13:49.047825: step 4320, loss 0.649345.
Test: 2018-08-01T00:13:49.516465: step 4320, loss 0.547914.
Train: 2018-08-01T00:13:49.688299: step 4321, loss 0.579708.
Train: 2018-08-01T00:13:49.844546: step 4322, loss 0.51072.
Train: 2018-08-01T00:13:50.000756: step 4323, loss 0.648237.
Train: 2018-08-01T00:13:50.156940: step 4324, loss 0.545303.
Train: 2018-08-01T00:13:50.313186: step 4325, loss 0.562402.
Train: 2018-08-01T00:13:50.484987: step 4326, loss 0.664268.
Train: 2018-08-01T00:13:50.641225: step 4327, loss 0.579321.
Train: 2018-08-01T00:13:50.781824: step 4328, loss 0.495125.
Train: 2018-08-01T00:13:50.953629: step 4329, loss 0.528885.
Train: 2018-08-01T00:13:51.109842: step 4330, loss 0.562459.
Test: 2018-08-01T00:13:51.578484: step 4330, loss 0.548463.
Train: 2018-08-01T00:13:51.734719: step 4331, loss 0.612642.
Train: 2018-08-01T00:13:51.890909: step 4332, loss 0.645925.
Train: 2018-08-01T00:13:52.047152: step 4333, loss 0.595772.
Train: 2018-08-01T00:13:52.218996: step 4334, loss 0.595685.
Train: 2018-08-01T00:13:52.375195: step 4335, loss 0.496454.
Train: 2018-08-01T00:13:52.531408: step 4336, loss 0.496592.
Train: 2018-08-01T00:13:52.687621: step 4337, loss 0.595542.
Train: 2018-08-01T00:13:52.859432: step 4338, loss 0.463738.
Train: 2018-08-01T00:13:53.015676: step 4339, loss 0.529586.
Train: 2018-08-01T00:13:53.171860: step 4340, loss 0.529518.
Test: 2018-08-01T00:13:53.640528: step 4340, loss 0.548675.
Train: 2018-08-01T00:13:53.796744: step 4341, loss 0.57909.
Train: 2018-08-01T00:13:53.952951: step 4342, loss 0.512774.
Train: 2018-08-01T00:13:54.124791: step 4343, loss 0.662256.
Train: 2018-08-01T00:13:54.281004: step 4344, loss 0.512585.
Train: 2018-08-01T00:13:54.437219: step 4345, loss 0.512494.
Train: 2018-08-01T00:13:54.609052: step 4346, loss 0.562475.
Train: 2018-08-01T00:13:54.765266: step 4347, loss 0.612686.
Train: 2018-08-01T00:13:54.921479: step 4348, loss 0.579218.
Train: 2018-08-01T00:13:55.093309: step 4349, loss 0.612787.
Train: 2018-08-01T00:13:55.249528: step 4350, loss 0.478546.
Test: 2018-08-01T00:13:55.733789: step 4350, loss 0.548369.
Train: 2018-08-01T00:13:55.889972: step 4351, loss 0.596056.
Train: 2018-08-01T00:13:56.046214: step 4352, loss 0.579261.
Train: 2018-08-01T00:13:56.218046: step 4353, loss 0.478272.
Train: 2018-08-01T00:13:56.374266: step 4354, loss 0.562428.
Train: 2018-08-01T00:13:56.530477: step 4355, loss 0.646905.
Train: 2018-08-01T00:13:56.686660: step 4356, loss 0.630032.
Train: 2018-08-01T00:13:56.842908: step 4357, loss 0.511749.
Train: 2018-08-01T00:13:57.014709: step 4358, loss 0.528631.
Train: 2018-08-01T00:13:57.170952: step 4359, loss 0.528602.
Train: 2018-08-01T00:13:57.342760: step 4360, loss 0.46083.
Test: 2018-08-01T00:13:57.827018: step 4360, loss 0.54819.
Train: 2018-08-01T00:13:57.983263: step 4361, loss 0.596365.
Train: 2018-08-01T00:13:58.170689: step 4362, loss 0.579416.
Train: 2018-08-01T00:13:58.311311: step 4363, loss 0.545361.
Train: 2018-08-01T00:13:58.483129: step 4364, loss 0.596537.
Train: 2018-08-01T00:13:58.654951: step 4365, loss 0.596571.
Train: 2018-08-01T00:13:58.826785: step 4366, loss 0.494021.
Train: 2018-08-01T00:13:58.982999: step 4367, loss 0.528159.
Train: 2018-08-01T00:13:59.139211: step 4368, loss 0.579546.
Train: 2018-08-01T00:13:59.295456: step 4369, loss 0.44218.
Train: 2018-08-01T00:13:59.467260: step 4370, loss 0.510718.
Test: 2018-08-01T00:13:59.935900: step 4370, loss 0.547926.
Train: 2018-08-01T00:14:00.107762: step 4371, loss 0.510541.
Train: 2018-08-01T00:14:00.279570: step 4372, loss 0.492991.
Train: 2018-08-01T00:14:00.467025: step 4373, loss 0.614725.
Train: 2018-08-01T00:14:00.623264: step 4374, loss 0.614906.
Train: 2018-08-01T00:14:00.779462: step 4375, loss 0.474822.
Train: 2018-08-01T00:14:00.951317: step 4376, loss 0.527307.
Train: 2018-08-01T00:14:01.107531: step 4377, loss 0.580117.
Train: 2018-08-01T00:14:01.263714: step 4378, loss 0.615534.
Train: 2018-08-01T00:14:01.419928: step 4379, loss 0.473997.
Train: 2018-08-01T00:14:01.576142: step 4380, loss 0.580273.
Test: 2018-08-01T00:14:02.044781: step 4380, loss 0.547656.
Train: 2018-08-01T00:14:02.216615: step 4381, loss 0.491436.
Train: 2018-08-01T00:14:02.372859: step 4382, loss 0.526922.
Train: 2018-08-01T00:14:02.529042: step 4383, loss 0.687664.
Train: 2018-08-01T00:14:02.685258: step 4384, loss 0.562593.
Train: 2018-08-01T00:14:02.857121: step 4385, loss 0.562596.
Train: 2018-08-01T00:14:03.013305: step 4386, loss 0.598362.
Train: 2018-08-01T00:14:03.169547: step 4387, loss 0.544718.
Train: 2018-08-01T00:14:03.341386: step 4388, loss 0.50899.
Train: 2018-08-01T00:14:03.497595: step 4389, loss 0.544719.
Train: 2018-08-01T00:14:03.653780: step 4390, loss 0.508961.
Test: 2018-08-01T00:14:04.138071: step 4390, loss 0.547619.
Train: 2018-08-01T00:14:04.309879: step 4391, loss 0.634181.
Train: 2018-08-01T00:14:04.481712: step 4392, loss 0.544711.
Train: 2018-08-01T00:14:04.653545: step 4393, loss 0.562599.
Train: 2018-08-01T00:14:04.809790: step 4394, loss 0.598359.
Train: 2018-08-01T00:14:04.966006: step 4395, loss 0.580453.
Train: 2018-08-01T00:14:05.169051: step 4396, loss 0.66964.
Train: 2018-08-01T00:14:05.340883: step 4397, loss 0.509165.
Train: 2018-08-01T00:14:05.512744: step 4398, loss 0.598062.
Train: 2018-08-01T00:14:05.668962: step 4399, loss 0.527073.
Train: 2018-08-01T00:14:05.840791: step 4400, loss 0.562506.
Test: 2018-08-01T00:14:06.309408: step 4400, loss 0.547702.
Train: 2018-08-01T00:14:07.043635: step 4401, loss 0.633155.
Train: 2018-08-01T00:14:07.215478: step 4402, loss 0.597718.
Train: 2018-08-01T00:14:07.371683: step 4403, loss 0.509755.
Train: 2018-08-01T00:14:07.527896: step 4404, loss 0.56245.
Train: 2018-08-01T00:14:07.684110: step 4405, loss 0.579944.
Train: 2018-08-01T00:14:07.855920: step 4406, loss 0.544965.
Train: 2018-08-01T00:14:08.012159: step 4407, loss 0.597308.
Train: 2018-08-01T00:14:08.168377: step 4408, loss 0.562419.
Train: 2018-08-01T00:14:08.324593: step 4409, loss 0.458174.
Train: 2018-08-01T00:14:08.480774: step 4410, loss 0.49293.
Test: 2018-08-01T00:14:08.965034: step 4410, loss 0.547857.
Train: 2018-08-01T00:14:09.121279: step 4411, loss 0.54503.
Train: 2018-08-01T00:14:09.293085: step 4412, loss 0.492807.
Train: 2018-08-01T00:14:09.464920: step 4413, loss 0.597297.
Train: 2018-08-01T00:14:09.621167: step 4414, loss 0.527519.
Train: 2018-08-01T00:14:09.792967: step 4415, loss 0.44007.
Train: 2018-08-01T00:14:09.964828: step 4416, loss 0.509847.
Train: 2018-08-01T00:14:10.121016: step 4417, loss 0.580064.
Train: 2018-08-01T00:14:10.292849: step 4418, loss 0.597772.
Train: 2018-08-01T00:14:10.449095: step 4419, loss 0.527147.
Train: 2018-08-01T00:14:10.605306: step 4420, loss 0.47395.
Test: 2018-08-01T00:14:11.073944: step 4420, loss 0.54766.
Train: 2018-08-01T00:14:11.230129: step 4421, loss 0.509238.
Train: 2018-08-01T00:14:11.386373: step 4422, loss 0.562567.
Train: 2018-08-01T00:14:11.542584: step 4423, loss 0.651985.
Train: 2018-08-01T00:14:11.698803: step 4424, loss 0.580506.
Train: 2018-08-01T00:14:11.855013: step 4425, loss 0.580525.
Train: 2018-08-01T00:14:12.073682: step 4426, loss 0.562615.
Train: 2018-08-01T00:14:12.245518: step 4427, loss 0.562616.
Train: 2018-08-01T00:14:12.401755: step 4428, loss 0.598444.
Train: 2018-08-01T00:14:12.573566: step 4429, loss 0.491003.
Train: 2018-08-01T00:14:12.729779: step 4430, loss 0.562609.
Test: 2018-08-01T00:14:13.214073: step 4430, loss 0.547616.
Train: 2018-08-01T00:14:13.385905: step 4431, loss 0.437273.
Train: 2018-08-01T00:14:13.542119: step 4432, loss 0.562626.
Train: 2018-08-01T00:14:13.698336: step 4433, loss 0.598559.
Train: 2018-08-01T00:14:13.854545: step 4434, loss 0.67046.
Train: 2018-08-01T00:14:14.010759: step 4435, loss 0.526739.
Train: 2018-08-01T00:14:14.182565: step 4436, loss 0.472951.
Train: 2018-08-01T00:14:14.370023: step 4437, loss 0.508801.
Train: 2018-08-01T00:14:14.557476: step 4438, loss 0.526719.
Train: 2018-08-01T00:14:14.729338: step 4439, loss 0.598628.
Train: 2018-08-01T00:14:14.916770: step 4440, loss 0.544669.
Test: 2018-08-01T00:14:15.385407: step 4440, loss 0.547593.
Train: 2018-08-01T00:14:15.541651: step 4441, loss 0.526662.
Train: 2018-08-01T00:14:15.697859: step 4442, loss 0.562678.
Train: 2018-08-01T00:14:15.854079: step 4443, loss 0.544656.
Train: 2018-08-01T00:14:16.010262: step 4444, loss 0.562692.
Train: 2018-08-01T00:14:16.182125: step 4445, loss 0.490511.
Train: 2018-08-01T00:14:16.338334: step 4446, loss 0.526576.
Train: 2018-08-01T00:14:16.541387: step 4447, loss 0.562729.
Train: 2018-08-01T00:14:16.713255: step 4448, loss 0.671415.
Train: 2018-08-01T00:14:16.885057: step 4449, loss 0.598931.
Train: 2018-08-01T00:14:17.041299: step 4450, loss 0.707313.
Test: 2018-08-01T00:14:17.509908: step 4450, loss 0.547591.
Train: 2018-08-01T00:14:17.681772: step 4451, loss 0.490621.
Train: 2018-08-01T00:14:17.853604: step 4452, loss 0.544676.
Train: 2018-08-01T00:14:18.009817: step 4453, loss 0.580569.
Train: 2018-08-01T00:14:18.181655: step 4454, loss 0.59841.
Train: 2018-08-01T00:14:18.400327: step 4455, loss 0.598293.
Train: 2018-08-01T00:14:18.540919: step 4456, loss 0.544752.
Train: 2018-08-01T00:14:18.712753: step 4457, loss 0.473744.
Train: 2018-08-01T00:14:18.868965: step 4458, loss 0.527049.
Train: 2018-08-01T00:14:19.025179: step 4459, loss 0.668881.
Train: 2018-08-01T00:14:19.181393: step 4460, loss 0.544816.
Test: 2018-08-01T00:14:19.650063: step 4460, loss 0.547706.
Train: 2018-08-01T00:14:19.837524: step 4461, loss 0.597801.
Train: 2018-08-01T00:14:20.009325: step 4462, loss 0.474399.
Train: 2018-08-01T00:14:20.165571: step 4463, loss 0.580071.
Train: 2018-08-01T00:14:20.321779: step 4464, loss 0.544883.
Train: 2018-08-01T00:14:20.493610: step 4465, loss 0.474627.
Train: 2018-08-01T00:14:20.649829: step 4466, loss 0.685485.
Train: 2018-08-01T00:14:20.806043: step 4467, loss 0.580003.
Train: 2018-08-01T00:14:20.962259: step 4468, loss 0.562446.
Train: 2018-08-01T00:14:21.118439: step 4469, loss 0.544946.
Train: 2018-08-01T00:14:21.274677: step 4470, loss 0.632318.
Test: 2018-08-01T00:14:21.758944: step 4470, loss 0.547827.
Train: 2018-08-01T00:14:21.915128: step 4471, loss 0.614723.
Train: 2018-08-01T00:14:22.086964: step 4472, loss 0.649333.
Train: 2018-08-01T00:14:22.243206: step 4473, loss 0.545089.
Train: 2018-08-01T00:14:22.430635: step 4474, loss 0.614176.
Train: 2018-08-01T00:14:22.618089: step 4475, loss 0.562396.
Train: 2018-08-01T00:14:22.774303: step 4476, loss 0.579531.
Train: 2018-08-01T00:14:22.930515: step 4477, loss 0.579475.
Train: 2018-08-01T00:14:23.086729: step 4478, loss 0.562403.
Train: 2018-08-01T00:14:23.242942: step 4479, loss 0.596352.
Train: 2018-08-01T00:14:23.399185: step 4480, loss 0.511664.
Test: 2018-08-01T00:14:23.867826: step 4480, loss 0.548286.
Train: 2018-08-01T00:14:24.024010: step 4481, loss 0.54554.
Train: 2018-08-01T00:14:24.195877: step 4482, loss 0.613008.
Train: 2018-08-01T00:14:24.352058: step 4483, loss 0.528789.
Train: 2018-08-01T00:14:24.523922: step 4484, loss 0.612854.
Train: 2018-08-01T00:14:24.680135: step 4485, loss 0.579225.
Train: 2018-08-01T00:14:24.836318: step 4486, loss 0.545722.
Train: 2018-08-01T00:14:24.992532: step 4487, loss 0.529033.
Train: 2018-08-01T00:14:25.148747: step 4488, loss 0.662726.
Train: 2018-08-01T00:14:25.320580: step 4489, loss 0.529136.
Train: 2018-08-01T00:14:25.492446: step 4490, loss 0.579148.
Test: 2018-08-01T00:14:25.961089: step 4490, loss 0.548572.
Train: 2018-08-01T00:14:26.132890: step 4491, loss 0.579135.
Train: 2018-08-01T00:14:26.289133: step 4492, loss 0.579122.
Train: 2018-08-01T00:14:26.445349: step 4493, loss 0.56252.
Train: 2018-08-01T00:14:26.601560: step 4494, loss 0.562527.
Train: 2018-08-01T00:14:26.757775: step 4495, loss 0.711562.
Train: 2018-08-01T00:14:26.913987: step 4496, loss 0.579066.
Train: 2018-08-01T00:14:27.070195: step 4497, loss 0.644878.
Train: 2018-08-01T00:14:27.226410: step 4498, loss 0.56262.
Train: 2018-08-01T00:14:27.398219: step 4499, loss 0.611674.
Train: 2018-08-01T00:14:27.570060: step 4500, loss 0.627813.
Test: 2018-08-01T00:14:28.038695: step 4500, loss 0.549169.
Train: 2018-08-01T00:14:28.866655: step 4501, loss 0.497901.
Train: 2018-08-01T00:14:29.022869: step 4502, loss 0.498095.
Train: 2018-08-01T00:14:29.210299: step 4503, loss 0.482011.
Train: 2018-08-01T00:14:29.350886: step 4504, loss 0.611278.
Train: 2018-08-01T00:14:29.522749: step 4505, loss 0.611282.
Train: 2018-08-01T00:14:29.694559: step 4506, loss 0.562781.
Train: 2018-08-01T00:14:29.897635: step 4507, loss 0.595096.
Train: 2018-08-01T00:14:30.053847: step 4508, loss 0.530499.
Train: 2018-08-01T00:14:30.225713: step 4509, loss 0.578939.
Train: 2018-08-01T00:14:30.460003: step 4510, loss 0.611246.
Test: 2018-08-01T00:14:30.944266: step 4510, loss 0.549272.
Train: 2018-08-01T00:14:31.100476: step 4511, loss 0.659667.
Train: 2018-08-01T00:14:31.256691: step 4512, loss 0.450012.
Train: 2018-08-01T00:14:31.428526: step 4513, loss 0.562811.
Train: 2018-08-01T00:14:31.600362: step 4514, loss 0.562802.
Train: 2018-08-01T00:14:31.756597: step 4515, loss 0.528343.
Train: 2018-08-01T00:14:31.928411: step 4516, loss 0.514253.
Train: 2018-08-01T00:14:32.147110: step 4517, loss 0.578954.
Train: 2018-08-01T00:14:32.303321: step 4518, loss 0.627707.
Train: 2018-08-01T00:14:32.459567: step 4519, loss 0.497648.
Train: 2018-08-01T00:14:32.615777: step 4520, loss 0.54638.
Test: 2018-08-01T00:14:33.100039: step 4520, loss 0.548971.
Train: 2018-08-01T00:14:33.256252: step 4521, loss 0.709717.
Train: 2018-08-01T00:14:33.412465: step 4522, loss 0.61167.
Train: 2018-08-01T00:14:33.584270: step 4523, loss 0.513686.
Train: 2018-08-01T00:14:33.756109: step 4524, loss 0.481004.
Train: 2018-08-01T00:14:33.912318: step 4525, loss 0.529918.
Train: 2018-08-01T00:14:34.068532: step 4526, loss 0.62822.
Train: 2018-08-01T00:14:34.240366: step 4527, loss 0.579026.
Train: 2018-08-01T00:14:34.396611: step 4528, loss 0.54616.
Train: 2018-08-01T00:14:34.568445: step 4529, loss 0.546127.
Train: 2018-08-01T00:14:34.724658: step 4530, loss 0.529602.
Test: 2018-08-01T00:14:35.193315: step 4530, loss 0.54872.
Train: 2018-08-01T00:14:35.365128: step 4531, loss 0.529514.
Train: 2018-08-01T00:14:35.521343: step 4532, loss 0.529408.
Train: 2018-08-01T00:14:35.691566: step 4533, loss 0.545898.
Train: 2018-08-01T00:14:35.847784: step 4534, loss 0.61248.
Train: 2018-08-01T00:14:36.019618: step 4535, loss 0.478987.
Train: 2018-08-01T00:14:36.175830: step 4536, loss 0.579212.
Train: 2018-08-01T00:14:36.332045: step 4537, loss 0.562445.
Train: 2018-08-01T00:14:36.503852: step 4538, loss 0.59612.
Train: 2018-08-01T00:14:36.660087: step 4539, loss 0.461182.
Train: 2018-08-01T00:14:36.816276: step 4540, loss 0.663996.
Test: 2018-08-01T00:14:37.284915: step 4540, loss 0.548214.
Train: 2018-08-01T00:14:37.456751: step 4541, loss 0.528503.
Train: 2018-08-01T00:14:37.612997: step 4542, loss 0.545421.
Train: 2018-08-01T00:14:37.769208: step 4543, loss 0.494328.
Train: 2018-08-01T00:14:37.941038: step 4544, loss 0.545331.
Train: 2018-08-01T00:14:38.097256: step 4545, loss 0.579512.
Train: 2018-08-01T00:14:38.253473: step 4546, loss 0.579551.
Train: 2018-08-01T00:14:38.409678: step 4547, loss 0.562396.
Train: 2018-08-01T00:14:38.581518: step 4548, loss 0.562397.
Train: 2018-08-01T00:14:38.737731: step 4549, loss 0.631356.
Train: 2018-08-01T00:14:38.893944: step 4550, loss 0.493425.
Test: 2018-08-01T00:14:39.362581: step 4550, loss 0.547943.
Train: 2018-08-01T00:14:39.518800: step 4551, loss 0.5624.
Train: 2018-08-01T00:14:39.690604: step 4552, loss 0.596969.
Train: 2018-08-01T00:14:39.846817: step 4553, loss 0.579693.
Train: 2018-08-01T00:14:40.018677: step 4554, loss 0.700743.
Train: 2018-08-01T00:14:40.190490: step 4555, loss 0.458857.
Train: 2018-08-01T00:14:40.362351: step 4556, loss 0.562399.
Train: 2018-08-01T00:14:40.518564: step 4557, loss 0.527904.
Train: 2018-08-01T00:14:40.690369: step 4558, loss 0.665911.
Train: 2018-08-01T00:14:40.846614: step 4559, loss 0.527941.
Train: 2018-08-01T00:14:41.002826: step 4560, loss 0.510749.
Test: 2018-08-01T00:14:41.471465: step 4560, loss 0.547979.
Train: 2018-08-01T00:14:41.643270: step 4561, loss 0.510742.
Train: 2018-08-01T00:14:41.799484: step 4562, loss 0.476229.
Train: 2018-08-01T00:14:41.971320: step 4563, loss 0.51059.
Train: 2018-08-01T00:14:42.127533: step 4564, loss 0.545089.
Train: 2018-08-01T00:14:42.283748: step 4565, loss 0.579773.
Train: 2018-08-01T00:14:42.439960: step 4566, loss 0.701597.
Train: 2018-08-01T00:14:42.596203: step 4567, loss 0.614594.
Train: 2018-08-01T00:14:42.752416: step 4568, loss 0.510294.
Train: 2018-08-01T00:14:42.908630: step 4569, loss 0.510306.
Train: 2018-08-01T00:14:43.064843: step 4570, loss 0.527659.
Test: 2018-08-01T00:14:43.549109: step 4570, loss 0.547852.
Train: 2018-08-01T00:14:43.705318: step 4571, loss 0.597206.
Train: 2018-08-01T00:14:43.861531: step 4572, loss 0.510221.
Train: 2018-08-01T00:14:44.017745: step 4573, loss 0.61467.
Train: 2018-08-01T00:14:44.173953: step 4574, loss 0.475335.
Train: 2018-08-01T00:14:44.330172: step 4575, loss 0.510107.
Train: 2018-08-01T00:14:44.502006: step 4576, loss 0.614853.
Train: 2018-08-01T00:14:44.673846: step 4577, loss 0.632389.
Train: 2018-08-01T00:14:44.830025: step 4578, loss 0.475025.
Train: 2018-08-01T00:14:44.986238: step 4579, loss 0.56244.
Train: 2018-08-01T00:14:45.158073: step 4580, loss 0.562444.
Test: 2018-08-01T00:14:45.626738: step 4580, loss 0.547773.
Train: 2018-08-01T00:14:45.782956: step 4581, loss 0.422263.
Train: 2018-08-01T00:14:45.954791: step 4582, loss 0.56246.
Train: 2018-08-01T00:14:46.110976: step 4583, loss 0.597687.
Train: 2018-08-01T00:14:46.282834: step 4584, loss 0.491957.
Train: 2018-08-01T00:14:46.439055: step 4585, loss 0.527157.
Train: 2018-08-01T00:14:46.595266: step 4586, loss 0.651072.
Train: 2018-08-01T00:14:46.751451: step 4587, loss 0.527069.
Train: 2018-08-01T00:14:46.923315: step 4588, loss 0.722222.
Train: 2018-08-01T00:14:47.079501: step 4589, loss 0.651106.
Train: 2018-08-01T00:14:47.266954: step 4590, loss 0.597837.
Test: 2018-08-01T00:14:47.751216: step 4590, loss 0.547725.
Train: 2018-08-01T00:14:47.907453: step 4591, loss 0.59771.
Train: 2018-08-01T00:14:48.079265: step 4592, loss 0.457112.
Train: 2018-08-01T00:14:48.235502: step 4593, loss 0.527389.
Train: 2018-08-01T00:14:48.407314: step 4594, loss 0.562444.
Train: 2018-08-01T00:14:48.579172: step 4595, loss 0.492453.
Train: 2018-08-01T00:14:48.735364: step 4596, loss 0.614937.
Train: 2018-08-01T00:14:48.907197: step 4597, loss 0.579923.
Train: 2018-08-01T00:14:49.079030: step 4598, loss 0.45762.
Train: 2018-08-01T00:14:49.235268: step 4599, loss 0.544956.
Train: 2018-08-01T00:14:49.391481: step 4600, loss 0.614916.
Test: 2018-08-01T00:14:49.875748: step 4600, loss 0.547793.
Train: 2018-08-01T00:14:50.594330: step 4601, loss 0.579927.
Train: 2018-08-01T00:14:50.766165: step 4602, loss 0.579917.
Train: 2018-08-01T00:14:50.922383: step 4603, loss 0.527498.
Train: 2018-08-01T00:14:51.109807: step 4604, loss 0.527505.
Train: 2018-08-01T00:14:51.281640: step 4605, loss 0.544965.
Train: 2018-08-01T00:14:51.437854: step 4606, loss 0.562434.
Train: 2018-08-01T00:14:51.594091: step 4607, loss 0.509993.
Train: 2018-08-01T00:14:51.765903: step 4608, loss 0.422452.
Train: 2018-08-01T00:14:51.937736: step 4609, loss 0.509806.
Train: 2018-08-01T00:14:52.093979: step 4610, loss 0.527259.
Test: 2018-08-01T00:14:52.562589: step 4610, loss 0.547701.
Train: 2018-08-01T00:14:52.734423: step 4611, loss 0.456493.
Train: 2018-08-01T00:14:52.890677: step 4612, loss 0.562528.
Train: 2018-08-01T00:14:53.046850: step 4613, loss 0.526931.
Train: 2018-08-01T00:14:53.234308: step 4614, loss 0.544713.
Train: 2018-08-01T00:14:53.406177: step 4615, loss 0.562635.
Train: 2018-08-01T00:14:53.578000: step 4616, loss 0.544665.
Train: 2018-08-01T00:14:53.734214: step 4617, loss 0.562703.
Train: 2018-08-01T00:14:53.890403: step 4618, loss 0.562733.
Train: 2018-08-01T00:14:54.062268: step 4619, loss 0.544625.
Train: 2018-08-01T00:14:54.249696: step 4620, loss 0.726285.
Test: 2018-08-01T00:14:54.733986: step 4620, loss 0.547572.
Train: 2018-08-01T00:14:54.890169: step 4621, loss 0.508315.
Train: 2018-08-01T00:14:55.046382: step 4622, loss 0.744265.
Train: 2018-08-01T00:14:55.218219: step 4623, loss 0.59893.
Train: 2018-08-01T00:14:55.390052: step 4624, loss 0.580733.
Train: 2018-08-01T00:14:55.561886: step 4625, loss 0.526693.
Train: 2018-08-01T00:14:55.718124: step 4626, loss 0.580557.
Train: 2018-08-01T00:14:55.905558: step 4627, loss 0.562596.
Train: 2018-08-01T00:14:56.077391: step 4628, loss 0.509067.
Train: 2018-08-01T00:14:56.249252: step 4629, loss 0.562555.
Train: 2018-08-01T00:14:56.389843: step 4630, loss 0.633629.
Test: 2018-08-01T00:14:56.874108: step 4630, loss 0.547677.
Train: 2018-08-01T00:14:57.030319: step 4631, loss 0.597967.
Train: 2018-08-01T00:14:57.202159: step 4632, loss 0.562496.
Train: 2018-08-01T00:14:57.358340: step 4633, loss 0.474379.
Train: 2018-08-01T00:14:57.530176: step 4634, loss 0.580064.
Train: 2018-08-01T00:14:57.670767: step 4635, loss 0.544893.
Train: 2018-08-01T00:14:57.842632: step 4636, loss 0.562453.
Train: 2018-08-01T00:14:57.998846: step 4637, loss 0.579971.
Train: 2018-08-01T00:14:58.170681: step 4638, loss 0.492444.
Train: 2018-08-01T00:14:58.358134: step 4639, loss 0.527452.
Train: 2018-08-01T00:14:58.514322: step 4640, loss 0.527447.
Test: 2018-08-01T00:14:58.982959: step 4640, loss 0.547782.
Train: 2018-08-01T00:14:59.154821: step 4641, loss 0.457401.
Train: 2018-08-01T00:14:59.311008: step 4642, loss 0.492283.
Train: 2018-08-01T00:14:59.482873: step 4643, loss 0.456921.
Train: 2018-08-01T00:14:59.670301: step 4644, loss 0.597814.
Train: 2018-08-01T00:14:59.826514: step 4645, loss 0.527089.
Train: 2018-08-01T00:14:59.982726: step 4646, loss 0.633601.
Train: 2018-08-01T00:15:00.138940: step 4647, loss 0.491374.
Train: 2018-08-01T00:15:00.310775: step 4648, loss 0.616077.
Train: 2018-08-01T00:15:00.482610: step 4649, loss 0.598295.
Train: 2018-08-01T00:15:00.670101: step 4650, loss 0.562586.
Test: 2018-08-01T00:15:01.138708: step 4650, loss 0.547626.
Train: 2018-08-01T00:15:01.326163: step 4651, loss 0.580457.
Train: 2018-08-01T00:15:01.497996: step 4652, loss 0.580453.
Train: 2018-08-01T00:15:01.669831: step 4653, loss 0.419736.
Train: 2018-08-01T00:15:01.826046: step 4654, loss 0.544715.
Train: 2018-08-01T00:15:01.982288: step 4655, loss 0.473082.
Train: 2018-08-01T00:15:02.138471: step 4656, loss 0.544686.
Train: 2018-08-01T00:15:02.294714: step 4657, loss 0.472721.
Train: 2018-08-01T00:15:02.466545: step 4658, loss 0.562695.
Train: 2018-08-01T00:15:02.638354: step 4659, loss 0.526547.
Train: 2018-08-01T00:15:02.794593: step 4660, loss 0.453931.
Test: 2018-08-01T00:15:03.278830: step 4660, loss 0.547569.
Train: 2018-08-01T00:15:03.450664: step 4661, loss 0.508197.
Train: 2018-08-01T00:15:03.622543: step 4662, loss 0.599424.
Train: 2018-08-01T00:15:03.778742: step 4663, loss 0.526262.
Train: 2018-08-01T00:15:03.934956: step 4664, loss 0.63647.
Train: 2018-08-01T00:15:04.091140: step 4665, loss 0.47098.
Train: 2018-08-01T00:15:04.262998: step 4666, loss 0.618339.
Train: 2018-08-01T00:15:04.419217: step 4667, loss 0.563037.
Train: 2018-08-01T00:15:04.575425: step 4668, loss 0.618453.
Train: 2018-08-01T00:15:04.747260: step 4669, loss 0.599961.
Train: 2018-08-01T00:15:04.903481: step 4670, loss 0.636779.
Test: 2018-08-01T00:15:05.372091: step 4670, loss 0.547574.
Train: 2018-08-01T00:15:05.543954: step 4671, loss 0.526183.
Train: 2018-08-01T00:15:05.700138: step 4672, loss 0.581317.
Train: 2018-08-01T00:15:05.856375: step 4673, loss 0.562917.
Train: 2018-08-01T00:15:06.012565: step 4674, loss 0.690921.
Train: 2018-08-01T00:15:06.184399: step 4675, loss 0.562826.
Train: 2018-08-01T00:15:06.340643: step 4676, loss 0.65355.
Train: 2018-08-01T00:15:06.496856: step 4677, loss 0.598851.
Train: 2018-08-01T00:15:06.653039: step 4678, loss 0.490733.
Train: 2018-08-01T00:15:06.809252: step 4679, loss 0.634275.
Train: 2018-08-01T00:15:06.965467: step 4680, loss 0.633915.
Test: 2018-08-01T00:15:07.449727: step 4680, loss 0.547669.
Train: 2018-08-01T00:15:07.605971: step 4681, loss 0.562527.
Train: 2018-08-01T00:15:07.762154: step 4682, loss 0.544833.
Train: 2018-08-01T00:15:07.934013: step 4683, loss 0.492122.
Train: 2018-08-01T00:15:08.090233: step 4684, loss 0.702744.
Train: 2018-08-01T00:15:08.246446: step 4685, loss 0.579885.
Train: 2018-08-01T00:15:08.402629: step 4686, loss 0.492911.
Train: 2018-08-01T00:15:08.558873: step 4687, loss 0.631693.
Train: 2018-08-01T00:15:08.730708: step 4688, loss 0.68318.
Train: 2018-08-01T00:15:08.886892: step 4689, loss 0.44226.
Train: 2018-08-01T00:15:09.058751: step 4690, loss 0.630839.
Test: 2018-08-01T00:15:09.527365: step 4690, loss 0.548126.
Train: 2018-08-01T00:15:09.683579: step 4691, loss 0.528307.
Train: 2018-08-01T00:15:09.839793: step 4692, loss 0.647397.
Train: 2018-08-01T00:15:09.996031: step 4693, loss 0.494684.
Train: 2018-08-01T00:15:10.152245: step 4694, loss 0.494851.
Train: 2018-08-01T00:15:10.308463: step 4695, loss 0.376795.
Train: 2018-08-01T00:15:10.464646: step 4696, loss 0.579329.
Train: 2018-08-01T00:15:10.620891: step 4697, loss 0.59629.
Train: 2018-08-01T00:15:10.777073: step 4698, loss 0.562411.
Train: 2018-08-01T00:15:10.948938: step 4699, loss 0.562409.
Train: 2018-08-01T00:15:11.105124: step 4700, loss 0.613363.
Test: 2018-08-01T00:15:11.589414: step 4700, loss 0.548183.
Train: 2018-08-01T00:15:12.276723: step 4701, loss 0.562407.
Train: 2018-08-01T00:15:12.448587: step 4702, loss 0.630355.
Train: 2018-08-01T00:15:12.604802: step 4703, loss 0.613321.
Train: 2018-08-01T00:15:12.776635: step 4704, loss 0.596299.
Train: 2018-08-01T00:15:12.932818: step 4705, loss 0.477869.
Train: 2018-08-01T00:15:13.089062: step 4706, loss 0.56242.
Train: 2018-08-01T00:15:13.245275: step 4707, loss 0.562421.
Train: 2018-08-01T00:15:13.401458: step 4708, loss 0.545527.
Train: 2018-08-01T00:15:13.557703: step 4709, loss 0.461039.
Train: 2018-08-01T00:15:13.729532: step 4710, loss 0.579343.
Test: 2018-08-01T00:15:14.198177: step 4710, loss 0.548218.
Train: 2018-08-01T00:15:14.354392: step 4711, loss 0.596312.
Train: 2018-08-01T00:15:14.510605: step 4712, loss 0.613298.
Train: 2018-08-01T00:15:14.666822: step 4713, loss 0.392799.
Train: 2018-08-01T00:15:14.823001: step 4714, loss 0.460373.
Train: 2018-08-01T00:15:14.994866: step 4715, loss 0.647759.
Train: 2018-08-01T00:15:15.151051: step 4716, loss 0.459734.
Train: 2018-08-01T00:15:15.307293: step 4717, loss 0.545224.
Train: 2018-08-01T00:15:15.479099: step 4718, loss 0.700248.
Train: 2018-08-01T00:15:15.650957: step 4719, loss 0.648644.
Train: 2018-08-01T00:15:15.807176: step 4720, loss 0.614125.
Test: 2018-08-01T00:15:16.275814: step 4720, loss 0.547975.
Train: 2018-08-01T00:15:16.447651: step 4721, loss 0.631287.
Train: 2018-08-01T00:15:16.603863: step 4722, loss 0.476462.
Train: 2018-08-01T00:15:16.760047: step 4723, loss 0.665456.
Train: 2018-08-01T00:15:16.916261: step 4724, loss 0.579536.
Train: 2018-08-01T00:15:17.103748: step 4725, loss 0.596605.
Train: 2018-08-01T00:15:17.259930: step 4726, loss 0.545336.
Train: 2018-08-01T00:15:17.400552: step 4727, loss 0.511312.
Train: 2018-08-01T00:15:17.572393: step 4728, loss 0.562403.
Train: 2018-08-01T00:15:17.728601: step 4729, loss 0.579405.
Train: 2018-08-01T00:15:17.884815: step 4730, loss 0.61336.
Test: 2018-08-01T00:15:18.353454: step 4730, loss 0.548211.
Train: 2018-08-01T00:15:18.525259: step 4731, loss 0.630239.
Train: 2018-08-01T00:15:18.681473: step 4732, loss 0.511672.
Train: 2018-08-01T00:15:18.853308: step 4733, loss 0.494855.
Train: 2018-08-01T00:15:19.009551: step 4734, loss 0.596202.
Train: 2018-08-01T00:15:19.165734: step 4735, loss 0.646822.
Train: 2018-08-01T00:15:19.306357: step 4736, loss 0.545583.
Train: 2018-08-01T00:15:19.478187: step 4737, loss 0.579264.
Train: 2018-08-01T00:15:19.634404: step 4738, loss 0.612856.
Train: 2018-08-01T00:15:19.790588: step 4739, loss 0.545682.
Train: 2018-08-01T00:15:19.946831: step 4740, loss 0.69644.
Test: 2018-08-01T00:15:20.415440: step 4740, loss 0.548502.
Train: 2018-08-01T00:15:20.587300: step 4741, loss 0.66263.
Train: 2018-08-01T00:15:20.743520: step 4742, loss 0.562508.
Train: 2018-08-01T00:15:20.899732: step 4743, loss 0.562537.
Train: 2018-08-01T00:15:21.055941: step 4744, loss 0.513084.
Train: 2018-08-01T00:15:21.212155: step 4745, loss 0.546126.
Train: 2018-08-01T00:15:21.368343: step 4746, loss 0.595464.
Train: 2018-08-01T00:15:21.524587: step 4747, loss 0.562615.
Train: 2018-08-01T00:15:21.680770: step 4748, loss 0.579009.
Train: 2018-08-01T00:15:21.836983: step 4749, loss 0.595357.
Train: 2018-08-01T00:15:21.993198: step 4750, loss 0.562661.
Test: 2018-08-01T00:15:22.477458: step 4750, loss 0.549018.
Train: 2018-08-01T00:15:22.633703: step 4751, loss 0.627908.
Train: 2018-08-01T00:15:22.789887: step 4752, loss 0.562698.
Train: 2018-08-01T00:15:22.961732: step 4753, loss 0.530224.
Train: 2018-08-01T00:15:23.149176: step 4754, loss 0.562726.
Train: 2018-08-01T00:15:23.352255: step 4755, loss 0.611408.
Train: 2018-08-01T00:15:23.539710: step 4756, loss 0.465499.
Train: 2018-08-01T00:15:23.727166: step 4757, loss 0.643845.
Train: 2018-08-01T00:15:23.883379: step 4758, loss 0.546523.
Train: 2018-08-01T00:15:24.039593: step 4759, loss 0.627609.
Train: 2018-08-01T00:15:24.211428: step 4760, loss 0.514132.
Test: 2018-08-01T00:15:24.680097: step 4760, loss 0.549169.
Train: 2018-08-01T00:15:24.836281: step 4761, loss 0.578953.
Train: 2018-08-01T00:15:24.992495: step 4762, loss 0.497884.
Train: 2018-08-01T00:15:25.148709: step 4763, loss 0.546484.
Train: 2018-08-01T00:15:25.320543: step 4764, loss 0.530166.
Train: 2018-08-01T00:15:25.476786: step 4765, loss 0.530062.
Train: 2018-08-01T00:15:25.632999: step 4766, loss 0.546292.
Train: 2018-08-01T00:15:25.804835: step 4767, loss 0.579019.
Train: 2018-08-01T00:15:25.961048: step 4768, loss 0.562591.
Train: 2018-08-01T00:15:26.117261: step 4769, loss 0.595542.
Train: 2018-08-01T00:15:26.273477: step 4770, loss 0.579071.
Test: 2018-08-01T00:15:26.757707: step 4770, loss 0.54869.
Train: 2018-08-01T00:15:26.929543: step 4771, loss 0.612166.
Train: 2018-08-01T00:15:27.101376: step 4772, loss 0.562537.
Train: 2018-08-01T00:15:27.273243: step 4773, loss 0.496272.
Train: 2018-08-01T00:15:27.429450: step 4774, loss 0.462944.
Train: 2018-08-01T00:15:27.585662: step 4775, loss 0.579146.
Train: 2018-08-01T00:15:27.757502: step 4776, loss 0.629278.
Train: 2018-08-01T00:15:27.913715: step 4777, loss 0.629377.
Train: 2018-08-01T00:15:28.085551: step 4778, loss 0.528993.
Train: 2018-08-01T00:15:28.241758: step 4779, loss 0.696482.
Train: 2018-08-01T00:15:28.397971: step 4780, loss 0.495527.
Test: 2018-08-01T00:15:28.882239: step 4780, loss 0.548448.
Train: 2018-08-01T00:15:29.038422: step 4781, loss 0.478779.
Train: 2018-08-01T00:15:29.194665: step 4782, loss 0.612744.
Train: 2018-08-01T00:15:29.350879: step 4783, loss 0.545677.
Train: 2018-08-01T00:15:29.522719: step 4784, loss 0.528866.
Train: 2018-08-01T00:15:29.678928: step 4785, loss 0.629702.
Train: 2018-08-01T00:15:29.850762: step 4786, loss 0.596081.
Train: 2018-08-01T00:15:30.006946: step 4787, loss 0.495167.
Train: 2018-08-01T00:15:30.178781: step 4788, loss 0.562436.
Train: 2018-08-01T00:15:30.335017: step 4789, loss 0.596133.
Train: 2018-08-01T00:15:30.491207: step 4790, loss 0.596144.
Test: 2018-08-01T00:15:30.975511: step 4790, loss 0.548316.
Train: 2018-08-01T00:15:31.147304: step 4791, loss 0.663561.
Train: 2018-08-01T00:15:31.303518: step 4792, loss 0.579265.
Train: 2018-08-01T00:15:31.475352: step 4793, loss 0.512047.
Train: 2018-08-01T00:15:31.631596: step 4794, loss 0.579236.
Train: 2018-08-01T00:15:31.787809: step 4795, loss 0.663105.
Train: 2018-08-01T00:15:31.975236: step 4796, loss 0.562463.
Train: 2018-08-01T00:15:32.162691: step 4797, loss 0.529061.
Train: 2018-08-01T00:15:32.303307: step 4798, loss 0.629233.
Train: 2018-08-01T00:15:32.459496: step 4799, loss 0.495871.
Train: 2018-08-01T00:15:32.709439: step 4800, loss 0.66237.
Test: 2018-08-01T00:15:33.178114: step 4800, loss 0.5486.
Train: 2018-08-01T00:15:34.021632: step 4801, loss 0.579122.
Train: 2018-08-01T00:15:34.193465: step 4802, loss 0.562525.
Train: 2018-08-01T00:15:34.380922: step 4803, loss 0.61219.
Train: 2018-08-01T00:15:34.537135: step 4804, loss 0.678156.
Train: 2018-08-01T00:15:34.724590: step 4805, loss 0.513229.
Train: 2018-08-01T00:15:34.865218: step 4806, loss 0.546197.
Train: 2018-08-01T00:15:35.037018: step 4807, loss 0.529858.
Train: 2018-08-01T00:15:35.193266: step 4808, loss 0.529895.
Train: 2018-08-01T00:15:35.349444: step 4809, loss 0.464422.
Train: 2018-08-01T00:15:35.490037: step 4810, loss 0.579016.
Test: 2018-08-01T00:15:35.974298: step 4810, loss 0.548854.
Train: 2018-08-01T00:15:36.130511: step 4811, loss 0.480497.
Train: 2018-08-01T00:15:36.286724: step 4812, loss 0.480239.
Train: 2018-08-01T00:15:36.442938: step 4813, loss 0.595614.
Train: 2018-08-01T00:15:36.599182: step 4814, loss 0.579108.
Train: 2018-08-01T00:15:36.755403: step 4815, loss 0.579134.
Train: 2018-08-01T00:15:36.911578: step 4816, loss 0.491357.
Train: 2018-08-01T00:15:37.083443: step 4817, loss 0.579193.
Train: 2018-08-01T00:15:37.239657: step 4818, loss 0.478589.
Train: 2018-08-01T00:15:37.395870: step 4819, loss 0.579273.
Train: 2018-08-01T00:15:37.552083: step 4820, loss 0.59621.
Test: 2018-08-01T00:15:38.020723: step 4820, loss 0.548232.
Train: 2018-08-01T00:15:38.176938: step 4821, loss 0.49467.
Train: 2018-08-01T00:15:38.333151: step 4822, loss 0.64737.
Train: 2018-08-01T00:15:38.504979: step 4823, loss 0.698577.
Train: 2018-08-01T00:15:38.661198: step 4824, loss 0.579416.
Train: 2018-08-01T00:15:38.817381: step 4825, loss 0.698409.
Train: 2018-08-01T00:15:38.973597: step 4826, loss 0.579366.
Train: 2018-08-01T00:15:39.129840: step 4827, loss 0.630056.
Train: 2018-08-01T00:15:39.286022: step 4828, loss 0.54558.
Train: 2018-08-01T00:15:39.442266: step 4829, loss 0.478418.
Train: 2018-08-01T00:15:39.598479: step 4830, loss 0.528875.
Test: 2018-08-01T00:15:40.067088: step 4830, loss 0.548398.
Train: 2018-08-01T00:15:40.238954: step 4831, loss 0.579231.
Train: 2018-08-01T00:15:40.395172: step 4832, loss 0.595996.
Train: 2018-08-01T00:15:40.551351: step 4833, loss 0.662994.
Train: 2018-08-01T00:15:40.707588: step 4834, loss 0.51232.
Train: 2018-08-01T00:15:40.863807: step 4835, loss 0.746137.
Train: 2018-08-01T00:15:41.020024: step 4836, loss 0.446088.
Train: 2018-08-01T00:15:41.191857: step 4837, loss 0.545909.
Train: 2018-08-01T00:15:41.348069: step 4838, loss 0.512759.
Train: 2018-08-01T00:15:41.504253: step 4839, loss 0.612282.
Train: 2018-08-01T00:15:41.660466: step 4840, loss 0.496224.
Test: 2018-08-01T00:15:42.129107: step 4840, loss 0.548634.
Train: 2018-08-01T00:15:42.285350: step 4841, loss 0.662031.
Train: 2018-08-01T00:15:42.441535: step 4842, loss 0.628804.
Train: 2018-08-01T00:15:42.597772: step 4843, loss 0.678312.
Train: 2018-08-01T00:15:42.753960: step 4844, loss 0.546089.
Train: 2018-08-01T00:15:42.910174: step 4845, loss 0.579034.
Train: 2018-08-01T00:15:43.066417: step 4846, loss 0.49703.
Train: 2018-08-01T00:15:43.222631: step 4847, loss 0.644531.
Train: 2018-08-01T00:15:43.378845: step 4848, loss 0.546305.
Train: 2018-08-01T00:15:43.550648: step 4849, loss 0.513701.
Train: 2018-08-01T00:15:43.706886: step 4850, loss 0.432139.
Test: 2018-08-01T00:15:44.191123: step 4850, loss 0.548957.
Train: 2018-08-01T00:15:44.347367: step 4851, loss 0.644396.
Train: 2018-08-01T00:15:44.503551: step 4852, loss 0.628083.
Train: 2018-08-01T00:15:44.659794: step 4853, loss 0.61171.
Train: 2018-08-01T00:15:44.831628: step 4854, loss 0.562654.
Train: 2018-08-01T00:15:44.987813: step 4855, loss 0.530003.
Train: 2018-08-01T00:15:45.144056: step 4856, loss 0.546329.
Train: 2018-08-01T00:15:45.300240: step 4857, loss 0.497295.
Train: 2018-08-01T00:15:45.456484: step 4858, loss 0.595373.
Train: 2018-08-01T00:15:45.628317: step 4859, loss 0.67734.
Train: 2018-08-01T00:15:45.784530: step 4860, loss 0.611763.
Test: 2018-08-01T00:15:46.253141: step 4860, loss 0.548946.
Train: 2018-08-01T00:15:46.409389: step 4861, loss 0.644428.
Train: 2018-08-01T00:15:46.581219: step 4862, loss 0.660584.
Train: 2018-08-01T00:15:46.737432: step 4863, loss 0.530182.
Train: 2018-08-01T00:15:46.893616: step 4864, loss 0.546512.
Train: 2018-08-01T00:15:47.049860: step 4865, loss 0.46559.
Train: 2018-08-01T00:15:47.206043: step 4866, loss 0.595149.
Train: 2018-08-01T00:15:47.362286: step 4867, loss 0.514161.
Train: 2018-08-01T00:15:47.518494: step 4868, loss 0.562741.
Train: 2018-08-01T00:15:47.674708: step 4869, loss 0.741253.
Train: 2018-08-01T00:15:47.830926: step 4870, loss 0.578951.
Test: 2018-08-01T00:15:48.299537: step 4870, loss 0.549231.
Train: 2018-08-01T00:15:48.471401: step 4871, loss 0.498087.
Train: 2018-08-01T00:15:48.627617: step 4872, loss 0.449607.
Train: 2018-08-01T00:15:48.783799: step 4873, loss 0.627542.
Train: 2018-08-01T00:15:48.940042: step 4874, loss 0.595164.
Train: 2018-08-01T00:15:49.096256: step 4875, loss 0.578955.
Train: 2018-08-01T00:15:49.252439: step 4876, loss 0.530294.
Train: 2018-08-01T00:15:49.424304: step 4877, loss 0.578961.
Train: 2018-08-01T00:15:49.580517: step 4878, loss 0.562715.
Train: 2018-08-01T00:15:49.752321: step 4879, loss 0.578969.
Train: 2018-08-01T00:15:49.908570: step 4880, loss 0.546419.
Test: 2018-08-01T00:15:50.377204: step 4880, loss 0.549038.
Train: 2018-08-01T00:15:50.533423: step 4881, loss 0.481209.
Train: 2018-08-01T00:15:50.705253: step 4882, loss 0.562656.
Train: 2018-08-01T00:15:50.861462: step 4883, loss 0.513502.
Train: 2018-08-01T00:15:51.017650: step 4884, loss 0.496887.
Train: 2018-08-01T00:15:51.189485: step 4885, loss 0.447098.
Train: 2018-08-01T00:15:51.345699: step 4886, loss 0.512755.
Train: 2018-08-01T00:15:51.501912: step 4887, loss 0.479044.
Train: 2018-08-01T00:15:51.658155: step 4888, loss 0.579244.
Train: 2018-08-01T00:15:51.814338: step 4889, loss 0.494829.
Train: 2018-08-01T00:15:51.970583: step 4890, loss 0.562404.
Test: 2018-08-01T00:15:52.454845: step 4890, loss 0.548076.
Train: 2018-08-01T00:15:52.611057: step 4891, loss 0.613701.
Train: 2018-08-01T00:15:52.767273: step 4892, loss 0.528045.
Train: 2018-08-01T00:15:52.923497: step 4893, loss 0.510647.
Train: 2018-08-01T00:15:53.095288: step 4894, loss 0.423756.
Train: 2018-08-01T00:15:53.267156: step 4895, loss 0.614741.
Train: 2018-08-01T00:15:53.423367: step 4896, loss 0.562446.
Train: 2018-08-01T00:15:53.579580: step 4897, loss 0.580062.
Train: 2018-08-01T00:15:53.735763: step 4898, loss 0.580143.
Train: 2018-08-01T00:15:53.891976: step 4899, loss 0.456303.
Train: 2018-08-01T00:15:54.048190: step 4900, loss 0.598075.
Test: 2018-08-01T00:15:54.516860: step 4900, loss 0.547642.
Train: 2018-08-01T00:15:55.251034: step 4901, loss 0.616017.
Train: 2018-08-01T00:15:55.407276: step 4902, loss 0.598273.
Train: 2018-08-01T00:15:55.579082: step 4903, loss 0.508996.
Train: 2018-08-01T00:15:55.735325: step 4904, loss 0.544711.
Train: 2018-08-01T00:15:55.891508: step 4905, loss 0.544701.
Train: 2018-08-01T00:15:56.063374: step 4906, loss 0.526755.
Train: 2018-08-01T00:15:56.219588: step 4907, loss 0.400974.
Train: 2018-08-01T00:15:56.391391: step 4908, loss 0.580707.
Train: 2018-08-01T00:15:56.547635: step 4909, loss 0.508496.
Train: 2018-08-01T00:15:56.703819: step 4910, loss 0.544627.
Test: 2018-08-01T00:15:57.188109: step 4910, loss 0.54757.
Train: 2018-08-01T00:15:57.344295: step 4911, loss 0.471911.
Train: 2018-08-01T00:15:57.500532: step 4912, loss 0.635795.
Train: 2018-08-01T00:15:57.656750: step 4913, loss 0.654241.
Train: 2018-08-01T00:15:57.812960: step 4914, loss 0.599436.
Train: 2018-08-01T00:15:57.969177: step 4915, loss 0.526322.
Train: 2018-08-01T00:15:58.125390: step 4916, loss 0.508051.
Train: 2018-08-01T00:15:58.281599: step 4917, loss 0.581156.
Train: 2018-08-01T00:15:58.437812: step 4918, loss 0.489753.
Train: 2018-08-01T00:15:58.594034: step 4919, loss 0.434829.
Train: 2018-08-01T00:15:58.750215: step 4920, loss 0.599586.
Test: 2018-08-01T00:15:59.234476: step 4920, loss 0.54757.
Train: 2018-08-01T00:15:59.421964: step 4921, loss 0.562941.
Train: 2018-08-01T00:15:59.593799: step 4922, loss 0.526212.
Train: 2018-08-01T00:15:59.781250: step 4923, loss 0.434236.
Train: 2018-08-01T00:15:59.968680: step 4924, loss 0.50771.
Train: 2018-08-01T00:16:00.156137: step 4925, loss 0.600031.
Train: 2018-08-01T00:16:00.328000: step 4926, loss 0.544579.
Train: 2018-08-01T00:16:00.484184: step 4927, loss 0.526038.
Train: 2018-08-01T00:16:00.640396: step 4928, loss 0.526011.
Train: 2018-08-01T00:16:00.796634: step 4929, loss 0.48878.
Train: 2018-08-01T00:16:00.952854: step 4930, loss 0.488664.
Test: 2018-08-01T00:16:01.437085: step 4930, loss 0.547634.
Train: 2018-08-01T00:16:01.593326: step 4931, loss 0.563284.
Train: 2018-08-01T00:16:01.749536: step 4932, loss 0.600787.
Train: 2018-08-01T00:16:01.905726: step 4933, loss 0.507105.
Train: 2018-08-01T00:16:02.061969: step 4934, loss 0.525833.
Train: 2018-08-01T00:16:02.218152: step 4935, loss 0.56342.
Train: 2018-08-01T00:16:02.374396: step 4936, loss 0.544621.
Train: 2018-08-01T00:16:02.530579: step 4937, loss 0.469265.
Train: 2018-08-01T00:16:02.702445: step 4938, loss 0.469148.
Train: 2018-08-01T00:16:02.858627: step 4939, loss 0.450067.
Train: 2018-08-01T00:16:03.014841: step 4940, loss 0.620574.
Test: 2018-08-01T00:16:03.499103: step 4940, loss 0.547772.
Train: 2018-08-01T00:16:03.655350: step 4941, loss 0.563692.
Train: 2018-08-01T00:16:03.811559: step 4942, loss 0.658918.
Train: 2018-08-01T00:16:03.967767: step 4943, loss 0.525655.
Train: 2018-08-01T00:16:04.123980: step 4944, loss 0.525656.
Train: 2018-08-01T00:16:04.295820: step 4945, loss 0.620816.
Train: 2018-08-01T00:16:04.452003: step 4946, loss 0.582708.
Train: 2018-08-01T00:16:04.608247: step 4947, loss 0.677575.
Train: 2018-08-01T00:16:04.764460: step 4948, loss 0.506792.
Train: 2018-08-01T00:16:04.920680: step 4949, loss 0.714609.
Train: 2018-08-01T00:16:05.092510: step 4950, loss 0.619839.
Test: 2018-08-01T00:16:05.561120: step 4950, loss 0.547641.
Train: 2018-08-01T00:16:05.717363: step 4951, loss 0.469739.
Train: 2018-08-01T00:16:05.873577: step 4952, loss 0.563239.
Train: 2018-08-01T00:16:06.029759: step 4953, loss 0.581756.
Train: 2018-08-01T00:16:06.185999: step 4954, loss 0.507538.
Train: 2018-08-01T00:16:06.342215: step 4955, loss 0.470699.
Train: 2018-08-01T00:16:06.498430: step 4956, loss 0.581463.
Train: 2018-08-01T00:16:06.654643: step 4957, loss 0.655028.
Train: 2018-08-01T00:16:06.826474: step 4958, loss 0.471181.
Train: 2018-08-01T00:16:06.982691: step 4959, loss 0.599544.
Train: 2018-08-01T00:16:07.138875: step 4960, loss 0.508043.
Test: 2018-08-01T00:16:07.607515: step 4960, loss 0.547567.
Train: 2018-08-01T00:16:07.763759: step 4961, loss 0.5446.
Train: 2018-08-01T00:16:07.935594: step 4962, loss 0.544605.
Train: 2018-08-01T00:16:08.091807: step 4963, loss 0.653814.
Train: 2018-08-01T00:16:08.248021: step 4964, loss 0.526463.
Train: 2018-08-01T00:16:08.404203: step 4965, loss 0.490265.
Train: 2018-08-01T00:16:08.560447: step 4966, loss 0.635152.
Train: 2018-08-01T00:16:08.716630: step 4967, loss 0.598847.
Train: 2018-08-01T00:16:08.888465: step 4968, loss 0.616752.
Train: 2018-08-01T00:16:09.044678: step 4969, loss 0.562646.
Train: 2018-08-01T00:16:09.200893: step 4970, loss 0.437214.
Test: 2018-08-01T00:16:09.669562: step 4970, loss 0.547618.
Train: 2018-08-01T00:16:09.825746: step 4971, loss 0.598393.
Train: 2018-08-01T00:16:09.981989: step 4972, loss 0.634051.
Train: 2018-08-01T00:16:10.153824: step 4973, loss 0.580383.
Train: 2018-08-01T00:16:10.310008: step 4974, loss 0.509224.
Train: 2018-08-01T00:16:10.466221: step 4975, loss 0.580266.
Train: 2018-08-01T00:16:10.622464: step 4976, loss 0.59792.
Train: 2018-08-01T00:16:10.778678: step 4977, loss 0.615481.
Train: 2018-08-01T00:16:10.934885: step 4978, loss 0.562474.
Train: 2018-08-01T00:16:11.091099: step 4979, loss 0.492216.
Train: 2018-08-01T00:16:11.262942: step 4980, loss 0.562449.
Test: 2018-08-01T00:16:11.747172: step 4980, loss 0.547783.
Train: 2018-08-01T00:16:11.903413: step 4981, loss 0.579948.
Train: 2018-08-01T00:16:12.106486: step 4982, loss 0.475052.
Train: 2018-08-01T00:16:12.262675: step 4983, loss 0.562433.
Train: 2018-08-01T00:16:12.418889: step 4984, loss 0.527502.
Train: 2018-08-01T00:16:12.575132: step 4985, loss 0.5799.
Train: 2018-08-01T00:16:12.731345: step 4986, loss 0.614823.
Train: 2018-08-01T00:16:12.903151: step 4987, loss 0.579874.
Train: 2018-08-01T00:16:13.059389: step 4988, loss 0.527572.
Train: 2018-08-01T00:16:13.215602: step 4989, loss 0.562421.
Train: 2018-08-01T00:16:13.387444: step 4990, loss 0.597227.
Test: 2018-08-01T00:16:13.856052: step 4990, loss 0.547858.
Train: 2018-08-01T00:16:14.027911: step 4991, loss 0.510262.
Train: 2018-08-01T00:16:14.184130: step 4992, loss 0.492896.
Train: 2018-08-01T00:16:14.340338: step 4993, loss 0.666769.
Train: 2018-08-01T00:16:14.512151: step 4994, loss 0.597166.
Train: 2018-08-01T00:16:14.699606: step 4995, loss 0.631818.
Train: 2018-08-01T00:16:14.855818: step 4996, loss 0.510469.
Train: 2018-08-01T00:16:15.027652: step 4997, loss 0.458669.
Train: 2018-08-01T00:16:15.183875: step 4998, loss 0.545109.
Train: 2018-08-01T00:16:15.340110: step 4999, loss 0.631614.
Train: 2018-08-01T00:16:15.511925: step 5000, loss 0.648863.
Test: 2018-08-01T00:16:15.996175: step 5000, loss 0.547946.
Train: 2018-08-01T00:16:16.714787: step 5001, loss 0.5624.
Train: 2018-08-01T00:16:16.871001: step 5002, loss 0.614091.
Train: 2018-08-01T00:16:17.027184: step 5003, loss 0.631162.
Train: 2018-08-01T00:16:17.199044: step 5004, loss 0.52812.
Train: 2018-08-01T00:16:17.355262: step 5005, loss 0.528199.
Train: 2018-08-01T00:16:17.511476: step 5006, loss 0.681905.
Train: 2018-08-01T00:16:17.667660: step 5007, loss 0.579421.
Train: 2018-08-01T00:16:17.839524: step 5008, loss 0.443651.
Train: 2018-08-01T00:16:17.995737: step 5009, loss 0.596311.
Train: 2018-08-01T00:16:18.151956: step 5010, loss 0.528561.
Test: 2018-08-01T00:16:18.620561: step 5010, loss 0.548252.
Train: 2018-08-01T00:16:18.792396: step 5011, loss 0.511668.
Train: 2018-08-01T00:16:18.948609: step 5012, loss 0.562417.
Train: 2018-08-01T00:16:19.120474: step 5013, loss 0.562416.
Train: 2018-08-01T00:16:19.276688: step 5014, loss 0.613208.
Train: 2018-08-01T00:16:19.432901: step 5015, loss 0.460878.
Train: 2018-08-01T00:16:19.604731: step 5016, loss 0.54547.
Train: 2018-08-01T00:16:19.776544: step 5017, loss 0.562409.
Train: 2018-08-01T00:16:19.964024: step 5018, loss 0.494453.
Train: 2018-08-01T00:16:20.151481: step 5019, loss 0.61348.
Train: 2018-08-01T00:16:20.323288: step 5020, loss 0.511259.
Test: 2018-08-01T00:16:20.791932: step 5020, loss 0.548095.
Train: 2018-08-01T00:16:21.010656: step 5021, loss 0.613637.
Train: 2018-08-01T00:16:21.166839: step 5022, loss 0.545301.
Train: 2018-08-01T00:16:21.323053: step 5023, loss 0.54528.
Train: 2018-08-01T00:16:21.479266: step 5024, loss 0.613809.
Train: 2018-08-01T00:16:21.635482: step 5025, loss 0.562395.
Train: 2018-08-01T00:16:21.807340: step 5026, loss 0.510945.
Train: 2018-08-01T00:16:21.963565: step 5027, loss 0.545227.
Train: 2018-08-01T00:16:22.119766: step 5028, loss 0.459255.
Train: 2018-08-01T00:16:22.275990: step 5029, loss 0.614105.
Train: 2018-08-01T00:16:22.432199: step 5030, loss 0.631452.
Test: 2018-08-01T00:16:22.916460: step 5030, loss 0.547939.
Train: 2018-08-01T00:16:23.072643: step 5031, loss 0.59694.
Train: 2018-08-01T00:16:23.244508: step 5032, loss 0.614199.
Train: 2018-08-01T00:16:23.400727: step 5033, loss 0.510649.
Train: 2018-08-01T00:16:23.556906: step 5034, loss 0.510655.
Train: 2018-08-01T00:16:23.713150: step 5035, loss 0.579659.
Train: 2018-08-01T00:16:23.884984: step 5036, loss 0.5624.
Train: 2018-08-01T00:16:24.041166: step 5037, loss 0.631475.
Train: 2018-08-01T00:16:24.197412: step 5038, loss 0.596909.
Train: 2018-08-01T00:16:24.369240: step 5039, loss 0.57963.
Train: 2018-08-01T00:16:24.525430: step 5040, loss 0.493563.
Test: 2018-08-01T00:16:25.038744: step 5040, loss 0.54799.
Train: 2018-08-01T00:16:25.234253: step 5041, loss 0.614008.
Train: 2018-08-01T00:16:25.429707: step 5042, loss 0.665515.
Train: 2018-08-01T00:16:25.640163: step 5043, loss 0.545251.
Train: 2018-08-01T00:16:25.821652: step 5044, loss 0.459733.
Train: 2018-08-01T00:16:25.999209: step 5045, loss 0.630824.
Train: 2018-08-01T00:16:26.196649: step 5046, loss 0.494052.
Train: 2018-08-01T00:16:26.380158: step 5047, loss 0.494055.
Train: 2018-08-01T00:16:26.542723: step 5048, loss 0.493985.
Train: 2018-08-01T00:16:26.747935: step 5049, loss 0.613804.
Train: 2018-08-01T00:16:26.904147: step 5050, loss 0.579549.
Test: 2018-08-01T00:16:27.388440: step 5050, loss 0.548023.
Train: 2018-08-01T00:16:27.544652: step 5051, loss 0.579559.
Train: 2018-08-01T00:16:27.716461: step 5052, loss 0.665411.
Train: 2018-08-01T00:16:27.935159: step 5053, loss 0.59669.
Train: 2018-08-01T00:16:28.138277: step 5054, loss 0.665109.
Train: 2018-08-01T00:16:28.294446: step 5055, loss 0.477064.
Train: 2018-08-01T00:16:28.450660: step 5056, loss 0.562401.
Train: 2018-08-01T00:16:28.606874: step 5057, loss 0.528361.
Train: 2018-08-01T00:16:28.778715: step 5058, loss 0.562404.
Train: 2018-08-01T00:16:28.997433: step 5059, loss 0.494396.
Train: 2018-08-01T00:16:29.169243: step 5060, loss 0.613442.
Test: 2018-08-01T00:16:29.653503: step 5060, loss 0.548161.
Train: 2018-08-01T00:16:29.809742: step 5061, loss 0.613432.
Train: 2018-08-01T00:16:29.965964: step 5062, loss 0.528418.
Train: 2018-08-01T00:16:30.122170: step 5063, loss 0.562406.
Train: 2018-08-01T00:16:30.293980: step 5064, loss 0.579392.
Train: 2018-08-01T00:16:30.450192: step 5065, loss 0.494497.
Train: 2018-08-01T00:16:30.606417: step 5066, loss 0.562406.
Train: 2018-08-01T00:16:30.793863: step 5067, loss 0.545404.
Train: 2018-08-01T00:16:30.950076: step 5068, loss 0.664499.
Train: 2018-08-01T00:16:31.106288: step 5069, loss 0.562405.
Train: 2018-08-01T00:16:31.309372: step 5070, loss 0.596391.
Test: 2018-08-01T00:16:31.778036: step 5070, loss 0.548194.
Train: 2018-08-01T00:16:31.934251: step 5071, loss 0.613332.
Train: 2018-08-01T00:16:32.106085: step 5072, loss 0.545467.
Train: 2018-08-01T00:16:32.277888: step 5073, loss 0.545491.
Train: 2018-08-01T00:16:32.434102: step 5074, loss 0.663887.
Train: 2018-08-01T00:16:32.590316: step 5075, loss 0.461186.
Train: 2018-08-01T00:16:32.746530: step 5076, loss 0.528694.
Train: 2018-08-01T00:16:32.918364: step 5077, loss 0.545556.
Train: 2018-08-01T00:16:33.074577: step 5078, loss 0.545545.
Train: 2018-08-01T00:16:33.230821: step 5079, loss 0.562422.
Train: 2018-08-01T00:16:33.387004: step 5080, loss 0.56242.
Test: 2018-08-01T00:16:33.855644: step 5080, loss 0.54825.
Train: 2018-08-01T00:16:34.011890: step 5081, loss 0.680848.
Train: 2018-08-01T00:16:34.183694: step 5082, loss 0.68072.
Train: 2018-08-01T00:16:34.339936: step 5083, loss 0.646695.
Train: 2018-08-01T00:16:34.496157: step 5084, loss 0.629605.
Train: 2018-08-01T00:16:34.652333: step 5085, loss 0.646049.
Train: 2018-08-01T00:16:34.824167: step 5086, loss 0.562503.
Train: 2018-08-01T00:16:34.964760: step 5087, loss 0.661853.
Train: 2018-08-01T00:16:35.136626: step 5088, loss 0.579043.
Train: 2018-08-01T00:16:35.292808: step 5089, loss 0.579007.
Train: 2018-08-01T00:16:35.449052: step 5090, loss 0.546389.
Test: 2018-08-01T00:16:35.933312: step 5090, loss 0.549137.
Train: 2018-08-01T00:16:36.105143: step 5091, loss 0.514035.
Train: 2018-08-01T00:16:36.261363: step 5092, loss 0.449428.
Train: 2018-08-01T00:16:36.417570: step 5093, loss 0.595135.
Train: 2018-08-01T00:16:36.589379: step 5094, loss 0.546586.
Train: 2018-08-01T00:16:36.729970: step 5095, loss 0.546585.
Train: 2018-08-01T00:16:36.886185: step 5096, loss 0.578948.
Train: 2018-08-01T00:16:37.042398: step 5097, loss 0.514166.
Train: 2018-08-01T00:16:37.214258: step 5098, loss 0.5303.
Train: 2018-08-01T00:16:37.370447: step 5099, loss 0.530212.
Train: 2018-08-01T00:16:37.542281: step 5100, loss 0.562686.
Test: 2018-08-01T00:16:38.026574: step 5100, loss 0.548983.
Train: 2018-08-01T00:16:38.792007: step 5101, loss 0.627987.
Train: 2018-08-01T00:16:38.995067: step 5102, loss 0.513586.
Train: 2018-08-01T00:16:39.166931: step 5103, loss 0.562624.
Train: 2018-08-01T00:16:39.385600: step 5104, loss 0.513337.
Train: 2018-08-01T00:16:39.557440: step 5105, loss 0.562578.
Train: 2018-08-01T00:16:39.729271: step 5106, loss 0.595582.
Train: 2018-08-01T00:16:39.901104: step 5107, loss 0.579086.
Train: 2018-08-01T00:16:40.072939: step 5108, loss 0.579101.
Train: 2018-08-01T00:16:40.229182: step 5109, loss 0.54592.
Train: 2018-08-01T00:16:40.385367: step 5110, loss 0.479388.
Test: 2018-08-01T00:16:40.854009: step 5110, loss 0.548526.
Train: 2018-08-01T00:16:41.010219: step 5111, loss 0.562486.
Train: 2018-08-01T00:16:41.166468: step 5112, loss 0.579187.
Train: 2018-08-01T00:16:41.338268: step 5113, loss 0.495443.
Train: 2018-08-01T00:16:41.494480: step 5114, loss 0.47841.
Train: 2018-08-01T00:16:41.650726: step 5115, loss 0.613058.
Train: 2018-08-01T00:16:41.806934: step 5116, loss 0.545486.
Train: 2018-08-01T00:16:41.978742: step 5117, loss 0.616745.
Train: 2018-08-01T00:16:42.134982: step 5118, loss 0.49435.
Train: 2018-08-01T00:16:42.291170: step 5119, loss 0.57946.
Train: 2018-08-01T00:16:42.447413: step 5120, loss 0.442697.
Test: 2018-08-01T00:16:42.931676: step 5120, loss 0.548021.
Train: 2018-08-01T00:16:43.119101: step 5121, loss 0.49373.
Train: 2018-08-01T00:16:43.275313: step 5122, loss 0.66586.
Train: 2018-08-01T00:16:43.431536: step 5123, loss 0.579688.
Train: 2018-08-01T00:16:43.603362: step 5124, loss 0.614365.
Train: 2018-08-01T00:16:43.775199: step 5125, loss 0.614416.
Train: 2018-08-01T00:16:43.947032: step 5126, loss 0.579745.
Train: 2018-08-01T00:16:44.103245: step 5127, loss 0.597072.
Train: 2018-08-01T00:16:44.259490: step 5128, loss 0.458492.
Train: 2018-08-01T00:16:44.431294: step 5129, loss 0.614406.
Train: 2018-08-01T00:16:44.587540: step 5130, loss 0.59707.
Test: 2018-08-01T00:16:45.056180: step 5130, loss 0.547901.
Train: 2018-08-01T00:16:45.212387: step 5131, loss 0.579727.
Train: 2018-08-01T00:16:45.384227: step 5132, loss 0.666242.
Train: 2018-08-01T00:16:45.540439: step 5133, loss 0.545134.
Train: 2018-08-01T00:16:45.696652: step 5134, loss 0.631334.
Train: 2018-08-01T00:16:45.852866: step 5135, loss 0.528022.
Train: 2018-08-01T00:16:46.024677: step 5136, loss 0.528088.
Train: 2018-08-01T00:16:46.180883: step 5137, loss 0.545263.
Train: 2018-08-01T00:16:46.352969: step 5138, loss 0.442572.
Train: 2018-08-01T00:16:46.524835: step 5139, loss 0.493853.
Train: 2018-08-01T00:16:46.681045: step 5140, loss 0.596735.
Test: 2018-08-01T00:16:47.144976: step 5140, loss 0.548.
Train: 2018-08-01T00:16:47.316834: step 5141, loss 0.49363.
Train: 2018-08-01T00:16:47.488647: step 5142, loss 0.562397.
Train: 2018-08-01T00:16:47.644858: step 5143, loss 0.545138.
Train: 2018-08-01T00:16:47.801071: step 5144, loss 0.562403.
Train: 2018-08-01T00:16:47.957315: step 5145, loss 0.614384.
Train: 2018-08-01T00:16:48.129149: step 5146, loss 0.458373.
Train: 2018-08-01T00:16:48.285363: step 5147, loss 0.666677.
Train: 2018-08-01T00:16:48.441581: step 5148, loss 0.458112.
Train: 2018-08-01T00:16:48.613406: step 5149, loss 0.545006.
Train: 2018-08-01T00:16:48.753974: step 5150, loss 0.597324.
Test: 2018-08-01T00:16:49.238234: step 5150, loss 0.547806.
Train: 2018-08-01T00:16:49.394447: step 5151, loss 0.492564.
Train: 2018-08-01T00:16:49.550691: step 5152, loss 0.667447.
Train: 2018-08-01T00:16:49.722497: step 5153, loss 0.632456.
Train: 2018-08-01T00:16:49.878711: step 5154, loss 0.509975.
Train: 2018-08-01T00:16:50.050544: step 5155, loss 0.562437.
Train: 2018-08-01T00:16:50.206757: step 5156, loss 0.562436.
Train: 2018-08-01T00:16:50.362972: step 5157, loss 0.597389.
Train: 2018-08-01T00:16:50.519185: step 5158, loss 0.562432.
Train: 2018-08-01T00:16:50.675428: step 5159, loss 0.527528.
Train: 2018-08-01T00:16:50.847233: step 5160, loss 0.492644.
Test: 2018-08-01T00:16:51.331495: step 5160, loss 0.547811.
Train: 2018-08-01T00:16:51.487739: step 5161, loss 0.579889.
Train: 2018-08-01T00:16:51.643945: step 5162, loss 0.562432.
Train: 2018-08-01T00:16:51.800135: step 5163, loss 0.475085.
Train: 2018-08-01T00:16:51.971970: step 5164, loss 0.562439.
Train: 2018-08-01T00:16:52.128184: step 5165, loss 0.474863.
Train: 2018-08-01T00:16:52.300042: step 5166, loss 0.527343.
Train: 2018-08-01T00:16:52.456230: step 5167, loss 0.615273.
Train: 2018-08-01T00:16:52.612444: step 5168, loss 0.562479.
Train: 2018-08-01T00:16:52.784309: step 5169, loss 0.686009.
Train: 2018-08-01T00:16:52.940529: step 5170, loss 0.562482.
Test: 2018-08-01T00:16:53.424753: step 5170, loss 0.547724.
Train: 2018-08-01T00:16:53.580998: step 5171, loss 0.580094.
Train: 2018-08-01T00:16:53.737206: step 5172, loss 0.56247.
Train: 2018-08-01T00:16:53.893424: step 5173, loss 0.456984.
Train: 2018-08-01T00:16:54.065261: step 5174, loss 0.580055.
Train: 2018-08-01T00:16:54.221475: step 5175, loss 0.615238.
Train: 2018-08-01T00:16:54.377681: step 5176, loss 0.509732.
Train: 2018-08-01T00:16:54.518249: step 5177, loss 0.527309.
Train: 2018-08-01T00:16:54.690107: step 5178, loss 0.439374.
Train: 2018-08-01T00:16:54.846328: step 5179, loss 0.597719.
Train: 2018-08-01T00:16:55.002509: step 5180, loss 0.633058.
Test: 2018-08-01T00:16:55.486802: step 5180, loss 0.547712.
Train: 2018-08-01T00:16:55.643015: step 5181, loss 0.491911.
Train: 2018-08-01T00:16:55.814852: step 5182, loss 0.527172.
Train: 2018-08-01T00:16:55.955411: step 5183, loss 0.403358.
Train: 2018-08-01T00:16:56.127246: step 5184, loss 0.580266.
Train: 2018-08-01T00:16:56.299080: step 5185, loss 0.562547.
Train: 2018-08-01T00:16:56.439673: step 5186, loss 0.491264.
Train: 2018-08-01T00:16:56.595911: step 5187, loss 0.580469.
Train: 2018-08-01T00:16:56.767721: step 5188, loss 0.50887.
Train: 2018-08-01T00:16:56.923971: step 5189, loss 0.652445.
Train: 2018-08-01T00:16:57.080149: step 5190, loss 0.580629.
Test: 2018-08-01T00:16:57.548818: step 5190, loss 0.547597.
Train: 2018-08-01T00:16:57.705002: step 5191, loss 0.58064.
Train: 2018-08-01T00:16:57.861216: step 5192, loss 0.63459.
Train: 2018-08-01T00:16:58.033079: step 5193, loss 0.508755.
Train: 2018-08-01T00:16:58.189294: step 5194, loss 0.616501.
Train: 2018-08-01T00:16:58.345502: step 5195, loss 0.670209.
Train: 2018-08-01T00:16:58.532963: step 5196, loss 0.598356.
Train: 2018-08-01T00:16:58.689177: step 5197, loss 0.669509.
Train: 2018-08-01T00:16:58.845385: step 5198, loss 0.527039.
Train: 2018-08-01T00:16:59.001603: step 5199, loss 0.509461.
Train: 2018-08-01T00:16:59.157817: step 5200, loss 0.439053.
Test: 2018-08-01T00:16:59.626457: step 5200, loss 0.547723.
Train: 2018-08-01T00:17:00.345009: step 5201, loss 0.439138.
Train: 2018-08-01T00:17:00.516868: step 5202, loss 0.491933.
Train: 2018-08-01T00:17:00.688678: step 5203, loss 0.527156.
Train: 2018-08-01T00:17:00.829270: step 5204, loss 0.580217.
Train: 2018-08-01T00:17:01.001105: step 5205, loss 0.509325.
Train: 2018-08-01T00:17:01.157351: step 5206, loss 0.544771.
Train: 2018-08-01T00:17:01.313562: step 5207, loss 0.526952.
Train: 2018-08-01T00:17:01.485366: step 5208, loss 0.651762.
Train: 2018-08-01T00:17:01.641611: step 5209, loss 0.526883.
Train: 2018-08-01T00:17:01.829067: step 5210, loss 0.669754.
Test: 2018-08-01T00:17:02.297707: step 5210, loss 0.547633.
Train: 2018-08-01T00:17:02.453920: step 5211, loss 0.616114.
Train: 2018-08-01T00:17:02.610128: step 5212, loss 0.526929.
Train: 2018-08-01T00:17:02.781976: step 5213, loss 0.420184.
Train: 2018-08-01T00:17:02.953802: step 5214, loss 0.562559.
Train: 2018-08-01T00:17:03.110011: step 5215, loss 0.562565.
Train: 2018-08-01T00:17:03.266225: step 5216, loss 0.705211.
Train: 2018-08-01T00:17:03.422437: step 5217, loss 0.651553.
Train: 2018-08-01T00:17:03.594280: step 5218, loss 0.580278.
Train: 2018-08-01T00:17:03.750461: step 5219, loss 0.668681.
Train: 2018-08-01T00:17:03.906676: step 5220, loss 0.544857.
Test: 2018-08-01T00:17:04.390937: step 5220, loss 0.547756.
Train: 2018-08-01T00:17:04.547179: step 5221, loss 0.474681.
Train: 2018-08-01T00:17:04.703364: step 5222, loss 0.509894.
Train: 2018-08-01T00:17:04.859600: step 5223, loss 0.52745.
Train: 2018-08-01T00:17:05.015790: step 5224, loss 0.632366.
Train: 2018-08-01T00:17:05.172002: step 5225, loss 0.562429.
Train: 2018-08-01T00:17:05.328216: step 5226, loss 0.544998.
Train: 2018-08-01T00:17:05.500082: step 5227, loss 0.597225.
Train: 2018-08-01T00:17:05.656265: step 5228, loss 0.579788.
Train: 2018-08-01T00:17:05.796888: step 5229, loss 0.562409.
Train: 2018-08-01T00:17:05.968724: step 5230, loss 0.510463.
Test: 2018-08-01T00:17:06.421741: step 5230, loss 0.547916.
Train: 2018-08-01T00:17:06.593577: step 5231, loss 0.579704.
Train: 2018-08-01T00:17:06.749789: step 5232, loss 0.545118.
Train: 2018-08-01T00:17:06.906002: step 5233, loss 0.476037.
Train: 2018-08-01T00:17:07.062186: step 5234, loss 0.59697.
Train: 2018-08-01T00:17:07.234021: step 5235, loss 0.527831.
Train: 2018-08-01T00:17:07.390263: step 5236, loss 0.493222.
Train: 2018-08-01T00:17:07.546477: step 5237, loss 0.545085.
Train: 2018-08-01T00:17:07.702685: step 5238, loss 0.510366.
Train: 2018-08-01T00:17:07.858875: step 5239, loss 0.545031.
Train: 2018-08-01T00:17:08.015117: step 5240, loss 0.510157.
Test: 2018-08-01T00:17:08.499379: step 5240, loss 0.547806.
Train: 2018-08-01T00:17:08.655593: step 5241, loss 0.475096.
Train: 2018-08-01T00:17:08.811806: step 5242, loss 0.52739.
Train: 2018-08-01T00:17:08.968019: step 5243, loss 0.650433.
Train: 2018-08-01T00:17:09.124233: step 5244, loss 0.721117.
Train: 2018-08-01T00:17:09.280416: step 5245, loss 0.650552.
Train: 2018-08-01T00:17:09.467872: step 5246, loss 0.597628.
Train: 2018-08-01T00:17:09.608496: step 5247, loss 0.562452.
Train: 2018-08-01T00:17:09.780329: step 5248, loss 0.492428.
Train: 2018-08-01T00:17:09.936542: step 5249, loss 0.597409.
Train: 2018-08-01T00:17:10.092758: step 5250, loss 0.667192.
Test: 2018-08-01T00:17:10.577018: step 5250, loss 0.547841.
Train: 2018-08-01T00:17:10.733233: step 5251, loss 0.492781.
Train: 2018-08-01T00:17:10.889444: step 5252, loss 0.527653.
Train: 2018-08-01T00:17:11.045653: step 5253, loss 0.545049.
Train: 2018-08-01T00:17:11.201872: step 5254, loss 0.56241.
Train: 2018-08-01T00:17:11.373706: step 5255, loss 0.562408.
Train: 2018-08-01T00:17:11.561132: step 5256, loss 0.527751.
Train: 2018-08-01T00:17:11.717345: step 5257, loss 0.562406.
Train: 2018-08-01T00:17:11.873559: step 5258, loss 0.666349.
Train: 2018-08-01T00:17:12.029803: step 5259, loss 0.562403.
Train: 2018-08-01T00:17:12.186022: step 5260, loss 0.5624.
Test: 2018-08-01T00:17:12.670250: step 5260, loss 0.547959.
Train: 2018-08-01T00:17:12.826460: step 5261, loss 0.562398.
Train: 2018-08-01T00:17:12.982706: step 5262, loss 0.562397.
Train: 2018-08-01T00:17:13.138887: step 5263, loss 0.545195.
Train: 2018-08-01T00:17:13.295101: step 5264, loss 0.648333.
Train: 2018-08-01T00:17:13.435723: step 5265, loss 0.545243.
Train: 2018-08-01T00:17:13.607552: step 5266, loss 0.562396.
Train: 2018-08-01T00:17:13.779393: step 5267, loss 0.511091.
Train: 2018-08-01T00:17:13.935606: step 5268, loss 0.562397.
Train: 2018-08-01T00:17:14.091821: step 5269, loss 0.494051.
Train: 2018-08-01T00:17:14.248033: step 5270, loss 0.442711.
Test: 2018-08-01T00:17:14.732296: step 5270, loss 0.548043.
Train: 2018-08-01T00:17:14.904099: step 5271, loss 0.528117.
Train: 2018-08-01T00:17:15.060312: step 5272, loss 0.528024.
Train: 2018-08-01T00:17:15.216551: step 5273, loss 0.545162.
Train: 2018-08-01T00:17:15.372770: step 5274, loss 0.648829.
Train: 2018-08-01T00:17:15.528954: step 5275, loss 0.683556.
Train: 2018-08-01T00:17:15.685202: step 5276, loss 0.527811.
Train: 2018-08-01T00:17:15.841411: step 5277, loss 0.562403.
Train: 2018-08-01T00:17:16.013239: step 5278, loss 0.562402.
Train: 2018-08-01T00:17:16.169464: step 5279, loss 0.631557.
Train: 2018-08-01T00:17:16.341262: step 5280, loss 0.596937.
Test: 2018-08-01T00:17:16.794313: step 5280, loss 0.547961.
Train: 2018-08-01T00:17:16.966116: step 5281, loss 0.493436.
Train: 2018-08-01T00:17:17.137981: step 5282, loss 0.579631.
Train: 2018-08-01T00:17:17.294194: step 5283, loss 0.493511.
Train: 2018-08-01T00:17:17.450379: step 5284, loss 0.545169.
Train: 2018-08-01T00:17:17.606591: step 5285, loss 0.665835.
Train: 2018-08-01T00:17:17.762835: step 5286, loss 0.545175.
Train: 2018-08-01T00:17:17.934640: step 5287, loss 0.459131.
Train: 2018-08-01T00:17:18.090885: step 5288, loss 0.562397.
Train: 2018-08-01T00:17:18.262688: step 5289, loss 0.562398.
Train: 2018-08-01T00:17:18.418901: step 5290, loss 0.562399.
Test: 2018-08-01T00:17:18.887540: step 5290, loss 0.547942.
Train: 2018-08-01T00:17:19.059406: step 5291, loss 0.579665.
Train: 2018-08-01T00:17:19.231250: step 5292, loss 0.51059.
Train: 2018-08-01T00:17:19.403070: step 5293, loss 0.596977.
Train: 2018-08-01T00:17:19.559258: step 5294, loss 0.545109.
Train: 2018-08-01T00:17:19.715472: step 5295, loss 0.527796.
Train: 2018-08-01T00:17:19.871686: step 5296, loss 0.597048.
Train: 2018-08-01T00:17:20.027899: step 5297, loss 0.597061.
Train: 2018-08-01T00:17:20.184113: step 5298, loss 0.52776.
Train: 2018-08-01T00:17:20.371600: step 5299, loss 0.45844.
Train: 2018-08-01T00:17:20.527782: step 5300, loss 0.458263.
Test: 2018-08-01T00:17:20.996452: step 5300, loss 0.54784.
Train: 2018-08-01T00:17:21.668141: step 5301, loss 0.579831.
Train: 2018-08-01T00:17:21.839976: step 5302, loss 0.61479.
Train: 2018-08-01T00:17:21.996213: step 5303, loss 0.632345.
Train: 2018-08-01T00:17:22.168048: step 5304, loss 0.509995.
Train: 2018-08-01T00:17:22.324236: step 5305, loss 0.527449.
Train: 2018-08-01T00:17:22.480475: step 5306, loss 0.579961.
Train: 2018-08-01T00:17:22.652285: step 5307, loss 0.52739.
Train: 2018-08-01T00:17:22.808498: step 5308, loss 0.597551.
Train: 2018-08-01T00:17:22.964711: step 5309, loss 0.474677.
Train: 2018-08-01T00:17:23.120925: step 5310, loss 0.492132.
Test: 2018-08-01T00:17:23.605219: step 5310, loss 0.547721.
Train: 2018-08-01T00:17:23.777046: step 5311, loss 0.544855.
Train: 2018-08-01T00:17:23.933236: step 5312, loss 0.668478.
Train: 2018-08-01T00:17:24.089477: step 5313, loss 0.509482.
Train: 2018-08-01T00:17:24.245693: step 5314, loss 0.615573.
Train: 2018-08-01T00:17:24.417528: step 5315, loss 0.615578.
Train: 2018-08-01T00:17:24.573710: step 5316, loss 0.562499.
Train: 2018-08-01T00:17:24.729924: step 5317, loss 0.633145.
Train: 2018-08-01T00:17:24.901758: step 5318, loss 0.421437.
Train: 2018-08-01T00:17:25.057972: step 5319, loss 0.615389.
Train: 2018-08-01T00:17:25.214217: step 5320, loss 0.668227.
Test: 2018-08-01T00:17:25.698476: step 5320, loss 0.547739.
Train: 2018-08-01T00:17:25.854661: step 5321, loss 0.562466.
Train: 2018-08-01T00:17:26.010874: step 5322, loss 0.492248.
Train: 2018-08-01T00:17:26.182739: step 5323, loss 0.544914.
Train: 2018-08-01T00:17:26.338921: step 5324, loss 0.597499.
Train: 2018-08-01T00:17:26.495167: step 5325, loss 0.579948.
Train: 2018-08-01T00:17:26.651379: step 5326, loss 0.544954.
Train: 2018-08-01T00:17:26.807597: step 5327, loss 0.475109.
Train: 2018-08-01T00:17:26.963776: step 5328, loss 0.562433.
Train: 2018-08-01T00:17:27.119990: step 5329, loss 0.562434.
Train: 2018-08-01T00:17:27.276232: step 5330, loss 0.57991.
Test: 2018-08-01T00:17:27.760495: step 5330, loss 0.547803.
Train: 2018-08-01T00:17:27.916708: step 5331, loss 0.544962.
Train: 2018-08-01T00:17:28.088513: step 5332, loss 0.614849.
Train: 2018-08-01T00:17:28.244750: step 5333, loss 0.510057.
Train: 2018-08-01T00:17:28.400938: step 5334, loss 0.510059.
Train: 2018-08-01T00:17:28.557182: step 5335, loss 0.562433.
Train: 2018-08-01T00:17:28.729018: step 5336, loss 0.527478.
Train: 2018-08-01T00:17:28.885224: step 5337, loss 0.544944.
Train: 2018-08-01T00:17:29.057065: step 5338, loss 0.492393.
Train: 2018-08-01T00:17:29.228901: step 5339, loss 0.597545.
Train: 2018-08-01T00:17:29.385084: step 5340, loss 0.527329.
Test: 2018-08-01T00:17:29.853724: step 5340, loss 0.547738.
Train: 2018-08-01T00:17:30.009966: step 5341, loss 0.650417.
Train: 2018-08-01T00:17:30.166150: step 5342, loss 0.597644.
Train: 2018-08-01T00:17:30.353632: step 5343, loss 0.544886.
Train: 2018-08-01T00:17:30.509819: step 5344, loss 0.68545.
Train: 2018-08-01T00:17:30.666033: step 5345, loss 0.57998.
Train: 2018-08-01T00:17:30.822277: step 5346, loss 0.579928.
Train: 2018-08-01T00:17:30.978460: step 5347, loss 0.457743.
Train: 2018-08-01T00:17:31.134703: step 5348, loss 0.61473.
Train: 2018-08-01T00:17:31.290917: step 5349, loss 0.56242.
Train: 2018-08-01T00:17:31.478368: step 5350, loss 0.54503.
Test: 2018-08-01T00:17:31.962605: step 5350, loss 0.547869.
Train: 2018-08-01T00:17:32.118848: step 5351, loss 0.614516.
Train: 2018-08-01T00:17:32.275062: step 5352, loss 0.54507.
Train: 2018-08-01T00:17:32.446897: step 5353, loss 0.683606.
Train: 2018-08-01T00:17:32.618702: step 5354, loss 0.5624.
Train: 2018-08-01T00:17:32.774915: step 5355, loss 0.562397.
Train: 2018-08-01T00:17:32.931158: step 5356, loss 0.510882.
Train: 2018-08-01T00:17:33.087373: step 5357, loss 0.476667.
Train: 2018-08-01T00:17:33.243585: step 5358, loss 0.528106.
Train: 2018-08-01T00:17:33.399768: step 5359, loss 0.562395.
Train: 2018-08-01T00:17:33.571630: step 5360, loss 0.562395.
Test: 2018-08-01T00:17:34.040245: step 5360, loss 0.54802.
Train: 2018-08-01T00:17:34.196486: step 5361, loss 0.648233.
Train: 2018-08-01T00:17:34.368291: step 5362, loss 0.596698.
Train: 2018-08-01T00:17:34.524529: step 5363, loss 0.630907.
Train: 2018-08-01T00:17:34.696340: step 5364, loss 0.613664.
Train: 2018-08-01T00:17:34.852577: step 5365, loss 0.562401.
Train: 2018-08-01T00:17:35.008766: step 5366, loss 0.613399.
Train: 2018-08-01T00:17:35.165010: step 5367, loss 0.579359.
Train: 2018-08-01T00:17:35.321223: step 5368, loss 0.596215.
Train: 2018-08-01T00:17:35.477438: step 5369, loss 0.511903.
Train: 2018-08-01T00:17:35.633650: step 5370, loss 0.545632.
Test: 2018-08-01T00:17:36.097730: step 5370, loss 0.548392.
Train: 2018-08-01T00:17:36.253950: step 5371, loss 0.478519.
Train: 2018-08-01T00:17:36.410157: step 5372, loss 0.596023.
Train: 2018-08-01T00:17:36.566346: step 5373, loss 0.596013.
Train: 2018-08-01T00:17:36.738189: step 5374, loss 0.612758.
Train: 2018-08-01T00:17:36.910017: step 5375, loss 0.579205.
Train: 2018-08-01T00:17:37.066265: step 5376, loss 0.562469.
Train: 2018-08-01T00:17:37.222442: step 5377, loss 0.612574.
Train: 2018-08-01T00:17:37.378686: step 5378, loss 0.545819.
Train: 2018-08-01T00:17:37.534869: step 5379, loss 0.629086.
Train: 2018-08-01T00:17:37.691119: step 5380, loss 0.612347.
Test: 2018-08-01T00:17:38.159753: step 5380, loss 0.548654.
Train: 2018-08-01T00:17:38.315968: step 5381, loss 0.562529.
Train: 2018-08-01T00:17:38.472182: step 5382, loss 0.595611.
Train: 2018-08-01T00:17:38.628363: step 5383, loss 0.529581.
Train: 2018-08-01T00:17:38.784577: step 5384, loss 0.579047.
Train: 2018-08-01T00:17:38.940790: step 5385, loss 0.579036.
Train: 2018-08-01T00:17:39.112625: step 5386, loss 0.595445.
Train: 2018-08-01T00:17:39.268869: step 5387, loss 0.579014.
Train: 2018-08-01T00:17:39.425083: step 5388, loss 0.529909.
Train: 2018-08-01T00:17:39.581265: step 5389, loss 0.693463.
Train: 2018-08-01T00:17:39.737479: step 5390, loss 0.562675.
Test: 2018-08-01T00:17:40.206150: step 5390, loss 0.549075.
Train: 2018-08-01T00:17:40.362363: step 5391, loss 0.611513.
Train: 2018-08-01T00:17:40.518570: step 5392, loss 0.595185.
Train: 2018-08-01T00:17:40.674786: step 5393, loss 0.578946.
Train: 2018-08-01T00:17:40.830998: step 5394, loss 0.546655.
Train: 2018-08-01T00:17:40.987186: step 5395, loss 0.498373.
Train: 2018-08-01T00:17:41.143430: step 5396, loss 0.546717.
Train: 2018-08-01T00:17:41.330887: step 5397, loss 0.562821.
Train: 2018-08-01T00:17:41.487069: step 5398, loss 0.59505.
Train: 2018-08-01T00:17:41.643283: step 5399, loss 0.562814.
Train: 2018-08-01T00:17:41.799527: step 5400, loss 0.56281.
Test: 2018-08-01T00:17:42.268166: step 5400, loss 0.549296.
Train: 2018-08-01T00:17:43.002339: step 5401, loss 0.578935.
Train: 2018-08-01T00:17:43.174174: step 5402, loss 0.595074.
Train: 2018-08-01T00:17:43.330387: step 5403, loss 0.514387.
Train: 2018-08-01T00:17:43.502252: step 5404, loss 0.498167.
Train: 2018-08-01T00:17:43.658436: step 5405, loss 0.497991.
Train: 2018-08-01T00:17:43.814650: step 5406, loss 0.562717.
Train: 2018-08-01T00:17:43.986483: step 5407, loss 0.530084.
Train: 2018-08-01T00:17:44.142728: step 5408, loss 0.579.
Train: 2018-08-01T00:17:44.298942: step 5409, loss 0.661066.
Train: 2018-08-01T00:17:44.455154: step 5410, loss 0.677616.
Test: 2018-08-01T00:17:44.923795: step 5410, loss 0.548853.
Train: 2018-08-01T00:17:45.095624: step 5411, loss 0.546183.
Train: 2018-08-01T00:17:45.251844: step 5412, loss 0.562605.
Train: 2018-08-01T00:17:45.408064: step 5413, loss 0.496915.
Train: 2018-08-01T00:17:45.579891: step 5414, loss 0.579036.
Train: 2018-08-01T00:17:45.751721: step 5415, loss 0.611968.
Train: 2018-08-01T00:17:45.907934: step 5416, loss 0.595513.
Train: 2018-08-01T00:17:46.079774: step 5417, loss 0.513187.
Train: 2018-08-01T00:17:46.235957: step 5418, loss 0.421957.
Train: 2018-08-01T00:17:46.392170: step 5419, loss 0.479888.
Train: 2018-08-01T00:17:46.548415: step 5420, loss 0.562513.
Test: 2018-08-01T00:17:47.032677: step 5420, loss 0.548526.
Train: 2018-08-01T00:17:47.188889: step 5421, loss 0.729198.
Train: 2018-08-01T00:17:47.345097: step 5422, loss 0.595857.
Train: 2018-08-01T00:17:47.501285: step 5423, loss 0.462299.
Train: 2018-08-01T00:17:47.673121: step 5424, loss 0.495536.
Train: 2018-08-01T00:17:47.829364: step 5425, loss 0.579233.
Train: 2018-08-01T00:17:48.001168: step 5426, loss 0.49513.
Train: 2018-08-01T00:17:48.157413: step 5427, loss 0.478001.
Train: 2018-08-01T00:17:48.313626: step 5428, loss 0.57937.
Train: 2018-08-01T00:17:48.469845: step 5429, loss 0.562402.
Train: 2018-08-01T00:17:48.626053: step 5430, loss 0.664889.
Test: 2018-08-01T00:17:49.094693: step 5430, loss 0.548071.
Train: 2018-08-01T00:17:49.250907: step 5431, loss 0.493966.
Train: 2018-08-01T00:17:49.422742: step 5432, loss 0.648139.
Train: 2018-08-01T00:17:49.578954: step 5433, loss 0.579559.
Train: 2018-08-01T00:17:49.735138: step 5434, loss 0.59674.
Train: 2018-08-01T00:17:49.891352: step 5435, loss 0.442198.
Train: 2018-08-01T00:17:50.063193: step 5436, loss 0.527994.
Train: 2018-08-01T00:17:50.203779: step 5437, loss 0.458975.
Train: 2018-08-01T00:17:50.375613: step 5438, loss 0.510515.
Train: 2018-08-01T00:17:50.531857: step 5439, loss 0.54505.
Train: 2018-08-01T00:17:50.688070: step 5440, loss 0.579848.
Test: 2018-08-01T00:17:51.172302: step 5440, loss 0.5478.
Train: 2018-08-01T00:17:51.328516: step 5441, loss 0.457578.
Train: 2018-08-01T00:17:51.484754: step 5442, loss 0.439619.
Train: 2018-08-01T00:17:51.640972: step 5443, loss 0.527201.
Train: 2018-08-01T00:17:51.797186: step 5444, loss 0.580257.
Train: 2018-08-01T00:17:51.969020: step 5445, loss 0.526937.
Train: 2018-08-01T00:17:52.125234: step 5446, loss 0.437392.
Train: 2018-08-01T00:17:52.297037: step 5447, loss 0.580639.
Train: 2018-08-01T00:17:52.437661: step 5448, loss 0.490455.
Train: 2018-08-01T00:17:52.609489: step 5449, loss 0.58092.
Train: 2018-08-01T00:17:52.765709: step 5450, loss 0.581045.
Test: 2018-08-01T00:17:53.234349: step 5450, loss 0.547567.
Train: 2018-08-01T00:17:53.406153: step 5451, loss 0.635971.
Train: 2018-08-01T00:17:53.562397: step 5452, loss 0.562894.
Train: 2018-08-01T00:17:53.718610: step 5453, loss 0.617886.
Train: 2018-08-01T00:17:53.874795: step 5454, loss 0.507935.
Train: 2018-08-01T00:17:54.046628: step 5455, loss 0.507912.
Train: 2018-08-01T00:17:54.202841: step 5456, loss 0.526228.
Train: 2018-08-01T00:17:54.359087: step 5457, loss 0.562963.
Train: 2018-08-01T00:17:54.546536: step 5458, loss 0.562978.
Train: 2018-08-01T00:17:54.702755: step 5459, loss 0.507769.
Train: 2018-08-01T00:17:54.858938: step 5460, loss 0.581429.
Test: 2018-08-01T00:17:55.327579: step 5460, loss 0.547577.
Train: 2018-08-01T00:17:55.483820: step 5461, loss 0.581445.
Train: 2018-08-01T00:17:55.671279: step 5462, loss 0.636733.
Train: 2018-08-01T00:17:55.827491: step 5463, loss 0.562988.
Train: 2018-08-01T00:17:55.983674: step 5464, loss 0.544583.
Train: 2018-08-01T00:17:56.139918: step 5465, loss 0.544585.
Train: 2018-08-01T00:17:56.311753: step 5466, loss 0.581265.
Train: 2018-08-01T00:17:56.467936: step 5467, loss 0.489652.
Train: 2018-08-01T00:17:56.639772: step 5468, loss 0.544591.
Train: 2018-08-01T00:17:56.780363: step 5469, loss 0.526298.
Train: 2018-08-01T00:17:56.952198: step 5470, loss 0.581178.
Test: 2018-08-01T00:17:57.420869: step 5470, loss 0.547567.
Train: 2018-08-01T00:17:57.577082: step 5471, loss 0.581158.
Train: 2018-08-01T00:17:57.748922: step 5472, loss 0.581126.
Train: 2018-08-01T00:17:57.889508: step 5473, loss 0.581082.
Train: 2018-08-01T00:17:58.061343: step 5474, loss 0.435343.
Train: 2018-08-01T00:17:58.217526: step 5475, loss 0.562818.
Train: 2018-08-01T00:17:58.373765: step 5476, loss 0.50819.
Train: 2018-08-01T00:17:58.529980: step 5477, loss 0.508173.
Train: 2018-08-01T00:17:58.701788: step 5478, loss 0.654.
Train: 2018-08-01T00:17:58.858002: step 5479, loss 0.672157.
Train: 2018-08-01T00:17:59.014214: step 5480, loss 0.508251.
Test: 2018-08-01T00:17:59.482885: step 5480, loss 0.547572.
Train: 2018-08-01T00:17:59.639099: step 5481, loss 0.526465.
Train: 2018-08-01T00:17:59.795313: step 5482, loss 0.544624.
Train: 2018-08-01T00:17:59.967152: step 5483, loss 0.580871.
Train: 2018-08-01T00:18:00.123361: step 5484, loss 0.472235.
Train: 2018-08-01T00:18:00.279568: step 5485, loss 0.490335.
Train: 2018-08-01T00:18:00.435781: step 5486, loss 0.490288.
Train: 2018-08-01T00:18:00.592001: step 5487, loss 0.508339.
Train: 2018-08-01T00:18:00.763806: step 5488, loss 0.617323.
Train: 2018-08-01T00:18:00.920049: step 5489, loss 0.580994.
Train: 2018-08-01T00:18:01.091853: step 5490, loss 0.635595.
Test: 2018-08-01T00:18:01.576114: step 5490, loss 0.54757.
Train: 2018-08-01T00:18:01.732359: step 5491, loss 0.635515.
Train: 2018-08-01T00:18:01.888541: step 5492, loss 0.526478.
Train: 2018-08-01T00:18:02.044780: step 5493, loss 0.490279.
Train: 2018-08-01T00:18:02.232211: step 5494, loss 0.490311.
Train: 2018-08-01T00:18:02.372804: step 5495, loss 0.508405.
Train: 2018-08-01T00:18:02.544662: step 5496, loss 0.490241.
Train: 2018-08-01T00:18:02.700851: step 5497, loss 0.635404.
Train: 2018-08-01T00:18:02.857065: step 5498, loss 0.617263.
Train: 2018-08-01T00:18:03.013279: step 5499, loss 0.56277.
Train: 2018-08-01T00:18:03.185115: step 5500, loss 0.453957.
Test: 2018-08-01T00:18:03.653778: step 5500, loss 0.547573.
Train: 2018-08-01T00:18:04.341092: step 5501, loss 0.526479.
Train: 2018-08-01T00:18:04.497330: step 5502, loss 0.453827.
Train: 2018-08-01T00:18:04.653550: step 5503, loss 0.581.
Train: 2018-08-01T00:18:04.809733: step 5504, loss 0.708587.
Train: 2018-08-01T00:18:04.981597: step 5505, loss 0.635625.
Train: 2018-08-01T00:18:05.137805: step 5506, loss 0.617284.
Train: 2018-08-01T00:18:05.293995: step 5507, loss 0.653332.
Train: 2018-08-01T00:18:05.465829: step 5508, loss 0.54465.
Train: 2018-08-01T00:18:05.622043: step 5509, loss 0.490717.
Train: 2018-08-01T00:18:05.793878: step 5510, loss 0.526743.
Test: 2018-08-01T00:18:06.262548: step 5510, loss 0.547613.
Train: 2018-08-01T00:18:06.418762: step 5511, loss 0.419301.
Train: 2018-08-01T00:18:06.606211: step 5512, loss 0.580538.
Train: 2018-08-01T00:18:06.762430: step 5513, loss 0.508861.
Train: 2018-08-01T00:18:06.918614: step 5514, loss 0.598477.
Train: 2018-08-01T00:18:07.074852: step 5515, loss 0.472998.
Train: 2018-08-01T00:18:07.231040: step 5516, loss 0.56263.
Train: 2018-08-01T00:18:07.387288: step 5517, loss 0.52673.
Train: 2018-08-01T00:18:07.543499: step 5518, loss 0.544677.
Train: 2018-08-01T00:18:07.730954: step 5519, loss 0.54467.
Train: 2018-08-01T00:18:07.887167: step 5520, loss 0.634694.
Test: 2018-08-01T00:18:08.355807: step 5520, loss 0.547593.
Train: 2018-08-01T00:18:08.512023: step 5521, loss 0.598669.
Train: 2018-08-01T00:18:08.668204: step 5522, loss 0.634594.
Train: 2018-08-01T00:18:08.840064: step 5523, loss 0.508788.
Train: 2018-08-01T00:18:08.996252: step 5524, loss 0.634333.
Train: 2018-08-01T00:18:09.168118: step 5525, loss 0.526823.
Train: 2018-08-01T00:18:09.324330: step 5526, loss 0.491147.
Train: 2018-08-01T00:18:09.464923: step 5527, loss 0.616123.
Train: 2018-08-01T00:18:09.636727: step 5528, loss 0.616033.
Train: 2018-08-01T00:18:09.808594: step 5529, loss 0.633683.
Train: 2018-08-01T00:18:09.964805: step 5530, loss 0.562521.
Test: 2018-08-01T00:18:10.433446: step 5530, loss 0.547696.
Train: 2018-08-01T00:18:10.589630: step 5531, loss 0.544821.
Train: 2018-08-01T00:18:10.761464: step 5532, loss 0.597753.
Train: 2018-08-01T00:18:10.917709: step 5533, loss 0.439368.
Train: 2018-08-01T00:18:11.073891: step 5534, loss 0.509749.
Train: 2018-08-01T00:18:11.230128: step 5535, loss 0.615168.
Train: 2018-08-01T00:18:11.401964: step 5536, loss 0.720434.
Train: 2018-08-01T00:18:11.558183: step 5537, loss 0.544943.
Train: 2018-08-01T00:18:11.714396: step 5538, loss 0.63223.
Train: 2018-08-01T00:18:11.870610: step 5539, loss 0.458081.
Train: 2018-08-01T00:18:12.042415: step 5540, loss 0.597132.
Test: 2018-08-01T00:18:12.557942: step 5540, loss 0.547899.
Train: 2018-08-01T00:18:12.714162: step 5541, loss 0.631704.
Train: 2018-08-01T00:18:12.870376: step 5542, loss 0.579675.
Train: 2018-08-01T00:18:13.042206: step 5543, loss 0.596844.
Train: 2018-08-01T00:18:13.214045: step 5544, loss 0.47655.
Train: 2018-08-01T00:18:13.370229: step 5545, loss 0.493826.
Train: 2018-08-01T00:18:13.526442: step 5546, loss 0.579532.
Train: 2018-08-01T00:18:13.682656: step 5547, loss 0.596648.
Train: 2018-08-01T00:18:13.854515: step 5548, loss 0.52818.
Train: 2018-08-01T00:18:14.010728: step 5549, loss 0.511092.
Train: 2018-08-01T00:18:14.198159: step 5550, loss 0.630831.
Test: 2018-08-01T00:18:14.666798: step 5550, loss 0.548079.
Train: 2018-08-01T00:18:14.838634: step 5551, loss 0.511104.
Train: 2018-08-01T00:18:14.994848: step 5552, loss 0.665004.
Train: 2018-08-01T00:18:15.151062: step 5553, loss 0.562398.
Train: 2018-08-01T00:18:15.322897: step 5554, loss 0.647685.
Train: 2018-08-01T00:18:15.479109: step 5555, loss 0.545386.
Train: 2018-08-01T00:18:15.650974: step 5556, loss 0.528437.
Train: 2018-08-01T00:18:15.807188: step 5557, loss 0.528477.
Train: 2018-08-01T00:18:15.963401: step 5558, loss 0.613286.
Train: 2018-08-01T00:18:16.119614: step 5559, loss 0.528535.
Train: 2018-08-01T00:18:16.275798: step 5560, loss 0.562415.
Test: 2018-08-01T00:18:16.744437: step 5560, loss 0.548243.
Train: 2018-08-01T00:18:16.900681: step 5561, loss 0.545491.
Train: 2018-08-01T00:18:17.056864: step 5562, loss 0.528567.
Train: 2018-08-01T00:18:17.213104: step 5563, loss 0.613217.
Train: 2018-08-01T00:18:17.369321: step 5564, loss 0.528555.
Train: 2018-08-01T00:18:17.541151: step 5565, loss 0.528542.
Train: 2018-08-01T00:18:17.697370: step 5566, loss 0.52851.
Train: 2018-08-01T00:18:17.853553: step 5567, loss 0.630305.
Train: 2018-08-01T00:18:18.009766: step 5568, loss 0.579386.
Train: 2018-08-01T00:18:18.166011: step 5569, loss 0.579385.
Train: 2018-08-01T00:18:18.322194: step 5570, loss 0.596354.
Test: 2018-08-01T00:18:18.806485: step 5570, loss 0.548208.
Train: 2018-08-01T00:18:18.978291: step 5571, loss 0.579371.
Train: 2018-08-01T00:18:19.150155: step 5572, loss 0.579358.
Train: 2018-08-01T00:18:19.321962: step 5573, loss 0.680916.
Train: 2018-08-01T00:18:19.493819: step 5574, loss 0.579307.
Train: 2018-08-01T00:18:19.681250: step 5575, loss 0.646624.
Train: 2018-08-01T00:18:19.837465: step 5576, loss 0.512123.
Train: 2018-08-01T00:18:19.993707: step 5577, loss 0.595935.
Train: 2018-08-01T00:18:20.150337: step 5578, loss 0.57917.
Train: 2018-08-01T00:18:20.322172: step 5579, loss 0.545847.
Train: 2018-08-01T00:18:20.478380: step 5580, loss 0.579125.
Test: 2018-08-01T00:18:20.947853: step 5580, loss 0.548634.
Train: 2018-08-01T00:18:21.165540: step 5581, loss 0.529352.
Train: 2018-08-01T00:18:21.337345: step 5582, loss 0.529395.
Train: 2018-08-01T00:18:21.509182: step 5583, loss 0.512844.
Train: 2018-08-01T00:18:21.681016: step 5584, loss 0.678545.
Train: 2018-08-01T00:18:21.852851: step 5585, loss 0.529426.
Train: 2018-08-01T00:18:22.024685: step 5586, loss 0.562538.
Train: 2018-08-01T00:18:22.180899: step 5587, loss 0.52945.
Train: 2018-08-01T00:18:22.337112: step 5588, loss 0.52943.
Train: 2018-08-01T00:18:22.508982: step 5589, loss 0.496242.
Train: 2018-08-01T00:18:22.680805: step 5590, loss 0.562512.
Test: 2018-08-01T00:18:23.149450: step 5590, loss 0.548561.
Train: 2018-08-01T00:18:23.321286: step 5591, loss 0.728923.
Train: 2018-08-01T00:18:23.477502: step 5592, loss 0.462718.
Train: 2018-08-01T00:18:23.649328: step 5593, loss 0.429306.
Train: 2018-08-01T00:18:23.805548: step 5594, loss 0.44556.
Train: 2018-08-01T00:18:23.961761: step 5595, loss 0.579232.
Train: 2018-08-01T00:18:24.133565: step 5596, loss 0.562431.
Train: 2018-08-01T00:18:24.289779: step 5597, loss 0.511669.
Train: 2018-08-01T00:18:24.446017: step 5598, loss 0.61337.
Train: 2018-08-01T00:18:24.602236: step 5599, loss 0.57944.
Train: 2018-08-01T00:18:24.774070: step 5600, loss 0.528234.
Test: 2018-08-01T00:18:25.246215: step 5600, loss 0.548052.
Train: 2018-08-01T00:18:26.009080: step 5601, loss 0.665172.
Train: 2018-08-01T00:18:26.180885: step 5602, loss 0.528105.
Train: 2018-08-01T00:18:26.352745: step 5603, loss 0.459384.
Train: 2018-08-01T00:18:26.508971: step 5604, loss 0.459099.
Train: 2018-08-01T00:18:26.665178: step 5605, loss 0.666115.
Train: 2018-08-01T00:18:26.821359: step 5606, loss 0.597047.
Train: 2018-08-01T00:18:26.993194: step 5607, loss 0.631781.
Train: 2018-08-01T00:18:27.149440: step 5608, loss 0.579754.
Train: 2018-08-01T00:18:27.305622: step 5609, loss 0.59709.
Train: 2018-08-01T00:18:27.477492: step 5610, loss 0.63172.
Test: 2018-08-01T00:18:27.946126: step 5610, loss 0.547918.
Train: 2018-08-01T00:18:28.102310: step 5611, loss 0.614298.
Train: 2018-08-01T00:18:28.274174: step 5612, loss 0.596915.
Train: 2018-08-01T00:18:28.430357: step 5613, loss 0.614032.
Train: 2018-08-01T00:18:28.602192: step 5614, loss 0.579552.
Train: 2018-08-01T00:18:28.758436: step 5615, loss 0.665015.
Train: 2018-08-01T00:18:28.914619: step 5616, loss 0.511317.
Train: 2018-08-01T00:18:29.070834: step 5617, loss 0.511484.
Train: 2018-08-01T00:18:29.242698: step 5618, loss 0.630175.
Train: 2018-08-01T00:18:29.398913: step 5619, loss 0.596207.
Train: 2018-08-01T00:18:29.555119: step 5620, loss 0.528751.
Test: 2018-08-01T00:18:30.023764: step 5620, loss 0.548371.
Train: 2018-08-01T00:18:30.179948: step 5621, loss 0.596054.
Train: 2018-08-01T00:18:30.336162: step 5622, loss 0.67981.
Train: 2018-08-01T00:18:30.492405: step 5623, loss 0.529078.
Train: 2018-08-01T00:18:30.648614: step 5624, loss 0.612446.
Train: 2018-08-01T00:18:30.836075: step 5625, loss 0.579112.
Train: 2018-08-01T00:18:30.992282: step 5626, loss 0.579084.
Train: 2018-08-01T00:18:31.148471: step 5627, loss 0.562566.
Train: 2018-08-01T00:18:31.304716: step 5628, loss 0.595489.
Train: 2018-08-01T00:18:31.460929: step 5629, loss 0.529802.
Train: 2018-08-01T00:18:31.632732: step 5630, loss 0.447991.
Test: 2018-08-01T00:18:32.101403: step 5630, loss 0.548905.
Train: 2018-08-01T00:18:32.257617: step 5631, loss 0.644552.
Train: 2018-08-01T00:18:32.413824: step 5632, loss 0.529888.
Train: 2018-08-01T00:18:32.570044: step 5633, loss 0.562633.
Train: 2018-08-01T00:18:32.741881: step 5634, loss 0.644515.
Train: 2018-08-01T00:18:32.913683: step 5635, loss 0.546281.
Train: 2018-08-01T00:18:33.069896: step 5636, loss 0.51359.
Train: 2018-08-01T00:18:33.226134: step 5637, loss 0.529918.
Train: 2018-08-01T00:18:33.382349: step 5638, loss 0.529866.
Train: 2018-08-01T00:18:33.538537: step 5639, loss 0.595432.
Train: 2018-08-01T00:18:33.694780: step 5640, loss 0.595461.
Test: 2018-08-01T00:18:34.163422: step 5640, loss 0.548824.
Train: 2018-08-01T00:18:34.335255: step 5641, loss 0.54615.
Train: 2018-08-01T00:18:34.491438: step 5642, loss 0.611964.
Train: 2018-08-01T00:18:34.647653: step 5643, loss 0.628441.
Train: 2018-08-01T00:18:34.803865: step 5644, loss 0.513224.
Train: 2018-08-01T00:18:34.960108: step 5645, loss 0.463824.
Train: 2018-08-01T00:18:35.131915: step 5646, loss 0.562565.
Train: 2018-08-01T00:18:35.288151: step 5647, loss 0.595604.
Train: 2018-08-01T00:18:35.444371: step 5648, loss 0.595639.
Train: 2018-08-01T00:18:35.600555: step 5649, loss 0.512836.
Train: 2018-08-01T00:18:35.756768: step 5650, loss 0.595704.
Test: 2018-08-01T00:18:36.241059: step 5650, loss 0.5486.
Train: 2018-08-01T00:18:36.381651: step 5651, loss 0.545899.
Train: 2018-08-01T00:18:36.553486: step 5652, loss 0.479331.
Train: 2018-08-01T00:18:36.694049: step 5653, loss 0.495769.
Train: 2018-08-01T00:18:36.865912: step 5654, loss 0.528986.
Train: 2018-08-01T00:18:37.022125: step 5655, loss 0.629654.
Train: 2018-08-01T00:18:37.178334: step 5656, loss 0.646651.
Train: 2018-08-01T00:18:37.350169: step 5657, loss 0.579289.
Train: 2018-08-01T00:18:37.506358: step 5658, loss 0.461207.
Train: 2018-08-01T00:18:37.678193: step 5659, loss 0.596234.
Train: 2018-08-01T00:18:37.818785: step 5660, loss 0.545482.
Test: 2018-08-01T00:18:38.303046: step 5660, loss 0.548207.
Train: 2018-08-01T00:18:38.459259: step 5661, loss 0.596332.
Train: 2018-08-01T00:18:38.615473: step 5662, loss 0.494495.
Train: 2018-08-01T00:18:38.771714: step 5663, loss 0.562404.
Train: 2018-08-01T00:18:38.927930: step 5664, loss 0.477184.
Train: 2018-08-01T00:18:39.084113: step 5665, loss 0.562397.
Train: 2018-08-01T00:18:39.240326: step 5666, loss 0.562396.
Train: 2018-08-01T00:18:39.396540: step 5667, loss 0.528034.
Train: 2018-08-01T00:18:39.552778: step 5668, loss 0.631305.
Train: 2018-08-01T00:18:39.708997: step 5669, loss 0.562399.
Train: 2018-08-01T00:18:39.880801: step 5670, loss 0.579671.
Test: 2018-08-01T00:18:40.349472: step 5670, loss 0.547928.
Train: 2018-08-01T00:18:40.505686: step 5671, loss 0.527832.
Train: 2018-08-01T00:18:40.693111: step 5672, loss 0.441265.
Train: 2018-08-01T00:18:40.849324: step 5673, loss 0.545055.
Train: 2018-08-01T00:18:41.005538: step 5674, loss 0.510209.
Train: 2018-08-01T00:18:41.161783: step 5675, loss 0.544971.
Train: 2018-08-01T00:18:41.317995: step 5676, loss 0.544931.
Train: 2018-08-01T00:18:41.489830: step 5677, loss 0.615155.
Train: 2018-08-01T00:18:41.646014: step 5678, loss 0.56247.
Train: 2018-08-01T00:18:41.817873: step 5679, loss 0.597727.
Train: 2018-08-01T00:18:41.974092: step 5680, loss 0.562484.
Test: 2018-08-01T00:18:42.442731: step 5680, loss 0.547709.
Train: 2018-08-01T00:18:42.598940: step 5681, loss 0.580137.
Train: 2018-08-01T00:18:42.770750: step 5682, loss 0.56249.
Train: 2018-08-01T00:18:42.942585: step 5683, loss 0.491873.
Train: 2018-08-01T00:18:43.098827: step 5684, loss 0.580169.
Train: 2018-08-01T00:18:43.255011: step 5685, loss 0.562501.
Train: 2018-08-01T00:18:43.411249: step 5686, loss 0.562503.
Train: 2018-08-01T00:18:43.567438: step 5687, loss 0.562505.
Train: 2018-08-01T00:18:43.739303: step 5688, loss 0.615591.
Train: 2018-08-01T00:18:43.895487: step 5689, loss 0.527138.
Train: 2018-08-01T00:18:44.051737: step 5690, loss 0.633205.
Test: 2018-08-01T00:18:44.520369: step 5690, loss 0.547708.
Train: 2018-08-01T00:18:44.676583: step 5691, loss 0.633099.
Train: 2018-08-01T00:18:44.832797: step 5692, loss 0.632919.
Train: 2018-08-01T00:18:45.004601: step 5693, loss 0.562456.
Train: 2018-08-01T00:18:45.176467: step 5694, loss 0.474932.
Train: 2018-08-01T00:18:45.332649: step 5695, loss 0.57991.
Train: 2018-08-01T00:18:45.488864: step 5696, loss 0.510087.
Train: 2018-08-01T00:18:45.645106: step 5697, loss 0.579858.
Train: 2018-08-01T00:18:45.816911: step 5698, loss 0.562421.
Train: 2018-08-01T00:18:45.973157: step 5699, loss 0.597216.
Train: 2018-08-01T00:18:46.129338: step 5700, loss 0.666658.
Test: 2018-08-01T00:18:46.613630: step 5700, loss 0.547899.
Train: 2018-08-01T00:18:47.347802: step 5701, loss 0.614378.
Train: 2018-08-01T00:18:47.504016: step 5702, loss 0.52787.
Train: 2018-08-01T00:18:47.660229: step 5703, loss 0.579617.
Train: 2018-08-01T00:18:47.816476: step 5704, loss 0.562396.
Train: 2018-08-01T00:18:47.972687: step 5705, loss 0.545261.
Train: 2018-08-01T00:18:48.128870: step 5706, loss 0.528191.
Train: 2018-08-01T00:18:48.316327: step 5707, loss 0.579481.
Train: 2018-08-01T00:18:48.472539: step 5708, loss 0.596522.
Train: 2018-08-01T00:18:48.628753: step 5709, loss 0.596468.
Train: 2018-08-01T00:18:48.784967: step 5710, loss 0.511408.
Test: 2018-08-01T00:18:49.269257: step 5710, loss 0.548186.
Train: 2018-08-01T00:18:49.456715: step 5711, loss 0.494477.
Train: 2018-08-01T00:18:49.612928: step 5712, loss 0.562407.
Train: 2018-08-01T00:18:49.769143: step 5713, loss 0.681336.
Train: 2018-08-01T00:18:49.925355: step 5714, loss 0.579372.
Train: 2018-08-01T00:18:50.081562: step 5715, loss 0.562415.
Train: 2018-08-01T00:18:50.237781: step 5716, loss 0.663874.
Train: 2018-08-01T00:18:50.393965: step 5717, loss 0.646732.
Train: 2018-08-01T00:18:50.581445: step 5718, loss 0.663218.
Train: 2018-08-01T00:18:50.737664: step 5719, loss 0.544647.
Train: 2018-08-01T00:18:50.893873: step 5720, loss 0.545856.
Test: 2018-08-01T00:18:51.362488: step 5720, loss 0.548633.
Train: 2018-08-01T00:18:51.518728: step 5721, loss 0.595692.
Train: 2018-08-01T00:18:51.690566: step 5722, loss 0.595604.
Train: 2018-08-01T00:18:51.846779: step 5723, loss 0.562579.
Train: 2018-08-01T00:18:52.002993: step 5724, loss 0.644698.
Train: 2018-08-01T00:18:52.159176: step 5725, loss 0.595352.
Train: 2018-08-01T00:18:52.331041: step 5726, loss 0.530113.
Train: 2018-08-01T00:18:52.487254: step 5727, loss 0.481514.
Train: 2018-08-01T00:18:52.659059: step 5728, loss 0.578957.
Train: 2018-08-01T00:18:52.799682: step 5729, loss 0.546534.
Train: 2018-08-01T00:18:52.971522: step 5730, loss 0.530342.
Test: 2018-08-01T00:18:53.440127: step 5730, loss 0.54917.
Train: 2018-08-01T00:18:53.596364: step 5731, loss 0.562743.
Train: 2018-08-01T00:18:53.768199: step 5732, loss 0.578956.
Train: 2018-08-01T00:18:53.924418: step 5733, loss 0.643863.
Train: 2018-08-01T00:18:54.080632: step 5734, loss 0.5141.
Train: 2018-08-01T00:18:54.252460: step 5735, loss 0.627612.
Train: 2018-08-01T00:18:54.408681: step 5736, loss 0.530326.
Train: 2018-08-01T00:18:54.564893: step 5737, loss 0.562742.
Train: 2018-08-01T00:18:54.721107: step 5738, loss 0.546518.
Train: 2018-08-01T00:18:54.892911: step 5739, loss 0.546495.
Train: 2018-08-01T00:18:55.049155: step 5740, loss 0.595217.
Test: 2018-08-01T00:18:55.517794: step 5740, loss 0.549085.
Train: 2018-08-01T00:18:55.673978: step 5741, loss 0.530175.
Train: 2018-08-01T00:18:55.830225: step 5742, loss 0.530113.
Train: 2018-08-01T00:18:56.002026: step 5743, loss 0.464743.
Train: 2018-08-01T00:18:56.158240: step 5744, loss 0.579009.
Train: 2018-08-01T00:18:56.314454: step 5745, loss 0.546167.
Train: 2018-08-01T00:18:56.470697: step 5746, loss 0.56257.
Train: 2018-08-01T00:18:56.626910: step 5747, loss 0.546007.
Train: 2018-08-01T00:18:56.783094: step 5748, loss 0.612287.
Train: 2018-08-01T00:18:56.923686: step 5749, loss 0.496006.
Train: 2018-08-01T00:18:57.111171: step 5750, loss 0.479101.
Test: 2018-08-01T00:18:57.595403: step 5750, loss 0.548436.
Train: 2018-08-01T00:18:57.751646: step 5751, loss 0.579208.
Train: 2018-08-01T00:18:57.907830: step 5752, loss 0.478399.
Train: 2018-08-01T00:18:58.064045: step 5753, loss 0.511762.
Train: 2018-08-01T00:18:58.235879: step 5754, loss 0.545436.
Train: 2018-08-01T00:18:58.407738: step 5755, loss 0.528291.
Train: 2018-08-01T00:18:58.563957: step 5756, loss 0.630945.
Train: 2018-08-01T00:18:58.720175: step 5757, loss 0.596784.
Train: 2018-08-01T00:18:58.876353: step 5758, loss 0.579634.
Train: 2018-08-01T00:18:59.032598: step 5759, loss 0.5624.
Train: 2018-08-01T00:18:59.188813: step 5760, loss 0.527806.
Test: 2018-08-01T00:18:59.673042: step 5760, loss 0.547893.
Train: 2018-08-01T00:18:59.829285: step 5761, loss 0.475741.
Train: 2018-08-01T00:18:59.985468: step 5762, loss 0.492869.
Train: 2018-08-01T00:19:00.141681: step 5763, loss 0.667142.
Train: 2018-08-01T00:19:00.313518: step 5764, loss 0.492505.
Train: 2018-08-01T00:19:00.485351: step 5765, loss 0.579975.
Train: 2018-08-01T00:19:00.625974: step 5766, loss 0.509773.
Train: 2018-08-01T00:19:00.782189: step 5767, loss 0.544868.
Train: 2018-08-01T00:19:00.954022: step 5768, loss 0.615426.
Train: 2018-08-01T00:19:01.110204: step 5769, loss 0.562496.
Train: 2018-08-01T00:19:01.266418: step 5770, loss 0.597877.
Test: 2018-08-01T00:19:01.719467: step 5770, loss 0.54769.
Train: 2018-08-01T00:19:01.891273: step 5771, loss 0.491735.
Train: 2018-08-01T00:19:02.047516: step 5772, loss 0.473944.
Train: 2018-08-01T00:19:02.203729: step 5773, loss 0.598039.
Train: 2018-08-01T00:19:02.359943: step 5774, loss 0.615879.
Train: 2018-08-01T00:19:02.531785: step 5775, loss 0.526976.
Train: 2018-08-01T00:19:02.687961: step 5776, loss 0.473562.
Train: 2018-08-01T00:19:02.844175: step 5777, loss 0.562568.
Train: 2018-08-01T00:19:03.000419: step 5778, loss 0.509013.
Train: 2018-08-01T00:19:03.156625: step 5779, loss 0.473144.
Train: 2018-08-01T00:19:03.312814: step 5780, loss 0.598517.
Test: 2018-08-01T00:19:03.797106: step 5780, loss 0.547598.
Train: 2018-08-01T00:19:03.953320: step 5781, loss 0.598608.
Train: 2018-08-01T00:19:04.109533: step 5782, loss 0.454682.
Train: 2018-08-01T00:19:04.265748: step 5783, loss 0.58073.
Train: 2018-08-01T00:19:04.437587: step 5784, loss 0.562712.
Train: 2018-08-01T00:19:04.593789: step 5785, loss 0.508451.
Train: 2018-08-01T00:19:04.765599: step 5786, loss 0.599001.
Train: 2018-08-01T00:19:04.906216: step 5787, loss 0.526482.
Train: 2018-08-01T00:19:05.062405: step 5788, loss 0.599101.
Train: 2018-08-01T00:19:05.218648: step 5789, loss 0.471949.
Train: 2018-08-01T00:19:05.390453: step 5790, loss 0.671951.
Test: 2018-08-01T00:19:05.859123: step 5790, loss 0.54757.
Train: 2018-08-01T00:19:05.999715: step 5791, loss 0.544613.
Train: 2018-08-01T00:19:06.171544: step 5792, loss 0.471911.
Train: 2018-08-01T00:19:06.327763: step 5793, loss 0.508234.
Train: 2018-08-01T00:19:06.483977: step 5794, loss 0.599239.
Train: 2018-08-01T00:19:06.640185: step 5795, loss 0.544606.
Train: 2018-08-01T00:19:06.812024: step 5796, loss 0.508155.
Train: 2018-08-01T00:19:06.983829: step 5797, loss 0.544601.
Train: 2018-08-01T00:19:07.124452: step 5798, loss 0.654137.
Train: 2018-08-01T00:19:07.280667: step 5799, loss 0.508112.
Train: 2018-08-01T00:19:07.436848: step 5800, loss 0.526358.
Test: 2018-08-01T00:19:07.905521: step 5800, loss 0.547567.
Train: 2018-08-01T00:19:08.624071: step 5801, loss 0.526353.
Train: 2018-08-01T00:19:08.795936: step 5802, loss 0.435063.
Train: 2018-08-01T00:19:08.952119: step 5803, loss 0.508009.
Train: 2018-08-01T00:19:09.108363: step 5804, loss 0.581256.
Train: 2018-08-01T00:19:09.264545: step 5805, loss 0.471129.
Train: 2018-08-01T00:19:09.420759: step 5806, loss 0.526172.
Train: 2018-08-01T00:19:09.576972: step 5807, loss 0.67376.
Train: 2018-08-01T00:19:09.733185: step 5808, loss 0.618433.
Train: 2018-08-01T00:19:09.889399: step 5809, loss 0.526125.
Train: 2018-08-01T00:19:10.045642: step 5810, loss 0.618377.
Test: 2018-08-01T00:19:10.529906: step 5810, loss 0.547577.
Train: 2018-08-01T00:19:10.701740: step 5811, loss 0.599864.
Train: 2018-08-01T00:19:10.857947: step 5812, loss 0.654951.
Train: 2018-08-01T00:19:11.014168: step 5813, loss 0.562925.
Train: 2018-08-01T00:19:11.169236: step 5814, loss 0.599444.
Train: 2018-08-01T00:19:11.341071: step 5815, loss 0.562826.
Train: 2018-08-01T00:19:11.497316: step 5816, loss 0.617262.
Train: 2018-08-01T00:19:11.653499: step 5817, loss 0.598907.
Train: 2018-08-01T00:19:11.809741: step 5818, loss 0.544661.
Train: 2018-08-01T00:19:11.981547: step 5819, loss 0.598528.
Train: 2018-08-01T00:19:12.137790: step 5820, loss 0.508967.
Test: 2018-08-01T00:19:12.606400: step 5820, loss 0.547641.
Train: 2018-08-01T00:19:12.762644: step 5821, loss 0.491278.
Train: 2018-08-01T00:19:12.918858: step 5822, loss 0.633704.
Train: 2018-08-01T00:19:13.075071: step 5823, loss 0.544786.
Train: 2018-08-01T00:19:13.231284: step 5824, loss 0.633297.
Train: 2018-08-01T00:19:13.403121: step 5825, loss 0.597763.
Train: 2018-08-01T00:19:13.559327: step 5826, loss 0.615193.
Train: 2018-08-01T00:19:13.715546: step 5827, loss 0.579947.
Train: 2018-08-01T00:19:13.871729: step 5828, loss 0.562425.
Train: 2018-08-01T00:19:14.027972: step 5829, loss 0.45819.
Train: 2018-08-01T00:19:14.184185: step 5830, loss 0.458373.
Test: 2018-08-01T00:19:14.668417: step 5830, loss 0.54789.
Train: 2018-08-01T00:19:14.824662: step 5831, loss 0.54507.
Train: 2018-08-01T00:19:14.980843: step 5832, loss 0.545068.
Train: 2018-08-01T00:19:15.137088: step 5833, loss 0.527717.
Train: 2018-08-01T00:19:15.293306: step 5834, loss 0.579772.
Train: 2018-08-01T00:19:15.449515: step 5835, loss 0.597148.
Train: 2018-08-01T00:19:15.605699: step 5836, loss 0.597141.
Train: 2018-08-01T00:19:15.777532: step 5837, loss 0.510355.
Train: 2018-08-01T00:19:15.933745: step 5838, loss 0.527704.
Train: 2018-08-01T00:19:16.074338: step 5839, loss 0.562412.
Train: 2018-08-01T00:19:16.246203: step 5840, loss 0.545042.
Test: 2018-08-01T00:19:16.714838: step 5840, loss 0.547859.
Train: 2018-08-01T00:19:16.886674: step 5841, loss 0.527651.
Train: 2018-08-01T00:19:17.042892: step 5842, loss 0.649421.
Train: 2018-08-01T00:19:17.199106: step 5843, loss 0.47545.
Train: 2018-08-01T00:19:17.355287: step 5844, loss 0.56242.
Train: 2018-08-01T00:19:17.511535: step 5845, loss 0.545.
Train: 2018-08-01T00:19:17.667716: step 5846, loss 0.544988.
Train: 2018-08-01T00:19:17.823929: step 5847, loss 0.597339.
Train: 2018-08-01T00:19:17.980172: step 5848, loss 0.684653.
Train: 2018-08-01T00:19:18.136391: step 5849, loss 0.510127.
Train: 2018-08-01T00:19:18.292593: step 5850, loss 0.597262.
Test: 2018-08-01T00:19:18.761209: step 5850, loss 0.547848.
Train: 2018-08-01T00:19:18.933045: step 5851, loss 0.52762.
Train: 2018-08-01T00:19:19.104878: step 5852, loss 0.631967.
Train: 2018-08-01T00:19:19.261091: step 5853, loss 0.649207.
Train: 2018-08-01T00:19:19.432958: step 5854, loss 0.648953.
Train: 2018-08-01T00:19:19.589140: step 5855, loss 0.631367.
Train: 2018-08-01T00:19:19.745353: step 5856, loss 0.510907.
Train: 2018-08-01T00:19:19.901601: step 5857, loss 0.562396.
Train: 2018-08-01T00:19:20.073403: step 5858, loss 0.613559.
Train: 2018-08-01T00:19:20.229645: step 5859, loss 0.579399.
Train: 2018-08-01T00:19:20.385829: step 5860, loss 0.562414.
Test: 2018-08-01T00:19:20.870120: step 5860, loss 0.548286.
Train: 2018-08-01T00:19:21.041955: step 5861, loss 0.562424.
Train: 2018-08-01T00:19:21.213759: step 5862, loss 0.61295.
Train: 2018-08-01T00:19:21.369973: step 5863, loss 0.562449.
Train: 2018-08-01T00:19:21.541809: step 5864, loss 0.528986.
Train: 2018-08-01T00:19:21.713674: step 5865, loss 0.612594.
Train: 2018-08-01T00:19:21.879395: step 5866, loss 0.529155.
Train: 2018-08-01T00:19:22.035607: step 5867, loss 0.59578.
Train: 2018-08-01T00:19:22.191797: step 5868, loss 0.612343.
Train: 2018-08-01T00:19:22.379277: step 5869, loss 0.612242.
Train: 2018-08-01T00:19:22.551111: step 5870, loss 0.512976.
Test: 2018-08-01T00:19:23.004135: step 5870, loss 0.548747.
Train: 2018-08-01T00:19:23.160319: step 5871, loss 0.678053.
Train: 2018-08-01T00:19:23.332154: step 5872, loss 0.546146.
Train: 2018-08-01T00:19:23.503988: step 5873, loss 0.529805.
Train: 2018-08-01T00:19:23.675822: step 5874, loss 0.644529.
Train: 2018-08-01T00:19:23.847659: step 5875, loss 0.546318.
Train: 2018-08-01T00:19:24.003873: step 5876, loss 0.562675.
Train: 2018-08-01T00:19:24.160086: step 5877, loss 0.595256.
Train: 2018-08-01T00:19:24.331919: step 5878, loss 0.51395.
Train: 2018-08-01T00:19:24.488169: step 5879, loss 0.578963.
Train: 2018-08-01T00:19:24.644376: step 5880, loss 0.562724.
Test: 2018-08-01T00:19:25.113011: step 5880, loss 0.549135.
Train: 2018-08-01T00:19:25.269199: step 5881, loss 0.562727.
Train: 2018-08-01T00:19:25.425444: step 5882, loss 0.59519.
Train: 2018-08-01T00:19:25.597249: step 5883, loss 0.432941.
Train: 2018-08-01T00:19:25.753460: step 5884, loss 0.513936.
Train: 2018-08-01T00:19:25.909674: step 5885, loss 0.595287.
Train: 2018-08-01T00:19:26.065918: step 5886, loss 0.562653.
Train: 2018-08-01T00:19:26.222102: step 5887, loss 0.497122.
Train: 2018-08-01T00:19:26.376728: step 5888, loss 0.5626.
Train: 2018-08-01T00:19:26.548562: step 5889, loss 0.463687.
Train: 2018-08-01T00:19:26.704752: step 5890, loss 0.496311.
Test: 2018-08-01T00:19:27.173392: step 5890, loss 0.54856.
Train: 2018-08-01T00:19:27.329634: step 5891, loss 0.529209.
Train: 2018-08-01T00:19:27.485818: step 5892, loss 0.562464.
Train: 2018-08-01T00:19:27.642032: step 5893, loss 0.596073.
Train: 2018-08-01T00:19:27.813895: step 5894, loss 0.545541.
Train: 2018-08-01T00:19:27.970110: step 5895, loss 0.596309.
Train: 2018-08-01T00:19:28.126294: step 5896, loss 0.579404.
Train: 2018-08-01T00:19:28.282537: step 5897, loss 0.596481.
Train: 2018-08-01T00:19:28.438750: step 5898, loss 0.716018.
Train: 2018-08-01T00:19:28.610556: step 5899, loss 0.545346.
Train: 2018-08-01T00:19:28.766801: step 5900, loss 0.545355.
Test: 2018-08-01T00:19:29.251059: step 5900, loss 0.54813.
Train: 2018-08-01T00:19:29.922748: step 5901, loss 0.613527.
Train: 2018-08-01T00:19:30.094608: step 5902, loss 0.545376.
Train: 2018-08-01T00:19:30.250826: step 5903, loss 0.511352.
Train: 2018-08-01T00:19:30.407039: step 5904, loss 0.528356.
Train: 2018-08-01T00:19:30.563223: step 5905, loss 0.64759.
Train: 2018-08-01T00:19:30.719466: step 5906, loss 0.511315.
Train: 2018-08-01T00:19:30.891304: step 5907, loss 0.562401.
Train: 2018-08-01T00:19:31.047485: step 5908, loss 0.460157.
Train: 2018-08-01T00:19:31.203721: step 5909, loss 0.630693.
Train: 2018-08-01T00:19:31.359940: step 5910, loss 0.596568.
Test: 2018-08-01T00:19:31.828550: step 5910, loss 0.548089.
Train: 2018-08-01T00:19:31.984788: step 5911, loss 0.613659.
Train: 2018-08-01T00:19:32.156599: step 5912, loss 0.562398.
Train: 2018-08-01T00:19:32.312812: step 5913, loss 0.562399.
Train: 2018-08-01T00:19:32.469026: step 5914, loss 0.511232.
Train: 2018-08-01T00:19:32.625239: step 5915, loss 0.494152.
Train: 2018-08-01T00:19:32.781478: step 5916, loss 0.494055.
Train: 2018-08-01T00:19:32.937691: step 5917, loss 0.716527.
Train: 2018-08-01T00:19:33.093879: step 5918, loss 0.511034.
Train: 2018-08-01T00:19:33.265714: step 5919, loss 0.613786.
Train: 2018-08-01T00:19:33.421928: step 5920, loss 0.511021.
Test: 2018-08-01T00:19:33.890601: step 5920, loss 0.548048.
Train: 2018-08-01T00:19:34.046806: step 5921, loss 0.528127.
Train: 2018-08-01T00:19:34.202995: step 5922, loss 0.562395.
Train: 2018-08-01T00:19:34.374829: step 5923, loss 0.425058.
Train: 2018-08-01T00:19:34.531073: step 5924, loss 0.596832.
Train: 2018-08-01T00:19:34.687257: step 5925, loss 0.545145.
Train: 2018-08-01T00:19:34.843501: step 5926, loss 0.545112.
Train: 2018-08-01T00:19:34.999683: step 5927, loss 0.666372.
Train: 2018-08-01T00:19:35.155896: step 5928, loss 0.475742.
Train: 2018-08-01T00:19:35.312110: step 5929, loss 0.597132.
Train: 2018-08-01T00:19:35.468324: step 5930, loss 0.614538.
Test: 2018-08-01T00:19:35.936994: step 5930, loss 0.547865.
Train: 2018-08-01T00:19:36.093207: step 5931, loss 0.579787.
Train: 2018-08-01T00:19:36.265045: step 5932, loss 0.527678.
Train: 2018-08-01T00:19:36.421255: step 5933, loss 0.631891.
Train: 2018-08-01T00:19:36.593060: step 5934, loss 0.545057.
Train: 2018-08-01T00:19:36.749273: step 5935, loss 0.614434.
Train: 2018-08-01T00:19:36.905487: step 5936, loss 0.493136.
Train: 2018-08-01T00:19:37.061731: step 5937, loss 0.545092.
Train: 2018-08-01T00:19:37.217945: step 5938, loss 0.545091.
Train: 2018-08-01T00:19:37.374160: step 5939, loss 0.510453.
Train: 2018-08-01T00:19:37.530340: step 5940, loss 0.458401.
Test: 2018-08-01T00:19:37.998981: step 5940, loss 0.547863.
Train: 2018-08-01T00:19:38.155220: step 5941, loss 0.423404.
Train: 2018-08-01T00:19:38.327061: step 5942, loss 0.632226.
Train: 2018-08-01T00:19:38.483273: step 5943, loss 0.579936.
Train: 2018-08-01T00:19:38.639489: step 5944, loss 0.632579.
Train: 2018-08-01T00:19:38.826913: step 5945, loss 0.509816.
Train: 2018-08-01T00:19:38.967535: step 5946, loss 0.492182.
Train: 2018-08-01T00:19:39.139372: step 5947, loss 0.421607.
Train: 2018-08-01T00:19:39.295552: step 5948, loss 0.580177.
Train: 2018-08-01T00:19:39.451765: step 5949, loss 0.527055.
Train: 2018-08-01T00:19:39.607979: step 5950, loss 0.562549.
Test: 2018-08-01T00:19:40.092271: step 5950, loss 0.547634.
Train: 2018-08-01T00:19:40.248485: step 5951, loss 0.633937.
Train: 2018-08-01T00:19:40.404668: step 5952, loss 0.598316.
Train: 2018-08-01T00:19:40.560882: step 5953, loss 0.562592.
Train: 2018-08-01T00:19:40.732746: step 5954, loss 0.598359.
Train: 2018-08-01T00:19:40.888969: step 5955, loss 0.687726.
Train: 2018-08-01T00:19:41.045143: step 5956, loss 0.598246.
Train: 2018-08-01T00:19:41.201380: step 5957, loss 0.63371.
Train: 2018-08-01T00:19:41.357595: step 5958, loss 0.527064.
Train: 2018-08-01T00:19:41.513816: step 5959, loss 0.5625.
Train: 2018-08-01T00:19:41.669996: step 5960, loss 0.650646.
Test: 2018-08-01T00:19:42.138669: step 5960, loss 0.547749.
Train: 2018-08-01T00:19:42.310502: step 5961, loss 0.527326.
Train: 2018-08-01T00:19:42.466686: step 5962, loss 0.474866.
Train: 2018-08-01T00:19:42.638520: step 5963, loss 0.527457.
Train: 2018-08-01T00:19:42.794733: step 5964, loss 0.457576.
Train: 2018-08-01T00:19:42.950946: step 5965, loss 0.597417.
Train: 2018-08-01T00:19:43.122782: step 5966, loss 0.632402.
Train: 2018-08-01T00:19:43.278994: step 5967, loss 0.59738.
Train: 2018-08-01T00:19:43.435208: step 5968, loss 0.632215.
Train: 2018-08-01T00:19:43.591446: step 5969, loss 0.579823.
Train: 2018-08-01T00:19:43.747665: step 5970, loss 0.579771.
Test: 2018-08-01T00:19:44.216307: step 5970, loss 0.547906.
Train: 2018-08-01T00:19:44.372489: step 5971, loss 0.493144.
Train: 2018-08-01T00:19:44.528703: step 5972, loss 0.596988.
Train: 2018-08-01T00:19:44.684916: step 5973, loss 0.614187.
Train: 2018-08-01T00:19:44.856750: step 5974, loss 0.527954.
Train: 2018-08-01T00:19:45.044246: step 5975, loss 0.493622.
Train: 2018-08-01T00:19:45.247315: step 5976, loss 0.648328.
Train: 2018-08-01T00:19:45.419118: step 5977, loss 0.562395.
Train: 2018-08-01T00:19:45.575357: step 5978, loss 0.528134.
Train: 2018-08-01T00:19:45.747167: step 5979, loss 0.528164.
Train: 2018-08-01T00:19:45.940636: step 5980, loss 0.647958.
Test: 2018-08-01T00:19:46.409307: step 5980, loss 0.54809.
Train: 2018-08-01T00:19:46.565523: step 5981, loss 0.442794.
Train: 2018-08-01T00:19:46.721733: step 5982, loss 0.545302.
Train: 2018-08-01T00:19:46.893570: step 5983, loss 0.511074.
Train: 2018-08-01T00:19:47.065372: step 5984, loss 0.510999.
Train: 2018-08-01T00:19:47.221585: step 5985, loss 0.631069.
Train: 2018-08-01T00:19:47.377799: step 5986, loss 0.579579.
Train: 2018-08-01T00:19:47.534012: step 5987, loss 0.631161.
Train: 2018-08-01T00:19:47.690227: step 5988, loss 0.528035.
Train: 2018-08-01T00:19:47.846439: step 5989, loss 0.631115.
Train: 2018-08-01T00:19:48.002677: step 5990, loss 0.596717.
Test: 2018-08-01T00:19:48.486944: step 5990, loss 0.548047.
Train: 2018-08-01T00:19:48.643159: step 5991, loss 0.545261.
Train: 2018-08-01T00:19:48.814994: step 5992, loss 0.647976.
Train: 2018-08-01T00:19:48.971200: step 5993, loss 0.442863.
Train: 2018-08-01T00:19:49.127390: step 5994, loss 0.545325.
Train: 2018-08-01T00:19:49.314876: step 5995, loss 0.511174.
Train: 2018-08-01T00:19:49.471089: step 5996, loss 0.630757.
Train: 2018-08-01T00:19:49.627273: step 5997, loss 0.613655.
Train: 2018-08-01T00:19:49.783486: step 5998, loss 0.545329.
Train: 2018-08-01T00:19:49.939700: step 5999, loss 0.562399.
Train: 2018-08-01T00:19:50.095944: step 6000, loss 0.715845.
Test: 2018-08-01T00:19:50.564583: step 6000, loss 0.548168.
Train: 2018-08-01T00:19:51.298786: step 6001, loss 0.545404.
Train: 2018-08-01T00:19:51.470591: step 6002, loss 0.579372.
Train: 2018-08-01T00:19:51.626834: step 6003, loss 0.528569.
Train: 2018-08-01T00:19:51.783050: step 6004, loss 0.646915.
Train: 2018-08-01T00:19:51.954853: step 6005, loss 0.646704.
Train: 2018-08-01T00:19:52.111096: step 6006, loss 0.646414.
Train: 2018-08-01T00:19:52.267310: step 6007, loss 0.512319.
Train: 2018-08-01T00:19:52.423523: step 6008, loss 0.695796.
Train: 2018-08-01T00:19:52.595357: step 6009, loss 0.595685.
Train: 2018-08-01T00:19:52.751565: step 6010, loss 0.546063.
Test: 2018-08-01T00:19:53.235801: step 6010, loss 0.548838.
Train: 2018-08-01T00:19:53.392047: step 6011, loss 0.595464.
Train: 2018-08-01T00:19:53.548263: step 6012, loss 0.628103.
Train: 2018-08-01T00:19:53.720063: step 6013, loss 0.464937.
Train: 2018-08-01T00:19:53.876303: step 6014, loss 0.546457.
Train: 2018-08-01T00:19:54.032522: step 6015, loss 0.514045.
Train: 2018-08-01T00:19:54.204326: step 6016, loss 0.6114.
Train: 2018-08-01T00:19:54.360570: step 6017, loss 0.530335.
Train: 2018-08-01T00:19:54.516789: step 6018, loss 0.546544.
Train: 2018-08-01T00:19:54.672968: step 6019, loss 0.562744.
Train: 2018-08-01T00:19:54.829179: step 6020, loss 0.528138.
Test: 2018-08-01T00:19:55.313470: step 6020, loss 0.549124.
Train: 2018-08-01T00:19:55.469654: step 6021, loss 0.546483.
Train: 2018-08-01T00:19:55.625898: step 6022, loss 0.481375.
Train: 2018-08-01T00:19:55.813324: step 6023, loss 0.578985.
Train: 2018-08-01T00:19:55.969567: step 6024, loss 0.562642.
Train: 2018-08-01T00:19:56.125781: step 6025, loss 0.546217.
Train: 2018-08-01T00:19:56.281995: step 6026, loss 0.611926.
Train: 2018-08-01T00:19:56.438207: step 6027, loss 0.480207.
Train: 2018-08-01T00:19:56.594421: step 6028, loss 0.546025.
Train: 2018-08-01T00:19:56.750635: step 6029, loss 0.545947.
Train: 2018-08-01T00:19:56.922438: step 6030, loss 0.54587.
Test: 2018-08-01T00:19:57.391110: step 6030, loss 0.548507.
Train: 2018-08-01T00:19:57.547322: step 6031, loss 0.612542.
Train: 2018-08-01T00:19:57.703536: step 6032, loss 0.595917.
Train: 2018-08-01T00:19:57.875340: step 6033, loss 0.57921.
Train: 2018-08-01T00:19:58.047177: step 6034, loss 0.461822.
Train: 2018-08-01T00:19:58.203390: step 6035, loss 0.629715.
Train: 2018-08-01T00:19:58.344011: step 6036, loss 0.478212.
Train: 2018-08-01T00:19:58.515847: step 6037, loss 0.629986.
Train: 2018-08-01T00:19:58.672059: step 6038, loss 0.613165.
Train: 2018-08-01T00:19:58.828273: step 6039, loss 0.528566.
Train: 2018-08-01T00:19:59.000078: step 6040, loss 0.579356.
Test: 2018-08-01T00:19:59.468742: step 6040, loss 0.548212.
Train: 2018-08-01T00:19:59.624961: step 6041, loss 0.630237.
Train: 2018-08-01T00:19:59.781146: step 6042, loss 0.681066.
Train: 2018-08-01T00:19:59.937358: step 6043, loss 0.511675.
Train: 2018-08-01T00:20:00.109224: step 6044, loss 0.545525.
Train: 2018-08-01T00:20:00.281027: step 6045, loss 0.629965.
Train: 2018-08-01T00:20:00.452862: step 6046, loss 0.663579.
Train: 2018-08-01T00:20:00.609075: step 6047, loss 0.427979.
Train: 2018-08-01T00:20:00.765290: step 6048, loss 0.495244.
Train: 2018-08-01T00:20:00.921533: step 6049, loss 0.596066.
Train: 2018-08-01T00:20:01.093367: step 6050, loss 0.596071.
Test: 2018-08-01T00:20:01.561976: step 6050, loss 0.548365.
Train: 2018-08-01T00:20:01.718221: step 6051, loss 0.629683.
Train: 2018-08-01T00:20:01.890026: step 6052, loss 0.562448.
Train: 2018-08-01T00:20:02.046239: step 6053, loss 0.545682.
Train: 2018-08-01T00:20:02.202453: step 6054, loss 0.512174.
Train: 2018-08-01T00:20:02.358691: step 6055, loss 0.595987.
Train: 2018-08-01T00:20:02.514880: step 6056, loss 0.428345.
Train: 2018-08-01T00:20:02.671123: step 6057, loss 0.495249.
Train: 2018-08-01T00:20:02.827340: step 6058, loss 0.562432.
Train: 2018-08-01T00:20:02.983550: step 6059, loss 0.596215.
Train: 2018-08-01T00:20:03.139765: step 6060, loss 0.579346.
Test: 2018-08-01T00:20:03.608403: step 6060, loss 0.548211.
Train: 2018-08-01T00:20:03.780240: step 6061, loss 0.613284.
Train: 2018-08-01T00:20:03.936451: step 6062, loss 0.528471.
Train: 2018-08-01T00:20:04.092665: step 6063, loss 0.579395.
Train: 2018-08-01T00:20:04.248881: step 6064, loss 0.494392.
Train: 2018-08-01T00:20:04.405092: step 6065, loss 0.59647.
Train: 2018-08-01T00:20:04.576910: step 6066, loss 0.528292.
Train: 2018-08-01T00:20:04.733110: step 6067, loss 0.630721.
Train: 2018-08-01T00:20:04.889324: step 6068, loss 0.596572.
Train: 2018-08-01T00:20:05.045536: step 6069, loss 0.49406.
Train: 2018-08-01T00:20:05.201780: step 6070, loss 0.699196.
Test: 2018-08-01T00:20:05.670415: step 6070, loss 0.548097.
Train: 2018-08-01T00:20:05.826603: step 6071, loss 0.528242.
Train: 2018-08-01T00:20:05.982847: step 6072, loss 0.579466.
Train: 2018-08-01T00:20:06.139062: step 6073, loss 0.528291.
Train: 2018-08-01T00:20:06.295275: step 6074, loss 0.647657.
Train: 2018-08-01T00:20:06.451488: step 6075, loss 0.494295.
Train: 2018-08-01T00:20:06.607701: step 6076, loss 0.613471.
Train: 2018-08-01T00:20:06.763886: step 6077, loss 0.579411.
Train: 2018-08-01T00:20:06.935749: step 6078, loss 0.494455.
Train: 2018-08-01T00:20:07.091932: step 6079, loss 0.579396.
Train: 2018-08-01T00:20:07.248176: step 6080, loss 0.528432.
Test: 2018-08-01T00:20:07.732437: step 6080, loss 0.548175.
Train: 2018-08-01T00:20:07.904242: step 6081, loss 0.613389.
Train: 2018-08-01T00:20:08.044835: step 6082, loss 0.698313.
Train: 2018-08-01T00:20:08.201079: step 6083, loss 0.57936.
Train: 2018-08-01T00:20:08.357292: step 6084, loss 0.596233.
Train: 2018-08-01T00:20:08.529095: step 6085, loss 0.613014.
Train: 2018-08-01T00:20:08.669719: step 6086, loss 0.59606.
Train: 2018-08-01T00:20:08.841553: step 6087, loss 0.662978.
Train: 2018-08-01T00:20:08.997736: step 6088, loss 0.579162.
Train: 2018-08-01T00:20:09.153981: step 6089, loss 0.496084.
Train: 2018-08-01T00:20:09.325785: step 6090, loss 0.512842.
Test: 2018-08-01T00:20:09.794455: step 6090, loss 0.548693.
Train: 2018-08-01T00:20:09.950668: step 6091, loss 0.546003.
Train: 2018-08-01T00:20:10.122504: step 6092, loss 0.645174.
Train: 2018-08-01T00:20:10.278717: step 6093, loss 0.496602.
Train: 2018-08-01T00:20:10.434900: step 6094, loss 0.579053.
Train: 2018-08-01T00:20:10.591114: step 6095, loss 0.562578.
Train: 2018-08-01T00:20:10.762979: step 6096, loss 0.496731.
Train: 2018-08-01T00:20:10.919192: step 6097, loss 0.546098.
Train: 2018-08-01T00:20:11.075404: step 6098, loss 0.480086.
Train: 2018-08-01T00:20:11.262862: step 6099, loss 0.546006.
Train: 2018-08-01T00:20:11.419074: step 6100, loss 0.579105.
Test: 2018-08-01T00:20:11.887717: step 6100, loss 0.548589.
Train: 2018-08-01T00:20:12.762480: step 6101, loss 0.562507.
Train: 2018-08-01T00:20:12.996799: step 6102, loss 0.512524.
Train: 2018-08-01T00:20:13.153044: step 6103, loss 0.512364.
Train: 2018-08-01T00:20:13.309228: step 6104, loss 0.646264.
Train: 2018-08-01T00:20:13.481061: step 6105, loss 0.545654.
Train: 2018-08-01T00:20:13.652927: step 6106, loss 0.478307.
Train: 2018-08-01T00:20:13.809140: step 6107, loss 0.511785.
Train: 2018-08-01T00:20:13.965348: step 6108, loss 0.664072.
Train: 2018-08-01T00:20:14.121537: step 6109, loss 0.579382.
Train: 2018-08-01T00:20:14.277781: step 6110, loss 0.596399.
Test: 2018-08-01T00:20:14.762011: step 6110, loss 0.54816.
Train: 2018-08-01T00:20:14.918255: step 6111, loss 0.511374.
Train: 2018-08-01T00:20:15.074469: step 6112, loss 0.579436.
Train: 2018-08-01T00:20:15.230676: step 6113, loss 0.528291.
Train: 2018-08-01T00:20:15.386897: step 6114, loss 0.511156.
Train: 2018-08-01T00:20:15.558725: step 6115, loss 0.647986.
Train: 2018-08-01T00:20:15.714943: step 6116, loss 0.545266.
Train: 2018-08-01T00:20:15.871126: step 6117, loss 0.545251.
Train: 2018-08-01T00:20:16.023228: step 6118, loss 0.528071.
Train: 2018-08-01T00:20:16.179441: step 6119, loss 0.665519.
Train: 2018-08-01T00:20:16.335686: step 6120, loss 0.596761.
Test: 2018-08-01T00:20:16.804296: step 6120, loss 0.548018.
Train: 2018-08-01T00:20:16.960510: step 6121, loss 0.510888.
Train: 2018-08-01T00:20:17.132349: step 6122, loss 0.596737.
Train: 2018-08-01T00:20:17.288587: step 6123, loss 0.510906.
Train: 2018-08-01T00:20:17.444801: step 6124, loss 0.579565.
Train: 2018-08-01T00:20:17.616636: step 6125, loss 0.579567.
Train: 2018-08-01T00:20:17.772819: step 6126, loss 0.562395.
Train: 2018-08-01T00:20:17.944654: step 6127, loss 0.562395.
Train: 2018-08-01T00:20:18.100868: step 6128, loss 0.59672.
Train: 2018-08-01T00:20:18.257080: step 6129, loss 0.596696.
Train: 2018-08-01T00:20:18.413320: step 6130, loss 0.511002.
Test: 2018-08-01T00:20:18.897585: step 6130, loss 0.548054.
Train: 2018-08-01T00:20:19.069390: step 6131, loss 0.562396.
Train: 2018-08-01T00:20:19.225604: step 6132, loss 0.459652.
Train: 2018-08-01T00:20:19.397439: step 6133, loss 0.545247.
Train: 2018-08-01T00:20:19.553652: step 6134, loss 0.476522.
Train: 2018-08-01T00:20:19.725488: step 6135, loss 0.510734.
Train: 2018-08-01T00:20:19.881706: step 6136, loss 0.596953.
Train: 2018-08-01T00:20:20.053534: step 6137, loss 0.527773.
Train: 2018-08-01T00:20:20.209748: step 6138, loss 0.649216.
Train: 2018-08-01T00:20:20.365962: step 6139, loss 0.562414.
Train: 2018-08-01T00:20:20.522174: step 6140, loss 0.597201.
Test: 2018-08-01T00:20:21.006436: step 6140, loss 0.547851.
Train: 2018-08-01T00:20:21.193892: step 6141, loss 0.545022.
Train: 2018-08-01T00:20:21.350106: step 6142, loss 0.492812.
Train: 2018-08-01T00:20:21.506350: step 6143, loss 0.510149.
Train: 2018-08-01T00:20:21.662534: step 6144, loss 0.56243.
Train: 2018-08-01T00:20:21.818747: step 6145, loss 0.475001.
Train: 2018-08-01T00:20:21.990612: step 6146, loss 0.56245.
Train: 2018-08-01T00:20:22.162441: step 6147, loss 0.439427.
Train: 2018-08-01T00:20:22.318660: step 6148, loss 0.562486.
Train: 2018-08-01T00:20:22.474873: step 6149, loss 0.597917.
Train: 2018-08-01T00:20:22.646677: step 6150, loss 0.59802.
Test: 2018-08-01T00:20:23.115348: step 6150, loss 0.547658.
Train: 2018-08-01T00:20:23.287182: step 6151, loss 0.598086.
Train: 2018-08-01T00:20:23.443397: step 6152, loss 0.633691.
Train: 2018-08-01T00:20:23.599604: step 6153, loss 0.473654.
Train: 2018-08-01T00:20:23.771413: step 6154, loss 0.562549.
Train: 2018-08-01T00:20:23.927658: step 6155, loss 0.509153.
Train: 2018-08-01T00:20:24.083871: step 6156, loss 0.473464.
Train: 2018-08-01T00:20:24.240085: step 6157, loss 0.509009.
Train: 2018-08-01T00:20:24.411927: step 6158, loss 0.598416.
Train: 2018-08-01T00:20:24.568133: step 6159, loss 0.490892.
Train: 2018-08-01T00:20:24.724317: step 6160, loss 0.400874.
Test: 2018-08-01T00:20:25.208607: step 6160, loss 0.547584.
Train: 2018-08-01T00:20:25.364821: step 6161, loss 0.454395.
Train: 2018-08-01T00:20:25.552274: step 6162, loss 0.635337.
Train: 2018-08-01T00:20:25.708461: step 6163, loss 0.63563.
Train: 2018-08-01T00:20:25.864704: step 6164, loss 0.508126.
Train: 2018-08-01T00:20:26.020912: step 6165, loss 0.672541.
Train: 2018-08-01T00:20:26.192758: step 6166, loss 0.63601.
Train: 2018-08-01T00:20:26.348965: step 6167, loss 0.453268.
Train: 2018-08-01T00:20:26.505150: step 6168, loss 0.61769.
Train: 2018-08-01T00:20:26.677009: step 6169, loss 0.544597.
Train: 2018-08-01T00:20:26.833197: step 6170, loss 0.489835.
Test: 2018-08-01T00:20:27.301862: step 6170, loss 0.547567.
Train: 2018-08-01T00:20:27.473671: step 6171, loss 0.599381.
Train: 2018-08-01T00:20:27.629889: step 6172, loss 0.526344.
Train: 2018-08-01T00:20:27.786099: step 6173, loss 0.544599.
Train: 2018-08-01T00:20:27.942337: step 6174, loss 0.562852.
Train: 2018-08-01T00:20:28.114146: step 6175, loss 0.562849.
Train: 2018-08-01T00:20:28.270359: step 6176, loss 0.562843.
Train: 2018-08-01T00:20:28.426605: step 6177, loss 0.508138.
Train: 2018-08-01T00:20:28.582818: step 6178, loss 0.544603.
Train: 2018-08-01T00:20:28.754623: step 6179, loss 0.544602.
Train: 2018-08-01T00:20:28.910835: step 6180, loss 0.508128.
Test: 2018-08-01T00:20:29.379506: step 6180, loss 0.547567.
Train: 2018-08-01T00:20:29.535688: step 6181, loss 0.562849.
Train: 2018-08-01T00:20:29.691903: step 6182, loss 0.526343.
Train: 2018-08-01T00:20:29.879279: step 6183, loss 0.526329.
Train: 2018-08-01T00:20:30.019904: step 6184, loss 0.508028.
Train: 2018-08-01T00:20:30.176112: step 6185, loss 0.562898.
Train: 2018-08-01T00:20:30.347953: step 6186, loss 0.489615.
Train: 2018-08-01T00:20:30.488515: step 6187, loss 0.599649.
Train: 2018-08-01T00:20:30.660381: step 6188, loss 0.47111.
Train: 2018-08-01T00:20:30.816592: step 6189, loss 0.526226.
Train: 2018-08-01T00:20:30.988396: step 6190, loss 0.599876.
Test: 2018-08-01T00:20:31.457062: step 6190, loss 0.54758.
Train: 2018-08-01T00:20:31.613281: step 6191, loss 0.489235.
Train: 2018-08-01T00:20:31.769494: step 6192, loss 0.618484.
Train: 2018-08-01T00:20:31.925679: step 6193, loss 0.489129.
Train: 2018-08-01T00:20:32.113164: step 6194, loss 0.54458.
Train: 2018-08-01T00:20:32.269347: step 6195, loss 0.544581.
Train: 2018-08-01T00:20:32.425591: step 6196, loss 0.618732.
Train: 2018-08-01T00:20:32.581804: step 6197, loss 0.600183.
Train: 2018-08-01T00:20:32.738012: step 6198, loss 0.563098.
Train: 2018-08-01T00:20:32.894226: step 6199, loss 0.618567.
Train: 2018-08-01T00:20:33.050414: step 6200, loss 0.563042.
Test: 2018-08-01T00:20:33.503463: step 6200, loss 0.547579.
Train: 2018-08-01T00:20:34.268880: step 6201, loss 0.599852.
Train: 2018-08-01T00:20:34.425128: step 6202, loss 0.581338.
Train: 2018-08-01T00:20:34.581305: step 6203, loss 0.654541.
Train: 2018-08-01T00:20:34.737549: step 6204, loss 0.599359.
Train: 2018-08-01T00:20:34.893735: step 6205, loss 0.490097.
Train: 2018-08-01T00:20:35.049945: step 6206, loss 0.562751.
Train: 2018-08-01T00:20:35.206190: step 6207, loss 0.526584.
Train: 2018-08-01T00:20:35.378025: step 6208, loss 0.544663.
Train: 2018-08-01T00:20:35.534240: step 6209, loss 0.490717.
Train: 2018-08-01T00:20:35.706067: step 6210, loss 0.526714.
Test: 2018-08-01T00:20:36.174713: step 6210, loss 0.547606.
Train: 2018-08-01T00:20:36.330926: step 6211, loss 0.580604.
Train: 2018-08-01T00:20:36.502755: step 6212, loss 0.526749.
Train: 2018-08-01T00:20:36.658945: step 6213, loss 0.508824.
Train: 2018-08-01T00:20:36.815158: step 6214, loss 0.508814.
Train: 2018-08-01T00:20:36.971372: step 6215, loss 0.508779.
Train: 2018-08-01T00:20:37.127615: step 6216, loss 0.472765.
Train: 2018-08-01T00:20:37.283798: step 6217, loss 0.616743.
Train: 2018-08-01T00:20:37.440011: step 6218, loss 0.580738.
Train: 2018-08-01T00:20:37.627468: step 6219, loss 0.634911.
Train: 2018-08-01T00:20:37.783682: step 6220, loss 0.670939.
Test: 2018-08-01T00:20:38.252351: step 6220, loss 0.547598.
Train: 2018-08-01T00:20:38.408560: step 6221, loss 0.508671.
Train: 2018-08-01T00:20:38.564748: step 6222, loss 0.562654.
Train: 2018-08-01T00:20:38.752234: step 6223, loss 0.598533.
Train: 2018-08-01T00:20:38.908442: step 6224, loss 0.526792.
Train: 2018-08-01T00:20:39.064663: step 6225, loss 0.491054.
Train: 2018-08-01T00:20:39.220874: step 6226, loss 0.562599.
Train: 2018-08-01T00:20:39.377087: step 6227, loss 0.562594.
Train: 2018-08-01T00:20:39.533304: step 6228, loss 0.562588.
Train: 2018-08-01T00:20:39.689510: step 6229, loss 0.616128.
Train: 2018-08-01T00:20:39.861359: step 6230, loss 0.633856.
Test: 2018-08-01T00:20:40.345611: step 6230, loss 0.547659.
Train: 2018-08-01T00:20:40.501795: step 6231, loss 0.66921.
Train: 2018-08-01T00:20:40.671543: step 6232, loss 0.580222.
Train: 2018-08-01T00:20:40.827759: step 6233, loss 0.456656.
Train: 2018-08-01T00:20:40.983970: step 6234, loss 0.668086.
Train: 2018-08-01T00:20:41.140189: step 6235, loss 0.667695.
Train: 2018-08-01T00:20:41.296402: step 6236, loss 0.510064.
Train: 2018-08-01T00:20:41.452615: step 6237, loss 0.545026.
Train: 2018-08-01T00:20:41.608799: step 6238, loss 0.63177.
Train: 2018-08-01T00:20:41.765012: step 6239, loss 0.54513.
Train: 2018-08-01T00:20:41.921250: step 6240, loss 0.459095.
Test: 2018-08-01T00:20:42.389865: step 6240, loss 0.548.
Train: 2018-08-01T00:20:42.561731: step 6241, loss 0.545204.
Train: 2018-08-01T00:20:42.717945: step 6242, loss 0.699819.
Train: 2018-08-01T00:20:42.874157: step 6243, loss 0.613778.
Train: 2018-08-01T00:20:43.045994: step 6244, loss 0.528266.
Train: 2018-08-01T00:20:43.186591: step 6245, loss 0.732651.
Train: 2018-08-01T00:20:43.342767: step 6246, loss 0.494662.
Train: 2018-08-01T00:20:43.498981: step 6247, loss 0.494902.
Train: 2018-08-01T00:20:43.655220: step 6248, loss 0.579283.
Train: 2018-08-01T00:20:43.811434: step 6249, loss 0.629708.
Train: 2018-08-01T00:20:43.967622: step 6250, loss 0.478605.
Test: 2018-08-01T00:20:44.436292: step 6250, loss 0.548433.
Train: 2018-08-01T00:20:44.592506: step 6251, loss 0.579214.
Train: 2018-08-01T00:20:44.748719: step 6252, loss 0.595935.
Train: 2018-08-01T00:20:44.904903: step 6253, loss 0.545768.
Train: 2018-08-01T00:20:45.078824: step 6254, loss 0.479019.
Train: 2018-08-01T00:20:45.266290: step 6255, loss 0.495669.
Train: 2018-08-01T00:20:45.406886: step 6256, loss 0.595932.
Train: 2018-08-01T00:20:45.578720: step 6257, loss 0.595963.
Train: 2018-08-01T00:20:45.734933: step 6258, loss 0.612736.
Train: 2018-08-01T00:20:45.891148: step 6259, loss 0.54571.
Train: 2018-08-01T00:20:46.047360: step 6260, loss 0.579219.
Test: 2018-08-01T00:20:46.531590: step 6260, loss 0.548434.
Train: 2018-08-01T00:20:46.687835: step 6261, loss 0.562464.
Train: 2018-08-01T00:20:46.844044: step 6262, loss 0.579218.
Train: 2018-08-01T00:20:47.000257: step 6263, loss 0.562465.
Train: 2018-08-01T00:20:47.156477: step 6264, loss 0.646216.
Train: 2018-08-01T00:20:47.312683: step 6265, loss 0.646111.
Train: 2018-08-01T00:20:47.484519: step 6266, loss 0.479055.
Train: 2018-08-01T00:20:47.640707: step 6267, loss 0.562492.
Train: 2018-08-01T00:20:47.796920: step 6268, loss 0.595823.
Train: 2018-08-01T00:20:47.953133: step 6269, loss 0.64574.
Train: 2018-08-01T00:20:48.109373: step 6270, loss 0.51268.
Test: 2018-08-01T00:20:48.593609: step 6270, loss 0.548626.
Train: 2018-08-01T00:20:48.749855: step 6271, loss 0.628906.
Train: 2018-08-01T00:20:48.906068: step 6272, loss 0.579102.
Train: 2018-08-01T00:20:49.062279: step 6273, loss 0.512948.
Train: 2018-08-01T00:20:49.218493: step 6274, loss 0.446895.
Train: 2018-08-01T00:20:49.374675: step 6275, loss 0.463265.
Train: 2018-08-01T00:20:49.530920: step 6276, loss 0.579119.
Train: 2018-08-01T00:20:49.718345: step 6277, loss 0.512584.
Train: 2018-08-01T00:20:49.874589: step 6278, loss 0.562483.
Train: 2018-08-01T00:20:50.030772: step 6279, loss 0.595955.
Train: 2018-08-01T00:20:50.187011: step 6280, loss 0.512109.
Test: 2018-08-01T00:20:50.640035: step 6280, loss 0.548347.
Train: 2018-08-01T00:20:50.811840: step 6281, loss 0.562441.
Train: 2018-08-01T00:20:50.968083: step 6282, loss 0.545555.
Train: 2018-08-01T00:20:51.139887: step 6283, loss 0.528578.
Train: 2018-08-01T00:20:51.296100: step 6284, loss 0.596359.
Train: 2018-08-01T00:20:51.452344: step 6285, loss 0.511375.
Train: 2018-08-01T00:20:51.608558: step 6286, loss 0.596522.
Train: 2018-08-01T00:20:51.780390: step 6287, loss 0.545307.
Train: 2018-08-01T00:20:51.952233: step 6288, loss 0.47675.
Train: 2018-08-01T00:20:52.092814: step 6289, loss 0.682695.
Train: 2018-08-01T00:20:52.264649: step 6290, loss 0.682819.
Test: 2018-08-01T00:20:52.733294: step 6290, loss 0.548008.
Train: 2018-08-01T00:20:52.905101: step 6291, loss 0.562399.
Train: 2018-08-01T00:20:53.061343: step 6292, loss 0.613916.
Train: 2018-08-01T00:20:53.217556: step 6293, loss 0.579545.
Train: 2018-08-01T00:20:53.373770: step 6294, loss 0.68222.
Train: 2018-08-01T00:20:53.529984: step 6295, loss 0.579462.
Train: 2018-08-01T00:20:53.686196: step 6296, loss 0.579412.
Train: 2018-08-01T00:20:53.842410: step 6297, loss 0.477662.
Train: 2018-08-01T00:20:54.014214: step 6298, loss 0.66397.
Train: 2018-08-01T00:20:54.170460: step 6299, loss 0.629933.
Train: 2018-08-01T00:20:54.342288: step 6300, loss 0.612888.
Test: 2018-08-01T00:20:54.810933: step 6300, loss 0.548439.
Train: 2018-08-01T00:20:55.560752: step 6301, loss 0.478725.
Train: 2018-08-01T00:20:55.716971: step 6302, loss 0.529053.
Train: 2018-08-01T00:20:55.873154: step 6303, loss 0.579171.
Train: 2018-08-01T00:20:56.029368: step 6304, loss 0.579156.
Train: 2018-08-01T00:20:56.201203: step 6305, loss 0.495933.
Train: 2018-08-01T00:20:56.357445: step 6306, loss 0.662343.
Train: 2018-08-01T00:20:56.513660: step 6307, loss 0.496056.
Train: 2018-08-01T00:20:56.669872: step 6308, loss 0.562513.
Train: 2018-08-01T00:20:56.826085: step 6309, loss 0.529297.
Train: 2018-08-01T00:20:56.982299: step 6310, loss 0.545892.
Test: 2018-08-01T00:20:57.450940: step 6310, loss 0.548575.
Train: 2018-08-01T00:20:57.607153: step 6311, loss 0.562503.
Train: 2018-08-01T00:20:57.763368: step 6312, loss 0.645739.
Train: 2018-08-01T00:20:57.919580: step 6313, loss 0.595783.
Train: 2018-08-01T00:20:58.075763: step 6314, loss 0.562505.
Train: 2018-08-01T00:20:58.231976: step 6315, loss 0.579127.
Train: 2018-08-01T00:20:58.403836: step 6316, loss 0.595725.
Train: 2018-08-01T00:20:58.560025: step 6317, loss 0.529347.
Train: 2018-08-01T00:20:58.716268: step 6318, loss 0.545942.
Train: 2018-08-01T00:20:58.856830: step 6319, loss 0.562523.
Train: 2018-08-01T00:20:59.028696: step 6320, loss 0.57911.
Test: 2018-08-01T00:20:59.497334: step 6320, loss 0.54863.
Train: 2018-08-01T00:20:59.653518: step 6321, loss 0.615607.
Train: 2018-08-01T00:20:59.809732: step 6322, loss 0.579104.
Train: 2018-08-01T00:20:59.950354: step 6323, loss 0.612226.
Train: 2018-08-01T00:21:00.122159: step 6324, loss 0.496378.
Train: 2018-08-01T00:21:00.278372: step 6325, loss 0.546003.
Train: 2018-08-01T00:21:00.434616: step 6326, loss 0.612181.
Train: 2018-08-01T00:21:00.606420: step 6327, loss 0.628707.
Train: 2018-08-01T00:21:00.778286: step 6328, loss 0.446917.
Train: 2018-08-01T00:21:00.934469: step 6329, loss 0.546012.
Train: 2018-08-01T00:21:01.090712: step 6330, loss 0.595645.
Test: 2018-08-01T00:21:01.559329: step 6330, loss 0.54866.
Train: 2018-08-01T00:21:01.731187: step 6331, loss 0.512835.
Train: 2018-08-01T00:21:01.887371: step 6332, loss 0.612293.
Train: 2018-08-01T00:21:02.043608: step 6333, loss 0.59572.
Train: 2018-08-01T00:21:02.215421: step 6334, loss 0.612331.
Train: 2018-08-01T00:21:02.371663: step 6335, loss 0.562517.
Train: 2018-08-01T00:21:02.527879: step 6336, loss 0.42979.
Train: 2018-08-01T00:21:02.684089: step 6337, loss 0.545882.
Train: 2018-08-01T00:21:02.855919: step 6338, loss 0.512511.
Train: 2018-08-01T00:21:03.012106: step 6339, loss 0.579182.
Train: 2018-08-01T00:21:03.168320: step 6340, loss 0.545713.
Test: 2018-08-01T00:21:03.636985: step 6340, loss 0.548388.
Train: 2018-08-01T00:21:03.808796: step 6341, loss 0.478498.
Train: 2018-08-01T00:21:03.980630: step 6342, loss 0.478173.
Train: 2018-08-01T00:21:04.136844: step 6343, loss 0.697864.
Train: 2018-08-01T00:21:04.293088: step 6344, loss 0.528476.
Train: 2018-08-01T00:21:04.449301: step 6345, loss 0.528387.
Train: 2018-08-01T00:21:04.621105: step 6346, loss 0.5624.
Train: 2018-08-01T00:21:04.777351: step 6347, loss 0.613695.
Train: 2018-08-01T00:21:04.933561: step 6348, loss 0.596645.
Train: 2018-08-01T00:21:05.105397: step 6349, loss 0.493843.
Train: 2018-08-01T00:21:05.245991: step 6350, loss 0.545227.
Test: 2018-08-01T00:21:05.714629: step 6350, loss 0.547993.
Train: 2018-08-01T00:21:05.870837: step 6351, loss 0.493593.
Train: 2018-08-01T00:21:06.042648: step 6352, loss 0.562399.
Train: 2018-08-01T00:21:06.198891: step 6353, loss 0.493244.
Train: 2018-08-01T00:21:06.355104: step 6354, loss 0.562409.
Train: 2018-08-01T00:21:06.526940: step 6355, loss 0.649388.
Train: 2018-08-01T00:21:06.683155: step 6356, loss 0.457932.
Train: 2018-08-01T00:21:06.839335: step 6357, loss 0.475132.
Train: 2018-08-01T00:21:06.995548: step 6358, loss 0.544925.
Train: 2018-08-01T00:21:07.167393: step 6359, loss 0.580045.
Train: 2018-08-01T00:21:07.323623: step 6360, loss 0.562481.
Test: 2018-08-01T00:21:07.807889: step 6360, loss 0.5477.
Train: 2018-08-01T00:21:07.964103: step 6361, loss 0.668509.
Train: 2018-08-01T00:21:08.120287: step 6362, loss 0.615529.
Train: 2018-08-01T00:21:08.276501: step 6363, loss 0.580164.
Train: 2018-08-01T00:21:08.432713: step 6364, loss 0.544836.
Train: 2018-08-01T00:21:08.588951: step 6365, loss 0.474263.
Train: 2018-08-01T00:21:08.760798: step 6366, loss 0.703749.
Train: 2018-08-01T00:21:08.917006: step 6367, loss 0.597742.
Train: 2018-08-01T00:21:09.073218: step 6368, loss 0.544874.
Train: 2018-08-01T00:21:09.229401: step 6369, loss 0.527326.
Train: 2018-08-01T00:21:09.401261: step 6370, loss 0.702849.
Test: 2018-08-01T00:21:09.869906: step 6370, loss 0.547789.
Train: 2018-08-01T00:21:10.026120: step 6371, loss 0.56244.
Train: 2018-08-01T00:21:10.182302: step 6372, loss 0.562428.
Train: 2018-08-01T00:21:10.338541: step 6373, loss 0.475413.
Train: 2018-08-01T00:21:10.525972: step 6374, loss 0.492888.
Train: 2018-08-01T00:21:10.682216: step 6375, loss 0.458124.
Train: 2018-08-01T00:21:10.854020: step 6376, loss 0.684278.
Train: 2018-08-01T00:21:11.010259: step 6377, loss 0.562418.
Train: 2018-08-01T00:21:11.150826: step 6378, loss 0.510244.
Train: 2018-08-01T00:21:11.307064: step 6379, loss 0.527626.
Train: 2018-08-01T00:21:11.478905: step 6380, loss 0.579828.
Test: 2018-08-01T00:21:11.947514: step 6380, loss 0.547839.
Train: 2018-08-01T00:21:12.103728: step 6381, loss 0.510178.
Train: 2018-08-01T00:21:12.275562: step 6382, loss 0.649586.
Train: 2018-08-01T00:21:12.431776: step 6383, loss 0.492724.
Train: 2018-08-01T00:21:12.587991: step 6384, loss 0.632167.
Train: 2018-08-01T00:21:12.759855: step 6385, loss 0.701831.
Train: 2018-08-01T00:21:12.900441: step 6386, loss 0.562415.
Train: 2018-08-01T00:21:13.072282: step 6387, loss 0.527731.
Train: 2018-08-01T00:21:13.244111: step 6388, loss 0.545095.
Train: 2018-08-01T00:21:13.400332: step 6389, loss 0.44139.
Train: 2018-08-01T00:21:13.556543: step 6390, loss 0.614298.
Test: 2018-08-01T00:21:14.025183: step 6390, loss 0.547921.
Train: 2018-08-01T00:21:14.181366: step 6391, loss 0.579697.
Train: 2018-08-01T00:21:14.337579: step 6392, loss 0.614259.
Train: 2018-08-01T00:21:14.493824: step 6393, loss 0.596928.
Train: 2018-08-01T00:21:14.650038: step 6394, loss 0.665808.
Train: 2018-08-01T00:21:14.821875: step 6395, loss 0.51085.
Train: 2018-08-01T00:21:14.978055: step 6396, loss 0.579543.
Train: 2018-08-01T00:21:15.134269: step 6397, loss 0.511061.
Train: 2018-08-01T00:21:15.290482: step 6398, loss 0.545304.
Train: 2018-08-01T00:21:15.446696: step 6399, loss 0.630724.
Train: 2018-08-01T00:21:15.602940: step 6400, loss 0.596506.
Test: 2018-08-01T00:21:16.071549: step 6400, loss 0.548151.
Train: 2018-08-01T00:21:16.774510: step 6401, loss 0.630479.
Train: 2018-08-01T00:21:16.930747: step 6402, loss 0.494525.
Train: 2018-08-01T00:21:17.118203: step 6403, loss 0.562413.
Train: 2018-08-01T00:21:17.274428: step 6404, loss 0.427021.
Train: 2018-08-01T00:21:17.430605: step 6405, loss 0.477704.
Train: 2018-08-01T00:21:17.586843: step 6406, loss 0.494485.
Train: 2018-08-01T00:21:17.743032: step 6407, loss 0.545367.
Train: 2018-08-01T00:21:17.899277: step 6408, loss 0.54531.
Train: 2018-08-01T00:21:18.055460: step 6409, loss 0.648093.
Train: 2018-08-01T00:21:18.242940: step 6410, loss 0.57956.
Test: 2018-08-01T00:21:18.711585: step 6410, loss 0.548008.
Train: 2018-08-01T00:21:18.867800: step 6411, loss 0.528031.
Train: 2018-08-01T00:21:19.023982: step 6412, loss 0.510775.
Train: 2018-08-01T00:21:19.180196: step 6413, loss 0.51067.
Train: 2018-08-01T00:21:19.352031: step 6414, loss 0.57969.
Train: 2018-08-01T00:21:19.523865: step 6415, loss 0.666351.
Train: 2018-08-01T00:21:19.680079: step 6416, loss 0.579736.
Train: 2018-08-01T00:21:19.851914: step 6417, loss 0.458438.
Train: 2018-08-01T00:21:19.992506: step 6418, loss 0.56241.
Train: 2018-08-01T00:21:20.164371: step 6419, loss 0.597166.
Train: 2018-08-01T00:21:20.320555: step 6420, loss 0.579802.
Test: 2018-08-01T00:21:20.804816: step 6420, loss 0.547854.
Train: 2018-08-01T00:21:20.961070: step 6421, loss 0.597198.
Train: 2018-08-01T00:21:21.101652: step 6422, loss 0.475492.
Train: 2018-08-01T00:21:21.273487: step 6423, loss 0.614621.
Train: 2018-08-01T00:21:21.445327: step 6424, loss 0.649423.
Train: 2018-08-01T00:21:21.585919: step 6425, loss 0.59717.
Train: 2018-08-01T00:21:21.742126: step 6426, loss 0.510367.
Train: 2018-08-01T00:21:21.898310: step 6427, loss 0.562407.
Train: 2018-08-01T00:21:22.054554: step 6428, loss 0.614363.
Train: 2018-08-01T00:21:22.210766: step 6429, loss 0.527817.
Train: 2018-08-01T00:21:22.366980: step 6430, loss 0.562401.
Test: 2018-08-01T00:21:22.835620: step 6430, loss 0.547944.
Train: 2018-08-01T00:21:22.991834: step 6431, loss 0.493348.
Train: 2018-08-01T00:21:23.148049: step 6432, loss 0.493329.
Train: 2018-08-01T00:21:23.304255: step 6433, loss 0.510533.
Train: 2018-08-01T00:21:23.460475: step 6434, loss 0.579729.
Train: 2018-08-01T00:21:23.632281: step 6435, loss 0.510368.
Train: 2018-08-01T00:21:23.788492: step 6436, loss 0.597179.
Train: 2018-08-01T00:21:23.944730: step 6437, loss 0.492804.
Train: 2018-08-01T00:21:24.100918: step 6438, loss 0.510105.
Train: 2018-08-01T00:21:24.257163: step 6439, loss 0.579923.
Train: 2018-08-01T00:21:24.413345: step 6440, loss 0.527404.
Test: 2018-08-01T00:21:24.882017: step 6440, loss 0.547753.
Train: 2018-08-01T00:21:25.053851: step 6441, loss 0.562458.
Train: 2018-08-01T00:21:25.210064: step 6442, loss 0.668038.
Train: 2018-08-01T00:21:25.366250: step 6443, loss 0.615261.
Train: 2018-08-01T00:21:25.522492: step 6444, loss 0.492129.
Train: 2018-08-01T00:21:25.678705: step 6445, loss 0.650412.
Train: 2018-08-01T00:21:25.850510: step 6446, loss 0.492183.
Train: 2018-08-01T00:21:25.991102: step 6447, loss 0.544892.
Train: 2018-08-01T00:21:26.147314: step 6448, loss 0.562461.
Train: 2018-08-01T00:21:26.303553: step 6449, loss 0.580032.
Train: 2018-08-01T00:21:26.459741: step 6450, loss 0.580025.
Test: 2018-08-01T00:21:26.944002: step 6450, loss 0.547756.
Train: 2018-08-01T00:21:27.100216: step 6451, loss 0.474684.
Train: 2018-08-01T00:21:27.240809: step 6452, loss 0.702986.
Train: 2018-08-01T00:21:27.397052: step 6453, loss 0.615067.
Train: 2018-08-01T00:21:27.553265: step 6454, loss 0.527441.
Train: 2018-08-01T00:21:27.709450: step 6455, loss 0.510018.
Train: 2018-08-01T00:21:27.865692: step 6456, loss 0.544971.
Train: 2018-08-01T00:21:28.037523: step 6457, loss 0.562429.
Train: 2018-08-01T00:21:28.193734: step 6458, loss 0.492651.
Train: 2018-08-01T00:21:28.349954: step 6459, loss 0.579883.
Train: 2018-08-01T00:21:28.506138: step 6460, loss 0.56243.
Test: 2018-08-01T00:21:28.974822: step 6460, loss 0.54781.
Train: 2018-08-01T00:21:29.146613: step 6461, loss 0.684646.
Train: 2018-08-01T00:21:29.302826: step 6462, loss 0.475281.
Train: 2018-08-01T00:21:29.459064: step 6463, loss 0.440465.
Train: 2018-08-01T00:21:29.630898: step 6464, loss 0.510085.
Train: 2018-08-01T00:21:29.787123: step 6465, loss 0.597401.
Train: 2018-08-01T00:21:29.943301: step 6466, loss 0.544938.
Train: 2018-08-01T00:21:30.099545: step 6467, loss 0.562448.
Train: 2018-08-01T00:21:30.271349: step 6468, loss 0.579999.
Train: 2018-08-01T00:21:30.427562: step 6469, loss 0.5449.
Train: 2018-08-01T00:21:30.583806: step 6470, loss 0.615172.
Test: 2018-08-01T00:21:31.052448: step 6470, loss 0.547749.
Train: 2018-08-01T00:21:31.208659: step 6471, loss 0.580027.
Train: 2018-08-01T00:21:31.396085: step 6472, loss 0.650251.
Train: 2018-08-01T00:21:31.552301: step 6473, loss 0.527394.
Train: 2018-08-01T00:21:31.708536: step 6474, loss 0.614962.
Train: 2018-08-01T00:21:31.864756: step 6475, loss 0.510014.
Train: 2018-08-01T00:21:32.020970: step 6476, loss 0.684619.
Train: 2018-08-01T00:21:32.177152: step 6477, loss 0.49279.
Train: 2018-08-01T00:21:32.333366: step 6478, loss 0.545034.
Train: 2018-08-01T00:21:32.520853: step 6479, loss 0.52769.
Train: 2018-08-01T00:21:32.661444: step 6480, loss 0.527708.
Test: 2018-08-01T00:21:33.145676: step 6480, loss 0.547881.
Train: 2018-08-01T00:21:33.301919: step 6481, loss 0.56241.
Train: 2018-08-01T00:21:33.458140: step 6482, loss 0.510361.
Train: 2018-08-01T00:21:33.629969: step 6483, loss 0.579773.
Train: 2018-08-01T00:21:33.786181: step 6484, loss 0.597147.
Train: 2018-08-01T00:21:33.957985: step 6485, loss 0.579774.
Train: 2018-08-01T00:21:34.114230: step 6486, loss 0.56241.
Train: 2018-08-01T00:21:34.270443: step 6487, loss 0.510378.
Train: 2018-08-01T00:21:34.426626: step 6488, loss 0.545061.
Train: 2018-08-01T00:21:34.614112: step 6489, loss 0.562411.
Train: 2018-08-01T00:21:34.770326: step 6490, loss 0.475599.
Test: 2018-08-01T00:21:35.254588: step 6490, loss 0.547854.
Train: 2018-08-01T00:21:35.410770: step 6491, loss 0.492855.
Train: 2018-08-01T00:21:35.567015: step 6492, loss 0.649587.
Train: 2018-08-01T00:21:35.738818: step 6493, loss 0.544981.
Train: 2018-08-01T00:21:35.895047: step 6494, loss 0.649748.
Train: 2018-08-01T00:21:36.035623: step 6495, loss 0.562429.
Train: 2018-08-01T00:21:36.191837: step 6496, loss 0.527536.
Train: 2018-08-01T00:21:36.348081: step 6497, loss 0.579873.
Train: 2018-08-01T00:21:36.504295: step 6498, loss 0.544986.
Train: 2018-08-01T00:21:36.660478: step 6499, loss 0.562426.
Train: 2018-08-01T00:21:36.832312: step 6500, loss 0.667043.
Test: 2018-08-01T00:21:37.300982: step 6500, loss 0.547844.
Train: 2018-08-01T00:21:37.988291: step 6501, loss 0.562419.
Train: 2018-08-01T00:21:38.144529: step 6502, loss 0.527658.
Train: 2018-08-01T00:21:38.300749: step 6503, loss 0.579773.
Train: 2018-08-01T00:21:38.472553: step 6504, loss 0.579749.
Train: 2018-08-01T00:21:38.644387: step 6505, loss 0.614357.
Train: 2018-08-01T00:21:38.800601: step 6506, loss 0.545119.
Train: 2018-08-01T00:21:38.956816: step 6507, loss 0.493382.
Train: 2018-08-01T00:21:39.113028: step 6508, loss 0.579646.
Train: 2018-08-01T00:21:39.269242: step 6509, loss 0.476219.
Train: 2018-08-01T00:21:39.425455: step 6510, loss 0.545151.
Test: 2018-08-01T00:21:39.909715: step 6510, loss 0.547944.
Train: 2018-08-01T00:21:40.065961: step 6511, loss 0.493348.
Train: 2018-08-01T00:21:40.222175: step 6512, loss 0.47593.
Train: 2018-08-01T00:21:40.394009: step 6513, loss 0.510375.
Train: 2018-08-01T00:21:40.550192: step 6514, loss 0.597225.
Train: 2018-08-01T00:21:40.706429: step 6515, loss 0.597319.
Train: 2018-08-01T00:21:40.862618: step 6516, loss 0.579908.
Train: 2018-08-01T00:21:41.018841: step 6517, loss 0.579933.
Train: 2018-08-01T00:21:41.190697: step 6518, loss 0.422396.
Train: 2018-08-01T00:21:41.346910: step 6519, loss 0.597558.
Train: 2018-08-01T00:21:41.503093: step 6520, loss 0.456969.
Test: 2018-08-01T00:21:41.971763: step 6520, loss 0.547715.
Train: 2018-08-01T00:21:42.127946: step 6521, loss 0.562483.
Train: 2018-08-01T00:21:42.299782: step 6522, loss 0.580184.
Train: 2018-08-01T00:21:42.471647: step 6523, loss 0.562516.
Train: 2018-08-01T00:21:42.627861: step 6524, loss 0.509285.
Train: 2018-08-01T00:21:42.784044: step 6525, loss 0.633693.
Train: 2018-08-01T00:21:42.955879: step 6526, loss 0.544753.
Train: 2018-08-01T00:21:43.112093: step 6527, loss 0.509113.
Train: 2018-08-01T00:21:43.268336: step 6528, loss 0.473368.
Train: 2018-08-01T00:21:43.440170: step 6529, loss 0.491061.
Train: 2018-08-01T00:21:43.596377: step 6530, loss 0.580567.
Test: 2018-08-01T00:21:44.080645: step 6530, loss 0.547598.
Train: 2018-08-01T00:21:44.236828: step 6531, loss 0.562654.
Train: 2018-08-01T00:21:44.393041: step 6532, loss 0.526647.
Train: 2018-08-01T00:21:44.564876: step 6533, loss 0.652959.
Train: 2018-08-01T00:21:44.736736: step 6534, loss 0.562706.
Train: 2018-08-01T00:21:44.892924: step 6535, loss 0.634962.
Train: 2018-08-01T00:21:45.049138: step 6536, loss 0.544651.
Train: 2018-08-01T00:21:45.205351: step 6537, loss 0.490561.
Train: 2018-08-01T00:21:45.361564: step 6538, loss 0.544655.
Train: 2018-08-01T00:21:45.517809: step 6539, loss 0.580727.
Train: 2018-08-01T00:21:45.705265: step 6540, loss 0.58072.
Test: 2018-08-01T00:21:46.173907: step 6540, loss 0.547589.
Train: 2018-08-01T00:21:46.330112: step 6541, loss 0.544659.
Train: 2018-08-01T00:21:46.486334: step 6542, loss 0.508638.
Train: 2018-08-01T00:21:46.658137: step 6543, loss 0.58069.
Train: 2018-08-01T00:21:46.814386: step 6544, loss 0.562672.
Train: 2018-08-01T00:21:46.970562: step 6545, loss 0.598672.
Train: 2018-08-01T00:21:47.126776: step 6546, loss 0.634589.
Train: 2018-08-01T00:21:47.283020: step 6547, loss 0.652359.
Train: 2018-08-01T00:21:47.454824: step 6548, loss 0.634141.
Train: 2018-08-01T00:21:47.611038: step 6549, loss 0.562559.
Train: 2018-08-01T00:21:47.767252: step 6550, loss 0.544784.
Test: 2018-08-01T00:21:48.235922: step 6550, loss 0.547694.
Train: 2018-08-01T00:21:48.407760: step 6551, loss 0.562501.
Train: 2018-08-01T00:21:48.563971: step 6552, loss 0.456716.
Train: 2018-08-01T00:21:48.720153: step 6553, loss 0.597678.
Train: 2018-08-01T00:21:48.891989: step 6554, loss 0.544891.
Train: 2018-08-01T00:21:49.048232: step 6555, loss 0.615085.
Train: 2018-08-01T00:21:49.204416: step 6556, loss 0.527431.
Train: 2018-08-01T00:21:49.360658: step 6557, loss 0.63235.
Train: 2018-08-01T00:21:49.516844: step 6558, loss 0.667037.
Train: 2018-08-01T00:21:49.673085: step 6559, loss 0.545044.
Train: 2018-08-01T00:21:49.844921: step 6560, loss 0.545093.
Test: 2018-08-01T00:21:50.313530: step 6560, loss 0.547943.
Train: 2018-08-01T00:21:50.469774: step 6561, loss 0.614192.
Train: 2018-08-01T00:21:50.625988: step 6562, loss 0.562396.
Train: 2018-08-01T00:21:50.782170: step 6563, loss 0.459455.
Train: 2018-08-01T00:21:50.938383: step 6564, loss 0.61381.
Train: 2018-08-01T00:21:51.110218: step 6565, loss 0.61372.
Train: 2018-08-01T00:21:51.250842: step 6566, loss 0.6136.
Train: 2018-08-01T00:21:51.422670: step 6567, loss 0.596437.
Train: 2018-08-01T00:21:51.578858: step 6568, loss 0.56241.
Train: 2018-08-01T00:21:51.719476: step 6569, loss 0.579334.
Train: 2018-08-01T00:21:51.875696: step 6570, loss 0.494949.
Test: 2018-08-01T00:21:52.344335: step 6570, loss 0.548325.
Train: 2018-08-01T00:21:52.516171: step 6571, loss 0.528739.
Train: 2018-08-01T00:21:52.672354: step 6572, loss 0.511925.
Train: 2018-08-01T00:21:52.828597: step 6573, loss 0.478223.
Train: 2018-08-01T00:21:52.984810: step 6574, loss 0.511814.
Train: 2018-08-01T00:21:53.140993: step 6575, loss 0.57933.
Train: 2018-08-01T00:21:53.297207: step 6576, loss 0.66408.
Train: 2018-08-01T00:21:53.469069: step 6577, loss 0.613255.
Train: 2018-08-01T00:21:53.625256: step 6578, loss 0.545477.
Train: 2018-08-01T00:21:53.781467: step 6579, loss 0.562415.
Train: 2018-08-01T00:21:53.937706: step 6580, loss 0.596277.
Test: 2018-08-01T00:21:54.406323: step 6580, loss 0.548248.
Train: 2018-08-01T00:21:54.562560: step 6581, loss 0.579337.
Train: 2018-08-01T00:21:54.734370: step 6582, loss 0.56242.
Train: 2018-08-01T00:21:54.890614: step 6583, loss 0.562422.
Train: 2018-08-01T00:21:55.046827: step 6584, loss 0.562424.
Train: 2018-08-01T00:21:55.203040: step 6585, loss 0.528667.
Train: 2018-08-01T00:21:55.359225: step 6586, loss 0.562424.
Train: 2018-08-01T00:21:55.531095: step 6587, loss 0.444215.
Train: 2018-08-01T00:21:55.671681: step 6588, loss 0.647034.
Train: 2018-08-01T00:21:55.827864: step 6589, loss 0.562414.
Train: 2018-08-01T00:21:55.984107: step 6590, loss 0.596303.
Test: 2018-08-01T00:21:56.468369: step 6590, loss 0.548222.
Train: 2018-08-01T00:21:56.655826: step 6591, loss 0.613251.
Train: 2018-08-01T00:21:56.796419: step 6592, loss 0.69789.
Train: 2018-08-01T00:21:56.952602: step 6593, loss 0.697529.
Train: 2018-08-01T00:21:57.108844: step 6594, loss 0.646498.
Train: 2018-08-01T00:21:57.280673: step 6595, loss 0.612631.
Train: 2018-08-01T00:21:57.421240: step 6596, loss 0.512623.
Train: 2018-08-01T00:21:57.593105: step 6597, loss 0.579092.
Train: 2018-08-01T00:21:57.764935: step 6598, loss 0.562566.
Train: 2018-08-01T00:21:57.921154: step 6599, loss 0.579033.
Train: 2018-08-01T00:21:58.077337: step 6600, loss 0.595397.
Test: 2018-08-01T00:21:58.546007: step 6600, loss 0.548982.
Train: 2018-08-01T00:21:59.248938: step 6601, loss 0.578991.
Train: 2018-08-01T00:21:59.405181: step 6602, loss 0.546409.
Train: 2018-08-01T00:21:59.561366: step 6603, loss 0.481489.
Train: 2018-08-01T00:21:59.733224: step 6604, loss 0.578961.
Train: 2018-08-01T00:21:59.889440: step 6605, loss 0.578959.
Train: 2018-08-01T00:22:00.061278: step 6606, loss 0.611401.
Train: 2018-08-01T00:22:00.201870: step 6607, loss 0.449318.
Train: 2018-08-01T00:22:00.358084: step 6608, loss 0.530287.
Train: 2018-08-01T00:22:00.529887: step 6609, loss 0.627724.
Train: 2018-08-01T00:22:00.686111: step 6610, loss 0.611498.
Test: 2018-08-01T00:22:01.154773: step 6610, loss 0.549084.
Train: 2018-08-01T00:22:01.326576: step 6611, loss 0.595233.
Train: 2018-08-01T00:22:01.482821: step 6612, loss 0.644002.
Train: 2018-08-01T00:22:01.639003: step 6613, loss 0.49779.
Train: 2018-08-01T00:22:01.810837: step 6614, loss 0.514028.
Train: 2018-08-01T00:22:01.967051: step 6615, loss 0.546466.
Train: 2018-08-01T00:22:02.154507: step 6616, loss 0.660327.
Train: 2018-08-01T00:22:02.295130: step 6617, loss 0.513901.
Train: 2018-08-01T00:22:02.451314: step 6618, loss 0.578974.
Train: 2018-08-01T00:22:02.607556: step 6619, loss 0.513815.
Train: 2018-08-01T00:22:02.763770: step 6620, loss 0.595302.
Test: 2018-08-01T00:22:03.232413: step 6620, loss 0.54898.
Train: 2018-08-01T00:22:03.388625: step 6621, loss 0.52999.
Train: 2018-08-01T00:22:03.544808: step 6622, loss 0.597545.
Train: 2018-08-01T00:22:03.716641: step 6623, loss 0.464353.
Train: 2018-08-01T00:22:03.872891: step 6624, loss 0.529751.
Train: 2018-08-01T00:22:04.029099: step 6625, loss 0.513137.
Train: 2018-08-01T00:22:04.185283: step 6626, loss 0.595627.
Train: 2018-08-01T00:22:04.341495: step 6627, loss 0.496145.
Train: 2018-08-01T00:22:04.513354: step 6628, loss 0.462537.
Train: 2018-08-01T00:22:04.669543: step 6629, loss 0.56246.
Train: 2018-08-01T00:22:04.825758: step 6630, loss 0.495126.
Test: 2018-08-01T00:22:05.310045: step 6630, loss 0.548249.
Train: 2018-08-01T00:22:05.466268: step 6631, loss 0.647016.
Train: 2018-08-01T00:22:05.622446: step 6632, loss 0.545427.
Train: 2018-08-01T00:22:05.778660: step 6633, loss 0.596482.
Train: 2018-08-01T00:22:05.934902: step 6634, loss 0.545312.
Train: 2018-08-01T00:22:06.091085: step 6635, loss 0.596659.
Train: 2018-08-01T00:22:06.247330: step 6636, loss 0.596722.
Train: 2018-08-01T00:22:06.419170: step 6637, loss 0.47648.
Train: 2018-08-01T00:22:06.575347: step 6638, loss 0.510726.
Train: 2018-08-01T00:22:06.731585: step 6639, loss 0.527854.
Train: 2018-08-01T00:22:06.887774: step 6640, loss 0.527753.
Test: 2018-08-01T00:22:07.356414: step 6640, loss 0.547859.
Train: 2018-08-01T00:22:07.528250: step 6641, loss 0.545032.
Train: 2018-08-01T00:22:07.668841: step 6642, loss 0.597302.
Train: 2018-08-01T00:22:07.840676: step 6643, loss 0.614867.
Train: 2018-08-01T00:22:07.996890: step 6644, loss 0.544942.
Train: 2018-08-01T00:22:08.153103: step 6645, loss 0.685084.
Train: 2018-08-01T00:22:08.309341: step 6646, loss 0.684986.
Train: 2018-08-01T00:22:08.465554: step 6647, loss 0.492586.
Train: 2018-08-01T00:22:08.637364: step 6648, loss 0.597301.
Train: 2018-08-01T00:22:08.793602: step 6649, loss 0.562419.
Train: 2018-08-01T00:22:08.949827: step 6650, loss 0.597169.
Test: 2018-08-01T00:22:09.418462: step 6650, loss 0.547887.
Train: 2018-08-01T00:22:09.590267: step 6651, loss 0.631775.
Train: 2018-08-01T00:22:09.746480: step 6652, loss 0.545112.
Train: 2018-08-01T00:22:09.902724: step 6653, loss 0.579647.
Train: 2018-08-01T00:22:10.074529: step 6654, loss 0.579602.
Train: 2018-08-01T00:22:10.230765: step 6655, loss 0.613884.
Train: 2018-08-01T00:22:10.386979: step 6656, loss 0.596617.
Train: 2018-08-01T00:22:10.543198: step 6657, loss 0.545345.
Train: 2018-08-01T00:22:10.699381: step 6658, loss 0.613429.
Train: 2018-08-01T00:22:10.886838: step 6659, loss 0.545457.
Train: 2018-08-01T00:22:11.043076: step 6660, loss 0.444045.
Test: 2018-08-01T00:22:11.527343: step 6660, loss 0.548265.
Train: 2018-08-01T00:22:11.683525: step 6661, loss 0.630037.
Train: 2018-08-01T00:22:11.839740: step 6662, loss 0.562425.
Train: 2018-08-01T00:22:12.011575: step 6663, loss 0.596151.
Train: 2018-08-01T00:22:12.167817: step 6664, loss 0.562435.
Train: 2018-08-01T00:22:12.324031: step 6665, loss 0.61288.
Train: 2018-08-01T00:22:12.480245: step 6666, loss 0.663133.
Train: 2018-08-01T00:22:12.652049: step 6667, loss 0.545742.
Train: 2018-08-01T00:22:12.792666: step 6668, loss 0.562483.
Train: 2018-08-01T00:22:13.011372: step 6669, loss 0.545853.
Train: 2018-08-01T00:22:13.167554: step 6670, loss 0.562508.
Test: 2018-08-01T00:22:13.636224: step 6670, loss 0.548622.
Train: 2018-08-01T00:22:13.792438: step 6671, loss 0.562518.
Train: 2018-08-01T00:22:13.948621: step 6672, loss 0.463074.
Train: 2018-08-01T00:22:14.151699: step 6673, loss 0.529344.
Train: 2018-08-01T00:22:14.307912: step 6674, loss 0.612343.
Train: 2018-08-01T00:22:14.464126: step 6675, loss 0.579126.
Train: 2018-08-01T00:22:14.620337: step 6676, loss 0.612378.
Train: 2018-08-01T00:22:14.776551: step 6677, loss 0.512657.
Train: 2018-08-01T00:22:14.932796: step 6678, loss 0.595756.
Train: 2018-08-01T00:22:15.104600: step 6679, loss 0.562504.
Train: 2018-08-01T00:22:15.276435: step 6680, loss 0.67891.
Test: 2018-08-01T00:22:15.760695: step 6680, loss 0.548612.
Train: 2018-08-01T00:22:15.916909: step 6681, loss 0.545912.
Train: 2018-08-01T00:22:16.073123: step 6682, loss 0.529355.
Train: 2018-08-01T00:22:16.260601: step 6683, loss 0.463055.
Train: 2018-08-01T00:22:16.416792: step 6684, loss 0.562514.
Train: 2018-08-01T00:22:16.573037: step 6685, loss 0.562504.
Train: 2018-08-01T00:22:16.729220: step 6686, loss 0.662397.
Train: 2018-08-01T00:22:16.885464: step 6687, loss 0.495912.
Train: 2018-08-01T00:22:17.041647: step 6688, loss 0.495842.
Train: 2018-08-01T00:22:17.197860: step 6689, loss 0.562477.
Train: 2018-08-01T00:22:17.354093: step 6690, loss 0.646112.
Test: 2018-08-01T00:22:17.838365: step 6690, loss 0.548448.
Train: 2018-08-01T00:22:17.994579: step 6691, loss 0.562463.
Train: 2018-08-01T00:22:18.150797: step 6692, loss 0.595952.
Train: 2018-08-01T00:22:18.307000: step 6693, loss 0.629445.
Train: 2018-08-01T00:22:18.478810: step 6694, loss 0.595925.
Train: 2018-08-01T00:22:18.635023: step 6695, loss 0.629301.
Train: 2018-08-01T00:22:18.791237: step 6696, loss 0.595771.
Train: 2018-08-01T00:22:18.947451: step 6697, loss 0.545972.
Train: 2018-08-01T00:22:19.103664: step 6698, loss 0.496247.
Train: 2018-08-01T00:22:19.259876: step 6699, loss 0.512716.
Train: 2018-08-01T00:22:19.416091: step 6700, loss 0.54583.
Test: 2018-08-01T00:22:19.900352: step 6700, loss 0.548648.
Train: 2018-08-01T00:22:20.634556: step 6701, loss 0.529339.
Train: 2018-08-01T00:22:20.790769: step 6702, loss 0.529468.
Train: 2018-08-01T00:22:20.947012: step 6703, loss 0.562497.
Train: 2018-08-01T00:22:21.103195: step 6704, loss 0.529052.
Train: 2018-08-01T00:22:21.259439: step 6705, loss 0.478711.
Train: 2018-08-01T00:22:21.415622: step 6706, loss 0.579252.
Train: 2018-08-01T00:22:21.571836: step 6707, loss 0.646731.
Train: 2018-08-01T00:22:21.743670: step 6708, loss 0.545541.
Train: 2018-08-01T00:22:21.899914: step 6709, loss 0.596242.
Train: 2018-08-01T00:22:22.056127: step 6710, loss 0.494708.
Test: 2018-08-01T00:22:22.524767: step 6710, loss 0.548209.
Train: 2018-08-01T00:22:22.743467: step 6711, loss 0.545451.
Train: 2018-08-01T00:22:22.915301: step 6712, loss 0.630391.
Train: 2018-08-01T00:22:23.071514: step 6713, loss 0.562406.
Train: 2018-08-01T00:22:23.243343: step 6714, loss 0.511334.
Train: 2018-08-01T00:22:23.399533: step 6715, loss 0.511254.
Train: 2018-08-01T00:22:23.555776: step 6716, loss 0.528226.
Train: 2018-08-01T00:22:23.711959: step 6717, loss 0.511007.
Train: 2018-08-01T00:22:23.868205: step 6718, loss 0.545216.
Train: 2018-08-01T00:22:24.040008: step 6719, loss 0.579636.
Train: 2018-08-01T00:22:24.196256: step 6720, loss 0.596958.
Test: 2018-08-01T00:22:24.664860: step 6720, loss 0.547916.
Train: 2018-08-01T00:22:24.821074: step 6721, loss 0.597018.
Train: 2018-08-01T00:22:24.977316: step 6722, loss 0.631693.
Train: 2018-08-01T00:22:25.149123: step 6723, loss 0.510461.
Train: 2018-08-01T00:22:25.305336: step 6724, loss 0.579735.
Train: 2018-08-01T00:22:25.477202: step 6725, loss 0.458444.
Train: 2018-08-01T00:22:25.633415: step 6726, loss 0.683915.
Train: 2018-08-01T00:22:25.789628: step 6727, loss 0.510361.
Train: 2018-08-01T00:22:25.945841: step 6728, loss 0.649206.
Train: 2018-08-01T00:22:26.117683: step 6729, loss 0.545071.
Train: 2018-08-01T00:22:26.273890: step 6730, loss 0.510421.
Test: 2018-08-01T00:22:26.758121: step 6730, loss 0.547897.
Train: 2018-08-01T00:22:26.914364: step 6731, loss 0.579745.
Train: 2018-08-01T00:22:27.070578: step 6732, loss 0.579742.
Train: 2018-08-01T00:22:27.226792: step 6733, loss 0.614379.
Train: 2018-08-01T00:22:27.383005: step 6734, loss 0.700823.
Train: 2018-08-01T00:22:27.539218: step 6735, loss 0.631387.
Train: 2018-08-01T00:22:27.695401: step 6736, loss 0.5624.
Train: 2018-08-01T00:22:27.851614: step 6737, loss 0.476825.
Train: 2018-08-01T00:22:28.007828: step 6738, loss 0.494073.
Train: 2018-08-01T00:22:28.164073: step 6739, loss 0.528261.
Train: 2018-08-01T00:22:28.335878: step 6740, loss 0.579473.
Test: 2018-08-01T00:22:28.804546: step 6740, loss 0.548112.
Train: 2018-08-01T00:22:28.960760: step 6741, loss 0.528271.
Train: 2018-08-01T00:22:29.132565: step 6742, loss 0.545332.
Train: 2018-08-01T00:22:29.288809: step 6743, loss 0.579482.
Train: 2018-08-01T00:22:29.445018: step 6744, loss 0.476978.
Train: 2018-08-01T00:22:29.616852: step 6745, loss 0.545289.
Train: 2018-08-01T00:22:29.788661: step 6746, loss 0.665243.
Train: 2018-08-01T00:22:29.944905: step 6747, loss 0.493842.
Train: 2018-08-01T00:22:30.101118: step 6748, loss 0.528087.
Train: 2018-08-01T00:22:30.257332: step 6749, loss 0.510856.
Train: 2018-08-01T00:22:30.413514: step 6750, loss 0.390232.
Test: 2018-08-01T00:22:30.866533: step 6750, loss 0.547925.
Train: 2018-08-01T00:22:31.022747: step 6751, loss 0.527818.
Train: 2018-08-01T00:22:31.178960: step 6752, loss 0.527672.
Train: 2018-08-01T00:22:31.335174: step 6753, loss 0.632238.
Train: 2018-08-01T00:22:31.491412: step 6754, loss 0.579948.
Train: 2018-08-01T00:22:31.663223: step 6755, loss 0.474738.
Train: 2018-08-01T00:22:31.835082: step 6756, loss 0.597679.
Train: 2018-08-01T00:22:31.975680: step 6757, loss 0.544846.
Train: 2018-08-01T00:22:32.147509: step 6758, loss 0.580189.
Train: 2018-08-01T00:22:32.303728: step 6759, loss 0.580232.
Train: 2018-08-01T00:22:32.459911: step 6760, loss 0.562527.
Test: 2018-08-01T00:22:32.944172: step 6760, loss 0.54767.
Train: 2018-08-01T00:22:33.100387: step 6761, loss 0.509282.
Train: 2018-08-01T00:22:33.256624: step 6762, loss 0.580323.
Train: 2018-08-01T00:22:33.412843: step 6763, loss 0.473583.
Train: 2018-08-01T00:22:33.569026: step 6764, loss 0.473421.
Train: 2018-08-01T00:22:33.725269: step 6765, loss 0.38377.
Train: 2018-08-01T00:22:33.912695: step 6766, loss 0.634546.
Train: 2018-08-01T00:22:34.068939: step 6767, loss 0.490557.
Train: 2018-08-01T00:22:34.225152: step 6768, loss 0.598945.
Train: 2018-08-01T00:22:34.381336: step 6769, loss 0.653542.
Train: 2018-08-01T00:22:34.537549: step 6770, loss 0.526447.
Test: 2018-08-01T00:22:35.006220: step 6770, loss 0.547572.
Train: 2018-08-01T00:22:35.162433: step 6771, loss 0.508224.
Train: 2018-08-01T00:22:35.318647: step 6772, loss 0.653958.
Train: 2018-08-01T00:22:35.474830: step 6773, loss 0.581059.
Train: 2018-08-01T00:22:35.631043: step 6774, loss 0.508171.
Train: 2018-08-01T00:22:35.787309: step 6775, loss 0.617497.
Train: 2018-08-01T00:22:35.943501: step 6776, loss 0.581027.
Train: 2018-08-01T00:22:36.115336: step 6777, loss 0.599177.
Train: 2018-08-01T00:22:36.271548: step 6778, loss 0.526467.
Train: 2018-08-01T00:22:36.427731: step 6779, loss 0.453963.
Train: 2018-08-01T00:22:36.583945: step 6780, loss 0.5809.
Test: 2018-08-01T00:22:37.052614: step 6780, loss 0.547577.
Train: 2018-08-01T00:22:37.224450: step 6781, loss 0.508365.
Train: 2018-08-01T00:22:37.380633: step 6782, loss 0.453938.
Train: 2018-08-01T00:22:37.536846: step 6783, loss 0.471951.
Train: 2018-08-01T00:22:37.693061: step 6784, loss 0.508184.
Train: 2018-08-01T00:22:37.849273: step 6785, loss 0.654182.
Train: 2018-08-01T00:22:38.005519: step 6786, loss 0.56288.
Train: 2018-08-01T00:22:38.161732: step 6787, loss 0.581188.
Train: 2018-08-01T00:22:38.333560: step 6788, loss 0.544594.
Train: 2018-08-01T00:22:38.489748: step 6789, loss 0.562898.
Train: 2018-08-01T00:22:38.645961: step 6790, loss 0.489681.
Test: 2018-08-01T00:22:39.114634: step 6790, loss 0.547571.
Train: 2018-08-01T00:22:39.270841: step 6791, loss 0.636184.
Train: 2018-08-01T00:22:39.442682: step 6792, loss 0.544593.
Train: 2018-08-01T00:22:39.598864: step 6793, loss 0.544594.
Train: 2018-08-01T00:22:39.755077: step 6794, loss 0.636066.
Train: 2018-08-01T00:22:39.911321: step 6795, loss 0.617664.
Train: 2018-08-01T00:22:40.067534: step 6796, loss 0.526384.
Train: 2018-08-01T00:22:40.239370: step 6797, loss 0.544614.
Train: 2018-08-01T00:22:40.395584: step 6798, loss 0.453812.
Train: 2018-08-01T00:22:40.551766: step 6799, loss 0.544621.
Train: 2018-08-01T00:22:40.707979: step 6800, loss 0.653575.
Test: 2018-08-01T00:22:41.176649: step 6800, loss 0.547576.
Train: 2018-08-01T00:22:41.895231: step 6801, loss 0.544628.
Train: 2018-08-01T00:22:42.051445: step 6802, loss 0.508416.
Train: 2018-08-01T00:22:42.207659: step 6803, loss 0.544637.
Train: 2018-08-01T00:22:42.363873: step 6804, loss 0.580821.
Train: 2018-08-01T00:22:42.520090: step 6805, loss 0.490415.
Train: 2018-08-01T00:22:42.691890: step 6806, loss 0.508488.
Train: 2018-08-01T00:22:42.848127: step 6807, loss 0.454192.
Train: 2018-08-01T00:22:43.004347: step 6808, loss 0.472132.
Train: 2018-08-01T00:22:43.160560: step 6809, loss 0.635492.
Train: 2018-08-01T00:22:43.316769: step 6810, loss 0.599209.
Test: 2018-08-01T00:22:43.801005: step 6810, loss 0.547571.
Train: 2018-08-01T00:22:43.957218: step 6811, loss 0.562818.
Train: 2018-08-01T00:22:44.113431: step 6812, loss 0.653883.
Train: 2018-08-01T00:22:44.269645: step 6813, loss 0.562803.
Train: 2018-08-01T00:22:44.425859: step 6814, loss 0.508286.
Train: 2018-08-01T00:22:44.582072: step 6815, loss 0.599086.
Train: 2018-08-01T00:22:44.738317: step 6816, loss 0.508362.
Train: 2018-08-01T00:22:44.925767: step 6817, loss 0.580875.
Train: 2018-08-01T00:22:45.066359: step 6818, loss 0.526529.
Train: 2018-08-01T00:22:45.222582: step 6819, loss 0.598925.
Train: 2018-08-01T00:22:45.394381: step 6820, loss 0.616944.
Test: 2018-08-01T00:22:45.863056: step 6820, loss 0.547588.
Train: 2018-08-01T00:22:46.034882: step 6821, loss 0.634852.
Train: 2018-08-01T00:22:46.191104: step 6822, loss 0.580646.
Train: 2018-08-01T00:22:46.347284: step 6823, loss 0.65228.
Train: 2018-08-01T00:22:46.503528: step 6824, loss 0.580439.
Train: 2018-08-01T00:22:46.659741: step 6825, loss 0.687011.
Train: 2018-08-01T00:22:46.815954: step 6826, loss 0.597861.
Train: 2018-08-01T00:22:46.972184: step 6827, loss 0.544887.
Train: 2018-08-01T00:22:47.143996: step 6828, loss 0.632395.
Train: 2018-08-01T00:22:47.300185: step 6829, loss 0.510249.
Train: 2018-08-01T00:22:47.456399: step 6830, loss 0.47584.
Test: 2018-08-01T00:22:47.925070: step 6830, loss 0.547943.
Train: 2018-08-01T00:22:48.081254: step 6831, loss 0.527869.
Train: 2018-08-01T00:22:48.253118: step 6832, loss 0.527933.
Train: 2018-08-01T00:22:48.424922: step 6833, loss 0.562398.
Train: 2018-08-01T00:22:48.581136: step 6834, loss 0.596784.
Train: 2018-08-01T00:22:48.737349: step 6835, loss 0.528064.
Train: 2018-08-01T00:22:48.893563: step 6836, loss 0.648157.
Train: 2018-08-01T00:22:49.049776: step 6837, loss 0.51105.
Train: 2018-08-01T00:22:49.221612: step 6838, loss 0.68208.
Train: 2018-08-01T00:22:49.362234: step 6839, loss 0.511255.
Train: 2018-08-01T00:22:49.518416: step 6840, loss 0.596443.
Test: 2018-08-01T00:22:50.002709: step 6840, loss 0.548186.
Train: 2018-08-01T00:22:50.158891: step 6841, loss 0.562409.
Train: 2018-08-01T00:22:50.330727: step 6842, loss 0.528507.
Train: 2018-08-01T00:22:50.486940: step 6843, loss 0.477741.
Train: 2018-08-01T00:22:50.627557: step 6844, loss 0.579357.
Train: 2018-08-01T00:22:50.783744: step 6845, loss 0.545469.
Train: 2018-08-01T00:22:50.939958: step 6846, loss 0.630223.
Train: 2018-08-01T00:22:51.096201: step 6847, loss 0.647125.
Train: 2018-08-01T00:22:51.252410: step 6848, loss 0.528599.
Train: 2018-08-01T00:22:51.424220: step 6849, loss 0.511748.
Train: 2018-08-01T00:22:51.564847: step 6850, loss 0.579314.
Test: 2018-08-01T00:22:52.049074: step 6850, loss 0.548286.
Train: 2018-08-01T00:22:52.189696: step 6851, loss 0.57931.
Train: 2018-08-01T00:22:52.345910: step 6852, loss 0.59618.
Train: 2018-08-01T00:22:52.517714: step 6853, loss 0.511849.
Train: 2018-08-01T00:22:52.673927: step 6854, loss 0.528708.
Train: 2018-08-01T00:22:52.830170: step 6855, loss 0.613043.
Train: 2018-08-01T00:22:52.986385: step 6856, loss 0.461217.
Train: 2018-08-01T00:22:53.158189: step 6857, loss 0.613106.
Train: 2018-08-01T00:22:53.314402: step 6858, loss 0.613135.
Train: 2018-08-01T00:22:53.470616: step 6859, loss 0.596224.
Train: 2018-08-01T00:22:53.642481: step 6860, loss 0.596204.
Test: 2018-08-01T00:22:54.111121: step 6860, loss 0.548301.
Train: 2018-08-01T00:22:54.267334: step 6861, loss 0.613042.
Train: 2018-08-01T00:22:54.439139: step 6862, loss 0.562435.
Train: 2018-08-01T00:22:54.595387: step 6863, loss 0.562441.
Train: 2018-08-01T00:22:54.751590: step 6864, loss 0.612832.
Train: 2018-08-01T00:22:54.907780: step 6865, loss 0.545693.
Train: 2018-08-01T00:22:55.064023: step 6866, loss 0.562464.
Train: 2018-08-01T00:22:55.220236: step 6867, loss 0.629356.
Train: 2018-08-01T00:22:55.392071: step 6868, loss 0.545794.
Train: 2018-08-01T00:22:55.548253: step 6869, loss 0.595818.
Train: 2018-08-01T00:22:55.704468: step 6870, loss 0.62904.
Test: 2018-08-01T00:22:56.188759: step 6870, loss 0.548626.
Train: 2018-08-01T00:22:56.344974: step 6871, loss 0.56252.
Train: 2018-08-01T00:22:56.501157: step 6872, loss 0.512871.
Train: 2018-08-01T00:22:56.657394: step 6873, loss 0.645236.
Train: 2018-08-01T00:22:56.829205: step 6874, loss 0.595567.
Train: 2018-08-01T00:22:57.001038: step 6875, loss 0.54612.
Train: 2018-08-01T00:22:57.157252: step 6876, loss 0.529729.
Train: 2018-08-01T00:22:57.313497: step 6877, loss 0.579027.
Train: 2018-08-01T00:22:57.469709: step 6878, loss 0.447766.
Train: 2018-08-01T00:22:57.641538: step 6879, loss 0.628317.
Train: 2018-08-01T00:22:57.797727: step 6880, loss 0.480436.
Test: 2018-08-01T00:22:58.266398: step 6880, loss 0.548799.
Train: 2018-08-01T00:22:58.422580: step 6881, loss 0.611969.
Train: 2018-08-01T00:22:58.578795: step 6882, loss 0.463716.
Train: 2018-08-01T00:22:58.735032: step 6883, loss 0.612113.
Train: 2018-08-01T00:22:58.906872: step 6884, loss 0.595634.
Train: 2018-08-01T00:22:59.063056: step 6885, loss 0.496273.
Train: 2018-08-01T00:22:59.219301: step 6886, loss 0.562516.
Train: 2018-08-01T00:22:59.375484: step 6887, loss 0.629044.
Train: 2018-08-01T00:22:59.531727: step 6888, loss 0.612447.
Train: 2018-08-01T00:22:59.687940: step 6889, loss 0.579147.
Train: 2018-08-01T00:22:59.844154: step 6890, loss 0.595796.
Test: 2018-08-01T00:23:00.312793: step 6890, loss 0.548564.
Train: 2018-08-01T00:23:00.469007: step 6891, loss 0.46265.
Train: 2018-08-01T00:23:00.640841: step 6892, loss 0.512502.
Train: 2018-08-01T00:23:00.797055: step 6893, loss 0.61257.
Train: 2018-08-01T00:23:00.953268: step 6894, loss 0.646054.
Train: 2018-08-01T00:23:01.109483: step 6895, loss 0.679461.
Train: 2018-08-01T00:23:01.281319: step 6896, loss 0.49577.
Train: 2018-08-01T00:23:01.437501: step 6897, loss 0.545821.
Train: 2018-08-01T00:23:01.593743: step 6898, loss 0.645813.
Train: 2018-08-01T00:23:01.749957: step 6899, loss 0.562499.
Train: 2018-08-01T00:23:01.890519: step 6900, loss 0.496024.
Test: 2018-08-01T00:23:02.374811: step 6900, loss 0.548587.
Train: 2018-08-01T00:23:03.093393: step 6901, loss 0.628998.
Train: 2018-08-01T00:23:03.265228: step 6902, loss 0.695382.
Train: 2018-08-01T00:23:03.421412: step 6903, loss 0.562533.
Train: 2018-08-01T00:23:03.577624: step 6904, loss 0.546032.
Train: 2018-08-01T00:23:03.733868: step 6905, loss 0.59555.
Train: 2018-08-01T00:23:03.890075: step 6906, loss 0.52967.
Train: 2018-08-01T00:23:04.046289: step 6907, loss 0.562595.
Train: 2018-08-01T00:23:04.218099: step 6908, loss 0.562603.
Train: 2018-08-01T00:23:04.374312: step 6909, loss 0.529779.
Train: 2018-08-01T00:23:04.530527: step 6910, loss 0.48052.
Test: 2018-08-01T00:23:04.999197: step 6910, loss 0.548821.
Train: 2018-08-01T00:23:05.155409: step 6911, loss 0.49681.
Train: 2018-08-01T00:23:05.311623: step 6912, loss 0.645023.
Train: 2018-08-01T00:23:05.467806: step 6913, loss 0.546045.
Train: 2018-08-01T00:23:05.639641: step 6914, loss 0.479858.
Train: 2018-08-01T00:23:05.795885: step 6915, loss 0.628864.
Train: 2018-08-01T00:23:05.952098: step 6916, loss 0.645572.
Train: 2018-08-01T00:23:06.108313: step 6917, loss 0.496047.
Train: 2018-08-01T00:23:06.264494: step 6918, loss 0.529222.
Train: 2018-08-01T00:23:06.420709: step 6919, loss 0.562487.
Train: 2018-08-01T00:23:06.576922: step 6920, loss 0.545776.
Test: 2018-08-01T00:23:07.061212: step 6920, loss 0.548452.
Train: 2018-08-01T00:23:07.217428: step 6921, loss 0.562465.
Train: 2018-08-01T00:23:07.373641: step 6922, loss 0.478626.
Train: 2018-08-01T00:23:07.529849: step 6923, loss 0.56244.
Train: 2018-08-01T00:23:07.701689: step 6924, loss 0.646763.
Train: 2018-08-01T00:23:07.857903: step 6925, loss 0.629979.
Train: 2018-08-01T00:23:08.014109: step 6926, loss 0.579315.
Train: 2018-08-01T00:23:08.170329: step 6927, loss 0.579313.
Train: 2018-08-01T00:23:08.342164: step 6928, loss 0.511769.
Train: 2018-08-01T00:23:08.482756: step 6929, loss 0.494842.
Train: 2018-08-01T00:23:08.638939: step 6930, loss 0.562417.
Test: 2018-08-01T00:23:09.123231: step 6930, loss 0.548219.
Train: 2018-08-01T00:23:09.279444: step 6931, loss 0.528513.
Train: 2018-08-01T00:23:09.451248: step 6932, loss 0.613358.
Train: 2018-08-01T00:23:09.607487: step 6933, loss 0.528404.
Train: 2018-08-01T00:23:09.779327: step 6934, loss 0.545377.
Train: 2018-08-01T00:23:09.951163: step 6935, loss 0.596507.
Train: 2018-08-01T00:23:10.122966: step 6936, loss 0.579468.
Train: 2018-08-01T00:23:10.279210: step 6937, loss 0.511159.
Train: 2018-08-01T00:23:10.435392: step 6938, loss 0.5795.
Train: 2018-08-01T00:23:10.591636: step 6939, loss 0.493919.
Train: 2018-08-01T00:23:10.747850: step 6940, loss 0.545243.
Test: 2018-08-01T00:23:11.216491: step 6940, loss 0.548004.
Train: 2018-08-01T00:23:11.372704: step 6941, loss 0.47646.
Train: 2018-08-01T00:23:11.528887: step 6942, loss 0.57964.
Train: 2018-08-01T00:23:11.685124: step 6943, loss 0.562402.
Train: 2018-08-01T00:23:11.841313: step 6944, loss 0.441143.
Train: 2018-08-01T00:23:11.997558: step 6945, loss 0.475469.
Train: 2018-08-01T00:23:12.153778: step 6946, loss 0.579905.
Train: 2018-08-01T00:23:12.325611: step 6947, loss 0.615069.
Train: 2018-08-01T00:23:12.481820: step 6948, loss 0.580051.
Train: 2018-08-01T00:23:12.622381: step 6949, loss 0.562478.
Train: 2018-08-01T00:23:12.794245: step 6950, loss 0.562489.
Test: 2018-08-01T00:23:13.278506: step 6950, loss 0.547697.
Train: 2018-08-01T00:23:13.434690: step 6951, loss 0.580175.
Train: 2018-08-01T00:23:13.575313: step 6952, loss 0.52712.
Train: 2018-08-01T00:23:13.731496: step 6953, loss 0.491655.
Train: 2018-08-01T00:23:13.903361: step 6954, loss 0.704541.
Train: 2018-08-01T00:23:14.059576: step 6955, loss 0.598019.
Train: 2018-08-01T00:23:14.215796: step 6956, loss 0.58025.
Train: 2018-08-01T00:23:14.371979: step 6957, loss 0.63334.
Train: 2018-08-01T00:23:14.528215: step 6958, loss 0.615499.
Train: 2018-08-01T00:23:14.684399: step 6959, loss 0.527243.
Train: 2018-08-01T00:23:14.856233: step 6960, loss 0.474573.
Test: 2018-08-01T00:23:15.324874: step 6960, loss 0.547751.
Train: 2018-08-01T00:23:15.512360: step 6961, loss 0.509764.
Train: 2018-08-01T00:23:15.668573: step 6962, loss 0.544894.
Train: 2018-08-01T00:23:15.824786: step 6963, loss 0.632737.
Train: 2018-08-01T00:23:15.980994: step 6964, loss 0.527351.
Train: 2018-08-01T00:23:16.137182: step 6965, loss 0.579999.
Train: 2018-08-01T00:23:16.309018: step 6966, loss 0.544917.
Train: 2018-08-01T00:23:16.465230: step 6967, loss 0.544923.
Train: 2018-08-01T00:23:16.637066: step 6968, loss 0.615011.
Train: 2018-08-01T00:23:16.793280: step 6969, loss 0.457425.
Train: 2018-08-01T00:23:16.949522: step 6970, loss 0.527419.
Test: 2018-08-01T00:23:17.433754: step 6970, loss 0.54777.
Train: 2018-08-01T00:23:17.589999: step 6971, loss 0.492333.
Train: 2018-08-01T00:23:17.761802: step 6972, loss 0.615141.
Train: 2018-08-01T00:23:17.918046: step 6973, loss 0.580037.
Train: 2018-08-01T00:23:18.058638: step 6974, loss 0.439399.
Train: 2018-08-01T00:23:18.214822: step 6975, loss 0.615328.
Train: 2018-08-01T00:23:18.371066: step 6976, loss 0.509581.
Train: 2018-08-01T00:23:18.527249: step 6977, loss 0.63314.
Train: 2018-08-01T00:23:18.683495: step 6978, loss 0.527162.
Train: 2018-08-01T00:23:18.855295: step 6979, loss 0.491788.
Train: 2018-08-01T00:23:19.011510: step 6980, loss 0.63333.
Test: 2018-08-01T00:23:19.480186: step 6980, loss 0.547683.
Train: 2018-08-01T00:23:19.652009: step 6981, loss 0.491677.
Train: 2018-08-01T00:23:19.823821: step 6982, loss 0.491605.
Train: 2018-08-01T00:23:19.995679: step 6983, loss 0.562536.
Train: 2018-08-01T00:23:20.151870: step 6984, loss 0.598133.
Train: 2018-08-01T00:23:20.308082: step 6985, loss 0.455719.
Train: 2018-08-01T00:23:20.464295: step 6986, loss 0.455509.
Train: 2018-08-01T00:23:20.620508: step 6987, loss 0.562609.
Train: 2018-08-01T00:23:20.776752: step 6988, loss 0.652413.
Train: 2018-08-01T00:23:20.948581: step 6989, loss 0.544676.
Train: 2018-08-01T00:23:21.120415: step 6990, loss 0.508679.
Test: 2018-08-01T00:23:21.589061: step 6990, loss 0.547589.
Train: 2018-08-01T00:23:21.745245: step 6991, loss 0.670823.
Train: 2018-08-01T00:23:21.901488: step 6992, loss 0.634755.
Train: 2018-08-01T00:23:22.088946: step 6993, loss 0.562663.
Train: 2018-08-01T00:23:22.245158: step 6994, loss 0.61655.
Train: 2018-08-01T00:23:22.401371: step 6995, loss 0.688121.
Train: 2018-08-01T00:23:22.557555: step 6996, loss 0.5983.
Train: 2018-08-01T00:23:22.713767: step 6997, loss 0.598113.
Train: 2018-08-01T00:23:22.870012: step 6998, loss 0.597921.
Train: 2018-08-01T00:23:23.026194: step 6999, loss 0.544856.
Train: 2018-08-01T00:23:23.182408: step 7000, loss 0.544903.
Test: 2018-08-01T00:23:23.666699: step 7000, loss 0.547791.
Train: 2018-08-01T00:23:24.322766: step 7001, loss 0.492469.
Train: 2018-08-01T00:23:24.479012: step 7002, loss 0.510064.
Train: 2018-08-01T00:23:24.635192: step 7003, loss 0.527557.
Train: 2018-08-01T00:23:24.791437: step 7004, loss 0.492729.
Train: 2018-08-01T00:23:24.963271: step 7005, loss 0.649581.
Train: 2018-08-01T00:23:25.103864: step 7006, loss 0.684322.
Train: 2018-08-01T00:23:25.275698: step 7007, loss 0.631879.
Train: 2018-08-01T00:23:25.463123: step 7008, loss 0.493186.
Train: 2018-08-01T00:23:25.603747: step 7009, loss 0.476068.
Train: 2018-08-01T00:23:25.759954: step 7010, loss 0.52789.
Test: 2018-08-01T00:23:26.228570: step 7010, loss 0.547952.
Train: 2018-08-01T00:23:26.400416: step 7011, loss 0.389873.
Train: 2018-08-01T00:23:26.572238: step 7012, loss 0.666178.
Train: 2018-08-01T00:23:26.712832: step 7013, loss 0.441256.
Train: 2018-08-01T00:23:26.869076: step 7014, loss 0.545062.
Train: 2018-08-01T00:23:27.025283: step 7015, loss 0.597194.
Train: 2018-08-01T00:23:27.181470: step 7016, loss 0.527589.
Train: 2018-08-01T00:23:27.337685: step 7017, loss 0.54498.
Train: 2018-08-01T00:23:27.493897: step 7018, loss 0.597399.
Train: 2018-08-01T00:23:27.665733: step 7019, loss 0.614943.
Train: 2018-08-01T00:23:27.806325: step 7020, loss 0.562442.
Test: 2018-08-01T00:23:28.290617: step 7020, loss 0.547784.
Train: 2018-08-01T00:23:28.446799: step 7021, loss 0.47492.
Train: 2018-08-01T00:23:28.603045: step 7022, loss 0.615028.
Train: 2018-08-01T00:23:28.774847: step 7023, loss 0.579982.
Train: 2018-08-01T00:23:28.931061: step 7024, loss 0.544918.
Train: 2018-08-01T00:23:29.087305: step 7025, loss 0.632584.
Train: 2018-08-01T00:23:29.243489: step 7026, loss 0.544929.
Train: 2018-08-01T00:23:29.399732: step 7027, loss 0.492427.
Train: 2018-08-01T00:23:29.555945: step 7028, loss 0.544934.
Train: 2018-08-01T00:23:29.712129: step 7029, loss 0.579964.
Train: 2018-08-01T00:23:29.883994: step 7030, loss 0.579966.
Test: 2018-08-01T00:23:30.352635: step 7030, loss 0.547777.
Train: 2018-08-01T00:23:30.524439: step 7031, loss 0.544929.
Train: 2018-08-01T00:23:30.680682: step 7032, loss 0.579961.
Train: 2018-08-01T00:23:30.836913: step 7033, loss 0.6675.
Train: 2018-08-01T00:23:31.008730: step 7034, loss 0.544959.
Train: 2018-08-01T00:23:31.164937: step 7035, loss 0.440289.
Train: 2018-08-01T00:23:31.321129: step 7036, loss 0.492611.
Train: 2018-08-01T00:23:31.477341: step 7037, loss 0.562435.
Train: 2018-08-01T00:23:31.633584: step 7038, loss 0.56244.
Train: 2018-08-01T00:23:31.789798: step 7039, loss 0.597471.
Train: 2018-08-01T00:23:31.945983: step 7040, loss 0.562446.
Test: 2018-08-01T00:23:32.414651: step 7040, loss 0.547775.
Train: 2018-08-01T00:23:32.570865: step 7041, loss 0.509885.
Train: 2018-08-01T00:23:32.727079: step 7042, loss 0.52738.
Train: 2018-08-01T00:23:32.883286: step 7043, loss 0.632681.
Train: 2018-08-01T00:23:33.055098: step 7044, loss 0.544901.
Train: 2018-08-01T00:23:33.211310: step 7045, loss 0.562457.
Train: 2018-08-01T00:23:33.367523: step 7046, loss 0.544898.
Train: 2018-08-01T00:23:33.523766: step 7047, loss 0.650275.
Train: 2018-08-01T00:23:33.679979: step 7048, loss 0.597538.
Train: 2018-08-01T00:23:33.836162: step 7049, loss 0.527417.
Train: 2018-08-01T00:23:34.008028: step 7050, loss 0.667413.
Test: 2018-08-01T00:23:34.476637: step 7050, loss 0.547816.
Train: 2018-08-01T00:23:34.632881: step 7051, loss 0.614781.
Train: 2018-08-01T00:23:34.804687: step 7052, loss 0.527626.
Train: 2018-08-01T00:23:34.976553: step 7053, loss 0.683893.
Train: 2018-08-01T00:23:35.132735: step 7054, loss 0.441406.
Train: 2018-08-01T00:23:35.304570: step 7055, loss 0.47613.
Train: 2018-08-01T00:23:35.460782: step 7056, loss 0.545151.
Train: 2018-08-01T00:23:35.616996: step 7057, loss 0.579646.
Train: 2018-08-01T00:23:35.773210: step 7058, loss 0.648606.
Train: 2018-08-01T00:23:35.929453: step 7059, loss 0.545183.
Train: 2018-08-01T00:23:36.085667: step 7060, loss 0.510819.
Test: 2018-08-01T00:23:36.569929: step 7060, loss 0.548004.
Train: 2018-08-01T00:23:36.726143: step 7061, loss 0.562396.
Train: 2018-08-01T00:23:36.882355: step 7062, loss 0.476485.
Train: 2018-08-01T00:23:37.038539: step 7063, loss 0.493595.
Train: 2018-08-01T00:23:37.194753: step 7064, loss 0.631336.
Train: 2018-08-01T00:23:37.350996: step 7065, loss 0.458916.
Train: 2018-08-01T00:23:37.522835: step 7066, loss 0.579687.
Train: 2018-08-01T00:23:37.679043: step 7067, loss 0.562405.
Train: 2018-08-01T00:23:37.835258: step 7068, loss 0.597089.
Train: 2018-08-01T00:23:37.991471: step 7069, loss 0.492996.
Train: 2018-08-01T00:23:38.147684: step 7070, loss 0.527649.
Test: 2018-08-01T00:23:38.616324: step 7070, loss 0.547836.
Train: 2018-08-01T00:23:38.772538: step 7071, loss 0.492749.
Train: 2018-08-01T00:23:38.944366: step 7072, loss 0.614833.
Train: 2018-08-01T00:23:39.100580: step 7073, loss 0.474959.
Train: 2018-08-01T00:23:39.256769: step 7074, loss 0.562453.
Train: 2018-08-01T00:23:39.412983: step 7075, loss 0.597637.
Train: 2018-08-01T00:23:39.569226: step 7076, loss 0.509638.
Train: 2018-08-01T00:23:39.741030: step 7077, loss 0.456596.
Train: 2018-08-01T00:23:39.897274: step 7078, loss 0.491684.
Train: 2018-08-01T00:23:40.053487: step 7079, loss 0.491441.
Train: 2018-08-01T00:23:40.209702: step 7080, loss 0.598286.
Test: 2018-08-01T00:23:40.693931: step 7080, loss 0.547614.
Train: 2018-08-01T00:23:40.865798: step 7081, loss 0.687992.
Train: 2018-08-01T00:23:41.022010: step 7082, loss 0.544694.
Train: 2018-08-01T00:23:41.178218: step 7083, loss 0.616477.
Train: 2018-08-01T00:23:41.350065: step 7084, loss 0.634426.
Train: 2018-08-01T00:23:41.506278: step 7085, loss 0.526767.
Train: 2018-08-01T00:23:41.662485: step 7086, loss 0.598445.
Train: 2018-08-01T00:23:41.818701: step 7087, loss 0.705741.
Train: 2018-08-01T00:23:41.990535: step 7088, loss 0.50907.
Train: 2018-08-01T00:23:42.146716: step 7089, loss 0.598132.
Train: 2018-08-01T00:23:42.302962: step 7090, loss 0.704468.
Test: 2018-08-01T00:23:42.771569: step 7090, loss 0.547704.
Train: 2018-08-01T00:23:42.943440: step 7091, loss 0.509511.
Train: 2018-08-01T00:23:43.115271: step 7092, loss 0.668062.
Train: 2018-08-01T00:23:43.271483: step 7093, loss 0.54493.
Train: 2018-08-01T00:23:43.427666: step 7094, loss 0.49266.
Train: 2018-08-01T00:23:43.583880: step 7095, loss 0.579811.
Train: 2018-08-01T00:23:43.740124: step 7096, loss 0.649132.
Train: 2018-08-01T00:23:43.896306: step 7097, loss 0.579679.
Train: 2018-08-01T00:23:44.052555: step 7098, loss 0.562397.
Train: 2018-08-01T00:23:44.208733: step 7099, loss 0.682468.
Train: 2018-08-01T00:23:44.364948: step 7100, loss 0.494124.
Test: 2018-08-01T00:23:44.833618: step 7100, loss 0.548159.
Train: 2018-08-01T00:23:45.548083: step 7101, loss 0.562404.
Train: 2018-08-01T00:23:45.704328: step 7102, loss 0.562411.
Train: 2018-08-01T00:23:45.860510: step 7103, loss 0.511677.
Train: 2018-08-01T00:23:46.016755: step 7104, loss 0.477988.
Train: 2018-08-01T00:23:46.172968: step 7105, loss 0.663742.
Train: 2018-08-01T00:23:46.344797: step 7106, loss 0.51185.
Train: 2018-08-01T00:23:46.500986: step 7107, loss 0.47818.
Train: 2018-08-01T00:23:46.657199: step 7108, loss 0.545563.
Train: 2018-08-01T00:23:46.813437: step 7109, loss 0.562424.
Train: 2018-08-01T00:23:46.969627: step 7110, loss 0.697641.
Test: 2018-08-01T00:23:47.438298: step 7110, loss 0.548286.
Train: 2018-08-01T00:23:47.594480: step 7111, loss 0.596192.
Train: 2018-08-01T00:23:47.750718: step 7112, loss 0.596148.
Train: 2018-08-01T00:23:47.922558: step 7113, loss 0.579266.
Train: 2018-08-01T00:23:48.078772: step 7114, loss 0.562445.
Train: 2018-08-01T00:23:48.234985: step 7115, loss 0.579224.
Train: 2018-08-01T00:23:48.391199: step 7116, loss 0.59595.
Train: 2018-08-01T00:23:48.563034: step 7117, loss 0.612609.
Train: 2018-08-01T00:23:48.719218: step 7118, loss 0.529142.
Train: 2018-08-01T00:23:48.891082: step 7119, loss 0.612434.
Train: 2018-08-01T00:23:49.047265: step 7120, loss 0.645566.
Test: 2018-08-01T00:23:49.500331: step 7120, loss 0.548668.
Train: 2018-08-01T00:23:49.672148: step 7121, loss 0.545975.
Train: 2018-08-01T00:23:49.828357: step 7122, loss 0.47996.
Train: 2018-08-01T00:23:49.984546: step 7123, loss 0.529545.
Train: 2018-08-01T00:23:50.156405: step 7124, loss 0.579066.
Train: 2018-08-01T00:23:50.312618: step 7125, loss 0.546052.
Train: 2018-08-01T00:23:50.468831: step 7126, loss 0.661629.
Train: 2018-08-01T00:23:50.640641: step 7127, loss 0.66152.
Train: 2018-08-01T00:23:50.796885: step 7128, loss 0.579039.
Train: 2018-08-01T00:23:50.953093: step 7129, loss 0.628249.
Train: 2018-08-01T00:23:51.124903: step 7130, loss 0.480854.
Test: 2018-08-01T00:23:51.593573: step 7130, loss 0.548976.
Train: 2018-08-01T00:23:51.765409: step 7131, loss 0.628002.
Train: 2018-08-01T00:23:51.921622: step 7132, loss 0.513771.
Train: 2018-08-01T00:23:52.093457: step 7133, loss 0.692993.
Train: 2018-08-01T00:23:52.249671: step 7134, loss 0.49775.
Train: 2018-08-01T00:23:52.421474: step 7135, loss 0.578957.
Train: 2018-08-01T00:23:52.577719: step 7136, loss 0.465529.
Train: 2018-08-01T00:23:52.733901: step 7137, loss 0.51409.
Train: 2018-08-01T00:23:52.921357: step 7138, loss 0.530229.
Train: 2018-08-01T00:23:53.077571: step 7139, loss 0.578974.
Train: 2018-08-01T00:23:53.233823: step 7140, loss 0.578985.
Test: 2018-08-01T00:23:53.686802: step 7140, loss 0.548967.
Train: 2018-08-01T00:23:53.843047: step 7141, loss 0.628024.
Train: 2018-08-01T00:23:54.030473: step 7142, loss 0.611704.
Train: 2018-08-01T00:23:54.186710: step 7143, loss 0.497243.
Train: 2018-08-01T00:23:54.342924: step 7144, loss 0.431674.
Train: 2018-08-01T00:23:54.499144: step 7145, loss 0.480473.
Train: 2018-08-01T00:23:54.655351: step 7146, loss 0.579063.
Train: 2018-08-01T00:23:54.827192: step 7147, loss 0.545964.
Train: 2018-08-01T00:23:54.983376: step 7148, loss 0.495974.
Train: 2018-08-01T00:23:55.155243: step 7149, loss 0.612604.
Train: 2018-08-01T00:23:55.311454: step 7150, loss 0.495376.
Test: 2018-08-01T00:23:55.780093: step 7150, loss 0.548331.
Train: 2018-08-01T00:23:55.936308: step 7151, loss 0.579275.
Train: 2018-08-01T00:23:56.108151: step 7152, loss 0.579323.
Train: 2018-08-01T00:23:56.264326: step 7153, loss 0.545456.
Train: 2018-08-01T00:23:56.420540: step 7154, loss 0.562404.
Train: 2018-08-01T00:23:56.592403: step 7155, loss 0.630617.
Train: 2018-08-01T00:23:56.748586: step 7156, loss 0.442843.
Train: 2018-08-01T00:23:56.904830: step 7157, loss 0.562396.
Train: 2018-08-01T00:23:57.061044: step 7158, loss 0.579578.
Train: 2018-08-01T00:23:57.264115: step 7159, loss 0.493512.
Train: 2018-08-01T00:23:57.420305: step 7160, loss 0.527852.
Test: 2018-08-01T00:23:57.888974: step 7160, loss 0.547895.
Train: 2018-08-01T00:23:58.045188: step 7161, loss 0.63173.
Train: 2018-08-01T00:23:58.217022: step 7162, loss 0.614501.
Train: 2018-08-01T00:23:58.373207: step 7163, loss 0.492903.
Train: 2018-08-01T00:23:58.545071: step 7164, loss 0.579828.
Train: 2018-08-01T00:23:58.701285: step 7165, loss 0.649576.
Train: 2018-08-01T00:23:58.857467: step 7166, loss 0.57985.
Train: 2018-08-01T00:23:59.013680: step 7167, loss 0.68435.
Train: 2018-08-01T00:23:59.169925: step 7168, loss 0.579793.
Train: 2018-08-01T00:23:59.310487: step 7169, loss 0.579745.
Train: 2018-08-01T00:23:59.497978: step 7170, loss 0.596993.
Test: 2018-08-01T00:23:59.966612: step 7170, loss 0.547956.
Train: 2018-08-01T00:24:00.122826: step 7171, loss 0.527903.
Train: 2018-08-01T00:24:00.294660: step 7172, loss 0.614038.
Train: 2018-08-01T00:24:00.435224: step 7173, loss 0.510887.
Train: 2018-08-01T00:24:00.622679: step 7174, loss 0.562396.
Train: 2018-08-01T00:24:00.763295: step 7175, loss 0.647992.
Train: 2018-08-01T00:24:00.935137: step 7176, loss 0.442869.
Train: 2018-08-01T00:24:01.091319: step 7177, loss 0.545331.
Train: 2018-08-01T00:24:01.247563: step 7178, loss 0.545333.
Train: 2018-08-01T00:24:01.403777: step 7179, loss 0.613605.
Train: 2018-08-01T00:24:01.559991: step 7180, loss 0.425933.
Test: 2018-08-01T00:24:02.044251: step 7180, loss 0.548091.
Train: 2018-08-01T00:24:02.200465: step 7181, loss 0.494058.
Train: 2018-08-01T00:24:02.356648: step 7182, loss 0.511014.
Train: 2018-08-01T00:24:02.497239: step 7183, loss 0.493681.
Train: 2018-08-01T00:24:02.653484: step 7184, loss 0.527913.
Train: 2018-08-01T00:24:02.840934: step 7185, loss 0.64895.
Train: 2018-08-01T00:24:02.997154: step 7186, loss 0.47568.
Train: 2018-08-01T00:24:03.153337: step 7187, loss 0.510216.
Train: 2018-08-01T00:24:03.309581: step 7188, loss 0.667207.
Train: 2018-08-01T00:24:03.465793: step 7189, loss 0.61491.
Train: 2018-08-01T00:24:03.637598: step 7190, loss 0.579942.
Test: 2018-08-01T00:24:04.106237: step 7190, loss 0.547784.
Train: 2018-08-01T00:24:04.278104: step 7191, loss 0.597452.
Train: 2018-08-01T00:24:04.434318: step 7192, loss 0.544942.
Train: 2018-08-01T00:24:04.590500: step 7193, loss 0.562439.
Train: 2018-08-01T00:24:04.746744: step 7194, loss 0.57993.
Train: 2018-08-01T00:24:04.918548: step 7195, loss 0.719783.
Train: 2018-08-01T00:24:05.074762: step 7196, loss 0.527557.
Train: 2018-08-01T00:24:05.230976: step 7197, loss 0.54502.
Train: 2018-08-01T00:24:05.402837: step 7198, loss 0.545044.
Train: 2018-08-01T00:24:05.559047: step 7199, loss 0.527717.
Train: 2018-08-01T00:24:05.715236: step 7200, loss 0.510405.
Test: 2018-08-01T00:24:06.183908: step 7200, loss 0.547891.
Train: 2018-08-01T00:24:06.902490: step 7201, loss 0.545072.
Train: 2018-08-01T00:24:07.074294: step 7202, loss 0.66646.
Train: 2018-08-01T00:24:07.230537: step 7203, loss 0.545086.
Train: 2018-08-01T00:24:07.386751: step 7204, loss 0.59701.
Train: 2018-08-01T00:24:07.542973: step 7205, loss 0.61424.
Train: 2018-08-01T00:24:07.699147: step 7206, loss 0.476178.
Train: 2018-08-01T00:24:07.855390: step 7207, loss 0.6141.
Train: 2018-08-01T00:24:08.011574: step 7208, loss 0.631243.
Train: 2018-08-01T00:24:08.167826: step 7209, loss 0.528049.
Train: 2018-08-01T00:24:08.339622: step 7210, loss 0.5281.
Test: 2018-08-01T00:24:08.808293: step 7210, loss 0.548048.
Train: 2018-08-01T00:24:08.980097: step 7211, loss 0.44246.
Train: 2018-08-01T00:24:09.136340: step 7212, loss 0.579548.
Train: 2018-08-01T00:24:09.308184: step 7213, loss 0.562395.
Train: 2018-08-01T00:24:09.464358: step 7214, loss 0.66545.
Train: 2018-08-01T00:24:09.604950: step 7215, loss 0.545237.
Train: 2018-08-01T00:24:09.761164: step 7216, loss 0.61384.
Train: 2018-08-01T00:24:09.917378: step 7217, loss 0.596646.
Train: 2018-08-01T00:24:10.089212: step 7218, loss 0.579492.
Train: 2018-08-01T00:24:10.245456: step 7219, loss 0.596528.
Train: 2018-08-01T00:24:10.401640: step 7220, loss 0.545373.
Test: 2018-08-01T00:24:10.885901: step 7220, loss 0.548169.
Train: 2018-08-01T00:24:11.042146: step 7221, loss 0.579405.
Train: 2018-08-01T00:24:11.198328: step 7222, loss 0.511495.
Train: 2018-08-01T00:24:11.354541: step 7223, loss 0.511533.
Train: 2018-08-01T00:24:11.526375: step 7224, loss 0.580503.
Train: 2018-08-01T00:24:11.666968: step 7225, loss 0.613294.
Train: 2018-08-01T00:24:11.838832: step 7226, loss 0.44378.
Train: 2018-08-01T00:24:11.995017: step 7227, loss 0.494541.
Train: 2018-08-01T00:24:12.151230: step 7228, loss 0.545401.
Train: 2018-08-01T00:24:12.307442: step 7229, loss 0.630564.
Train: 2018-08-01T00:24:12.463656: step 7230, loss 0.562399.
Test: 2018-08-01T00:24:12.932327: step 7230, loss 0.548102.
Train: 2018-08-01T00:24:13.088510: step 7231, loss 0.630687.
Train: 2018-08-01T00:24:13.291588: step 7232, loss 0.494126.
Train: 2018-08-01T00:24:13.447801: step 7233, loss 0.545315.
Train: 2018-08-01T00:24:13.604044: step 7234, loss 0.511095.
Train: 2018-08-01T00:24:13.775874: step 7235, loss 0.579526.
Train: 2018-08-01T00:24:13.932063: step 7236, loss 0.493786.
Train: 2018-08-01T00:24:14.088301: step 7237, loss 0.596777.
Train: 2018-08-01T00:24:14.244514: step 7238, loss 0.545181.
Train: 2018-08-01T00:24:14.400733: step 7239, loss 0.545156.
Train: 2018-08-01T00:24:14.556915: step 7240, loss 0.545129.
Test: 2018-08-01T00:24:15.041207: step 7240, loss 0.547916.
Train: 2018-08-01T00:24:15.197422: step 7241, loss 0.458599.
Train: 2018-08-01T00:24:15.353605: step 7242, loss 0.545057.
Train: 2018-08-01T00:24:15.509848: step 7243, loss 0.649446.
Train: 2018-08-01T00:24:15.666062: step 7244, loss 0.666995.
Train: 2018-08-01T00:24:15.822245: step 7245, loss 0.475314.
Train: 2018-08-01T00:24:15.994110: step 7246, loss 0.649609.
Train: 2018-08-01T00:24:16.150323: step 7247, loss 0.544996.
Train: 2018-08-01T00:24:16.306506: step 7248, loss 0.63211.
Train: 2018-08-01T00:24:16.478372: step 7249, loss 0.614614.
Train: 2018-08-01T00:24:16.634585: step 7250, loss 0.527685.
Test: 2018-08-01T00:24:17.103195: step 7250, loss 0.547888.
Train: 2018-08-01T00:24:17.259409: step 7251, loss 0.510389.
Train: 2018-08-01T00:24:17.415622: step 7252, loss 0.701057.
Train: 2018-08-01T00:24:17.571866: step 7253, loss 0.683414.
Train: 2018-08-01T00:24:17.728048: step 7254, loss 0.648478.
Train: 2018-08-01T00:24:17.884287: step 7255, loss 0.476746.
Train: 2018-08-01T00:24:18.056096: step 7256, loss 0.545324.
Train: 2018-08-01T00:24:18.212309: step 7257, loss 0.511313.
Train: 2018-08-01T00:24:18.368523: step 7258, loss 0.630415.
Train: 2018-08-01T00:24:18.524736: step 7259, loss 0.579371.
Train: 2018-08-01T00:24:18.680981: step 7260, loss 0.460897.
Test: 2018-08-01T00:24:19.133994: step 7260, loss 0.548258.
Train: 2018-08-01T00:24:19.305835: step 7261, loss 0.663882.
Train: 2018-08-01T00:24:19.462047: step 7262, loss 0.545549.
Train: 2018-08-01T00:24:19.618230: step 7263, loss 0.410774.
Train: 2018-08-01T00:24:19.774471: step 7264, loss 0.579296.
Train: 2018-08-01T00:24:19.946304: step 7265, loss 0.494897.
Train: 2018-08-01T00:24:20.102523: step 7266, loss 0.663891.
Train: 2018-08-01T00:24:20.289975: step 7267, loss 0.460937.
Train: 2018-08-01T00:24:20.446190: step 7268, loss 0.460759.
Train: 2018-08-01T00:24:20.602375: step 7269, loss 0.562405.
Train: 2018-08-01T00:24:20.758589: step 7270, loss 0.579444.
Test: 2018-08-01T00:24:21.242881: step 7270, loss 0.548092.
Train: 2018-08-01T00:24:21.414686: step 7271, loss 0.511148.
Train: 2018-08-01T00:24:21.570898: step 7272, loss 0.510998.
Train: 2018-08-01T00:24:21.727112: step 7273, loss 0.493636.
Train: 2018-08-01T00:24:21.867735: step 7274, loss 0.54514.
Train: 2018-08-01T00:24:22.023951: step 7275, loss 0.614385.
Train: 2018-08-01T00:24:22.180162: step 7276, loss 0.492925.
Train: 2018-08-01T00:24:22.351996: step 7277, loss 0.544994.
Train: 2018-08-01T00:24:22.508206: step 7278, loss 0.562437.
Train: 2018-08-01T00:24:22.680015: step 7279, loss 0.615059.
Train: 2018-08-01T00:24:22.836257: step 7280, loss 0.56246.
Test: 2018-08-01T00:24:23.304899: step 7280, loss 0.547737.
Train: 2018-08-01T00:24:23.523567: step 7281, loss 0.597651.
Train: 2018-08-01T00:24:23.679811: step 7282, loss 0.509659.
Train: 2018-08-01T00:24:23.835994: step 7283, loss 0.615362.
Train: 2018-08-01T00:24:23.992236: step 7284, loss 0.527216.
Train: 2018-08-01T00:24:24.148422: step 7285, loss 0.544841.
Train: 2018-08-01T00:24:24.304634: step 7286, loss 0.703773.
Train: 2018-08-01T00:24:24.460882: step 7287, loss 0.597754.
Train: 2018-08-01T00:24:24.648339: step 7288, loss 0.562472.
Train: 2018-08-01T00:24:24.804552: step 7289, loss 0.544889.
Train: 2018-08-01T00:24:24.960760: step 7290, loss 0.632644.
Test: 2018-08-01T00:24:25.429406: step 7290, loss 0.547783.
Train: 2018-08-01T00:24:25.585583: step 7291, loss 0.562442.
Train: 2018-08-01T00:24:25.788690: step 7292, loss 0.510029.
Train: 2018-08-01T00:24:25.944874: step 7293, loss 0.579873.
Train: 2018-08-01T00:24:26.085497: step 7294, loss 0.632102.
Train: 2018-08-01T00:24:26.241711: step 7295, loss 0.527657.
Train: 2018-08-01T00:24:26.413545: step 7296, loss 0.614457.
Train: 2018-08-01T00:24:26.569729: step 7297, loss 0.579713.
Train: 2018-08-01T00:24:26.725941: step 7298, loss 0.545133.
Train: 2018-08-01T00:24:26.882155: step 7299, loss 0.596866.
Train: 2018-08-01T00:24:27.038398: step 7300, loss 0.545201.
Test: 2018-08-01T00:24:27.507038: step 7300, loss 0.548022.
Train: 2018-08-01T00:24:28.194378: step 7301, loss 0.545231.
Train: 2018-08-01T00:24:28.350591: step 7302, loss 0.528113.
Train: 2018-08-01T00:24:28.522426: step 7303, loss 0.528138.
Train: 2018-08-01T00:24:28.678640: step 7304, loss 0.442505.
Train: 2018-08-01T00:24:28.834854: step 7305, loss 0.562395.
Train: 2018-08-01T00:24:28.991036: step 7306, loss 0.648314.
Train: 2018-08-01T00:24:29.162870: step 7307, loss 0.596766.
Train: 2018-08-01T00:24:29.319110: step 7308, loss 0.596751.
Train: 2018-08-01T00:24:29.475298: step 7309, loss 0.493748.
Train: 2018-08-01T00:24:29.631541: step 7310, loss 0.613892.
Test: 2018-08-01T00:24:30.115798: step 7310, loss 0.54803.
Train: 2018-08-01T00:24:30.271987: step 7311, loss 0.596706.
Train: 2018-08-01T00:24:30.412603: step 7312, loss 0.476708.
Train: 2018-08-01T00:24:30.584443: step 7313, loss 0.562395.
Train: 2018-08-01T00:24:30.740657: step 7314, loss 0.648141.
Train: 2018-08-01T00:24:30.896871: step 7315, loss 0.596659.
Train: 2018-08-01T00:24:31.068699: step 7316, loss 0.613719.
Train: 2018-08-01T00:24:31.224919: step 7317, loss 0.545326.
Train: 2018-08-01T00:24:31.381101: step 7318, loss 0.647628.
Train: 2018-08-01T00:24:31.537340: step 7319, loss 0.681401.
Train: 2018-08-01T00:24:31.693552: step 7320, loss 0.443924.
Test: 2018-08-01T00:24:32.162167: step 7320, loss 0.548275.
Train: 2018-08-01T00:24:32.334028: step 7321, loss 0.545527.
Train: 2018-08-01T00:24:32.490216: step 7322, loss 0.562427.
Train: 2018-08-01T00:24:32.646460: step 7323, loss 0.545582.
Train: 2018-08-01T00:24:32.802679: step 7324, loss 0.562435.
Train: 2018-08-01T00:24:32.958856: step 7325, loss 0.562438.
Train: 2018-08-01T00:24:33.115095: step 7326, loss 0.528806.
Train: 2018-08-01T00:24:33.271314: step 7327, loss 0.54562.
Train: 2018-08-01T00:24:33.443118: step 7328, loss 0.461476.
Train: 2018-08-01T00:24:33.583710: step 7329, loss 0.613014.
Train: 2018-08-01T00:24:33.739923: step 7330, loss 0.478021.
Test: 2018-08-01T00:24:34.208563: step 7330, loss 0.548248.
Train: 2018-08-01T00:24:34.380400: step 7331, loss 0.545496.
Train: 2018-08-01T00:24:34.536612: step 7332, loss 0.63026.
Train: 2018-08-01T00:24:34.692825: step 7333, loss 0.562407.
Train: 2018-08-01T00:24:34.849070: step 7334, loss 0.579406.
Train: 2018-08-01T00:24:35.020904: step 7335, loss 0.545389.
Train: 2018-08-01T00:24:35.177088: step 7336, loss 0.613495.
Train: 2018-08-01T00:24:35.333300: step 7337, loss 0.545368.
Train: 2018-08-01T00:24:35.489544: step 7338, loss 0.59648.
Train: 2018-08-01T00:24:35.661379: step 7339, loss 0.545363.
Train: 2018-08-01T00:24:35.817563: step 7340, loss 0.596481.
Test: 2018-08-01T00:24:36.286203: step 7340, loss 0.548137.
Train: 2018-08-01T00:24:36.442417: step 7341, loss 0.511299.
Train: 2018-08-01T00:24:36.598630: step 7342, loss 0.545358.
Train: 2018-08-01T00:24:36.786123: step 7343, loss 0.579454.
Train: 2018-08-01T00:24:36.942300: step 7344, loss 0.596522.
Train: 2018-08-01T00:24:37.098512: step 7345, loss 0.528281.
Train: 2018-08-01T00:24:37.254727: step 7346, loss 0.511199.
Train: 2018-08-01T00:24:37.410969: step 7347, loss 0.562397.
Train: 2018-08-01T00:24:37.582806: step 7348, loss 0.545291.
Train: 2018-08-01T00:24:37.738989: step 7349, loss 0.562396.
Train: 2018-08-01T00:24:37.910822: step 7350, loss 0.528104.
Test: 2018-08-01T00:24:38.379493: step 7350, loss 0.548016.
Train: 2018-08-01T00:24:38.551333: step 7351, loss 0.425021.
Train: 2018-08-01T00:24:38.707541: step 7352, loss 0.493473.
Train: 2018-08-01T00:24:38.863755: step 7353, loss 0.579706.
Train: 2018-08-01T00:24:39.035589: step 7354, loss 0.562411.
Train: 2018-08-01T00:24:39.191803: step 7355, loss 0.562421.
Train: 2018-08-01T00:24:39.348017: step 7356, loss 0.562431.
Train: 2018-08-01T00:24:39.504224: step 7357, loss 0.649944.
Train: 2018-08-01T00:24:39.660412: step 7358, loss 0.562444.
Train: 2018-08-01T00:24:39.816625: step 7359, loss 0.527399.
Train: 2018-08-01T00:24:39.972840: step 7360, loss 0.579993.
Test: 2018-08-01T00:24:40.457130: step 7360, loss 0.547758.
Train: 2018-08-01T00:24:40.628966: step 7361, loss 0.439597.
Train: 2018-08-01T00:24:40.785150: step 7362, loss 0.544877.
Train: 2018-08-01T00:24:40.941363: step 7363, loss 0.615363.
Train: 2018-08-01T00:24:41.097576: step 7364, loss 0.509548.
Train: 2018-08-01T00:24:41.253789: step 7365, loss 0.6332.
Train: 2018-08-01T00:24:41.410034: step 7366, loss 0.580182.
Train: 2018-08-01T00:24:41.566217: step 7367, loss 0.544819.
Train: 2018-08-01T00:24:41.722460: step 7368, loss 0.562501.
Train: 2018-08-01T00:24:41.878673: step 7369, loss 0.633235.
Train: 2018-08-01T00:24:42.034857: step 7370, loss 0.615485.
Test: 2018-08-01T00:24:42.503497: step 7370, loss 0.547718.
Train: 2018-08-01T00:24:42.659740: step 7371, loss 0.544851.
Train: 2018-08-01T00:24:42.815950: step 7372, loss 0.738513.
Train: 2018-08-01T00:24:42.987784: step 7373, loss 0.56245.
Train: 2018-08-01T00:24:43.144002: step 7374, loss 0.440147.
Train: 2018-08-01T00:24:43.300218: step 7375, loss 0.562427.
Train: 2018-08-01T00:24:43.456398: step 7376, loss 0.510174.
Train: 2018-08-01T00:24:43.612613: step 7377, loss 0.579824.
Train: 2018-08-01T00:24:43.784477: step 7378, loss 0.597196.
Train: 2018-08-01T00:24:43.940691: step 7379, loss 0.614512.
Train: 2018-08-01T00:24:44.096904: step 7380, loss 0.579738.
Test: 2018-08-01T00:24:44.565544: step 7380, loss 0.54792.
Train: 2018-08-01T00:24:44.737350: step 7381, loss 0.596992.
Train: 2018-08-01T00:24:44.909213: step 7382, loss 0.545147.
Train: 2018-08-01T00:24:45.065398: step 7383, loss 0.476307.
Train: 2018-08-01T00:24:45.221640: step 7384, loss 0.476349.
Train: 2018-08-01T00:24:45.377854: step 7385, loss 0.527949.
Train: 2018-08-01T00:24:45.549695: step 7386, loss 0.631382.
Train: 2018-08-01T00:24:45.705901: step 7387, loss 0.579646.
Train: 2018-08-01T00:24:45.862116: step 7388, loss 0.61413.
Train: 2018-08-01T00:24:46.002677: step 7389, loss 0.562397.
Train: 2018-08-01T00:24:46.158921: step 7390, loss 0.631242.
Test: 2018-08-01T00:24:46.643182: step 7390, loss 0.54801.
Train: 2018-08-01T00:24:46.799397: step 7391, loss 0.579575.
Train: 2018-08-01T00:24:46.955609: step 7392, loss 0.596687.
Train: 2018-08-01T00:24:47.111792: step 7393, loss 0.699253.
Train: 2018-08-01T00:24:47.268036: step 7394, loss 0.562401.
Train: 2018-08-01T00:24:47.424219: step 7395, loss 0.562408.
Train: 2018-08-01T00:24:47.580432: step 7396, loss 0.528583.
Train: 2018-08-01T00:24:47.752267: step 7397, loss 0.494921.
Train: 2018-08-01T00:24:47.892861: step 7398, loss 0.680438.
Train: 2018-08-01T00:24:48.049110: step 7399, loss 0.528817.
Train: 2018-08-01T00:24:48.205311: step 7400, loss 0.646352.
Test: 2018-08-01T00:24:48.689578: step 7400, loss 0.548455.
Train: 2018-08-01T00:24:49.361265: step 7401, loss 0.679582.
Train: 2018-08-01T00:24:49.533131: step 7402, loss 0.662432.
Train: 2018-08-01T00:24:49.689315: step 7403, loss 0.66192.
Train: 2018-08-01T00:24:49.861175: step 7404, loss 0.628415.
Train: 2018-08-01T00:24:50.017393: step 7405, loss 0.611688.
Train: 2018-08-01T00:24:50.173607: step 7406, loss 0.481553.
Train: 2018-08-01T00:24:50.329790: step 7407, loss 0.546622.
Train: 2018-08-01T00:24:50.501623: step 7408, loss 0.546728.
Train: 2018-08-01T00:24:50.657838: step 7409, loss 0.546812.
Train: 2018-08-01T00:24:50.814051: step 7410, loss 0.53085.
Test: 2018-08-01T00:24:51.267099: step 7410, loss 0.549506.
Train: 2018-08-01T00:24:51.423283: step 7411, loss 0.530897.
Train: 2018-08-01T00:24:51.579527: step 7412, loss 0.562912.
Train: 2018-08-01T00:24:51.751362: step 7413, loss 0.546902.
Train: 2018-08-01T00:24:51.907578: step 7414, loss 0.610954.
Train: 2018-08-01T00:24:52.063757: step 7415, loss 0.546881.
Train: 2018-08-01T00:24:52.220001: step 7416, loss 0.546865.
Train: 2018-08-01T00:24:52.376184: step 7417, loss 0.562878.
Train: 2018-08-01T00:24:52.532398: step 7418, loss 0.530739.
Train: 2018-08-01T00:24:52.688642: step 7419, loss 0.546746.
Train: 2018-08-01T00:24:52.844850: step 7420, loss 0.498306.
Test: 2018-08-01T00:24:53.329086: step 7420, loss 0.54922.
Train: 2018-08-01T00:24:53.485300: step 7421, loss 0.546589.
Train: 2018-08-01T00:24:53.641544: step 7422, loss 0.497791.
Train: 2018-08-01T00:24:53.797758: step 7423, loss 0.46485.
Train: 2018-08-01T00:24:53.953940: step 7424, loss 0.62821.
Train: 2018-08-01T00:24:54.125805: step 7425, loss 0.56258.
Train: 2018-08-01T00:24:54.297610: step 7426, loss 0.595609.
Train: 2018-08-01T00:24:54.438232: step 7427, loss 0.678601.
Train: 2018-08-01T00:24:54.610067: step 7428, loss 0.562515.
Train: 2018-08-01T00:24:54.766280: step 7429, loss 0.545892.
Train: 2018-08-01T00:24:54.922495: step 7430, loss 0.529223.
Test: 2018-08-01T00:24:55.391133: step 7430, loss 0.54853.
Train: 2018-08-01T00:24:55.547317: step 7431, loss 0.529151.
Train: 2018-08-01T00:24:55.703530: step 7432, loss 0.512355.
Train: 2018-08-01T00:24:55.859745: step 7433, loss 0.562458.
Train: 2018-08-01T00:24:56.015958: step 7434, loss 0.461639.
Train: 2018-08-01T00:24:56.172202: step 7435, loss 0.646776.
Train: 2018-08-01T00:24:56.328414: step 7436, loss 0.545508.
Train: 2018-08-01T00:24:56.515865: step 7437, loss 0.562411.
Train: 2018-08-01T00:24:56.672053: step 7438, loss 0.528424.
Train: 2018-08-01T00:24:56.812677: step 7439, loss 0.630542.
Train: 2018-08-01T00:24:56.968889: step 7440, loss 0.562399.
Test: 2018-08-01T00:24:57.437530: step 7440, loss 0.548097.
Train: 2018-08-01T00:24:57.624980: step 7441, loss 0.528242.
Train: 2018-08-01T00:24:57.781168: step 7442, loss 0.511079.
Train: 2018-08-01T00:24:57.937382: step 7443, loss 0.545251.
Train: 2018-08-01T00:24:58.093595: step 7444, loss 0.562396.
Train: 2018-08-01T00:24:58.249809: step 7445, loss 0.545178.
Train: 2018-08-01T00:24:58.406023: step 7446, loss 0.545145.
Train: 2018-08-01T00:24:58.562236: step 7447, loss 0.527821.
Train: 2018-08-01T00:24:58.734095: step 7448, loss 0.562407.
Train: 2018-08-01T00:24:58.890285: step 7449, loss 0.527675.
Train: 2018-08-01T00:24:59.046529: step 7450, loss 0.61465.
Test: 2018-08-01T00:24:59.515168: step 7450, loss 0.547827.
Train: 2018-08-01T00:24:59.702629: step 7451, loss 0.667022.
Train: 2018-08-01T00:24:59.858807: step 7452, loss 0.614699.
Train: 2018-08-01T00:25:00.015051: step 7453, loss 0.579823.
Train: 2018-08-01T00:25:00.171265: step 7454, loss 0.579795.
Train: 2018-08-01T00:25:00.343094: step 7455, loss 0.545057.
Train: 2018-08-01T00:25:00.499282: step 7456, loss 0.57974.
Train: 2018-08-01T00:25:00.655495: step 7457, loss 0.510478.
Train: 2018-08-01T00:25:00.827362: step 7458, loss 0.579704.
Train: 2018-08-01T00:25:00.983568: step 7459, loss 0.57969.
Train: 2018-08-01T00:25:01.139782: step 7460, loss 0.493313.
Test: 2018-08-01T00:25:01.624049: step 7460, loss 0.547935.
Train: 2018-08-01T00:25:01.780233: step 7461, loss 0.493301.
Train: 2018-08-01T00:25:01.936446: step 7462, loss 0.441337.
Train: 2018-08-01T00:25:02.092660: step 7463, loss 0.52772.
Train: 2018-08-01T00:25:02.248903: step 7464, loss 0.632006.
Train: 2018-08-01T00:25:02.405116: step 7465, loss 0.579849.
Train: 2018-08-01T00:25:02.561330: step 7466, loss 0.562427.
Train: 2018-08-01T00:25:02.717514: step 7467, loss 0.649747.
Train: 2018-08-01T00:25:02.873754: step 7468, loss 0.527519.
Train: 2018-08-01T00:25:03.045562: step 7469, loss 0.614798.
Train: 2018-08-01T00:25:03.201805: step 7470, loss 0.684522.
Test: 2018-08-01T00:25:03.670446: step 7470, loss 0.547849.
Train: 2018-08-01T00:25:03.842250: step 7471, loss 0.632007.
Train: 2018-08-01T00:25:03.998488: step 7472, loss 0.475716.
Train: 2018-08-01T00:25:04.154676: step 7473, loss 0.52779.
Train: 2018-08-01T00:25:04.310889: step 7474, loss 0.562402.
Train: 2018-08-01T00:25:04.467133: step 7475, loss 0.5624.
Train: 2018-08-01T00:25:04.623317: step 7476, loss 0.562399.
Train: 2018-08-01T00:25:04.779560: step 7477, loss 0.441741.
Train: 2018-08-01T00:25:04.935774: step 7478, loss 0.545145.
Train: 2018-08-01T00:25:05.091987: step 7479, loss 0.631495.
Train: 2018-08-01T00:25:05.263817: step 7480, loss 0.545128.
Test: 2018-08-01T00:25:05.732462: step 7480, loss 0.547934.
Train: 2018-08-01T00:25:05.904297: step 7481, loss 0.493295.
Train: 2018-08-01T00:25:06.060511: step 7482, loss 0.596997.
Train: 2018-08-01T00:25:06.216694: step 7483, loss 0.475873.
Train: 2018-08-01T00:25:06.388564: step 7484, loss 0.545071.
Train: 2018-08-01T00:25:06.560401: step 7485, loss 0.597147.
Train: 2018-08-01T00:25:06.716606: step 7486, loss 0.579801.
Train: 2018-08-01T00:25:06.872790: step 7487, loss 0.545021.
Train: 2018-08-01T00:25:07.029004: step 7488, loss 0.597241.
Train: 2018-08-01T00:25:07.185217: step 7489, loss 0.527595.
Train: 2018-08-01T00:25:07.341432: step 7490, loss 0.579846.
Test: 2018-08-01T00:25:07.810101: step 7490, loss 0.54783.
Train: 2018-08-01T00:25:07.966284: step 7491, loss 0.492715.
Train: 2018-08-01T00:25:08.138150: step 7492, loss 0.510085.
Train: 2018-08-01T00:25:08.294357: step 7493, loss 0.597392.
Train: 2018-08-01T00:25:08.450584: step 7494, loss 0.474957.
Train: 2018-08-01T00:25:08.622410: step 7495, loss 0.492315.
Train: 2018-08-01T00:25:08.778618: step 7496, loss 0.474545.
Train: 2018-08-01T00:25:08.934838: step 7497, loss 0.509537.
Train: 2018-08-01T00:25:09.091020: step 7498, loss 0.633405.
Train: 2018-08-01T00:25:09.247264: step 7499, loss 0.562537.
Train: 2018-08-01T00:25:09.403478: step 7500, loss 0.526947.
Test: 2018-08-01T00:25:09.887740: step 7500, loss 0.547633.
Train: 2018-08-01T00:25:10.575078: step 7501, loss 0.616111.
Train: 2018-08-01T00:25:10.731262: step 7502, loss 0.580453.
Train: 2018-08-01T00:25:10.887506: step 7503, loss 0.526838.
Train: 2018-08-01T00:25:11.043713: step 7504, loss 0.562603.
Train: 2018-08-01T00:25:11.199931: step 7505, loss 0.687968.
Train: 2018-08-01T00:25:11.356116: step 7506, loss 0.544712.
Train: 2018-08-01T00:25:11.512329: step 7507, loss 0.634059.
Train: 2018-08-01T00:25:11.668573: step 7508, loss 0.491245.
Train: 2018-08-01T00:25:11.840377: step 7509, loss 0.491306.
Train: 2018-08-01T00:25:11.980969: step 7510, loss 0.56256.
Test: 2018-08-01T00:25:12.465260: step 7510, loss 0.547644.
Train: 2018-08-01T00:25:12.621475: step 7511, loss 0.544748.
Train: 2018-08-01T00:25:12.777688: step 7512, loss 0.580371.
Train: 2018-08-01T00:25:12.933907: step 7513, loss 0.705.
Train: 2018-08-01T00:25:13.090114: step 7514, loss 0.562535.
Train: 2018-08-01T00:25:13.246329: step 7515, loss 0.562517.
Train: 2018-08-01T00:25:13.402511: step 7516, loss 0.54482.
Train: 2018-08-01T00:25:13.558724: step 7517, loss 0.491897.
Train: 2018-08-01T00:25:13.714938: step 7518, loss 0.439042.
Train: 2018-08-01T00:25:13.871181: step 7519, loss 0.597794.
Train: 2018-08-01T00:25:14.027364: step 7520, loss 0.580149.
Test: 2018-08-01T00:25:14.496004: step 7520, loss 0.547706.
Train: 2018-08-01T00:25:14.667839: step 7521, loss 0.580147.
Train: 2018-08-01T00:25:14.824052: step 7522, loss 0.580137.
Train: 2018-08-01T00:25:14.995887: step 7523, loss 0.562483.
Train: 2018-08-01T00:25:15.167748: step 7524, loss 0.474363.
Train: 2018-08-01T00:25:15.323936: step 7525, loss 0.637712.
Train: 2018-08-01T00:25:15.480149: step 7526, loss 0.527238.
Train: 2018-08-01T00:25:15.652014: step 7527, loss 0.650553.
Train: 2018-08-01T00:25:15.808198: step 7528, loss 0.562466.
Train: 2018-08-01T00:25:15.964412: step 7529, loss 0.544897.
Train: 2018-08-01T00:25:16.120626: step 7530, loss 0.650155.
Test: 2018-08-01T00:25:16.604910: step 7530, loss 0.547787.
Train: 2018-08-01T00:25:16.761100: step 7531, loss 0.492447.
Train: 2018-08-01T00:25:16.917344: step 7532, loss 0.597388.
Train: 2018-08-01T00:25:17.073556: step 7533, loss 0.47519.
Train: 2018-08-01T00:25:17.229741: step 7534, loss 0.544984.
Train: 2018-08-01T00:25:17.385953: step 7535, loss 0.544985.
Train: 2018-08-01T00:25:17.542191: step 7536, loss 0.527538.
Train: 2018-08-01T00:25:17.714031: step 7537, loss 0.667159.
Train: 2018-08-01T00:25:17.870245: step 7538, loss 0.562425.
Train: 2018-08-01T00:25:18.026458: step 7539, loss 0.666933.
Train: 2018-08-01T00:25:18.182672: step 7540, loss 0.562414.
Test: 2018-08-01T00:25:18.651281: step 7540, loss 0.547892.
Train: 2018-08-01T00:25:18.807520: step 7541, loss 0.614411.
Train: 2018-08-01T00:25:18.963739: step 7542, loss 0.614255.
Train: 2018-08-01T00:25:19.119922: step 7543, loss 0.545172.
Train: 2018-08-01T00:25:19.291757: step 7544, loss 0.562396.
Train: 2018-08-01T00:25:19.447987: step 7545, loss 0.596659.
Train: 2018-08-01T00:25:19.604222: step 7546, loss 0.57948.
Train: 2018-08-01T00:25:19.760422: step 7547, loss 0.630541.
Train: 2018-08-01T00:25:19.916641: step 7548, loss 0.52846.
Train: 2018-08-01T00:25:20.072854: step 7549, loss 0.680916.
Train: 2018-08-01T00:25:20.229067: step 7550, loss 0.495.
Test: 2018-08-01T00:25:20.697708: step 7550, loss 0.548363.
Train: 2018-08-01T00:25:20.853921: step 7551, loss 0.713751.
Train: 2018-08-01T00:25:21.010104: step 7552, loss 0.562465.
Train: 2018-08-01T00:25:21.166317: step 7553, loss 0.712449.
Train: 2018-08-01T00:25:21.338153: step 7554, loss 0.579093.
Train: 2018-08-01T00:25:21.494396: step 7555, loss 0.611979.
Train: 2018-08-01T00:25:21.666201: step 7556, loss 0.464411.
Train: 2018-08-01T00:25:21.822444: step 7557, loss 0.562671.
Train: 2018-08-01T00:25:21.978658: step 7558, loss 0.562703.
Train: 2018-08-01T00:25:22.134871: step 7559, loss 0.611411.
Train: 2018-08-01T00:25:22.291055: step 7560, loss 0.578946.
Test: 2018-08-01T00:25:22.775346: step 7560, loss 0.549285.
Train: 2018-08-01T00:25:22.931555: step 7561, loss 0.611212.
Train: 2018-08-01T00:25:23.087773: step 7562, loss 0.595017.
Train: 2018-08-01T00:25:23.243956: step 7563, loss 0.611002.
Train: 2018-08-01T00:25:23.400200: step 7564, loss 0.562928.
Train: 2018-08-01T00:25:23.556384: step 7565, loss 0.547025.
Train: 2018-08-01T00:25:23.712597: step 7566, loss 0.515261.
Train: 2018-08-01T00:25:23.884432: step 7567, loss 0.435788.
Train: 2018-08-01T00:25:24.040645: step 7568, loss 0.483308.
Train: 2018-08-01T00:25:24.212513: step 7569, loss 0.51496.
Train: 2018-08-01T00:25:24.368693: step 7570, loss 0.562867.
Test: 2018-08-01T00:25:24.837363: step 7570, loss 0.549315.
Train: 2018-08-01T00:25:25.024813: step 7571, loss 0.611173.
Train: 2018-08-01T00:25:25.181003: step 7572, loss 0.546607.
Train: 2018-08-01T00:25:25.321596: step 7573, loss 0.643831.
Train: 2018-08-01T00:25:25.477844: step 7574, loss 0.481489.
Train: 2018-08-01T00:25:25.634052: step 7575, loss 0.578978.
Train: 2018-08-01T00:25:25.790235: step 7576, loss 0.415607.
Train: 2018-08-01T00:25:25.946479: step 7577, loss 0.529764.
Train: 2018-08-01T00:25:26.133905: step 7578, loss 0.546054.
Train: 2018-08-01T00:25:26.290149: step 7579, loss 0.628876.
Train: 2018-08-01T00:25:26.446332: step 7580, loss 0.512551.
Test: 2018-08-01T00:25:26.915002: step 7580, loss 0.548472.
Train: 2018-08-01T00:25:27.086836: step 7581, loss 0.545754.
Train: 2018-08-01T00:25:27.243019: step 7582, loss 0.528881.
Train: 2018-08-01T00:25:27.399233: step 7583, loss 0.511865.
Train: 2018-08-01T00:25:27.555447: step 7584, loss 0.562415.
Train: 2018-08-01T00:25:27.711660: step 7585, loss 0.613419.
Train: 2018-08-01T00:25:27.867874: step 7586, loss 0.494174.
Train: 2018-08-01T00:25:28.024113: step 7587, loss 0.493913.
Train: 2018-08-01T00:25:28.195957: step 7588, loss 0.510806.
Train: 2018-08-01T00:25:28.352135: step 7589, loss 0.493287.
Train: 2018-08-01T00:25:28.508348: step 7590, loss 0.597152.
Test: 2018-08-01T00:25:28.977019: step 7590, loss 0.547821.
Train: 2018-08-01T00:25:29.133232: step 7591, loss 0.510102.
Train: 2018-08-01T00:25:29.289416: step 7592, loss 0.66756.
Train: 2018-08-01T00:25:29.445665: step 7593, loss 0.597579.
Train: 2018-08-01T00:25:29.601873: step 7594, loss 0.562467.
Train: 2018-08-01T00:25:29.773678: step 7595, loss 0.544863.
Train: 2018-08-01T00:25:29.914294: step 7596, loss 0.580117.
Train: 2018-08-01T00:25:30.086104: step 7597, loss 0.597787.
Train: 2018-08-01T00:25:30.242348: step 7598, loss 0.509532.
Train: 2018-08-01T00:25:30.398532: step 7599, loss 0.491827.
Train: 2018-08-01T00:25:30.554745: step 7600, loss 0.45633.
Test: 2018-08-01T00:25:31.039032: step 7600, loss 0.547667.
Train: 2018-08-01T00:25:31.741997: step 7601, loss 0.491539.
Train: 2018-08-01T00:25:31.898210: step 7602, loss 0.526939.
Train: 2018-08-01T00:25:32.054394: step 7603, loss 0.580462.
Train: 2018-08-01T00:25:32.226229: step 7604, loss 0.598461.
Train: 2018-08-01T00:25:32.382471: step 7605, loss 0.580592.
Train: 2018-08-01T00:25:32.538685: step 7606, loss 0.490745.
Train: 2018-08-01T00:25:32.710525: step 7607, loss 0.52665.
Train: 2018-08-01T00:25:32.866733: step 7608, loss 0.4544.
Train: 2018-08-01T00:25:33.038537: step 7609, loss 0.544632.
Train: 2018-08-01T00:25:33.194782: step 7610, loss 0.526457.
Test: 2018-08-01T00:25:33.663419: step 7610, loss 0.547568.
Train: 2018-08-01T00:25:33.835257: step 7611, loss 0.544606.
Train: 2018-08-01T00:25:34.007060: step 7612, loss 0.562861.
Train: 2018-08-01T00:25:34.163274: step 7613, loss 0.672723.
Train: 2018-08-01T00:25:34.319518: step 7614, loss 0.50797.
Train: 2018-08-01T00:25:34.475731: step 7615, loss 0.489614.
Train: 2018-08-01T00:25:34.647566: step 7616, loss 0.526233.
Train: 2018-08-01T00:25:34.819372: step 7617, loss 0.526201.
Train: 2018-08-01T00:25:34.975614: step 7618, loss 0.452517.
Train: 2018-08-01T00:25:35.131797: step 7619, loss 0.526116.
Train: 2018-08-01T00:25:35.288011: step 7620, loss 0.489037.
Test: 2018-08-01T00:25:35.756675: step 7620, loss 0.547602.
Train: 2018-08-01T00:25:35.912902: step 7621, loss 0.637444.
Train: 2018-08-01T00:25:36.069102: step 7622, loss 0.563187.
Train: 2018-08-01T00:25:36.225322: step 7623, loss 0.525961.
Train: 2018-08-01T00:25:36.381536: step 7624, loss 0.675131.
Train: 2018-08-01T00:25:36.537755: step 7625, loss 0.525949.
Train: 2018-08-01T00:25:36.693962: step 7626, loss 0.488687.
Train: 2018-08-01T00:25:36.850169: step 7627, loss 0.656436.
Train: 2018-08-01T00:25:37.037601: step 7628, loss 0.637692.
Train: 2018-08-01T00:25:37.193815: step 7629, loss 0.507421.
Train: 2018-08-01T00:25:37.350028: step 7630, loss 0.54458.
Test: 2018-08-01T00:25:37.834290: step 7630, loss 0.547592.
Train: 2018-08-01T00:25:37.990533: step 7631, loss 0.54458.
Train: 2018-08-01T00:25:38.162337: step 7632, loss 0.507572.
Train: 2018-08-01T00:25:38.302960: step 7633, loss 0.526087.
Train: 2018-08-01T00:25:38.474795: step 7634, loss 0.526093.
Train: 2018-08-01T00:25:38.630978: step 7635, loss 0.544579.
Train: 2018-08-01T00:25:38.771600: step 7636, loss 0.563062.
Train: 2018-08-01T00:25:38.927814: step 7637, loss 0.526101.
Train: 2018-08-01T00:25:39.084022: step 7638, loss 0.544579.
Train: 2018-08-01T00:25:39.255862: step 7639, loss 0.526102.
Train: 2018-08-01T00:25:39.412076: step 7640, loss 0.544579.
Test: 2018-08-01T00:25:39.880685: step 7640, loss 0.547585.
Train: 2018-08-01T00:25:40.036900: step 7641, loss 0.544579.
Train: 2018-08-01T00:25:40.193113: step 7642, loss 0.600046.
Train: 2018-08-01T00:25:40.364977: step 7643, loss 0.507622.
Train: 2018-08-01T00:25:40.521191: step 7644, loss 0.470666.
Train: 2018-08-01T00:25:40.693025: step 7645, loss 0.581571.
Train: 2018-08-01T00:25:40.833587: step 7646, loss 0.581585.
Train: 2018-08-01T00:25:40.989801: step 7647, loss 0.526079.
Train: 2018-08-01T00:25:41.146015: step 7648, loss 0.489073.
Train: 2018-08-01T00:25:41.317878: step 7649, loss 0.544579.
Train: 2018-08-01T00:25:41.489709: step 7650, loss 0.674295.
Test: 2018-08-01T00:25:41.973946: step 7650, loss 0.547589.
Train: 2018-08-01T00:25:42.130160: step 7651, loss 0.526068.
Train: 2018-08-01T00:25:42.286403: step 7652, loss 0.563077.
Train: 2018-08-01T00:25:42.442612: step 7653, loss 0.618506.
Train: 2018-08-01T00:25:42.598829: step 7654, loss 0.618376.
Train: 2018-08-01T00:25:42.755042: step 7655, loss 0.507778.
Train: 2018-08-01T00:25:42.911257: step 7656, loss 0.599689.
Train: 2018-08-01T00:25:43.083091: step 7657, loss 0.526263.
Train: 2018-08-01T00:25:43.239302: step 7658, loss 0.562884.
Train: 2018-08-01T00:25:43.395518: step 7659, loss 0.65414.
Train: 2018-08-01T00:25:43.567322: step 7660, loss 0.581009.
Test: 2018-08-01T00:25:44.035993: step 7660, loss 0.547573.
Train: 2018-08-01T00:25:44.192177: step 7661, loss 0.580904.
Train: 2018-08-01T00:25:44.348419: step 7662, loss 0.616956.
Train: 2018-08-01T00:25:44.504633: step 7663, loss 0.634698.
Train: 2018-08-01T00:25:44.676474: step 7664, loss 0.562618.
Train: 2018-08-01T00:25:44.817059: step 7665, loss 0.526892.
Train: 2018-08-01T00:25:44.973268: step 7666, loss 0.544766.
Train: 2018-08-01T00:25:45.129456: step 7667, loss 0.527077.
Train: 2018-08-01T00:25:45.285701: step 7668, loss 0.50947.
Train: 2018-08-01T00:25:45.441884: step 7669, loss 0.474245.
Train: 2018-08-01T00:25:45.598097: step 7670, loss 0.597776.
Test: 2018-08-01T00:25:46.066766: step 7670, loss 0.547718.
Train: 2018-08-01T00:25:46.238602: step 7671, loss 0.703526.
Train: 2018-08-01T00:25:46.394785: step 7672, loss 0.439403.
Train: 2018-08-01T00:25:46.551029: step 7673, loss 0.544894.
Train: 2018-08-01T00:25:46.707236: step 7674, loss 0.597564.
Train: 2018-08-01T00:25:46.863425: step 7675, loss 0.527381.
Train: 2018-08-01T00:25:47.019677: step 7676, loss 0.562447.
Train: 2018-08-01T00:25:47.191499: step 7677, loss 0.632499.
Train: 2018-08-01T00:25:47.347718: step 7678, loss 0.614891.
Train: 2018-08-01T00:25:47.503899: step 7679, loss 0.579871.
Train: 2018-08-01T00:25:47.660114: step 7680, loss 0.440602.
Test: 2018-08-01T00:25:48.128754: step 7680, loss 0.547851.
Train: 2018-08-01T00:25:48.284998: step 7681, loss 0.492836.
Train: 2018-08-01T00:25:48.456802: step 7682, loss 0.632044.
Train: 2018-08-01T00:25:48.613045: step 7683, loss 0.649403.
Train: 2018-08-01T00:25:48.769259: step 7684, loss 0.579778.
Train: 2018-08-01T00:25:48.925473: step 7685, loss 0.562407.
Train: 2018-08-01T00:25:49.097278: step 7686, loss 0.493199.
Train: 2018-08-01T00:25:49.253521: step 7687, loss 0.493239.
Train: 2018-08-01T00:25:49.409735: step 7688, loss 0.562403.
Train: 2018-08-01T00:25:49.581539: step 7689, loss 0.648935.
Train: 2018-08-01T00:25:49.737782: step 7690, loss 0.510534.
Test: 2018-08-01T00:25:50.206422: step 7690, loss 0.547926.
Train: 2018-08-01T00:25:50.362636: step 7691, loss 0.596977.
Train: 2018-08-01T00:25:50.518850: step 7692, loss 0.510572.
Train: 2018-08-01T00:25:50.690654: step 7693, loss 0.545122.
Train: 2018-08-01T00:25:50.846898: step 7694, loss 0.475972.
Train: 2018-08-01T00:25:51.003081: step 7695, loss 0.666289.
Train: 2018-08-01T00:25:51.174948: step 7696, loss 0.666276.
Train: 2018-08-01T00:25:51.346750: step 7697, loss 0.493272.
Train: 2018-08-01T00:25:51.502964: step 7698, loss 0.596947.
Train: 2018-08-01T00:25:51.674829: step 7699, loss 0.493376.
Train: 2018-08-01T00:25:51.831012: step 7700, loss 0.648687.
Test: 2018-08-01T00:25:52.299679: step 7700, loss 0.547964.
Train: 2018-08-01T00:25:53.002643: step 7701, loss 0.579634.
Train: 2018-08-01T00:25:53.158857: step 7702, loss 0.596822.
Train: 2018-08-01T00:25:53.315070: step 7703, loss 0.59676.
Train: 2018-08-01T00:25:53.471254: step 7704, loss 0.476668.
Train: 2018-08-01T00:25:53.627490: step 7705, loss 0.510991.
Train: 2018-08-01T00:25:53.783680: step 7706, loss 0.4767.
Train: 2018-08-01T00:25:53.939923: step 7707, loss 0.716884.
Train: 2018-08-01T00:25:54.096140: step 7708, loss 0.613841.
Train: 2018-08-01T00:25:54.252351: step 7709, loss 0.545276.
Train: 2018-08-01T00:25:54.424154: step 7710, loss 0.596595.
Test: 2018-08-01T00:25:54.892826: step 7710, loss 0.548103.
Train: 2018-08-01T00:25:55.049039: step 7711, loss 0.528256.
Train: 2018-08-01T00:25:55.205252: step 7712, loss 0.545344.
Train: 2018-08-01T00:25:55.361471: step 7713, loss 0.511261.
Train: 2018-08-01T00:25:55.517680: step 7714, loss 0.477141.
Train: 2018-08-01T00:25:55.689514: step 7715, loss 0.681954.
Train: 2018-08-01T00:25:55.845698: step 7716, loss 0.511178.
Train: 2018-08-01T00:25:56.001910: step 7717, loss 0.545316.
Train: 2018-08-01T00:25:56.173776: step 7718, loss 0.494023.
Train: 2018-08-01T00:25:56.345604: step 7719, loss 0.596641.
Train: 2018-08-01T00:25:56.501794: step 7720, loss 0.528116.
Test: 2018-08-01T00:25:56.970463: step 7720, loss 0.548022.
Train: 2018-08-01T00:25:57.126678: step 7721, loss 0.57956.
Train: 2018-08-01T00:25:57.282891: step 7722, loss 0.562396.
Train: 2018-08-01T00:25:57.439073: step 7723, loss 0.562396.
Train: 2018-08-01T00:25:57.595287: step 7724, loss 0.562397.
Train: 2018-08-01T00:25:57.767163: step 7725, loss 0.751867.
Train: 2018-08-01T00:25:57.938956: step 7726, loss 0.476465.
Train: 2018-08-01T00:25:58.095201: step 7727, loss 0.613918.
Train: 2018-08-01T00:25:58.251414: step 7728, loss 0.459498.
Train: 2018-08-01T00:25:58.392005: step 7729, loss 0.528086.
Train: 2018-08-01T00:25:58.563811: step 7730, loss 0.545228.
Test: 2018-08-01T00:25:59.032482: step 7730, loss 0.548006.
Train: 2018-08-01T00:25:59.188695: step 7731, loss 0.596764.
Train: 2018-08-01T00:25:59.360535: step 7732, loss 0.596776.
Train: 2018-08-01T00:25:59.516712: step 7733, loss 0.648326.
Train: 2018-08-01T00:25:59.672951: step 7734, loss 0.682517.
Train: 2018-08-01T00:25:59.813548: step 7735, loss 0.579502.
Train: 2018-08-01T00:25:59.985379: step 7736, loss 0.494191.
Train: 2018-08-01T00:26:00.141596: step 7737, loss 0.443247.
Train: 2018-08-01T00:26:00.297804: step 7738, loss 0.511321.
Train: 2018-08-01T00:26:00.454023: step 7739, loss 0.545355.
Train: 2018-08-01T00:26:00.610208: step 7740, loss 0.613598.
Test: 2018-08-01T00:26:01.094493: step 7740, loss 0.548102.
Train: 2018-08-01T00:26:01.250711: step 7741, loss 0.579471.
Train: 2018-08-01T00:26:01.406895: step 7742, loss 0.562398.
Train: 2018-08-01T00:26:01.547518: step 7743, loss 0.459947.
Train: 2018-08-01T00:26:01.719351: step 7744, loss 0.52819.
Train: 2018-08-01T00:26:01.875534: step 7745, loss 0.545257.
Train: 2018-08-01T00:26:02.031748: step 7746, loss 0.545222.
Train: 2018-08-01T00:26:02.187962: step 7747, loss 0.510765.
Train: 2018-08-01T00:26:02.359797: step 7748, loss 0.562399.
Train: 2018-08-01T00:26:02.500413: step 7749, loss 0.51051.
Train: 2018-08-01T00:26:02.672248: step 7750, loss 0.666496.
Test: 2018-08-01T00:26:03.140863: step 7750, loss 0.547871.
Train: 2018-08-01T00:26:03.297077: step 7751, loss 0.545047.
Train: 2018-08-01T00:26:03.468941: step 7752, loss 0.5798.
Train: 2018-08-01T00:26:03.625126: step 7753, loss 0.6668.
Train: 2018-08-01T00:26:03.765747: step 7754, loss 0.684078.
Train: 2018-08-01T00:26:03.921961: step 7755, loss 0.579741.
Train: 2018-08-01T00:26:04.078176: step 7756, loss 0.648834.
Train: 2018-08-01T00:26:04.234357: step 7757, loss 0.596839.
Train: 2018-08-01T00:26:04.406218: step 7758, loss 0.562395.
Train: 2018-08-01T00:26:04.562406: step 7759, loss 0.630765.
Train: 2018-08-01T00:26:04.734265: step 7760, loss 0.613461.
Test: 2018-08-01T00:26:05.202910: step 7760, loss 0.548227.
Train: 2018-08-01T00:26:05.359125: step 7761, loss 0.647119.
Train: 2018-08-01T00:26:05.546550: step 7762, loss 0.562432.
Train: 2018-08-01T00:26:05.702763: step 7763, loss 0.495385.
Train: 2018-08-01T00:26:05.858977: step 7764, loss 0.562471.
Train: 2018-08-01T00:26:06.015190: step 7765, loss 0.612485.
Train: 2018-08-01T00:26:06.171435: step 7766, loss 0.645566.
Train: 2018-08-01T00:26:06.327618: step 7767, loss 0.479833.
Train: 2018-08-01T00:26:06.483831: step 7768, loss 0.513049.
Train: 2018-08-01T00:26:06.655665: step 7769, loss 0.612025.
Train: 2018-08-01T00:26:06.811909: step 7770, loss 0.628414.
Test: 2018-08-01T00:26:07.280550: step 7770, loss 0.54886.
Train: 2018-08-01T00:26:07.452384: step 7771, loss 0.496939.
Train: 2018-08-01T00:26:07.608597: step 7772, loss 0.595419.
Train: 2018-08-01T00:26:07.764781: step 7773, loss 0.628151.
Train: 2018-08-01T00:26:07.921025: step 7774, loss 0.497263.
Train: 2018-08-01T00:26:08.077237: step 7775, loss 0.529982.
Train: 2018-08-01T00:26:08.233445: step 7776, loss 0.578994.
Train: 2018-08-01T00:26:08.405257: step 7777, loss 0.529971.
Train: 2018-08-01T00:26:08.545872: step 7778, loss 0.529937.
Train: 2018-08-01T00:26:08.702091: step 7779, loss 0.480745.
Train: 2018-08-01T00:26:08.889518: step 7780, loss 0.464065.
Test: 2018-08-01T00:26:09.358157: step 7780, loss 0.548754.
Train: 2018-08-01T00:26:09.514372: step 7781, loss 0.546072.
Train: 2018-08-01T00:26:09.670615: step 7782, loss 0.595659.
Train: 2018-08-01T00:26:09.826828: step 7783, loss 0.462784.
Train: 2018-08-01T00:26:09.998663: step 7784, loss 0.662674.
Train: 2018-08-01T00:26:10.154877: step 7785, loss 0.545715.
Train: 2018-08-01T00:26:10.311089: step 7786, loss 0.52886.
Train: 2018-08-01T00:26:10.467303: step 7787, loss 0.629817.
Train: 2018-08-01T00:26:10.623517: step 7788, loss 0.478041.
Train: 2018-08-01T00:26:10.779699: step 7789, loss 0.663983.
Train: 2018-08-01T00:26:10.935915: step 7790, loss 0.596308.
Test: 2018-08-01T00:26:11.404552: step 7790, loss 0.548211.
Train: 2018-08-01T00:26:11.560797: step 7791, loss 0.49458.
Train: 2018-08-01T00:26:11.732632: step 7792, loss 0.528437.
Train: 2018-08-01T00:26:11.888816: step 7793, loss 0.681535.
Train: 2018-08-01T00:26:12.045030: step 7794, loss 0.46029.
Train: 2018-08-01T00:26:12.216864: step 7795, loss 0.630584.
Train: 2018-08-01T00:26:12.373112: step 7796, loss 0.596505.
Train: 2018-08-01T00:26:12.544942: step 7797, loss 0.784057.
Train: 2018-08-01T00:26:12.701155: step 7798, loss 0.579397.
Train: 2018-08-01T00:26:12.857363: step 7799, loss 0.596283.
Train: 2018-08-01T00:26:13.013552: step 7800, loss 0.562426.
Test: 2018-08-01T00:26:13.497813: step 7800, loss 0.548352.
Train: 2018-08-01T00:26:14.185182: step 7801, loss 0.528793.
Train: 2018-08-01T00:26:14.388260: step 7802, loss 0.679946.
Train: 2018-08-01T00:26:14.544468: step 7803, loss 0.49558.
Train: 2018-08-01T00:26:14.716308: step 7804, loss 0.445691.
Train: 2018-08-01T00:26:14.872522: step 7805, loss 0.562482.
Train: 2018-08-01T00:26:15.044356: step 7806, loss 0.495749.
Train: 2018-08-01T00:26:15.216185: step 7807, loss 0.595881.
Train: 2018-08-01T00:26:15.387996: step 7808, loss 0.529045.
Train: 2018-08-01T00:26:15.544209: step 7809, loss 0.528999.
Train: 2018-08-01T00:26:15.700452: step 7810, loss 0.629499.
Test: 2018-08-01T00:26:16.184714: step 7810, loss 0.54841.
Train: 2018-08-01T00:26:16.340928: step 7811, loss 0.428296.
Train: 2018-08-01T00:26:16.497111: step 7812, loss 0.495184.
Train: 2018-08-01T00:26:16.653325: step 7813, loss 0.511808.
Train: 2018-08-01T00:26:16.809564: step 7814, loss 0.765694.
Train: 2018-08-01T00:26:16.965781: step 7815, loss 0.68105.
Train: 2018-08-01T00:26:17.137610: step 7816, loss 0.562416.
Train: 2018-08-01T00:26:17.293829: step 7817, loss 0.579326.
Train: 2018-08-01T00:26:17.434392: step 7818, loss 0.64685.
Train: 2018-08-01T00:26:17.637468: step 7819, loss 0.528742.
Train: 2018-08-01T00:26:17.793682: step 7820, loss 0.612897.
Test: 2018-08-01T00:26:18.262346: step 7820, loss 0.548395.
Train: 2018-08-01T00:26:18.418535: step 7821, loss 0.596017.
Train: 2018-08-01T00:26:18.574749: step 7822, loss 0.47874.
Train: 2018-08-01T00:26:18.730962: step 7823, loss 0.495537.
Train: 2018-08-01T00:26:18.887206: step 7824, loss 0.562462.
Train: 2018-08-01T00:26:19.043389: step 7825, loss 0.495465.
Train: 2018-08-01T00:26:19.199603: step 7826, loss 0.562452.
Train: 2018-08-01T00:26:19.371462: step 7827, loss 0.512043.
Train: 2018-08-01T00:26:19.543273: step 7828, loss 0.697135.
Train: 2018-08-01T00:26:19.699485: step 7829, loss 0.511924.
Train: 2018-08-01T00:26:19.871322: step 7830, loss 0.579282.
Test: 2018-08-01T00:26:20.355581: step 7830, loss 0.548311.
Train: 2018-08-01T00:26:20.511795: step 7831, loss 0.52871.
Train: 2018-08-01T00:26:20.668010: step 7832, loss 0.613058.
Train: 2018-08-01T00:26:20.824245: step 7833, loss 0.663712.
Train: 2018-08-01T00:26:20.996082: step 7834, loss 0.579289.
Train: 2018-08-01T00:26:21.167892: step 7835, loss 0.579271.
Train: 2018-08-01T00:26:21.324135: step 7836, loss 0.495192.
Train: 2018-08-01T00:26:21.480319: step 7837, loss 0.562442.
Train: 2018-08-01T00:26:21.652179: step 7838, loss 0.713713.
Train: 2018-08-01T00:26:21.808397: step 7839, loss 0.59599.
Train: 2018-08-01T00:26:21.980204: step 7840, loss 0.562467.
Test: 2018-08-01T00:26:22.448872: step 7840, loss 0.548506.
Train: 2018-08-01T00:26:22.605055: step 7841, loss 0.645921.
Train: 2018-08-01T00:26:22.761270: step 7842, loss 0.495963.
Train: 2018-08-01T00:26:22.917482: step 7843, loss 0.462881.
Train: 2018-08-01T00:26:23.073726: step 7844, loss 0.562512.
Train: 2018-08-01T00:26:23.229940: step 7845, loss 0.645564.
Train: 2018-08-01T00:26:23.386122: step 7846, loss 0.628894.
Train: 2018-08-01T00:26:23.542366: step 7847, loss 0.595658.
Train: 2018-08-01T00:26:23.698550: step 7848, loss 0.52949.
Train: 2018-08-01T00:26:23.854765: step 7849, loss 0.579067.
Train: 2018-08-01T00:26:24.011006: step 7850, loss 0.546079.
Test: 2018-08-01T00:26:24.510878: step 7850, loss 0.548777.
Train: 2018-08-01T00:26:24.667103: step 7851, loss 0.562574.
Train: 2018-08-01T00:26:24.823287: step 7852, loss 0.579047.
Train: 2018-08-01T00:26:24.979500: step 7853, loss 0.480285.
Train: 2018-08-01T00:26:25.135713: step 7854, loss 0.496673.
Train: 2018-08-01T00:26:25.323169: step 7855, loss 0.529538.
Train: 2018-08-01T00:26:25.463791: step 7856, loss 0.545986.
Train: 2018-08-01T00:26:25.620005: step 7857, loss 0.512732.
Train: 2018-08-01T00:26:25.776219: step 7858, loss 0.462597.
Train: 2018-08-01T00:26:25.932432: step 7859, loss 0.562467.
Train: 2018-08-01T00:26:26.088615: step 7860, loss 0.562445.
Test: 2018-08-01T00:26:26.557285: step 7860, loss 0.548309.
Train: 2018-08-01T00:26:26.729089: step 7861, loss 0.64674.
Train: 2018-08-01T00:26:26.885302: step 7862, loss 0.528621.
Train: 2018-08-01T00:26:27.057169: step 7863, loss 0.54547.
Train: 2018-08-01T00:26:27.229003: step 7864, loss 0.545419.
Train: 2018-08-01T00:26:27.385216: step 7865, loss 0.579433.
Train: 2018-08-01T00:26:27.557021: step 7866, loss 0.630672.
Train: 2018-08-01T00:26:27.713235: step 7867, loss 0.647816.
Train: 2018-08-01T00:26:27.869472: step 7868, loss 0.528246.
Train: 2018-08-01T00:26:28.025692: step 7869, loss 0.647788.
Train: 2018-08-01T00:26:28.181905: step 7870, loss 0.494166.
Test: 2018-08-01T00:26:28.666136: step 7870, loss 0.548115.
Train: 2018-08-01T00:26:28.822349: step 7871, loss 0.528282.
Train: 2018-08-01T00:26:28.978563: step 7872, loss 0.494128.
Train: 2018-08-01T00:26:29.134800: step 7873, loss 0.630787.
Train: 2018-08-01T00:26:29.291021: step 7874, loss 0.562397.
Train: 2018-08-01T00:26:29.447234: step 7875, loss 0.579502.
Train: 2018-08-01T00:26:29.619068: step 7876, loss 0.528184.
Train: 2018-08-01T00:26:29.790873: step 7877, loss 0.630861.
Train: 2018-08-01T00:26:29.947116: step 7878, loss 0.630827.
Train: 2018-08-01T00:26:30.118921: step 7879, loss 0.476986.
Train: 2018-08-01T00:26:30.275171: step 7880, loss 0.562398.
Test: 2018-08-01T00:26:30.743808: step 7880, loss 0.548095.
Train: 2018-08-01T00:26:30.900019: step 7881, loss 0.579481.
Train: 2018-08-01T00:26:31.056231: step 7882, loss 0.596554.
Train: 2018-08-01T00:26:31.212445: step 7883, loss 0.579465.
Train: 2018-08-01T00:26:31.368628: step 7884, loss 0.562401.
Train: 2018-08-01T00:26:31.524866: step 7885, loss 0.511292.
Train: 2018-08-01T00:26:31.681085: step 7886, loss 0.511288.
Train: 2018-08-01T00:26:31.852890: step 7887, loss 0.460081.
Train: 2018-08-01T00:26:31.993512: step 7888, loss 0.562399.
Train: 2018-08-01T00:26:32.149726: step 7889, loss 0.613788.
Train: 2018-08-01T00:26:32.305939: step 7890, loss 0.596697.
Test: 2018-08-01T00:26:32.774580: step 7890, loss 0.548029.
Train: 2018-08-01T00:26:32.946411: step 7891, loss 0.562398.
Train: 2018-08-01T00:26:33.102628: step 7892, loss 0.613897.
Train: 2018-08-01T00:26:33.274463: step 7893, loss 0.459434.
Train: 2018-08-01T00:26:33.430645: step 7894, loss 0.562398.
Train: 2018-08-01T00:26:33.586890: step 7895, loss 0.613999.
Train: 2018-08-01T00:26:33.743097: step 7896, loss 0.545195.
Train: 2018-08-01T00:26:33.899286: step 7897, loss 0.631244.
Train: 2018-08-01T00:26:34.055526: step 7898, loss 0.562398.
Train: 2018-08-01T00:26:34.211737: step 7899, loss 0.596779.
Train: 2018-08-01T00:26:34.367956: step 7900, loss 0.545225.
Test: 2018-08-01T00:26:34.836596: step 7900, loss 0.548028.
Train: 2018-08-01T00:26:35.570799: step 7901, loss 0.493756.
Train: 2018-08-01T00:26:35.727013: step 7902, loss 0.596732.
Train: 2018-08-01T00:26:35.883196: step 7903, loss 0.562397.
Train: 2018-08-01T00:26:36.039440: step 7904, loss 0.613884.
Train: 2018-08-01T00:26:36.195655: step 7905, loss 0.493809.
Train: 2018-08-01T00:26:36.367458: step 7906, loss 0.442342.
Train: 2018-08-01T00:26:36.523703: step 7907, loss 0.528027.
Train: 2018-08-01T00:26:36.679884: step 7908, loss 0.52795.
Train: 2018-08-01T00:26:36.851719: step 7909, loss 0.545133.
Train: 2018-08-01T00:26:37.007963: step 7910, loss 0.493157.
Test: 2018-08-01T00:26:37.476603: step 7910, loss 0.54787.
Train: 2018-08-01T00:26:37.632810: step 7911, loss 0.614521.
Train: 2018-08-01T00:26:37.789000: step 7912, loss 0.545015.
Train: 2018-08-01T00:26:37.945249: step 7913, loss 0.614756.
Train: 2018-08-01T00:26:38.101457: step 7914, loss 0.544971.
Train: 2018-08-01T00:26:38.257640: step 7915, loss 0.632365.
Train: 2018-08-01T00:26:38.413879: step 7916, loss 0.579919.
Train: 2018-08-01T00:26:38.585718: step 7917, loss 0.527484.
Train: 2018-08-01T00:26:38.741901: step 7918, loss 0.544958.
Train: 2018-08-01T00:26:38.882525: step 7919, loss 0.52747.
Train: 2018-08-01T00:26:39.054358: step 7920, loss 0.509951.
Test: 2018-08-01T00:26:39.522998: step 7920, loss 0.547776.
Train: 2018-08-01T00:26:39.679183: step 7921, loss 0.492366.
Train: 2018-08-01T00:26:39.835396: step 7922, loss 0.667805.
Train: 2018-08-01T00:26:39.991639: step 7923, loss 0.56246.
Train: 2018-08-01T00:26:40.147853: step 7924, loss 0.509757.
Train: 2018-08-01T00:26:40.304066: step 7925, loss 0.544882.
Train: 2018-08-01T00:26:40.460279: step 7926, loss 0.544871.
Train: 2018-08-01T00:26:40.632085: step 7927, loss 0.668189.
Train: 2018-08-01T00:26:40.788297: step 7928, loss 0.509653.
Train: 2018-08-01T00:26:40.944536: step 7929, loss 0.615298.
Train: 2018-08-01T00:26:41.100724: step 7930, loss 0.668036.
Test: 2018-08-01T00:26:41.585029: step 7930, loss 0.547757.
Train: 2018-08-01T00:26:41.741229: step 7931, loss 0.527348.
Train: 2018-08-01T00:26:41.913034: step 7932, loss 0.492346.
Train: 2018-08-01T00:26:42.053656: step 7933, loss 0.579962.
Train: 2018-08-01T00:26:42.209870: step 7934, loss 0.54494.
Train: 2018-08-01T00:26:42.366083: step 7935, loss 0.544947.
Train: 2018-08-01T00:26:42.522297: step 7936, loss 0.509976.
Train: 2018-08-01T00:26:42.678510: step 7937, loss 0.632418.
Train: 2018-08-01T00:26:42.850341: step 7938, loss 0.544954.
Train: 2018-08-01T00:26:43.022186: step 7939, loss 0.57991.
Train: 2018-08-01T00:26:43.178393: step 7940, loss 0.544969.
Test: 2018-08-01T00:26:43.647034: step 7940, loss 0.547813.
Train: 2018-08-01T00:26:43.803216: step 7941, loss 0.52752.
Train: 2018-08-01T00:26:43.959430: step 7942, loss 0.579886.
Train: 2018-08-01T00:26:44.115643: step 7943, loss 0.649684.
Train: 2018-08-01T00:26:44.287509: step 7944, loss 0.597271.
Train: 2018-08-01T00:26:44.443691: step 7945, loss 0.597195.
Train: 2018-08-01T00:26:44.599904: step 7946, loss 0.614457.
Train: 2018-08-01T00:26:44.756148: step 7947, loss 0.614299.
Train: 2018-08-01T00:26:44.912363: step 7948, loss 0.562398.
Train: 2018-08-01T00:26:45.084197: step 7949, loss 0.493652.
Train: 2018-08-01T00:26:45.240404: step 7950, loss 0.528085.
Test: 2018-08-01T00:26:45.709050: step 7950, loss 0.548046.
Train: 2018-08-01T00:26:45.865234: step 7951, loss 0.579532.
Train: 2018-08-01T00:26:46.032993: step 7952, loss 0.545281.
Train: 2018-08-01T00:26:46.189204: step 7953, loss 0.6137.
Train: 2018-08-01T00:26:46.345456: step 7954, loss 0.545323.
Train: 2018-08-01T00:26:46.501660: step 7955, loss 0.545343.
Train: 2018-08-01T00:26:46.657874: step 7956, loss 0.494225.
Train: 2018-08-01T00:26:46.829703: step 7957, loss 0.528298.
Train: 2018-08-01T00:26:46.985917: step 7958, loss 0.511198.
Train: 2018-08-01T00:26:47.142135: step 7959, loss 0.545302.
Train: 2018-08-01T00:26:47.298354: step 7960, loss 0.682266.
Test: 2018-08-01T00:26:47.782636: step 7960, loss 0.54806.
Train: 2018-08-01T00:26:47.938794: step 7961, loss 0.493916.
Train: 2018-08-01T00:26:48.095042: step 7962, loss 0.716601.
Train: 2018-08-01T00:26:48.251251: step 7963, loss 0.59661.
Train: 2018-08-01T00:26:48.423086: step 7964, loss 0.596546.
Train: 2018-08-01T00:26:48.579269: step 7965, loss 0.562401.
Train: 2018-08-01T00:26:48.719862: step 7966, loss 0.681413.
Train: 2018-08-01T00:26:48.876075: step 7967, loss 0.494653.
Train: 2018-08-01T00:26:49.032315: step 7968, loss 0.613131.
Train: 2018-08-01T00:26:49.188532: step 7969, loss 0.511855.
Train: 2018-08-01T00:26:49.344749: step 7970, loss 0.579268.
Test: 2018-08-01T00:26:49.813355: step 7970, loss 0.548371.
Train: 2018-08-01T00:26:49.969595: step 7971, loss 0.629662.
Train: 2018-08-01T00:26:50.125812: step 7972, loss 0.461873.
Train: 2018-08-01T00:26:50.281996: step 7973, loss 0.528948.
Train: 2018-08-01T00:26:50.438209: step 7974, loss 0.629484.
Train: 2018-08-01T00:26:50.610073: step 7975, loss 0.629432.
Train: 2018-08-01T00:26:50.766293: step 7976, loss 0.612611.
Train: 2018-08-01T00:26:50.922471: step 7977, loss 0.54581.
Train: 2018-08-01T00:26:51.078717: step 7978, loss 0.545849.
Train: 2018-08-01T00:26:51.234927: step 7979, loss 0.595759.
Train: 2018-08-01T00:26:51.391111: step 7980, loss 0.628928.
Test: 2018-08-01T00:26:51.859781: step 7980, loss 0.548658.
Train: 2018-08-01T00:26:52.031616: step 7981, loss 0.479701.
Train: 2018-08-01T00:26:52.187829: step 7982, loss 0.463198.
Train: 2018-08-01T00:26:52.328421: step 7983, loss 0.512798.
Train: 2018-08-01T00:26:52.484634: step 7984, loss 0.529293.
Train: 2018-08-01T00:26:52.640817: step 7985, loss 0.579144.
Train: 2018-08-01T00:26:52.828275: step 7986, loss 0.512433.
Train: 2018-08-01T00:26:52.984488: step 7987, loss 0.545738.
Train: 2018-08-01T00:26:53.140700: step 7988, loss 0.629552.
Train: 2018-08-01T00:26:53.296947: step 7989, loss 0.69685.
Train: 2018-08-01T00:26:53.453160: step 7990, loss 0.596026.
Test: 2018-08-01T00:26:53.921797: step 7990, loss 0.548408.
Train: 2018-08-01T00:26:54.093637: step 7991, loss 0.545681.
Train: 2018-08-01T00:26:54.249840: step 7992, loss 0.562456.
Train: 2018-08-01T00:26:54.406029: step 7993, loss 0.579212.
Train: 2018-08-01T00:26:54.562242: step 7994, loss 0.545717.
Train: 2018-08-01T00:26:54.718457: step 7995, loss 0.512239.
Train: 2018-08-01T00:26:54.874708: step 7996, loss 0.579211.
Train: 2018-08-01T00:26:55.046504: step 7997, loss 0.445133.
Train: 2018-08-01T00:26:55.202748: step 7998, loss 0.612843.
Train: 2018-08-01T00:26:55.358931: step 7999, loss 0.495148.
Train: 2018-08-01T00:26:55.515178: step 8000, loss 0.596153.
Test: 2018-08-01T00:26:55.999407: step 8000, loss 0.548279.
Train: 2018-08-01T00:26:56.702397: step 8001, loss 0.562423.
Train: 2018-08-01T00:26:56.858610: step 8002, loss 0.630083.
Train: 2018-08-01T00:26:57.014794: step 8003, loss 0.596262.
Train: 2018-08-01T00:26:57.186659: step 8004, loss 0.630099.
Train: 2018-08-01T00:26:57.342876: step 8005, loss 0.613126.
Train: 2018-08-01T00:26:57.499086: step 8006, loss 0.562427.
Train: 2018-08-01T00:26:57.655294: step 8007, loss 0.478197.
Train: 2018-08-01T00:26:57.811512: step 8008, loss 0.478196.
Train: 2018-08-01T00:26:57.967730: step 8009, loss 0.596168.
Train: 2018-08-01T00:26:58.139555: step 8010, loss 0.579308.
Test: 2018-08-01T00:26:58.608200: step 8010, loss 0.548277.
Train: 2018-08-01T00:26:58.764414: step 8011, loss 0.613099.
Train: 2018-08-01T00:26:58.920627: step 8012, loss 0.545536.
Train: 2018-08-01T00:26:59.076844: step 8013, loss 0.5962.
Train: 2018-08-01T00:26:59.233055: step 8014, loss 0.62995.
Train: 2018-08-01T00:26:59.420481: step 8015, loss 0.596146.
Train: 2018-08-01T00:26:59.576694: step 8016, loss 0.646585.
Train: 2018-08-01T00:26:59.732906: step 8017, loss 0.5121.
Train: 2018-08-01T00:26:59.889151: step 8018, loss 0.495436.
Train: 2018-08-01T00:27:00.045365: step 8019, loss 0.52896.
Train: 2018-08-01T00:27:00.201547: step 8020, loss 0.545703.
Test: 2018-08-01T00:27:00.670217: step 8020, loss 0.548416.
Train: 2018-08-01T00:27:00.826431: step 8021, loss 0.61275.
Train: 2018-08-01T00:27:00.982614: step 8022, loss 0.545693.
Train: 2018-08-01T00:27:01.138827: step 8023, loss 0.512156.
Train: 2018-08-01T00:27:01.310693: step 8024, loss 0.612801.
Train: 2018-08-01T00:27:01.466877: step 8025, loss 0.562448.
Train: 2018-08-01T00:27:01.623090: step 8026, loss 0.495276.
Train: 2018-08-01T00:27:01.779302: step 8027, loss 0.511992.
Train: 2018-08-01T00:27:01.935547: step 8028, loss 0.562431.
Train: 2018-08-01T00:27:02.091754: step 8029, loss 0.494886.
Train: 2018-08-01T00:27:02.247975: step 8030, loss 0.494683.
Test: 2018-08-01T00:27:02.732235: step 8030, loss 0.548174.
Train: 2018-08-01T00:27:02.872797: step 8031, loss 0.64738.
Train: 2018-08-01T00:27:03.044632: step 8032, loss 0.511314.
Train: 2018-08-01T00:27:03.200845: step 8033, loss 0.579472.
Train: 2018-08-01T00:27:03.357083: step 8034, loss 0.528177.
Train: 2018-08-01T00:27:03.513302: step 8035, loss 0.528094.
Train: 2018-08-01T00:27:03.685138: step 8036, loss 0.476411.
Train: 2018-08-01T00:27:03.841354: step 8037, loss 0.57966.
Train: 2018-08-01T00:27:03.997533: step 8038, loss 0.597031.
Train: 2018-08-01T00:27:04.138126: step 8039, loss 0.510357.
Train: 2018-08-01T00:27:04.309960: step 8040, loss 0.458032.
Test: 2018-08-01T00:27:04.778630: step 8040, loss 0.547807.
Train: 2018-08-01T00:27:04.934815: step 8041, loss 0.597363.
Train: 2018-08-01T00:27:05.091061: step 8042, loss 0.614994.
Train: 2018-08-01T00:27:05.247271: step 8043, loss 0.544906.
Train: 2018-08-01T00:27:05.403486: step 8044, loss 0.544884.
Train: 2018-08-01T00:27:05.559706: step 8045, loss 0.509642.
Train: 2018-08-01T00:27:05.715881: step 8046, loss 0.544838.
Train: 2018-08-01T00:27:05.887715: step 8047, loss 0.580193.
Train: 2018-08-01T00:27:06.043929: step 8048, loss 0.633388.
Train: 2018-08-01T00:27:06.200142: step 8049, loss 0.562518.
Train: 2018-08-01T00:27:06.371978: step 8050, loss 0.491609.
Test: 2018-08-01T00:27:06.840652: step 8050, loss 0.547668.
Train: 2018-08-01T00:27:07.012483: step 8051, loss 0.633516.
Train: 2018-08-01T00:27:07.168696: step 8052, loss 0.544783.
Train: 2018-08-01T00:27:07.324879: step 8053, loss 0.598016.
Train: 2018-08-01T00:27:07.481119: step 8054, loss 0.562522.
Train: 2018-08-01T00:27:07.652952: step 8055, loss 0.668848.
Train: 2018-08-01T00:27:07.809171: step 8056, loss 0.562501.
Train: 2018-08-01T00:27:07.965384: step 8057, loss 0.615424.
Train: 2018-08-01T00:27:08.152840: step 8058, loss 0.597664.
Train: 2018-08-01T00:27:08.309048: step 8059, loss 0.492279.
Train: 2018-08-01T00:27:08.465236: step 8060, loss 0.544932.
Test: 2018-08-01T00:27:08.933908: step 8060, loss 0.547795.
Train: 2018-08-01T00:27:09.090093: step 8061, loss 0.579923.
Train: 2018-08-01T00:27:09.261925: step 8062, loss 0.457687.
Train: 2018-08-01T00:27:09.418139: step 8063, loss 0.597344.
Train: 2018-08-01T00:27:09.574384: step 8064, loss 0.61477.
Train: 2018-08-01T00:27:09.730596: step 8065, loss 0.597271.
Train: 2018-08-01T00:27:09.902401: step 8066, loss 0.631989.
Train: 2018-08-01T00:27:10.042993: step 8067, loss 0.649143.
Train: 2018-08-01T00:27:10.214829: step 8068, loss 0.545119.
Train: 2018-08-01T00:27:10.371071: step 8069, loss 0.527941.
Train: 2018-08-01T00:27:10.527254: step 8070, loss 0.579584.
Test: 2018-08-01T00:27:11.011545: step 8070, loss 0.548037.
Train: 2018-08-01T00:27:11.167729: step 8071, loss 0.493806.
Train: 2018-08-01T00:27:11.323943: step 8072, loss 0.562396.
Train: 2018-08-01T00:27:11.480157: step 8073, loss 0.425502.
Train: 2018-08-01T00:27:11.636400: step 8074, loss 0.579528.
Train: 2018-08-01T00:27:11.792584: step 8075, loss 0.596689.
Train: 2018-08-01T00:27:11.964452: step 8076, loss 0.562395.
Train: 2018-08-01T00:27:12.120656: step 8077, loss 0.528087.
Train: 2018-08-01T00:27:12.276875: step 8078, loss 0.631061.
Train: 2018-08-01T00:27:12.448713: step 8079, loss 0.631034.
Train: 2018-08-01T00:27:12.589306: step 8080, loss 0.596667.
Test: 2018-08-01T00:27:13.073567: step 8080, loss 0.548073.
Train: 2018-08-01T00:27:13.229747: step 8081, loss 0.630817.
Train: 2018-08-01T00:27:13.385990: step 8082, loss 0.613579.
Train: 2018-08-01T00:27:13.542175: step 8083, loss 0.511385.
Train: 2018-08-01T00:27:13.698417: step 8084, loss 0.528465.
Train: 2018-08-01T00:27:13.854599: step 8085, loss 0.460709.
Train: 2018-08-01T00:27:14.010814: step 8086, loss 0.494576.
Train: 2018-08-01T00:27:14.167057: step 8087, loss 0.562407.
Train: 2018-08-01T00:27:14.338862: step 8088, loss 0.528387.
Train: 2018-08-01T00:27:14.479486: step 8089, loss 0.613519.
Train: 2018-08-01T00:27:14.651324: step 8090, loss 0.5624.
Test: 2018-08-01T00:27:15.119959: step 8090, loss 0.548106.
Train: 2018-08-01T00:27:15.291794: step 8091, loss 0.511195.
Train: 2018-08-01T00:27:15.447978: step 8092, loss 0.613679.
Train: 2018-08-01T00:27:15.604192: step 8093, loss 0.562397.
Train: 2018-08-01T00:27:15.776025: step 8094, loss 0.459714.
Train: 2018-08-01T00:27:15.932238: step 8095, loss 0.528097.
Train: 2018-08-01T00:27:16.088452: step 8096, loss 0.493636.
Train: 2018-08-01T00:27:16.244665: step 8097, loss 0.665864.
Train: 2018-08-01T00:27:16.400879: step 8098, loss 0.545134.
Train: 2018-08-01T00:27:16.557123: step 8099, loss 0.527822.
Train: 2018-08-01T00:27:16.713336: step 8100, loss 0.527766.
Test: 2018-08-01T00:27:17.181945: step 8100, loss 0.547877.
Train: 2018-08-01T00:27:17.900528: step 8101, loss 0.579766.
Train: 2018-08-01T00:27:18.056771: step 8102, loss 0.458123.
Train: 2018-08-01T00:27:18.212955: step 8103, loss 0.667015.
Train: 2018-08-01T00:27:18.369168: step 8104, loss 0.649674.
Train: 2018-08-01T00:27:18.525381: step 8105, loss 0.579868.
Train: 2018-08-01T00:27:18.697216: step 8106, loss 0.475279.
Train: 2018-08-01T00:27:18.853460: step 8107, loss 0.579865.
Train: 2018-08-01T00:27:19.025289: step 8108, loss 0.544984.
Train: 2018-08-01T00:27:19.165887: step 8109, loss 0.510079.
Train: 2018-08-01T00:27:19.322071: step 8110, loss 0.579901.
Test: 2018-08-01T00:27:19.790739: step 8110, loss 0.547798.
Train: 2018-08-01T00:27:19.946954: step 8111, loss 0.579915.
Train: 2018-08-01T00:27:20.118757: step 8112, loss 0.509985.
Train: 2018-08-01T00:27:20.274972: step 8113, loss 0.49244.
Train: 2018-08-01T00:27:20.446830: step 8114, loss 0.509855.
Train: 2018-08-01T00:27:20.603055: step 8115, loss 0.527318.
Train: 2018-08-01T00:27:20.759234: step 8116, loss 0.54486.
Train: 2018-08-01T00:27:20.931069: step 8117, loss 0.58015.
Train: 2018-08-01T00:27:21.087312: step 8118, loss 0.562504.
Train: 2018-08-01T00:27:21.274738: step 8119, loss 0.527081.
Train: 2018-08-01T00:27:21.430950: step 8120, loss 0.527033.
Test: 2018-08-01T00:27:21.899621: step 8120, loss 0.547654.
Train: 2018-08-01T00:27:22.055835: step 8121, loss 0.491412.
Train: 2018-08-01T00:27:22.212058: step 8122, loss 0.526907.
Train: 2018-08-01T00:27:22.383883: step 8123, loss 0.491075.
Train: 2018-08-01T00:27:22.540096: step 8124, loss 0.580569.
Train: 2018-08-01T00:27:22.696312: step 8125, loss 0.544671.
Train: 2018-08-01T00:27:22.852523: step 8126, loss 0.580716.
Train: 2018-08-01T00:27:23.008736: step 8127, loss 0.639773.
Train: 2018-08-01T00:27:23.164950: step 8128, loss 0.562712.
Train: 2018-08-01T00:27:23.321159: step 8129, loss 0.508499.
Train: 2018-08-01T00:27:23.492967: step 8130, loss 0.562723.
Test: 2018-08-01T00:27:23.961642: step 8130, loss 0.547578.
Train: 2018-08-01T00:27:24.117821: step 8131, loss 0.490358.
Train: 2018-08-01T00:27:24.274035: step 8132, loss 0.635205.
Train: 2018-08-01T00:27:24.430249: step 8133, loss 0.580858.
Train: 2018-08-01T00:27:24.602108: step 8134, loss 0.653265.
Train: 2018-08-01T00:27:24.742675: step 8135, loss 0.454283.
Train: 2018-08-01T00:27:24.914510: step 8136, loss 0.56271.
Train: 2018-08-01T00:27:25.070754: step 8137, loss 0.598817.
Train: 2018-08-01T00:27:25.226967: step 8138, loss 0.490543.
Train: 2018-08-01T00:27:25.383150: step 8139, loss 0.526621.
Train: 2018-08-01T00:27:25.555011: step 8140, loss 0.490542.
Test: 2018-08-01T00:27:26.023655: step 8140, loss 0.547584.
Train: 2018-08-01T00:27:26.179863: step 8141, loss 0.598813.
Train: 2018-08-01T00:27:26.336077: step 8142, loss 0.616883.
Train: 2018-08-01T00:27:26.492300: step 8143, loss 0.526604.
Train: 2018-08-01T00:27:26.664100: step 8144, loss 0.598774.
Train: 2018-08-01T00:27:26.820314: step 8145, loss 0.454539.
Train: 2018-08-01T00:27:26.976528: step 8146, loss 0.562687.
Train: 2018-08-01T00:27:27.132741: step 8147, loss 0.616802.
Train: 2018-08-01T00:27:27.288984: step 8148, loss 0.526632.
Train: 2018-08-01T00:27:27.445200: step 8149, loss 0.65278.
Train: 2018-08-01T00:27:27.601411: step 8150, loss 0.580651.
Test: 2018-08-01T00:27:28.085676: step 8150, loss 0.547603.
Train: 2018-08-01T00:27:28.241855: step 8151, loss 0.580595.
Train: 2018-08-01T00:27:28.398099: step 8152, loss 0.723882.
Train: 2018-08-01T00:27:28.554313: step 8153, loss 0.580416.
Train: 2018-08-01T00:27:28.710530: step 8154, loss 0.527006.
Train: 2018-08-01T00:27:28.882362: step 8155, loss 0.509398.
Train: 2018-08-01T00:27:29.038569: step 8156, loss 0.491852.
Train: 2018-08-01T00:27:29.194789: step 8157, loss 0.456662.
Train: 2018-08-01T00:27:29.350971: step 8158, loss 0.615409.
Train: 2018-08-01T00:27:29.522836: step 8159, loss 0.544851.
Train: 2018-08-01T00:27:29.679044: step 8160, loss 0.632969.
Test: 2018-08-01T00:27:30.147691: step 8160, loss 0.547734.
Train: 2018-08-01T00:27:30.303903: step 8161, loss 0.66805.
Train: 2018-08-01T00:27:30.460088: step 8162, loss 0.509818.
Train: 2018-08-01T00:27:30.616299: step 8163, loss 0.544933.
Train: 2018-08-01T00:27:30.772543: step 8164, loss 0.509988.
Train: 2018-08-01T00:27:30.928727: step 8165, loss 0.562433.
Train: 2018-08-01T00:27:31.100562: step 8166, loss 0.614803.
Train: 2018-08-01T00:27:31.241155: step 8167, loss 0.562424.
Train: 2018-08-01T00:27:31.397397: step 8168, loss 0.632051.
Train: 2018-08-01T00:27:31.553610: step 8169, loss 0.64925.
Train: 2018-08-01T00:27:31.709795: step 8170, loss 0.666252.
Test: 2018-08-01T00:27:32.178464: step 8170, loss 0.547972.
Train: 2018-08-01T00:27:32.334647: step 8171, loss 0.562397.
Train: 2018-08-01T00:27:32.490860: step 8172, loss 0.57955.
Train: 2018-08-01T00:27:32.647075: step 8173, loss 0.545313.
Train: 2018-08-01T00:27:32.803287: step 8174, loss 0.579428.
Train: 2018-08-01T00:27:32.959500: step 8175, loss 0.613316.
Train: 2018-08-01T00:27:33.115715: step 8176, loss 0.66385.
Train: 2018-08-01T00:27:33.287583: step 8177, loss 0.528795.
Train: 2018-08-01T00:27:33.443793: step 8178, loss 0.44516.
Train: 2018-08-01T00:27:33.600007: step 8179, loss 0.545734.
Train: 2018-08-01T00:27:33.756220: step 8180, loss 0.579185.
Test: 2018-08-01T00:27:34.224830: step 8180, loss 0.548497.
Train: 2018-08-01T00:27:34.396700: step 8181, loss 0.545782.
Train: 2018-08-01T00:27:34.552877: step 8182, loss 0.512426.
Train: 2018-08-01T00:27:34.709125: step 8183, loss 0.428954.
Train: 2018-08-01T00:27:34.865336: step 8184, loss 0.64613.
Train: 2018-08-01T00:27:35.021548: step 8185, loss 0.562459.
Train: 2018-08-01T00:27:35.177732: step 8186, loss 0.461851.
Train: 2018-08-01T00:27:35.333974: step 8187, loss 0.579252.
Train: 2018-08-01T00:27:35.505780: step 8188, loss 0.562433.
Train: 2018-08-01T00:27:35.661993: step 8189, loss 0.562425.
Train: 2018-08-01T00:27:35.818207: step 8190, loss 0.646971.
Test: 2018-08-01T00:27:36.286877: step 8190, loss 0.548252.
Train: 2018-08-01T00:27:36.443060: step 8191, loss 0.545501.
Train: 2018-08-01T00:27:36.614895: step 8192, loss 0.579343.
Train: 2018-08-01T00:27:36.771108: step 8193, loss 0.596282.
Train: 2018-08-01T00:27:36.927321: step 8194, loss 0.697866.
Train: 2018-08-01T00:27:37.099156: step 8195, loss 0.494845.
Train: 2018-08-01T00:27:37.239780: step 8196, loss 0.596184.
Train: 2018-08-01T00:27:37.395987: step 8197, loss 0.629862.
Train: 2018-08-01T00:27:37.567827: step 8198, loss 0.511972.
Train: 2018-08-01T00:27:37.739632: step 8199, loss 0.579248.
Train: 2018-08-01T00:27:37.895876: step 8200, loss 0.663159.
Test: 2018-08-01T00:27:38.364516: step 8200, loss 0.548442.
Train: 2018-08-01T00:27:39.098689: step 8201, loss 0.579204.
Train: 2018-08-01T00:27:39.254902: step 8202, loss 0.545775.
Train: 2018-08-01T00:27:39.411145: step 8203, loss 0.595826.
Train: 2018-08-01T00:27:39.567363: step 8204, loss 0.545867.
Train: 2018-08-01T00:27:39.723573: step 8205, loss 0.628944.
Train: 2018-08-01T00:27:39.879783: step 8206, loss 0.595667.
Train: 2018-08-01T00:27:40.051591: step 8207, loss 0.61213.
Train: 2018-08-01T00:27:40.207803: step 8208, loss 0.496663.
Train: 2018-08-01T00:27:40.364047: step 8209, loss 0.546133.
Train: 2018-08-01T00:27:40.535877: step 8210, loss 0.447521.
Test: 2018-08-01T00:27:41.004522: step 8210, loss 0.5488.
Train: 2018-08-01T00:27:41.160706: step 8211, loss 0.496745.
Train: 2018-08-01T00:27:41.316949: step 8212, loss 0.59556.
Train: 2018-08-01T00:27:41.473162: step 8213, loss 0.529496.
Train: 2018-08-01T00:27:41.644998: step 8214, loss 0.545968.
Train: 2018-08-01T00:27:41.801212: step 8215, loss 0.612322.
Train: 2018-08-01T00:27:41.973058: step 8216, loss 0.545877.
Train: 2018-08-01T00:27:42.144880: step 8217, loss 0.47922.
Train: 2018-08-01T00:27:42.301064: step 8218, loss 0.612586.
Train: 2018-08-01T00:27:42.457277: step 8219, loss 0.595936.
Train: 2018-08-01T00:27:42.613490: step 8220, loss 0.629488.
Test: 2018-08-01T00:27:43.097766: step 8220, loss 0.548421.
Train: 2018-08-01T00:27:43.253965: step 8221, loss 0.495412.
Train: 2018-08-01T00:27:43.425800: step 8222, loss 0.596015.
Train: 2018-08-01T00:27:43.566393: step 8223, loss 0.495266.
Train: 2018-08-01T00:27:43.738228: step 8224, loss 0.511963.
Train: 2018-08-01T00:27:43.878849: step 8225, loss 0.613028.
Train: 2018-08-01T00:27:44.050684: step 8226, loss 0.528639.
Train: 2018-08-01T00:27:44.222490: step 8227, loss 0.562416.
Train: 2018-08-01T00:27:44.378732: step 8228, loss 0.477641.
Train: 2018-08-01T00:27:44.534946: step 8229, loss 0.528396.
Train: 2018-08-01T00:27:44.691160: step 8230, loss 0.545341.
Test: 2018-08-01T00:27:45.159799: step 8230, loss 0.548066.
Train: 2018-08-01T00:27:45.331604: step 8231, loss 0.528171.
Train: 2018-08-01T00:27:45.487848: step 8232, loss 0.613905.
Train: 2018-08-01T00:27:45.644061: step 8233, loss 0.63123.
Train: 2018-08-01T00:27:45.815865: step 8234, loss 0.527948.
Train: 2018-08-01T00:27:45.972109: step 8235, loss 0.596895.
Train: 2018-08-01T00:27:46.128323: step 8236, loss 0.5624.
Train: 2018-08-01T00:27:46.284536: step 8237, loss 0.510589.
Train: 2018-08-01T00:27:46.471992: step 8238, loss 0.562402.
Train: 2018-08-01T00:27:46.628206: step 8239, loss 0.614343.
Train: 2018-08-01T00:27:46.784419: step 8240, loss 0.614354.
Test: 2018-08-01T00:27:47.253059: step 8240, loss 0.547912.
Train: 2018-08-01T00:27:47.409273: step 8241, loss 0.562404.
Train: 2018-08-01T00:27:47.581078: step 8242, loss 0.61429.
Train: 2018-08-01T00:27:47.737315: step 8243, loss 0.562401.
Train: 2018-08-01T00:27:47.893534: step 8244, loss 0.68316.
Train: 2018-08-01T00:27:48.065371: step 8245, loss 0.527994.
Train: 2018-08-01T00:27:48.221582: step 8246, loss 0.493739.
Train: 2018-08-01T00:27:48.377766: step 8247, loss 0.528098.
Train: 2018-08-01T00:27:48.533979: step 8248, loss 0.459531.
Train: 2018-08-01T00:27:48.705814: step 8249, loss 0.631063.
Train: 2018-08-01T00:27:48.862057: step 8250, loss 0.579565.
Test: 2018-08-01T00:27:49.330701: step 8250, loss 0.54802.
Train: 2018-08-01T00:27:49.486911: step 8251, loss 0.528061.
Train: 2018-08-01T00:27:49.658717: step 8252, loss 0.579569.
Train: 2018-08-01T00:27:49.830550: step 8253, loss 0.562396.
Train: 2018-08-01T00:27:49.986795: step 8254, loss 0.716987.
Train: 2018-08-01T00:27:50.143007: step 8255, loss 0.476707.
Train: 2018-08-01T00:27:50.299190: step 8256, loss 0.596646.
Train: 2018-08-01T00:27:50.455438: step 8257, loss 0.596606.
Train: 2018-08-01T00:27:50.627272: step 8258, loss 0.528242.
Train: 2018-08-01T00:27:50.783452: step 8259, loss 0.579461.
Train: 2018-08-01T00:27:50.955286: step 8260, loss 0.5624.
Test: 2018-08-01T00:27:51.423957: step 8260, loss 0.548142.
Train: 2018-08-01T00:27:51.580175: step 8261, loss 0.494285.
Train: 2018-08-01T00:27:51.736384: step 8262, loss 0.494267.
Train: 2018-08-01T00:27:51.892594: step 8263, loss 0.664734.
Train: 2018-08-01T00:27:52.048811: step 8264, loss 0.528301.
Train: 2018-08-01T00:27:52.204995: step 8265, loss 0.5624.
Train: 2018-08-01T00:27:52.361207: step 8266, loss 0.460063.
Train: 2018-08-01T00:27:52.517451: step 8267, loss 0.476965.
Train: 2018-08-01T00:27:52.673665: step 8268, loss 0.562396.
Train: 2018-08-01T00:27:52.829847: step 8269, loss 0.562396.
Train: 2018-08-01T00:27:52.986062: step 8270, loss 0.493511.
Test: 2018-08-01T00:27:53.454736: step 8270, loss 0.547935.
Train: 2018-08-01T00:27:53.610941: step 8271, loss 0.510574.
Train: 2018-08-01T00:27:53.767159: step 8272, loss 0.493059.
Train: 2018-08-01T00:27:53.923367: step 8273, loss 0.61465.
Train: 2018-08-01T00:27:54.095177: step 8274, loss 0.632276.
Train: 2018-08-01T00:27:54.251391: step 8275, loss 0.544949.
Train: 2018-08-01T00:27:54.407634: step 8276, loss 0.49238.
Train: 2018-08-01T00:27:54.563842: step 8277, loss 0.650246.
Train: 2018-08-01T00:27:54.720031: step 8278, loss 0.509747.
Train: 2018-08-01T00:27:54.876274: step 8279, loss 0.668044.
Train: 2018-08-01T00:27:55.048079: step 8280, loss 0.527288.
Test: 2018-08-01T00:27:55.516749: step 8280, loss 0.547737.
Train: 2018-08-01T00:27:55.672962: step 8281, loss 0.668014.
Train: 2018-08-01T00:27:55.844797: step 8282, loss 0.52733.
Train: 2018-08-01T00:27:56.000980: step 8283, loss 0.562454.
Train: 2018-08-01T00:27:56.157219: step 8284, loss 0.579981.
Train: 2018-08-01T00:27:56.329068: step 8285, loss 0.65.
Train: 2018-08-01T00:27:56.485243: step 8286, loss 0.562433.
Train: 2018-08-01T00:27:56.641486: step 8287, loss 0.510132.
Train: 2018-08-01T00:27:56.797693: step 8288, loss 0.579828.
Train: 2018-08-01T00:27:56.953907: step 8289, loss 0.545032.
Train: 2018-08-01T00:27:57.125716: step 8290, loss 0.545048.
Test: 2018-08-01T00:27:57.594388: step 8290, loss 0.547881.
Train: 2018-08-01T00:27:57.750601: step 8291, loss 0.56241.
Train: 2018-08-01T00:27:57.906785: step 8292, loss 0.527734.
Train: 2018-08-01T00:27:58.062997: step 8293, loss 0.649076.
Train: 2018-08-01T00:27:58.219241: step 8294, loss 0.579712.
Train: 2018-08-01T00:27:58.375449: step 8295, loss 0.458725.
Train: 2018-08-01T00:27:58.547260: step 8296, loss 0.527841.
Train: 2018-08-01T00:27:58.703473: step 8297, loss 0.510533.
Train: 2018-08-01T00:27:58.875337: step 8298, loss 0.562405.
Train: 2018-08-01T00:27:59.031521: step 8299, loss 0.475758.
Train: 2018-08-01T00:27:59.172112: step 8300, loss 0.562413.
Test: 2018-08-01T00:27:59.656373: step 8300, loss 0.547846.
Train: 2018-08-01T00:28:00.374956: step 8301, loss 0.562419.
Train: 2018-08-01T00:28:00.531200: step 8302, loss 0.492695.
Train: 2018-08-01T00:28:00.703004: step 8303, loss 0.579911.
Train: 2018-08-01T00:28:00.859248: step 8304, loss 0.579953.
Train: 2018-08-01T00:28:01.015431: step 8305, loss 0.56245.
Train: 2018-08-01T00:28:01.171669: step 8306, loss 0.632681.
Train: 2018-08-01T00:28:01.327892: step 8307, loss 0.580012.
Train: 2018-08-01T00:28:01.484071: step 8308, loss 0.492256.
Train: 2018-08-01T00:28:01.640285: step 8309, loss 0.667821.
Train: 2018-08-01T00:28:01.812150: step 8310, loss 0.579995.
Test: 2018-08-01T00:28:02.280790: step 8310, loss 0.547775.
Train: 2018-08-01T00:28:02.452619: step 8311, loss 0.685085.
Train: 2018-08-01T00:28:02.608807: step 8312, loss 0.614834.
Train: 2018-08-01T00:28:02.765052: step 8313, loss 0.492798.
Train: 2018-08-01T00:28:02.952478: step 8314, loss 0.475579.
Train: 2018-08-01T00:28:03.093070: step 8315, loss 0.492996.
Train: 2018-08-01T00:28:03.249282: step 8316, loss 0.545052.
Train: 2018-08-01T00:28:03.405496: step 8317, loss 0.753457.
Train: 2018-08-01T00:28:03.561709: step 8318, loss 0.458452.
Train: 2018-08-01T00:28:03.717923: step 8319, loss 0.562405.
Train: 2018-08-01T00:28:03.889760: step 8320, loss 0.545101.
Test: 2018-08-01T00:28:04.374020: step 8320, loss 0.547919.
Train: 2018-08-01T00:28:04.530267: step 8321, loss 0.45862.
Train: 2018-08-01T00:28:04.686447: step 8322, loss 0.597041.
Train: 2018-08-01T00:28:04.842659: step 8323, loss 0.527752.
Train: 2018-08-01T00:28:05.014496: step 8324, loss 0.52772.
Train: 2018-08-01T00:28:05.186354: step 8325, loss 0.57978.
Train: 2018-08-01T00:28:05.342543: step 8326, loss 0.475498.
Train: 2018-08-01T00:28:05.498757: step 8327, loss 0.492745.
Train: 2018-08-01T00:28:05.655000: step 8328, loss 0.544964.
Train: 2018-08-01T00:28:05.811183: step 8329, loss 0.579961.
Train: 2018-08-01T00:28:05.967430: step 8330, loss 0.597562.
Test: 2018-08-01T00:28:06.451657: step 8330, loss 0.547745.
Train: 2018-08-01T00:28:06.607871: step 8331, loss 0.580039.
Train: 2018-08-01T00:28:06.764084: step 8332, loss 0.474511.
Train: 2018-08-01T00:28:06.920323: step 8333, loss 0.68586.
Train: 2018-08-01T00:28:07.076546: step 8334, loss 0.597726.
Train: 2018-08-01T00:28:07.248380: step 8335, loss 0.580086.
Train: 2018-08-01T00:28:07.388969: step 8336, loss 0.544874.
Train: 2018-08-01T00:28:07.545151: step 8337, loss 0.509718.
Train: 2018-08-01T00:28:07.701399: step 8338, loss 0.65038.
Train: 2018-08-01T00:28:07.857609: step 8339, loss 0.562458.
Train: 2018-08-01T00:28:08.029414: step 8340, loss 0.509837.
Test: 2018-08-01T00:28:08.498053: step 8340, loss 0.547769.
Train: 2018-08-01T00:28:08.654299: step 8341, loss 0.597509.
Train: 2018-08-01T00:28:08.810480: step 8342, loss 0.527418.
Train: 2018-08-01T00:28:08.966693: step 8343, loss 0.509927.
Train: 2018-08-01T00:28:09.122907: step 8344, loss 0.474892.
Train: 2018-08-01T00:28:09.279122: step 8345, loss 0.439699.
Train: 2018-08-01T00:28:09.450990: step 8346, loss 0.615234.
Train: 2018-08-01T00:28:09.607168: step 8347, loss 0.632966.
Train: 2018-08-01T00:28:09.763414: step 8348, loss 0.562482.
Train: 2018-08-01T00:28:09.919626: step 8349, loss 0.615404.
Train: 2018-08-01T00:28:10.075810: step 8350, loss 0.527218.
Test: 2018-08-01T00:28:10.560071: step 8350, loss 0.547717.
Train: 2018-08-01T00:28:10.716314: step 8351, loss 0.562482.
Train: 2018-08-01T00:28:10.872498: step 8352, loss 0.474332.
Train: 2018-08-01T00:28:11.028742: step 8353, loss 0.438945.
Train: 2018-08-01T00:28:11.184949: step 8354, loss 0.597898.
Train: 2018-08-01T00:28:11.341163: step 8355, loss 0.509338.
Train: 2018-08-01T00:28:11.497382: step 8356, loss 0.420403.
Train: 2018-08-01T00:28:11.669187: step 8357, loss 0.580408.
Train: 2018-08-01T00:28:11.809779: step 8358, loss 0.419469.
Train: 2018-08-01T00:28:11.981643: step 8359, loss 0.544676.
Train: 2018-08-01T00:28:12.137857: step 8360, loss 0.5627.
Test: 2018-08-01T00:28:12.606497: step 8360, loss 0.547575.
Train: 2018-08-01T00:28:12.793922: step 8361, loss 0.580863.
Train: 2018-08-01T00:28:12.950171: step 8362, loss 0.599121.
Train: 2018-08-01T00:28:13.090759: step 8363, loss 0.490002.
Train: 2018-08-01T00:28:13.246943: step 8364, loss 0.617589.
Train: 2018-08-01T00:28:13.403155: step 8365, loss 0.599408.
Train: 2018-08-01T00:28:13.575015: step 8366, loss 0.43492.
Train: 2018-08-01T00:28:13.731234: step 8367, loss 0.691102.
Train: 2018-08-01T00:28:13.903038: step 8368, loss 0.507969.
Train: 2018-08-01T00:28:14.059282: step 8369, loss 0.672807.
Train: 2018-08-01T00:28:14.215495: step 8370, loss 0.526301.
Test: 2018-08-01T00:28:14.730999: step 8370, loss 0.547567.
Train: 2018-08-01T00:28:14.918456: step 8371, loss 0.599419.
Train: 2018-08-01T00:28:15.059048: step 8372, loss 0.617586.
Train: 2018-08-01T00:28:15.230852: step 8373, loss 0.562812.
Train: 2018-08-01T00:28:15.387097: step 8374, loss 0.56278.
Train: 2018-08-01T00:28:15.543280: step 8375, loss 0.617115.
Train: 2018-08-01T00:28:15.699492: step 8376, loss 0.634985.
Train: 2018-08-01T00:28:15.855705: step 8377, loss 0.526667.
Train: 2018-08-01T00:28:16.043192: step 8378, loss 0.562631.
Train: 2018-08-01T00:28:16.183784: step 8379, loss 0.616273.
Train: 2018-08-01T00:28:16.339967: step 8380, loss 0.526913.
Test: 2018-08-01T00:28:16.824229: step 8380, loss 0.547656.
Train: 2018-08-01T00:28:16.980475: step 8381, loss 0.491436.
Train: 2018-08-01T00:28:17.136655: step 8382, loss 0.615769.
Train: 2018-08-01T00:28:17.292870: step 8383, loss 0.456282.
Train: 2018-08-01T00:28:17.449117: step 8384, loss 0.580196.
Train: 2018-08-01T00:28:17.620917: step 8385, loss 0.633191.
Train: 2018-08-01T00:28:17.777161: step 8386, loss 0.509571.
Train: 2018-08-01T00:28:17.933375: step 8387, loss 0.544859.
Train: 2018-08-01T00:28:18.089588: step 8388, loss 0.685682.
Train: 2018-08-01T00:28:18.261431: step 8389, loss 0.580011.
Train: 2018-08-01T00:28:18.417605: step 8390, loss 0.649979.
Test: 2018-08-01T00:28:18.886276: step 8390, loss 0.547822.
Train: 2018-08-01T00:28:19.042490: step 8391, loss 0.63219.
Train: 2018-08-01T00:28:19.198672: step 8392, loss 0.527686.
Train: 2018-08-01T00:28:19.386160: step 8393, loss 0.597004.
Train: 2018-08-01T00:28:19.542342: step 8394, loss 0.458989.
Train: 2018-08-01T00:28:19.698590: step 8395, loss 0.51079.
Train: 2018-08-01T00:28:19.870421: step 8396, loss 0.682698.
Train: 2018-08-01T00:28:20.011016: step 8397, loss 0.596676.
Train: 2018-08-01T00:28:20.182819: step 8398, loss 0.579488.
Train: 2018-08-01T00:28:20.370275: step 8399, loss 0.443111.
Train: 2018-08-01T00:28:20.510866: step 8400, loss 0.545373.
Test: 2018-08-01T00:28:20.995127: step 8400, loss 0.548148.
Train: 2018-08-01T00:28:21.666876: step 8401, loss 0.528358.
Train: 2018-08-01T00:28:21.838714: step 8402, loss 0.511326.
Train: 2018-08-01T00:28:21.994917: step 8403, loss 0.579443.
Train: 2018-08-01T00:28:22.151106: step 8404, loss 0.545346.
Train: 2018-08-01T00:28:22.307350: step 8405, loss 0.613602.
Train: 2018-08-01T00:28:22.463558: step 8406, loss 0.528262.
Train: 2018-08-01T00:28:22.635395: step 8407, loss 0.54532.
Train: 2018-08-01T00:28:22.791612: step 8408, loss 0.476944.
Train: 2018-08-01T00:28:22.947795: step 8409, loss 0.545271.
Train: 2018-08-01T00:28:23.088417: step 8410, loss 0.596716.
Test: 2018-08-01T00:28:23.557058: step 8410, loss 0.548007.
Train: 2018-08-01T00:28:23.728887: step 8411, loss 0.528029.
Train: 2018-08-01T00:28:23.885075: step 8412, loss 0.579609.
Train: 2018-08-01T00:28:24.041319: step 8413, loss 0.717509.
Train: 2018-08-01T00:28:24.197536: step 8414, loss 0.527968.
Train: 2018-08-01T00:28:24.353746: step 8415, loss 0.614009.
Train: 2018-08-01T00:28:24.509960: step 8416, loss 0.510849.
Train: 2018-08-01T00:28:24.666173: step 8417, loss 0.528045.
Train: 2018-08-01T00:28:24.837977: step 8418, loss 0.476506.
Train: 2018-08-01T00:28:24.994215: step 8419, loss 0.527991.
Train: 2018-08-01T00:28:25.150434: step 8420, loss 0.596864.
Test: 2018-08-01T00:28:25.634697: step 8420, loss 0.547953.
Train: 2018-08-01T00:28:25.853394: step 8421, loss 0.545147.
Train: 2018-08-01T00:28:26.009614: step 8422, loss 0.596946.
Train: 2018-08-01T00:28:26.165822: step 8423, loss 0.545119.
Train: 2018-08-01T00:28:26.306413: step 8424, loss 0.562403.
Train: 2018-08-01T00:28:26.462598: step 8425, loss 0.648931.
Train: 2018-08-01T00:28:26.618811: step 8426, loss 0.579695.
Train: 2018-08-01T00:28:26.775023: step 8427, loss 0.666056.
Train: 2018-08-01T00:28:26.931238: step 8428, loss 0.580781.
Train: 2018-08-01T00:28:27.103072: step 8429, loss 0.562396.
Train: 2018-08-01T00:28:27.274931: step 8430, loss 0.596701.
Test: 2018-08-01T00:28:27.727955: step 8430, loss 0.54807.
Train: 2018-08-01T00:28:27.899760: step 8431, loss 0.647941.
Train: 2018-08-01T00:28:28.087247: step 8432, loss 0.511257.
Train: 2018-08-01T00:28:28.243429: step 8433, loss 0.511386.
Train: 2018-08-01T00:28:28.415265: step 8434, loss 0.460511.
Train: 2018-08-01T00:28:28.555856: step 8435, loss 0.562406.
Train: 2018-08-01T00:28:28.727722: step 8436, loss 0.477432.
Train: 2018-08-01T00:28:28.883905: step 8437, loss 0.579425.
Train: 2018-08-01T00:28:29.040118: step 8438, loss 0.460134.
Train: 2018-08-01T00:28:29.227575: step 8439, loss 0.476944.
Train: 2018-08-01T00:28:29.383819: step 8440, loss 0.57955.
Test: 2018-08-01T00:28:29.852461: step 8440, loss 0.547987.
Train: 2018-08-01T00:28:30.008672: step 8441, loss 0.562396.
Train: 2018-08-01T00:28:30.164885: step 8442, loss 0.665932.
Train: 2018-08-01T00:28:30.352312: step 8443, loss 0.424229.
Train: 2018-08-01T00:28:30.508525: step 8444, loss 0.597047.
Train: 2018-08-01T00:28:30.664739: step 8445, loss 0.64919.
Train: 2018-08-01T00:28:30.820985: step 8446, loss 0.579776.
Train: 2018-08-01T00:28:30.992817: step 8447, loss 0.614514.
Train: 2018-08-01T00:28:31.149030: step 8448, loss 0.597122.
Train: 2018-08-01T00:28:31.305215: step 8449, loss 0.527736.
Train: 2018-08-01T00:28:31.477072: step 8450, loss 0.493102.
Test: 2018-08-01T00:28:31.945688: step 8450, loss 0.547892.
Train: 2018-08-01T00:28:32.101901: step 8451, loss 0.475735.
Train: 2018-08-01T00:28:32.258114: step 8452, loss 0.527685.
Train: 2018-08-01T00:28:32.429950: step 8453, loss 0.475428.
Train: 2018-08-01T00:28:32.586162: step 8454, loss 0.632229.
Train: 2018-08-01T00:28:32.742376: step 8455, loss 0.562435.
Train: 2018-08-01T00:28:32.898624: step 8456, loss 0.579944.
Train: 2018-08-01T00:28:33.054828: step 8457, loss 0.579965.
Train: 2018-08-01T00:28:33.211017: step 8458, loss 0.492335.
Train: 2018-08-01T00:28:33.367261: step 8459, loss 0.509797.
Train: 2018-08-01T00:28:33.539065: step 8460, loss 0.615227.
Test: 2018-08-01T00:28:34.007735: step 8460, loss 0.547731.
Train: 2018-08-01T00:28:34.163919: step 8461, loss 0.49206.
Train: 2018-08-01T00:28:34.320132: step 8462, loss 0.544849.
Train: 2018-08-01T00:28:34.476345: step 8463, loss 0.580158.
Train: 2018-08-01T00:28:34.648180: step 8464, loss 0.544817.
Train: 2018-08-01T00:28:34.804394: step 8465, loss 0.509391.
Train: 2018-08-01T00:28:34.976254: step 8466, loss 0.544787.
Train: 2018-08-01T00:28:35.132472: step 8467, loss 0.562538.
Train: 2018-08-01T00:28:35.273064: step 8468, loss 0.580344.
Train: 2018-08-01T00:28:35.444903: step 8469, loss 0.615987.
Train: 2018-08-01T00:28:35.601081: step 8470, loss 0.615983.
Test: 2018-08-01T00:28:36.069722: step 8470, loss 0.547651.
Train: 2018-08-01T00:28:36.225966: step 8471, loss 0.580342.
Train: 2018-08-01T00:28:36.382180: step 8472, loss 0.633623.
Train: 2018-08-01T00:28:36.538393: step 8473, loss 0.54479.
Train: 2018-08-01T00:28:36.694605: step 8474, loss 0.633304.
Train: 2018-08-01T00:28:36.866411: step 8475, loss 0.580138.
Train: 2018-08-01T00:28:37.007002: step 8476, loss 0.58007.
Train: 2018-08-01T00:28:37.163255: step 8477, loss 0.580003.
Train: 2018-08-01T00:28:37.335052: step 8478, loss 0.56244.
Train: 2018-08-01T00:28:37.475643: step 8479, loss 0.597326.
Train: 2018-08-01T00:28:37.647478: step 8480, loss 0.666792.
Test: 2018-08-01T00:28:38.116148: step 8480, loss 0.547902.
Train: 2018-08-01T00:28:38.272362: step 8481, loss 0.545085.
Train: 2018-08-01T00:28:38.428575: step 8482, loss 0.476115.
Train: 2018-08-01T00:28:38.584788: step 8483, loss 0.545176.
Train: 2018-08-01T00:28:38.741002: step 8484, loss 0.613976.
Train: 2018-08-01T00:28:38.897215: step 8485, loss 0.47662.
Train: 2018-08-01T00:28:39.069051: step 8486, loss 0.596681.
Train: 2018-08-01T00:28:39.225233: step 8487, loss 0.545273.
Train: 2018-08-01T00:28:39.381446: step 8488, loss 0.562396.
Train: 2018-08-01T00:28:39.537660: step 8489, loss 0.528202.
Train: 2018-08-01T00:28:39.709494: step 8490, loss 0.562397.
Test: 2018-08-01T00:28:40.178165: step 8490, loss 0.548082.
Train: 2018-08-01T00:28:40.334373: step 8491, loss 0.664965.
Train: 2018-08-01T00:28:40.506183: step 8492, loss 0.562398.
Train: 2018-08-01T00:28:40.662396: step 8493, loss 0.511273.
Train: 2018-08-01T00:28:40.818610: step 8494, loss 0.47723.
Train: 2018-08-01T00:28:40.974823: step 8495, loss 0.630597.
Train: 2018-08-01T00:28:41.131065: step 8496, loss 0.579446.
Train: 2018-08-01T00:28:41.318493: step 8497, loss 0.528325.
Train: 2018-08-01T00:28:41.474740: step 8498, loss 0.477197.
Train: 2018-08-01T00:28:41.630919: step 8499, loss 0.562399.
Train: 2018-08-01T00:28:41.787134: step 8500, loss 0.596574.
Test: 2018-08-01T00:28:42.255773: step 8500, loss 0.548077.
Train: 2018-08-01T00:28:43.021250: step 8501, loss 0.596597.
Train: 2018-08-01T00:28:43.177465: step 8502, loss 0.545294.
Train: 2018-08-01T00:28:43.333648: step 8503, loss 0.613723.
Train: 2018-08-01T00:28:43.505506: step 8504, loss 0.579498.
Train: 2018-08-01T00:28:43.661694: step 8505, loss 0.613668.
Train: 2018-08-01T00:28:43.817942: step 8506, loss 0.528264.
Train: 2018-08-01T00:28:43.974151: step 8507, loss 0.528288.
Train: 2018-08-01T00:28:44.145989: step 8508, loss 0.52829.
Train: 2018-08-01T00:28:44.302170: step 8509, loss 0.545336.
Train: 2018-08-01T00:28:44.458420: step 8510, loss 0.681925.
Test: 2018-08-01T00:28:44.927053: step 8510, loss 0.548118.
Train: 2018-08-01T00:28:45.083237: step 8511, loss 0.630621.
Train: 2018-08-01T00:28:45.255072: step 8512, loss 0.562403.
Train: 2018-08-01T00:28:45.411285: step 8513, loss 0.52843.
Train: 2018-08-01T00:28:45.567499: step 8514, loss 0.596348.
Train: 2018-08-01T00:28:45.723711: step 8515, loss 0.63019.
Train: 2018-08-01T00:28:45.879951: step 8516, loss 0.494802.
Train: 2018-08-01T00:28:46.036138: step 8517, loss 0.494874.
Train: 2018-08-01T00:28:46.208003: step 8518, loss 0.528641.
Train: 2018-08-01T00:28:46.364186: step 8519, loss 0.613131.
Train: 2018-08-01T00:28:46.520400: step 8520, loss 0.545517.
Test: 2018-08-01T00:28:46.989070: step 8520, loss 0.548261.
Train: 2018-08-01T00:28:47.145285: step 8521, loss 0.630049.
Train: 2018-08-01T00:28:47.301500: step 8522, loss 0.562422.
Train: 2018-08-01T00:28:47.473332: step 8523, loss 0.545541.
Train: 2018-08-01T00:28:47.629545: step 8524, loss 0.478028.
Train: 2018-08-01T00:28:47.785729: step 8525, loss 0.545522.
Train: 2018-08-01T00:28:47.941943: step 8526, loss 0.630104.
Train: 2018-08-01T00:28:48.113776: step 8527, loss 0.545491.
Train: 2018-08-01T00:28:48.269990: step 8528, loss 0.579348.
Train: 2018-08-01T00:28:48.410612: step 8529, loss 0.630165.
Train: 2018-08-01T00:28:48.566830: step 8530, loss 0.647036.
Test: 2018-08-01T00:28:49.051087: step 8530, loss 0.548279.
Train: 2018-08-01T00:28:49.207271: step 8531, loss 0.596203.
Train: 2018-08-01T00:28:49.363514: step 8532, loss 0.511876.
Train: 2018-08-01T00:28:49.519728: step 8533, loss 0.562436.
Train: 2018-08-01T00:28:49.691567: step 8534, loss 0.579255.
Train: 2018-08-01T00:28:49.847772: step 8535, loss 0.54565.
Train: 2018-08-01T00:28:50.035233: step 8536, loss 0.596018.
Train: 2018-08-01T00:28:50.191450: step 8537, loss 0.512153.
Train: 2018-08-01T00:28:50.347665: step 8538, loss 0.629518.
Train: 2018-08-01T00:28:50.503843: step 8539, loss 0.512214.
Train: 2018-08-01T00:28:50.660055: step 8540, loss 0.478722.
Test: 2018-08-01T00:28:51.128695: step 8540, loss 0.54841.
Train: 2018-08-01T00:28:51.300563: step 8541, loss 0.562453.
Train: 2018-08-01T00:28:51.456743: step 8542, loss 0.545654.
Train: 2018-08-01T00:28:51.612988: step 8543, loss 0.579258.
Train: 2018-08-01T00:28:51.769207: step 8544, loss 0.495082.
Train: 2018-08-01T00:28:51.925414: step 8545, loss 0.579301.
Train: 2018-08-01T00:28:52.081629: step 8546, loss 0.494802.
Train: 2018-08-01T00:28:52.237811: step 8547, loss 0.596312.
Train: 2018-08-01T00:28:52.394055: step 8548, loss 0.57939.
Train: 2018-08-01T00:28:52.550270: step 8549, loss 0.477362.
Train: 2018-08-01T00:28:52.706452: step 8550, loss 0.5624.
Test: 2018-08-01T00:28:53.175119: step 8550, loss 0.548081.
Train: 2018-08-01T00:28:53.346962: step 8551, loss 0.562397.
Train: 2018-08-01T00:28:53.503164: step 8552, loss 0.476726.
Train: 2018-08-01T00:28:53.675009: step 8553, loss 0.528015.
Train: 2018-08-01T00:28:53.831220: step 8554, loss 0.596899.
Train: 2018-08-01T00:28:53.987402: step 8555, loss 0.545108.
Train: 2018-08-01T00:28:54.128024: step 8556, loss 0.493053.
Train: 2018-08-01T00:28:54.299830: step 8557, loss 0.545021.
Train: 2018-08-01T00:28:54.471663: step 8558, loss 0.510076.
Train: 2018-08-01T00:28:54.612286: step 8559, loss 0.59747.
Train: 2018-08-01T00:28:54.784090: step 8560, loss 0.457106.
Test: 2018-08-01T00:28:55.252730: step 8560, loss 0.54772.
Train: 2018-08-01T00:28:55.424566: step 8561, loss 0.544854.
Train: 2018-08-01T00:28:55.580809: step 8562, loss 0.633256.
Train: 2018-08-01T00:28:55.737022: step 8563, loss 0.615693.
Train: 2018-08-01T00:28:55.893204: step 8564, loss 0.615754.
Train: 2018-08-01T00:28:56.049419: step 8565, loss 0.509298.
Train: 2018-08-01T00:28:56.205633: step 8566, loss 0.491513.
Train: 2018-08-01T00:28:56.361875: step 8567, loss 0.5092.
Train: 2018-08-01T00:28:56.533680: step 8568, loss 0.633828.
Train: 2018-08-01T00:28:56.689923: step 8569, loss 0.63388.
Train: 2018-08-01T00:28:56.846138: step 8570, loss 0.544744.
Test: 2018-08-01T00:28:57.314782: step 8570, loss 0.547644.
Train: 2018-08-01T00:28:57.470991: step 8571, loss 0.509124.
Train: 2018-08-01T00:28:57.642797: step 8572, loss 0.491295.
Train: 2018-08-01T00:28:57.799041: step 8573, loss 0.669595.
Train: 2018-08-01T00:28:57.955252: step 8574, loss 0.580393.
Train: 2018-08-01T00:28:58.111467: step 8575, loss 0.580368.
Train: 2018-08-01T00:28:58.267674: step 8576, loss 0.633699.
Train: 2018-08-01T00:28:58.439485: step 8577, loss 0.580277.
Train: 2018-08-01T00:28:58.595697: step 8578, loss 0.456275.
Train: 2018-08-01T00:28:58.767531: step 8579, loss 0.562505.
Train: 2018-08-01T00:28:58.908155: step 8580, loss 0.54482.
Test: 2018-08-01T00:28:59.376789: step 8580, loss 0.5477.
Train: 2018-08-01T00:28:59.532979: step 8581, loss 0.527156.
Train: 2018-08-01T00:28:59.689191: step 8582, loss 0.650841.
Train: 2018-08-01T00:28:59.861026: step 8583, loss 0.562486.
Train: 2018-08-01T00:29:00.017241: step 8584, loss 0.474381.
Train: 2018-08-01T00:29:00.173479: step 8585, loss 0.544859.
Train: 2018-08-01T00:29:00.345312: step 8586, loss 0.439138.
Train: 2018-08-01T00:29:00.501501: step 8587, loss 0.597792.
Train: 2018-08-01T00:29:00.657715: step 8588, loss 0.491819.
Train: 2018-08-01T00:29:00.813928: step 8589, loss 0.4563.
Train: 2018-08-01T00:29:00.985798: step 8590, loss 0.509266.
Test: 2018-08-01T00:29:01.454402: step 8590, loss 0.547643.
Train: 2018-08-01T00:29:01.626268: step 8591, loss 0.562561.
Train: 2018-08-01T00:29:01.782481: step 8592, loss 0.508986.
Train: 2018-08-01T00:29:01.938699: step 8593, loss 0.49092.
Train: 2018-08-01T00:29:02.126145: step 8594, loss 0.616639.
Train: 2018-08-01T00:29:02.282333: step 8595, loss 0.544653.
Train: 2018-08-01T00:29:02.438547: step 8596, loss 0.635031.
Train: 2018-08-01T00:29:02.594791: step 8597, loss 0.472259.
Train: 2018-08-01T00:29:02.766595: step 8598, loss 0.50837.
Train: 2018-08-01T00:29:02.922810: step 8599, loss 0.61729.
Train: 2018-08-01T00:29:03.094644: step 8600, loss 0.544612.
Test: 2018-08-01T00:29:03.563284: step 8600, loss 0.547569.
Train: 2018-08-01T00:29:04.266281: step 8601, loss 0.526401.
Train: 2018-08-01T00:29:04.422492: step 8602, loss 0.653977.
Train: 2018-08-01T00:29:04.578696: step 8603, loss 0.635719.
Train: 2018-08-01T00:29:04.750537: step 8604, loss 0.562806.
Train: 2018-08-01T00:29:04.906719: step 8605, loss 0.562784.
Train: 2018-08-01T00:29:05.062967: step 8606, loss 0.472067.
Train: 2018-08-01T00:29:05.219176: step 8607, loss 0.50836.
Train: 2018-08-01T00:29:05.375360: step 8608, loss 0.526487.
Train: 2018-08-01T00:29:05.531574: step 8609, loss 0.580914.
Train: 2018-08-01T00:29:05.703432: step 8610, loss 0.453888.
Test: 2018-08-01T00:29:06.172078: step 8610, loss 0.54757.
Train: 2018-08-01T00:29:06.343882: step 8611, loss 0.544615.
Train: 2018-08-01T00:29:06.531364: step 8612, loss 0.562804.
Train: 2018-08-01T00:29:06.703203: step 8613, loss 0.61745.
Train: 2018-08-01T00:29:06.859387: step 8614, loss 0.69028.
Train: 2018-08-01T00:29:07.015632: step 8615, loss 0.599133.
Train: 2018-08-01T00:29:07.171839: step 8616, loss 0.617135.
Train: 2018-08-01T00:29:07.343649: step 8617, loss 0.544643.
Train: 2018-08-01T00:29:07.531131: step 8618, loss 0.54466.
Train: 2018-08-01T00:29:07.687318: step 8619, loss 0.652525.
Train: 2018-08-01T00:29:07.843532: step 8620, loss 0.670072.
Test: 2018-08-01T00:29:08.312201: step 8620, loss 0.54764.
Train: 2018-08-01T00:29:08.468410: step 8621, loss 0.473453.
Train: 2018-08-01T00:29:08.640221: step 8622, loss 0.669117.
Train: 2018-08-01T00:29:08.796434: step 8623, loss 0.597864.
Train: 2018-08-01T00:29:08.952677: step 8624, loss 0.632859.
Train: 2018-08-01T00:29:09.108891: step 8625, loss 0.64995.
Train: 2018-08-01T00:29:09.265073: step 8626, loss 0.510239.
Train: 2018-08-01T00:29:09.421287: step 8627, loss 0.562404.
Train: 2018-08-01T00:29:09.577532: step 8628, loss 0.614084.
Train: 2018-08-01T00:29:09.733748: step 8629, loss 0.648121.
Train: 2018-08-01T00:29:09.889928: step 8630, loss 0.613542.
Test: 2018-08-01T00:29:10.358598: step 8630, loss 0.548222.
Train: 2018-08-01T00:29:10.530432: step 8631, loss 0.545466.
Train: 2018-08-01T00:29:10.686650: step 8632, loss 0.545569.
Train: 2018-08-01T00:29:10.842865: step 8633, loss 0.512081.
Train: 2018-08-01T00:29:10.999042: step 8634, loss 0.512245.
Train: 2018-08-01T00:29:11.170902: step 8635, loss 0.6126.
Train: 2018-08-01T00:29:11.327090: step 8636, loss 0.562487.
Train: 2018-08-01T00:29:11.483335: step 8637, loss 0.662322.
Train: 2018-08-01T00:29:11.639548: step 8638, loss 0.496195.
Train: 2018-08-01T00:29:11.795762: step 8639, loss 0.463222.
Train: 2018-08-01T00:29:11.967601: step 8640, loss 0.57909.
Test: 2018-08-01T00:29:12.436230: step 8640, loss 0.548673.
Train: 2018-08-01T00:29:12.592451: step 8641, loss 0.57909.
Train: 2018-08-01T00:29:12.748664: step 8642, loss 0.579089.
Train: 2018-08-01T00:29:12.904871: step 8643, loss 0.529444.
Train: 2018-08-01T00:29:13.076681: step 8644, loss 0.545982.
Train: 2018-08-01T00:29:13.232919: step 8645, loss 0.479695.
Train: 2018-08-01T00:29:13.389138: step 8646, loss 0.529308.
Train: 2018-08-01T00:29:13.545354: step 8647, loss 0.629081.
Train: 2018-08-01T00:29:13.701565: step 8648, loss 0.529149.
Train: 2018-08-01T00:29:13.857778: step 8649, loss 0.645977.
Train: 2018-08-01T00:29:14.029613: step 8650, loss 0.612595.
Test: 2018-08-01T00:29:14.498248: step 8650, loss 0.548489.
Train: 2018-08-01T00:29:14.654467: step 8651, loss 0.512369.
Train: 2018-08-01T00:29:14.810684: step 8652, loss 0.54576.
Train: 2018-08-01T00:29:14.966894: step 8653, loss 0.445375.
Train: 2018-08-01T00:29:15.123107: step 8654, loss 0.495357.
Train: 2018-08-01T00:29:15.310558: step 8655, loss 0.528765.
Train: 2018-08-01T00:29:15.451155: step 8656, loss 0.511721.
Train: 2018-08-01T00:29:15.607369: step 8657, loss 0.528463.
Train: 2018-08-01T00:29:15.779204: step 8658, loss 0.528304.
Train: 2018-08-01T00:29:15.935387: step 8659, loss 0.562396.
Train: 2018-08-01T00:29:16.091601: step 8660, loss 0.562396.
Test: 2018-08-01T00:29:16.560274: step 8660, loss 0.547948.
Train: 2018-08-01T00:29:16.716453: step 8661, loss 0.579657.
Train: 2018-08-01T00:29:16.872668: step 8662, loss 0.527787.
Train: 2018-08-01T00:29:17.044532: step 8663, loss 0.631866.
Train: 2018-08-01T00:29:17.200745: step 8664, loss 0.475447.
Train: 2018-08-01T00:29:17.356966: step 8665, loss 0.562427.
Train: 2018-08-01T00:29:17.513173: step 8666, loss 0.492491.
Train: 2018-08-01T00:29:17.669355: step 8667, loss 0.562452.
Train: 2018-08-01T00:29:17.825601: step 8668, loss 0.703197.
Train: 2018-08-01T00:29:17.981782: step 8669, loss 0.580068.
Train: 2018-08-01T00:29:18.138027: step 8670, loss 0.63286.
Test: 2018-08-01T00:29:18.606662: step 8670, loss 0.547744.
Train: 2018-08-01T00:29:18.762874: step 8671, loss 0.562463.
Train: 2018-08-01T00:29:18.919064: step 8672, loss 0.562457.
Train: 2018-08-01T00:29:19.090928: step 8673, loss 0.615073.
Train: 2018-08-01T00:29:19.247112: step 8674, loss 0.544934.
Train: 2018-08-01T00:29:19.403324: step 8675, loss 0.632372.
Train: 2018-08-01T00:29:19.559538: step 8676, loss 0.614754.
Train: 2018-08-01T00:29:19.715751: step 8677, loss 0.68415.
Train: 2018-08-01T00:29:19.871964: step 8678, loss 0.597028.
Train: 2018-08-01T00:29:20.028179: step 8679, loss 0.59686.
Train: 2018-08-01T00:29:20.184392: step 8680, loss 0.545246.
Test: 2018-08-01T00:29:20.653057: step 8680, loss 0.548095.
Train: 2018-08-01T00:29:20.824898: step 8681, loss 0.511156.
Train: 2018-08-01T00:29:20.981111: step 8682, loss 0.528337.
Train: 2018-08-01T00:29:21.152915: step 8683, loss 0.545407.
Train: 2018-08-01T00:29:21.324749: step 8684, loss 0.528464.
Train: 2018-08-01T00:29:21.480994: step 8685, loss 0.545452.
Train: 2018-08-01T00:29:21.637177: step 8686, loss 0.54546.
Train: 2018-08-01T00:29:21.793425: step 8687, loss 0.562412.
Train: 2018-08-01T00:29:21.949603: step 8688, loss 0.494611.
Train: 2018-08-01T00:29:22.105817: step 8689, loss 0.562409.
Train: 2018-08-01T00:29:22.262030: step 8690, loss 0.545421.
Test: 2018-08-01T00:29:22.730701: step 8690, loss 0.548163.
Train: 2018-08-01T00:29:22.902539: step 8691, loss 0.613424.
Train: 2018-08-01T00:29:23.058743: step 8692, loss 0.596428.
Train: 2018-08-01T00:29:23.214933: step 8693, loss 0.647448.
Train: 2018-08-01T00:29:23.371147: step 8694, loss 0.52844.
Train: 2018-08-01T00:29:23.527389: step 8695, loss 0.59635.
Train: 2018-08-01T00:29:23.683607: step 8696, loss 0.647164.
Train: 2018-08-01T00:29:23.839786: step 8697, loss 0.579329.
Train: 2018-08-01T00:29:24.011621: step 8698, loss 0.596169.
Train: 2018-08-01T00:29:24.167833: step 8699, loss 0.646575.
Train: 2018-08-01T00:29:24.324047: step 8700, loss 0.595988.
Test: 2018-08-01T00:29:24.792717: step 8700, loss 0.548486.
Train: 2018-08-01T00:29:25.495679: step 8701, loss 0.54577.
Train: 2018-08-01T00:29:25.651863: step 8702, loss 0.512529.
Train: 2018-08-01T00:29:25.808074: step 8703, loss 0.645629.
Train: 2018-08-01T00:29:25.964319: step 8704, loss 0.512792.
Train: 2018-08-01T00:29:26.120532: step 8705, loss 0.579088.
Train: 2018-08-01T00:29:26.307959: step 8706, loss 0.529503.
Train: 2018-08-01T00:29:26.464172: step 8707, loss 0.463492.
Train: 2018-08-01T00:29:26.620385: step 8708, loss 0.579077.
Train: 2018-08-01T00:29:26.776628: step 8709, loss 0.62871.
Train: 2018-08-01T00:29:26.932812: step 8710, loss 0.661775.
Test: 2018-08-01T00:29:27.417104: step 8710, loss 0.548731.
Train: 2018-08-01T00:29:27.557699: step 8711, loss 0.562557.
Train: 2018-08-01T00:29:27.729507: step 8712, loss 0.579056.
Train: 2018-08-01T00:29:27.885744: step 8713, loss 0.546116.
Train: 2018-08-01T00:29:28.041957: step 8714, loss 0.611941.
Train: 2018-08-01T00:29:28.198171: step 8715, loss 0.529747.
Train: 2018-08-01T00:29:28.354354: step 8716, loss 0.579025.
Train: 2018-08-01T00:29:28.526188: step 8717, loss 0.496983.
Train: 2018-08-01T00:29:28.682401: step 8718, loss 0.562606.
Train: 2018-08-01T00:29:28.838640: step 8719, loss 0.661188.
Train: 2018-08-01T00:29:28.994859: step 8720, loss 0.546188.
Test: 2018-08-01T00:29:29.463497: step 8720, loss 0.548864.
Train: 2018-08-01T00:29:29.635334: step 8721, loss 0.546195.
Train: 2018-08-01T00:29:29.791549: step 8722, loss 0.529774.
Train: 2018-08-01T00:29:29.947759: step 8723, loss 0.562599.
Train: 2018-08-01T00:29:30.103974: step 8724, loss 0.513251.
Train: 2018-08-01T00:29:30.260188: step 8725, loss 0.364858.
Train: 2018-08-01T00:29:30.431991: step 8726, loss 0.64533.
Train: 2018-08-01T00:29:30.603846: step 8727, loss 0.628964.
Train: 2018-08-01T00:29:30.760040: step 8728, loss 0.529203.
Train: 2018-08-01T00:29:30.916253: step 8729, loss 0.615879.
Train: 2018-08-01T00:29:31.088088: step 8730, loss 0.47892.
Test: 2018-08-01T00:29:31.556763: step 8730, loss 0.548427.
Train: 2018-08-01T00:29:31.728564: step 8731, loss 0.595969.
Train: 2018-08-01T00:29:31.884776: step 8732, loss 0.495293.
Train: 2018-08-01T00:29:32.040990: step 8733, loss 0.612948.
Train: 2018-08-01T00:29:32.212855: step 8734, loss 0.494949.
Train: 2018-08-01T00:29:32.369039: step 8735, loss 0.511667.
Train: 2018-08-01T00:29:32.525251: step 8736, loss 0.52846.
Train: 2018-08-01T00:29:32.681500: step 8737, loss 0.528331.
Train: 2018-08-01T00:29:32.853325: step 8738, loss 0.528198.
Train: 2018-08-01T00:29:33.009538: step 8739, loss 0.613895.
Train: 2018-08-01T00:29:33.165760: step 8740, loss 0.545183.
Test: 2018-08-01T00:29:33.634397: step 8740, loss 0.547946.
Train: 2018-08-01T00:29:33.790605: step 8741, loss 0.631439.
Train: 2018-08-01T00:29:33.962440: step 8742, loss 0.510551.
Train: 2018-08-01T00:29:34.103039: step 8743, loss 0.52777.
Train: 2018-08-01T00:29:34.259221: step 8744, loss 0.562411.
Train: 2018-08-01T00:29:34.415436: step 8745, loss 0.458067.
Train: 2018-08-01T00:29:34.587269: step 8746, loss 0.649672.
Train: 2018-08-01T00:29:34.743483: step 8747, loss 0.544958.
Train: 2018-08-01T00:29:34.899695: step 8748, loss 0.614959.
Train: 2018-08-01T00:29:35.071556: step 8749, loss 0.544928.
Train: 2018-08-01T00:29:35.212153: step 8750, loss 0.474799.
Test: 2018-08-01T00:29:35.680762: step 8750, loss 0.547752.
Train: 2018-08-01T00:29:35.837007: step 8751, loss 0.40439.
Train: 2018-08-01T00:29:36.008841: step 8752, loss 0.633009.
Train: 2018-08-01T00:29:36.180646: step 8753, loss 0.474127.
Train: 2018-08-01T00:29:36.336859: step 8754, loss 0.456125.
Train: 2018-08-01T00:29:36.493073: step 8755, loss 0.437885.
Train: 2018-08-01T00:29:36.649317: step 8756, loss 0.544702.
Train: 2018-08-01T00:29:36.789911: step 8757, loss 0.490665.
Train: 2018-08-01T00:29:36.946122: step 8758, loss 0.490343.
Train: 2018-08-01T00:29:37.102335: step 8759, loss 0.562809.
Train: 2018-08-01T00:29:37.274165: step 8760, loss 0.764044.
Test: 2018-08-01T00:29:37.758431: step 8760, loss 0.547568.
Train: 2018-08-01T00:29:37.914645: step 8761, loss 0.617845.
Train: 2018-08-01T00:29:38.070858: step 8762, loss 0.434668.
Train: 2018-08-01T00:29:38.227072: step 8763, loss 0.599645.
Train: 2018-08-01T00:29:38.398876: step 8764, loss 0.562954.
Train: 2018-08-01T00:29:38.555090: step 8765, loss 0.599726.
Train: 2018-08-01T00:29:38.711303: step 8766, loss 0.599716.
Train: 2018-08-01T00:29:38.867516: step 8767, loss 0.581308.
Train: 2018-08-01T00:29:39.023761: step 8768, loss 0.654622.
Train: 2018-08-01T00:29:39.179943: step 8769, loss 0.617763.
Train: 2018-08-01T00:29:39.351778: step 8770, loss 0.508135.
Test: 2018-08-01T00:29:39.804826: step 8770, loss 0.547569.
Train: 2018-08-01T00:29:39.961041: step 8771, loss 0.526421.
Train: 2018-08-01T00:29:40.117255: step 8772, loss 0.544619.
Train: 2018-08-01T00:29:40.273437: step 8773, loss 0.5265.
Train: 2018-08-01T00:29:40.429675: step 8774, loss 0.598951.
Train: 2018-08-01T00:29:40.617108: step 8775, loss 0.580792.
Train: 2018-08-01T00:29:40.757699: step 8776, loss 0.418372.
Train: 2018-08-01T00:29:40.913943: step 8777, loss 0.562693.
Train: 2018-08-01T00:29:41.070156: step 8778, loss 0.526614.
Train: 2018-08-01T00:29:41.226339: step 8779, loss 0.688994.
Train: 2018-08-01T00:29:41.382583: step 8780, loss 0.598699.
Test: 2018-08-01T00:29:41.851223: step 8780, loss 0.547599.
Train: 2018-08-01T00:29:42.023058: step 8781, loss 0.598595.
Train: 2018-08-01T00:29:42.179275: step 8782, loss 0.508843.
Train: 2018-08-01T00:29:42.335454: step 8783, loss 0.705759.
Train: 2018-08-01T00:29:42.491698: step 8784, loss 0.473427.
Train: 2018-08-01T00:29:42.647907: step 8785, loss 0.615913.
Train: 2018-08-01T00:29:42.819752: step 8786, loss 0.52705.
Train: 2018-08-01T00:29:42.975959: step 8787, loss 0.527112.
Train: 2018-08-01T00:29:43.132173: step 8788, loss 0.509487.
Train: 2018-08-01T00:29:43.288356: step 8789, loss 0.739049.
Train: 2018-08-01T00:29:43.444600: step 8790, loss 0.509677.
Test: 2018-08-01T00:29:43.913240: step 8790, loss 0.547755.
Train: 2018-08-01T00:29:44.069424: step 8791, loss 0.509787.
Train: 2018-08-01T00:29:44.225667: step 8792, loss 0.544917.
Train: 2018-08-01T00:29:44.381851: step 8793, loss 0.720059.
Train: 2018-08-01T00:29:44.538064: step 8794, loss 0.614793.
Train: 2018-08-01T00:29:44.678657: step 8795, loss 0.52764.
Train: 2018-08-01T00:29:44.850516: step 8796, loss 0.510399.
Train: 2018-08-01T00:29:45.006704: step 8797, loss 0.631612.
Train: 2018-08-01T00:29:45.162917: step 8798, loss 0.545146.
Train: 2018-08-01T00:29:45.319162: step 8799, loss 0.52797.
Train: 2018-08-01T00:29:45.475374: step 8800, loss 0.579582.
Test: 2018-08-01T00:29:45.959607: step 8800, loss 0.548028.
Train: 2018-08-01T00:29:46.658590: step 8801, loss 0.579553.
Train: 2018-08-01T00:29:46.814803: step 8802, loss 0.648029.
Train: 2018-08-01T00:29:46.970987: step 8803, loss 0.545321.
Train: 2018-08-01T00:29:47.142821: step 8804, loss 0.545364.
Train: 2018-08-01T00:29:47.299065: step 8805, loss 0.630429.
Train: 2018-08-01T00:29:47.455248: step 8806, loss 0.56241.
Train: 2018-08-01T00:29:47.611462: step 8807, loss 0.680863.
Train: 2018-08-01T00:29:47.767700: step 8808, loss 0.62985.
Train: 2018-08-01T00:29:47.923888: step 8809, loss 0.562451.
Train: 2018-08-01T00:29:48.080132: step 8810, loss 0.629317.
Test: 2018-08-01T00:29:48.548742: step 8810, loss 0.548571.
Train: 2018-08-01T00:29:48.704956: step 8811, loss 0.495963.
Train: 2018-08-01T00:29:48.861169: step 8812, loss 0.512767.
Train: 2018-08-01T00:29:49.017384: step 8813, loss 0.595646.
Train: 2018-08-01T00:29:49.173626: step 8814, loss 0.529506.
Train: 2018-08-01T00:29:49.345455: step 8815, loss 0.661582.
Train: 2018-08-01T00:29:49.501645: step 8816, loss 0.39796.
Train: 2018-08-01T00:29:49.657882: step 8817, loss 0.579049.
Train: 2018-08-01T00:29:49.814096: step 8818, loss 0.529617.
Train: 2018-08-01T00:29:49.970314: step 8819, loss 0.595555.
Train: 2018-08-01T00:29:50.126527: step 8820, loss 0.529553.
Test: 2018-08-01T00:29:50.610759: step 8820, loss 0.548715.
Train: 2018-08-01T00:29:50.751381: step 8821, loss 0.512983.
Train: 2018-08-01T00:29:50.923185: step 8822, loss 0.57909.
Train: 2018-08-01T00:29:51.079400: step 8823, loss 0.479614.
Train: 2018-08-01T00:29:51.235614: step 8824, loss 0.479352.
Train: 2018-08-01T00:29:51.391857: step 8825, loss 0.512385.
Train: 2018-08-01T00:29:51.579283: step 8826, loss 0.512135.
Train: 2018-08-01T00:29:51.735525: step 8827, loss 0.680414.
Train: 2018-08-01T00:29:51.891709: step 8828, loss 0.562421.
Train: 2018-08-01T00:29:52.047953: step 8829, loss 0.579353.
Train: 2018-08-01T00:29:52.204166: step 8830, loss 0.511491.
Test: 2018-08-01T00:29:52.672807: step 8830, loss 0.548154.
Train: 2018-08-01T00:29:52.844641: step 8831, loss 0.579419.
Train: 2018-08-01T00:29:53.000825: step 8832, loss 0.511246.
Train: 2018-08-01T00:29:53.157038: step 8833, loss 0.613686.
Train: 2018-08-01T00:29:53.313282: step 8834, loss 0.425402.
Train: 2018-08-01T00:29:53.469495: step 8835, loss 0.493658.
Train: 2018-08-01T00:29:53.625704: step 8836, loss 0.614168.
Train: 2018-08-01T00:29:53.797514: step 8837, loss 0.631633.
Train: 2018-08-01T00:29:53.953728: step 8838, loss 0.510402.
Train: 2018-08-01T00:29:54.109970: step 8839, loss 0.510295.
Train: 2018-08-01T00:29:54.266183: step 8840, loss 0.562422.
Test: 2018-08-01T00:29:54.734793: step 8840, loss 0.54781.
Train: 2018-08-01T00:29:54.891007: step 8841, loss 0.475131.
Train: 2018-08-01T00:29:55.047221: step 8842, loss 0.439821.
Train: 2018-08-01T00:29:55.203433: step 8843, loss 0.544871.
Train: 2018-08-01T00:29:55.359678: step 8844, loss 0.580174.
Train: 2018-08-01T00:29:55.531482: step 8845, loss 0.527048.
Train: 2018-08-01T00:29:55.687726: step 8846, loss 0.473548.
Train: 2018-08-01T00:29:55.859568: step 8847, loss 0.59835.
Train: 2018-08-01T00:29:56.031364: step 8848, loss 0.616434.
Train: 2018-08-01T00:29:56.187579: step 8849, loss 0.598593.
Train: 2018-08-01T00:29:56.343792: step 8850, loss 0.616641.
Test: 2018-08-01T00:29:56.828054: step 8850, loss 0.547594.
Train: 2018-08-01T00:29:56.984267: step 8851, loss 0.562664.
Train: 2018-08-01T00:29:57.140510: step 8852, loss 0.562664.
Train: 2018-08-01T00:29:57.296694: step 8853, loss 0.49069.
Train: 2018-08-01T00:29:57.452906: step 8854, loss 0.688706.
Train: 2018-08-01T00:29:57.593532: step 8855, loss 0.616603.
Train: 2018-08-01T00:29:57.749712: step 8856, loss 0.508795.
Train: 2018-08-01T00:29:57.905926: step 8857, loss 0.490924.
Train: 2018-08-01T00:29:58.093381: step 8858, loss 0.50886.
Train: 2018-08-01T00:29:58.249620: step 8859, loss 0.562621.
Train: 2018-08-01T00:29:58.405839: step 8860, loss 0.437124.
Test: 2018-08-01T00:29:58.874479: step 8860, loss 0.547602.
Train: 2018-08-01T00:29:59.046284: step 8861, loss 0.634478.
Train: 2018-08-01T00:29:59.218145: step 8862, loss 0.454845.
Train: 2018-08-01T00:29:59.374356: step 8863, loss 0.45468.
Train: 2018-08-01T00:29:59.530581: step 8864, loss 0.508553.
Train: 2018-08-01T00:29:59.686758: step 8865, loss 0.508424.
Train: 2018-08-01T00:29:59.843002: step 8866, loss 0.599112.
Train: 2018-08-01T00:29:59.999216: step 8867, loss 0.59923.
Train: 2018-08-01T00:30:00.155430: step 8868, loss 0.599302.
Train: 2018-08-01T00:30:00.342880: step 8869, loss 0.635821.
Train: 2018-08-01T00:30:00.499099: step 8870, loss 0.52637.
Test: 2018-08-01T00:30:00.967708: step 8870, loss 0.547568.
Train: 2018-08-01T00:30:01.123921: step 8871, loss 0.65397.
Train: 2018-08-01T00:30:01.280163: step 8872, loss 0.526412.
Train: 2018-08-01T00:30:01.452001: step 8873, loss 0.471911.
Train: 2018-08-01T00:30:01.608217: step 8874, loss 0.56279.
Train: 2018-08-01T00:30:01.764428: step 8875, loss 0.617298.
Train: 2018-08-01T00:30:01.920641: step 8876, loss 0.562771.
Train: 2018-08-01T00:30:02.076824: step 8877, loss 0.599012.
Train: 2018-08-01T00:30:02.233037: step 8878, loss 0.508441.
Train: 2018-08-01T00:30:02.404873: step 8879, loss 0.490404.
Train: 2018-08-01T00:30:02.561085: step 8880, loss 0.562718.
Test: 2018-08-01T00:30:03.029756: step 8880, loss 0.547581.
Train: 2018-08-01T00:30:03.185964: step 8881, loss 0.671146.
Train: 2018-08-01T00:30:03.342152: step 8882, loss 0.688958.
Train: 2018-08-01T00:30:03.498367: step 8883, loss 0.652521.
Train: 2018-08-01T00:30:03.654579: step 8884, loss 0.598385.
Train: 2018-08-01T00:30:03.810792: step 8885, loss 0.54475.
Train: 2018-08-01T00:30:03.967006: step 8886, loss 0.580254.
Train: 2018-08-01T00:30:04.123219: step 8887, loss 0.58015.
Train: 2018-08-01T00:30:04.295054: step 8888, loss 0.597639.
Train: 2018-08-01T00:30:04.451267: step 8889, loss 0.579955.
Train: 2018-08-01T00:30:04.654345: step 8890, loss 0.562426.
Test: 2018-08-01T00:30:05.123017: step 8890, loss 0.547867.
Train: 2018-08-01T00:30:05.279230: step 8891, loss 0.684008.
Train: 2018-08-01T00:30:05.435443: step 8892, loss 0.562401.
Train: 2018-08-01T00:30:05.591656: step 8893, loss 0.562396.
Train: 2018-08-01T00:30:05.794734: step 8894, loss 0.596638.
Train: 2018-08-01T00:30:05.950918: step 8895, loss 0.613536.
Train: 2018-08-01T00:30:06.107129: step 8896, loss 0.579374.
Train: 2018-08-01T00:30:06.263374: step 8897, loss 0.562424.
Train: 2018-08-01T00:30:06.419556: step 8898, loss 0.528802.
Train: 2018-08-01T00:30:06.575770: step 8899, loss 0.612755.
Train: 2018-08-01T00:30:06.731983: step 8900, loss 0.629308.
Test: 2018-08-01T00:30:07.216275: step 8900, loss 0.548564.
Train: 2018-08-01T00:30:07.919236: step 8901, loss 0.562499.
Train: 2018-08-01T00:30:08.075420: step 8902, loss 0.562524.
Train: 2018-08-01T00:30:08.247284: step 8903, loss 0.62866.
Train: 2018-08-01T00:30:08.403467: step 8904, loss 0.67784.
Train: 2018-08-01T00:30:08.559680: step 8905, loss 0.57901.
Train: 2018-08-01T00:30:08.715927: step 8906, loss 0.595284.
Train: 2018-08-01T00:30:08.872138: step 8907, loss 0.62764.
Train: 2018-08-01T00:30:09.043942: step 8908, loss 0.546649.
Train: 2018-08-01T00:30:09.200156: step 8909, loss 0.54677.
Train: 2018-08-01T00:30:09.356370: step 8910, loss 0.643022.
Test: 2018-08-01T00:30:09.840632: step 8910, loss 0.549586.
Train: 2018-08-01T00:30:09.996844: step 8911, loss 0.499108.
Train: 2018-08-01T00:30:10.168679: step 8912, loss 0.515213.
Train: 2018-08-01T00:30:10.324923: step 8913, loss 0.531184.
Train: 2018-08-01T00:30:10.481106: step 8914, loss 0.531186.
Train: 2018-08-01T00:30:10.637319: step 8915, loss 0.578911.
Train: 2018-08-01T00:30:10.793533: step 8916, loss 0.578911.
Train: 2018-08-01T00:30:10.949777: step 8917, loss 0.642678.
Train: 2018-08-01T00:30:11.105961: step 8918, loss 0.515181.
Train: 2018-08-01T00:30:11.293415: step 8919, loss 0.515144.
Train: 2018-08-01T00:30:11.449629: step 8920, loss 0.546978.
Test: 2018-08-01T00:30:11.918299: step 8920, loss 0.549519.
Train: 2018-08-01T00:30:12.074482: step 8921, loss 0.594915.
Train: 2018-08-01T00:30:12.230697: step 8922, loss 0.594942.
Train: 2018-08-01T00:30:12.402562: step 8923, loss 0.57892.
Train: 2018-08-01T00:30:12.558744: step 8924, loss 0.482597.
Train: 2018-08-01T00:30:12.714988: step 8925, loss 0.578928.
Train: 2018-08-01T00:30:12.871171: step 8926, loss 0.530553.
Train: 2018-08-01T00:30:13.027412: step 8927, loss 0.562773.
Train: 2018-08-01T00:30:13.167977: step 8928, loss 0.497891.
Train: 2018-08-01T00:30:13.339812: step 8929, loss 0.513885.
Train: 2018-08-01T00:30:13.511646: step 8930, loss 0.578994.
Test: 2018-08-01T00:30:13.980317: step 8930, loss 0.548882.
Train: 2018-08-01T00:30:14.136530: step 8931, loss 0.447804.
Train: 2018-08-01T00:30:14.292743: step 8932, loss 0.595547.
Train: 2018-08-01T00:30:14.495793: step 8933, loss 0.529406.
Train: 2018-08-01T00:30:14.652004: step 8934, loss 0.579138.
Train: 2018-08-01T00:30:14.808243: step 8935, loss 0.579179.
Train: 2018-08-01T00:30:14.964456: step 8936, loss 0.495407.
Train: 2018-08-01T00:30:15.120675: step 8937, loss 0.646597.
Train: 2018-08-01T00:30:15.276883: step 8938, loss 0.528678.
Train: 2018-08-01T00:30:15.433101: step 8939, loss 0.562417.
Train: 2018-08-01T00:30:15.604942: step 8940, loss 0.579375.
Test: 2018-08-01T00:30:16.073576: step 8940, loss 0.548168.
Train: 2018-08-01T00:30:16.245382: step 8941, loss 0.562405.
Train: 2018-08-01T00:30:16.401594: step 8942, loss 0.5113.
Train: 2018-08-01T00:30:16.557808: step 8943, loss 0.545321.
Train: 2018-08-01T00:30:16.714021: step 8944, loss 0.493915.
Train: 2018-08-01T00:30:16.885856: step 8945, loss 0.579573.
Train: 2018-08-01T00:30:17.026448: step 8946, loss 0.596845.
Train: 2018-08-01T00:30:17.182692: step 8947, loss 0.493371.
Train: 2018-08-01T00:30:17.354527: step 8948, loss 0.510491.
Train: 2018-08-01T00:30:17.510748: step 8949, loss 0.649208.
Train: 2018-08-01T00:30:17.666953: step 8950, loss 0.63196.
Test: 2018-08-01T00:30:18.135562: step 8950, loss 0.547853.
Train: 2018-08-01T00:30:18.291807: step 8951, loss 0.684159.
Train: 2018-08-01T00:30:18.447991: step 8952, loss 0.562412.
Train: 2018-08-01T00:30:18.604235: step 8953, loss 0.510388.
Train: 2018-08-01T00:30:18.776065: step 8954, loss 0.562407.
Train: 2018-08-01T00:30:18.947874: step 8955, loss 0.579727.
Train: 2018-08-01T00:30:19.104088: step 8956, loss 0.527788.
Train: 2018-08-01T00:30:19.260300: step 8957, loss 0.614317.
Train: 2018-08-01T00:30:19.400923: step 8958, loss 0.493253.
Train: 2018-08-01T00:30:19.572727: step 8959, loss 0.527824.
Train: 2018-08-01T00:30:19.728940: step 8960, loss 0.493206.
Test: 2018-08-01T00:30:20.197605: step 8960, loss 0.547898.
Train: 2018-08-01T00:30:20.353824: step 8961, loss 0.597058.
Train: 2018-08-01T00:30:20.525659: step 8962, loss 0.510388.
Train: 2018-08-01T00:30:20.681842: step 8963, loss 0.614509.
Train: 2018-08-01T00:30:20.838087: step 8964, loss 0.545039.
Train: 2018-08-01T00:30:20.994305: step 8965, loss 0.562416.
Train: 2018-08-01T00:30:21.181756: step 8966, loss 0.423248.
Train: 2018-08-01T00:30:21.337941: step 8967, loss 0.579866.
Train: 2018-08-01T00:30:21.494152: step 8968, loss 0.44012.
Train: 2018-08-01T00:30:21.650365: step 8969, loss 0.75532.
Train: 2018-08-01T00:30:21.806579: step 8970, loss 0.562451.
Test: 2018-08-01T00:30:22.275249: step 8970, loss 0.547764.
Train: 2018-08-01T00:30:22.447085: step 8971, loss 0.579992.
Train: 2018-08-01T00:30:22.603297: step 8972, loss 0.579988.
Train: 2018-08-01T00:30:22.759481: step 8973, loss 0.632561.
Train: 2018-08-01T00:30:22.915719: step 8974, loss 0.492436.
Train: 2018-08-01T00:30:23.087529: step 8975, loss 0.47497.
Train: 2018-08-01T00:30:23.243743: step 8976, loss 0.474904.
Train: 2018-08-01T00:30:23.399986: step 8977, loss 0.579993.
Train: 2018-08-01T00:30:23.556170: step 8978, loss 0.597591.
Train: 2018-08-01T00:30:23.712383: step 8979, loss 0.492153.
Train: 2018-08-01T00:30:23.868595: step 8980, loss 0.580076.
Test: 2018-08-01T00:30:24.337271: step 8980, loss 0.547722.
Train: 2018-08-01T00:30:24.493474: step 8981, loss 0.544856.
Train: 2018-08-01T00:30:24.649694: step 8982, loss 0.597769.
Train: 2018-08-01T00:30:24.805908: step 8983, loss 0.52719.
Train: 2018-08-01T00:30:24.962120: step 8984, loss 0.61548.
Train: 2018-08-01T00:30:25.118329: step 8985, loss 0.61547.
Train: 2018-08-01T00:30:25.274517: step 8986, loss 0.650694.
Train: 2018-08-01T00:30:25.446352: step 8987, loss 0.527267.
Train: 2018-08-01T00:30:25.602595: step 8988, loss 0.474592.
Train: 2018-08-01T00:30:25.758780: step 8989, loss 0.544891.
Train: 2018-08-01T00:30:25.915027: step 8990, loss 0.527324.
Test: 2018-08-01T00:30:26.383662: step 8990, loss 0.547746.
Train: 2018-08-01T00:30:26.617983: step 8991, loss 0.615185.
Train: 2018-08-01T00:30:26.774190: step 8992, loss 0.562459.
Train: 2018-08-01T00:30:26.930409: step 8993, loss 0.492233.
Train: 2018-08-01T00:30:27.086617: step 8994, loss 0.597586.
Train: 2018-08-01T00:30:27.242836: step 8995, loss 0.597579.
Train: 2018-08-01T00:30:27.414641: step 8996, loss 0.685286.
Train: 2018-08-01T00:30:27.570885: step 8997, loss 0.562441.
Train: 2018-08-01T00:30:27.742689: step 8998, loss 0.544968.
Train: 2018-08-01T00:30:27.898938: step 8999, loss 0.579853.
Train: 2018-08-01T00:30:28.055115: step 9000, loss 0.579811.
Test: 2018-08-01T00:30:28.523757: step 9000, loss 0.547876.
Train: 2018-08-01T00:30:29.289232: step 9001, loss 0.562411.
Train: 2018-08-01T00:30:29.445416: step 9002, loss 0.631698.
Train: 2018-08-01T00:30:29.601629: step 9003, loss 0.441483.
Train: 2018-08-01T00:30:29.757842: step 9004, loss 0.476097.
Train: 2018-08-01T00:30:29.945323: step 9005, loss 0.579671.
Train: 2018-08-01T00:30:30.085920: step 9006, loss 0.596949.
Train: 2018-08-01T00:30:30.242133: step 9007, loss 0.527863.
Train: 2018-08-01T00:30:30.398316: step 9008, loss 0.614216.
Train: 2018-08-01T00:30:30.554560: step 9009, loss 0.631444.
Train: 2018-08-01T00:30:30.710774: step 9010, loss 0.545164.
Test: 2018-08-01T00:30:31.195035: step 9010, loss 0.547983.
Train: 2018-08-01T00:30:31.351249: step 9011, loss 0.579609.
Train: 2018-08-01T00:30:31.507470: step 9012, loss 0.579585.
Train: 2018-08-01T00:30:31.663645: step 9013, loss 0.545232.
Train: 2018-08-01T00:30:31.819889: step 9014, loss 0.648122.
Train: 2018-08-01T00:30:31.976099: step 9015, loss 0.54529.
Train: 2018-08-01T00:30:32.147932: step 9016, loss 0.51117.
Train: 2018-08-01T00:30:32.319741: step 9017, loss 0.613586.
Train: 2018-08-01T00:30:32.475955: step 9018, loss 0.477216.
Train: 2018-08-01T00:30:32.632169: step 9019, loss 0.562401.
Train: 2018-08-01T00:30:32.788382: step 9020, loss 0.613512.
Test: 2018-08-01T00:30:33.257021: step 9020, loss 0.548146.
Train: 2018-08-01T00:30:33.413236: step 9021, loss 0.596451.
Train: 2018-08-01T00:30:33.569480: step 9022, loss 0.528395.
Train: 2018-08-01T00:30:33.725663: step 9023, loss 0.681377.
Train: 2018-08-01T00:30:33.897498: step 9024, loss 0.579368.
Train: 2018-08-01T00:30:34.053741: step 9025, loss 0.545497.
Train: 2018-08-01T00:30:34.209926: step 9026, loss 0.680658.
Train: 2018-08-01T00:30:34.381783: step 9027, loss 0.495097.
Train: 2018-08-01T00:30:34.537972: step 9028, loss 0.579247.
Train: 2018-08-01T00:30:34.694216: step 9029, loss 0.595995.
Train: 2018-08-01T00:30:34.850429: step 9030, loss 0.580315.
Test: 2018-08-01T00:30:35.319039: step 9030, loss 0.548493.
Train: 2018-08-01T00:30:35.475252: step 9031, loss 0.49568.
Train: 2018-08-01T00:30:35.631497: step 9032, loss 0.562481.
Train: 2018-08-01T00:30:35.787710: step 9033, loss 0.645865.
Train: 2018-08-01T00:30:35.959514: step 9034, loss 0.612436.
Train: 2018-08-01T00:30:36.115758: step 9035, loss 0.628945.
Train: 2018-08-01T00:30:36.271972: step 9036, loss 0.529418.
Train: 2018-08-01T00:30:36.443776: step 9037, loss 0.512978.
Train: 2018-08-01T00:30:36.600026: step 9038, loss 0.480015.
Train: 2018-08-01T00:30:36.756241: step 9039, loss 0.595591.
Train: 2018-08-01T00:30:36.912441: step 9040, loss 0.546029.
Test: 2018-08-01T00:30:37.381086: step 9040, loss 0.548704.
Train: 2018-08-01T00:30:37.552893: step 9041, loss 0.463359.
Train: 2018-08-01T00:30:37.709106: step 9042, loss 0.512825.
Train: 2018-08-01T00:30:37.849722: step 9043, loss 0.628975.
Train: 2018-08-01T00:30:38.005943: step 9044, loss 0.445984.
Train: 2018-08-01T00:30:38.162125: step 9045, loss 0.46226.
Train: 2018-08-01T00:30:38.333988: step 9046, loss 0.528884.
Train: 2018-08-01T00:30:38.490172: step 9047, loss 0.545564.
Train: 2018-08-01T00:30:38.662006: step 9048, loss 0.579357.
Train: 2018-08-01T00:30:38.802629: step 9049, loss 0.52838.
Train: 2018-08-01T00:30:38.958812: step 9050, loss 0.562398.
Test: 2018-08-01T00:30:39.427482: step 9050, loss 0.548038.
Train: 2018-08-01T00:30:39.599318: step 9051, loss 0.54525.
Train: 2018-08-01T00:30:39.786774: step 9052, loss 0.648433.
Train: 2018-08-01T00:30:39.942957: step 9053, loss 0.596879.
Train: 2018-08-01T00:30:40.114821: step 9054, loss 0.510615.
Train: 2018-08-01T00:30:40.271005: step 9055, loss 0.596989.
Train: 2018-08-01T00:30:40.427248: step 9056, loss 0.597029.
Train: 2018-08-01T00:30:40.583432: step 9057, loss 0.545086.
Train: 2018-08-01T00:30:40.739645: step 9058, loss 0.6144.
Train: 2018-08-01T00:30:40.927131: step 9059, loss 0.683695.
Train: 2018-08-01T00:30:41.083346: step 9060, loss 0.510527.
Test: 2018-08-01T00:30:41.551955: step 9060, loss 0.547937.
Train: 2018-08-01T00:30:41.708197: step 9061, loss 0.562401.
Train: 2018-08-01T00:30:41.895665: step 9062, loss 0.545144.
Train: 2018-08-01T00:30:42.051838: step 9063, loss 0.52791.
Train: 2018-08-01T00:30:42.208081: step 9064, loss 0.57964.
Train: 2018-08-01T00:30:42.364295: step 9065, loss 0.700284.
Train: 2018-08-01T00:30:42.520503: step 9066, loss 0.57959.
Train: 2018-08-01T00:30:42.676722: step 9067, loss 0.545243.
Train: 2018-08-01T00:30:42.832904: step 9068, loss 0.596635.
Train: 2018-08-01T00:30:43.004740: step 9069, loss 0.61364.
Train: 2018-08-01T00:30:43.160955: step 9070, loss 0.562401.
Test: 2018-08-01T00:30:43.645262: step 9070, loss 0.548179.
Train: 2018-08-01T00:30:43.801458: step 9071, loss 0.579396.
Train: 2018-08-01T00:30:43.957672: step 9072, loss 0.57936.
Train: 2018-08-01T00:30:44.113855: step 9073, loss 0.494795.
Train: 2018-08-01T00:30:44.270099: step 9074, loss 0.494875.
Train: 2018-08-01T00:30:44.426312: step 9075, loss 0.461091.
Train: 2018-08-01T00:30:44.598116: step 9076, loss 0.613171.
Train: 2018-08-01T00:30:44.754360: step 9077, loss 0.545484.
Train: 2018-08-01T00:30:44.894953: step 9078, loss 0.630207.
Train: 2018-08-01T00:30:45.051166: step 9079, loss 0.596307.
Train: 2018-08-01T00:30:45.222996: step 9080, loss 0.5116.
Test: 2018-08-01T00:30:45.691640: step 9080, loss 0.548225.
Train: 2018-08-01T00:30:45.847854: step 9081, loss 0.664074.
Train: 2018-08-01T00:30:46.019683: step 9082, loss 0.494725.
Train: 2018-08-01T00:30:46.175903: step 9083, loss 0.528571.
Train: 2018-08-01T00:30:46.332085: step 9084, loss 0.562415.
Train: 2018-08-01T00:30:46.488298: step 9085, loss 0.545472.
Train: 2018-08-01T00:30:46.644543: step 9086, loss 0.494591.
Train: 2018-08-01T00:30:46.800756: step 9087, loss 0.579392.
Train: 2018-08-01T00:30:46.956940: step 9088, loss 0.511376.
Train: 2018-08-01T00:30:47.113183: step 9089, loss 0.596489.
Train: 2018-08-01T00:30:47.269396: step 9090, loss 0.630669.
Test: 2018-08-01T00:30:47.738036: step 9090, loss 0.548103.
Train: 2018-08-01T00:30:47.894250: step 9091, loss 0.647754.
Train: 2018-08-01T00:30:48.050463: step 9092, loss 0.596504.
Train: 2018-08-01T00:30:48.206680: step 9093, loss 0.579429.
Train: 2018-08-01T00:30:48.362859: step 9094, loss 0.596404.
Train: 2018-08-01T00:30:48.534695: step 9095, loss 0.68118.
Train: 2018-08-01T00:30:48.690908: step 9096, loss 0.596234.
Train: 2018-08-01T00:30:48.847157: step 9097, loss 0.596124.
Train: 2018-08-01T00:30:49.003335: step 9098, loss 0.49532.
Train: 2018-08-01T00:30:49.159548: step 9099, loss 0.528973.
Train: 2018-08-01T00:30:49.331408: step 9100, loss 0.529028.
Test: 2018-08-01T00:30:49.800053: step 9100, loss 0.548481.
Train: 2018-08-01T00:30:50.503014: step 9101, loss 0.562473.
Train: 2018-08-01T00:30:50.674820: step 9102, loss 0.579176.
Train: 2018-08-01T00:30:50.815443: step 9103, loss 0.545789.
Train: 2018-08-01T00:30:50.971624: step 9104, loss 0.6626.
Train: 2018-08-01T00:30:51.127838: step 9105, loss 0.412565.
Train: 2018-08-01T00:30:51.284050: step 9106, loss 0.629184.
Train: 2018-08-01T00:30:51.440264: step 9107, loss 0.512465.
Train: 2018-08-01T00:30:51.612124: step 9108, loss 0.579168.
Train: 2018-08-01T00:30:51.768313: step 9109, loss 0.512387.
Train: 2018-08-01T00:30:51.940178: step 9110, loss 0.629349.
Test: 2018-08-01T00:30:52.408818: step 9110, loss 0.548462.
Train: 2018-08-01T00:30:52.565036: step 9111, loss 0.478842.
Train: 2018-08-01T00:30:52.721239: step 9112, loss 0.545705.
Train: 2018-08-01T00:30:52.877428: step 9113, loss 0.629585.
Train: 2018-08-01T00:30:53.033642: step 9114, loss 0.629628.
Train: 2018-08-01T00:30:53.189855: step 9115, loss 0.612816.
Train: 2018-08-01T00:30:53.361690: step 9116, loss 0.696627.
Train: 2018-08-01T00:30:53.502312: step 9117, loss 0.629356.
Train: 2018-08-01T00:30:53.674146: step 9118, loss 0.54583.
Train: 2018-08-01T00:30:53.830360: step 9119, loss 0.56251.
Train: 2018-08-01T00:30:53.986573: step 9120, loss 0.612238.
Test: 2018-08-01T00:30:54.455213: step 9120, loss 0.548718.
Train: 2018-08-01T00:30:54.627018: step 9121, loss 0.479949.
Train: 2018-08-01T00:30:54.783231: step 9122, loss 0.595563.
Train: 2018-08-01T00:30:54.939475: step 9123, loss 0.480194.
Train: 2018-08-01T00:30:55.111279: step 9124, loss 0.562573.
Train: 2018-08-01T00:30:55.267524: step 9125, loss 0.529605.
Train: 2018-08-01T00:30:55.423737: step 9126, loss 0.711047.
Train: 2018-08-01T00:30:55.579919: step 9127, loss 0.562576.
Train: 2018-08-01T00:30:55.736133: step 9128, loss 0.529675.
Train: 2018-08-01T00:30:55.892348: step 9129, loss 0.611937.
Train: 2018-08-01T00:30:56.048585: step 9130, loss 0.529732.
Test: 2018-08-01T00:30:56.532854: step 9130, loss 0.548842.
Train: 2018-08-01T00:30:56.689035: step 9131, loss 0.57903.
Train: 2018-08-01T00:30:56.845273: step 9132, loss 0.562603.
Train: 2018-08-01T00:30:57.001492: step 9133, loss 0.562604.
Train: 2018-08-01T00:30:57.157676: step 9134, loss 0.595451.
Train: 2018-08-01T00:30:57.345162: step 9135, loss 0.513351.
Train: 2018-08-01T00:30:57.485724: step 9136, loss 0.628317.
Train: 2018-08-01T00:30:57.641968: step 9137, loss 0.54618.
Train: 2018-08-01T00:30:57.813802: step 9138, loss 0.579028.
Train: 2018-08-01T00:30:57.970016: step 9139, loss 0.546177.
Train: 2018-08-01T00:30:58.126228: step 9140, loss 0.611896.
Test: 2018-08-01T00:30:58.594869: step 9140, loss 0.548845.
Train: 2018-08-01T00:30:58.766675: step 9141, loss 0.546173.
Train: 2018-08-01T00:30:58.922917: step 9142, loss 0.562599.
Train: 2018-08-01T00:30:59.079101: step 9143, loss 0.546161.
Train: 2018-08-01T00:30:59.235344: step 9144, loss 0.496801.
Train: 2018-08-01T00:30:59.391560: step 9145, loss 0.529618.
Train: 2018-08-01T00:30:59.547741: step 9146, loss 0.413906.
Train: 2018-08-01T00:30:59.703984: step 9147, loss 0.595705.
Train: 2018-08-01T00:30:59.860198: step 9148, loss 0.495871.
Train: 2018-08-01T00:31:00.016381: step 9149, loss 0.529004.
Train: 2018-08-01T00:31:00.172625: step 9150, loss 0.562442.
Test: 2018-08-01T00:31:00.656855: step 9150, loss 0.548289.
Train: 2018-08-01T00:31:00.813070: step 9151, loss 0.545544.
Train: 2018-08-01T00:31:00.969313: step 9152, loss 0.545461.
Train: 2018-08-01T00:31:01.141148: step 9153, loss 0.579421.
Train: 2018-08-01T00:31:01.297331: step 9154, loss 0.562398.
Train: 2018-08-01T00:31:01.437954: step 9155, loss 0.52814.
Train: 2018-08-01T00:31:01.609760: step 9156, loss 0.596763.
Train: 2018-08-01T00:31:01.766002: step 9157, loss 0.68297.
Train: 2018-08-01T00:31:01.922215: step 9158, loss 0.493476.
Train: 2018-08-01T00:31:02.078429: step 9159, loss 0.51064.
Train: 2018-08-01T00:31:02.234647: step 9160, loss 0.579688.
Test: 2018-08-01T00:31:02.718874: step 9160, loss 0.547908.
Train: 2018-08-01T00:31:02.859465: step 9161, loss 0.527782.
Train: 2018-08-01T00:31:03.015703: step 9162, loss 0.510381.
Train: 2018-08-01T00:31:03.187543: step 9163, loss 0.579798.
Train: 2018-08-01T00:31:03.343727: step 9164, loss 0.562421.
Train: 2018-08-01T00:31:03.499940: step 9165, loss 0.49266.
Train: 2018-08-01T00:31:03.656154: step 9166, loss 0.544953.
Train: 2018-08-01T00:31:03.843611: step 9167, loss 0.544923.
Train: 2018-08-01T00:31:03.999823: step 9168, loss 0.527332.
Train: 2018-08-01T00:31:04.156036: step 9169, loss 0.456831.
Train: 2018-08-01T00:31:04.327903: step 9170, loss 0.509483.
Test: 2018-08-01T00:31:04.796510: step 9170, loss 0.54767.
Train: 2018-08-01T00:31:04.983992: step 9171, loss 0.668968.
Train: 2018-08-01T00:31:05.124590: step 9172, loss 0.526993.
Train: 2018-08-01T00:31:05.280804: step 9173, loss 0.526936.
Train: 2018-08-01T00:31:05.436986: step 9174, loss 0.509025.
Train: 2018-08-01T00:31:05.593234: step 9175, loss 0.562605.
Train: 2018-08-01T00:31:05.749444: step 9176, loss 0.490875.
Train: 2018-08-01T00:31:05.905628: step 9177, loss 0.634617.
Train: 2018-08-01T00:31:06.093084: step 9178, loss 0.562676.
Train: 2018-08-01T00:31:06.249321: step 9179, loss 0.544654.
Train: 2018-08-01T00:31:06.405511: step 9180, loss 0.490485.
Test: 2018-08-01T00:31:06.858529: step 9180, loss 0.547579.
Train: 2018-08-01T00:31:07.014743: step 9181, loss 0.598897.
Train: 2018-08-01T00:31:07.202198: step 9182, loss 0.508426.
Train: 2018-08-01T00:31:07.358411: step 9183, loss 0.580884.
Train: 2018-08-01T00:31:07.514656: step 9184, loss 0.599055.
Train: 2018-08-01T00:31:07.670869: step 9185, loss 0.526476.
Train: 2018-08-01T00:31:07.842698: step 9186, loss 0.68984.
Train: 2018-08-01T00:31:07.998920: step 9187, loss 0.580876.
Train: 2018-08-01T00:31:08.155106: step 9188, loss 0.562728.
Train: 2018-08-01T00:31:08.326934: step 9189, loss 0.580763.
Train: 2018-08-01T00:31:08.483148: step 9190, loss 0.454556.
Test: 2018-08-01T00:31:08.936168: step 9190, loss 0.547591.
Train: 2018-08-01T00:31:09.108003: step 9191, loss 0.598695.
Train: 2018-08-01T00:31:09.295490: step 9192, loss 0.54467.
Train: 2018-08-01T00:31:09.451671: step 9193, loss 0.688465.
Train: 2018-08-01T00:31:09.607884: step 9194, loss 0.508847.
Train: 2018-08-01T00:31:09.748507: step 9195, loss 0.616274.
Train: 2018-08-01T00:31:09.920342: step 9196, loss 0.616112.
Train: 2018-08-01T00:31:10.076525: step 9197, loss 0.651489.
Train: 2018-08-01T00:31:10.232769: step 9198, loss 0.686502.
Train: 2018-08-01T00:31:10.404604: step 9199, loss 0.580086.
Train: 2018-08-01T00:31:10.560792: step 9200, loss 0.562445.
Test: 2018-08-01T00:31:11.013836: step 9200, loss 0.547831.
Train: 2018-08-01T00:31:11.716766: step 9201, loss 0.562423.
Train: 2018-08-01T00:31:11.873010: step 9202, loss 0.510371.
Train: 2018-08-01T00:31:12.029223: step 9203, loss 0.562402.
Train: 2018-08-01T00:31:12.185408: step 9204, loss 0.545166.
Train: 2018-08-01T00:31:12.341619: step 9205, loss 0.528021.
Train: 2018-08-01T00:31:12.513456: step 9206, loss 0.579551.
Train: 2018-08-01T00:31:12.669668: step 9207, loss 0.511027.
Train: 2018-08-01T00:31:12.825880: step 9208, loss 0.476861.
Train: 2018-08-01T00:31:12.982125: step 9209, loss 0.613741.
Train: 2018-08-01T00:31:13.138309: step 9210, loss 0.545287.
Test: 2018-08-01T00:31:13.622602: step 9210, loss 0.54807.
Train: 2018-08-01T00:31:13.794435: step 9211, loss 0.511071.
Train: 2018-08-01T00:31:13.966239: step 9212, loss 0.579517.
Train: 2018-08-01T00:31:14.122483: step 9213, loss 0.579524.
Train: 2018-08-01T00:31:14.278696: step 9214, loss 0.648048.
Train: 2018-08-01T00:31:14.450501: step 9215, loss 0.545286.
Train: 2018-08-01T00:31:14.606714: step 9216, loss 0.49401.
Train: 2018-08-01T00:31:14.762928: step 9217, loss 0.459782.
Train: 2018-08-01T00:31:14.919174: step 9218, loss 0.630934.
Train: 2018-08-01T00:31:15.075385: step 9219, loss 0.596687.
Train: 2018-08-01T00:31:15.231598: step 9220, loss 0.425221.
Test: 2018-08-01T00:31:15.715859: step 9220, loss 0.548006.
Train: 2018-08-01T00:31:15.872074: step 9221, loss 0.596763.
Train: 2018-08-01T00:31:16.028256: step 9222, loss 0.562396.
Train: 2018-08-01T00:31:16.184500: step 9223, loss 0.527939.
Train: 2018-08-01T00:31:16.356335: step 9224, loss 0.579656.
Train: 2018-08-01T00:31:16.512549: step 9225, loss 0.63151.
Train: 2018-08-01T00:31:16.668762: step 9226, loss 0.596956.
Train: 2018-08-01T00:31:16.824969: step 9227, loss 0.631473.
Train: 2018-08-01T00:31:16.981189: step 9228, loss 0.562398.
Train: 2018-08-01T00:31:17.152993: step 9229, loss 0.631267.
Train: 2018-08-01T00:31:17.309242: step 9230, loss 0.579573.
Test: 2018-08-01T00:31:17.777846: step 9230, loss 0.548045.
Train: 2018-08-01T00:31:17.934060: step 9231, loss 0.545258.
Train: 2018-08-01T00:31:18.105895: step 9232, loss 0.562396.
Train: 2018-08-01T00:31:18.262123: step 9233, loss 0.528243.
Train: 2018-08-01T00:31:18.402700: step 9234, loss 0.562399.
Train: 2018-08-01T00:31:18.558913: step 9235, loss 0.596493.
Train: 2018-08-01T00:31:18.715152: step 9236, loss 0.664551.
Train: 2018-08-01T00:31:18.886993: step 9237, loss 0.562408.
Train: 2018-08-01T00:31:19.043206: step 9238, loss 0.630168.
Train: 2018-08-01T00:31:19.215035: step 9239, loss 0.427344.
Train: 2018-08-01T00:31:19.371224: step 9240, loss 0.663667.
Test: 2018-08-01T00:31:19.839863: step 9240, loss 0.548335.
Train: 2018-08-01T00:31:19.996110: step 9241, loss 0.562435.
Train: 2018-08-01T00:31:20.167937: step 9242, loss 0.612861.
Train: 2018-08-01T00:31:20.355398: step 9243, loss 0.461862.
Train: 2018-08-01T00:31:20.511612: step 9244, loss 0.663.
Train: 2018-08-01T00:31:20.667825: step 9245, loss 0.595916.
Train: 2018-08-01T00:31:20.824038: step 9246, loss 0.56248.
Train: 2018-08-01T00:31:20.980253: step 9247, loss 0.529181.
Train: 2018-08-01T00:31:21.152058: step 9248, loss 0.462671.
Train: 2018-08-01T00:31:21.323917: step 9249, loss 0.529194.
Train: 2018-08-01T00:31:21.464514: step 9250, loss 0.59583.
Test: 2018-08-01T00:31:21.933153: step 9250, loss 0.54851.
Train: 2018-08-01T00:31:22.089337: step 9251, loss 0.595851.
Train: 2018-08-01T00:31:22.245587: step 9252, loss 0.56248.
Train: 2018-08-01T00:31:22.417386: step 9253, loss 0.512397.
Train: 2018-08-01T00:31:22.573599: step 9254, loss 0.495618.
Train: 2018-08-01T00:31:22.729813: step 9255, loss 0.562459.
Train: 2018-08-01T00:31:22.886057: step 9256, loss 0.612803.
Train: 2018-08-01T00:31:23.042238: step 9257, loss 0.596051.
Train: 2018-08-01T00:31:23.198483: step 9258, loss 0.528814.
Train: 2018-08-01T00:31:23.354690: step 9259, loss 0.461443.
Train: 2018-08-01T00:31:23.526502: step 9260, loss 0.579302.
Test: 2018-08-01T00:31:23.995140: step 9260, loss 0.548255.
Train: 2018-08-01T00:31:24.151378: step 9261, loss 0.731552.
Train: 2018-08-01T00:31:24.307598: step 9262, loss 0.630031.
Train: 2018-08-01T00:31:24.463806: step 9263, loss 0.528673.
Train: 2018-08-01T00:31:24.651268: step 9264, loss 0.579291.
Train: 2018-08-01T00:31:24.807481: step 9265, loss 0.52874.
Train: 2018-08-01T00:31:24.963694: step 9266, loss 0.562434.
Train: 2018-08-01T00:31:25.119901: step 9267, loss 0.528757.
Train: 2018-08-01T00:31:25.276122: step 9268, loss 0.629817.
Train: 2018-08-01T00:31:25.432335: step 9269, loss 0.663451.
Train: 2018-08-01T00:31:25.588518: step 9270, loss 0.612848.
Test: 2018-08-01T00:31:26.057188: step 9270, loss 0.548424.
Train: 2018-08-01T00:31:26.213371: step 9271, loss 0.562457.
Train: 2018-08-01T00:31:26.369585: step 9272, loss 0.478867.
Train: 2018-08-01T00:31:26.525798: step 9273, loss 0.529052.
Train: 2018-08-01T00:31:26.682046: step 9274, loss 0.612607.
Train: 2018-08-01T00:31:26.853846: step 9275, loss 0.662681.
Train: 2018-08-01T00:31:27.010090: step 9276, loss 0.545822.
Train: 2018-08-01T00:31:27.166303: step 9277, loss 0.678986.
Train: 2018-08-01T00:31:27.322517: step 9278, loss 0.54593.
Train: 2018-08-01T00:31:27.478725: step 9279, loss 0.479793.
Train: 2018-08-01T00:31:27.634913: step 9280, loss 0.562544.
Test: 2018-08-01T00:31:28.103554: step 9280, loss 0.548707.
Train: 2018-08-01T00:31:28.259797: step 9281, loss 0.529491.
Train: 2018-08-01T00:31:28.416011: step 9282, loss 0.628674.
Train: 2018-08-01T00:31:28.572225: step 9283, loss 0.546033.
Train: 2018-08-01T00:31:28.728408: step 9284, loss 0.562555.
Train: 2018-08-01T00:31:28.900273: step 9285, loss 0.562556.
Train: 2018-08-01T00:31:29.072101: step 9286, loss 0.595581.
Train: 2018-08-01T00:31:29.228322: step 9287, loss 0.496533.
Train: 2018-08-01T00:31:29.400155: step 9288, loss 0.595593.
Train: 2018-08-01T00:31:29.556339: step 9289, loss 0.479914.
Train: 2018-08-01T00:31:29.712584: step 9290, loss 0.512864.
Test: 2018-08-01T00:31:30.196844: step 9290, loss 0.548615.
Train: 2018-08-01T00:31:30.353026: step 9291, loss 0.545916.
Train: 2018-08-01T00:31:30.493650: step 9292, loss 0.545853.
Train: 2018-08-01T00:31:30.665453: step 9293, loss 0.61255.
Train: 2018-08-01T00:31:30.821667: step 9294, loss 0.512309.
Train: 2018-08-01T00:31:30.977880: step 9295, loss 0.595979.
Train: 2018-08-01T00:31:31.134133: step 9296, loss 0.545655.
Train: 2018-08-01T00:31:31.305929: step 9297, loss 0.562438.
Train: 2018-08-01T00:31:31.462173: step 9298, loss 0.612997.
Train: 2018-08-01T00:31:31.618356: step 9299, loss 0.646781.
Train: 2018-08-01T00:31:31.774599: step 9300, loss 0.596155.
Test: 2018-08-01T00:31:32.243235: step 9300, loss 0.548323.
Train: 2018-08-01T00:31:32.961791: step 9301, loss 0.511886.
Train: 2018-08-01T00:31:33.118029: step 9302, loss 0.461333.
Train: 2018-08-01T00:31:33.274249: step 9303, loss 0.579304.
Train: 2018-08-01T00:31:33.461674: step 9304, loss 0.494816.
Train: 2018-08-01T00:31:33.617887: step 9305, loss 0.528533.
Train: 2018-08-01T00:31:33.774101: step 9306, loss 0.579392.
Train: 2018-08-01T00:31:33.930345: step 9307, loss 0.545381.
Train: 2018-08-01T00:31:34.086558: step 9308, loss 0.528281.
Train: 2018-08-01T00:31:34.258362: step 9309, loss 0.493988.
Train: 2018-08-01T00:31:34.445845: step 9310, loss 0.545237.
Test: 2018-08-01T00:31:34.914489: step 9310, loss 0.547982.
Train: 2018-08-01T00:31:35.070673: step 9311, loss 0.665684.
Train: 2018-08-01T00:31:35.226886: step 9312, loss 0.424497.
Train: 2018-08-01T00:31:35.383130: step 9313, loss 0.545109.
Train: 2018-08-01T00:31:35.539314: step 9314, loss 0.562409.
Train: 2018-08-01T00:31:35.695556: step 9315, loss 0.545021.
Train: 2018-08-01T00:31:35.851770: step 9316, loss 0.510096.
Train: 2018-08-01T00:31:36.007952: step 9317, loss 0.544942.
Train: 2018-08-01T00:31:36.164196: step 9318, loss 0.527352.
Train: 2018-08-01T00:31:36.320410: step 9319, loss 0.562473.
Train: 2018-08-01T00:31:36.476623: step 9320, loss 0.491872.
Test: 2018-08-01T00:31:36.945232: step 9320, loss 0.547681.
Train: 2018-08-01T00:31:37.085856: step 9321, loss 0.509373.
Train: 2018-08-01T00:31:37.242070: step 9322, loss 0.669216.
Train: 2018-08-01T00:31:37.413904: step 9323, loss 0.562557.
Train: 2018-08-01T00:31:37.570117: step 9324, loss 0.455574.
Train: 2018-08-01T00:31:37.741922: step 9325, loss 0.508957.
Train: 2018-08-01T00:31:37.898134: step 9326, loss 0.598488.
Train: 2018-08-01T00:31:38.054379: step 9327, loss 0.616549.
Train: 2018-08-01T00:31:38.210592: step 9328, loss 0.544672.
Train: 2018-08-01T00:31:38.366805: step 9329, loss 0.598666.
Train: 2018-08-01T00:31:38.523019: step 9330, loss 0.454652.
Test: 2018-08-01T00:31:38.991660: step 9330, loss 0.547588.
Train: 2018-08-01T00:31:39.147873: step 9331, loss 0.46653.
Train: 2018-08-01T00:31:39.304057: step 9332, loss 0.580789.
Train: 2018-08-01T00:31:39.460294: step 9333, loss 0.580845.
Train: 2018-08-01T00:31:39.632103: step 9334, loss 0.689651.
Train: 2018-08-01T00:31:39.788349: step 9335, loss 0.617083.
Train: 2018-08-01T00:31:39.960183: step 9336, loss 0.653137.
Train: 2018-08-01T00:31:40.116366: step 9337, loss 0.598748.
Train: 2018-08-01T00:31:40.272579: step 9338, loss 0.508733.
Train: 2018-08-01T00:31:40.428823: step 9339, loss 0.63434.
Train: 2018-08-01T00:31:40.585006: step 9340, loss 0.58046.
Test: 2018-08-01T00:31:41.069298: step 9340, loss 0.547644.
Train: 2018-08-01T00:31:41.225482: step 9341, loss 0.509126.
Train: 2018-08-01T00:31:41.381694: step 9342, loss 0.633612.
Train: 2018-08-01T00:31:41.537908: step 9343, loss 0.473961.
Train: 2018-08-01T00:31:41.694152: step 9344, loss 0.491786.
Train: 2018-08-01T00:31:41.865989: step 9345, loss 0.509498.
Train: 2018-08-01T00:31:42.022169: step 9346, loss 0.544829.
Train: 2018-08-01T00:31:42.194005: step 9347, loss 0.491821.
Train: 2018-08-01T00:31:42.350218: step 9348, loss 0.562503.
Train: 2018-08-01T00:31:42.506462: step 9349, loss 0.509403.
Train: 2018-08-01T00:31:42.662674: step 9350, loss 0.668882.
Test: 2018-08-01T00:31:43.131315: step 9350, loss 0.547678.
Train: 2018-08-01T00:31:43.318771: step 9351, loss 0.61568.
Train: 2018-08-01T00:31:43.474984: step 9352, loss 0.562508.
Train: 2018-08-01T00:31:43.631192: step 9353, loss 0.5625.
Train: 2018-08-01T00:31:43.787405: step 9354, loss 0.509514.
Train: 2018-08-01T00:31:43.928003: step 9355, loss 0.615448.
Train: 2018-08-01T00:31:44.099833: step 9356, loss 0.580113.
Train: 2018-08-01T00:31:44.256052: step 9357, loss 0.615293.
Train: 2018-08-01T00:31:44.427886: step 9358, loss 0.527322.
Train: 2018-08-01T00:31:44.584102: step 9359, loss 0.597539.
Train: 2018-08-01T00:31:44.755935: step 9360, loss 0.474896.
Test: 2018-08-01T00:31:45.224575: step 9360, loss 0.547786.
Train: 2018-08-01T00:31:45.380759: step 9361, loss 0.632441.
Train: 2018-08-01T00:31:45.552593: step 9362, loss 0.544961.
Train: 2018-08-01T00:31:45.708806: step 9363, loss 0.614783.
Train: 2018-08-01T00:31:45.865020: step 9364, loss 0.510168.
Train: 2018-08-01T00:31:46.036855: step 9365, loss 0.64942.
Train: 2018-08-01T00:31:46.193098: step 9366, loss 0.510328.
Train: 2018-08-01T00:31:46.349311: step 9367, loss 0.579747.
Train: 2018-08-01T00:31:46.521116: step 9368, loss 0.475837.
Train: 2018-08-01T00:31:46.677329: step 9369, loss 0.545092.
Train: 2018-08-01T00:31:46.817921: step 9370, loss 0.475827.
Test: 2018-08-01T00:31:47.302207: step 9370, loss 0.547888.
Train: 2018-08-01T00:31:47.458397: step 9371, loss 0.527728.
Train: 2018-08-01T00:31:47.645852: step 9372, loss 0.475561.
Train: 2018-08-01T00:31:47.802095: step 9373, loss 0.632099.
Train: 2018-08-01T00:31:47.958279: step 9374, loss 0.544983.
Train: 2018-08-01T00:31:48.114524: step 9375, loss 0.440139.
Train: 2018-08-01T00:31:48.270736: step 9376, loss 0.650068.
Train: 2018-08-01T00:31:48.426949: step 9377, loss 0.422063.
Train: 2018-08-01T00:31:48.583158: step 9378, loss 0.492051.
Train: 2018-08-01T00:31:48.754992: step 9379, loss 0.544825.
Train: 2018-08-01T00:31:48.911216: step 9380, loss 0.562523.
Test: 2018-08-01T00:31:49.379822: step 9380, loss 0.547652.
Train: 2018-08-01T00:31:49.536065: step 9381, loss 0.562549.
Train: 2018-08-01T00:31:49.692278: step 9382, loss 0.491223.
Train: 2018-08-01T00:31:49.864084: step 9383, loss 0.598394.
Train: 2018-08-01T00:31:50.035948: step 9384, loss 0.634372.
Train: 2018-08-01T00:31:50.192161: step 9385, loss 0.526732.
Train: 2018-08-01T00:31:50.363992: step 9386, loss 0.56265.
Train: 2018-08-01T00:31:50.504589: step 9387, loss 0.490702.
Train: 2018-08-01T00:31:50.676429: step 9388, loss 0.652773.
Train: 2018-08-01T00:31:50.832636: step 9389, loss 0.490599.
Train: 2018-08-01T00:31:51.020063: step 9390, loss 0.616799.
Test: 2018-08-01T00:31:51.488701: step 9390, loss 0.547587.
Train: 2018-08-01T00:31:51.660538: step 9391, loss 0.52662.
Train: 2018-08-01T00:31:51.816751: step 9392, loss 0.634846.
Train: 2018-08-01T00:31:51.988616: step 9393, loss 0.526637.
Train: 2018-08-01T00:31:52.144829: step 9394, loss 0.52665.
Train: 2018-08-01T00:31:52.301042: step 9395, loss 0.634714.
Train: 2018-08-01T00:31:52.457256: step 9396, loss 0.598633.
Train: 2018-08-01T00:31:52.613472: step 9397, loss 0.616504.
Train: 2018-08-01T00:31:52.769683: step 9398, loss 0.508881.
Train: 2018-08-01T00:31:52.925897: step 9399, loss 0.598356.
Train: 2018-08-01T00:31:53.113356: step 9400, loss 0.52689.
Test: 2018-08-01T00:31:53.581992: step 9400, loss 0.547643.
Train: 2018-08-01T00:31:54.238059: step 9401, loss 0.651634.
Train: 2018-08-01T00:31:54.409924: step 9402, loss 0.562537.
Train: 2018-08-01T00:31:54.566132: step 9403, loss 0.615672.
Train: 2018-08-01T00:31:54.722352: step 9404, loss 0.6508.
Train: 2018-08-01T00:31:54.878534: step 9405, loss 0.474536.
Train: 2018-08-01T00:31:55.034748: step 9406, loss 0.562451.
Train: 2018-08-01T00:31:55.190991: step 9407, loss 0.492458.
Train: 2018-08-01T00:31:55.362795: step 9408, loss 0.579906.
Train: 2018-08-01T00:31:55.519039: step 9409, loss 0.544981.
Train: 2018-08-01T00:31:55.675221: step 9410, loss 0.632131.
Test: 2018-08-01T00:31:56.159514: step 9410, loss 0.547854.
Train: 2018-08-01T00:31:56.315723: step 9411, loss 0.649368.
Train: 2018-08-01T00:31:56.487566: step 9412, loss 0.510404.
Train: 2018-08-01T00:31:56.643776: step 9413, loss 0.545106.
Train: 2018-08-01T00:31:56.815580: step 9414, loss 0.683268.
Train: 2018-08-01T00:31:56.971794: step 9415, loss 0.614022.
Train: 2018-08-01T00:31:57.128038: step 9416, loss 0.579538.
Train: 2018-08-01T00:31:57.284251: step 9417, loss 0.494084.
Train: 2018-08-01T00:31:57.456086: step 9418, loss 0.630557.
Train: 2018-08-01T00:31:57.627914: step 9419, loss 0.681309.
Train: 2018-08-01T00:31:57.784103: step 9420, loss 0.596235.
Test: 2018-08-01T00:31:58.252744: step 9420, loss 0.548344.
Train: 2018-08-01T00:31:58.408957: step 9421, loss 0.478288.
Train: 2018-08-01T00:31:58.580825: step 9422, loss 0.495319.
Train: 2018-08-01T00:31:58.737035: step 9423, loss 0.528938.
Train: 2018-08-01T00:31:58.893219: step 9424, loss 0.629454.
Train: 2018-08-01T00:31:59.049462: step 9425, loss 0.595913.
Train: 2018-08-01T00:31:59.205677: step 9426, loss 0.579171.
Train: 2018-08-01T00:31:59.361889: step 9427, loss 0.529168.
Train: 2018-08-01T00:31:59.518102: step 9428, loss 0.562497.
Train: 2018-08-01T00:31:59.689908: step 9429, loss 0.579133.
Train: 2018-08-01T00:31:59.830530: step 9430, loss 0.512661.
Test: 2018-08-01T00:32:00.314790: step 9430, loss 0.548592.
Train: 2018-08-01T00:32:00.486620: step 9431, loss 0.54589.
Train: 2018-08-01T00:32:00.642845: step 9432, loss 0.595756.
Train: 2018-08-01T00:32:00.814674: step 9433, loss 0.562504.
Train: 2018-08-01T00:32:00.955272: step 9434, loss 0.495992.
Train: 2018-08-01T00:32:01.111475: step 9435, loss 0.612443.
Train: 2018-08-01T00:32:01.283314: step 9436, loss 0.46255.
Train: 2018-08-01T00:32:01.439498: step 9437, loss 0.579171.
Train: 2018-08-01T00:32:01.595711: step 9438, loss 0.57919.
Train: 2018-08-01T00:32:01.751955: step 9439, loss 0.646183.
Train: 2018-08-01T00:32:01.923789: step 9440, loss 0.646183.
Test: 2018-08-01T00:32:02.392429: step 9440, loss 0.548464.
Train: 2018-08-01T00:32:02.548613: step 9441, loss 0.562468.
Train: 2018-08-01T00:32:02.704827: step 9442, loss 0.629298.
Train: 2018-08-01T00:32:02.861072: step 9443, loss 0.629182.
Train: 2018-08-01T00:32:03.032898: step 9444, loss 0.529244.
Train: 2018-08-01T00:32:03.189112: step 9445, loss 0.479516.
Train: 2018-08-01T00:32:03.345331: step 9446, loss 0.678698.
Train: 2018-08-01T00:32:03.501515: step 9447, loss 0.562531.
Train: 2018-08-01T00:32:03.657759: step 9448, loss 0.512924.
Train: 2018-08-01T00:32:03.813942: step 9449, loss 0.628673.
Train: 2018-08-01T00:32:03.970185: step 9450, loss 0.66161.
Test: 2018-08-01T00:32:04.438794: step 9450, loss 0.548795.
Train: 2018-08-01T00:32:04.610629: step 9451, loss 0.595509.
Train: 2018-08-01T00:32:04.766842: step 9452, loss 0.529775.
Train: 2018-08-01T00:32:04.938708: step 9453, loss 0.579011.
Train: 2018-08-01T00:32:05.094919: step 9454, loss 0.49722.
Train: 2018-08-01T00:32:05.266762: step 9455, loss 0.497249.
Train: 2018-08-01T00:32:05.438561: step 9456, loss 0.513544.
Train: 2018-08-01T00:32:05.594774: step 9457, loss 0.56262.
Train: 2018-08-01T00:32:05.750987: step 9458, loss 0.496908.
Train: 2018-08-01T00:32:05.922847: step 9459, loss 0.529636.
Train: 2018-08-01T00:32:06.079036: step 9460, loss 0.546026.
Test: 2018-08-01T00:32:06.547706: step 9460, loss 0.548642.
Train: 2018-08-01T00:32:06.719542: step 9461, loss 0.479631.
Train: 2018-08-01T00:32:06.875724: step 9462, loss 0.512537.
Train: 2018-08-01T00:32:07.031968: step 9463, loss 0.612664.
Train: 2018-08-01T00:32:07.203806: step 9464, loss 0.57924.
Train: 2018-08-01T00:32:07.391229: step 9465, loss 0.562433.
Train: 2018-08-01T00:32:07.547472: step 9466, loss 0.629998.
Train: 2018-08-01T00:32:07.719276: step 9467, loss 0.511657.
Train: 2018-08-01T00:32:07.875521: step 9468, loss 0.579368.
Train: 2018-08-01T00:32:08.031734: step 9469, loss 0.528431.
Train: 2018-08-01T00:32:08.187947: step 9470, loss 0.613476.
Test: 2018-08-01T00:32:08.672179: step 9470, loss 0.548127.
Train: 2018-08-01T00:32:08.812801: step 9471, loss 0.596489.
Train: 2018-08-01T00:32:08.984606: step 9472, loss 0.443021.
Train: 2018-08-01T00:32:09.140843: step 9473, loss 0.528209.
Train: 2018-08-01T00:32:09.297057: step 9474, loss 0.528117.
Train: 2018-08-01T00:32:09.453245: step 9475, loss 0.699907.
Train: 2018-08-01T00:32:09.625080: step 9476, loss 0.596792.
Train: 2018-08-01T00:32:09.765673: step 9477, loss 0.579593.
Train: 2018-08-01T00:32:09.937537: step 9478, loss 0.528013.
Train: 2018-08-01T00:32:10.093721: step 9479, loss 0.562396.
Train: 2018-08-01T00:32:10.249935: step 9480, loss 0.562396.
Test: 2018-08-01T00:32:10.718574: step 9480, loss 0.547992.
Train: 2018-08-01T00:32:10.874787: step 9481, loss 0.545195.
Train: 2018-08-01T00:32:11.031001: step 9482, loss 0.579605.
Train: 2018-08-01T00:32:11.187215: step 9483, loss 0.579606.
Train: 2018-08-01T00:32:11.343459: step 9484, loss 0.614016.
Train: 2018-08-01T00:32:11.499641: step 9485, loss 0.528016.
Train: 2018-08-01T00:32:11.655886: step 9486, loss 0.631132.
Train: 2018-08-01T00:32:11.827715: step 9487, loss 0.596717.
Train: 2018-08-01T00:32:11.999524: step 9488, loss 0.596657.
Train: 2018-08-01T00:32:12.155770: step 9489, loss 0.545302.
Train: 2018-08-01T00:32:12.311981: step 9490, loss 0.681869.
Test: 2018-08-01T00:32:12.780592: step 9490, loss 0.548159.
Train: 2018-08-01T00:32:12.968047: step 9491, loss 0.494357.
Train: 2018-08-01T00:32:13.124292: step 9492, loss 0.647306.
Train: 2018-08-01T00:32:13.280504: step 9493, loss 0.477768.
Train: 2018-08-01T00:32:13.436718: step 9494, loss 0.562419.
Train: 2018-08-01T00:32:13.592931: step 9495, loss 0.461094.
Train: 2018-08-01T00:32:13.764766: step 9496, loss 0.511725.
Train: 2018-08-01T00:32:13.920987: step 9497, loss 0.680873.
Train: 2018-08-01T00:32:14.092784: step 9498, loss 0.545505.
Train: 2018-08-01T00:32:14.249028: step 9499, loss 0.545508.
Train: 2018-08-01T00:32:14.405241: step 9500, loss 0.613158.
Test: 2018-08-01T00:32:14.905094: step 9500, loss 0.548266.
Train: 2018-08-01T00:32:15.623706: step 9501, loss 0.528614.
Train: 2018-08-01T00:32:15.779914: step 9502, loss 0.477901.
Train: 2018-08-01T00:32:15.936134: step 9503, loss 0.562416.
Train: 2018-08-01T00:32:16.107981: step 9504, loss 0.545462.
Train: 2018-08-01T00:32:16.279772: step 9505, loss 0.528458.
Train: 2018-08-01T00:32:16.436011: step 9506, loss 0.579411.
Train: 2018-08-01T00:32:16.592198: step 9507, loss 0.511305.
Train: 2018-08-01T00:32:16.764033: step 9508, loss 0.562398.
Train: 2018-08-01T00:32:16.920277: step 9509, loss 0.528194.
Train: 2018-08-01T00:32:17.076460: step 9510, loss 0.596676.
Test: 2018-08-01T00:32:17.560752: step 9510, loss 0.548021.
Train: 2018-08-01T00:32:17.716966: step 9511, loss 0.459398.
Train: 2018-08-01T00:32:17.873149: step 9512, loss 0.562397.
Train: 2018-08-01T00:32:18.029362: step 9513, loss 0.579661.
Train: 2018-08-01T00:32:18.185576: step 9514, loss 0.545106.
Train: 2018-08-01T00:32:18.357412: step 9515, loss 0.493074.
Train: 2018-08-01T00:32:18.513654: step 9516, loss 0.64933.
Train: 2018-08-01T00:32:18.669837: step 9517, loss 0.545014.
Train: 2018-08-01T00:32:18.826051: step 9518, loss 0.544996.
Train: 2018-08-01T00:32:18.982264: step 9519, loss 0.684594.
Train: 2018-08-01T00:32:19.138478: step 9520, loss 0.562427.
Test: 2018-08-01T00:32:19.607148: step 9520, loss 0.547827.
Train: 2018-08-01T00:32:19.763362: step 9521, loss 0.562424.
Train: 2018-08-01T00:32:19.919575: step 9522, loss 0.597265.
Train: 2018-08-01T00:32:20.075758: step 9523, loss 0.527614.
Train: 2018-08-01T00:32:20.232002: step 9524, loss 0.440664.
Train: 2018-08-01T00:32:20.388185: step 9525, loss 0.492759.
Train: 2018-08-01T00:32:20.560059: step 9526, loss 0.475166.
Train: 2018-08-01T00:32:20.700612: step 9527, loss 0.544935.
Train: 2018-08-01T00:32:20.856855: step 9528, loss 0.562458.
Train: 2018-08-01T00:32:21.013069: step 9529, loss 0.49205.
Train: 2018-08-01T00:32:21.169282: step 9530, loss 0.615483.
Test: 2018-08-01T00:32:21.637894: step 9530, loss 0.547687.
Train: 2018-08-01T00:32:21.809728: step 9531, loss 0.580208.
Train: 2018-08-01T00:32:21.965971: step 9532, loss 0.597973.
Train: 2018-08-01T00:32:22.137775: step 9533, loss 0.527046.
Train: 2018-08-01T00:32:22.278398: step 9534, loss 0.615809.
Train: 2018-08-01T00:32:22.434582: step 9535, loss 0.598055.
Train: 2018-08-01T00:32:22.606415: step 9536, loss 0.491528.
Train: 2018-08-01T00:32:22.762630: step 9537, loss 0.527018.
Train: 2018-08-01T00:32:22.918842: step 9538, loss 0.615852.
Train: 2018-08-01T00:32:23.075080: step 9539, loss 0.598073.
Train: 2018-08-01T00:32:23.231296: step 9540, loss 0.562531.
Test: 2018-08-01T00:32:23.715560: step 9540, loss 0.547671.
Train: 2018-08-01T00:32:23.887365: step 9541, loss 0.509309.
Train: 2018-08-01T00:32:24.043579: step 9542, loss 0.597997.
Train: 2018-08-01T00:32:24.199793: step 9543, loss 0.633415.
Train: 2018-08-01T00:32:24.356006: step 9544, loss 0.544812.
Train: 2018-08-01T00:32:24.512219: step 9545, loss 0.38582.
Train: 2018-08-01T00:32:24.668432: step 9546, loss 0.474065.
Train: 2018-08-01T00:32:24.824677: step 9547, loss 0.562519.
Train: 2018-08-01T00:32:24.996480: step 9548, loss 0.562534.
Train: 2018-08-01T00:32:25.152724: step 9549, loss 0.59812.
Train: 2018-08-01T00:32:25.324560: step 9550, loss 0.580353.
Test: 2018-08-01T00:32:25.793169: step 9550, loss 0.547646.
Train: 2018-08-01T00:32:25.949383: step 9551, loss 0.598168.
Train: 2018-08-01T00:32:26.121217: step 9552, loss 0.580353.
Train: 2018-08-01T00:32:26.277461: step 9553, loss 0.580335.
Train: 2018-08-01T00:32:26.433644: step 9554, loss 0.526999.
Train: 2018-08-01T00:32:26.589887: step 9555, loss 0.49149.
Train: 2018-08-01T00:32:26.746102: step 9556, loss 0.562538.
Train: 2018-08-01T00:32:26.902285: step 9557, loss 0.704732.
Train: 2018-08-01T00:32:27.058538: step 9558, loss 0.544785.
Train: 2018-08-01T00:32:27.230367: step 9559, loss 0.527088.
Train: 2018-08-01T00:32:27.386546: step 9560, loss 0.615592.
Test: 2018-08-01T00:32:27.855211: step 9560, loss 0.547702.
Train: 2018-08-01T00:32:28.089508: step 9561, loss 0.509502.
Train: 2018-08-01T00:32:28.245745: step 9562, loss 0.54484.
Train: 2018-08-01T00:32:28.417585: step 9563, loss 0.491941.
Train: 2018-08-01T00:32:28.573798: step 9564, loss 0.562485.
Train: 2018-08-01T00:32:28.730012: step 9565, loss 0.562486.
Train: 2018-08-01T00:32:28.886195: step 9566, loss 0.615423.
Train: 2018-08-01T00:32:29.042408: step 9567, loss 0.580113.
Train: 2018-08-01T00:32:29.198621: step 9568, loss 0.474411.
Train: 2018-08-01T00:32:29.354835: step 9569, loss 0.580093.
Train: 2018-08-01T00:32:29.526700: step 9570, loss 0.562476.
Test: 2018-08-01T00:32:29.995340: step 9570, loss 0.547727.
Train: 2018-08-01T00:32:30.151548: step 9571, loss 0.474421.
Train: 2018-08-01T00:32:30.307765: step 9572, loss 0.544852.
Train: 2018-08-01T00:32:30.479596: step 9573, loss 0.509547.
Train: 2018-08-01T00:32:30.635816: step 9574, loss 0.562498.
Train: 2018-08-01T00:32:30.776408: step 9575, loss 0.52711.
Train: 2018-08-01T00:32:30.932615: step 9576, loss 0.704342.
Train: 2018-08-01T00:32:31.104450: step 9577, loss 0.527083.
Train: 2018-08-01T00:32:31.245048: step 9578, loss 0.491665.
Train: 2018-08-01T00:32:31.401231: step 9579, loss 0.527069.
Train: 2018-08-01T00:32:31.573091: step 9580, loss 0.527041.
Test: 2018-08-01T00:32:32.041705: step 9580, loss 0.54766.
Train: 2018-08-01T00:32:32.213541: step 9581, loss 0.615837.
Train: 2018-08-01T00:32:32.369754: step 9582, loss 0.580312.
Train: 2018-08-01T00:32:32.525999: step 9583, loss 0.562539.
Train: 2018-08-01T00:32:32.682182: step 9584, loss 0.598072.
Train: 2018-08-01T00:32:32.838395: step 9585, loss 0.580284.
Train: 2018-08-01T00:32:32.994638: step 9586, loss 0.651191.
Train: 2018-08-01T00:32:33.150822: step 9587, loss 0.474045.
Train: 2018-08-01T00:32:33.307036: step 9588, loss 0.438773.
Train: 2018-08-01T00:32:33.463278: step 9589, loss 0.633268.
Train: 2018-08-01T00:32:33.619492: step 9590, loss 0.509454.
Test: 2018-08-01T00:32:34.103723: step 9590, loss 0.547692.
Train: 2018-08-01T00:32:34.259967: step 9591, loss 0.562503.
Train: 2018-08-01T00:32:34.416180: step 9592, loss 0.615578.
Train: 2018-08-01T00:32:34.572363: step 9593, loss 0.5625.
Train: 2018-08-01T00:32:34.728577: step 9594, loss 0.650823.
Train: 2018-08-01T00:32:34.900442: step 9595, loss 0.580112.
Train: 2018-08-01T00:32:35.056655: step 9596, loss 0.632834.
Train: 2018-08-01T00:32:35.212838: step 9597, loss 0.457227.
Train: 2018-08-01T00:32:35.384704: step 9598, loss 0.597475.
Train: 2018-08-01T00:32:35.540886: step 9599, loss 0.492503.
Train: 2018-08-01T00:32:35.697130: step 9600, loss 0.544962.
Test: 2018-08-01T00:32:36.181361: step 9600, loss 0.547808.
Train: 2018-08-01T00:32:36.868731: step 9601, loss 0.492568.
Train: 2018-08-01T00:32:37.024914: step 9602, loss 0.579914.
Train: 2018-08-01T00:32:37.181128: step 9603, loss 0.562438.
Train: 2018-08-01T00:32:37.337341: step 9604, loss 0.649861.
Train: 2018-08-01T00:32:37.493585: step 9605, loss 0.597361.
Train: 2018-08-01T00:32:37.649768: step 9606, loss 0.562427.
Train: 2018-08-01T00:32:37.805982: step 9607, loss 0.527606.
Train: 2018-08-01T00:32:37.962195: step 9608, loss 0.545027.
Train: 2018-08-01T00:32:38.134029: step 9609, loss 0.440752.
Train: 2018-08-01T00:32:38.290243: step 9610, loss 0.56242.
Test: 2018-08-01T00:32:38.758883: step 9610, loss 0.547837.
Train: 2018-08-01T00:32:38.915129: step 9611, loss 0.562424.
Train: 2018-08-01T00:32:39.071309: step 9612, loss 0.579861.
Train: 2018-08-01T00:32:39.227554: step 9613, loss 0.579871.
Train: 2018-08-01T00:32:39.383767: step 9614, loss 0.544984.
Train: 2018-08-01T00:32:39.539975: step 9615, loss 0.54498.
Train: 2018-08-01T00:32:39.696165: step 9616, loss 0.544973.
Train: 2018-08-01T00:32:39.852377: step 9617, loss 0.544965.
Train: 2018-08-01T00:32:40.008590: step 9618, loss 0.57992.
Train: 2018-08-01T00:32:40.164833: step 9619, loss 0.527462.
Train: 2018-08-01T00:32:40.336674: step 9620, loss 0.492434.
Test: 2018-08-01T00:32:40.805279: step 9620, loss 0.54777.
Train: 2018-08-01T00:32:40.961492: step 9621, loss 0.579981.
Train: 2018-08-01T00:32:41.117730: step 9622, loss 0.61511.
Train: 2018-08-01T00:32:41.273918: step 9623, loss 0.597566.
Train: 2018-08-01T00:32:41.445753: step 9624, loss 0.562455.
Train: 2018-08-01T00:32:41.601967: step 9625, loss 0.562452.
Train: 2018-08-01T00:32:41.758180: step 9626, loss 0.579981.
Train: 2018-08-01T00:32:41.914394: step 9627, loss 0.720104.
Train: 2018-08-01T00:32:42.070638: step 9628, loss 0.544968.
Train: 2018-08-01T00:32:42.226845: step 9629, loss 0.475328.
Train: 2018-08-01T00:32:42.383034: step 9630, loss 0.545019.
Test: 2018-08-01T00:32:42.851675: step 9630, loss 0.547857.
Train: 2018-08-01T00:32:43.007919: step 9631, loss 0.545029.
Train: 2018-08-01T00:32:43.179723: step 9632, loss 0.673636.
Train: 2018-08-01T00:32:43.335966: step 9633, loss 0.527726.
Train: 2018-08-01T00:32:43.492180: step 9634, loss 0.545089.
Train: 2018-08-01T00:32:43.664010: step 9635, loss 0.527807.
Train: 2018-08-01T00:32:43.820198: step 9636, loss 0.475953.
Train: 2018-08-01T00:32:43.992032: step 9637, loss 0.631622.
Train: 2018-08-01T00:32:44.148277: step 9638, loss 0.510506.
Train: 2018-08-01T00:32:44.304490: step 9639, loss 0.475867.
Train: 2018-08-01T00:32:44.460703: step 9640, loss 0.458387.
Test: 2018-08-01T00:32:44.929342: step 9640, loss 0.547855.
Train: 2018-08-01T00:32:45.085557: step 9641, loss 0.684144.
Train: 2018-08-01T00:32:45.241740: step 9642, loss 0.632039.
Train: 2018-08-01T00:32:45.397984: step 9643, loss 0.510219.
Train: 2018-08-01T00:32:45.569787: step 9644, loss 0.510196.
Train: 2018-08-01T00:32:45.741623: step 9645, loss 0.632134.
Train: 2018-08-01T00:32:45.897836: step 9646, loss 0.510144.
Train: 2018-08-01T00:32:46.054074: step 9647, loss 0.527549.
Train: 2018-08-01T00:32:46.210294: step 9648, loss 0.475147.
Train: 2018-08-01T00:32:46.366501: step 9649, loss 0.562439.
Train: 2018-08-01T00:32:46.522689: step 9650, loss 0.650086.
Test: 2018-08-01T00:32:47.003931: step 9650, loss 0.547767.
Train: 2018-08-01T00:32:47.160144: step 9651, loss 0.527382.
Train: 2018-08-01T00:32:47.316353: step 9652, loss 0.509813.
Train: 2018-08-01T00:32:47.472542: step 9653, loss 0.54489.
Train: 2018-08-01T00:32:47.628754: step 9654, loss 0.580064.
Train: 2018-08-01T00:32:47.800589: step 9655, loss 0.474417.
Train: 2018-08-01T00:32:47.972455: step 9656, loss 0.580134.
Train: 2018-08-01T00:32:48.128639: step 9657, loss 0.615515.
Train: 2018-08-01T00:32:48.284850: step 9658, loss 0.527139.
Train: 2018-08-01T00:32:48.441096: step 9659, loss 0.580201.
Train: 2018-08-01T00:32:48.597308: step 9660, loss 0.597912.
Test: 2018-08-01T00:32:49.065952: step 9660, loss 0.547688.
Train: 2018-08-01T00:32:49.222162: step 9661, loss 0.509417.
Train: 2018-08-01T00:32:49.378377: step 9662, loss 0.615621.
Train: 2018-08-01T00:32:49.534559: step 9663, loss 0.544811.
Train: 2018-08-01T00:32:49.690802: step 9664, loss 0.580193.
Train: 2018-08-01T00:32:49.847010: step 9665, loss 0.580178.
Train: 2018-08-01T00:32:50.003229: step 9666, loss 0.615479.
Train: 2018-08-01T00:32:50.175064: step 9667, loss 0.54485.
Train: 2018-08-01T00:32:50.346904: step 9668, loss 0.544865.
Train: 2018-08-01T00:32:50.503112: step 9669, loss 0.650413.
Train: 2018-08-01T00:32:50.659326: step 9670, loss 0.632647.
Test: 2018-08-01T00:32:51.127965: step 9670, loss 0.547791.
Train: 2018-08-01T00:32:51.315416: step 9671, loss 0.579931.
Train: 2018-08-01T00:32:51.471636: step 9672, loss 0.475245.
Train: 2018-08-01T00:32:51.627819: step 9673, loss 0.684268.
Train: 2018-08-01T00:32:51.784062: step 9674, loss 0.527712.
Train: 2018-08-01T00:32:51.940244: step 9675, loss 0.510491.
Train: 2018-08-01T00:32:52.096459: step 9676, loss 0.545123.
Train: 2018-08-01T00:32:52.252706: step 9677, loss 0.527884.
Train: 2018-08-01T00:32:52.424532: step 9678, loss 0.562399.
Train: 2018-08-01T00:32:52.580720: step 9679, loss 0.562398.
Train: 2018-08-01T00:32:52.736934: step 9680, loss 0.562398.
Test: 2018-08-01T00:32:53.205603: step 9680, loss 0.547974.
Train: 2018-08-01T00:32:53.361812: step 9681, loss 0.52795.
Train: 2018-08-01T00:32:53.549268: step 9682, loss 0.493496.
Train: 2018-08-01T00:32:53.689866: step 9683, loss 0.683112.
Train: 2018-08-01T00:32:53.861695: step 9684, loss 0.562398.
Train: 2018-08-01T00:32:54.017914: step 9685, loss 0.562397.
Train: 2018-08-01T00:32:54.174133: step 9686, loss 0.596807.
Train: 2018-08-01T00:32:54.330346: step 9687, loss 0.545211.
Train: 2018-08-01T00:32:54.486525: step 9688, loss 0.528052.
Train: 2018-08-01T00:32:54.642737: step 9689, loss 0.596732.
Train: 2018-08-01T00:32:54.814572: step 9690, loss 0.665334.
Test: 2018-08-01T00:32:55.283213: step 9690, loss 0.548061.
Train: 2018-08-01T00:32:55.423804: step 9691, loss 0.51104.
Train: 2018-08-01T00:32:55.595665: step 9692, loss 0.630789.
Train: 2018-08-01T00:32:55.751852: step 9693, loss 0.477089.
Train: 2018-08-01T00:32:55.908090: step 9694, loss 0.5624.
Train: 2018-08-01T00:32:56.064310: step 9695, loss 0.494225.
Train: 2018-08-01T00:32:56.220493: step 9696, loss 0.562399.
Train: 2018-08-01T00:32:56.376737: step 9697, loss 0.545334.
Train: 2018-08-01T00:32:56.532920: step 9698, loss 0.596556.
Train: 2018-08-01T00:32:56.689133: step 9699, loss 0.476984.
Train: 2018-08-01T00:32:56.845346: step 9700, loss 0.528178.
Test: 2018-08-01T00:32:57.314017: step 9700, loss 0.548041.
Train: 2018-08-01T00:32:58.032569: step 9701, loss 0.476687.
Train: 2018-08-01T00:32:58.188783: step 9702, loss 0.545202.
Train: 2018-08-01T00:32:58.345026: step 9703, loss 0.579644.
Train: 2018-08-01T00:32:58.501209: step 9704, loss 0.596975.
Train: 2018-08-01T00:32:58.657422: step 9705, loss 0.579719.
Train: 2018-08-01T00:32:58.813636: step 9706, loss 0.562408.
Train: 2018-08-01T00:32:58.985470: step 9707, loss 0.579762.
Train: 2018-08-01T00:32:59.157304: step 9708, loss 0.562412.
Train: 2018-08-01T00:32:59.313549: step 9709, loss 0.545042.
Train: 2018-08-01T00:32:59.469732: step 9710, loss 0.614562.
Test: 2018-08-01T00:32:59.938403: step 9710, loss 0.547862.
Train: 2018-08-01T00:33:00.125859: step 9711, loss 0.562414.
Train: 2018-08-01T00:33:00.282042: step 9712, loss 0.579788.
Train: 2018-08-01T00:33:00.438255: step 9713, loss 0.388762.
Train: 2018-08-01T00:33:00.594499: step 9714, loss 0.649424.
Train: 2018-08-01T00:33:00.750681: step 9715, loss 0.510189.
Train: 2018-08-01T00:33:00.891305: step 9716, loss 0.579856.
Train: 2018-08-01T00:33:01.063134: step 9717, loss 0.632206.
Train: 2018-08-01T00:33:01.234979: step 9718, loss 0.562426.
Train: 2018-08-01T00:33:01.391157: step 9719, loss 0.579854.
Train: 2018-08-01T00:33:01.531779: step 9720, loss 0.57984.
Test: 2018-08-01T00:33:02.016011: step 9720, loss 0.547846.
Train: 2018-08-01T00:33:02.203493: step 9721, loss 0.597223.
Train: 2018-08-01T00:33:02.359710: step 9722, loss 0.718811.
Train: 2018-08-01T00:33:02.515923: step 9723, loss 0.510463.
Train: 2018-08-01T00:33:02.672137: step 9724, loss 0.631481.
Train: 2018-08-01T00:33:02.828351: step 9725, loss 0.596821.
Train: 2018-08-01T00:33:02.984535: step 9726, loss 0.510944.
Train: 2018-08-01T00:33:03.140747: step 9727, loss 0.562396.
Train: 2018-08-01T00:33:03.296987: step 9728, loss 0.477041.
Train: 2018-08-01T00:33:03.453199: step 9729, loss 0.511217.
Train: 2018-08-01T00:33:03.609412: step 9730, loss 0.545334.
Test: 2018-08-01T00:33:04.093678: step 9730, loss 0.548101.
Train: 2018-08-01T00:33:04.265508: step 9731, loss 0.545325.
Train: 2018-08-01T00:33:04.421698: step 9732, loss 0.562397.
Train: 2018-08-01T00:33:04.577941: step 9733, loss 0.528203.
Train: 2018-08-01T00:33:04.749746: step 9734, loss 0.493929.
Train: 2018-08-01T00:33:04.905958: step 9735, loss 0.5967.
Train: 2018-08-01T00:33:05.062173: step 9736, loss 0.528044.
Train: 2018-08-01T00:33:05.218387: step 9737, loss 0.545191.
Train: 2018-08-01T00:33:05.374629: step 9738, loss 0.476213.
Train: 2018-08-01T00:33:05.546433: step 9739, loss 0.493253.
Train: 2018-08-01T00:33:05.702647: step 9740, loss 0.510359.
Test: 2018-08-01T00:33:06.171318: step 9740, loss 0.547835.
Train: 2018-08-01T00:33:06.327501: step 9741, loss 0.597262.
Train: 2018-08-01T00:33:06.483714: step 9742, loss 0.527488.
Train: 2018-08-01T00:33:06.655574: step 9743, loss 0.579976.
Train: 2018-08-01T00:33:06.811799: step 9744, loss 0.580034.
Train: 2018-08-01T00:33:06.968006: step 9745, loss 0.544867.
Train: 2018-08-01T00:33:07.124190: step 9746, loss 0.527206.
Train: 2018-08-01T00:33:07.280439: step 9747, loss 0.562499.
Train: 2018-08-01T00:33:07.436617: step 9748, loss 0.58022.
Train: 2018-08-01T00:33:07.592830: step 9749, loss 0.668906.
Train: 2018-08-01T00:33:07.780316: step 9750, loss 0.491631.
Test: 2018-08-01T00:33:08.248926: step 9750, loss 0.547674.
Train: 2018-08-01T00:33:08.405140: step 9751, loss 0.651169.
Train: 2018-08-01T00:33:08.561354: step 9752, loss 0.61565.
Train: 2018-08-01T00:33:08.717596: step 9753, loss 0.827715.
Train: 2018-08-01T00:33:08.905047: step 9754, loss 0.527297.
Train: 2018-08-01T00:33:09.061269: step 9755, loss 0.492424.
Train: 2018-08-01T00:33:09.217480: step 9756, loss 0.475181.
Train: 2018-08-01T00:33:09.373664: step 9757, loss 0.579844.
Train: 2018-08-01T00:33:09.529877: step 9758, loss 0.475463.
Train: 2018-08-01T00:33:09.686090: step 9759, loss 0.5798.
Train: 2018-08-01T00:33:09.857926: step 9760, loss 0.579802.
Test: 2018-08-01T00:33:10.326594: step 9760, loss 0.547875.
Train: 2018-08-01T00:33:10.482777: step 9761, loss 0.579771.
Train: 2018-08-01T00:33:10.639022: step 9762, loss 0.527727.
Train: 2018-08-01T00:33:10.795205: step 9763, loss 0.597072.
Train: 2018-08-01T00:33:10.967041: step 9764, loss 0.648982.
Train: 2018-08-01T00:33:11.123254: step 9765, loss 0.545124.
Train: 2018-08-01T00:33:11.279466: step 9766, loss 0.596892.
Train: 2018-08-01T00:33:11.435710: step 9767, loss 0.631237.
Train: 2018-08-01T00:33:11.591929: step 9768, loss 0.545238.
Train: 2018-08-01T00:33:11.748138: step 9769, loss 0.54528.
Train: 2018-08-01T00:33:11.904320: step 9770, loss 0.562399.
Test: 2018-08-01T00:33:12.372959: step 9770, loss 0.548119.
Train: 2018-08-01T00:33:12.529207: step 9771, loss 0.511236.
Train: 2018-08-01T00:33:12.685418: step 9772, loss 0.511275.
Train: 2018-08-01T00:33:12.841631: step 9773, loss 0.647627.
Train: 2018-08-01T00:33:12.997844: step 9774, loss 0.545379.
Train: 2018-08-01T00:33:13.169663: step 9775, loss 0.59643.
Train: 2018-08-01T00:33:13.325863: step 9776, loss 0.613385.
Train: 2018-08-01T00:33:13.482106: step 9777, loss 0.579373.
Train: 2018-08-01T00:33:13.638290: step 9778, loss 0.545488.
Train: 2018-08-01T00:33:13.794503: step 9779, loss 0.545515.
Train: 2018-08-01T00:33:13.950716: step 9780, loss 0.579316.
Test: 2018-08-01T00:33:14.434978: step 9780, loss 0.548299.
Train: 2018-08-01T00:33:14.591191: step 9781, loss 0.629921.
Train: 2018-08-01T00:33:14.747434: step 9782, loss 0.579276.
Train: 2018-08-01T00:33:14.903618: step 9783, loss 0.579252.
Train: 2018-08-01T00:33:15.059862: step 9784, loss 0.612777.
Train: 2018-08-01T00:33:15.216075: step 9785, loss 0.562467.
Train: 2018-08-01T00:33:15.387881: step 9786, loss 0.595871.
Train: 2018-08-01T00:33:15.544128: step 9787, loss 0.545838.
Train: 2018-08-01T00:33:15.700342: step 9788, loss 0.54588.
Train: 2018-08-01T00:33:15.856519: step 9789, loss 0.512698.
Train: 2018-08-01T00:33:15.997136: step 9790, loss 0.595721.
Test: 2018-08-01T00:33:16.481406: step 9790, loss 0.548625.
Train: 2018-08-01T00:33:16.637586: step 9791, loss 0.628892.
Train: 2018-08-01T00:33:16.793830: step 9792, loss 0.529395.
Train: 2018-08-01T00:33:16.950045: step 9793, loss 0.612207.
Train: 2018-08-01T00:33:17.106228: step 9794, loss 0.47987.
Train: 2018-08-01T00:33:17.246849: step 9795, loss 0.612165.
Train: 2018-08-01T00:33:17.403063: step 9796, loss 0.496411.
Train: 2018-08-01T00:33:17.590525: step 9797, loss 0.46325.
Train: 2018-08-01T00:33:17.731105: step 9798, loss 0.462979.
Train: 2018-08-01T00:33:17.887324: step 9799, loss 0.462549.
Train: 2018-08-01T00:33:18.043533: step 9800, loss 0.562462.
Test: 2018-08-01T00:33:18.512181: step 9800, loss 0.548347.
Train: 2018-08-01T00:33:19.230730: step 9801, loss 0.562438.
Train: 2018-08-01T00:33:19.402589: step 9802, loss 0.494813.
Train: 2018-08-01T00:33:19.558807: step 9803, loss 0.562407.
Train: 2018-08-01T00:33:19.730614: step 9804, loss 0.579466.
Train: 2018-08-01T00:33:19.886857: step 9805, loss 0.613793.
Train: 2018-08-01T00:33:20.058685: step 9806, loss 0.562396.
Train: 2018-08-01T00:33:20.214873: step 9807, loss 0.49352.
Train: 2018-08-01T00:33:20.371088: step 9808, loss 0.458754.
Train: 2018-08-01T00:33:20.511710: step 9809, loss 0.597112.
Train: 2018-08-01T00:33:20.683544: step 9810, loss 0.527602.
Test: 2018-08-01T00:33:21.152184: step 9810, loss 0.547804.
Train: 2018-08-01T00:33:21.324020: step 9811, loss 0.597375.
Train: 2018-08-01T00:33:21.480233: step 9812, loss 0.527414.
Train: 2018-08-01T00:33:21.636416: step 9813, loss 0.562459.
Train: 2018-08-01T00:33:21.792629: step 9814, loss 0.509655.
Train: 2018-08-01T00:33:21.980087: step 9815, loss 0.65077.
Train: 2018-08-01T00:33:22.120709: step 9816, loss 0.580175.
Train: 2018-08-01T00:33:22.276890: step 9817, loss 0.49175.
Train: 2018-08-01T00:33:22.433104: step 9818, loss 0.615662.
Train: 2018-08-01T00:33:22.589319: step 9819, loss 0.562519.
Train: 2018-08-01T00:33:22.745561: step 9820, loss 0.580252.
Test: 2018-08-01T00:33:23.214201: step 9820, loss 0.547675.
Train: 2018-08-01T00:33:23.386008: step 9821, loss 0.580251.
Train: 2018-08-01T00:33:23.542221: step 9822, loss 0.597963.
Train: 2018-08-01T00:33:23.698463: step 9823, loss 0.509396.
Train: 2018-08-01T00:33:23.854676: step 9824, loss 0.562509.
Train: 2018-08-01T00:33:24.010885: step 9825, loss 0.544811.
Train: 2018-08-01T00:33:24.182725: step 9826, loss 0.597891.
Train: 2018-08-01T00:33:24.338934: step 9827, loss 0.456423.
Train: 2018-08-01T00:33:24.495152: step 9828, loss 0.633278.
Train: 2018-08-01T00:33:24.651365: step 9829, loss 0.562502.
Train: 2018-08-01T00:33:24.807548: step 9830, loss 0.597852.
Test: 2018-08-01T00:33:25.291840: step 9830, loss 0.547705.
Train: 2018-08-01T00:33:25.448023: step 9831, loss 0.562492.
Train: 2018-08-01T00:33:25.604237: step 9832, loss 0.633042.
Train: 2018-08-01T00:33:25.760480: step 9833, loss 0.527266.
Train: 2018-08-01T00:33:25.916694: step 9834, loss 0.597618.
Train: 2018-08-01T00:33:26.072907: step 9835, loss 0.579997.
Train: 2018-08-01T00:33:26.229092: step 9836, loss 0.544935.
Train: 2018-08-01T00:33:26.400925: step 9837, loss 0.492519.
Train: 2018-08-01T00:33:26.557139: step 9838, loss 0.579903.
Train: 2018-08-01T00:33:26.713352: step 9839, loss 0.544974.
Train: 2018-08-01T00:33:26.869566: step 9840, loss 0.510086.
Test: 2018-08-01T00:33:27.353826: step 9840, loss 0.547815.
Train: 2018-08-01T00:33:27.510071: step 9841, loss 0.562429.
Train: 2018-08-01T00:33:27.666284: step 9842, loss 0.510065.
Train: 2018-08-01T00:33:27.806878: step 9843, loss 0.510023.
Train: 2018-08-01T00:33:27.963059: step 9844, loss 0.579936.
Train: 2018-08-01T00:33:28.134925: step 9845, loss 0.457357.
Train: 2018-08-01T00:33:28.291132: step 9846, loss 0.59757.
Train: 2018-08-01T00:33:28.447323: step 9847, loss 0.615219.
Train: 2018-08-01T00:33:28.603534: step 9848, loss 0.597657.
Train: 2018-08-01T00:33:28.775399: step 9849, loss 0.632837.
Train: 2018-08-01T00:33:28.931583: step 9850, loss 0.580032.
Test: 2018-08-01T00:33:29.400252: step 9850, loss 0.547761.
Train: 2018-08-01T00:33:29.572058: step 9851, loss 0.544908.
Train: 2018-08-01T00:33:29.728271: step 9852, loss 0.562448.
Train: 2018-08-01T00:33:29.884514: step 9853, loss 0.544935.
Train: 2018-08-01T00:33:30.040697: step 9854, loss 0.492465.
Train: 2018-08-01T00:33:30.196941: step 9855, loss 0.56244.
Train: 2018-08-01T00:33:30.353156: step 9856, loss 0.562441.
Train: 2018-08-01T00:33:30.509369: step 9857, loss 0.61495.
Train: 2018-08-01T00:33:30.696834: step 9858, loss 0.50997.
Train: 2018-08-01T00:33:30.853008: step 9859, loss 0.509969.
Train: 2018-08-01T00:33:31.009221: step 9860, loss 0.597446.
Test: 2018-08-01T00:33:31.477892: step 9860, loss 0.547784.
Train: 2018-08-01T00:33:31.649726: step 9861, loss 0.614953.
Train: 2018-08-01T00:33:31.805940: step 9862, loss 0.684869.
Train: 2018-08-01T00:33:31.962153: step 9863, loss 0.614761.
Train: 2018-08-01T00:33:32.118366: step 9864, loss 0.562416.
Train: 2018-08-01T00:33:32.274551: step 9865, loss 0.527731.
Train: 2018-08-01T00:33:32.430764: step 9866, loss 0.66621.
Train: 2018-08-01T00:33:32.586976: step 9867, loss 0.579638.
Train: 2018-08-01T00:33:32.743189: step 9868, loss 0.528036.
Train: 2018-08-01T00:33:32.930646: step 9869, loss 0.510992.
Train: 2018-08-01T00:33:33.102481: step 9870, loss 0.596612.
Test: 2018-08-01T00:33:33.571120: step 9870, loss 0.5481.
Train: 2018-08-01T00:33:33.727370: step 9871, loss 0.579473.
Train: 2018-08-01T00:33:33.883549: step 9872, loss 0.511278.
Train: 2018-08-01T00:33:34.055383: step 9873, loss 0.460257.
Train: 2018-08-01T00:33:34.211621: step 9874, loss 0.51129.
Train: 2018-08-01T00:33:34.383431: step 9875, loss 0.528273.
Train: 2018-08-01T00:33:34.539644: step 9876, loss 0.562397.
Train: 2018-08-01T00:33:34.695858: step 9877, loss 0.545271.
Train: 2018-08-01T00:33:34.852071: step 9878, loss 0.596708.
Train: 2018-08-01T00:33:35.008286: step 9879, loss 0.493694.
Train: 2018-08-01T00:33:35.180150: step 9880, loss 0.476343.
Test: 2018-08-01T00:33:35.648790: step 9880, loss 0.547942.
Train: 2018-08-01T00:33:35.805003: step 9881, loss 0.52787.
Train: 2018-08-01T00:33:35.961218: step 9882, loss 0.562406.
Train: 2018-08-01T00:33:36.148643: step 9883, loss 0.597162.
Train: 2018-08-01T00:33:36.304886: step 9884, loss 0.614652.
Train: 2018-08-01T00:33:36.461099: step 9885, loss 0.61471.
Train: 2018-08-01T00:33:36.617313: step 9886, loss 0.492703.
Train: 2018-08-01T00:33:36.773496: step 9887, loss 0.649674.
Train: 2018-08-01T00:33:36.929709: step 9888, loss 0.527542.
Train: 2018-08-01T00:33:37.085953: step 9889, loss 0.579871.
Train: 2018-08-01T00:33:37.257758: step 9890, loss 0.614747.
Test: 2018-08-01T00:33:37.726428: step 9890, loss 0.547833.
Train: 2018-08-01T00:33:37.898263: step 9891, loss 0.614689.
Train: 2018-08-01T00:33:38.054446: step 9892, loss 0.597199.
Train: 2018-08-01T00:33:38.210659: step 9893, loss 0.61447.
Train: 2018-08-01T00:33:38.382495: step 9894, loss 0.562404.
Train: 2018-08-01T00:33:38.538732: step 9895, loss 0.648704.
Train: 2018-08-01T00:33:38.694922: step 9896, loss 0.528.
Train: 2018-08-01T00:33:38.851135: step 9897, loss 0.596696.
Train: 2018-08-01T00:33:39.007379: step 9898, loss 0.596593.
Train: 2018-08-01T00:33:39.163586: step 9899, loss 0.579443.
Train: 2018-08-01T00:33:39.319805: step 9900, loss 0.630359.
Test: 2018-08-01T00:33:39.788445: step 9900, loss 0.548247.
Train: 2018-08-01T00:33:40.460167: step 9901, loss 0.596259.
Train: 2018-08-01T00:33:40.647619: step 9902, loss 0.545578.
Train: 2018-08-01T00:33:40.803833: step 9903, loss 0.59604.
Train: 2018-08-01T00:33:40.960040: step 9904, loss 0.595941.
Train: 2018-08-01T00:33:41.116230: step 9905, loss 0.579162.
Train: 2018-08-01T00:33:41.288094: step 9906, loss 0.496018.
Train: 2018-08-01T00:33:41.444302: step 9907, loss 0.595701.
Train: 2018-08-01T00:33:41.600516: step 9908, loss 0.678426.
Train: 2018-08-01T00:33:41.756705: step 9909, loss 0.480093.
Train: 2018-08-01T00:33:41.928539: step 9910, loss 0.529652.
Test: 2018-08-01T00:33:42.397210: step 9910, loss 0.548815.
Train: 2018-08-01T00:33:42.553392: step 9911, loss 0.595487.
Train: 2018-08-01T00:33:42.725255: step 9912, loss 0.562601.
Train: 2018-08-01T00:33:42.881471: step 9913, loss 0.546197.
Train: 2018-08-01T00:33:43.037685: step 9914, loss 0.513398.
Train: 2018-08-01T00:33:43.193868: step 9915, loss 0.562608.
Train: 2018-08-01T00:33:43.350111: step 9916, loss 0.579029.
Train: 2018-08-01T00:33:43.506324: step 9917, loss 0.463983.
Train: 2018-08-01T00:33:43.662509: step 9918, loss 0.529629.
Train: 2018-08-01T00:33:43.818722: step 9919, loss 0.562553.
Train: 2018-08-01T00:33:43.974959: step 9920, loss 0.529408.
Test: 2018-08-01T00:33:44.443575: step 9920, loss 0.548599.
Train: 2018-08-01T00:33:44.599820: step 9921, loss 0.62896.
Train: 2018-08-01T00:33:44.756002: step 9922, loss 0.512574.
Train: 2018-08-01T00:33:44.927868: step 9923, loss 0.529116.
Train: 2018-08-01T00:33:45.084051: step 9924, loss 0.512272.
Train: 2018-08-01T00:33:45.240294: step 9925, loss 0.629606.
Train: 2018-08-01T00:33:45.396507: step 9926, loss 0.545612.
Train: 2018-08-01T00:33:45.568342: step 9927, loss 0.646746.
Train: 2018-08-01T00:33:45.724555: step 9928, loss 0.54555.
Train: 2018-08-01T00:33:45.880769: step 9929, loss 0.528638.
Train: 2018-08-01T00:33:46.052604: step 9930, loss 0.579335.
Test: 2018-08-01T00:33:46.521214: step 9930, loss 0.548232.
Train: 2018-08-01T00:33:46.677458: step 9931, loss 0.545478.
Train: 2018-08-01T00:33:46.833666: step 9932, loss 0.613286.
Train: 2018-08-01T00:33:46.989878: step 9933, loss 0.580506.
Train: 2018-08-01T00:33:47.161719: step 9934, loss 0.579377.
Train: 2018-08-01T00:33:47.317902: step 9935, loss 0.596341.
Train: 2018-08-01T00:33:47.474115: step 9936, loss 0.579366.
Train: 2018-08-01T00:33:47.630328: step 9937, loss 0.596297.
Train: 2018-08-01T00:33:47.786573: step 9938, loss 0.562417.
Train: 2018-08-01T00:33:47.942781: step 9939, loss 0.511707.
Train: 2018-08-01T00:33:48.099002: step 9940, loss 0.528614.
Test: 2018-08-01T00:33:48.583260: step 9940, loss 0.548256.
Train: 2018-08-01T00:33:48.739444: step 9941, loss 0.477856.
Train: 2018-08-01T00:33:48.895657: step 9942, loss 0.545468.
Train: 2018-08-01T00:33:49.051871: step 9943, loss 0.494492.
Train: 2018-08-01T00:33:49.208114: step 9944, loss 0.579431.
Train: 2018-08-01T00:33:49.379949: step 9945, loss 0.562398.
Train: 2018-08-01T00:33:49.536133: step 9946, loss 0.579503.
Train: 2018-08-01T00:33:49.692376: step 9947, loss 0.528124.
Train: 2018-08-01T00:33:49.848559: step 9948, loss 0.631079.
Train: 2018-08-01T00:33:50.004802: step 9949, loss 0.528027.
Train: 2018-08-01T00:33:50.161017: step 9950, loss 0.648423.
Test: 2018-08-01T00:33:50.629656: step 9950, loss 0.547992.
Train: 2018-08-01T00:33:50.785870: step 9951, loss 0.717206.
Train: 2018-08-01T00:33:50.942053: step 9952, loss 0.493772.
Train: 2018-08-01T00:33:51.098268: step 9953, loss 0.476729.
Train: 2018-08-01T00:33:51.254481: step 9954, loss 0.596668.
Train: 2018-08-01T00:33:51.410730: step 9955, loss 0.648044.
Train: 2018-08-01T00:33:51.598150: step 9956, loss 0.6137.
Train: 2018-08-01T00:33:51.754363: step 9957, loss 0.477091.
Train: 2018-08-01T00:33:51.910607: step 9958, loss 0.647647.
Train: 2018-08-01T00:33:52.066790: step 9959, loss 0.562403.
Train: 2018-08-01T00:33:52.223004: step 9960, loss 0.647338.
Test: 2018-08-01T00:33:52.691674: step 9960, loss 0.548231.
Train: 2018-08-01T00:33:52.847888: step 9961, loss 0.596288.
Train: 2018-08-01T00:33:53.019725: step 9962, loss 0.579309.
Train: 2018-08-01T00:33:53.175906: step 9963, loss 0.511934.
Train: 2018-08-01T00:33:53.332149: step 9964, loss 0.545641.
Train: 2018-08-01T00:33:53.488362: step 9965, loss 0.596012.
Train: 2018-08-01T00:33:53.660200: step 9966, loss 0.579211.
Train: 2018-08-01T00:33:53.816410: step 9967, loss 0.512292.
Train: 2018-08-01T00:33:53.972624: step 9968, loss 0.595901.
Train: 2018-08-01T00:33:54.128806: step 9969, loss 0.612572.
Train: 2018-08-01T00:33:54.285021: step 9970, loss 0.562486.
Test: 2018-08-01T00:33:54.753689: step 9970, loss 0.548554.
Train: 2018-08-01T00:33:54.925526: step 9971, loss 0.595793.
Train: 2018-08-01T00:33:55.081709: step 9972, loss 0.545885.
Train: 2018-08-01T00:33:55.237953: step 9973, loss 0.512706.
Train: 2018-08-01T00:33:55.394166: step 9974, loss 0.645523.
Train: 2018-08-01T00:33:55.550350: step 9975, loss 0.479624.
Train: 2018-08-01T00:33:55.706593: step 9976, loss 0.545936.
Train: 2018-08-01T00:33:55.894052: step 9977, loss 0.579113.
Train: 2018-08-01T00:33:56.050232: step 9978, loss 0.595723.
Train: 2018-08-01T00:33:56.206476: step 9979, loss 0.529304.
Train: 2018-08-01T00:33:56.362660: step 9980, loss 0.62897.
Test: 2018-08-01T00:33:56.846951: step 9980, loss 0.548603.
Train: 2018-08-01T00:33:57.018781: step 9981, loss 0.545903.
Train: 2018-08-01T00:33:57.174995: step 9982, loss 0.529292.
Train: 2018-08-01T00:33:57.346804: step 9983, loss 0.462779.
Train: 2018-08-01T00:33:57.503017: step 9984, loss 0.56249.
Train: 2018-08-01T00:33:57.659255: step 9985, loss 0.445583.
Train: 2018-08-01T00:33:57.815468: step 9986, loss 0.461853.
Train: 2018-08-01T00:33:57.971687: step 9987, loss 0.56243.
Train: 2018-08-01T00:33:58.143517: step 9988, loss 0.545475.
Train: 2018-08-01T00:33:58.299735: step 9989, loss 0.596439.
Train: 2018-08-01T00:33:58.455949: step 9990, loss 0.562398.
Test: 2018-08-01T00:33:58.924589: step 9990, loss 0.548045.
Train: 2018-08-01T00:33:59.096425: step 9991, loss 0.59667.
Train: 2018-08-01T00:33:59.283849: step 9992, loss 0.4765.
Train: 2018-08-01T00:33:59.440064: step 9993, loss 0.562398.
Train: 2018-08-01T00:33:59.596287: step 9994, loss 0.545109.
Train: 2018-08-01T00:33:59.752520: step 9995, loss 0.510369.
Train: 2018-08-01T00:33:59.908734: step 9996, loss 0.492789.
Train: 2018-08-01T00:34:00.064948: step 9997, loss 0.632355.
Train: 2018-08-01T00:34:00.236752: step 9998, loss 0.457296.
Train: 2018-08-01T00:34:00.392990: step 9999, loss 0.527283.
Train: 2018-08-01T00:34:00.549179: step 10000, loss 0.615474.
Test: 2018-08-01T00:34:01.017848: step 10000, loss 0.547684.
Train: 2018-08-01T00:34:01.767674: step 10001, loss 0.704162.
Train: 2018-08-01T00:34:01.923858: step 10002, loss 0.597929.
Train: 2018-08-01T00:34:02.080071: step 10003, loss 0.544808.
Train: 2018-08-01T00:34:02.236314: step 10004, loss 0.544811.
Train: 2018-08-01T00:34:02.392498: step 10005, loss 0.59789.
Train: 2018-08-01T00:34:02.579954: step 10006, loss 0.491782.
Train: 2018-08-01T00:34:02.720545: step 10007, loss 0.474079.
Train: 2018-08-01T00:34:02.892410: step 10008, loss 0.544802.
Train: 2018-08-01T00:34:03.048624: step 10009, loss 0.544788.
Train: 2018-08-01T00:34:03.220459: step 10010, loss 0.651342.
Test: 2018-08-01T00:34:03.673448: step 10010, loss 0.547663.
Train: 2018-08-01T00:34:03.845282: step 10011, loss 0.633571.
Train: 2018-08-01T00:34:04.001496: step 10012, loss 0.52705.
Train: 2018-08-01T00:34:04.157739: step 10013, loss 0.52707.
Train: 2018-08-01T00:34:04.313947: step 10014, loss 0.491637.
Train: 2018-08-01T00:34:04.485787: step 10015, loss 0.54479.
Train: 2018-08-01T00:34:04.641971: step 10016, loss 0.491544.
Train: 2018-08-01T00:34:04.798183: step 10017, loss 0.651415.
Train: 2018-08-01T00:34:04.970044: step 10018, loss 0.49144.
Train: 2018-08-01T00:34:05.126232: step 10019, loss 0.72268.
Train: 2018-08-01T00:34:05.282445: step 10020, loss 0.509244.
Test: 2018-08-01T00:34:05.751087: step 10020, loss 0.547666.
Train: 2018-08-01T00:34:05.907299: step 10021, loss 0.56253.
Train: 2018-08-01T00:34:06.063512: step 10022, loss 0.580259.
Train: 2018-08-01T00:34:06.219757: step 10023, loss 0.473936.
Train: 2018-08-01T00:34:06.375940: step 10024, loss 0.438483.
Train: 2018-08-01T00:34:06.516562: step 10025, loss 0.456018.
Train: 2018-08-01T00:34:06.688365: step 10026, loss 0.54475.
Train: 2018-08-01T00:34:06.844612: step 10027, loss 0.562583.
Train: 2018-08-01T00:34:07.000818: step 10028, loss 0.580511.
Train: 2018-08-01T00:34:07.157031: step 10029, loss 0.724048.
Train: 2018-08-01T00:34:07.313244: step 10030, loss 0.490933.
Test: 2018-08-01T00:34:07.797482: step 10030, loss 0.547611.
Train: 2018-08-01T00:34:07.969352: step 10031, loss 0.544696.
Train: 2018-08-01T00:34:08.125529: step 10032, loss 0.526766.
Train: 2018-08-01T00:34:08.281742: step 10033, loss 0.616443.
Train: 2018-08-01T00:34:08.453578: step 10034, loss 0.544693.
Train: 2018-08-01T00:34:08.609792: step 10035, loss 0.580548.
Train: 2018-08-01T00:34:08.766035: step 10036, loss 0.526784.
Train: 2018-08-01T00:34:08.937840: step 10037, loss 0.455143.
Train: 2018-08-01T00:34:09.109674: step 10038, loss 0.580558.
Train: 2018-08-01T00:34:09.250266: step 10039, loss 0.508797.
Train: 2018-08-01T00:34:09.406479: step 10040, loss 0.454844.
Test: 2018-08-01T00:34:09.875150: step 10040, loss 0.547591.
Train: 2018-08-01T00:34:10.031358: step 10041, loss 0.688751.
Train: 2018-08-01T00:34:10.218814: step 10042, loss 0.616724.
Train: 2018-08-01T00:34:10.375033: step 10043, loss 0.490654.
Train: 2018-08-01T00:34:10.531247: step 10044, loss 0.49064.
Train: 2018-08-01T00:34:10.687429: step 10045, loss 0.544657.
Train: 2018-08-01T00:34:10.843676: step 10046, loss 0.580742.
Train: 2018-08-01T00:34:10.999887: step 10047, loss 0.544648.
Train: 2018-08-01T00:34:11.156070: step 10048, loss 0.49045.
Train: 2018-08-01T00:34:11.343526: step 10049, loss 0.65317.
Train: 2018-08-01T00:34:11.484142: step 10050, loss 0.562723.
Test: 2018-08-01T00:34:11.968409: step 10050, loss 0.54758.
Train: 2018-08-01T00:34:12.124593: step 10051, loss 0.635026.
Train: 2018-08-01T00:34:12.312078: step 10052, loss 0.689043.
Train: 2018-08-01T00:34:12.468293: step 10053, loss 0.634616.
Train: 2018-08-01T00:34:12.624477: step 10054, loss 0.508872.
Train: 2018-08-01T00:34:12.780720: step 10055, loss 0.562583.
Train: 2018-08-01T00:34:12.936902: step 10056, loss 0.633772.
Train: 2018-08-01T00:34:13.093118: step 10057, loss 0.580259.
Train: 2018-08-01T00:34:13.249329: step 10058, loss 0.633165.
Train: 2018-08-01T00:34:13.421165: step 10059, loss 0.615225.
Train: 2018-08-01T00:34:13.577408: step 10060, loss 0.527444.
Test: 2018-08-01T00:34:14.046048: step 10060, loss 0.547831.
Train: 2018-08-01T00:34:14.217853: step 10061, loss 0.544997.
Train: 2018-08-01T00:34:14.374097: step 10062, loss 0.440854.
Train: 2018-08-01T00:34:14.545901: step 10063, loss 0.493041.
Train: 2018-08-01T00:34:14.748980: step 10064, loss 0.649099.
Train: 2018-08-01T00:34:14.905217: step 10065, loss 0.51047.
Train: 2018-08-01T00:34:15.061436: step 10066, loss 0.493201.
Train: 2018-08-01T00:34:15.233239: step 10067, loss 0.579713.
Train: 2018-08-01T00:34:15.389484: step 10068, loss 0.597025.
Train: 2018-08-01T00:34:15.592556: step 10069, loss 0.545101.
Train: 2018-08-01T00:34:15.748769: step 10070, loss 0.597002.
Test: 2018-08-01T00:34:16.217414: step 10070, loss 0.547926.
Train: 2018-08-01T00:34:16.373628: step 10071, loss 0.717988.
Train: 2018-08-01T00:34:16.529812: step 10072, loss 0.614103.
Train: 2018-08-01T00:34:16.732925: step 10073, loss 0.4937.
Train: 2018-08-01T00:34:16.873512: step 10074, loss 0.528121.
Train: 2018-08-01T00:34:17.029694: step 10075, loss 0.545283.
Train: 2018-08-01T00:34:17.185908: step 10076, loss 0.562397.
Train: 2018-08-01T00:34:17.342121: step 10077, loss 0.528235.
Train: 2018-08-01T00:34:17.498334: step 10078, loss 0.545321.
Train: 2018-08-01T00:34:17.654549: step 10079, loss 0.54532.
Train: 2018-08-01T00:34:17.826408: step 10080, loss 0.511146.
Test: 2018-08-01T00:34:18.295053: step 10080, loss 0.548075.
Train: 2018-08-01T00:34:18.451261: step 10081, loss 0.5795.
Train: 2018-08-01T00:34:18.607451: step 10082, loss 0.54528.
Train: 2018-08-01T00:34:18.763664: step 10083, loss 0.545263.
Train: 2018-08-01T00:34:18.919913: step 10084, loss 0.631001.
Train: 2018-08-01T00:34:19.091711: step 10085, loss 0.510943.
Train: 2018-08-01T00:34:19.247925: step 10086, loss 0.562395.
Train: 2018-08-01T00:34:19.404139: step 10087, loss 0.613921.
Train: 2018-08-01T00:34:19.560352: step 10088, loss 0.459364.
Train: 2018-08-01T00:34:19.716565: step 10089, loss 0.562396.
Train: 2018-08-01T00:34:19.872779: step 10090, loss 0.596833.
Test: 2018-08-01T00:34:20.341449: step 10090, loss 0.547971.
Train: 2018-08-01T00:34:20.513284: step 10091, loss 0.682995.
Train: 2018-08-01T00:34:20.669467: step 10092, loss 0.596807.
Train: 2018-08-01T00:34:20.825680: step 10093, loss 0.682624.
Train: 2018-08-01T00:34:20.981894: step 10094, loss 0.579513.
Train: 2018-08-01T00:34:21.153728: step 10095, loss 0.494161.
Train: 2018-08-01T00:34:21.309942: step 10096, loss 0.511323.
Train: 2018-08-01T00:34:21.466180: step 10097, loss 0.477349.
Train: 2018-08-01T00:34:21.637991: step 10098, loss 0.596443.
Train: 2018-08-01T00:34:21.794204: step 10099, loss 0.528363.
Train: 2018-08-01T00:34:21.950442: step 10100, loss 0.511315.
Test: 2018-08-01T00:34:22.434678: step 10100, loss 0.548121.
Train: 2018-08-01T00:34:23.153291: step 10101, loss 0.460092.
Train: 2018-08-01T00:34:23.325095: step 10102, loss 0.528198.
Train: 2018-08-01T00:34:23.481334: step 10103, loss 0.61385.
Train: 2018-08-01T00:34:23.637551: step 10104, loss 0.493656.
Train: 2018-08-01T00:34:23.793765: step 10105, loss 0.717495.
Train: 2018-08-01T00:34:23.949979: step 10106, loss 0.562398.
Train: 2018-08-01T00:34:24.106193: step 10107, loss 0.562398.
Train: 2018-08-01T00:34:24.262400: step 10108, loss 0.73478.
Train: 2018-08-01T00:34:24.449831: step 10109, loss 0.57959.
Train: 2018-08-01T00:34:24.606045: step 10110, loss 0.528097.
Test: 2018-08-01T00:34:25.074716: step 10110, loss 0.548061.
Train: 2018-08-01T00:34:25.230929: step 10111, loss 0.630869.
Train: 2018-08-01T00:34:25.402764: step 10112, loss 0.545326.
Train: 2018-08-01T00:34:25.574568: step 10113, loss 0.579437.
Train: 2018-08-01T00:34:25.730806: step 10114, loss 0.528407.
Train: 2018-08-01T00:34:25.887020: step 10115, loss 0.545433.
Train: 2018-08-01T00:34:26.043208: step 10116, loss 0.477615.
Train: 2018-08-01T00:34:26.199421: step 10117, loss 0.562409.
Train: 2018-08-01T00:34:26.355636: step 10118, loss 0.511479.
Train: 2018-08-01T00:34:26.527507: step 10119, loss 0.545407.
Train: 2018-08-01T00:34:26.699341: step 10120, loss 0.630495.
Test: 2018-08-01T00:34:27.183567: step 10120, loss 0.548143.
Train: 2018-08-01T00:34:27.339812: step 10121, loss 0.596457.
Train: 2018-08-01T00:34:27.495993: step 10122, loss 0.596449.
Train: 2018-08-01T00:34:27.667853: step 10123, loss 0.49436.
Train: 2018-08-01T00:34:27.824041: step 10124, loss 0.630476.
Train: 2018-08-01T00:34:27.980285: step 10125, loss 0.579411.
Train: 2018-08-01T00:34:28.136498: step 10126, loss 0.562406.
Train: 2018-08-01T00:34:28.292706: step 10127, loss 0.511464.
Train: 2018-08-01T00:34:28.448926: step 10128, loss 0.698284.
Train: 2018-08-01T00:34:28.620730: step 10129, loss 0.545459.
Train: 2018-08-01T00:34:28.776969: step 10130, loss 0.579344.
Test: 2018-08-01T00:34:29.245613: step 10130, loss 0.548266.
Train: 2018-08-01T00:34:29.448692: step 10131, loss 0.697642.
Train: 2018-08-01T00:34:29.604904: step 10132, loss 0.511899.
Train: 2018-08-01T00:34:29.761118: step 10133, loss 0.612863.
Train: 2018-08-01T00:34:29.932922: step 10134, loss 0.562456.
Train: 2018-08-01T00:34:30.089167: step 10135, loss 0.545748.
Train: 2018-08-01T00:34:30.245380: step 10136, loss 0.629241.
Train: 2018-08-01T00:34:30.401572: step 10137, loss 0.579143.
Train: 2018-08-01T00:34:30.557778: step 10138, loss 0.562513.
Train: 2018-08-01T00:34:30.714021: step 10139, loss 0.529391.
Train: 2018-08-01T00:34:30.870233: step 10140, loss 0.579086.
Test: 2018-08-01T00:34:31.338874: step 10140, loss 0.54871.
Train: 2018-08-01T00:34:31.495056: step 10141, loss 0.562549.
Train: 2018-08-01T00:34:31.651270: step 10142, loss 0.595576.
Train: 2018-08-01T00:34:31.823106: step 10143, loss 0.562569.
Train: 2018-08-01T00:34:31.979319: step 10144, loss 0.661394.
Train: 2018-08-01T00:34:32.151154: step 10145, loss 0.611887.
Train: 2018-08-01T00:34:32.307398: step 10146, loss 0.529866.
Train: 2018-08-01T00:34:32.463610: step 10147, loss 0.546298.
Train: 2018-08-01T00:34:32.635446: step 10148, loss 0.611649.
Train: 2018-08-01T00:34:32.791661: step 10149, loss 0.627881.
Train: 2018-08-01T00:34:32.947841: step 10150, loss 0.513932.
Test: 2018-08-01T00:34:33.416512: step 10150, loss 0.549125.
Train: 2018-08-01T00:34:33.572697: step 10151, loss 0.611437.
Train: 2018-08-01T00:34:33.728939: step 10152, loss 0.578953.
Train: 2018-08-01T00:34:33.885152: step 10153, loss 0.627493.
Train: 2018-08-01T00:34:34.056957: step 10154, loss 0.530508.
Train: 2018-08-01T00:34:34.213210: step 10155, loss 0.578933.
Train: 2018-08-01T00:34:34.385006: step 10156, loss 0.611128.
Train: 2018-08-01T00:34:34.541245: step 10157, loss 0.643206.
Train: 2018-08-01T00:34:34.697432: step 10158, loss 0.514816.
Train: 2018-08-01T00:34:34.853676: step 10159, loss 0.530908.
Train: 2018-08-01T00:34:35.009889: step 10160, loss 0.642897.
Test: 2018-08-01T00:34:35.478532: step 10160, loss 0.54957.
Train: 2018-08-01T00:34:35.634746: step 10161, loss 0.546973.
Train: 2018-08-01T00:34:35.790958: step 10162, loss 0.483174.
Train: 2018-08-01T00:34:35.947169: step 10163, loss 0.594884.
Train: 2018-08-01T00:34:36.103383: step 10164, loss 0.674789.
Train: 2018-08-01T00:34:36.275218: step 10165, loss 0.546995.
Train: 2018-08-01T00:34:36.431401: step 10166, loss 0.594862.
Train: 2018-08-01T00:34:36.587614: step 10167, loss 0.483294.
Train: 2018-08-01T00:34:36.743828: step 10168, loss 0.578912.
Train: 2018-08-01T00:34:36.900041: step 10169, loss 0.46716.
Train: 2018-08-01T00:34:37.056285: step 10170, loss 0.530892.
Test: 2018-08-01T00:34:37.524895: step 10170, loss 0.549414.
Train: 2018-08-01T00:34:37.681109: step 10171, loss 0.48256.
Train: 2018-08-01T00:34:37.837352: step 10172, loss 0.562802.
Train: 2018-08-01T00:34:37.993566: step 10173, loss 0.61136.
Train: 2018-08-01T00:34:38.149748: step 10174, loss 0.611479.
Train: 2018-08-01T00:34:38.305962: step 10175, loss 0.562684.
Train: 2018-08-01T00:34:38.462176: step 10176, loss 0.546331.
Train: 2018-08-01T00:34:38.634011: step 10177, loss 0.562635.
Train: 2018-08-01T00:34:38.790254: step 10178, loss 0.496976.
Train: 2018-08-01T00:34:38.946467: step 10179, loss 0.529651.
Train: 2018-08-01T00:34:39.102681: step 10180, loss 0.546022.
Test: 2018-08-01T00:34:39.586942: step 10180, loss 0.548629.
Train: 2018-08-01T00:34:39.758747: step 10181, loss 0.595698.
Train: 2018-08-01T00:34:39.899364: step 10182, loss 0.479308.
Train: 2018-08-01T00:34:40.055552: step 10183, loss 0.545767.
Train: 2018-08-01T00:34:40.211766: step 10184, loss 0.579227.
Train: 2018-08-01T00:34:40.368009: step 10185, loss 0.478271.
Train: 2018-08-01T00:34:40.524223: step 10186, loss 0.579328.
Train: 2018-08-01T00:34:40.680431: step 10187, loss 0.494513.
Train: 2018-08-01T00:34:40.836621: step 10188, loss 0.528298.
Train: 2018-08-01T00:34:40.992833: step 10189, loss 0.493877.
Train: 2018-08-01T00:34:41.149047: step 10190, loss 0.51074.
Test: 2018-08-01T00:34:41.633338: step 10190, loss 0.547907.
Train: 2018-08-01T00:34:41.789553: step 10191, loss 0.475841.
Train: 2018-08-01T00:34:41.961357: step 10192, loss 0.579841.
Train: 2018-08-01T00:34:42.101948: step 10193, loss 0.685012.
Train: 2018-08-01T00:34:42.273782: step 10194, loss 0.509783.
Train: 2018-08-01T00:34:42.429996: step 10195, loss 0.527248.
Train: 2018-08-01T00:34:42.586209: step 10196, loss 0.668525.
Train: 2018-08-01T00:34:42.742454: step 10197, loss 0.562506.
Train: 2018-08-01T00:34:42.898668: step 10198, loss 0.509375.
Train: 2018-08-01T00:34:43.070472: step 10199, loss 0.527043.
Train: 2018-08-01T00:34:43.226709: step 10200, loss 0.544767.
Test: 2018-08-01T00:34:43.695355: step 10200, loss 0.547646.
Train: 2018-08-01T00:34:44.429559: step 10201, loss 0.598168.
Train: 2018-08-01T00:34:44.601364: step 10202, loss 0.509095.
Train: 2018-08-01T00:34:44.757575: step 10203, loss 0.544729.
Train: 2018-08-01T00:34:44.913791: step 10204, loss 0.562593.
Train: 2018-08-01T00:34:45.070028: step 10205, loss 0.598401.
Train: 2018-08-01T00:34:45.241837: step 10206, loss 0.508892.
Train: 2018-08-01T00:34:45.398082: step 10207, loss 0.419232.
Train: 2018-08-01T00:34:45.554290: step 10208, loss 0.580623.
Train: 2018-08-01T00:34:45.710508: step 10209, loss 0.544662.
Train: 2018-08-01T00:34:45.866691: step 10210, loss 0.598788.
Test: 2018-08-01T00:34:46.335331: step 10210, loss 0.547582.
Train: 2018-08-01T00:34:46.491575: step 10211, loss 0.544644.
Train: 2018-08-01T00:34:46.647758: step 10212, loss 0.653146.
Train: 2018-08-01T00:34:46.803972: step 10213, loss 0.598868.
Train: 2018-08-01T00:34:46.960211: step 10214, loss 0.580759.
Train: 2018-08-01T00:34:47.116429: step 10215, loss 0.526626.
Train: 2018-08-01T00:34:47.272638: step 10216, loss 0.472611.
Train: 2018-08-01T00:34:47.444448: step 10217, loss 0.598711.
Train: 2018-08-01T00:34:47.616282: step 10218, loss 0.652717.
Train: 2018-08-01T00:34:47.772496: step 10219, loss 0.490747.
Train: 2018-08-01T00:34:47.928709: step 10220, loss 0.526719.
Test: 2018-08-01T00:34:48.397348: step 10220, loss 0.547603.
Train: 2018-08-01T00:34:48.569183: step 10221, loss 0.616503.
Train: 2018-08-01T00:34:48.741018: step 10222, loss 0.634356.
Train: 2018-08-01T00:34:48.897232: step 10223, loss 0.508926.
Train: 2018-08-01T00:34:49.053445: step 10224, loss 0.580453.
Train: 2018-08-01T00:34:49.209690: step 10225, loss 0.509064.
Train: 2018-08-01T00:34:49.381493: step 10226, loss 0.562563.
Train: 2018-08-01T00:34:49.537707: step 10227, loss 0.544752.
Train: 2018-08-01T00:34:49.709572: step 10228, loss 0.491386.
Train: 2018-08-01T00:34:49.865754: step 10229, loss 0.544756.
Train: 2018-08-01T00:34:50.021969: step 10230, loss 0.580356.
Test: 2018-08-01T00:34:50.490609: step 10230, loss 0.547648.
Train: 2018-08-01T00:34:50.646822: step 10231, loss 0.615957.
Train: 2018-08-01T00:34:50.818658: step 10232, loss 0.633683.
Train: 2018-08-01T00:34:50.974895: step 10233, loss 0.54478.
Train: 2018-08-01T00:34:51.131116: step 10234, loss 0.505814.
Train: 2018-08-01T00:34:51.287296: step 10235, loss 0.420866.
Train: 2018-08-01T00:34:51.443510: step 10236, loss 0.544792.
Train: 2018-08-01T00:34:51.599725: step 10237, loss 0.491529.
Train: 2018-08-01T00:34:51.802803: step 10238, loss 0.54476.
Train: 2018-08-01T00:34:51.943424: step 10239, loss 0.63385.
Train: 2018-08-01T00:34:52.115254: step 10240, loss 0.544737.
Test: 2018-08-01T00:34:52.583899: step 10240, loss 0.547633.
Train: 2018-08-01T00:34:52.755703: step 10241, loss 0.491197.
Train: 2018-08-01T00:34:52.911947: step 10242, loss 0.580462.
Train: 2018-08-01T00:34:53.068130: step 10243, loss 0.544711.
Train: 2018-08-01T00:34:53.224343: step 10244, loss 0.508891.
Train: 2018-08-01T00:34:53.380558: step 10245, loss 0.670223.
Train: 2018-08-01T00:34:53.552422: step 10246, loss 0.68811.
Train: 2018-08-01T00:34:53.708604: step 10247, loss 0.526825.
Train: 2018-08-01T00:34:53.864849: step 10248, loss 0.580441.
Train: 2018-08-01T00:34:54.021063: step 10249, loss 0.509092.
Train: 2018-08-01T00:34:54.177276: step 10250, loss 0.509139.
Test: 2018-08-01T00:34:54.661507: step 10250, loss 0.547648.
Train: 2018-08-01T00:34:54.817721: step 10251, loss 0.615955.
Train: 2018-08-01T00:34:54.973933: step 10252, loss 0.420306.
Train: 2018-08-01T00:34:55.145768: step 10253, loss 0.598141.
Train: 2018-08-01T00:34:55.301982: step 10254, loss 0.562552.
Train: 2018-08-01T00:34:55.458196: step 10255, loss 0.562552.
Train: 2018-08-01T00:34:55.630031: step 10256, loss 0.651532.
Train: 2018-08-01T00:34:55.770658: step 10257, loss 0.598077.
Train: 2018-08-01T00:34:55.926836: step 10258, loss 0.597991.
Train: 2018-08-01T00:34:56.098703: step 10259, loss 0.615578.
Train: 2018-08-01T00:34:56.286158: step 10260, loss 0.597758.
Test: 2018-08-01T00:34:56.754797: step 10260, loss 0.547744.
Train: 2018-08-01T00:34:56.910980: step 10261, loss 0.474575.
Train: 2018-08-01T00:34:57.082815: step 10262, loss 0.562453.
Train: 2018-08-01T00:34:57.239054: step 10263, loss 0.61499.
Train: 2018-08-01T00:34:57.410863: step 10264, loss 0.562434.
Train: 2018-08-01T00:34:57.567107: step 10265, loss 0.510124.
Train: 2018-08-01T00:34:57.723320: step 10266, loss 0.527598.
Train: 2018-08-01T00:34:57.879536: step 10267, loss 0.475422.
Train: 2018-08-01T00:34:58.035747: step 10268, loss 0.666882.
Train: 2018-08-01T00:34:58.191960: step 10269, loss 0.562417.
Train: 2018-08-01T00:34:58.348183: step 10270, loss 0.597163.
Test: 2018-08-01T00:34:58.832435: step 10270, loss 0.547882.
Train: 2018-08-01T00:34:58.988649: step 10271, loss 0.527711.
Train: 2018-08-01T00:34:59.144831: step 10272, loss 0.614413.
Train: 2018-08-01T00:34:59.301076: step 10273, loss 0.614328.
Train: 2018-08-01T00:34:59.457297: step 10274, loss 0.614208.
Train: 2018-08-01T00:34:59.629093: step 10275, loss 0.614058.
Train: 2018-08-01T00:34:59.785337: step 10276, loss 0.510908.
Train: 2018-08-01T00:34:59.941521: step 10277, loss 0.476776.
Train: 2018-08-01T00:35:00.097765: step 10278, loss 0.596621.
Train: 2018-08-01T00:35:00.253977: step 10279, loss 0.545304.
Train: 2018-08-01T00:35:00.410161: step 10280, loss 0.664877.
Test: 2018-08-01T00:35:00.894453: step 10280, loss 0.54813.
Train: 2018-08-01T00:35:01.050636: step 10281, loss 0.596483.
Train: 2018-08-01T00:35:01.206879: step 10282, loss 0.545407.
Train: 2018-08-01T00:35:01.363095: step 10283, loss 0.579375.
Train: 2018-08-01T00:35:01.519306: step 10284, loss 0.494697.
Train: 2018-08-01T00:35:01.675527: step 10285, loss 0.647005.
Train: 2018-08-01T00:35:01.831703: step 10286, loss 0.613079.
Train: 2018-08-01T00:35:01.987916: step 10287, loss 0.528748.
Train: 2018-08-01T00:35:02.144131: step 10288, loss 0.511996.
Train: 2018-08-01T00:35:02.300374: step 10289, loss 0.562443.
Train: 2018-08-01T00:35:02.456582: step 10290, loss 0.59604.
Test: 2018-08-01T00:35:02.940818: step 10290, loss 0.548397.
Train: 2018-08-01T00:35:03.097056: step 10291, loss 0.545668.
Train: 2018-08-01T00:35:03.253275: step 10292, loss 0.528903.
Train: 2018-08-01T00:35:03.409490: step 10293, loss 0.646343.
Train: 2018-08-01T00:35:03.565702: step 10294, loss 0.545697.
Train: 2018-08-01T00:35:03.706294: step 10295, loss 0.445212.
Train: 2018-08-01T00:35:03.893751: step 10296, loss 0.612774.
Train: 2018-08-01T00:35:04.049964: step 10297, loss 0.596016.
Train: 2018-08-01T00:35:04.221793: step 10298, loss 0.579233.
Train: 2018-08-01T00:35:04.377982: step 10299, loss 0.579231.
Train: 2018-08-01T00:35:04.534226: step 10300, loss 0.596002.
Test: 2018-08-01T00:35:05.002866: step 10300, loss 0.54842.
Train: 2018-08-01T00:35:05.721447: step 10301, loss 0.51217.
Train: 2018-08-01T00:35:05.893253: step 10302, loss 0.528924.
Train: 2018-08-01T00:35:06.049490: step 10303, loss 0.646347.
Train: 2018-08-01T00:35:06.205708: step 10304, loss 0.595994.
Train: 2018-08-01T00:35:06.361892: step 10305, loss 0.495443.
Train: 2018-08-01T00:35:06.533726: step 10306, loss 0.646252.
Train: 2018-08-01T00:35:06.689988: step 10307, loss 0.445265.
Train: 2018-08-01T00:35:06.846184: step 10308, loss 0.64626.
Train: 2018-08-01T00:35:07.002367: step 10309, loss 0.562458.
Train: 2018-08-01T00:35:07.158589: step 10310, loss 0.545706.
Test: 2018-08-01T00:35:07.627221: step 10310, loss 0.548426.
Train: 2018-08-01T00:35:07.783465: step 10311, loss 0.545702.
Train: 2018-08-01T00:35:07.939678: step 10312, loss 0.696576.
Train: 2018-08-01T00:35:08.095862: step 10313, loss 0.562463.
Train: 2018-08-01T00:35:08.267695: step 10314, loss 0.612617.
Train: 2018-08-01T00:35:08.423909: step 10315, loss 0.495752.
Train: 2018-08-01T00:35:08.580153: step 10316, loss 0.512467.
Train: 2018-08-01T00:35:08.736366: step 10317, loss 0.612523.
Train: 2018-08-01T00:35:08.892550: step 10318, loss 0.562486.
Train: 2018-08-01T00:35:09.048762: step 10319, loss 0.512475.
Train: 2018-08-01T00:35:09.205008: step 10320, loss 0.562482.
Test: 2018-08-01T00:35:09.689268: step 10320, loss 0.548497.
Train: 2018-08-01T00:35:09.861103: step 10321, loss 0.562478.
Train: 2018-08-01T00:35:10.017316: step 10322, loss 0.412098.
Train: 2018-08-01T00:35:10.173530: step 10323, loss 0.512168.
Train: 2018-08-01T00:35:10.329712: step 10324, loss 0.545611.
Train: 2018-08-01T00:35:10.517199: step 10325, loss 0.494866.
Train: 2018-08-01T00:35:10.673382: step 10326, loss 0.613305.
Train: 2018-08-01T00:35:10.829595: step 10327, loss 0.46028.
Train: 2018-08-01T00:35:10.985809: step 10328, loss 0.596593.
Train: 2018-08-01T00:35:11.142053: step 10329, loss 0.510919.
Train: 2018-08-01T00:35:11.298272: step 10330, loss 0.579625.
Test: 2018-08-01T00:35:11.782527: step 10330, loss 0.547928.
Train: 2018-08-01T00:35:11.923123: step 10331, loss 0.475982.
Train: 2018-08-01T00:35:12.079303: step 10332, loss 0.527696.
Train: 2018-08-01T00:35:12.235547: step 10333, loss 0.649583.
Train: 2018-08-01T00:35:12.391755: step 10334, loss 0.492534.
Train: 2018-08-01T00:35:12.563602: step 10335, loss 0.650104.
Train: 2018-08-01T00:35:12.735424: step 10336, loss 0.597572.
Train: 2018-08-01T00:35:12.891643: step 10337, loss 0.527319.
Train: 2018-08-01T00:35:13.047862: step 10338, loss 0.632829.
Train: 2018-08-01T00:35:13.204040: step 10339, loss 0.456937.
Train: 2018-08-01T00:35:13.360253: step 10340, loss 0.509638.
Test: 2018-08-01T00:35:13.828918: step 10340, loss 0.547711.
Train: 2018-08-01T00:35:13.985106: step 10341, loss 0.474258.
Train: 2018-08-01T00:35:14.141355: step 10342, loss 0.527113.
Train: 2018-08-01T00:35:14.297564: step 10343, loss 0.54478.
Train: 2018-08-01T00:35:14.453747: step 10344, loss 0.544753.
Train: 2018-08-01T00:35:14.609999: step 10345, loss 0.616123.
Train: 2018-08-01T00:35:14.766175: step 10346, loss 0.598343.
Train: 2018-08-01T00:35:14.938008: step 10347, loss 0.5626.
Train: 2018-08-01T00:35:15.094222: step 10348, loss 0.473119.
Train: 2018-08-01T00:35:15.250435: step 10349, loss 0.670172.
Train: 2018-08-01T00:35:15.406679: step 10350, loss 0.508856.
Test: 2018-08-01T00:35:15.875314: step 10350, loss 0.54761.
Train: 2018-08-01T00:35:16.031534: step 10351, loss 0.544695.
Train: 2018-08-01T00:35:16.203368: step 10352, loss 0.634369.
Train: 2018-08-01T00:35:16.359582: step 10353, loss 0.634308.
Train: 2018-08-01T00:35:16.515796: step 10354, loss 0.473154.
Train: 2018-08-01T00:35:16.671978: step 10355, loss 0.508956.
Train: 2018-08-01T00:35:16.828192: step 10356, loss 0.473185.
Train: 2018-08-01T00:35:16.984405: step 10357, loss 0.580514.
Train: 2018-08-01T00:35:17.140617: step 10358, loss 0.580534.
Train: 2018-08-01T00:35:17.296832: step 10359, loss 0.598464.
Train: 2018-08-01T00:35:17.453044: step 10360, loss 0.526785.
Test: 2018-08-01T00:35:17.937337: step 10360, loss 0.547613.
Train: 2018-08-01T00:35:18.109170: step 10361, loss 0.490956.
Train: 2018-08-01T00:35:18.265355: step 10362, loss 0.472974.
Train: 2018-08-01T00:35:18.421568: step 10363, loss 0.634498.
Train: 2018-08-01T00:35:18.562190: step 10364, loss 0.50873.
Train: 2018-08-01T00:35:18.718403: step 10365, loss 0.508684.
Train: 2018-08-01T00:35:18.890209: step 10366, loss 0.598721.
Train: 2018-08-01T00:35:19.046422: step 10367, loss 0.47252.
Train: 2018-08-01T00:35:19.202636: step 10368, loss 0.508514.
Train: 2018-08-01T00:35:19.358884: step 10369, loss 0.417903.
Train: 2018-08-01T00:35:19.515092: step 10370, loss 0.58096.
Test: 2018-08-01T00:35:19.983732: step 10370, loss 0.547568.
Train: 2018-08-01T00:35:20.139916: step 10371, loss 0.544604.
Train: 2018-08-01T00:35:20.311752: step 10372, loss 0.471498.
Train: 2018-08-01T00:35:20.467994: step 10373, loss 0.489576.
Train: 2018-08-01T00:35:20.624201: step 10374, loss 0.636619.
Train: 2018-08-01T00:35:20.780420: step 10375, loss 0.67372.
Train: 2018-08-01T00:35:20.936629: step 10376, loss 0.710666.
Train: 2018-08-01T00:35:21.092847: step 10377, loss 0.415652.
Train: 2018-08-01T00:35:21.249061: step 10378, loss 0.673507.
Train: 2018-08-01T00:35:21.405246: step 10379, loss 0.544583.
Train: 2018-08-01T00:35:21.561488: step 10380, loss 0.471151.
Test: 2018-08-01T00:35:22.030098: step 10380, loss 0.54757.
Train: 2018-08-01T00:35:22.186336: step 10381, loss 0.526234.
Train: 2018-08-01T00:35:22.358176: step 10382, loss 0.526235.
Train: 2018-08-01T00:35:22.514361: step 10383, loss 0.599648.
Train: 2018-08-01T00:35:22.670574: step 10384, loss 0.562931.
Train: 2018-08-01T00:35:22.826786: step 10385, loss 0.617916.
Train: 2018-08-01T00:35:22.998621: step 10386, loss 0.544591.
Train: 2018-08-01T00:35:23.139214: step 10387, loss 0.709094.
Train: 2018-08-01T00:35:23.311048: step 10388, loss 0.581036.
Train: 2018-08-01T00:35:23.451640: step 10389, loss 0.635373.
Train: 2018-08-01T00:35:23.623474: step 10390, loss 0.689212.
Test: 2018-08-01T00:35:24.107737: step 10390, loss 0.547601.
Train: 2018-08-01T00:35:24.263980: step 10391, loss 0.472817.
Train: 2018-08-01T00:35:24.420164: step 10392, loss 0.63416.
Train: 2018-08-01T00:35:24.576406: step 10393, loss 0.544753.
Train: 2018-08-01T00:35:24.748245: step 10394, loss 0.633415.
Train: 2018-08-01T00:35:24.904424: step 10395, loss 0.756466.
Train: 2018-08-01T00:35:25.060668: step 10396, loss 0.457418.
Train: 2018-08-01T00:35:25.216882: step 10397, loss 0.597244.
Train: 2018-08-01T00:35:25.373095: step 10398, loss 0.562406.
Train: 2018-08-01T00:35:25.529278: step 10399, loss 0.631339.
Train: 2018-08-01T00:35:25.701129: step 10400, loss 0.493829.
Test: 2018-08-01T00:35:26.154163: step 10400, loss 0.5481.
Train: 2018-08-01T00:35:26.841472: step 10401, loss 0.494098.
Train: 2018-08-01T00:35:26.997686: step 10402, loss 0.511301.
Train: 2018-08-01T00:35:27.153928: step 10403, loss 0.579414.
Train: 2018-08-01T00:35:27.310141: step 10404, loss 0.528438.
Train: 2018-08-01T00:35:27.466356: step 10405, loss 0.494524.
Train: 2018-08-01T00:35:27.638190: step 10406, loss 0.528452.
Train: 2018-08-01T00:35:27.794398: step 10407, loss 0.613386.
Train: 2018-08-01T00:35:27.966208: step 10408, loss 0.630383.
Train: 2018-08-01T00:35:28.106825: step 10409, loss 0.562408.
Train: 2018-08-01T00:35:28.278665: step 10410, loss 0.460626.
Test: 2018-08-01T00:35:28.747274: step 10410, loss 0.54819.
Train: 2018-08-01T00:35:28.903488: step 10411, loss 0.511471.
Train: 2018-08-01T00:35:29.059702: step 10412, loss 0.596417.
Train: 2018-08-01T00:35:29.215940: step 10413, loss 0.630492.
Train: 2018-08-01T00:35:29.372129: step 10414, loss 0.613461.
Train: 2018-08-01T00:35:29.528343: step 10415, loss 0.596413.
Train: 2018-08-01T00:35:29.684586: step 10416, loss 0.579389.
Train: 2018-08-01T00:35:29.840799: step 10417, loss 0.562411.
Train: 2018-08-01T00:35:29.997015: step 10418, loss 0.562414.
Train: 2018-08-01T00:35:30.184438: step 10419, loss 0.562417.
Train: 2018-08-01T00:35:30.340653: step 10420, loss 0.511711.
Test: 2018-08-01T00:35:30.824947: step 10420, loss 0.548266.
Train: 2018-08-01T00:35:30.981127: step 10421, loss 0.528613.
Train: 2018-08-01T00:35:31.152986: step 10422, loss 0.545505.
Train: 2018-08-01T00:35:31.324796: step 10423, loss 0.630129.
Train: 2018-08-01T00:35:31.481009: step 10424, loss 0.630113.
Train: 2018-08-01T00:35:31.652874: step 10425, loss 0.51171.
Train: 2018-08-01T00:35:31.809088: step 10426, loss 0.613118.
Train: 2018-08-01T00:35:31.965301: step 10427, loss 0.494895.
Train: 2018-08-01T00:35:32.121509: step 10428, loss 0.646856.
Train: 2018-08-01T00:35:32.277734: step 10429, loss 0.461216.
Train: 2018-08-01T00:35:32.449533: step 10430, loss 0.629947.
Test: 2018-08-01T00:35:32.918203: step 10430, loss 0.548296.
Train: 2018-08-01T00:35:33.090038: step 10431, loss 0.545552.
Train: 2018-08-01T00:35:33.246221: step 10432, loss 0.545552.
Train: 2018-08-01T00:35:33.418089: step 10433, loss 0.511788.
Train: 2018-08-01T00:35:33.574269: step 10434, loss 0.562421.
Train: 2018-08-01T00:35:33.730484: step 10435, loss 0.528585.
Train: 2018-08-01T00:35:33.902348: step 10436, loss 0.61324.
Train: 2018-08-01T00:35:34.058561: step 10437, loss 0.596318.
Train: 2018-08-01T00:35:34.214745: step 10438, loss 0.562411.
Train: 2018-08-01T00:35:34.370988: step 10439, loss 0.596324.
Train: 2018-08-01T00:35:34.527172: step 10440, loss 0.409861.
Test: 2018-08-01T00:35:35.011463: step 10440, loss 0.548184.
Train: 2018-08-01T00:35:35.167678: step 10441, loss 0.596377.
Train: 2018-08-01T00:35:35.323890: step 10442, loss 0.49437.
Train: 2018-08-01T00:35:35.480104: step 10443, loss 0.681735.
Train: 2018-08-01T00:35:35.651936: step 10444, loss 0.528295.
Train: 2018-08-01T00:35:35.792536: step 10445, loss 0.698924.
Train: 2018-08-01T00:35:35.948744: step 10446, loss 0.613527.
Train: 2018-08-01T00:35:36.120578: step 10447, loss 0.630437.
Train: 2018-08-01T00:35:36.276792: step 10448, loss 0.477609.
Train: 2018-08-01T00:35:36.433006: step 10449, loss 0.426893.
Train: 2018-08-01T00:35:36.589188: step 10450, loss 0.511536.
Test: 2018-08-01T00:35:37.057829: step 10450, loss 0.54818.
Train: 2018-08-01T00:35:37.214073: step 10451, loss 0.460474.
Train: 2018-08-01T00:35:37.370255: step 10452, loss 0.5624.
Train: 2018-08-01T00:35:37.526470: step 10453, loss 0.476933.
Train: 2018-08-01T00:35:37.682707: step 10454, loss 0.562395.
Train: 2018-08-01T00:35:37.838898: step 10455, loss 0.648497.
Train: 2018-08-01T00:35:37.995111: step 10456, loss 0.527895.
Train: 2018-08-01T00:35:38.151323: step 10457, loss 0.614269.
Train: 2018-08-01T00:35:38.307566: step 10458, loss 0.718183.
Train: 2018-08-01T00:35:38.479371: step 10459, loss 0.493279.
Train: 2018-08-01T00:35:38.635584: step 10460, loss 0.562401.
Test: 2018-08-01T00:35:39.104255: step 10460, loss 0.547932.
Train: 2018-08-01T00:35:39.260474: step 10461, loss 0.545122.
Train: 2018-08-01T00:35:39.416682: step 10462, loss 0.562402.
Train: 2018-08-01T00:35:39.572895: step 10463, loss 0.475996.
Train: 2018-08-01T00:35:39.729079: step 10464, loss 0.597011.
Train: 2018-08-01T00:35:39.885293: step 10465, loss 0.510464.
Train: 2018-08-01T00:35:40.041506: step 10466, loss 0.545073.
Train: 2018-08-01T00:35:40.197749: step 10467, loss 0.579773.
Train: 2018-08-01T00:35:40.353931: step 10468, loss 0.579796.
Train: 2018-08-01T00:35:40.510145: step 10469, loss 0.66675.
Train: 2018-08-01T00:35:40.666389: step 10470, loss 0.545047.
Test: 2018-08-01T00:35:41.150621: step 10470, loss 0.547881.
Train: 2018-08-01T00:35:41.322455: step 10471, loss 0.545059.
Train: 2018-08-01T00:35:41.478699: step 10472, loss 0.545066.
Train: 2018-08-01T00:35:41.634912: step 10473, loss 0.493041.
Train: 2018-08-01T00:35:41.806717: step 10474, loss 0.458274.
Train: 2018-08-01T00:35:41.947309: step 10475, loss 0.545026.
Train: 2018-08-01T00:35:42.119143: step 10476, loss 0.56243.
Train: 2018-08-01T00:35:42.291009: step 10477, loss 0.579905.
Train: 2018-08-01T00:35:42.447222: step 10478, loss 0.61492.
Train: 2018-08-01T00:35:42.603435: step 10479, loss 0.422448.
Train: 2018-08-01T00:35:42.775240: step 10480, loss 0.615082.
Test: 2018-08-01T00:35:43.243910: step 10480, loss 0.547758.
Train: 2018-08-01T00:35:43.415716: step 10481, loss 0.527338.
Train: 2018-08-01T00:35:43.587549: step 10482, loss 0.703207.
Train: 2018-08-01T00:35:43.743801: step 10483, loss 0.58005.
Train: 2018-08-01T00:35:43.915600: step 10484, loss 0.544902.
Train: 2018-08-01T00:35:44.071812: step 10485, loss 0.509809.
Train: 2018-08-01T00:35:44.228024: step 10486, loss 0.492253.
Train: 2018-08-01T00:35:44.384275: step 10487, loss 0.580038.
Train: 2018-08-01T00:35:44.556073: step 10488, loss 0.63279.
Train: 2018-08-01T00:35:44.712311: step 10489, loss 0.492189.
Train: 2018-08-01T00:35:44.868525: step 10490, loss 0.685507.
Test: 2018-08-01T00:35:45.337170: step 10490, loss 0.547764.
Train: 2018-08-01T00:35:45.509000: step 10491, loss 0.597563.
Train: 2018-08-01T00:35:45.665213: step 10492, loss 0.597486.
Train: 2018-08-01T00:35:45.821432: step 10493, loss 0.475056.
Train: 2018-08-01T00:35:45.977645: step 10494, loss 0.527514.
Train: 2018-08-01T00:35:46.133829: step 10495, loss 0.649714.
Train: 2018-08-01T00:35:46.290072: step 10496, loss 0.527574.
Train: 2018-08-01T00:35:46.446286: step 10497, loss 0.510196.
Train: 2018-08-01T00:35:46.602471: step 10498, loss 0.597237.
Train: 2018-08-01T00:35:46.758712: step 10499, loss 0.562422.
Train: 2018-08-01T00:35:46.914897: step 10500, loss 0.562419.
Test: 2018-08-01T00:35:47.395104: step 10500, loss 0.547873.
Train: 2018-08-01T00:35:48.176171: step 10501, loss 0.562417.
Train: 2018-08-01T00:35:48.332354: step 10502, loss 0.510342.
Train: 2018-08-01T00:35:48.488593: step 10503, loss 0.631856.
Train: 2018-08-01T00:35:48.644811: step 10504, loss 0.493038.
Train: 2018-08-01T00:35:48.800996: step 10505, loss 0.579759.
Train: 2018-08-01T00:35:48.972830: step 10506, loss 0.49304.
Train: 2018-08-01T00:35:49.129067: step 10507, loss 0.562414.
Train: 2018-08-01T00:35:49.285257: step 10508, loss 0.545046.
Train: 2018-08-01T00:35:49.441501: step 10509, loss 0.545034.
Train: 2018-08-01T00:35:49.613335: step 10510, loss 0.579823.
Test: 2018-08-01T00:35:50.081975: step 10510, loss 0.547843.
Train: 2018-08-01T00:35:50.238183: step 10511, loss 0.649484.
Train: 2018-08-01T00:35:50.394402: step 10512, loss 0.614615.
Train: 2018-08-01T00:35:50.550585: step 10513, loss 0.614529.
Train: 2018-08-01T00:35:50.706799: step 10514, loss 0.579743.
Train: 2018-08-01T00:35:50.863042: step 10515, loss 0.631579.
Train: 2018-08-01T00:35:51.019256: step 10516, loss 0.527921.
Train: 2018-08-01T00:35:51.175469: step 10517, loss 0.510798.
Train: 2018-08-01T00:35:51.331682: step 10518, loss 0.54522.
Train: 2018-08-01T00:35:51.487896: step 10519, loss 0.613882.
Train: 2018-08-01T00:35:51.644109: step 10520, loss 0.579531.
Test: 2018-08-01T00:35:52.112747: step 10520, loss 0.548075.
Train: 2018-08-01T00:35:52.268958: step 10521, loss 0.562398.
Train: 2018-08-01T00:35:52.425177: step 10522, loss 0.664868.
Train: 2018-08-01T00:35:52.581360: step 10523, loss 0.698628.
Train: 2018-08-01T00:35:52.737603: step 10524, loss 0.528518.
Train: 2018-08-01T00:35:52.893817: step 10525, loss 0.494883.
Train: 2018-08-01T00:35:53.050030: step 10526, loss 0.612978.
Train: 2018-08-01T00:35:53.221836: step 10527, loss 0.495237.
Train: 2018-08-01T00:35:53.378073: step 10528, loss 0.579231.
Train: 2018-08-01T00:35:53.534262: step 10529, loss 0.595971.
Train: 2018-08-01T00:35:53.690476: step 10530, loss 0.562468.
Test: 2018-08-01T00:35:54.159145: step 10530, loss 0.548489.
Train: 2018-08-01T00:35:54.330950: step 10531, loss 0.662696.
Train: 2018-08-01T00:35:54.487189: step 10532, loss 0.57915.
Train: 2018-08-01T00:35:54.643408: step 10533, loss 0.462842.
Train: 2018-08-01T00:35:54.799620: step 10534, loss 0.579116.
Train: 2018-08-01T00:35:54.955804: step 10535, loss 0.54483.
Train: 2018-08-01T00:35:55.112017: step 10536, loss 0.496199.
Train: 2018-08-01T00:35:55.283881: step 10537, loss 0.496132.
Train: 2018-08-01T00:35:55.455686: step 10538, loss 0.562504.
Train: 2018-08-01T00:35:55.611899: step 10539, loss 0.645798.
Train: 2018-08-01T00:35:55.768113: step 10540, loss 0.545818.
Test: 2018-08-01T00:35:56.236784: step 10540, loss 0.548513.
Train: 2018-08-01T00:35:56.392997: step 10541, loss 0.512434.
Train: 2018-08-01T00:35:56.564802: step 10542, loss 0.462213.
Train: 2018-08-01T00:35:56.721014: step 10543, loss 0.428356.
Train: 2018-08-01T00:35:56.877258: step 10544, loss 0.562433.
Train: 2018-08-01T00:35:57.033475: step 10545, loss 0.494725.
Train: 2018-08-01T00:35:57.189655: step 10546, loss 0.73251.
Train: 2018-08-01T00:35:57.345893: step 10547, loss 0.596492.
Train: 2018-08-01T00:35:57.502107: step 10548, loss 0.596536.
Train: 2018-08-01T00:35:57.673916: step 10549, loss 0.66488.
Train: 2018-08-01T00:35:57.830164: step 10550, loss 0.562399.
Test: 2018-08-01T00:35:58.298801: step 10550, loss 0.548122.
Train: 2018-08-01T00:35:58.470630: step 10551, loss 0.511246.
Train: 2018-08-01T00:35:58.626849: step 10552, loss 0.460083.
Train: 2018-08-01T00:35:58.798689: step 10553, loss 0.613641.
Train: 2018-08-01T00:35:58.954898: step 10554, loss 0.613677.
Train: 2018-08-01T00:35:59.111111: step 10555, loss 0.494032.
Train: 2018-08-01T00:35:59.267327: step 10556, loss 0.528182.
Train: 2018-08-01T00:35:59.423507: step 10557, loss 0.613789.
Train: 2018-08-01T00:35:59.579753: step 10558, loss 0.596686.
Train: 2018-08-01T00:35:59.751557: step 10559, loss 0.613808.
Train: 2018-08-01T00:35:59.923390: step 10560, loss 0.562396.
Test: 2018-08-01T00:36:00.392029: step 10560, loss 0.54807.
Train: 2018-08-01T00:36:00.563896: step 10561, loss 0.562397.
Train: 2018-08-01T00:36:00.720112: step 10562, loss 0.562398.
Train: 2018-08-01T00:36:00.876294: step 10563, loss 0.664926.
Train: 2018-08-01T00:36:01.032506: step 10564, loss 0.562402.
Train: 2018-08-01T00:36:01.188749: step 10565, loss 0.511343.
Train: 2018-08-01T00:36:01.344932: step 10566, loss 0.613425.
Train: 2018-08-01T00:36:01.516801: step 10567, loss 0.54543.
Train: 2018-08-01T00:36:01.673011: step 10568, loss 0.562413.
Train: 2018-08-01T00:36:01.829218: step 10569, loss 0.630199.
Train: 2018-08-01T00:36:01.985434: step 10570, loss 0.528593.
Test: 2018-08-01T00:36:02.454079: step 10570, loss 0.548277.
Train: 2018-08-01T00:36:02.625907: step 10571, loss 0.562426.
Train: 2018-08-01T00:36:02.782126: step 10572, loss 0.545549.
Train: 2018-08-01T00:36:02.953962: step 10573, loss 0.494946.
Train: 2018-08-01T00:36:03.141413: step 10574, loss 0.562429.
Train: 2018-08-01T00:36:03.297600: step 10575, loss 0.528641.
Train: 2018-08-01T00:36:03.453844: step 10576, loss 0.528599.
Train: 2018-08-01T00:36:03.610026: step 10577, loss 0.579357.
Train: 2018-08-01T00:36:03.766266: step 10578, loss 0.545455.
Train: 2018-08-01T00:36:03.938076: step 10579, loss 0.579395.
Train: 2018-08-01T00:36:04.094322: step 10580, loss 0.613413.
Test: 2018-08-01T00:36:04.562959: step 10580, loss 0.548169.
Train: 2018-08-01T00:36:04.719175: step 10581, loss 0.630427.
Train: 2018-08-01T00:36:04.875355: step 10582, loss 0.59639.
Train: 2018-08-01T00:36:05.031599: step 10583, loss 0.630287.
Train: 2018-08-01T00:36:05.187782: step 10584, loss 0.596283.
Train: 2018-08-01T00:36:05.359641: step 10585, loss 0.562426.
Train: 2018-08-01T00:36:05.515867: step 10586, loss 0.562434.
Train: 2018-08-01T00:36:05.687704: step 10587, loss 0.528794.
Train: 2018-08-01T00:36:05.843912: step 10588, loss 0.663281.
Train: 2018-08-01T00:36:05.984472: step 10589, loss 0.579222.
Train: 2018-08-01T00:36:06.156306: step 10590, loss 0.562471.
Test: 2018-08-01T00:36:06.624976: step 10590, loss 0.548509.
Train: 2018-08-01T00:36:06.781159: step 10591, loss 0.595859.
Train: 2018-08-01T00:36:06.937373: step 10592, loss 0.579147.
Train: 2018-08-01T00:36:07.093586: step 10593, loss 0.579124.
Train: 2018-08-01T00:36:07.249799: step 10594, loss 0.628828.
Train: 2018-08-01T00:36:07.406044: step 10595, loss 0.562552.
Train: 2018-08-01T00:36:07.593469: step 10596, loss 0.529605.
Train: 2018-08-01T00:36:07.749713: step 10597, loss 0.513214.
Train: 2018-08-01T00:36:07.905926: step 10598, loss 0.562591.
Train: 2018-08-01T00:36:08.077732: step 10599, loss 0.611929.
Train: 2018-08-01T00:36:08.218347: step 10600, loss 0.546172.
Test: 2018-08-01T00:36:08.686993: step 10600, loss 0.548853.
Train: 2018-08-01T00:36:09.421195: step 10601, loss 0.496912.
Train: 2018-08-01T00:36:09.593001: step 10602, loss 0.513283.
Train: 2018-08-01T00:36:09.764835: step 10603, loss 0.611982.
Train: 2018-08-01T00:36:09.921074: step 10604, loss 0.496646.
Train: 2018-08-01T00:36:10.077296: step 10605, loss 0.628619.
Train: 2018-08-01T00:36:10.233506: step 10606, loss 0.479897.
Train: 2018-08-01T00:36:10.389690: step 10607, loss 0.47969.
Train: 2018-08-01T00:36:10.545933: step 10608, loss 0.496.
Train: 2018-08-01T00:36:10.702116: step 10609, loss 0.612574.
Train: 2018-08-01T00:36:10.873952: step 10610, loss 0.579212.
Test: 2018-08-01T00:36:11.342624: step 10610, loss 0.548382.
Train: 2018-08-01T00:36:11.498835: step 10611, loss 0.579243.
Train: 2018-08-01T00:36:11.655019: step 10612, loss 0.629771.
Train: 2018-08-01T00:36:11.826889: step 10613, loss 0.596133.
Train: 2018-08-01T00:36:11.998718: step 10614, loss 0.545574.
Train: 2018-08-01T00:36:12.154931: step 10615, loss 0.579298.
Train: 2018-08-01T00:36:12.311114: step 10616, loss 0.511798.
Train: 2018-08-01T00:36:12.482980: step 10617, loss 0.562423.
Train: 2018-08-01T00:36:12.639162: step 10618, loss 0.494751.
Train: 2018-08-01T00:36:12.795403: step 10619, loss 0.596319.
Train: 2018-08-01T00:36:12.951589: step 10620, loss 0.613343.
Test: 2018-08-01T00:36:13.404638: step 10620, loss 0.548183.
Train: 2018-08-01T00:36:13.560852: step 10621, loss 0.528433.
Train: 2018-08-01T00:36:13.732687: step 10622, loss 0.562405.
Train: 2018-08-01T00:36:13.888901: step 10623, loss 0.52836.
Train: 2018-08-01T00:36:14.060711: step 10624, loss 0.494216.
Train: 2018-08-01T00:36:14.216919: step 10625, loss 0.511139.
Train: 2018-08-01T00:36:14.373132: step 10626, loss 0.579533.
Train: 2018-08-01T00:36:14.544966: step 10627, loss 0.528042.
Train: 2018-08-01T00:36:14.701212: step 10628, loss 0.527953.
Train: 2018-08-01T00:36:14.904257: step 10629, loss 0.476041.
Train: 2018-08-01T00:36:15.060470: step 10630, loss 0.493054.
Test: 2018-08-01T00:36:15.529110: step 10630, loss 0.547838.
Train: 2018-08-01T00:36:15.685324: step 10631, loss 0.52759.
Train: 2018-08-01T00:36:15.841570: step 10632, loss 0.649908.
Train: 2018-08-01T00:36:15.997781: step 10633, loss 0.597532.
Train: 2018-08-01T00:36:16.153995: step 10634, loss 0.615176.
Train: 2018-08-01T00:36:16.310216: step 10635, loss 0.474543.
Train: 2018-08-01T00:36:16.482043: step 10636, loss 0.527242.
Train: 2018-08-01T00:36:16.638256: step 10637, loss 0.63311.
Train: 2018-08-01T00:36:16.794476: step 10638, loss 0.562496.
Train: 2018-08-01T00:36:16.950652: step 10639, loss 0.650896.
Train: 2018-08-01T00:36:17.106891: step 10640, loss 0.686146.
Test: 2018-08-01T00:36:17.591128: step 10640, loss 0.547724.
Train: 2018-08-01T00:36:17.731750: step 10641, loss 0.580096.
Train: 2018-08-01T00:36:17.903585: step 10642, loss 0.474608.
Train: 2018-08-01T00:36:18.059768: step 10643, loss 0.597552.
Train: 2018-08-01T00:36:18.216015: step 10644, loss 0.544927.
Train: 2018-08-01T00:36:18.372195: step 10645, loss 0.544945.
Train: 2018-08-01T00:36:18.544029: step 10646, loss 0.562435.
Train: 2018-08-01T00:36:18.700244: step 10647, loss 0.510052.
Train: 2018-08-01T00:36:18.856457: step 10648, loss 0.70208.
Train: 2018-08-01T00:36:19.012670: step 10649, loss 0.666921.
Train: 2018-08-01T00:36:19.168913: step 10650, loss 0.475645.
Test: 2018-08-01T00:36:19.653149: step 10650, loss 0.547904.
Train: 2018-08-01T00:36:19.793767: step 10651, loss 0.579723.
Train: 2018-08-01T00:36:19.949950: step 10652, loss 0.666087.
Train: 2018-08-01T00:36:20.106163: step 10653, loss 0.614059.
Train: 2018-08-01T00:36:20.262378: step 10654, loss 0.579548.
Train: 2018-08-01T00:36:20.418592: step 10655, loss 0.476962.
Train: 2018-08-01T00:36:20.590426: step 10656, loss 0.494198.
Train: 2018-08-01T00:36:20.762260: step 10657, loss 0.579437.
Train: 2018-08-01T00:36:20.918504: step 10658, loss 0.596441.
Train: 2018-08-01T00:36:21.074687: step 10659, loss 0.511421.
Train: 2018-08-01T00:36:21.230928: step 10660, loss 0.579394.
Test: 2018-08-01T00:36:21.699566: step 10660, loss 0.548192.
Train: 2018-08-01T00:36:21.855754: step 10661, loss 0.579385.
Train: 2018-08-01T00:36:22.027589: step 10662, loss 0.528484.
Train: 2018-08-01T00:36:22.168211: step 10663, loss 0.579371.
Train: 2018-08-01T00:36:22.324425: step 10664, loss 0.477639.
Train: 2018-08-01T00:36:22.496259: step 10665, loss 0.443605.
Train: 2018-08-01T00:36:22.652473: step 10666, loss 0.562403.
Train: 2018-08-01T00:36:22.839898: step 10667, loss 0.630651.
Train: 2018-08-01T00:36:22.996143: step 10668, loss 0.511144.
Train: 2018-08-01T00:36:23.152356: step 10669, loss 0.562396.
Train: 2018-08-01T00:36:23.308540: step 10670, loss 0.528101.
Test: 2018-08-01T00:36:23.777209: step 10670, loss 0.548007.
Train: 2018-08-01T00:36:23.933395: step 10671, loss 0.510846.
Train: 2018-08-01T00:36:24.089607: step 10672, loss 0.614084.
Train: 2018-08-01T00:36:24.230198: step 10673, loss 0.562399.
Train: 2018-08-01T00:36:24.386442: step 10674, loss 0.545121.
Train: 2018-08-01T00:36:24.558277: step 10675, loss 0.545098.
Train: 2018-08-01T00:36:24.730082: step 10676, loss 0.458405.
Train: 2018-08-01T00:36:24.886319: step 10677, loss 0.5798.
Train: 2018-08-01T00:36:25.042508: step 10678, loss 0.579848.
Train: 2018-08-01T00:36:25.198721: step 10679, loss 0.579886.
Train: 2018-08-01T00:36:25.354934: step 10680, loss 0.579914.
Test: 2018-08-01T00:36:25.839229: step 10680, loss 0.54779.
Train: 2018-08-01T00:36:25.995440: step 10681, loss 0.579932.
Train: 2018-08-01T00:36:26.167245: step 10682, loss 0.614943.
Train: 2018-08-01T00:36:26.323458: step 10683, loss 0.492467.
Train: 2018-08-01T00:36:26.479672: step 10684, loss 0.474928.
Train: 2018-08-01T00:36:26.635885: step 10685, loss 0.597515.
Train: 2018-08-01T00:36:26.792129: step 10686, loss 0.544905.
Train: 2018-08-01T00:36:26.948312: step 10687, loss 0.63273.
Train: 2018-08-01T00:36:27.104525: step 10688, loss 0.68541.
Train: 2018-08-01T00:36:27.292011: step 10689, loss 0.632565.
Train: 2018-08-01T00:36:27.448228: step 10690, loss 0.649826.
Test: 2018-08-01T00:36:27.916835: step 10690, loss 0.547842.
Train: 2018-08-01T00:36:28.073049: step 10691, loss 0.457967.
Train: 2018-08-01T00:36:28.229262: step 10692, loss 0.492924.
Train: 2018-08-01T00:36:28.416719: step 10693, loss 0.597124.
Train: 2018-08-01T00:36:28.572964: step 10694, loss 0.545074.
Train: 2018-08-01T00:36:28.729175: step 10695, loss 0.597036.
Train: 2018-08-01T00:36:28.885383: step 10696, loss 0.545112.
Train: 2018-08-01T00:36:29.025982: step 10697, loss 0.5624.
Train: 2018-08-01T00:36:29.197818: step 10698, loss 0.52789.
Train: 2018-08-01T00:36:29.354029: step 10699, loss 0.476161.
Train: 2018-08-01T00:36:29.525834: step 10700, loss 0.527873.
Test: 2018-08-01T00:36:30.010125: step 10700, loss 0.547927.
Train: 2018-08-01T00:36:30.713056: step 10701, loss 0.562402.
Train: 2018-08-01T00:36:30.869269: step 10702, loss 0.545098.
Train: 2018-08-01T00:36:31.041134: step 10703, loss 0.562407.
Train: 2018-08-01T00:36:31.197341: step 10704, loss 0.614453.
Train: 2018-08-01T00:36:31.353554: step 10705, loss 0.527708.
Train: 2018-08-01T00:36:31.509774: step 10706, loss 0.562412.
Train: 2018-08-01T00:36:31.665957: step 10707, loss 0.579785.
Train: 2018-08-01T00:36:31.822171: step 10708, loss 0.545039.
Train: 2018-08-01T00:36:31.978415: step 10709, loss 0.649324.
Train: 2018-08-01T00:36:32.150249: step 10710, loss 0.649235.
Test: 2018-08-01T00:36:32.618889: step 10710, loss 0.547898.
Train: 2018-08-01T00:36:32.790724: step 10711, loss 0.579732.
Train: 2018-08-01T00:36:32.946937: step 10712, loss 0.596974.
Train: 2018-08-01T00:36:33.103150: step 10713, loss 0.458953.
Train: 2018-08-01T00:36:33.259334: step 10714, loss 0.579624.
Train: 2018-08-01T00:36:33.415577: step 10715, loss 0.47635.
Train: 2018-08-01T00:36:33.571793: step 10716, loss 0.579613.
Train: 2018-08-01T00:36:33.728005: step 10717, loss 0.596831.
Train: 2018-08-01T00:36:33.899835: step 10718, loss 0.476352.
Train: 2018-08-01T00:36:34.040402: step 10719, loss 0.614069.
Train: 2018-08-01T00:36:34.196644: step 10720, loss 0.493502.
Test: 2018-08-01T00:36:34.680906: step 10720, loss 0.547961.
Train: 2018-08-01T00:36:34.837122: step 10721, loss 0.545157.
Train: 2018-08-01T00:36:35.008960: step 10722, loss 0.648706.
Train: 2018-08-01T00:36:35.165139: step 10723, loss 0.562399.
Train: 2018-08-01T00:36:35.321351: step 10724, loss 0.510644.
Train: 2018-08-01T00:36:35.477589: step 10725, loss 0.57966.
Train: 2018-08-01T00:36:35.633810: step 10726, loss 0.5624.
Train: 2018-08-01T00:36:35.789990: step 10727, loss 0.5624.
Train: 2018-08-01T00:36:35.961860: step 10728, loss 0.493327.
Train: 2018-08-01T00:36:36.133686: step 10729, loss 0.527827.
Train: 2018-08-01T00:36:36.289874: step 10730, loss 0.458525.
Test: 2018-08-01T00:36:36.758544: step 10730, loss 0.547872.
Train: 2018-08-01T00:36:36.930374: step 10731, loss 0.475597.
Train: 2018-08-01T00:36:37.086563: step 10732, loss 0.649571.
Train: 2018-08-01T00:36:37.242777: step 10733, loss 0.5275.
Train: 2018-08-01T00:36:37.398989: step 10734, loss 0.632469.
Train: 2018-08-01T00:36:37.555234: step 10735, loss 0.615019.
Train: 2018-08-01T00:36:37.711416: step 10736, loss 0.492347.
Train: 2018-08-01T00:36:37.883251: step 10737, loss 0.562452.
Train: 2018-08-01T00:36:38.039466: step 10738, loss 0.527343.
Train: 2018-08-01T00:36:38.195677: step 10739, loss 0.580041.
Train: 2018-08-01T00:36:38.367537: step 10740, loss 0.474515.
Test: 2018-08-01T00:36:38.836153: step 10740, loss 0.547721.
Train: 2018-08-01T00:36:38.992366: step 10741, loss 0.456742.
Train: 2018-08-01T00:36:39.148610: step 10742, loss 0.544822.
Train: 2018-08-01T00:36:39.304795: step 10743, loss 0.580249.
Train: 2018-08-01T00:36:39.461039: step 10744, loss 0.509231.
Train: 2018-08-01T00:36:39.617220: step 10745, loss 0.491295.
Train: 2018-08-01T00:36:39.773433: step 10746, loss 0.616217.
Train: 2018-08-01T00:36:39.929646: step 10747, loss 0.544701.
Train: 2018-08-01T00:36:40.085860: step 10748, loss 0.58058.
Train: 2018-08-01T00:36:40.242073: step 10749, loss 0.59859.
Train: 2018-08-01T00:36:40.413919: step 10750, loss 0.526692.
Test: 2018-08-01T00:36:40.898200: step 10750, loss 0.547594.
Train: 2018-08-01T00:36:41.054383: step 10751, loss 0.544668.
Train: 2018-08-01T00:36:41.210596: step 10752, loss 0.652732.
Train: 2018-08-01T00:36:41.366810: step 10753, loss 0.580667.
Train: 2018-08-01T00:36:41.538644: step 10754, loss 0.454761.
Train: 2018-08-01T00:36:41.694858: step 10755, loss 0.598641.
Train: 2018-08-01T00:36:41.851102: step 10756, loss 0.562657.
Train: 2018-08-01T00:36:42.007286: step 10757, loss 0.562653.
Train: 2018-08-01T00:36:42.163525: step 10758, loss 0.544677.
Train: 2018-08-01T00:36:42.319737: step 10759, loss 0.54468.
Train: 2018-08-01T00:36:42.491578: step 10760, loss 0.63448.
Test: 2018-08-01T00:36:42.960220: step 10760, loss 0.547608.
Train: 2018-08-01T00:36:43.132046: step 10761, loss 0.616433.
Train: 2018-08-01T00:36:43.288235: step 10762, loss 0.508913.
Train: 2018-08-01T00:36:43.444449: step 10763, loss 0.562592.
Train: 2018-08-01T00:36:43.600662: step 10764, loss 0.562579.
Train: 2018-08-01T00:36:43.772497: step 10765, loss 0.473432.
Train: 2018-08-01T00:36:43.928710: step 10766, loss 0.633871.
Train: 2018-08-01T00:36:44.084948: step 10767, loss 0.651581.
Train: 2018-08-01T00:36:44.241167: step 10768, loss 0.509251.
Train: 2018-08-01T00:36:44.397375: step 10769, loss 0.668922.
Train: 2018-08-01T00:36:44.553602: step 10770, loss 0.5625.
Test: 2018-08-01T00:36:45.037855: step 10770, loss 0.547719.
Train: 2018-08-01T00:36:45.194069: step 10771, loss 0.580109.
Train: 2018-08-01T00:36:45.350283: step 10772, loss 0.527309.
Train: 2018-08-01T00:36:45.506496: step 10773, loss 0.632604.
Train: 2018-08-01T00:36:45.662679: step 10774, loss 0.57992.
Train: 2018-08-01T00:36:45.834514: step 10775, loss 0.527565.
Train: 2018-08-01T00:36:45.990727: step 10776, loss 0.527639.
Train: 2018-08-01T00:36:46.162592: step 10777, loss 0.527692.
Train: 2018-08-01T00:36:46.318808: step 10778, loss 0.579751.
Train: 2018-08-01T00:36:46.475020: step 10779, loss 0.579727.
Train: 2018-08-01T00:36:46.631233: step 10780, loss 0.562403.
Test: 2018-08-01T00:36:47.099873: step 10780, loss 0.547935.
Train: 2018-08-01T00:36:47.256081: step 10781, loss 0.510575.
Train: 2018-08-01T00:36:47.412300: step 10782, loss 0.631474.
Train: 2018-08-01T00:36:47.568513: step 10783, loss 0.424446.
Train: 2018-08-01T00:36:47.724727: step 10784, loss 0.579657.
Train: 2018-08-01T00:36:47.896556: step 10785, loss 0.631461.
Train: 2018-08-01T00:36:48.083988: step 10786, loss 0.510638.
Train: 2018-08-01T00:36:48.240200: step 10787, loss 0.596912.
Train: 2018-08-01T00:36:48.396439: step 10788, loss 0.562399.
Train: 2018-08-01T00:36:48.552666: step 10789, loss 0.596884.
Train: 2018-08-01T00:36:48.708875: step 10790, loss 0.493487.
Test: 2018-08-01T00:36:49.177512: step 10790, loss 0.547968.
Train: 2018-08-01T00:36:49.333728: step 10791, loss 0.545166.
Train: 2018-08-01T00:36:49.489909: step 10792, loss 0.596878.
Train: 2018-08-01T00:36:49.646152: step 10793, loss 0.631348.
Train: 2018-08-01T00:36:49.802335: step 10794, loss 0.527962.
Train: 2018-08-01T00:36:49.974169: step 10795, loss 0.648436.
Train: 2018-08-01T00:36:50.114792: step 10796, loss 0.493689.
Train: 2018-08-01T00:36:50.286627: step 10797, loss 0.579562.
Train: 2018-08-01T00:36:50.427219: step 10798, loss 0.682465.
Train: 2018-08-01T00:36:50.599048: step 10799, loss 0.528178.
Train: 2018-08-01T00:36:50.755236: step 10800, loss 0.562398.
Test: 2018-08-01T00:36:51.223907: step 10800, loss 0.548121.
Train: 2018-08-01T00:36:51.911246: step 10801, loss 0.613555.
Train: 2018-08-01T00:36:52.067460: step 10802, loss 0.579417.
Train: 2018-08-01T00:36:52.223673: step 10803, loss 0.630314.
Train: 2018-08-01T00:36:52.395479: step 10804, loss 0.579341.
Train: 2018-08-01T00:36:52.567343: step 10805, loss 0.562426.
Train: 2018-08-01T00:36:52.723551: step 10806, loss 0.528774.
Train: 2018-08-01T00:36:52.895360: step 10807, loss 0.579246.
Train: 2018-08-01T00:36:53.051604: step 10808, loss 0.679855.
Train: 2018-08-01T00:36:53.207820: step 10809, loss 0.462183.
Train: 2018-08-01T00:36:53.364000: step 10810, loss 0.595863.
Test: 2018-08-01T00:36:53.832674: step 10810, loss 0.548535.
Train: 2018-08-01T00:36:54.004507: step 10811, loss 0.595817.
Train: 2018-08-01T00:36:54.145099: step 10812, loss 0.462712.
Train: 2018-08-01T00:36:54.316933: step 10813, loss 0.512607.
Train: 2018-08-01T00:36:54.473146: step 10814, loss 0.595789.
Train: 2018-08-01T00:36:54.629356: step 10815, loss 0.54584.
Train: 2018-08-01T00:36:54.785573: step 10816, loss 0.529158.
Train: 2018-08-01T00:36:54.941785: step 10817, loss 0.51242.
Train: 2018-08-01T00:36:55.097969: step 10818, loss 0.529026.
Train: 2018-08-01T00:36:55.254183: step 10819, loss 0.512166.
Train: 2018-08-01T00:36:55.410397: step 10820, loss 0.528809.
Test: 2018-08-01T00:36:55.879066: step 10820, loss 0.548297.
Train: 2018-08-01T00:36:56.035251: step 10821, loss 0.646792.
Train: 2018-08-01T00:36:56.191493: step 10822, loss 0.61313.
Train: 2018-08-01T00:36:56.347708: step 10823, loss 0.579335.
Train: 2018-08-01T00:36:56.503921: step 10824, loss 0.562416.
Train: 2018-08-01T00:36:56.660128: step 10825, loss 0.562414.
Train: 2018-08-01T00:36:56.847597: step 10826, loss 0.681029.
Train: 2018-08-01T00:36:56.988152: step 10827, loss 0.494727.
Train: 2018-08-01T00:36:57.160017: step 10828, loss 0.647021.
Train: 2018-08-01T00:36:57.316200: step 10829, loss 0.528626.
Train: 2018-08-01T00:36:57.472414: step 10830, loss 0.629971.
Test: 2018-08-01T00:36:57.956676: step 10830, loss 0.548311.
Train: 2018-08-01T00:36:58.097268: step 10831, loss 0.613009.
Train: 2018-08-01T00:36:58.269128: step 10832, loss 0.545615.
Train: 2018-08-01T00:36:58.425346: step 10833, loss 0.478467.
Train: 2018-08-01T00:36:58.581553: step 10834, loss 0.444882.
Train: 2018-08-01T00:36:58.737768: step 10835, loss 0.579264.
Train: 2018-08-01T00:36:58.893986: step 10836, loss 0.526479.
Train: 2018-08-01T00:36:59.065824: step 10837, loss 0.596196.
Train: 2018-08-01T00:36:59.222034: step 10838, loss 0.579327.
Train: 2018-08-01T00:36:59.362626: step 10839, loss 0.61319.
Train: 2018-08-01T00:36:59.518810: step 10840, loss 0.511636.
Test: 2018-08-01T00:37:00.003101: step 10840, loss 0.548226.
Train: 2018-08-01T00:37:00.174936: step 10841, loss 0.511585.
Train: 2018-08-01T00:37:00.331153: step 10842, loss 0.57938.
Train: 2018-08-01T00:37:00.487332: step 10843, loss 0.545412.
Train: 2018-08-01T00:37:00.643546: step 10844, loss 0.47731.
Train: 2018-08-01T00:37:00.799790: step 10845, loss 0.494143.
Train: 2018-08-01T00:37:00.956006: step 10846, loss 0.613766.
Train: 2018-08-01T00:37:01.112222: step 10847, loss 0.579559.
Train: 2018-08-01T00:37:01.299644: step 10848, loss 0.528007.
Train: 2018-08-01T00:37:01.455894: step 10849, loss 0.596861.
Train: 2018-08-01T00:37:01.612069: step 10850, loss 0.527887.
Test: 2018-08-01T00:37:02.080710: step 10850, loss 0.547926.
Train: 2018-08-01T00:37:02.252576: step 10851, loss 0.510542.
Train: 2018-08-01T00:37:02.424378: step 10852, loss 0.579734.
Train: 2018-08-01T00:37:02.580593: step 10853, loss 0.649204.
Train: 2018-08-01T00:37:02.736836: step 10854, loss 0.64923.
Train: 2018-08-01T00:37:02.893049: step 10855, loss 0.597098.
Train: 2018-08-01T00:37:03.049263: step 10856, loss 0.597041.
Train: 2018-08-01T00:37:03.205446: step 10857, loss 0.493264.
Train: 2018-08-01T00:37:03.361660: step 10858, loss 0.493313.
Train: 2018-08-01T00:37:03.517874: step 10859, loss 0.579679.
Train: 2018-08-01T00:37:03.674117: step 10860, loss 0.493286.
Test: 2018-08-01T00:37:04.158378: step 10860, loss 0.547919.
Train: 2018-08-01T00:37:04.314595: step 10861, loss 0.493214.
Train: 2018-08-01T00:37:04.486399: step 10862, loss 0.527744.
Train: 2018-08-01T00:37:04.642610: step 10863, loss 0.527672.
Train: 2018-08-01T00:37:04.798853: step 10864, loss 0.649491.
Train: 2018-08-01T00:37:04.955038: step 10865, loss 0.579854.
Train: 2018-08-01T00:37:05.111280: step 10866, loss 0.457796.
Train: 2018-08-01T00:37:05.267493: step 10867, loss 0.527489.
Train: 2018-08-01T00:37:05.423676: step 10868, loss 0.544933.
Train: 2018-08-01T00:37:05.579890: step 10869, loss 0.632649.
Train: 2018-08-01T00:37:05.751724: step 10870, loss 0.597586.
Test: 2018-08-01T00:37:06.220395: step 10870, loss 0.54775.
Train: 2018-08-01T00:37:06.376609: step 10871, loss 0.615158.
Train: 2018-08-01T00:37:06.532823: step 10872, loss 0.474687.
Train: 2018-08-01T00:37:06.704652: step 10873, loss 0.492204.
Train: 2018-08-01T00:37:06.860876: step 10874, loss 0.632825.
Train: 2018-08-01T00:37:07.017053: step 10875, loss 0.527282.
Train: 2018-08-01T00:37:07.173297: step 10876, loss 0.597679.
Train: 2018-08-01T00:37:07.345102: step 10877, loss 0.562472.
Train: 2018-08-01T00:37:07.485724: step 10878, loss 0.632872.
Train: 2018-08-01T00:37:07.657559: step 10879, loss 0.509728.
Train: 2018-08-01T00:37:07.813768: step 10880, loss 0.474605.
Test: 2018-08-01T00:37:08.282383: step 10880, loss 0.54774.
Train: 2018-08-01T00:37:08.438626: step 10881, loss 0.54488.
Train: 2018-08-01T00:37:08.594809: step 10882, loss 0.527268.
Train: 2018-08-01T00:37:08.751023: step 10883, loss 0.580102.
Train: 2018-08-01T00:37:08.922888: step 10884, loss 0.597758.
Train: 2018-08-01T00:37:09.079104: step 10885, loss 0.615401.
Train: 2018-08-01T00:37:09.235309: step 10886, loss 0.597729.
Train: 2018-08-01T00:37:09.391534: step 10887, loss 0.509666.
Train: 2018-08-01T00:37:09.547736: step 10888, loss 0.527282.
Train: 2018-08-01T00:37:09.703957: step 10889, loss 0.562468.
Train: 2018-08-01T00:37:09.860138: step 10890, loss 0.562468.
Test: 2018-08-01T00:37:10.344429: step 10890, loss 0.547739.
Train: 2018-08-01T00:37:10.500614: step 10891, loss 0.632817.
Train: 2018-08-01T00:37:10.656857: step 10892, loss 0.544894.
Train: 2018-08-01T00:37:10.813069: step 10893, loss 0.59755.
Train: 2018-08-01T00:37:10.969283: step 10894, loss 0.685103.
Train: 2018-08-01T00:37:11.141088: step 10895, loss 0.667229.
Train: 2018-08-01T00:37:11.281707: step 10896, loss 0.579803.
Train: 2018-08-01T00:37:11.437924: step 10897, loss 0.700893.
Train: 2018-08-01T00:37:11.594137: step 10898, loss 0.63122.
Train: 2018-08-01T00:37:11.750351: step 10899, loss 0.613676.
Train: 2018-08-01T00:37:11.906564: step 10900, loss 0.613342.
Test: 2018-08-01T00:37:12.390826: step 10900, loss 0.548309.
Train: 2018-08-01T00:37:13.062543: step 10901, loss 0.663598.
Train: 2018-08-01T00:37:13.234349: step 10902, loss 0.579196.
Train: 2018-08-01T00:37:13.406183: step 10903, loss 0.645561.
Train: 2018-08-01T00:37:13.562421: step 10904, loss 0.529611.
Train: 2018-08-01T00:37:13.718639: step 10905, loss 0.579007.
Train: 2018-08-01T00:37:13.874824: step 10906, loss 0.465018.
Train: 2018-08-01T00:37:14.031036: step 10907, loss 0.643849.
Train: 2018-08-01T00:37:14.187279: step 10908, loss 0.611246.
Train: 2018-08-01T00:37:14.343465: step 10909, loss 0.546766.
Train: 2018-08-01T00:37:14.515297: step 10910, loss 0.482784.
Test: 2018-08-01T00:37:14.983968: step 10910, loss 0.549522.
Train: 2018-08-01T00:37:15.140182: step 10911, loss 0.546921.
Train: 2018-08-01T00:37:15.296395: step 10912, loss 0.498998.
Train: 2018-08-01T00:37:15.483822: step 10913, loss 0.594908.
Train: 2018-08-01T00:37:15.640034: step 10914, loss 0.498932.
Train: 2018-08-01T00:37:15.796278: step 10915, loss 0.626985.
Train: 2018-08-01T00:37:15.968083: step 10916, loss 0.578919.
Train: 2018-08-01T00:37:16.124326: step 10917, loss 0.659113.
Train: 2018-08-01T00:37:16.280509: step 10918, loss 0.498807.
Train: 2018-08-01T00:37:16.436756: step 10919, loss 0.53083.
Train: 2018-08-01T00:37:16.608558: step 10920, loss 0.530774.
Test: 2018-08-01T00:37:17.077231: step 10920, loss 0.549381.
Train: 2018-08-01T00:37:17.233441: step 10921, loss 0.562846.
Train: 2018-08-01T00:37:17.389625: step 10922, loss 0.3856.
Train: 2018-08-01T00:37:17.545837: step 10923, loss 0.546565.
Train: 2018-08-01T00:37:17.717673: step 10924, loss 0.546426.
Train: 2018-08-01T00:37:17.858296: step 10925, loss 0.497233.
Train: 2018-08-01T00:37:18.030099: step 10926, loss 0.496806.
Train: 2018-08-01T00:37:18.186313: step 10927, loss 0.612189.
Train: 2018-08-01T00:37:18.342557: step 10928, loss 0.529236.
Train: 2018-08-01T00:37:18.498770: step 10929, loss 0.612624.
Train: 2018-08-01T00:37:18.654978: step 10930, loss 0.596014.
Test: 2018-08-01T00:37:19.123623: step 10930, loss 0.54834.
Train: 2018-08-01T00:37:19.295459: step 10931, loss 0.562436.
Train: 2018-08-01T00:37:19.436020: step 10932, loss 0.596184.
Train: 2018-08-01T00:37:19.592258: step 10933, loss 0.646985.
Train: 2018-08-01T00:37:19.764068: step 10934, loss 0.528572.
Train: 2018-08-01T00:37:19.920283: step 10935, loss 0.545474.
Train: 2018-08-01T00:37:20.076529: step 10936, loss 0.681139.
Train: 2018-08-01T00:37:20.232708: step 10937, loss 0.460715.
Train: 2018-08-01T00:37:20.388952: step 10938, loss 0.596343.
Train: 2018-08-01T00:37:20.545135: step 10939, loss 0.61333.
Train: 2018-08-01T00:37:20.685758: step 10940, loss 0.630279.
Test: 2018-08-01T00:37:21.169989: step 10940, loss 0.548224.
Train: 2018-08-01T00:37:21.326236: step 10941, loss 0.647134.
Train: 2018-08-01T00:37:21.482447: step 10942, loss 0.494813.
Train: 2018-08-01T00:37:21.638629: step 10943, loss 0.545542.
Train: 2018-08-01T00:37:21.794873: step 10944, loss 0.66365.
Train: 2018-08-01T00:37:21.951090: step 10945, loss 0.478267.
Train: 2018-08-01T00:37:22.122891: step 10946, loss 0.495141.
Train: 2018-08-01T00:37:22.279104: step 10947, loss 0.646609.
Train: 2018-08-01T00:37:22.435343: step 10948, loss 0.51197.
Train: 2018-08-01T00:37:22.622774: step 10949, loss 0.612918.
Train: 2018-08-01T00:37:22.779019: step 10950, loss 0.511985.
Test: 2018-08-01T00:37:23.263279: step 10950, loss 0.548349.
Train: 2018-08-01T00:37:23.419463: step 10951, loss 0.562438.
Train: 2018-08-01T00:37:23.575676: step 10952, loss 0.562436.
Train: 2018-08-01T00:37:23.747513: step 10953, loss 0.562434.
Train: 2018-08-01T00:37:23.903754: step 10954, loss 0.478194.
Train: 2018-08-01T00:37:24.059970: step 10955, loss 0.528669.
Train: 2018-08-01T00:37:24.216153: step 10956, loss 0.646997.
Train: 2018-08-01T00:37:24.388010: step 10957, loss 0.545487.
Train: 2018-08-01T00:37:24.544230: step 10958, loss 0.51158.
Train: 2018-08-01T00:37:24.700413: step 10959, loss 0.681221.
Train: 2018-08-01T00:37:24.856656: step 10960, loss 0.443631.
Test: 2018-08-01T00:37:25.325301: step 10960, loss 0.548173.
Train: 2018-08-01T00:37:25.481510: step 10961, loss 0.545409.
Train: 2018-08-01T00:37:25.637723: step 10962, loss 0.52835.
Train: 2018-08-01T00:37:25.793937: step 10963, loss 0.511212.
Train: 2018-08-01T00:37:25.950153: step 10964, loss 0.613722.
Train: 2018-08-01T00:37:26.106333: step 10965, loss 0.47671.
Train: 2018-08-01T00:37:26.278168: step 10966, loss 0.596766.
Train: 2018-08-01T00:37:26.434431: step 10967, loss 0.493519.
Train: 2018-08-01T00:37:26.590631: step 10968, loss 0.545132.
Train: 2018-08-01T00:37:26.746839: step 10969, loss 0.562405.
Train: 2018-08-01T00:37:26.903021: step 10970, loss 0.614486.
Test: 2018-08-01T00:37:27.387284: step 10970, loss 0.547859.
Train: 2018-08-01T00:37:27.559145: step 10971, loss 0.631944.
Train: 2018-08-01T00:37:27.715356: step 10972, loss 0.631957.
Train: 2018-08-01T00:37:27.871544: step 10973, loss 0.562413.
Train: 2018-08-01T00:37:28.027789: step 10974, loss 0.579765.
Train: 2018-08-01T00:37:28.184002: step 10975, loss 0.493066.
Train: 2018-08-01T00:37:28.340216: step 10976, loss 0.562408.
Train: 2018-08-01T00:37:28.496430: step 10977, loss 0.493065.
Train: 2018-08-01T00:37:28.668234: step 10978, loss 0.527705.
Train: 2018-08-01T00:37:28.824446: step 10979, loss 0.440779.
Train: 2018-08-01T00:37:28.980660: step 10980, loss 0.579852.
Test: 2018-08-01T00:37:29.464952: step 10980, loss 0.547804.
Train: 2018-08-01T00:37:29.605515: step 10981, loss 0.66725.
Train: 2018-08-01T00:37:29.777374: step 10982, loss 0.49252.
Train: 2018-08-01T00:37:29.933595: step 10983, loss 0.579945.
Train: 2018-08-01T00:37:30.089807: step 10984, loss 0.474842.
Train: 2018-08-01T00:37:30.246013: step 10985, loss 0.5449.
Train: 2018-08-01T00:37:30.402233: step 10986, loss 0.544875.
Train: 2018-08-01T00:37:30.558415: step 10987, loss 0.491968.
Train: 2018-08-01T00:37:30.714654: step 10988, loss 0.491784.
Train: 2018-08-01T00:37:30.886495: step 10989, loss 0.473689.
Train: 2018-08-01T00:37:31.042677: step 10990, loss 0.562509.
Test: 2018-08-01T00:37:31.495726: step 10990, loss 0.547577.
Train: 2018-08-01T00:37:31.651940: step 10991, loss 0.453668.
Train: 2018-08-01T00:37:31.823778: step 10992, loss 0.61904.
Train: 2018-08-01T00:37:31.995615: step 10993, loss 0.546007.
Train: 2018-08-01T00:37:32.136196: step 10994, loss 0.59945.
Train: 2018-08-01T00:37:32.292409: step 10995, loss 0.599691.
Train: 2018-08-01T00:37:32.464255: step 10996, loss 0.599219.
Train: 2018-08-01T00:37:32.604842: step 10997, loss 0.654012.
Train: 2018-08-01T00:37:32.761056: step 10998, loss 0.617244.
Train: 2018-08-01T00:37:32.932892: step 10999, loss 0.580744.
Train: 2018-08-01T00:37:33.089109: step 11000, loss 0.598678.
Test: 2018-08-01T00:37:33.573368: step 11000, loss 0.547611.
Train: 2018-08-01T00:37:34.276295: step 11001, loss 0.562644.
Train: 2018-08-01T00:37:34.432542: step 11002, loss 0.526809.
Train: 2018-08-01T00:37:34.588721: step 11003, loss 0.47326.
Train: 2018-08-01T00:37:34.744935: step 11004, loss 0.634014.
Train: 2018-08-01T00:37:34.901148: step 11005, loss 0.491287.
Train: 2018-08-01T00:37:35.057391: step 11006, loss 0.598191.
Train: 2018-08-01T00:37:35.213576: step 11007, loss 0.651415.
Train: 2018-08-01T00:37:35.385410: step 11008, loss 0.686148.
Train: 2018-08-01T00:37:35.526032: step 11009, loss 0.459939.
Train: 2018-08-01T00:37:35.682250: step 11010, loss 0.510155.
Test: 2018-08-01T00:37:36.166508: step 11010, loss 0.54779.
Train: 2018-08-01T00:37:36.338312: step 11011, loss 0.632612.
Train: 2018-08-01T00:37:36.494525: step 11012, loss 0.527359.
Train: 2018-08-01T00:37:36.650739: step 11013, loss 0.457305.
Train: 2018-08-01T00:37:36.806982: step 11014, loss 0.738601.
Train: 2018-08-01T00:37:36.963190: step 11015, loss 0.614999.
Train: 2018-08-01T00:37:37.119404: step 11016, loss 0.562491.
Train: 2018-08-01T00:37:37.275594: step 11017, loss 0.510351.
Train: 2018-08-01T00:37:37.447428: step 11018, loss 0.614679.
Train: 2018-08-01T00:37:37.603641: step 11019, loss 0.666297.
Train: 2018-08-01T00:37:37.759854: step 11020, loss 0.579725.
Test: 2018-08-01T00:37:38.228494: step 11020, loss 0.548116.
Train: 2018-08-01T00:37:38.384708: step 11021, loss 0.562515.
Train: 2018-08-01T00:37:38.540922: step 11022, loss 0.425623.
Train: 2018-08-01T00:37:38.697135: step 11023, loss 0.579595.
Train: 2018-08-01T00:37:38.853348: step 11024, loss 0.613802.
Train: 2018-08-01T00:37:39.009562: step 11025, loss 0.545473.
Train: 2018-08-01T00:37:39.165806: step 11026, loss 0.596529.
Train: 2018-08-01T00:37:39.337640: step 11027, loss 0.545518.
Train: 2018-08-01T00:37:39.493854: step 11028, loss 0.545214.
Train: 2018-08-01T00:37:39.650069: step 11029, loss 0.562803.
Train: 2018-08-01T00:37:39.806250: step 11030, loss 0.527435.
Test: 2018-08-01T00:37:40.274920: step 11030, loss 0.548865.
Train: 2018-08-01T00:37:40.446726: step 11031, loss 0.565363.
Train: 2018-08-01T00:37:40.602969: step 11032, loss 0.56264.
Train: 2018-08-01T00:37:40.759183: step 11033, loss 0.510884.
Train: 2018-08-01T00:37:40.915396: step 11034, loss 0.566535.
Train: 2018-08-01T00:37:41.071579: step 11035, loss 0.529071.
Train: 2018-08-01T00:37:41.227792: step 11036, loss 0.512002.
Train: 2018-08-01T00:37:41.384030: step 11037, loss 0.49478.
Train: 2018-08-01T00:37:41.540219: step 11038, loss 0.511741.
Train: 2018-08-01T00:37:41.696433: step 11039, loss 0.477071.
Train: 2018-08-01T00:37:41.868303: step 11040, loss 0.598005.
Test: 2018-08-01T00:37:42.336937: step 11040, loss 0.548537.
Train: 2018-08-01T00:37:42.508767: step 11041, loss 0.476509.
Train: 2018-08-01T00:37:42.664955: step 11042, loss 0.597819.
Train: 2018-08-01T00:37:42.821169: step 11043, loss 0.528352.
Train: 2018-08-01T00:37:42.993003: step 11044, loss 0.598186.
Train: 2018-08-01T00:37:43.133626: step 11045, loss 0.68576.
Train: 2018-08-01T00:37:43.289810: step 11046, loss 0.651276.
Train: 2018-08-01T00:37:43.446056: step 11047, loss 0.632752.
Train: 2018-08-01T00:37:43.617888: step 11048, loss 0.562207.
Train: 2018-08-01T00:37:43.774102: step 11049, loss 0.667393.
Train: 2018-08-01T00:37:43.930318: step 11050, loss 0.544764.
Test: 2018-08-01T00:37:44.398949: step 11050, loss 0.548793.
Train: 2018-08-01T00:37:44.539516: step 11051, loss 0.617663.
Train: 2018-08-01T00:37:44.711351: step 11052, loss 0.603465.
Train: 2018-08-01T00:37:44.851944: step 11053, loss 0.495594.
Train: 2018-08-01T00:37:45.023779: step 11054, loss 0.581806.
Train: 2018-08-01T00:37:45.195614: step 11055, loss 0.477289.
Train: 2018-08-01T00:37:45.351827: step 11056, loss 0.597431.
Train: 2018-08-01T00:37:45.508070: step 11057, loss 0.426947.
Train: 2018-08-01T00:37:45.664254: step 11058, loss 0.59674.
Train: 2018-08-01T00:37:45.820500: step 11059, loss 0.649525.
Train: 2018-08-01T00:37:45.992332: step 11060, loss 0.49632.
Test: 2018-08-01T00:37:46.476593: step 11060, loss 0.548852.
Train: 2018-08-01T00:37:46.632807: step 11061, loss 0.514758.
Train: 2018-08-01T00:37:46.804644: step 11062, loss 0.547073.
Train: 2018-08-01T00:37:46.945237: step 11063, loss 0.530373.
Train: 2018-08-01T00:37:47.101416: step 11064, loss 0.634137.
Train: 2018-08-01T00:37:47.273279: step 11065, loss 0.52939.
Train: 2018-08-01T00:37:47.429465: step 11066, loss 0.512597.
Train: 2018-08-01T00:37:47.585709: step 11067, loss 0.545171.
Train: 2018-08-01T00:37:47.741919: step 11068, loss 0.595057.
Train: 2018-08-01T00:37:47.898129: step 11069, loss 0.467264.
Train: 2018-08-01T00:37:48.054319: step 11070, loss 0.597013.
Test: 2018-08-01T00:37:48.538611: step 11070, loss 0.550991.
Train: 2018-08-01T00:37:48.694793: step 11071, loss 0.611983.
Train: 2018-08-01T00:37:48.851038: step 11072, loss 0.448385.
Train: 2018-08-01T00:37:49.007220: step 11073, loss 0.582149.
Train: 2018-08-01T00:37:49.163464: step 11074, loss 0.477833.
Train: 2018-08-01T00:37:49.319681: step 11075, loss 0.473768.
Train: 2018-08-01T00:37:49.475862: step 11076, loss 0.601713.
Train: 2018-08-01T00:37:49.632104: step 11077, loss 0.524645.
Train: 2018-08-01T00:37:49.772667: step 11078, loss 0.493343.
Train: 2018-08-01T00:37:49.928913: step 11079, loss 0.494763.
Train: 2018-08-01T00:37:50.100741: step 11080, loss 0.486456.
Test: 2018-08-01T00:37:50.569380: step 11080, loss 0.549613.
Train: 2018-08-01T00:37:50.725569: step 11081, loss 0.528987.
Train: 2018-08-01T00:37:50.897434: step 11082, loss 0.521132.
Train: 2018-08-01T00:37:51.053646: step 11083, loss 0.613374.
Train: 2018-08-01T00:37:51.209860: step 11084, loss 0.449317.
Train: 2018-08-01T00:37:51.366073: step 11085, loss 0.613961.
Train: 2018-08-01T00:37:51.522289: step 11086, loss 0.638062.
Train: 2018-08-01T00:37:51.694125: step 11087, loss 0.547576.
Train: 2018-08-01T00:37:51.850305: step 11088, loss 0.658852.
Train: 2018-08-01T00:37:52.006544: step 11089, loss 0.46428.
Train: 2018-08-01T00:37:52.162732: step 11090, loss 0.566524.
Test: 2018-08-01T00:37:52.631401: step 11090, loss 0.549702.
Train: 2018-08-01T00:37:52.818827: step 11091, loss 0.648648.
Train: 2018-08-01T00:37:52.975041: step 11092, loss 0.587868.
Train: 2018-08-01T00:37:53.131286: step 11093, loss 0.567296.
Train: 2018-08-01T00:37:53.287469: step 11094, loss 0.600512.
Train: 2018-08-01T00:37:53.443720: step 11095, loss 0.535926.
Train: 2018-08-01T00:37:53.599926: step 11096, loss 0.681898.
Train: 2018-08-01T00:37:53.756139: step 11097, loss 0.54484.
Train: 2018-08-01T00:37:53.927976: step 11098, loss 0.530991.
Train: 2018-08-01T00:37:54.084156: step 11099, loss 0.536783.
Train: 2018-08-01T00:37:54.240370: step 11100, loss 0.61859.
Test: 2018-08-01T00:37:54.724661: step 11100, loss 0.552009.
Train: 2018-08-01T00:37:55.396349: step 11101, loss 0.568529.
Train: 2018-08-01T00:37:55.552564: step 11102, loss 0.577713.
Train: 2018-08-01T00:37:55.708807: step 11103, loss 0.592649.
Train: 2018-08-01T00:37:55.880610: step 11104, loss 0.522763.
Train: 2018-08-01T00:37:56.036851: step 11105, loss 0.644253.
Train: 2018-08-01T00:37:56.193077: step 11106, loss 0.630834.
Train: 2018-08-01T00:37:56.349281: step 11107, loss 0.469916.
Train: 2018-08-01T00:37:56.505496: step 11108, loss 0.543761.
Train: 2018-08-01T00:37:56.677329: step 11109, loss 0.569247.
Train: 2018-08-01T00:37:56.833543: step 11110, loss 0.611459.
Test: 2018-08-01T00:37:57.302183: step 11110, loss 0.549605.
Train: 2018-08-01T00:37:57.458396: step 11111, loss 0.619468.
Train: 2018-08-01T00:37:57.614605: step 11112, loss 0.620616.
Train: 2018-08-01T00:37:57.770794: step 11113, loss 0.515629.
Train: 2018-08-01T00:37:57.927040: step 11114, loss 0.580089.
Train: 2018-08-01T00:37:58.083251: step 11115, loss 0.651373.
Train: 2018-08-01T00:37:58.255056: step 11116, loss 0.564643.
Train: 2018-08-01T00:37:58.395647: step 11117, loss 0.597164.
Train: 2018-08-01T00:37:58.551891: step 11118, loss 0.45911.
Train: 2018-08-01T00:37:58.708104: step 11119, loss 0.598403.
Train: 2018-08-01T00:37:58.879908: step 11120, loss 0.530596.
Test: 2018-08-01T00:37:59.364185: step 11120, loss 0.549463.
Train: 2018-08-01T00:37:59.520414: step 11121, loss 0.564416.
Train: 2018-08-01T00:37:59.676628: step 11122, loss 0.598897.
Train: 2018-08-01T00:37:59.832844: step 11123, loss 0.476952.
Train: 2018-08-01T00:37:59.989054: step 11124, loss 0.690606.
Train: 2018-08-01T00:38:00.145262: step 11125, loss 0.54743.
Train: 2018-08-01T00:38:00.301483: step 11126, loss 0.49478.
Train: 2018-08-01T00:38:00.473311: step 11127, loss 0.494383.
Train: 2018-08-01T00:38:00.629523: step 11128, loss 0.61604.
Train: 2018-08-01T00:38:00.785713: step 11129, loss 0.633336.
Train: 2018-08-01T00:38:00.941927: step 11130, loss 0.511932.
Test: 2018-08-01T00:38:01.410597: step 11130, loss 0.54942.
Train: 2018-08-01T00:38:01.582440: step 11131, loss 0.615922.
Train: 2018-08-01T00:38:01.738645: step 11132, loss 0.563825.
Train: 2018-08-01T00:38:01.894858: step 11133, loss 0.562776.
Train: 2018-08-01T00:38:02.051072: step 11134, loss 0.575043.
Train: 2018-08-01T00:38:02.207254: step 11135, loss 0.499722.
Train: 2018-08-01T00:38:02.363468: step 11136, loss 0.569084.
Train: 2018-08-01T00:38:02.519681: step 11137, loss 0.635267.
Train: 2018-08-01T00:38:02.691516: step 11138, loss 0.521828.
Train: 2018-08-01T00:38:02.847755: step 11139, loss 0.591655.
Train: 2018-08-01T00:38:03.003942: step 11140, loss 0.582659.
Test: 2018-08-01T00:38:03.472583: step 11140, loss 0.549786.
Train: 2018-08-01T00:38:03.628797: step 11141, loss 0.563705.
Train: 2018-08-01T00:38:03.816286: step 11142, loss 0.447387.
Train: 2018-08-01T00:38:03.972496: step 11143, loss 0.52827.
Train: 2018-08-01T00:38:04.128716: step 11144, loss 0.666293.
Train: 2018-08-01T00:38:04.300547: step 11145, loss 0.529511.
Train: 2018-08-01T00:38:04.456757: step 11146, loss 0.58111.
Train: 2018-08-01T00:38:04.612971: step 11147, loss 0.579768.
Train: 2018-08-01T00:38:04.784809: step 11148, loss 0.47652.
Train: 2018-08-01T00:38:04.956636: step 11149, loss 0.616493.
Train: 2018-08-01T00:38:05.112825: step 11150, loss 0.476249.
Test: 2018-08-01T00:38:05.581494: step 11150, loss 0.549224.
Train: 2018-08-01T00:38:05.737708: step 11151, loss 0.564741.
Train: 2018-08-01T00:38:05.909537: step 11152, loss 0.49432.
Train: 2018-08-01T00:38:06.065751: step 11153, loss 0.476097.
Train: 2018-08-01T00:38:06.221973: step 11154, loss 0.598603.
Train: 2018-08-01T00:38:06.378183: step 11155, loss 0.582728.
Train: 2018-08-01T00:38:06.534366: step 11156, loss 0.706044.
Train: 2018-08-01T00:38:06.690613: step 11157, loss 0.564075.
Train: 2018-08-01T00:38:06.862415: step 11158, loss 0.582365.
Train: 2018-08-01T00:38:07.034250: step 11159, loss 0.510229.
Train: 2018-08-01T00:38:07.174841: step 11160, loss 0.546317.
Test: 2018-08-01T00:38:07.643512: step 11160, loss 0.54903.
Train: 2018-08-01T00:38:07.799725: step 11161, loss 0.598977.
Train: 2018-08-01T00:38:07.955909: step 11162, loss 0.58013.
Train: 2018-08-01T00:38:08.143390: step 11163, loss 0.545933.
Train: 2018-08-01T00:38:08.299578: step 11164, loss 0.599539.
Train: 2018-08-01T00:38:08.455821: step 11165, loss 0.512163.
Train: 2018-08-01T00:38:08.612004: step 11166, loss 0.529609.
Train: 2018-08-01T00:38:08.768218: step 11167, loss 0.510455.
Train: 2018-08-01T00:38:08.924431: step 11168, loss 0.528554.
Train: 2018-08-01T00:38:09.096266: step 11169, loss 0.721856.
Train: 2018-08-01T00:38:09.268100: step 11170, loss 0.546112.
Test: 2018-08-01T00:38:09.736771: step 11170, loss 0.548986.
Train: 2018-08-01T00:38:09.908576: step 11171, loss 0.493558.
Train: 2018-08-01T00:38:10.064790: step 11172, loss 0.599264.
Train: 2018-08-01T00:38:10.221004: step 11173, loss 0.59878.
Train: 2018-08-01T00:38:10.408458: step 11174, loss 0.529259.
Train: 2018-08-01T00:38:10.549052: step 11175, loss 0.615936.
Train: 2018-08-01T00:38:10.705265: step 11176, loss 0.633712.
Train: 2018-08-01T00:38:10.861508: step 11177, loss 0.546482.
Train: 2018-08-01T00:38:11.017722: step 11178, loss 0.492397.
Train: 2018-08-01T00:38:11.189526: step 11179, loss 0.564012.
Train: 2018-08-01T00:38:11.361387: step 11180, loss 0.528675.
Test: 2018-08-01T00:38:11.830000: step 11180, loss 0.548876.
Train: 2018-08-01T00:38:11.986244: step 11181, loss 0.547459.
Train: 2018-08-01T00:38:12.142458: step 11182, loss 0.597783.
Train: 2018-08-01T00:38:12.298671: step 11183, loss 0.545481.
Train: 2018-08-01T00:38:12.454856: step 11184, loss 0.528423.
Train: 2018-08-01T00:38:12.626714: step 11185, loss 0.52921.
Train: 2018-08-01T00:38:12.782904: step 11186, loss 0.581679.
Train: 2018-08-01T00:38:12.954768: step 11187, loss 0.580069.
Train: 2018-08-01T00:38:13.110951: step 11188, loss 0.528366.
Train: 2018-08-01T00:38:13.267166: step 11189, loss 0.477111.
Train: 2018-08-01T00:38:13.423410: step 11190, loss 0.56356.
Test: 2018-08-01T00:38:13.907670: step 11190, loss 0.548838.
Train: 2018-08-01T00:38:14.063886: step 11191, loss 0.562717.
Train: 2018-08-01T00:38:14.220066: step 11192, loss 0.476954.
Train: 2018-08-01T00:38:14.376279: step 11193, loss 0.528736.
Train: 2018-08-01T00:38:14.548115: step 11194, loss 0.493428.
Train: 2018-08-01T00:38:14.719949: step 11195, loss 0.528625.
Train: 2018-08-01T00:38:14.923051: step 11196, loss 0.49466.
Train: 2018-08-01T00:38:15.079271: step 11197, loss 0.423404.
Train: 2018-08-01T00:38:15.235484: step 11198, loss 0.510088.
Train: 2018-08-01T00:38:15.407327: step 11199, loss 0.527591.
Train: 2018-08-01T00:38:15.563536: step 11200, loss 0.635763.
Test: 2018-08-01T00:38:16.032167: step 11200, loss 0.548526.
Train: 2018-08-01T00:38:16.703891: step 11201, loss 0.563484.
Train: 2018-08-01T00:38:16.875720: step 11202, loss 0.636543.
Train: 2018-08-01T00:38:17.031909: step 11203, loss 0.582038.
Train: 2018-08-01T00:38:17.188121: step 11204, loss 0.454383.
Train: 2018-08-01T00:38:17.359986: step 11205, loss 0.746367.
Train: 2018-08-01T00:38:17.516169: step 11206, loss 0.527268.
Train: 2018-08-01T00:38:17.672413: step 11207, loss 0.600236.
Train: 2018-08-01T00:38:17.828628: step 11208, loss 0.490867.
Train: 2018-08-01T00:38:17.984846: step 11209, loss 0.60013.
Train: 2018-08-01T00:38:18.156683: step 11210, loss 0.618295.
Test: 2018-08-01T00:38:18.625285: step 11210, loss 0.548408.
Train: 2018-08-01T00:38:18.781498: step 11211, loss 0.490891.
Train: 2018-08-01T00:38:18.937744: step 11212, loss 0.61812.
Train: 2018-08-01T00:38:19.109546: step 11213, loss 0.454769.
Train: 2018-08-01T00:38:19.265796: step 11214, loss 0.509168.
Train: 2018-08-01T00:38:19.422003: step 11215, loss 0.599845.
Train: 2018-08-01T00:38:19.578217: step 11216, loss 0.509141.
Train: 2018-08-01T00:38:19.750046: step 11217, loss 0.58168.
Train: 2018-08-01T00:38:19.906264: step 11218, loss 0.545353.
Train: 2018-08-01T00:38:20.062481: step 11219, loss 0.527222.
Train: 2018-08-01T00:38:20.234308: step 11220, loss 0.527237.
Test: 2018-08-01T00:38:20.702953: step 11220, loss 0.548307.
Train: 2018-08-01T00:38:20.874782: step 11221, loss 0.527201.
Train: 2018-08-01T00:38:21.031001: step 11222, loss 0.636117.
Train: 2018-08-01T00:38:21.187218: step 11223, loss 0.599802.
Train: 2018-08-01T00:38:21.359044: step 11224, loss 0.672234.
Train: 2018-08-01T00:38:21.530884: step 11225, loss 0.599801.
Train: 2018-08-01T00:38:21.687069: step 11226, loss 0.545298.
Train: 2018-08-01T00:38:21.843312: step 11227, loss 0.437336.
Train: 2018-08-01T00:38:21.999494: step 11228, loss 0.617254.
Train: 2018-08-01T00:38:22.155708: step 11229, loss 0.509437.
Train: 2018-08-01T00:38:22.327569: step 11230, loss 0.50948.
Test: 2018-08-01T00:38:22.811805: step 11230, loss 0.548263.
Train: 2018-08-01T00:38:22.968048: step 11231, loss 0.509396.
Train: 2018-08-01T00:38:23.124262: step 11232, loss 0.473626.
Train: 2018-08-01T00:38:23.280469: step 11233, loss 0.617209.
Train: 2018-08-01T00:38:23.452279: step 11234, loss 0.491507.
Train: 2018-08-01T00:38:23.608493: step 11235, loss 0.563167.
Train: 2018-08-01T00:38:23.764706: step 11236, loss 0.509197.
Train: 2018-08-01T00:38:23.905329: step 11237, loss 0.437014.
Train: 2018-08-01T00:38:24.061545: step 11238, loss 0.708535.
Train: 2018-08-01T00:38:24.217756: step 11239, loss 0.690045.
Train: 2018-08-01T00:38:24.373969: step 11240, loss 0.581387.
Test: 2018-08-01T00:38:24.858230: step 11240, loss 0.548183.
Train: 2018-08-01T00:38:25.014414: step 11241, loss 0.581486.
Train: 2018-08-01T00:38:25.170660: step 11242, loss 0.599216.
Train: 2018-08-01T00:38:25.326865: step 11243, loss 0.688796.
Train: 2018-08-01T00:38:25.483054: step 11244, loss 0.509591.
Train: 2018-08-01T00:38:25.654889: step 11245, loss 0.598759.
Train: 2018-08-01T00:38:25.811127: step 11246, loss 0.616334.
Train: 2018-08-01T00:38:25.967315: step 11247, loss 0.52768.
Train: 2018-08-01T00:38:26.123559: step 11248, loss 0.598275.
Train: 2018-08-01T00:38:26.279773: step 11249, loss 0.457626.
Train: 2018-08-01T00:38:26.435989: step 11250, loss 0.545449.
Test: 2018-08-01T00:38:26.904626: step 11250, loss 0.548334.
Train: 2018-08-01T00:38:27.060834: step 11251, loss 0.475428.
Train: 2018-08-01T00:38:27.232675: step 11252, loss 0.598019.
Train: 2018-08-01T00:38:27.388887: step 11253, loss 0.54548.
Train: 2018-08-01T00:38:27.545071: step 11254, loss 0.65049.
Train: 2018-08-01T00:38:27.701315: step 11255, loss 0.597903.
Train: 2018-08-01T00:38:27.873155: step 11256, loss 0.580381.
Train: 2018-08-01T00:38:28.029363: step 11257, loss 0.580328.
Train: 2018-08-01T00:38:28.185571: step 11258, loss 0.615005.
Train: 2018-08-01T00:38:28.357381: step 11259, loss 0.562879.
Train: 2018-08-01T00:38:28.498003: step 11260, loss 0.631946.
Test: 2018-08-01T00:38:28.982235: step 11260, loss 0.54849.
Train: 2018-08-01T00:38:29.138478: step 11261, loss 0.494074.
Train: 2018-08-01T00:38:29.294662: step 11262, loss 0.528548.
Train: 2018-08-01T00:38:29.450899: step 11263, loss 0.54574.
Train: 2018-08-01T00:38:29.607118: step 11264, loss 0.528622.
Train: 2018-08-01T00:38:29.763331: step 11265, loss 0.614239.
Train: 2018-08-01T00:38:29.919515: step 11266, loss 0.614213.
Train: 2018-08-01T00:38:30.091387: step 11267, loss 0.511627.
Train: 2018-08-01T00:38:30.263210: step 11268, loss 0.562806.
Train: 2018-08-01T00:38:30.419431: step 11269, loss 0.494683.
Train: 2018-08-01T00:38:30.575636: step 11270, loss 0.511679.
Test: 2018-08-01T00:38:31.044280: step 11270, loss 0.548549.
Train: 2018-08-01T00:38:31.262981: step 11271, loss 0.511569.
Train: 2018-08-01T00:38:31.419164: step 11272, loss 0.648399.
Train: 2018-08-01T00:38:31.575377: step 11273, loss 0.597046.
Train: 2018-08-01T00:38:31.731590: step 11274, loss 0.631285.
Train: 2018-08-01T00:38:31.887803: step 11275, loss 0.562827.
Train: 2018-08-01T00:38:32.044017: step 11276, loss 0.494545.
Train: 2018-08-01T00:38:32.215852: step 11277, loss 0.596977.
Train: 2018-08-01T00:38:32.372065: step 11278, loss 0.528699.
Train: 2018-08-01T00:38:32.528280: step 11279, loss 0.562793.
Train: 2018-08-01T00:38:32.684526: step 11280, loss 0.59705.
Test: 2018-08-01T00:38:33.153157: step 11280, loss 0.548519.
Train: 2018-08-01T00:38:33.324967: step 11281, loss 0.494457.
Train: 2018-08-01T00:38:33.481181: step 11282, loss 0.545683.
Train: 2018-08-01T00:38:33.637395: step 11283, loss 0.579863.
Train: 2018-08-01T00:38:33.793607: step 11284, loss 0.511482.
Train: 2018-08-01T00:38:33.949821: step 11285, loss 0.631426.
Train: 2018-08-01T00:38:34.106065: step 11286, loss 0.597051.
Train: 2018-08-01T00:38:34.262279: step 11287, loss 0.562834.
Train: 2018-08-01T00:38:34.434107: step 11288, loss 0.562717.
Train: 2018-08-01T00:38:34.574705: step 11289, loss 0.459978.
Train: 2018-08-01T00:38:34.730889: step 11290, loss 0.477019.
Test: 2018-08-01T00:38:35.199559: step 11290, loss 0.548394.
Train: 2018-08-01T00:38:35.355773: step 11291, loss 0.493992.
Train: 2018-08-01T00:38:35.527615: step 11292, loss 0.597153.
Train: 2018-08-01T00:38:35.683824: step 11293, loss 0.458922.
Train: 2018-08-01T00:38:35.840003: step 11294, loss 0.545448.
Train: 2018-08-01T00:38:35.996247: step 11295, loss 0.562813.
Train: 2018-08-01T00:38:36.152461: step 11296, loss 0.61504.
Train: 2018-08-01T00:38:36.308677: step 11297, loss 0.527806.
Train: 2018-08-01T00:38:36.464888: step 11298, loss 0.545387.
Train: 2018-08-01T00:38:36.636693: step 11299, loss 0.474959.
Train: 2018-08-01T00:38:36.792938: step 11300, loss 0.492094.
Test: 2018-08-01T00:38:37.245924: step 11300, loss 0.548056.
Train: 2018-08-01T00:38:37.980158: step 11301, loss 0.59834.
Train: 2018-08-01T00:38:38.136365: step 11302, loss 0.491642.
Train: 2018-08-01T00:38:38.276963: step 11303, loss 0.491668.
Train: 2018-08-01T00:38:38.448798: step 11304, loss 0.616584.
Train: 2018-08-01T00:38:38.605013: step 11305, loss 0.545383.
Train: 2018-08-01T00:38:38.792437: step 11306, loss 0.598752.
Train: 2018-08-01T00:38:38.933029: step 11307, loss 0.508826.
Train: 2018-08-01T00:38:39.089267: step 11308, loss 0.689443.
Train: 2018-08-01T00:38:39.261107: step 11309, loss 0.437139.
Train: 2018-08-01T00:38:39.401699: step 11310, loss 0.600004.
Test: 2018-08-01T00:38:39.885961: step 11310, loss 0.547933.
Train: 2018-08-01T00:38:40.042147: step 11311, loss 0.617399.
Train: 2018-08-01T00:38:40.198389: step 11312, loss 0.562943.
Train: 2018-08-01T00:38:40.354601: step 11313, loss 0.545208.
Train: 2018-08-01T00:38:40.510784: step 11314, loss 0.563189.
Train: 2018-08-01T00:38:40.667028: step 11315, loss 0.527172.
Train: 2018-08-01T00:38:40.823241: step 11316, loss 0.617075.
Train: 2018-08-01T00:38:40.995077: step 11317, loss 0.616953.
Train: 2018-08-01T00:38:41.135663: step 11318, loss 0.491131.
Train: 2018-08-01T00:38:41.307506: step 11319, loss 0.545022.
Train: 2018-08-01T00:38:41.463718: step 11320, loss 0.68856.
Test: 2018-08-01T00:38:41.932326: step 11320, loss 0.547972.
Train: 2018-08-01T00:38:42.104161: step 11321, loss 0.741902.
Train: 2018-08-01T00:38:42.260405: step 11322, loss 0.527235.
Train: 2018-08-01T00:38:42.416589: step 11323, loss 0.598405.
Train: 2018-08-01T00:38:42.588449: step 11324, loss 0.545177.
Train: 2018-08-01T00:38:42.744673: step 11325, loss 0.756358.
Train: 2018-08-01T00:38:42.900875: step 11326, loss 0.580308.
Train: 2018-08-01T00:38:43.057065: step 11327, loss 0.493192.
Train: 2018-08-01T00:38:43.244520: step 11328, loss 0.545431.
Train: 2018-08-01T00:38:43.385142: step 11329, loss 0.580009.
Train: 2018-08-01T00:38:43.541349: step 11330, loss 0.476819.
Test: 2018-08-01T00:38:44.025617: step 11330, loss 0.548381.
Train: 2018-08-01T00:38:44.197449: step 11331, loss 0.562725.
Train: 2018-08-01T00:38:44.369257: step 11332, loss 0.665418.
Train: 2018-08-01T00:38:44.525469: step 11333, loss 0.613917.
Train: 2018-08-01T00:38:44.697334: step 11334, loss 0.494705.
Train: 2018-08-01T00:38:44.853548: step 11335, loss 0.596701.
Train: 2018-08-01T00:38:45.009762: step 11336, loss 0.596456.
Train: 2018-08-01T00:38:45.165969: step 11337, loss 0.613601.
Train: 2018-08-01T00:38:45.337815: step 11338, loss 0.545744.
Train: 2018-08-01T00:38:45.494018: step 11339, loss 0.579361.
Train: 2018-08-01T00:38:45.650236: step 11340, loss 0.579744.
Test: 2018-08-01T00:38:46.118876: step 11340, loss 0.548847.
Train: 2018-08-01T00:38:46.275090: step 11341, loss 0.545612.
Train: 2018-08-01T00:38:46.446916: step 11342, loss 0.545805.
Train: 2018-08-01T00:38:46.603108: step 11343, loss 0.59615.
Train: 2018-08-01T00:38:46.759322: step 11344, loss 0.648156.
Train: 2018-08-01T00:38:46.899944: step 11345, loss 0.513675.
Train: 2018-08-01T00:38:47.071778: step 11346, loss 0.528956.
Train: 2018-08-01T00:38:47.227992: step 11347, loss 0.561655.
Train: 2018-08-01T00:38:47.384206: step 11348, loss 0.513441.
Train: 2018-08-01T00:38:47.540391: step 11349, loss 0.530211.
Train: 2018-08-01T00:38:47.696632: step 11350, loss 0.597582.
Test: 2018-08-01T00:38:48.176782: step 11350, loss 0.548831.
Train: 2018-08-01T00:38:48.332965: step 11351, loss 0.578865.
Train: 2018-08-01T00:38:48.489203: step 11352, loss 0.530475.
Train: 2018-08-01T00:38:48.661046: step 11353, loss 0.697192.
Train: 2018-08-01T00:38:48.817227: step 11354, loss 0.512375.
Train: 2018-08-01T00:38:48.973479: step 11355, loss 0.529055.
Train: 2018-08-01T00:38:49.129686: step 11356, loss 0.512506.
Train: 2018-08-01T00:38:49.285897: step 11357, loss 0.613271.
Train: 2018-08-01T00:38:49.442080: step 11358, loss 0.545784.
Train: 2018-08-01T00:38:49.598327: step 11359, loss 0.547728.
Train: 2018-08-01T00:38:49.754538: step 11360, loss 0.546308.
Test: 2018-08-01T00:38:50.238799: step 11360, loss 0.548814.
Train: 2018-08-01T00:38:50.395013: step 11361, loss 0.494651.
Train: 2018-08-01T00:38:50.566817: step 11362, loss 0.563521.
Train: 2018-08-01T00:38:50.723031: step 11363, loss 0.664147.
Train: 2018-08-01T00:38:50.894864: step 11364, loss 0.496166.
Train: 2018-08-01T00:38:51.035458: step 11365, loss 0.563055.
Train: 2018-08-01T00:38:51.191701: step 11366, loss 0.564256.
Train: 2018-08-01T00:38:51.347917: step 11367, loss 0.49619.
Train: 2018-08-01T00:38:51.504128: step 11368, loss 0.59673.
Train: 2018-08-01T00:38:51.660312: step 11369, loss 0.646803.
Train: 2018-08-01T00:38:51.832170: step 11370, loss 0.647072.
Test: 2018-08-01T00:38:52.300815: step 11370, loss 0.548674.
Train: 2018-08-01T00:38:52.457032: step 11371, loss 0.562832.
Train: 2018-08-01T00:38:52.613244: step 11372, loss 0.512402.
Train: 2018-08-01T00:38:52.785078: step 11373, loss 0.545825.
Train: 2018-08-01T00:38:52.941291: step 11374, loss 0.546028.
Train: 2018-08-01T00:38:53.128717: step 11375, loss 0.596488.
Train: 2018-08-01T00:38:53.284960: step 11376, loss 0.529095.
Train: 2018-08-01T00:38:53.441175: step 11377, loss 0.579301.
Train: 2018-08-01T00:38:53.597382: step 11378, loss 0.663634.
Train: 2018-08-01T00:38:53.753601: step 11379, loss 0.545986.
Train: 2018-08-01T00:38:53.925435: step 11380, loss 0.579437.
Test: 2018-08-01T00:38:54.394076: step 11380, loss 0.54866.
Train: 2018-08-01T00:38:54.550260: step 11381, loss 0.595921.
Train: 2018-08-01T00:38:54.722118: step 11382, loss 0.479103.
Train: 2018-08-01T00:38:54.878337: step 11383, loss 0.596085.
Train: 2018-08-01T00:38:55.034550: step 11384, loss 0.562754.
Train: 2018-08-01T00:38:55.206356: step 11385, loss 0.596181.
Train: 2018-08-01T00:38:55.362569: step 11386, loss 0.546033.
Train: 2018-08-01T00:38:55.518813: step 11387, loss 0.579882.
Train: 2018-08-01T00:38:55.675026: step 11388, loss 0.563032.
Train: 2018-08-01T00:38:55.846831: step 11389, loss 0.646884.
Train: 2018-08-01T00:38:56.003045: step 11390, loss 0.646668.
Test: 2018-08-01T00:38:56.471684: step 11390, loss 0.548748.
Train: 2018-08-01T00:38:56.627897: step 11391, loss 0.712575.
Train: 2018-08-01T00:38:56.784112: step 11392, loss 0.562626.
Train: 2018-08-01T00:38:56.955976: step 11393, loss 0.578953.
Train: 2018-08-01T00:38:57.112159: step 11394, loss 0.530243.
Train: 2018-08-01T00:38:57.268403: step 11395, loss 0.464584.
Train: 2018-08-01T00:38:57.440207: step 11396, loss 0.627477.
Train: 2018-08-01T00:38:57.580830: step 11397, loss 0.628582.
Train: 2018-08-01T00:38:57.752665: step 11398, loss 0.496875.
Train: 2018-08-01T00:38:57.908847: step 11399, loss 0.545636.
Train: 2018-08-01T00:38:58.065061: step 11400, loss 0.513744.
Test: 2018-08-01T00:38:58.533702: step 11400, loss 0.54919.
Train: 2018-08-01T00:38:59.236691: step 11401, loss 0.44935.
Train: 2018-08-01T00:38:59.392905: step 11402, loss 0.644122.
Train: 2018-08-01T00:38:59.549115: step 11403, loss 0.725275.
Train: 2018-08-01T00:38:59.720923: step 11404, loss 0.545966.
Train: 2018-08-01T00:38:59.877161: step 11405, loss 0.563941.
Train: 2018-08-01T00:39:00.033382: step 11406, loss 0.562624.
Train: 2018-08-01T00:39:00.205210: step 11407, loss 0.564271.
Train: 2018-08-01T00:39:00.361429: step 11408, loss 0.579933.
Train: 2018-08-01T00:39:00.517642: step 11409, loss 0.643928.
Train: 2018-08-01T00:39:00.673826: step 11410, loss 0.612693.
Test: 2018-08-01T00:39:01.142495: step 11410, loss 0.549221.
Train: 2018-08-01T00:39:01.314301: step 11411, loss 0.514086.
Train: 2018-08-01T00:39:01.470547: step 11412, loss 0.61114.
Train: 2018-08-01T00:39:01.626728: step 11413, loss 0.481051.
Train: 2018-08-01T00:39:01.798562: step 11414, loss 0.499893.
Train: 2018-08-01T00:39:01.939184: step 11415, loss 0.597296.
Train: 2018-08-01T00:39:02.095400: step 11416, loss 0.498109.
Train: 2018-08-01T00:39:02.267232: step 11417, loss 0.628709.
Train: 2018-08-01T00:39:02.423445: step 11418, loss 0.612594.
Train: 2018-08-01T00:39:02.579628: step 11419, loss 0.612432.
Train: 2018-08-01T00:39:02.735842: step 11420, loss 0.596113.
Test: 2018-08-01T00:39:03.204513: step 11420, loss 0.549111.
Train: 2018-08-01T00:39:03.376347: step 11421, loss 0.579585.
Train: 2018-08-01T00:39:03.532555: step 11422, loss 0.562841.
Train: 2018-08-01T00:39:03.688774: step 11423, loss 0.579365.
Train: 2018-08-01T00:39:03.844957: step 11424, loss 0.595751.
Train: 2018-08-01T00:39:04.016792: step 11425, loss 0.546495.
Train: 2018-08-01T00:39:04.173005: step 11426, loss 0.595684.
Train: 2018-08-01T00:39:04.329250: step 11427, loss 0.431943.
Train: 2018-08-01T00:39:04.485432: step 11428, loss 0.546457.
Train: 2018-08-01T00:39:04.641646: step 11429, loss 0.562884.
Train: 2018-08-01T00:39:04.797889: step 11430, loss 0.464058.
Test: 2018-08-01T00:39:05.282120: step 11430, loss 0.548994.
Train: 2018-08-01T00:39:05.438335: step 11431, loss 0.628969.
Train: 2018-08-01T00:39:05.594572: step 11432, loss 0.579336.
Train: 2018-08-01T00:39:05.750761: step 11433, loss 0.562809.
Train: 2018-08-01T00:39:05.906976: step 11434, loss 0.512926.
Train: 2018-08-01T00:39:06.110068: step 11435, loss 0.529472.
Train: 2018-08-01T00:39:06.266291: step 11436, loss 0.546037.
Train: 2018-08-01T00:39:06.438138: step 11437, loss 0.629786.
Train: 2018-08-01T00:39:06.594314: step 11438, loss 0.509033.
Train: 2018-08-01T00:39:06.750551: step 11439, loss 0.512224.
Train: 2018-08-01T00:39:06.906775: step 11440, loss 0.545886.
Test: 2018-08-01T00:39:07.375411: step 11440, loss 0.548484.
Train: 2018-08-01T00:39:07.547245: step 11441, loss 0.545748.
Train: 2018-08-01T00:39:07.703453: step 11442, loss 0.52868.
Train: 2018-08-01T00:39:07.844021: step 11443, loss 0.579695.
Train: 2018-08-01T00:39:08.000236: step 11444, loss 0.56266.
Train: 2018-08-01T00:39:08.156448: step 11445, loss 0.648282.
Train: 2018-08-01T00:39:08.343933: step 11446, loss 0.494026.
Train: 2018-08-01T00:39:08.500118: step 11447, loss 0.511106.
Train: 2018-08-01T00:39:08.656331: step 11448, loss 0.562639.
Train: 2018-08-01T00:39:08.812544: step 11449, loss 0.562627.
Train: 2018-08-01T00:39:08.968791: step 11450, loss 0.528055.
Test: 2018-08-01T00:39:09.453049: step 11450, loss 0.548119.
Train: 2018-08-01T00:39:09.609233: step 11451, loss 0.59729.
Train: 2018-08-01T00:39:09.765447: step 11452, loss 0.597339.
Train: 2018-08-01T00:39:09.921659: step 11453, loss 0.597365.
Train: 2018-08-01T00:39:10.077873: step 11454, loss 0.562628.
Train: 2018-08-01T00:39:10.234117: step 11455, loss 0.475771.
Train: 2018-08-01T00:39:10.390325: step 11456, loss 0.545233.
Train: 2018-08-01T00:39:10.562135: step 11457, loss 0.63229.
Train: 2018-08-01T00:39:10.718381: step 11458, loss 0.580048.
Train: 2018-08-01T00:39:10.874562: step 11459, loss 0.527788.
Train: 2018-08-01T00:39:11.030805: step 11460, loss 0.562623.
Test: 2018-08-01T00:39:11.515067: step 11460, loss 0.548028.
Train: 2018-08-01T00:39:11.686909: step 11461, loss 0.527767.
Train: 2018-08-01T00:39:11.843085: step 11462, loss 0.64981.
Train: 2018-08-01T00:39:11.999329: step 11463, loss 0.492912.
Train: 2018-08-01T00:39:12.155542: step 11464, loss 0.458033.
Train: 2018-08-01T00:39:12.311755: step 11465, loss 0.545164.
Train: 2018-08-01T00:39:12.467971: step 11466, loss 0.527645.
Train: 2018-08-01T00:39:12.639774: step 11467, loss 0.615213.
Train: 2018-08-01T00:39:12.827229: step 11468, loss 0.457355.
Train: 2018-08-01T00:39:12.967854: step 11469, loss 0.562658.
Train: 2018-08-01T00:39:13.124066: step 11470, loss 0.456914.
Test: 2018-08-01T00:39:13.608295: step 11470, loss 0.547876.
Train: 2018-08-01T00:39:13.764528: step 11471, loss 0.49193.
Train: 2018-08-01T00:39:13.936345: step 11472, loss 0.633694.
Train: 2018-08-01T00:39:14.092583: step 11473, loss 0.544943.
Train: 2018-08-01T00:39:14.264423: step 11474, loss 0.56275.
Train: 2018-08-01T00:39:14.420606: step 11475, loss 0.634223.
Train: 2018-08-01T00:39:14.576820: step 11476, loss 0.544896.
Train: 2018-08-01T00:39:14.733033: step 11477, loss 0.562781.
Train: 2018-08-01T00:39:14.889248: step 11478, loss 0.652212.
Train: 2018-08-01T00:39:15.045495: step 11479, loss 0.598509.
Train: 2018-08-01T00:39:15.201706: step 11480, loss 0.544904.
Test: 2018-08-01T00:39:15.670312: step 11480, loss 0.547813.
Train: 2018-08-01T00:39:15.826557: step 11481, loss 0.634018.
Train: 2018-08-01T00:39:15.998361: step 11482, loss 0.616053.
Train: 2018-08-01T00:39:16.138954: step 11483, loss 0.562689.
Train: 2018-08-01T00:39:16.310789: step 11484, loss 0.4566.
Train: 2018-08-01T00:39:16.451381: step 11485, loss 0.545001.
Train: 2018-08-01T00:39:16.623215: step 11486, loss 0.686162.
Train: 2018-08-01T00:39:16.779428: step 11487, loss 0.580233.
Train: 2018-08-01T00:39:16.935641: step 11488, loss 0.527518.
Train: 2018-08-01T00:39:17.091855: step 11489, loss 0.597639.
Train: 2018-08-01T00:39:17.248099: step 11490, loss 0.597544.
Test: 2018-08-01T00:39:17.716708: step 11490, loss 0.547992.
Train: 2018-08-01T00:39:17.872953: step 11491, loss 0.632289.
Train: 2018-08-01T00:39:18.044758: step 11492, loss 0.666759.
Train: 2018-08-01T00:39:18.200998: step 11493, loss 0.527999.
Train: 2018-08-01T00:39:18.357184: step 11494, loss 0.57977.
Train: 2018-08-01T00:39:18.513428: step 11495, loss 0.511101.
Train: 2018-08-01T00:39:18.669641: step 11496, loss 0.425702.
Train: 2018-08-01T00:39:18.825855: step 11497, loss 0.562552.
Train: 2018-08-01T00:39:18.982068: step 11498, loss 0.528354.
Train: 2018-08-01T00:39:19.138252: step 11499, loss 0.562552.
Train: 2018-08-01T00:39:19.310088: step 11500, loss 0.528328.
Test: 2018-08-01T00:39:19.778759: step 11500, loss 0.548208.
Train: 2018-08-01T00:39:20.528586: step 11501, loss 0.5968.
Train: 2018-08-01T00:39:20.684794: step 11502, loss 0.494032.
Train: 2018-08-01T00:39:20.841011: step 11503, loss 0.648298.
Train: 2018-08-01T00:39:20.997221: step 11504, loss 0.476801.
Train: 2018-08-01T00:39:21.153405: step 11505, loss 0.665547.
Train: 2018-08-01T00:39:21.309618: step 11506, loss 0.614018.
Train: 2018-08-01T00:39:21.481452: step 11507, loss 0.511138.
Train: 2018-08-01T00:39:21.637666: step 11508, loss 0.562542.
Train: 2018-08-01T00:39:21.793910: step 11509, loss 0.511167.
Train: 2018-08-01T00:39:21.965747: step 11510, loss 0.631076.
Test: 2018-08-01T00:39:22.434385: step 11510, loss 0.548201.
Train: 2018-08-01T00:39:22.621811: step 11511, loss 0.528292.
Train: 2018-08-01T00:39:22.762402: step 11512, loss 0.56254.
Train: 2018-08-01T00:39:22.934238: step 11513, loss 0.562518.
Train: 2018-08-01T00:39:23.090451: step 11514, loss 0.613912.
Train: 2018-08-01T00:39:23.246694: step 11515, loss 0.425645.
Train: 2018-08-01T00:39:23.402907: step 11516, loss 0.579672.
Train: 2018-08-01T00:39:23.559122: step 11517, loss 0.562538.
Train: 2018-08-01T00:39:23.762169: step 11518, loss 0.631211.
Train: 2018-08-01T00:39:23.918383: step 11519, loss 0.579703.
Train: 2018-08-01T00:39:24.074625: step 11520, loss 0.562542.
Test: 2018-08-01T00:39:24.558857: step 11520, loss 0.548172.
Train: 2018-08-01T00:39:24.715070: step 11521, loss 0.545383.
Train: 2018-08-01T00:39:24.886930: step 11522, loss 0.631127.
Train: 2018-08-01T00:39:25.043149: step 11523, loss 0.613917.
Train: 2018-08-01T00:39:25.199333: step 11524, loss 0.511245.
Train: 2018-08-01T00:39:25.371197: step 11525, loss 0.630865.
Train: 2018-08-01T00:39:25.543001: step 11526, loss 0.613692.
Train: 2018-08-01T00:39:25.699214: step 11527, loss 0.630585.
Train: 2018-08-01T00:39:25.855459: step 11528, loss 0.562546.
Train: 2018-08-01T00:39:26.027293: step 11529, loss 0.494911.
Train: 2018-08-01T00:39:26.183476: step 11530, loss 0.54567.
Test: 2018-08-01T00:39:26.652147: step 11530, loss 0.548433.
Train: 2018-08-01T00:39:26.808330: step 11531, loss 0.52882.
Train: 2018-08-01T00:39:26.980190: step 11532, loss 0.511965.
Train: 2018-08-01T00:39:27.136378: step 11533, loss 0.64693.
Train: 2018-08-01T00:39:27.292592: step 11534, loss 0.478247.
Train: 2018-08-01T00:39:27.448835: step 11535, loss 0.613179.
Train: 2018-08-01T00:39:27.605020: step 11536, loss 0.562555.
Train: 2018-08-01T00:39:27.776853: step 11537, loss 0.511935.
Train: 2018-08-01T00:39:27.933067: step 11538, loss 0.545664.
Train: 2018-08-01T00:39:28.104927: step 11539, loss 0.630171.
Train: 2018-08-01T00:39:28.261145: step 11540, loss 0.511832.
Test: 2018-08-01T00:39:28.729785: step 11540, loss 0.548376.
Train: 2018-08-01T00:39:28.885999: step 11541, loss 0.647135.
Train: 2018-08-01T00:39:29.042212: step 11542, loss 0.528726.
Train: 2018-08-01T00:39:29.229668: step 11543, loss 0.579454.
Train: 2018-08-01T00:39:29.385881: step 11544, loss 0.562543.
Train: 2018-08-01T00:39:29.542095: step 11545, loss 0.545635.
Train: 2018-08-01T00:39:29.698308: step 11546, loss 0.579453.
Train: 2018-08-01T00:39:29.854522: step 11547, loss 0.528718.
Train: 2018-08-01T00:39:30.010730: step 11548, loss 0.562538.
Train: 2018-08-01T00:39:30.166949: step 11549, loss 0.613328.
Train: 2018-08-01T00:39:30.338753: step 11550, loss 0.46097.
Test: 2018-08-01T00:39:30.807424: step 11550, loss 0.548336.
Train: 2018-08-01T00:39:30.963640: step 11551, loss 0.647291.
Train: 2018-08-01T00:39:31.119845: step 11552, loss 0.528627.
Train: 2018-08-01T00:39:31.276058: step 11553, loss 0.47772.
Train: 2018-08-01T00:39:31.463492: step 11554, loss 0.562524.
Train: 2018-08-01T00:39:31.619733: step 11555, loss 0.545497.
Train: 2018-08-01T00:39:31.775947: step 11556, loss 0.46019.
Train: 2018-08-01T00:39:31.932160: step 11557, loss 0.545403.
Train: 2018-08-01T00:39:32.088376: step 11558, loss 0.493854.
Train: 2018-08-01T00:39:32.244587: step 11559, loss 0.579745.
Train: 2018-08-01T00:39:32.416420: step 11560, loss 0.597092.
Test: 2018-08-01T00:39:32.885062: step 11560, loss 0.548012.
Train: 2018-08-01T00:39:33.041270: step 11561, loss 0.527865.
Train: 2018-08-01T00:39:33.213080: step 11562, loss 0.440917.
Train: 2018-08-01T00:39:33.369324: step 11563, loss 0.562541.
Train: 2018-08-01T00:39:33.525509: step 11564, loss 0.47502.
Train: 2018-08-01T00:39:33.681745: step 11565, loss 0.544994.
Train: 2018-08-01T00:39:33.837933: step 11566, loss 0.491971.
Train: 2018-08-01T00:39:33.994183: step 11567, loss 0.580379.
Train: 2018-08-01T00:39:34.150361: step 11568, loss 0.633902.
Train: 2018-08-01T00:39:34.306574: step 11569, loss 0.723327.
Train: 2018-08-01T00:39:34.462788: step 11570, loss 0.43779.
Test: 2018-08-01T00:39:34.947048: step 11570, loss 0.547737.
Train: 2018-08-01T00:39:35.103262: step 11571, loss 0.562698.
Train: 2018-08-01T00:39:35.259476: step 11572, loss 0.544823.
Train: 2018-08-01T00:39:35.415714: step 11573, loss 0.473203.
Train: 2018-08-01T00:39:35.571936: step 11574, loss 0.562738.
Train: 2018-08-01T00:39:35.743739: step 11575, loss 0.598696.
Train: 2018-08-01T00:39:35.899952: step 11576, loss 0.634708.
Train: 2018-08-01T00:39:36.056195: step 11577, loss 0.490845.
Train: 2018-08-01T00:39:36.212411: step 11578, loss 0.508802.
Train: 2018-08-01T00:39:36.368616: step 11579, loss 0.688826.
Train: 2018-08-01T00:39:36.524805: step 11580, loss 0.544777.
Test: 2018-08-01T00:39:36.993475: step 11580, loss 0.547705.
Train: 2018-08-01T00:39:37.149658: step 11581, loss 0.50883.
Train: 2018-08-01T00:39:37.305871: step 11582, loss 0.544782.
Train: 2018-08-01T00:39:37.462118: step 11583, loss 0.598703.
Train: 2018-08-01T00:39:37.618323: step 11584, loss 0.508861.
Train: 2018-08-01T00:39:37.774513: step 11585, loss 0.50886.
Train: 2018-08-01T00:39:37.946346: step 11586, loss 0.634646.
Train: 2018-08-01T00:39:38.086939: step 11587, loss 0.50886.
Train: 2018-08-01T00:39:38.243183: step 11588, loss 0.544784.
Train: 2018-08-01T00:39:38.399396: step 11589, loss 0.508851.
Train: 2018-08-01T00:39:38.555610: step 11590, loss 0.454884.
Test: 2018-08-01T00:39:39.039842: step 11590, loss 0.547693.
Train: 2018-08-01T00:39:39.196054: step 11591, loss 0.634835.
Train: 2018-08-01T00:39:39.352298: step 11592, loss 0.490683.
Train: 2018-08-01T00:39:39.508511: step 11593, loss 0.653055.
Train: 2018-08-01T00:39:39.664695: step 11594, loss 0.526703.
Train: 2018-08-01T00:39:39.820938: step 11595, loss 0.54475.
Train: 2018-08-01T00:39:39.977152: step 11596, loss 0.562804.
Train: 2018-08-01T00:39:40.180238: step 11597, loss 0.562804.
Train: 2018-08-01T00:39:40.320821: step 11598, loss 0.436418.
Train: 2018-08-01T00:39:40.477005: step 11599, loss 0.617063.
Train: 2018-08-01T00:39:40.633248: step 11600, loss 0.562824.
Test: 2018-08-01T00:39:41.101892: step 11600, loss 0.547677.
Train: 2018-08-01T00:39:41.789222: step 11601, loss 0.580918.
Train: 2018-08-01T00:39:41.945410: step 11602, loss 0.617084.
Train: 2018-08-01T00:39:42.117245: step 11603, loss 0.617006.
Train: 2018-08-01T00:39:42.273489: step 11604, loss 0.544752.
Train: 2018-08-01T00:39:42.460948: step 11605, loss 0.472726.
Train: 2018-08-01T00:39:42.617158: step 11606, loss 0.634526.
Train: 2018-08-01T00:39:42.773372: step 11607, loss 0.544687.
Train: 2018-08-01T00:39:42.929585: step 11608, loss 0.616844.
Train: 2018-08-01T00:39:43.085802: step 11609, loss 0.582666.
Train: 2018-08-01T00:39:43.241981: step 11610, loss 0.56269.
Test: 2018-08-01T00:39:43.726273: step 11610, loss 0.54774.
Train: 2018-08-01T00:39:43.882487: step 11611, loss 0.545383.
Train: 2018-08-01T00:39:44.038670: step 11612, loss 0.580434.
Train: 2018-08-01T00:39:44.194883: step 11613, loss 0.615881.
Train: 2018-08-01T00:39:44.351097: step 11614, loss 0.45641.
Train: 2018-08-01T00:39:44.507343: step 11615, loss 0.544926.
Train: 2018-08-01T00:39:44.679145: step 11616, loss 0.562604.
Train: 2018-08-01T00:39:44.835392: step 11617, loss 0.562601.
Train: 2018-08-01T00:39:44.991603: step 11618, loss 0.580235.
Train: 2018-08-01T00:39:45.147815: step 11619, loss 0.439276.
Train: 2018-08-01T00:39:45.304024: step 11620, loss 0.597858.
Test: 2018-08-01T00:39:45.772670: step 11620, loss 0.54784.
Train: 2018-08-01T00:39:45.944504: step 11621, loss 0.61549.
Train: 2018-08-01T00:39:46.100688: step 11622, loss 0.633057.
Train: 2018-08-01T00:39:46.256902: step 11623, loss 0.56259.
Train: 2018-08-01T00:39:46.413114: step 11624, loss 0.50993.
Train: 2018-08-01T00:39:46.569327: step 11625, loss 0.702855.
Train: 2018-08-01T00:39:46.725576: step 11626, loss 0.527599.
Train: 2018-08-01T00:39:46.881754: step 11627, loss 0.457888.
Train: 2018-08-01T00:39:47.037998: step 11628, loss 0.579992.
Train: 2018-08-01T00:39:47.194181: step 11629, loss 0.54513.
Train: 2018-08-01T00:39:47.350425: step 11630, loss 0.475478.
Test: 2018-08-01T00:39:47.819064: step 11630, loss 0.54796.
Train: 2018-08-01T00:39:47.975250: step 11631, loss 0.545126.
Train: 2018-08-01T00:39:48.131461: step 11632, loss 0.684672.
Train: 2018-08-01T00:39:48.287700: step 11633, loss 0.562554.
Train: 2018-08-01T00:39:48.443919: step 11634, loss 0.614781.
Train: 2018-08-01T00:39:48.600101: step 11635, loss 0.71897.
Train: 2018-08-01T00:39:48.756346: step 11636, loss 0.6491.
Train: 2018-08-01T00:39:48.928151: step 11637, loss 0.476378.
Train: 2018-08-01T00:39:49.084397: step 11638, loss 0.459464.
Train: 2018-08-01T00:39:49.240577: step 11639, loss 0.562522.
Train: 2018-08-01T00:39:49.396815: step 11640, loss 0.511112.
Test: 2018-08-01T00:39:49.865461: step 11640, loss 0.548174.
Train: 2018-08-01T00:39:50.021675: step 11641, loss 0.528256.
Train: 2018-08-01T00:39:50.177883: step 11642, loss 0.596797.
Train: 2018-08-01T00:39:50.334110: step 11643, loss 0.511114.
Train: 2018-08-01T00:39:50.505939: step 11644, loss 0.545373.
Train: 2018-08-01T00:39:50.646528: step 11645, loss 0.613993.
Train: 2018-08-01T00:39:50.818332: step 11646, loss 0.476729.
Train: 2018-08-01T00:39:50.958958: step 11647, loss 0.528158.
Train: 2018-08-01T00:39:51.130796: step 11648, loss 0.510895.
Train: 2018-08-01T00:39:51.286997: step 11649, loss 0.579762.
Train: 2018-08-01T00:39:51.443211: step 11650, loss 0.527968.
Test: 2018-08-01T00:39:51.927448: step 11650, loss 0.548025.
Train: 2018-08-01T00:39:52.083694: step 11651, loss 0.54521.
Train: 2018-08-01T00:39:52.239876: step 11652, loss 0.527832.
Train: 2018-08-01T00:39:52.396113: step 11653, loss 0.579917.
Train: 2018-08-01T00:39:52.567923: step 11654, loss 0.492862.
Train: 2018-08-01T00:39:52.724166: step 11655, loss 0.54508.
Train: 2018-08-01T00:39:52.880375: step 11656, loss 0.702612.
Train: 2018-08-01T00:39:53.036594: step 11657, loss 0.615083.
Train: 2018-08-01T00:39:53.192801: step 11658, loss 0.63254.
Train: 2018-08-01T00:39:53.364611: step 11659, loss 0.510138.
Train: 2018-08-01T00:39:53.520825: step 11660, loss 0.492725.
Test: 2018-08-01T00:39:53.989495: step 11660, loss 0.547919.
Train: 2018-08-01T00:39:54.145678: step 11661, loss 0.510167.
Train: 2018-08-01T00:39:54.301892: step 11662, loss 0.597484.
Train: 2018-08-01T00:39:54.473726: step 11663, loss 0.56254.
Train: 2018-08-01T00:39:54.629941: step 11664, loss 0.527582.
Train: 2018-08-01T00:39:54.786183: step 11665, loss 0.422629.
Train: 2018-08-01T00:39:54.942397: step 11666, loss 0.632683.
Train: 2018-08-01T00:39:55.098605: step 11667, loss 0.615216.
Train: 2018-08-01T00:39:55.254793: step 11668, loss 0.562558.
Train: 2018-08-01T00:39:55.426628: step 11669, loss 0.650348.
Train: 2018-08-01T00:39:55.582842: step 11670, loss 0.562551.
Test: 2018-08-01T00:39:56.051514: step 11670, loss 0.547877.
Train: 2018-08-01T00:39:56.207729: step 11671, loss 0.580059.
Train: 2018-08-01T00:39:56.363940: step 11672, loss 0.597516.
Train: 2018-08-01T00:39:56.520152: step 11673, loss 0.614901.
Train: 2018-08-01T00:39:56.707617: step 11674, loss 0.61476.
Train: 2018-08-01T00:39:56.848201: step 11675, loss 0.562508.
Train: 2018-08-01T00:39:57.004385: step 11676, loss 0.597124.
Train: 2018-08-01T00:39:57.160628: step 11677, loss 0.579753.
Train: 2018-08-01T00:39:57.316843: step 11678, loss 0.545286.
Train: 2018-08-01T00:39:57.473054: step 11679, loss 0.613975.
Train: 2018-08-01T00:39:57.644859: step 11680, loss 0.511163.
Test: 2018-08-01T00:39:58.097878: step 11680, loss 0.548193.
Train: 2018-08-01T00:39:58.254091: step 11681, loss 0.596642.
Train: 2018-08-01T00:39:58.410304: step 11682, loss 0.545457.
Train: 2018-08-01T00:39:58.566518: step 11683, loss 0.54549.
Train: 2018-08-01T00:39:58.722731: step 11684, loss 0.477578.
Train: 2018-08-01T00:39:58.910212: step 11685, loss 0.681408.
Train: 2018-08-01T00:39:59.066401: step 11686, loss 0.562502.
Train: 2018-08-01T00:39:59.222640: step 11687, loss 0.57944.
Train: 2018-08-01T00:39:59.394479: step 11688, loss 0.69778.
Train: 2018-08-01T00:39:59.550693: step 11689, loss 0.562521.
Train: 2018-08-01T00:39:59.706909: step 11690, loss 0.562534.
Test: 2018-08-01T00:40:00.175546: step 11690, loss 0.548516.
Train: 2018-08-01T00:40:00.331763: step 11691, loss 0.579301.
Train: 2018-08-01T00:40:00.487944: step 11692, loss 0.595983.
Train: 2018-08-01T00:40:00.644157: step 11693, loss 0.512583.
Train: 2018-08-01T00:40:00.800370: step 11694, loss 0.645794.
Train: 2018-08-01T00:40:00.956608: step 11695, loss 0.579199.
Train: 2018-08-01T00:40:01.112822: step 11696, loss 0.661927.
Train: 2018-08-01T00:40:01.269040: step 11697, loss 0.562656.
Train: 2018-08-01T00:40:01.425254: step 11698, loss 0.562685.
Train: 2018-08-01T00:40:01.581470: step 11699, loss 0.497168.
Train: 2018-08-01T00:40:01.753303: step 11700, loss 0.562725.
Test: 2018-08-01T00:40:02.221913: step 11700, loss 0.549045.
Train: 2018-08-01T00:40:02.924906: step 11701, loss 0.611779.
Train: 2018-08-01T00:40:03.081085: step 11702, loss 0.481137.
Train: 2018-08-01T00:40:03.237301: step 11703, loss 0.497448.
Train: 2018-08-01T00:40:03.393513: step 11704, loss 0.546386.
Train: 2018-08-01T00:40:03.549757: step 11705, loss 0.513588.
Train: 2018-08-01T00:40:03.705978: step 11706, loss 0.644778.
Train: 2018-08-01T00:40:03.862154: step 11707, loss 0.595551.
Train: 2018-08-01T00:40:04.018367: step 11708, loss 0.562675.
Train: 2018-08-01T00:40:04.174619: step 11709, loss 0.579124.
Train: 2018-08-01T00:40:04.346440: step 11710, loss 0.52974.
Test: 2018-08-01T00:40:04.815085: step 11710, loss 0.548854.
Train: 2018-08-01T00:40:04.971268: step 11711, loss 0.496732.
Train: 2018-08-01T00:40:05.127483: step 11712, loss 0.628705.
Train: 2018-08-01T00:40:05.283725: step 11713, loss 0.562626.
Train: 2018-08-01T00:40:05.439934: step 11714, loss 0.529513.
Train: 2018-08-01T00:40:05.596123: step 11715, loss 0.562605.
Train: 2018-08-01T00:40:05.752335: step 11716, loss 0.612411.
Train: 2018-08-01T00:40:05.908548: step 11717, loss 0.662297.
Train: 2018-08-01T00:40:06.064762: step 11718, loss 0.529384.
Train: 2018-08-01T00:40:06.220976: step 11719, loss 0.728618.
Train: 2018-08-01T00:40:06.377189: step 11720, loss 0.512938.
Test: 2018-08-01T00:40:06.845859: step 11720, loss 0.548779.
Train: 2018-08-01T00:40:07.017694: step 11721, loss 0.645292.
Train: 2018-08-01T00:40:07.158286: step 11722, loss 0.595627.
Train: 2018-08-01T00:40:07.314469: step 11723, loss 0.595562.
Train: 2018-08-01T00:40:07.486304: step 11724, loss 0.546294.
Train: 2018-08-01T00:40:07.642517: step 11725, loss 0.546349.
Train: 2018-08-01T00:40:07.798756: step 11726, loss 0.481023.
Train: 2018-08-01T00:40:07.954944: step 11727, loss 0.579072.
Train: 2018-08-01T00:40:08.126810: step 11728, loss 0.611764.
Train: 2018-08-01T00:40:08.282992: step 11729, loss 0.497384.
Train: 2018-08-01T00:40:08.439207: step 11730, loss 0.513675.
Test: 2018-08-01T00:40:08.907877: step 11730, loss 0.548992.
Train: 2018-08-01T00:40:09.064060: step 11731, loss 0.529952.
Train: 2018-08-01T00:40:09.220303: step 11732, loss 0.562684.
Train: 2018-08-01T00:40:09.376487: step 11733, loss 0.579112.
Train: 2018-08-01T00:40:09.532700: step 11734, loss 0.546169.
Train: 2018-08-01T00:40:09.704559: step 11735, loss 0.513094.
Train: 2018-08-01T00:40:09.876370: step 11736, loss 0.529492.
Train: 2018-08-01T00:40:10.032615: step 11737, loss 0.545973.
Train: 2018-08-01T00:40:10.188829: step 11738, loss 0.612553.
Train: 2018-08-01T00:40:10.360661: step 11739, loss 0.580362.
Train: 2018-08-01T00:40:10.516870: step 11740, loss 0.478888.
Test: 2018-08-01T00:40:10.985515: step 11740, loss 0.54847.
Train: 2018-08-01T00:40:11.141728: step 11741, loss 0.52896.
Train: 2018-08-01T00:40:11.297912: step 11742, loss 0.54567.
Train: 2018-08-01T00:40:11.454150: step 11743, loss 0.61317.
Train: 2018-08-01T00:40:11.610370: step 11744, loss 0.562486.
Train: 2018-08-01T00:40:11.766582: step 11745, loss 0.460692.
Train: 2018-08-01T00:40:11.922796: step 11746, loss 0.596519.
Train: 2018-08-01T00:40:12.094630: step 11747, loss 0.408856.
Train: 2018-08-01T00:40:12.250844: step 11748, loss 0.631058.
Train: 2018-08-01T00:40:12.422678: step 11749, loss 0.614074.
Train: 2018-08-01T00:40:12.578863: step 11750, loss 0.596943.
Test: 2018-08-01T00:40:13.047538: step 11750, loss 0.548014.
Train: 2018-08-01T00:40:13.234958: step 11751, loss 0.648774.
Train: 2018-08-01T00:40:13.391172: step 11752, loss 0.614244.
Train: 2018-08-01T00:40:13.547384: step 11753, loss 0.614195.
Train: 2018-08-01T00:40:13.703631: step 11754, loss 0.562464.
Train: 2018-08-01T00:40:13.859843: step 11755, loss 0.596843.
Train: 2018-08-01T00:40:14.016026: step 11756, loss 0.613936.
Train: 2018-08-01T00:40:14.187861: step 11757, loss 0.511115.
Train: 2018-08-01T00:40:14.344104: step 11758, loss 0.579555.
Train: 2018-08-01T00:40:14.500286: step 11759, loss 0.596595.
Train: 2018-08-01T00:40:14.656531: step 11760, loss 0.613566.
Test: 2018-08-01T00:40:15.125139: step 11760, loss 0.548244.
Train: 2018-08-01T00:40:15.281380: step 11761, loss 0.52849.
Train: 2018-08-01T00:40:15.484462: step 11762, loss 0.545513.
Train: 2018-08-01T00:40:15.640676: step 11763, loss 0.647189.
Train: 2018-08-01T00:40:15.796889: step 11764, loss 0.511778.
Train: 2018-08-01T00:40:15.953072: step 11765, loss 0.545609.
Train: 2018-08-01T00:40:16.124937: step 11766, loss 0.646825.
Train: 2018-08-01T00:40:16.281121: step 11767, loss 0.545667.
Train: 2018-08-01T00:40:16.452954: step 11768, loss 0.428047.
Train: 2018-08-01T00:40:16.624789: step 11769, loss 0.495214.
Train: 2018-08-01T00:40:16.781003: step 11770, loss 0.54564.
Test: 2018-08-01T00:40:17.249673: step 11770, loss 0.548344.
Train: 2018-08-01T00:40:17.405886: step 11771, loss 0.545597.
Train: 2018-08-01T00:40:17.577724: step 11772, loss 0.579404.
Train: 2018-08-01T00:40:17.733936: step 11773, loss 0.647244.
Train: 2018-08-01T00:40:17.890119: step 11774, loss 0.613349.
Train: 2018-08-01T00:40:18.061978: step 11775, loss 0.545524.
Train: 2018-08-01T00:40:18.218197: step 11776, loss 0.426896.
Train: 2018-08-01T00:40:18.374413: step 11777, loss 0.647376.
Train: 2018-08-01T00:40:18.530624: step 11778, loss 0.545477.
Train: 2018-08-01T00:40:18.718050: step 11779, loss 0.511455.
Train: 2018-08-01T00:40:18.874288: step 11780, loss 0.664638.
Test: 2018-08-01T00:40:19.327306: step 11780, loss 0.548205.
Train: 2018-08-01T00:40:19.483494: step 11781, loss 0.545437.
Train: 2018-08-01T00:40:19.639739: step 11782, loss 0.511378.
Train: 2018-08-01T00:40:19.827198: step 11783, loss 0.528373.
Train: 2018-08-01T00:40:19.983408: step 11784, loss 0.61366.
Train: 2018-08-01T00:40:20.139621: step 11785, loss 0.511232.
Train: 2018-08-01T00:40:20.295804: step 11786, loss 0.528264.
Train: 2018-08-01T00:40:20.452018: step 11787, loss 0.528207.
Train: 2018-08-01T00:40:20.608231: step 11788, loss 0.579613.
Train: 2018-08-01T00:40:20.764445: step 11789, loss 0.54527.
Train: 2018-08-01T00:40:20.936279: step 11790, loss 0.476392.
Test: 2018-08-01T00:40:21.420571: step 11790, loss 0.548005.
Train: 2018-08-01T00:40:21.576788: step 11791, loss 0.596978.
Train: 2018-08-01T00:40:21.732998: step 11792, loss 0.493286.
Train: 2018-08-01T00:40:21.889182: step 11793, loss 0.545125.
Train: 2018-08-01T00:40:22.061016: step 11794, loss 0.579861.
Train: 2018-08-01T00:40:22.217229: step 11795, loss 0.545056.
Train: 2018-08-01T00:40:22.373473: step 11796, loss 0.457721.
Train: 2018-08-01T00:40:22.529656: step 11797, loss 0.632583.
Train: 2018-08-01T00:40:22.685903: step 11798, loss 0.580066.
Train: 2018-08-01T00:40:22.842113: step 11799, loss 0.474629.
Train: 2018-08-01T00:40:23.013949: step 11800, loss 0.509671.
Test: 2018-08-01T00:40:23.482589: step 11800, loss 0.547755.
Train: 2018-08-01T00:40:24.201173: step 11801, loss 0.650912.
Train: 2018-08-01T00:40:24.357354: step 11802, loss 0.509482.
Train: 2018-08-01T00:40:24.513568: step 11803, loss 0.615746.
Train: 2018-08-01T00:40:24.685433: step 11804, loss 0.473898.
Train: 2018-08-01T00:40:24.841615: step 11805, loss 0.544826.
Train: 2018-08-01T00:40:24.997828: step 11806, loss 0.491413.
Train: 2018-08-01T00:40:25.154043: step 11807, loss 0.616156.
Train: 2018-08-01T00:40:25.341498: step 11808, loss 0.544776.
Train: 2018-08-01T00:40:25.497712: step 11809, loss 0.598431.
Train: 2018-08-01T00:40:25.653955: step 11810, loss 0.562659.
Test: 2018-08-01T00:40:26.122564: step 11810, loss 0.54767.
Train: 2018-08-01T00:40:26.294425: step 11811, loss 0.526855.
Train: 2018-08-01T00:40:26.450614: step 11812, loss 0.491007.
Train: 2018-08-01T00:40:26.606857: step 11813, loss 0.598567.
Train: 2018-08-01T00:40:26.763041: step 11814, loss 0.598597.
Train: 2018-08-01T00:40:26.919253: step 11815, loss 0.526786.
Train: 2018-08-01T00:40:27.091088: step 11816, loss 0.472908.
Train: 2018-08-01T00:40:27.247332: step 11817, loss 0.59867.
Train: 2018-08-01T00:40:27.403542: step 11818, loss 0.598697.
Train: 2018-08-01T00:40:27.559729: step 11819, loss 0.526734.
Train: 2018-08-01T00:40:27.715943: step 11820, loss 0.580707.
Test: 2018-08-01T00:40:28.184583: step 11820, loss 0.547648.
Train: 2018-08-01T00:40:28.340826: step 11821, loss 0.454779.
Train: 2018-08-01T00:40:28.512630: step 11822, loss 0.508697.
Train: 2018-08-01T00:40:28.668874: step 11823, loss 0.59882.
Train: 2018-08-01T00:40:28.825091: step 11824, loss 0.580805.
Train: 2018-08-01T00:40:28.981301: step 11825, loss 0.544698.
Train: 2018-08-01T00:40:29.137515: step 11826, loss 0.707271.
Train: 2018-08-01T00:40:29.293697: step 11827, loss 0.436525.
Train: 2018-08-01T00:40:29.449910: step 11828, loss 0.598794.
Train: 2018-08-01T00:40:29.606158: step 11829, loss 0.544712.
Train: 2018-08-01T00:40:29.777990: step 11830, loss 0.634739.
Test: 2018-08-01T00:40:30.246629: step 11830, loss 0.547649.
Train: 2018-08-01T00:40:30.418465: step 11831, loss 0.526752.
Train: 2018-08-01T00:40:30.574649: step 11832, loss 0.490874.
Train: 2018-08-01T00:40:30.730861: step 11833, loss 0.562685.
Train: 2018-08-01T00:40:30.887074: step 11834, loss 0.652399.
Train: 2018-08-01T00:40:31.043318: step 11835, loss 0.580576.
Train: 2018-08-01T00:40:31.199502: step 11836, loss 0.437495.
Train: 2018-08-01T00:40:31.355739: step 11837, loss 0.616271.
Train: 2018-08-01T00:40:31.511928: step 11838, loss 0.687641.
Train: 2018-08-01T00:40:31.683762: step 11839, loss 0.633841.
Train: 2018-08-01T00:40:31.855623: step 11840, loss 0.509345.
Test: 2018-08-01T00:40:32.324270: step 11840, loss 0.547737.
Train: 2018-08-01T00:40:32.558560: step 11841, loss 0.615646.
Train: 2018-08-01T00:40:32.714772: step 11842, loss 0.509615.
Train: 2018-08-01T00:40:32.886643: step 11843, loss 0.54492.
Train: 2018-08-01T00:40:33.058441: step 11844, loss 0.527376.
Train: 2018-08-01T00:40:33.214654: step 11845, loss 0.527413.
Train: 2018-08-01T00:40:33.370868: step 11846, loss 0.580029.
Train: 2018-08-01T00:40:33.527111: step 11847, loss 0.580007.
Train: 2018-08-01T00:40:33.683325: step 11848, loss 0.492511.
Train: 2018-08-01T00:40:33.839508: step 11849, loss 0.579978.
Train: 2018-08-01T00:40:34.027001: step 11850, loss 0.475062.
Test: 2018-08-01T00:40:34.511256: step 11850, loss 0.547834.
Train: 2018-08-01T00:40:34.667470: step 11851, loss 0.562488.
Train: 2018-08-01T00:40:34.823652: step 11852, loss 0.509958.
Train: 2018-08-01T00:40:34.979897: step 11853, loss 0.509896.
Train: 2018-08-01T00:40:35.136082: step 11854, loss 0.54494.
Train: 2018-08-01T00:40:35.292323: step 11855, loss 0.615315.
Train: 2018-08-01T00:40:35.448531: step 11856, loss 0.509681.
Train: 2018-08-01T00:40:35.620340: step 11857, loss 0.615447.
Train: 2018-08-01T00:40:35.760963: step 11858, loss 0.527241.
Train: 2018-08-01T00:40:35.917177: step 11859, loss 0.703816.
Train: 2018-08-01T00:40:36.073385: step 11860, loss 0.544894.
Test: 2018-08-01T00:40:36.542001: step 11860, loss 0.547771.
Train: 2018-08-01T00:40:36.713865: step 11861, loss 0.615366.
Train: 2018-08-01T00:40:36.870049: step 11862, loss 0.580092.
Train: 2018-08-01T00:40:37.026292: step 11863, loss 0.439673.
Train: 2018-08-01T00:40:37.182508: step 11864, loss 0.474775.
Train: 2018-08-01T00:40:37.354334: step 11865, loss 0.597632.
Train: 2018-08-01T00:40:37.510524: step 11866, loss 0.632791.
Train: 2018-08-01T00:40:37.666762: step 11867, loss 0.38692.
Train: 2018-08-01T00:40:37.822983: step 11868, loss 0.580102.
Train: 2018-08-01T00:40:37.979195: step 11869, loss 0.527295.
Train: 2018-08-01T00:40:38.151029: step 11870, loss 0.633089.
Test: 2018-08-01T00:40:38.619639: step 11870, loss 0.547755.
Train: 2018-08-01T00:40:38.775883: step 11871, loss 0.491949.
Train: 2018-08-01T00:40:38.932095: step 11872, loss 0.562539.
Train: 2018-08-01T00:40:39.088309: step 11873, loss 0.686332.
Train: 2018-08-01T00:40:39.244526: step 11874, loss 0.668536.
Train: 2018-08-01T00:40:39.416357: step 11875, loss 0.527278.
Train: 2018-08-01T00:40:39.588163: step 11876, loss 0.650458.
Train: 2018-08-01T00:40:39.744400: step 11877, loss 0.544958.
Train: 2018-08-01T00:40:39.900614: step 11878, loss 0.579974.
Train: 2018-08-01T00:40:40.056827: step 11879, loss 0.422899.
Train: 2018-08-01T00:40:40.213015: step 11880, loss 0.614789.
Test: 2018-08-01T00:40:40.681681: step 11880, loss 0.547878.
Train: 2018-08-01T00:40:40.853490: step 11881, loss 0.614725.
Train: 2018-08-01T00:40:41.009703: step 11882, loss 0.614621.
Train: 2018-08-01T00:40:41.165918: step 11883, loss 0.579796.
Train: 2018-08-01T00:40:41.322164: step 11884, loss 0.579746.
Train: 2018-08-01T00:40:41.478344: step 11885, loss 0.631465.
Train: 2018-08-01T00:40:41.634558: step 11886, loss 0.493648.
Train: 2018-08-01T00:40:41.790802: step 11887, loss 0.562437.
Train: 2018-08-01T00:40:41.947017: step 11888, loss 0.545306.
Train: 2018-08-01T00:40:42.103229: step 11889, loss 0.54533.
Train: 2018-08-01T00:40:42.259411: step 11890, loss 0.476983.
Test: 2018-08-01T00:40:42.743698: step 11890, loss 0.54812.
Train: 2018-08-01T00:40:42.915535: step 11891, loss 0.476945.
Train: 2018-08-01T00:40:43.071754: step 11892, loss 0.596693.
Train: 2018-08-01T00:40:43.227965: step 11893, loss 0.631018.
Train: 2018-08-01T00:40:43.384149: step 11894, loss 0.47672.
Train: 2018-08-01T00:40:43.556013: step 11895, loss 0.5796.
Train: 2018-08-01T00:40:43.712197: step 11896, loss 0.562436.
Train: 2018-08-01T00:40:43.884031: step 11897, loss 0.699958.
Train: 2018-08-01T00:40:44.040269: step 11898, loss 0.493773.
Train: 2018-08-01T00:40:44.196491: step 11899, loss 0.61392.
Train: 2018-08-01T00:40:44.352701: step 11900, loss 0.408138.
Test: 2018-08-01T00:40:44.836932: step 11900, loss 0.548059.
Train: 2018-08-01T00:40:45.571169: step 11901, loss 0.596773.
Train: 2018-08-01T00:40:45.727381: step 11902, loss 0.51089.
Train: 2018-08-01T00:40:45.899208: step 11903, loss 0.614062.
Train: 2018-08-01T00:40:46.055398: step 11904, loss 0.476356.
Train: 2018-08-01T00:40:46.211635: step 11905, loss 0.579685.
Train: 2018-08-01T00:40:46.383478: step 11906, loss 0.579709.
Train: 2018-08-01T00:40:46.539689: step 11907, loss 0.527874.
Train: 2018-08-01T00:40:46.695906: step 11908, loss 0.545138.
Train: 2018-08-01T00:40:46.852111: step 11909, loss 0.527787.
Train: 2018-08-01T00:40:47.008299: step 11910, loss 0.562452.
Test: 2018-08-01T00:40:47.476969: step 11910, loss 0.547897.
Train: 2018-08-01T00:40:47.633183: step 11911, loss 0.597229.
Train: 2018-08-01T00:40:47.789397: step 11912, loss 0.562459.
Train: 2018-08-01T00:40:47.961225: step 11913, loss 0.666932.
Train: 2018-08-01T00:40:48.117415: step 11914, loss 0.475483.
Train: 2018-08-01T00:40:48.273653: step 11915, loss 0.545058.
Train: 2018-08-01T00:40:48.429842: step 11916, loss 0.59728.
Train: 2018-08-01T00:40:48.586055: step 11917, loss 0.632094.
Train: 2018-08-01T00:40:48.757890: step 11918, loss 0.614621.
Train: 2018-08-01T00:40:48.914103: step 11919, loss 0.579806.
Train: 2018-08-01T00:40:49.070316: step 11920, loss 0.510478.
Test: 2018-08-01T00:40:49.538987: step 11920, loss 0.547952.
Train: 2018-08-01T00:40:49.710791: step 11921, loss 0.527834.
Train: 2018-08-01T00:40:49.867037: step 11922, loss 0.527848.
Train: 2018-08-01T00:40:50.038873: step 11923, loss 0.614336.
Train: 2018-08-01T00:40:50.195086: step 11924, loss 0.631583.
Train: 2018-08-01T00:40:50.351298: step 11925, loss 0.614206.
Train: 2018-08-01T00:40:50.538723: step 11926, loss 0.545219.
Train: 2018-08-01T00:40:50.694969: step 11927, loss 0.54525.
Train: 2018-08-01T00:40:50.851149: step 11928, loss 0.579593.
Train: 2018-08-01T00:40:51.007363: step 11929, loss 0.630966.
Train: 2018-08-01T00:40:51.163607: step 11930, loss 0.596618.
Test: 2018-08-01T00:40:51.632216: step 11930, loss 0.548165.
Train: 2018-08-01T00:40:51.772840: step 11931, loss 0.528348.
Train: 2018-08-01T00:40:51.929022: step 11932, loss 0.528415.
Train: 2018-08-01T00:40:52.085260: step 11933, loss 0.613424.
Train: 2018-08-01T00:40:52.241479: step 11934, loss 0.562447.
Train: 2018-08-01T00:40:52.413284: step 11935, loss 0.61326.
Train: 2018-08-01T00:40:52.569497: step 11936, loss 0.630056.
Train: 2018-08-01T00:40:52.741331: step 11937, loss 0.629867.
Train: 2018-08-01T00:40:52.897545: step 11938, loss 0.545697.
Train: 2018-08-01T00:40:53.053789: step 11939, loss 0.612713.
Train: 2018-08-01T00:40:53.209997: step 11940, loss 0.662605.
Test: 2018-08-01T00:40:53.694233: step 11940, loss 0.548645.
Train: 2018-08-01T00:40:53.850447: step 11941, loss 0.579154.
Train: 2018-08-01T00:40:54.022283: step 11942, loss 0.529515.
Train: 2018-08-01T00:40:54.178525: step 11943, loss 0.595569.
Train: 2018-08-01T00:40:54.334739: step 11944, loss 0.59549.
Train: 2018-08-01T00:40:54.490952: step 11945, loss 0.529929.
Train: 2018-08-01T00:40:54.647166: step 11946, loss 0.562694.
Train: 2018-08-01T00:40:54.803384: step 11947, loss 0.530113.
Train: 2018-08-01T00:40:54.975185: step 11948, loss 0.562726.
Train: 2018-08-01T00:40:55.115801: step 11949, loss 0.595279.
Train: 2018-08-01T00:40:55.271989: step 11950, loss 0.481463.
Test: 2018-08-01T00:40:55.756281: step 11950, loss 0.549115.
Train: 2018-08-01T00:40:55.928112: step 11951, loss 0.579005.
Train: 2018-08-01T00:40:56.084298: step 11952, loss 0.546456.
Train: 2018-08-01T00:40:56.240537: step 11953, loss 0.513849.
Train: 2018-08-01T00:40:56.396756: step 11954, loss 0.644304.
Train: 2018-08-01T00:40:56.552939: step 11955, loss 0.546368.
Train: 2018-08-01T00:40:56.709177: step 11956, loss 0.530003.
Train: 2018-08-01T00:40:56.865396: step 11957, loss 0.660872.
Train: 2018-08-01T00:40:57.052856: step 11958, loss 0.595402.
Train: 2018-08-01T00:40:57.209035: step 11959, loss 0.562678.
Train: 2018-08-01T00:40:57.365279: step 11960, loss 0.579032.
Test: 2018-08-01T00:40:57.818301: step 11960, loss 0.548995.
Train: 2018-08-01T00:40:57.990127: step 11961, loss 0.595377.
Train: 2018-08-01T00:40:58.161968: step 11962, loss 0.660702.
Train: 2018-08-01T00:40:58.318150: step 11963, loss 0.611616.
Train: 2018-08-01T00:40:58.474363: step 11964, loss 0.530221.
Train: 2018-08-01T00:40:58.614987: step 11965, loss 0.595228.
Train: 2018-08-01T00:40:58.786821: step 11966, loss 0.627605.
Train: 2018-08-01T00:40:58.943043: step 11967, loss 0.546643.
Train: 2018-08-01T00:40:59.099248: step 11968, loss 0.466001.
Train: 2018-08-01T00:40:59.271077: step 11969, loss 0.433678.
Train: 2018-08-01T00:40:59.427267: step 11970, loss 0.546605.
Test: 2018-08-01T00:40:59.895936: step 11970, loss 0.549163.
Train: 2018-08-01T00:41:00.067770: step 11971, loss 0.546523.
Train: 2018-08-01T00:41:00.223984: step 11972, loss 0.627864.
Train: 2018-08-01T00:41:00.395789: step 11973, loss 0.579018.
Train: 2018-08-01T00:41:00.552003: step 11974, loss 0.464634.
Train: 2018-08-01T00:41:00.708247: step 11975, loss 0.447889.
Train: 2018-08-01T00:41:00.864429: step 11976, loss 0.644988.
Train: 2018-08-01T00:41:01.020642: step 11977, loss 0.479932.
Train: 2018-08-01T00:41:01.176887: step 11978, loss 0.562546.
Train: 2018-08-01T00:41:01.333101: step 11979, loss 0.495842.
Train: 2018-08-01T00:41:01.504929: step 11980, loss 0.445248.
Test: 2018-08-01T00:41:01.989197: step 11980, loss 0.54835.
Train: 2018-08-01T00:41:02.145409: step 11981, loss 0.562463.
Train: 2018-08-01T00:41:02.301623: step 11982, loss 0.579392.
Train: 2018-08-01T00:41:02.457836: step 11983, loss 0.528373.
Train: 2018-08-01T00:41:02.629667: step 11984, loss 0.68222.
Train: 2018-08-01T00:41:02.785885: step 11985, loss 0.459486.
Train: 2018-08-01T00:41:02.942067: step 11986, loss 0.682987.
Train: 2018-08-01T00:41:03.098281: step 11987, loss 0.57968.
Train: 2018-08-01T00:41:03.254494: step 11988, loss 0.424264.
Train: 2018-08-01T00:41:03.410740: step 11989, loss 0.61441.
Train: 2018-08-01T00:41:03.566921: step 11990, loss 0.493008.
Test: 2018-08-01T00:41:04.035592: step 11990, loss 0.547874.
Train: 2018-08-01T00:41:04.191801: step 11991, loss 0.649481.
Train: 2018-08-01T00:41:04.347989: step 11992, loss 0.614733.
Train: 2018-08-01T00:41:04.504202: step 11993, loss 0.545025.
Train: 2018-08-01T00:41:04.660415: step 11994, loss 0.632203.
Train: 2018-08-01T00:41:04.847902: step 11995, loss 0.527604.
Train: 2018-08-01T00:41:05.004085: step 11996, loss 0.562452.
Train: 2018-08-01T00:41:05.160298: step 11997, loss 0.579869.
Train: 2018-08-01T00:41:05.316512: step 11998, loss 0.510224.
Train: 2018-08-01T00:41:05.472756: step 11999, loss 0.562451.
Train: 2018-08-01T00:41:05.628969: step 12000, loss 0.666949.
Test: 2018-08-01T00:41:06.097609: step 12000, loss 0.547883.
Train: 2018-08-01T00:41:06.863055: step 12001, loss 0.562446.
Train: 2018-08-01T00:41:07.034898: step 12002, loss 0.579814.
Train: 2018-08-01T00:41:07.175483: step 12003, loss 0.493047.
Train: 2018-08-01T00:41:07.331666: step 12004, loss 0.64915.
Train: 2018-08-01T00:41:07.503531: step 12005, loss 0.458533.
Train: 2018-08-01T00:41:07.659744: step 12006, loss 0.510482.
Train: 2018-08-01T00:41:07.815927: step 12007, loss 0.510448.
Train: 2018-08-01T00:41:07.972141: step 12008, loss 0.614494.
Train: 2018-08-01T00:41:08.143975: step 12009, loss 0.527722.
Train: 2018-08-01T00:41:08.315809: step 12010, loss 0.597188.
Test: 2018-08-01T00:41:08.784481: step 12010, loss 0.547892.
Train: 2018-08-01T00:41:08.940663: step 12011, loss 0.666705.
Train: 2018-08-01T00:41:09.096907: step 12012, loss 0.597151.
Train: 2018-08-01T00:41:09.268741: step 12013, loss 0.579764.
Train: 2018-08-01T00:41:09.440579: step 12014, loss 0.510534.
Train: 2018-08-01T00:41:09.596790: step 12015, loss 0.527861.
Train: 2018-08-01T00:41:09.753004: step 12016, loss 0.545151.
Train: 2018-08-01T00:41:09.909217: step 12017, loss 0.648815.
Train: 2018-08-01T00:41:10.081021: step 12018, loss 0.562427.
Train: 2018-08-01T00:41:10.237234: step 12019, loss 0.562426.
Train: 2018-08-01T00:41:10.409070: step 12020, loss 0.59686.
Test: 2018-08-01T00:41:10.862119: step 12020, loss 0.548027.
Train: 2018-08-01T00:41:11.033953: step 12021, loss 0.528038.
Train: 2018-08-01T00:41:11.190169: step 12022, loss 0.682674.
Train: 2018-08-01T00:41:11.361972: step 12023, loss 0.528148.
Train: 2018-08-01T00:41:11.518185: step 12024, loss 0.511097.
Train: 2018-08-01T00:41:11.674398: step 12025, loss 0.545329.
Train: 2018-08-01T00:41:11.830641: step 12026, loss 0.545338.
Train: 2018-08-01T00:41:11.986855: step 12027, loss 0.613678.
Train: 2018-08-01T00:41:12.143069: step 12028, loss 0.579495.
Train: 2018-08-01T00:41:12.299252: step 12029, loss 0.511268.
Train: 2018-08-01T00:41:12.455491: step 12030, loss 0.596527.
Test: 2018-08-01T00:41:12.939727: step 12030, loss 0.548159.
Train: 2018-08-01T00:41:13.095970: step 12031, loss 0.511308.
Train: 2018-08-01T00:41:13.252184: step 12032, loss 0.528342.
Train: 2018-08-01T00:41:13.408397: step 12033, loss 0.579481.
Train: 2018-08-01T00:41:13.580227: step 12034, loss 0.562426.
Train: 2018-08-01T00:41:13.736415: step 12035, loss 0.545359.
Train: 2018-08-01T00:41:13.892628: step 12036, loss 0.562425.
Train: 2018-08-01T00:41:14.048842: step 12037, loss 0.562424.
Train: 2018-08-01T00:41:14.205086: step 12038, loss 0.579517.
Train: 2018-08-01T00:41:14.361304: step 12039, loss 0.511131.
Train: 2018-08-01T00:41:14.517482: step 12040, loss 0.544169.
Test: 2018-08-01T00:41:15.001744: step 12040, loss 0.548077.
Train: 2018-08-01T00:41:15.173609: step 12041, loss 0.562422.
Train: 2018-08-01T00:41:15.329823: step 12042, loss 0.648163.
Train: 2018-08-01T00:41:15.486005: step 12043, loss 0.596708.
Train: 2018-08-01T00:41:15.642249: step 12044, loss 0.459639.
Train: 2018-08-01T00:41:15.814053: step 12045, loss 0.442418.
Train: 2018-08-01T00:41:15.954671: step 12046, loss 0.562422.
Train: 2018-08-01T00:41:16.110890: step 12047, loss 0.614079.
Train: 2018-08-01T00:41:16.267104: step 12048, loss 0.493469.
Train: 2018-08-01T00:41:16.423286: step 12049, loss 0.596971.
Train: 2018-08-01T00:41:16.579530: step 12050, loss 0.510546.
Test: 2018-08-01T00:41:17.048170: step 12050, loss 0.547924.
Train: 2018-08-01T00:41:17.204383: step 12051, loss 0.597083.
Train: 2018-08-01T00:41:17.360566: step 12052, loss 0.458363.
Train: 2018-08-01T00:41:17.516780: step 12053, loss 0.631988.
Train: 2018-08-01T00:41:17.657373: step 12054, loss 0.527631.
Train: 2018-08-01T00:41:17.829231: step 12055, loss 0.527585.
Train: 2018-08-01T00:41:18.001072: step 12056, loss 0.527532.
Train: 2018-08-01T00:41:18.157285: step 12057, loss 0.492478.
Train: 2018-08-01T00:41:18.313493: step 12058, loss 0.650191.
Train: 2018-08-01T00:41:18.469712: step 12059, loss 0.580047.
Train: 2018-08-01T00:41:18.625895: step 12060, loss 0.439459.
Test: 2018-08-01T00:41:19.094565: step 12060, loss 0.547751.
Train: 2018-08-01T00:41:19.250748: step 12061, loss 0.509659.
Train: 2018-08-01T00:41:19.406992: step 12062, loss 0.615493.
Train: 2018-08-01T00:41:19.563200: step 12063, loss 0.562527.
Train: 2018-08-01T00:41:19.735041: step 12064, loss 0.633371.
Train: 2018-08-01T00:41:19.891225: step 12065, loss 0.615671.
Train: 2018-08-01T00:41:20.047470: step 12066, loss 0.580233.
Train: 2018-08-01T00:41:20.219302: step 12067, loss 0.597894.
Train: 2018-08-01T00:41:20.375486: step 12068, loss 0.421237.
Train: 2018-08-01T00:41:20.531729: step 12069, loss 0.580189.
Train: 2018-08-01T00:41:20.687912: step 12070, loss 0.597865.
Test: 2018-08-01T00:41:21.156578: step 12070, loss 0.547727.
Train: 2018-08-01T00:41:21.328418: step 12071, loss 0.544854.
Train: 2018-08-01T00:41:21.484631: step 12072, loss 0.615497.
Train: 2018-08-01T00:41:21.656466: step 12073, loss 0.509581.
Train: 2018-08-01T00:41:21.812682: step 12074, loss 0.456681.
Train: 2018-08-01T00:41:21.953271: step 12075, loss 0.562515.
Train: 2018-08-01T00:41:22.125108: step 12076, loss 0.491838.
Train: 2018-08-01T00:41:22.296944: step 12077, loss 0.562532.
Train: 2018-08-01T00:41:22.453154: step 12078, loss 0.491654.
Train: 2018-08-01T00:41:22.624994: step 12079, loss 0.562557.
Train: 2018-08-01T00:41:22.781172: step 12080, loss 0.526997.
Test: 2018-08-01T00:41:23.249814: step 12080, loss 0.547665.
Train: 2018-08-01T00:41:23.421647: step 12081, loss 0.544767.
Train: 2018-08-01T00:41:23.562273: step 12082, loss 0.544752.
Train: 2018-08-01T00:41:23.718483: step 12083, loss 0.544738.
Train: 2018-08-01T00:41:23.874697: step 12084, loss 0.634284.
Train: 2018-08-01T00:41:24.046526: step 12085, loss 0.526801.
Train: 2018-08-01T00:41:24.202744: step 12086, loss 0.598514.
Train: 2018-08-01T00:41:24.358927: step 12087, loss 0.490914.
Train: 2018-08-01T00:41:24.530787: step 12088, loss 0.598555.
Train: 2018-08-01T00:41:24.671354: step 12089, loss 0.526757.
Train: 2018-08-01T00:41:24.827593: step 12090, loss 0.670422.
Test: 2018-08-01T00:41:25.311830: step 12090, loss 0.54763.
Train: 2018-08-01T00:41:25.483689: step 12091, loss 0.526772.
Train: 2018-08-01T00:41:25.639914: step 12092, loss 0.706076.
Train: 2018-08-01T00:41:25.796093: step 12093, loss 0.526853.
Train: 2018-08-01T00:41:25.967950: step 12094, loss 0.562602.
Train: 2018-08-01T00:41:26.124170: step 12095, loss 0.491321.
Train: 2018-08-01T00:41:26.295998: step 12096, loss 0.615976.
Train: 2018-08-01T00:41:26.452212: step 12097, loss 0.509248.
Train: 2018-08-01T00:41:26.608437: step 12098, loss 0.633581.
Train: 2018-08-01T00:41:26.780236: step 12099, loss 0.562541.
Train: 2018-08-01T00:41:26.936482: step 12100, loss 0.580223.
Test: 2018-08-01T00:41:27.389498: step 12100, loss 0.547726.
Train: 2018-08-01T00:41:28.076807: step 12101, loss 0.703807.
Train: 2018-08-01T00:41:28.233051: step 12102, loss 0.527296.
Train: 2018-08-01T00:41:28.389259: step 12103, loss 0.632668.
Train: 2018-08-01T00:41:28.545480: step 12104, loss 0.562459.
Train: 2018-08-01T00:41:28.701685: step 12105, loss 0.61473.
Train: 2018-08-01T00:41:28.857920: step 12106, loss 0.597148.
Train: 2018-08-01T00:41:29.014089: step 12107, loss 0.631399.
Train: 2018-08-01T00:41:29.170301: step 12108, loss 0.528321.
Train: 2018-08-01T00:41:29.326545: step 12109, loss 0.580387.
Train: 2018-08-01T00:41:29.498379: step 12110, loss 0.596556.
Test: 2018-08-01T00:41:29.967022: step 12110, loss 0.548188.
Train: 2018-08-01T00:41:30.123233: step 12111, loss 0.528446.
Train: 2018-08-01T00:41:30.279446: step 12112, loss 0.528465.
Train: 2018-08-01T00:41:30.435663: step 12113, loss 0.494576.
Train: 2018-08-01T00:41:30.591844: step 12114, loss 0.613292.
Train: 2018-08-01T00:41:30.748056: step 12115, loss 0.511652.
Train: 2018-08-01T00:41:30.904271: step 12116, loss 0.511677.
Train: 2018-08-01T00:41:31.060510: step 12117, loss 0.630151.
Train: 2018-08-01T00:41:31.232342: step 12118, loss 0.545526.
Train: 2018-08-01T00:41:31.372935: step 12119, loss 0.579358.
Train: 2018-08-01T00:41:31.544778: step 12120, loss 0.46101.
Test: 2018-08-01T00:41:32.013384: step 12120, loss 0.548271.
Train: 2018-08-01T00:41:32.185220: step 12121, loss 0.579368.
Train: 2018-08-01T00:41:32.341433: step 12122, loss 0.477752.
Train: 2018-08-01T00:41:32.497646: step 12123, loss 0.511524.
Train: 2018-08-01T00:41:32.653860: step 12124, loss 0.545419.
Train: 2018-08-01T00:41:32.810107: step 12125, loss 0.562428.
Train: 2018-08-01T00:41:32.981938: step 12126, loss 0.596613.
Train: 2018-08-01T00:41:33.122531: step 12127, loss 0.545304.
Train: 2018-08-01T00:41:33.309958: step 12128, loss 0.493828.
Train: 2018-08-01T00:41:33.466170: step 12129, loss 0.613996.
Train: 2018-08-01T00:41:33.622408: step 12130, loss 0.562425.
Test: 2018-08-01T00:41:34.106675: step 12130, loss 0.547991.
Train: 2018-08-01T00:41:34.262858: step 12131, loss 0.493472.
Train: 2018-08-01T00:41:34.434718: step 12132, loss 0.52788.
Train: 2018-08-01T00:41:34.575285: step 12133, loss 0.579748.
Train: 2018-08-01T00:41:34.731527: step 12134, loss 0.510397.
Train: 2018-08-01T00:41:34.887742: step 12135, loss 0.510283.
Train: 2018-08-01T00:41:35.043926: step 12136, loss 0.545018.
Train: 2018-08-01T00:41:35.200169: step 12137, loss 0.544982.
Train: 2018-08-01T00:41:35.356352: step 12138, loss 0.579998.
Train: 2018-08-01T00:41:35.528187: step 12139, loss 0.562484.
Train: 2018-08-01T00:41:35.668778: step 12140, loss 0.63285.
Test: 2018-08-01T00:41:36.121828: step 12140, loss 0.54776.
Train: 2018-08-01T00:41:36.278012: step 12141, loss 0.668089.
Train: 2018-08-01T00:41:36.434226: step 12142, loss 0.474581.
Train: 2018-08-01T00:41:36.590438: step 12143, loss 0.544906.
Train: 2018-08-01T00:41:36.746652: step 12144, loss 0.632859.
Train: 2018-08-01T00:41:36.902866: step 12145, loss 0.54491.
Train: 2018-08-01T00:41:37.059112: step 12146, loss 0.527344.
Train: 2018-08-01T00:41:37.215293: step 12147, loss 0.650339.
Train: 2018-08-01T00:41:37.371506: step 12148, loss 0.544931.
Train: 2018-08-01T00:41:37.527719: step 12149, loss 0.562474.
Train: 2018-08-01T00:41:37.683967: step 12150, loss 0.615015.
Test: 2018-08-01T00:41:38.168225: step 12150, loss 0.547818.
Train: 2018-08-01T00:41:38.324406: step 12151, loss 0.527488.
Train: 2018-08-01T00:41:38.480645: step 12152, loss 0.614864.
Train: 2018-08-01T00:41:38.636833: step 12153, loss 0.56245.
Train: 2018-08-01T00:41:38.824321: step 12154, loss 0.510208.
Train: 2018-08-01T00:41:38.980504: step 12155, loss 0.510245.
Train: 2018-08-01T00:41:39.136718: step 12156, loss 0.597238.
Train: 2018-08-01T00:41:39.292931: step 12157, loss 0.510273.
Train: 2018-08-01T00:41:39.433556: step 12158, loss 0.527656.
Train: 2018-08-01T00:41:39.589760: step 12159, loss 0.440628.
Train: 2018-08-01T00:41:39.745950: step 12160, loss 0.510134.
Test: 2018-08-01T00:41:40.230242: step 12160, loss 0.54782.
Train: 2018-08-01T00:41:40.386455: step 12161, loss 0.562459.
Train: 2018-08-01T00:41:40.542671: step 12162, loss 0.615034.
Train: 2018-08-01T00:41:40.698852: step 12163, loss 0.615105.
Train: 2018-08-01T00:41:40.855089: step 12164, loss 0.597576.
Train: 2018-08-01T00:41:41.026899: step 12165, loss 0.667749.
Train: 2018-08-01T00:41:41.183146: step 12166, loss 0.579984.
Train: 2018-08-01T00:41:41.339356: step 12167, loss 0.475032.
Train: 2018-08-01T00:41:41.495570: step 12168, loss 0.510027.
Train: 2018-08-01T00:41:41.667408: step 12169, loss 0.562458.
Train: 2018-08-01T00:41:41.823589: step 12170, loss 0.684831.
Test: 2018-08-01T00:41:42.292258: step 12170, loss 0.547836.
Train: 2018-08-01T00:41:42.448472: step 12171, loss 0.544997.
Train: 2018-08-01T00:41:42.604656: step 12172, loss 0.614744.
Train: 2018-08-01T00:41:42.760899: step 12173, loss 0.64944.
Train: 2018-08-01T00:41:42.917113: step 12174, loss 0.562432.
Train: 2018-08-01T00:41:43.073295: step 12175, loss 0.527818.
Train: 2018-08-01T00:41:43.260751: step 12176, loss 0.510611.
Train: 2018-08-01T00:41:43.416966: step 12177, loss 0.458909.
Train: 2018-08-01T00:41:43.573204: step 12178, loss 0.510643.
Train: 2018-08-01T00:41:43.745044: step 12179, loss 0.596978.
Train: 2018-08-01T00:41:43.901257: step 12180, loss 0.648852.
Test: 2018-08-01T00:41:44.369867: step 12180, loss 0.547958.
Train: 2018-08-01T00:41:44.526110: step 12181, loss 0.527877.
Train: 2018-08-01T00:41:44.682327: step 12182, loss 0.510617.
Train: 2018-08-01T00:41:44.838537: step 12183, loss 0.562422.
Train: 2018-08-01T00:41:44.994721: step 12184, loss 0.458725.
Train: 2018-08-01T00:41:45.150964: step 12185, loss 0.579739.
Train: 2018-08-01T00:41:45.307182: step 12186, loss 0.562429.
Train: 2018-08-01T00:41:45.479017: step 12187, loss 0.683916.
Train: 2018-08-01T00:41:45.635195: step 12188, loss 0.597117.
Train: 2018-08-01T00:41:45.791409: step 12189, loss 0.545102.
Train: 2018-08-01T00:41:45.947622: step 12190, loss 0.61436.
Test: 2018-08-01T00:41:46.416291: step 12190, loss 0.547947.
Train: 2018-08-01T00:41:46.572506: step 12191, loss 0.545135.
Train: 2018-08-01T00:41:46.728720: step 12192, loss 0.596958.
Train: 2018-08-01T00:41:46.884902: step 12193, loss 0.631392.
Train: 2018-08-01T00:41:47.041149: step 12194, loss 0.476395.
Train: 2018-08-01T00:41:47.197360: step 12195, loss 0.528038.
Train: 2018-08-01T00:41:47.353569: step 12196, loss 0.493681.
Train: 2018-08-01T00:41:47.509796: step 12197, loss 0.631195.
Train: 2018-08-01T00:41:47.681624: step 12198, loss 0.648358.
Train: 2018-08-01T00:41:47.853450: step 12199, loss 0.52809.
Train: 2018-08-01T00:41:48.009671: step 12200, loss 0.579562.
Test: 2018-08-01T00:41:48.474260: step 12200, loss 0.548072.
Train: 2018-08-01T00:41:49.208457: step 12201, loss 0.545286.
Train: 2018-08-01T00:41:49.364671: step 12202, loss 0.562416.
Train: 2018-08-01T00:41:49.520884: step 12203, loss 0.613736.
Train: 2018-08-01T00:41:49.677103: step 12204, loss 0.596587.
Train: 2018-08-01T00:41:49.848939: step 12205, loss 0.630651.
Train: 2018-08-01T00:41:50.005152: step 12206, loss 0.460317.
Train: 2018-08-01T00:41:50.161335: step 12207, loss 0.596436.
Train: 2018-08-01T00:41:50.317579: step 12208, loss 0.579414.
Train: 2018-08-01T00:41:50.473792: step 12209, loss 0.596364.
Train: 2018-08-01T00:41:50.629975: step 12210, loss 0.562432.
Test: 2018-08-01T00:41:51.098646: step 12210, loss 0.548267.
Train: 2018-08-01T00:41:51.254828: step 12211, loss 0.596277.
Train: 2018-08-01T00:41:51.411043: step 12212, loss 0.511761.
Train: 2018-08-01T00:41:51.567255: step 12213, loss 0.562444.
Train: 2018-08-01T00:41:51.723469: step 12214, loss 0.528701.
Train: 2018-08-01T00:41:51.879713: step 12215, loss 0.613063.
Train: 2018-08-01T00:41:52.051518: step 12216, loss 0.545586.
Train: 2018-08-01T00:41:52.207731: step 12217, loss 0.562449.
Train: 2018-08-01T00:41:52.363976: step 12218, loss 0.646716.
Train: 2018-08-01T00:41:52.520188: step 12219, loss 0.579286.
Train: 2018-08-01T00:41:52.676402: step 12220, loss 0.612884.
Test: 2018-08-01T00:41:53.160667: step 12220, loss 0.548423.
Train: 2018-08-01T00:41:53.316871: step 12221, loss 0.579246.
Train: 2018-08-01T00:41:53.473090: step 12222, loss 0.612711.
Train: 2018-08-01T00:41:53.629303: step 12223, loss 0.545788.
Train: 2018-08-01T00:41:53.785516: step 12224, loss 0.612527.
Train: 2018-08-01T00:41:53.941725: step 12225, loss 0.595792.
Train: 2018-08-01T00:41:54.097948: step 12226, loss 0.512746.
Train: 2018-08-01T00:41:54.254152: step 12227, loss 0.529397.
Train: 2018-08-01T00:41:54.410375: step 12228, loss 0.562549.
Train: 2018-08-01T00:41:54.582205: step 12229, loss 0.47977.
Train: 2018-08-01T00:41:54.722797: step 12230, loss 0.579118.
Test: 2018-08-01T00:41:55.191409: step 12230, loss 0.548653.
Train: 2018-08-01T00:41:55.363242: step 12231, loss 0.47962.
Train: 2018-08-01T00:41:55.519471: step 12232, loss 0.64561.
Train: 2018-08-01T00:41:55.675699: step 12233, loss 0.529266.
Train: 2018-08-01T00:41:55.831882: step 12234, loss 0.64575.
Train: 2018-08-01T00:41:55.988126: step 12235, loss 0.529221.
Train: 2018-08-01T00:41:56.144309: step 12236, loss 0.62913.
Train: 2018-08-01T00:41:56.300553: step 12237, loss 0.645754.
Train: 2018-08-01T00:41:56.472387: step 12238, loss 0.64564.
Train: 2018-08-01T00:41:56.612980: step 12239, loss 0.612288.
Train: 2018-08-01T00:41:56.784784: step 12240, loss 0.579098.
Test: 2018-08-01T00:41:57.253454: step 12240, loss 0.548776.
Train: 2018-08-01T00:41:57.425261: step 12241, loss 0.529604.
Train: 2018-08-01T00:41:57.581472: step 12242, loss 0.579061.
Train: 2018-08-01T00:41:57.737685: step 12243, loss 0.59548.
Train: 2018-08-01T00:41:57.878302: step 12244, loss 0.529835.
Train: 2018-08-01T00:41:58.034492: step 12245, loss 0.579027.
Train: 2018-08-01T00:41:58.190736: step 12246, loss 0.546292.
Train: 2018-08-01T00:41:58.331328: step 12247, loss 0.497244.
Train: 2018-08-01T00:41:58.503134: step 12248, loss 0.677208.
Train: 2018-08-01T00:41:58.674991: step 12249, loss 0.579014.
Train: 2018-08-01T00:41:58.831210: step 12250, loss 0.562677.
Test: 2018-08-01T00:41:59.299850: step 12250, loss 0.549019.
Train: 2018-08-01T00:41:59.456064: step 12251, loss 0.562684.
Train: 2018-08-01T00:41:59.612288: step 12252, loss 0.546379.
Train: 2018-08-01T00:41:59.784082: step 12253, loss 0.497452.
Train: 2018-08-01T00:41:59.940325: step 12254, loss 0.562679.
Train: 2018-08-01T00:42:00.096539: step 12255, loss 0.562666.
Train: 2018-08-01T00:42:00.252722: step 12256, loss 0.513554.
Train: 2018-08-01T00:42:00.408935: step 12257, loss 0.546235.
Train: 2018-08-01T00:42:00.565149: step 12258, loss 0.595484.
Train: 2018-08-01T00:42:00.721363: step 12259, loss 0.727211.
Train: 2018-08-01T00:42:00.893232: step 12260, loss 0.529715.
Test: 2018-08-01T00:42:01.361868: step 12260, loss 0.54884.
Train: 2018-08-01T00:42:01.518075: step 12261, loss 0.463949.
Train: 2018-08-01T00:42:01.674264: step 12262, loss 0.529662.
Train: 2018-08-01T00:42:01.830478: step 12263, loss 0.513082.
Train: 2018-08-01T00:42:02.002313: step 12264, loss 0.512932.
Train: 2018-08-01T00:42:02.142904: step 12265, loss 0.678696.
Train: 2018-08-01T00:42:02.299149: step 12266, loss 0.496063.
Train: 2018-08-01T00:42:02.470977: step 12267, loss 0.529206.
Train: 2018-08-01T00:42:02.627197: step 12268, loss 0.529105.
Train: 2018-08-01T00:42:02.783381: step 12269, loss 0.57922.
Train: 2018-08-01T00:42:02.955248: step 12270, loss 0.545682.
Test: 2018-08-01T00:42:03.423885: step 12270, loss 0.548365.
Train: 2018-08-01T00:42:03.580067: step 12271, loss 0.579279.
Train: 2018-08-01T00:42:03.736311: step 12272, loss 0.579305.
Train: 2018-08-01T00:42:03.892494: step 12273, loss 0.562439.
Train: 2018-08-01T00:42:04.048723: step 12274, loss 0.494782.
Train: 2018-08-01T00:42:04.220543: step 12275, loss 0.545474.
Train: 2018-08-01T00:42:04.376758: step 12276, loss 0.613405.
Train: 2018-08-01T00:42:04.517378: step 12277, loss 0.613478.
Train: 2018-08-01T00:42:04.673592: step 12278, loss 0.562417.
Train: 2018-08-01T00:42:04.829800: step 12279, loss 0.528334.
Train: 2018-08-01T00:42:04.986013: step 12280, loss 0.596533.
Test: 2018-08-01T00:42:05.470250: step 12280, loss 0.548122.
Train: 2018-08-01T00:42:05.626494: step 12281, loss 0.511213.
Train: 2018-08-01T00:42:05.782676: step 12282, loss 0.562413.
Train: 2018-08-01T00:42:05.938915: step 12283, loss 0.596622.
Train: 2018-08-01T00:42:06.095135: step 12284, loss 0.545298.
Train: 2018-08-01T00:42:06.251351: step 12285, loss 0.493911.
Train: 2018-08-01T00:42:06.407566: step 12286, loss 0.528107.
Train: 2018-08-01T00:42:06.579365: step 12287, loss 0.579595.
Train: 2018-08-01T00:42:06.735609: step 12288, loss 0.579621.
Train: 2018-08-01T00:42:06.891823: step 12289, loss 0.476275.
Train: 2018-08-01T00:42:07.048036: step 12290, loss 0.614208.
Test: 2018-08-01T00:42:07.516646: step 12290, loss 0.547943.
Train: 2018-08-01T00:42:07.672859: step 12291, loss 0.441425.
Train: 2018-08-01T00:42:07.829074: step 12292, loss 0.423774.
Train: 2018-08-01T00:42:07.985319: step 12293, loss 0.545029.
Train: 2018-08-01T00:42:08.141533: step 12294, loss 0.632347.
Train: 2018-08-01T00:42:08.297713: step 12295, loss 0.562461.
Train: 2018-08-01T00:42:08.469550: step 12296, loss 0.492234.
Train: 2018-08-01T00:42:08.625793: step 12297, loss 0.509658.
Train: 2018-08-01T00:42:08.781974: step 12298, loss 0.456508.
Train: 2018-08-01T00:42:08.938214: step 12299, loss 0.509318.
Train: 2018-08-01T00:42:09.110058: step 12300, loss 0.509125.
Test: 2018-08-01T00:42:09.578693: step 12300, loss 0.547633.
Train: 2018-08-01T00:42:10.281653: step 12301, loss 0.491032.
Train: 2018-08-01T00:42:10.437836: step 12302, loss 0.598634.
Train: 2018-08-01T00:42:10.594052: step 12303, loss 0.508568.
Train: 2018-08-01T00:42:10.765910: step 12304, loss 0.562761.
Train: 2018-08-01T00:42:10.922098: step 12305, loss 0.671862.
Train: 2018-08-01T00:42:11.078343: step 12306, loss 0.526421.
Train: 2018-08-01T00:42:11.234555: step 12307, loss 0.708686.
Train: 2018-08-01T00:42:11.390763: step 12308, loss 0.54462.
Train: 2018-08-01T00:42:11.546982: step 12309, loss 0.544621.
Train: 2018-08-01T00:42:11.703178: step 12310, loss 0.617436.
Test: 2018-08-01T00:42:12.171832: step 12310, loss 0.547584.
Train: 2018-08-01T00:42:12.328049: step 12311, loss 0.544627.
Train: 2018-08-01T00:42:12.484263: step 12312, loss 0.562795.
Train: 2018-08-01T00:42:12.640447: step 12313, loss 0.544637.
Train: 2018-08-01T00:42:12.796695: step 12314, loss 0.580893.
Train: 2018-08-01T00:42:12.952903: step 12315, loss 0.725685.
Train: 2018-08-01T00:42:13.109117: step 12316, loss 0.56271.
Train: 2018-08-01T00:42:13.265333: step 12317, loss 0.616637.
Train: 2018-08-01T00:42:13.421513: step 12318, loss 0.526788.
Train: 2018-08-01T00:42:13.577758: step 12319, loss 0.544734.
Train: 2018-08-01T00:42:13.733971: step 12320, loss 0.544755.
Test: 2018-08-01T00:42:14.202581: step 12320, loss 0.547667.
Train: 2018-08-01T00:42:14.374445: step 12321, loss 0.615914.
Train: 2018-08-01T00:42:14.515007: step 12322, loss 0.491597.
Train: 2018-08-01T00:42:14.686841: step 12323, loss 0.544819.
Train: 2018-08-01T00:42:14.843086: step 12324, loss 0.509474.
Train: 2018-08-01T00:42:15.046163: step 12325, loss 0.509504.
Train: 2018-08-01T00:42:15.202347: step 12326, loss 0.491835.
Train: 2018-08-01T00:42:15.358590: step 12327, loss 0.421049.
Train: 2018-08-01T00:42:15.561667: step 12328, loss 0.509351.
Train: 2018-08-01T00:42:15.717881: step 12329, loss 0.527001.
Train: 2018-08-01T00:42:15.889685: step 12330, loss 0.598239.
Test: 2018-08-01T00:42:16.358356: step 12330, loss 0.547641.
Train: 2018-08-01T00:42:16.514539: step 12331, loss 0.544735.
Train: 2018-08-01T00:42:16.670752: step 12332, loss 0.580518.
Train: 2018-08-01T00:42:16.826965: step 12333, loss 0.688098.
Train: 2018-08-01T00:42:16.983180: step 12334, loss 0.544713.
Train: 2018-08-01T00:42:17.139392: step 12335, loss 0.598442.
Train: 2018-08-01T00:42:17.311252: step 12336, loss 0.544723.
Train: 2018-08-01T00:42:17.467471: step 12337, loss 0.652009.
Train: 2018-08-01T00:42:17.623685: step 12338, loss 0.56259.
Train: 2018-08-01T00:42:17.779897: step 12339, loss 0.633828.
Train: 2018-08-01T00:42:17.936082: step 12340, loss 0.704679.
Test: 2018-08-01T00:42:18.404721: step 12340, loss 0.547705.
Train: 2018-08-01T00:42:18.560965: step 12341, loss 0.63799.
Train: 2018-08-01T00:42:18.717178: step 12342, loss 0.597686.
Train: 2018-08-01T00:42:18.873386: step 12343, loss 0.597481.
Train: 2018-08-01T00:42:19.029610: step 12344, loss 0.52759.
Train: 2018-08-01T00:42:19.185819: step 12345, loss 0.545073.
Train: 2018-08-01T00:42:19.357624: step 12346, loss 0.527841.
Train: 2018-08-01T00:42:19.513836: step 12347, loss 0.596889.
Train: 2018-08-01T00:42:19.670051: step 12348, loss 0.562409.
Train: 2018-08-01T00:42:19.826263: step 12349, loss 0.682389.
Train: 2018-08-01T00:42:19.982507: step 12350, loss 0.562411.
Test: 2018-08-01T00:42:20.466738: step 12350, loss 0.548176.
Train: 2018-08-01T00:42:20.622976: step 12351, loss 0.579423.
Train: 2018-08-01T00:42:20.779199: step 12352, loss 0.579371.
Train: 2018-08-01T00:42:20.935379: step 12353, loss 0.562436.
Train: 2018-08-01T00:42:21.091593: step 12354, loss 0.511937.
Train: 2018-08-01T00:42:21.247830: step 12355, loss 0.629672.
Train: 2018-08-01T00:42:21.404048: step 12356, loss 0.54571.
Train: 2018-08-01T00:42:21.560258: step 12357, loss 0.529032.
Train: 2018-08-01T00:42:21.732068: step 12358, loss 0.529084.
Train: 2018-08-01T00:42:21.888311: step 12359, loss 0.545799.
Train: 2018-08-01T00:42:22.044524: step 12360, loss 0.612557.
Test: 2018-08-01T00:42:22.513164: step 12360, loss 0.548535.
Train: 2018-08-01T00:42:22.669375: step 12361, loss 0.562498.
Train: 2018-08-01T00:42:22.841219: step 12362, loss 0.579165.
Train: 2018-08-01T00:42:22.997426: step 12363, loss 0.512556.
Train: 2018-08-01T00:42:23.169230: step 12364, loss 0.579159.
Train: 2018-08-01T00:42:23.325469: step 12365, loss 0.729033.
Train: 2018-08-01T00:42:23.481683: step 12366, loss 0.545908.
Train: 2018-08-01T00:42:23.637900: step 12367, loss 0.446447.
Train: 2018-08-01T00:42:23.794111: step 12368, loss 0.545945.
Train: 2018-08-01T00:42:23.950333: step 12369, loss 0.479545.
Train: 2018-08-01T00:42:24.106511: step 12370, loss 0.745413.
Test: 2018-08-01T00:42:24.575175: step 12370, loss 0.548612.
Train: 2018-08-01T00:42:24.731364: step 12371, loss 0.545911.
Train: 2018-08-01T00:42:24.887616: step 12372, loss 0.52932.
Train: 2018-08-01T00:42:25.043816: step 12373, loss 0.662157.
Train: 2018-08-01T00:42:25.200036: step 12374, loss 0.562534.
Train: 2018-08-01T00:42:25.356249: step 12375, loss 0.545973.
Train: 2018-08-01T00:42:25.512433: step 12376, loss 0.661901.
Train: 2018-08-01T00:42:25.668670: step 12377, loss 0.529502.
Train: 2018-08-01T00:42:25.824883: step 12378, loss 0.628614.
Train: 2018-08-01T00:42:25.981110: step 12379, loss 0.612029.
Train: 2018-08-01T00:42:26.137286: step 12380, loss 0.529714.
Test: 2018-08-01T00:42:26.605957: step 12380, loss 0.548865.
Train: 2018-08-01T00:42:26.777760: step 12381, loss 0.628304.
Train: 2018-08-01T00:42:26.933974: step 12382, loss 0.579024.
Train: 2018-08-01T00:42:27.090241: step 12383, loss 0.644431.
Train: 2018-08-01T00:42:27.246431: step 12384, loss 0.595302.
Train: 2018-08-01T00:42:27.402644: step 12385, loss 0.62776.
Train: 2018-08-01T00:42:27.558858: step 12386, loss 0.56276.
Train: 2018-08-01T00:42:27.715071: step 12387, loss 0.562796.
Train: 2018-08-01T00:42:27.871284: step 12388, loss 0.514478.
Train: 2018-08-01T00:42:28.027497: step 12389, loss 0.514556.
Train: 2018-08-01T00:42:28.183681: step 12390, loss 0.611126.
Test: 2018-08-01T00:42:28.652347: step 12390, loss 0.549389.
Train: 2018-08-01T00:42:28.808565: step 12391, loss 0.498529.
Train: 2018-08-01T00:42:28.964779: step 12392, loss 0.562848.
Train: 2018-08-01T00:42:29.120992: step 12393, loss 0.562838.
Train: 2018-08-01T00:42:29.277216: step 12394, loss 0.530593.
Train: 2018-08-01T00:42:29.433426: step 12395, loss 0.530526.
Train: 2018-08-01T00:42:29.589638: step 12396, loss 0.465739.
Train: 2018-08-01T00:42:29.745815: step 12397, loss 0.449124.
Train: 2018-08-01T00:42:29.902058: step 12398, loss 0.611622.
Train: 2018-08-01T00:42:30.058242: step 12399, loss 0.595397.
Train: 2018-08-01T00:42:30.214486: step 12400, loss 0.611902.
Test: 2018-08-01T00:42:30.667506: step 12400, loss 0.548801.
Train: 2018-08-01T00:42:31.370465: step 12401, loss 0.595526.
Train: 2018-08-01T00:42:31.542271: step 12402, loss 0.645054.
Train: 2018-08-01T00:42:31.698515: step 12403, loss 0.463558.
Train: 2018-08-01T00:42:31.854696: step 12404, loss 0.678301.
Train: 2018-08-01T00:42:32.026531: step 12405, loss 0.661782.
Train: 2018-08-01T00:42:32.182744: step 12406, loss 0.463455.
Train: 2018-08-01T00:42:32.323367: step 12407, loss 0.595614.
Train: 2018-08-01T00:42:32.495202: step 12408, loss 0.612144.
Train: 2018-08-01T00:42:32.651385: step 12409, loss 0.479965.
Train: 2018-08-01T00:42:32.807598: step 12410, loss 0.529489.
Test: 2018-08-01T00:42:33.276239: step 12410, loss 0.548681.
Train: 2018-08-01T00:42:33.494967: step 12411, loss 0.695.
Train: 2018-08-01T00:42:33.666797: step 12412, loss 0.463268.
Train: 2018-08-01T00:42:33.838632: step 12413, loss 0.579106.
Train: 2018-08-01T00:42:33.994850: step 12414, loss 0.545958.
Train: 2018-08-01T00:42:34.151068: step 12415, loss 0.529337.
Train: 2018-08-01T00:42:34.307272: step 12416, loss 0.545896.
Train: 2018-08-01T00:42:34.463492: step 12417, loss 0.629106.
Train: 2018-08-01T00:42:34.635320: step 12418, loss 0.612486.
Train: 2018-08-01T00:42:34.791536: step 12419, loss 0.612486.
Train: 2018-08-01T00:42:34.947722: step 12420, loss 0.462599.
Test: 2018-08-01T00:42:35.432008: step 12420, loss 0.548542.
Train: 2018-08-01T00:42:35.572607: step 12421, loss 0.562499.
Train: 2018-08-01T00:42:35.744436: step 12422, loss 0.49576.
Train: 2018-08-01T00:42:35.900660: step 12423, loss 0.462191.
Train: 2018-08-01T00:42:36.056862: step 12424, loss 0.629541.
Train: 2018-08-01T00:42:36.213051: step 12425, loss 0.562454.
Train: 2018-08-01T00:42:36.369291: step 12426, loss 0.562446.
Train: 2018-08-01T00:42:36.525477: step 12427, loss 0.596167.
Train: 2018-08-01T00:42:36.681716: step 12428, loss 0.596202.
Train: 2018-08-01T00:42:36.837929: step 12429, loss 0.545539.
Train: 2018-08-01T00:42:36.994119: step 12430, loss 0.545522.
Test: 2018-08-01T00:42:37.462758: step 12430, loss 0.548253.
Train: 2018-08-01T00:42:37.619002: step 12431, loss 0.562427.
Train: 2018-08-01T00:42:37.775186: step 12432, loss 0.52854.
Train: 2018-08-01T00:42:37.931428: step 12433, loss 0.528489.
Train: 2018-08-01T00:42:38.103265: step 12434, loss 0.630397.
Train: 2018-08-01T00:42:38.275102: step 12435, loss 0.528401.
Train: 2018-08-01T00:42:38.431318: step 12436, loss 0.562412.
Train: 2018-08-01T00:42:38.587525: step 12437, loss 0.528326.
Train: 2018-08-01T00:42:38.759329: step 12438, loss 0.460011.
Train: 2018-08-01T00:42:38.899956: step 12439, loss 0.630855.
Train: 2018-08-01T00:42:39.056136: step 12440, loss 0.562406.
Test: 2018-08-01T00:42:39.524809: step 12440, loss 0.548036.
Train: 2018-08-01T00:42:39.681019: step 12441, loss 0.442282.
Train: 2018-08-01T00:42:39.852853: step 12442, loss 0.614034.
Train: 2018-08-01T00:42:39.993415: step 12443, loss 0.510686.
Train: 2018-08-01T00:42:40.149664: step 12444, loss 0.562411.
Train: 2018-08-01T00:42:40.321465: step 12445, loss 0.475831.
Train: 2018-08-01T00:42:40.462081: step 12446, loss 0.579792.
Train: 2018-08-01T00:42:40.618269: step 12447, loss 0.475376.
Train: 2018-08-01T00:42:40.774508: step 12448, loss 0.579911.
Train: 2018-08-01T00:42:40.930727: step 12449, loss 0.54494.
Train: 2018-08-01T00:42:41.086911: step 12450, loss 0.474671.
Test: 2018-08-01T00:42:41.555550: step 12450, loss 0.547733.
Train: 2018-08-01T00:42:41.727415: step 12451, loss 0.562487.
Train: 2018-08-01T00:42:41.883630: step 12452, loss 0.562506.
Train: 2018-08-01T00:42:42.024224: step 12453, loss 0.473948.
Train: 2018-08-01T00:42:42.196055: step 12454, loss 0.527002.
Train: 2018-08-01T00:42:42.336617: step 12455, loss 0.598247.
Train: 2018-08-01T00:42:42.508452: step 12456, loss 0.544726.
Train: 2018-08-01T00:42:42.664665: step 12457, loss 0.598461.
Train: 2018-08-01T00:42:42.820903: step 12458, loss 0.634417.
Train: 2018-08-01T00:42:42.977123: step 12459, loss 0.63444.
Train: 2018-08-01T00:42:43.133305: step 12460, loss 0.419155.
Test: 2018-08-01T00:42:43.617597: step 12460, loss 0.547613.
Train: 2018-08-01T00:42:43.789427: step 12461, loss 0.652408.
Train: 2018-08-01T00:42:43.945615: step 12462, loss 0.490861.
Train: 2018-08-01T00:42:44.101829: step 12463, loss 0.616505.
Train: 2018-08-01T00:42:44.258042: step 12464, loss 0.562642.
Train: 2018-08-01T00:42:44.414285: step 12465, loss 0.562636.
Train: 2018-08-01T00:42:44.570500: step 12466, loss 0.473007.
Train: 2018-08-01T00:42:44.742304: step 12467, loss 0.544702.
Train: 2018-08-01T00:42:44.898518: step 12468, loss 0.580581.
Train: 2018-08-01T00:42:45.054761: step 12469, loss 0.472926.
Train: 2018-08-01T00:42:45.210969: step 12470, loss 0.508766.
Test: 2018-08-01T00:42:45.679615: step 12470, loss 0.547605.
Train: 2018-08-01T00:42:45.851444: step 12471, loss 0.616635.
Train: 2018-08-01T00:42:46.007665: step 12472, loss 0.544676.
Train: 2018-08-01T00:42:46.179467: step 12473, loss 0.400606.
Train: 2018-08-01T00:42:46.335711: step 12474, loss 0.490506.
Train: 2018-08-01T00:42:46.491924: step 12475, loss 0.544643.
Train: 2018-08-01T00:42:46.648142: step 12476, loss 0.59908.
Train: 2018-08-01T00:42:46.804359: step 12477, loss 0.617351.
Train: 2018-08-01T00:42:46.976186: step 12478, loss 0.58101.
Train: 2018-08-01T00:42:47.132399: step 12479, loss 0.544618.
Train: 2018-08-01T00:42:47.288613: step 12480, loss 0.61744.
Test: 2018-08-01T00:42:47.757253: step 12480, loss 0.547578.
Train: 2018-08-01T00:42:47.929086: step 12481, loss 0.599205.
Train: 2018-08-01T00:42:48.085271: step 12482, loss 0.526449.
Train: 2018-08-01T00:42:48.241509: step 12483, loss 0.708076.
Train: 2018-08-01T00:42:48.413349: step 12484, loss 0.671434.
Train: 2018-08-01T00:42:48.569533: step 12485, loss 0.580748.
Train: 2018-08-01T00:42:48.725776: step 12486, loss 0.544685.
Train: 2018-08-01T00:42:48.881984: step 12487, loss 0.634278.
Train: 2018-08-01T00:42:49.053794: step 12488, loss 0.580424.
Train: 2018-08-01T00:42:49.194422: step 12489, loss 0.509242.
Train: 2018-08-01T00:42:49.350599: step 12490, loss 0.456239.
Test: 2018-08-01T00:42:49.819272: step 12490, loss 0.547701.
Train: 2018-08-01T00:42:49.975486: step 12491, loss 0.527137.
Train: 2018-08-01T00:42:50.147318: step 12492, loss 0.633185.
Train: 2018-08-01T00:42:50.303526: step 12493, loss 0.562492.
Train: 2018-08-01T00:42:50.459746: step 12494, loss 0.509668.
Train: 2018-08-01T00:42:50.600308: step 12495, loss 0.61527.
Train: 2018-08-01T00:42:50.772171: step 12496, loss 0.58003.
Train: 2018-08-01T00:42:50.928356: step 12497, loss 0.422255.
Train: 2018-08-01T00:42:51.084604: step 12498, loss 0.632569.
Train: 2018-08-01T00:42:51.272065: step 12499, loss 0.457379.
Train: 2018-08-01T00:42:51.428240: step 12500, loss 0.685113.
Test: 2018-08-01T00:42:51.896879: step 12500, loss 0.547798.
Train: 2018-08-01T00:42:52.553005: step 12501, loss 0.562453.
Train: 2018-08-01T00:42:52.709218: step 12502, loss 0.527485.
Train: 2018-08-01T00:42:52.865432: step 12503, loss 0.562447.
Train: 2018-08-01T00:42:53.021614: step 12504, loss 0.579905.
Train: 2018-08-01T00:42:53.177828: step 12505, loss 0.667118.
Train: 2018-08-01T00:42:53.334074: step 12506, loss 0.545026.
Train: 2018-08-01T00:42:53.521498: step 12507, loss 0.545051.
Train: 2018-08-01T00:42:53.677711: step 12508, loss 0.440954.
Train: 2018-08-01T00:42:53.833956: step 12509, loss 0.475634.
Train: 2018-08-01T00:42:53.990169: step 12510, loss 0.56243.
Test: 2018-08-01T00:42:54.458780: step 12510, loss 0.54786.
Train: 2018-08-01T00:42:54.630645: step 12511, loss 0.492819.
Train: 2018-08-01T00:42:54.786827: step 12512, loss 0.475251.
Train: 2018-08-01T00:42:54.927449: step 12513, loss 0.632403.
Train: 2018-08-01T00:42:55.099278: step 12514, loss 0.615006.
Train: 2018-08-01T00:42:55.255491: step 12515, loss 0.544934.
Train: 2018-08-01T00:42:55.411711: step 12516, loss 0.544925.
Train: 2018-08-01T00:42:55.583546: step 12517, loss 0.527357.
Train: 2018-08-01T00:42:55.739728: step 12518, loss 0.562477.
Train: 2018-08-01T00:42:55.895942: step 12519, loss 0.439322.
Train: 2018-08-01T00:42:56.067801: step 12520, loss 0.54486.
Test: 2018-08-01T00:42:56.536442: step 12520, loss 0.54771.
Train: 2018-08-01T00:42:56.692632: step 12521, loss 0.527158.
Train: 2018-08-01T00:42:56.864495: step 12522, loss 0.473932.
Train: 2018-08-01T00:42:57.005091: step 12523, loss 0.402568.
Train: 2018-08-01T00:42:57.161301: step 12524, loss 0.616181.
Train: 2018-08-01T00:42:57.317520: step 12525, loss 0.616404.
Train: 2018-08-01T00:42:57.473698: step 12526, loss 0.598588.
Train: 2018-08-01T00:42:57.629911: step 12527, loss 0.56266.
Train: 2018-08-01T00:42:57.786126: step 12528, loss 0.670648.
Train: 2018-08-01T00:42:57.942370: step 12529, loss 0.562502.
Train: 2018-08-01T00:42:58.098581: step 12530, loss 0.527469.
Test: 2018-08-01T00:42:58.567221: step 12530, loss 0.547678.
Train: 2018-08-01T00:42:58.723438: step 12531, loss 0.456908.
Train: 2018-08-01T00:42:58.895258: step 12532, loss 0.580622.
Train: 2018-08-01T00:42:59.051488: step 12533, loss 0.562865.
Train: 2018-08-01T00:42:59.207696: step 12534, loss 0.490536.
Train: 2018-08-01T00:42:59.363881: step 12535, loss 0.562717.
Train: 2018-08-01T00:42:59.520128: step 12536, loss 0.58081.
Train: 2018-08-01T00:42:59.676336: step 12537, loss 0.635088.
Train: 2018-08-01T00:42:59.832550: step 12538, loss 0.508506.
Train: 2018-08-01T00:43:00.004354: step 12539, loss 0.580806.
Train: 2018-08-01T00:43:00.160598: step 12540, loss 0.562726.
Test: 2018-08-01T00:43:00.629207: step 12540, loss 0.547599.
Train: 2018-08-01T00:43:00.785452: step 12541, loss 0.598833.
Train: 2018-08-01T00:43:00.941636: step 12542, loss 0.562706.
Train: 2018-08-01T00:43:01.097851: step 12543, loss 0.580709.
Train: 2018-08-01T00:43:01.254095: step 12544, loss 0.544684.
Train: 2018-08-01T00:43:01.425896: step 12545, loss 0.508749.
Train: 2018-08-01T00:43:01.582141: step 12546, loss 0.508772.
Train: 2018-08-01T00:43:01.738354: step 12547, loss 0.598585.
Train: 2018-08-01T00:43:01.894566: step 12548, loss 0.580607.
Train: 2018-08-01T00:43:02.050751: step 12549, loss 0.6344.
Train: 2018-08-01T00:43:02.222586: step 12550, loss 0.580533.
Test: 2018-08-01T00:43:02.691255: step 12550, loss 0.54764.
Train: 2018-08-01T00:43:02.863060: step 12551, loss 0.544734.
Train: 2018-08-01T00:43:03.003682: step 12552, loss 0.437692.
Train: 2018-08-01T00:43:03.159868: step 12553, loss 0.598274.
Train: 2018-08-01T00:43:03.331700: step 12554, loss 0.651741.
Train: 2018-08-01T00:43:03.487938: step 12555, loss 0.562568.
Train: 2018-08-01T00:43:03.644128: step 12556, loss 0.491477.
Train: 2018-08-01T00:43:03.800371: step 12557, loss 0.527036.
Train: 2018-08-01T00:43:03.956585: step 12558, loss 0.580294.
Train: 2018-08-01T00:43:04.097146: step 12559, loss 0.562539.
Train: 2018-08-01T00:43:04.253390: step 12560, loss 0.438443.
Test: 2018-08-01T00:43:04.737652: step 12560, loss 0.547683.
Train: 2018-08-01T00:43:04.893835: step 12561, loss 0.509312.
Train: 2018-08-01T00:43:05.050079: step 12562, loss 0.58032.
Train: 2018-08-01T00:43:05.206292: step 12563, loss 0.651478.
Train: 2018-08-01T00:43:05.362475: step 12564, loss 0.54478.
Train: 2018-08-01T00:43:05.518723: step 12565, loss 0.420381.
Train: 2018-08-01T00:43:05.674932: step 12566, loss 0.633757.
Train: 2018-08-01T00:43:05.831151: step 12567, loss 0.598175.
Train: 2018-08-01T00:43:05.987353: step 12568, loss 0.544768.
Train: 2018-08-01T00:43:06.143566: step 12569, loss 0.491382.
Train: 2018-08-01T00:43:06.299756: step 12570, loss 0.526955.
Test: 2018-08-01T00:43:06.768425: step 12570, loss 0.547653.
Train: 2018-08-01T00:43:06.924639: step 12571, loss 0.616051.
Train: 2018-08-01T00:43:07.080854: step 12572, loss 0.562579.
Train: 2018-08-01T00:43:07.237037: step 12573, loss 0.544754.
Train: 2018-08-01T00:43:07.393279: step 12574, loss 0.616053.
Train: 2018-08-01T00:43:07.565117: step 12575, loss 0.509137.
Train: 2018-08-01T00:43:07.736919: step 12576, loss 0.651619.
Train: 2018-08-01T00:43:07.877511: step 12577, loss 0.651489.
Train: 2018-08-01T00:43:08.033724: step 12578, loss 0.615767.
Train: 2018-08-01T00:43:08.205589: step 12579, loss 0.615586.
Train: 2018-08-01T00:43:08.361803: step 12580, loss 0.509606.
Test: 2018-08-01T00:43:08.830413: step 12580, loss 0.547753.
Train: 2018-08-01T00:43:08.986627: step 12581, loss 0.562477.
Train: 2018-08-01T00:43:09.142869: step 12582, loss 0.527378.
Train: 2018-08-01T00:43:09.299083: step 12583, loss 0.614994.
Train: 2018-08-01T00:43:09.470918: step 12584, loss 0.562445.
Train: 2018-08-01T00:43:09.627131: step 12585, loss 0.527567.
Train: 2018-08-01T00:43:09.783345: step 12586, loss 0.545023.
Train: 2018-08-01T00:43:09.970802: step 12587, loss 0.527652.
Train: 2018-08-01T00:43:10.127017: step 12588, loss 0.718813.
Train: 2018-08-01T00:43:10.283228: step 12589, loss 0.753044.
Train: 2018-08-01T00:43:10.439441: step 12590, loss 0.51068.
Test: 2018-08-01T00:43:10.908093: step 12590, loss 0.548023.
Train: 2018-08-01T00:43:11.079916: step 12591, loss 0.562407.
Train: 2018-08-01T00:43:11.236130: step 12592, loss 0.562407.
Train: 2018-08-01T00:43:11.392343: step 12593, loss 0.511217.
Train: 2018-08-01T00:43:11.548556: step 12594, loss 0.59647.
Train: 2018-08-01T00:43:11.720362: step 12595, loss 0.613383.
Train: 2018-08-01T00:43:11.876605: step 12596, loss 0.528542.
Train: 2018-08-01T00:43:12.048410: step 12597, loss 0.56243.
Train: 2018-08-01T00:43:12.204623: step 12598, loss 0.562436.
Train: 2018-08-01T00:43:12.360866: step 12599, loss 0.528739.
Train: 2018-08-01T00:43:12.517050: step 12600, loss 0.495098.
Test: 2018-08-01T00:43:12.985720: step 12600, loss 0.548342.
Train: 2018-08-01T00:43:13.657437: step 12601, loss 0.764537.
Train: 2018-08-01T00:43:13.813651: step 12602, loss 0.478467.
Train: 2018-08-01T00:43:13.969864: step 12603, loss 0.62958.
Train: 2018-08-01T00:43:14.126081: step 12604, loss 0.595968.
Train: 2018-08-01T00:43:14.329156: step 12605, loss 0.562482.
Train: 2018-08-01T00:43:14.485369: step 12606, loss 0.662601.
Train: 2018-08-01T00:43:14.641553: step 12607, loss 0.512603.
Train: 2018-08-01T00:43:14.797766: step 12608, loss 0.496103.
Train: 2018-08-01T00:43:14.953979: step 12609, loss 0.79486.
Train: 2018-08-01T00:43:15.110223: step 12610, loss 0.612154.
Test: 2018-08-01T00:43:15.578862: step 12610, loss 0.548801.
Train: 2018-08-01T00:43:15.735077: step 12611, loss 0.480258.
Train: 2018-08-01T00:43:15.891260: step 12612, loss 0.694041.
Train: 2018-08-01T00:43:16.047503: step 12613, loss 0.513551.
Train: 2018-08-01T00:43:16.203717: step 12614, loss 0.562675.
Train: 2018-08-01T00:43:16.359901: step 12615, loss 0.595273.
Train: 2018-08-01T00:43:16.531735: step 12616, loss 0.562725.
Train: 2018-08-01T00:43:16.703599: step 12617, loss 0.51409.
Train: 2018-08-01T00:43:16.859813: step 12618, loss 0.514139.
Train: 2018-08-01T00:43:17.016031: step 12619, loss 0.48171.
Train: 2018-08-01T00:43:17.172240: step 12620, loss 0.514033.
Test: 2018-08-01T00:43:17.640879: step 12620, loss 0.549084.
Train: 2018-08-01T00:43:17.797093: step 12621, loss 0.546438.
Train: 2018-08-01T00:43:17.953307: step 12622, loss 0.54637.
Train: 2018-08-01T00:43:18.109521: step 12623, loss 0.51359.
Train: 2018-08-01T00:43:18.265703: step 12624, loss 0.628253.
Train: 2018-08-01T00:43:18.421916: step 12625, loss 0.579045.
Train: 2018-08-01T00:43:18.593783: step 12626, loss 0.546116.
Train: 2018-08-01T00:43:18.765616: step 12627, loss 0.628582.
Train: 2018-08-01T00:43:18.921830: step 12628, loss 0.579081.
Train: 2018-08-01T00:43:19.078045: step 12629, loss 0.595617.
Train: 2018-08-01T00:43:19.234251: step 12630, loss 0.628692.
Test: 2018-08-01T00:43:19.702892: step 12630, loss 0.548722.
Train: 2018-08-01T00:43:19.859110: step 12631, loss 0.645181.
Train: 2018-08-01T00:43:20.015323: step 12632, loss 0.51308.
Train: 2018-08-01T00:43:20.171508: step 12633, loss 0.529603.
Train: 2018-08-01T00:43:20.327720: step 12634, loss 0.546089.
Train: 2018-08-01T00:43:20.483965: step 12635, loss 0.480098.
Train: 2018-08-01T00:43:20.640176: step 12636, loss 0.546037.
Train: 2018-08-01T00:43:20.796387: step 12637, loss 0.446667.
Train: 2018-08-01T00:43:20.968195: step 12638, loss 0.496074.
Train: 2018-08-01T00:43:21.124408: step 12639, loss 0.562492.
Train: 2018-08-01T00:43:21.280622: step 12640, loss 0.56247.
Test: 2018-08-01T00:43:21.764913: step 12640, loss 0.548383.
Train: 2018-08-01T00:43:21.936719: step 12641, loss 0.629663.
Train: 2018-08-01T00:43:22.092962: step 12642, loss 0.54448.
Train: 2018-08-01T00:43:22.249178: step 12643, loss 0.545554.
Train: 2018-08-01T00:43:22.405359: step 12644, loss 0.545506.
Train: 2018-08-01T00:43:22.561603: step 12645, loss 0.528498.
Train: 2018-08-01T00:43:22.717822: step 12646, loss 0.613432.
Train: 2018-08-01T00:43:22.873999: step 12647, loss 0.596481.
Train: 2018-08-01T00:43:23.061491: step 12648, loss 0.477136.
Train: 2018-08-01T00:43:23.217688: step 12649, loss 0.596589.
Train: 2018-08-01T00:43:23.373883: step 12650, loss 0.562405.
Test: 2018-08-01T00:43:23.842521: step 12650, loss 0.548051.
Train: 2018-08-01T00:43:23.998737: step 12651, loss 0.579545.
Train: 2018-08-01T00:43:24.170570: step 12652, loss 0.579562.
Train: 2018-08-01T00:43:24.326784: step 12653, loss 0.596742.
Train: 2018-08-01T00:43:24.482997: step 12654, loss 0.631089.
Train: 2018-08-01T00:43:24.639211: step 12655, loss 0.510932.
Train: 2018-08-01T00:43:24.795457: step 12656, loss 0.47662.
Train: 2018-08-01T00:43:24.951637: step 12657, loss 0.4937.
Train: 2018-08-01T00:43:25.123472: step 12658, loss 0.527987.
Train: 2018-08-01T00:43:25.279686: step 12659, loss 0.510667.
Train: 2018-08-01T00:43:25.451520: step 12660, loss 0.63158.
Test: 2018-08-01T00:43:25.935814: step 12660, loss 0.547913.
Train: 2018-08-01T00:43:26.092021: step 12661, loss 0.631682.
Train: 2018-08-01T00:43:26.263862: step 12662, loss 0.510446.
Train: 2018-08-01T00:43:26.435690: step 12663, loss 0.423701.
Train: 2018-08-01T00:43:26.591911: step 12664, loss 0.527653.
Train: 2018-08-01T00:43:26.748091: step 12665, loss 0.597302.
Train: 2018-08-01T00:43:26.904336: step 12666, loss 0.649787.
Train: 2018-08-01T00:43:27.060549: step 12667, loss 0.632364.
Train: 2018-08-01T00:43:27.216763: step 12668, loss 0.579915.
Train: 2018-08-01T00:43:27.372948: step 12669, loss 0.475131.
Train: 2018-08-01T00:43:27.544805: step 12670, loss 0.527501.
Test: 2018-08-01T00:43:28.013450: step 12670, loss 0.547803.
Train: 2018-08-01T00:43:28.185285: step 12671, loss 0.562445.
Train: 2018-08-01T00:43:28.341470: step 12672, loss 0.527453.
Train: 2018-08-01T00:43:28.544578: step 12673, loss 0.492391.
Train: 2018-08-01T00:43:28.700790: step 12674, loss 0.544915.
Train: 2018-08-01T00:43:28.857004: step 12675, loss 0.615202.
Train: 2018-08-01T00:43:29.013187: step 12676, loss 0.562476.
Train: 2018-08-01T00:43:29.169430: step 12677, loss 0.527273.
Train: 2018-08-01T00:43:29.325614: step 12678, loss 0.421524.
Train: 2018-08-01T00:43:29.481827: step 12679, loss 0.474173.
Train: 2018-08-01T00:43:29.638066: step 12680, loss 0.633428.
Test: 2018-08-01T00:43:30.122333: step 12680, loss 0.54767.
Train: 2018-08-01T00:43:30.278515: step 12681, loss 0.527021.
Train: 2018-08-01T00:43:30.434760: step 12682, loss 0.58036.
Train: 2018-08-01T00:43:30.590972: step 12683, loss 0.580403.
Train: 2018-08-01T00:43:30.762817: step 12684, loss 0.651824.
Train: 2018-08-01T00:43:30.903369: step 12685, loss 0.54474.
Train: 2018-08-01T00:43:31.059582: step 12686, loss 0.580424.
Train: 2018-08-01T00:43:31.215820: step 12687, loss 0.509076.
Train: 2018-08-01T00:43:31.387655: step 12688, loss 0.455557.
Train: 2018-08-01T00:43:31.543875: step 12689, loss 0.705486.
Train: 2018-08-01T00:43:31.700058: step 12690, loss 0.651836.
Test: 2018-08-01T00:43:32.168728: step 12690, loss 0.54765.
Train: 2018-08-01T00:43:32.324936: step 12691, loss 0.544752.
Train: 2018-08-01T00:43:32.496745: step 12692, loss 0.633717.
Train: 2018-08-01T00:43:32.652959: step 12693, loss 0.562537.
Train: 2018-08-01T00:43:32.809173: step 12694, loss 0.509395.
Train: 2018-08-01T00:43:32.981007: step 12695, loss 0.509461.
Train: 2018-08-01T00:43:33.137221: step 12696, loss 0.650853.
Train: 2018-08-01T00:43:33.293465: step 12697, loss 0.633039.
Train: 2018-08-01T00:43:33.449647: step 12698, loss 0.597655.
Train: 2018-08-01T00:43:33.605860: step 12699, loss 0.492303.
Train: 2018-08-01T00:43:33.762104: step 12700, loss 0.667494.
Test: 2018-08-01T00:43:34.230745: step 12700, loss 0.547821.
Train: 2018-08-01T00:43:34.918084: step 12701, loss 0.6148.
Train: 2018-08-01T00:43:35.089890: step 12702, loss 0.579818.
Train: 2018-08-01T00:43:35.246101: step 12703, loss 0.649089.
Train: 2018-08-01T00:43:35.402345: step 12704, loss 0.545146.
Train: 2018-08-01T00:43:35.574151: step 12705, loss 0.47641.
Train: 2018-08-01T00:43:35.730363: step 12706, loss 0.493755.
Train: 2018-08-01T00:43:35.886612: step 12707, loss 0.579548.
Train: 2018-08-01T00:43:36.042820: step 12708, loss 0.579529.
Train: 2018-08-01T00:43:36.214626: step 12709, loss 0.562404.
Train: 2018-08-01T00:43:36.370864: step 12710, loss 0.511149.
Test: 2018-08-01T00:43:36.839510: step 12710, loss 0.548103.
Train: 2018-08-01T00:43:37.011313: step 12711, loss 0.579485.
Train: 2018-08-01T00:43:37.167557: step 12712, loss 0.545334.
Train: 2018-08-01T00:43:37.339392: step 12713, loss 0.545337.
Train: 2018-08-01T00:43:37.495605: step 12714, loss 0.459987.
Train: 2018-08-01T00:43:37.651819: step 12715, loss 0.562404.
Train: 2018-08-01T00:43:37.792381: step 12716, loss 0.613757.
Train: 2018-08-01T00:43:37.948624: step 12717, loss 0.613783.
Train: 2018-08-01T00:43:38.104807: step 12718, loss 0.562403.
Train: 2018-08-01T00:43:38.261051: step 12719, loss 0.579523.
Train: 2018-08-01T00:43:38.432856: step 12720, loss 0.476841.
Test: 2018-08-01T00:43:38.901526: step 12720, loss 0.548062.
Train: 2018-08-01T00:43:39.057710: step 12721, loss 0.476772.
Train: 2018-08-01T00:43:39.213953: step 12722, loss 0.613878.
Train: 2018-08-01T00:43:39.385759: step 12723, loss 0.4937.
Train: 2018-08-01T00:43:39.541970: step 12724, loss 0.545197.
Train: 2018-08-01T00:43:39.698214: step 12725, loss 0.545166.
Train: 2018-08-01T00:43:39.838801: step 12726, loss 0.424239.
Train: 2018-08-01T00:43:40.010645: step 12727, loss 0.770392.
Train: 2018-08-01T00:43:40.166824: step 12728, loss 0.597091.
Train: 2018-08-01T00:43:40.307447: step 12729, loss 0.510409.
Train: 2018-08-01T00:43:40.479276: step 12730, loss 0.562416.
Test: 2018-08-01T00:43:40.947925: step 12730, loss 0.547887.
Train: 2018-08-01T00:43:41.104136: step 12731, loss 0.59712.
Train: 2018-08-01T00:43:41.260319: step 12732, loss 0.527717.
Train: 2018-08-01T00:43:41.416531: step 12733, loss 0.614483.
Train: 2018-08-01T00:43:41.572775: step 12734, loss 0.579764.
Train: 2018-08-01T00:43:41.744580: step 12735, loss 0.579752.
Train: 2018-08-01T00:43:41.900823: step 12736, loss 0.579735.
Train: 2018-08-01T00:43:42.057037: step 12737, loss 0.527801.
Train: 2018-08-01T00:43:42.213251: step 12738, loss 0.579706.
Train: 2018-08-01T00:43:42.369464: step 12739, loss 0.562409.
Train: 2018-08-01T00:43:42.525647: step 12740, loss 0.631503.
Test: 2018-08-01T00:43:43.009943: step 12740, loss 0.547962.
Train: 2018-08-01T00:43:43.166123: step 12741, loss 0.579653.
Train: 2018-08-01T00:43:43.322366: step 12742, loss 0.545184.
Train: 2018-08-01T00:43:43.478549: step 12743, loss 0.5968.
Train: 2018-08-01T00:43:43.634763: step 12744, loss 0.579574.
Train: 2018-08-01T00:43:43.806628: step 12745, loss 0.545259.
Train: 2018-08-01T00:43:43.978432: step 12746, loss 0.613768.
Train: 2018-08-01T00:43:44.134645: step 12747, loss 0.494042.
Train: 2018-08-01T00:43:44.290885: step 12748, loss 0.511169.
Train: 2018-08-01T00:43:44.447074: step 12749, loss 0.528245.
Train: 2018-08-01T00:43:44.603316: step 12750, loss 0.579493.
Test: 2018-08-01T00:43:45.087548: step 12750, loss 0.54809.
Train: 2018-08-01T00:43:45.228170: step 12751, loss 0.511123.
Train: 2018-08-01T00:43:45.399975: step 12752, loss 0.613732.
Train: 2018-08-01T00:43:45.556218: step 12753, loss 0.596628.
Train: 2018-08-01T00:43:45.712401: step 12754, loss 0.51108.
Train: 2018-08-01T00:43:45.868615: step 12755, loss 0.545288.
Train: 2018-08-01T00:43:46.024854: step 12756, loss 0.4939.
Train: 2018-08-01T00:43:46.181041: step 12757, loss 0.5281.
Train: 2018-08-01T00:43:46.337256: step 12758, loss 0.562402.
Train: 2018-08-01T00:43:46.493493: step 12759, loss 0.579613.
Train: 2018-08-01T00:43:46.665334: step 12760, loss 0.493481.
Test: 2018-08-01T00:43:47.133944: step 12760, loss 0.547949.
Train: 2018-08-01T00:43:47.290157: step 12761, loss 0.562406.
Train: 2018-08-01T00:43:47.446371: step 12762, loss 0.475929.
Train: 2018-08-01T00:43:47.602608: step 12763, loss 0.579758.
Train: 2018-08-01T00:43:47.774449: step 12764, loss 0.614564.
Train: 2018-08-01T00:43:47.930632: step 12765, loss 0.510218.
Train: 2018-08-01T00:43:48.086876: step 12766, loss 0.579864.
Train: 2018-08-01T00:43:48.243094: step 12767, loss 0.544981.
Train: 2018-08-01T00:43:48.399297: step 12768, loss 0.544963.
Train: 2018-08-01T00:43:48.555485: step 12769, loss 0.527442.
Train: 2018-08-01T00:43:48.711700: step 12770, loss 0.527392.
Test: 2018-08-01T00:43:49.180370: step 12770, loss 0.547757.
Train: 2018-08-01T00:43:49.352174: step 12771, loss 0.580029.
Train: 2018-08-01T00:43:49.508387: step 12772, loss 0.597649.
Train: 2018-08-01T00:43:49.649010: step 12773, loss 0.580078.
Train: 2018-08-01T00:43:49.805223: step 12774, loss 0.527266.
Train: 2018-08-01T00:43:49.977028: step 12775, loss 0.544865.
Train: 2018-08-01T00:43:50.133275: step 12776, loss 0.58012.
Train: 2018-08-01T00:43:50.289454: step 12777, loss 0.56249.
Train: 2018-08-01T00:43:50.461314: step 12778, loss 0.580135.
Train: 2018-08-01T00:43:50.617535: step 12779, loss 0.527209.
Train: 2018-08-01T00:43:50.773747: step 12780, loss 0.686017.
Test: 2018-08-01T00:43:51.242386: step 12780, loss 0.547728.
Train: 2018-08-01T00:43:51.398570: step 12781, loss 0.562484.
Train: 2018-08-01T00:43:51.570405: step 12782, loss 0.562476.
Train: 2018-08-01T00:43:51.710996: step 12783, loss 0.650344.
Train: 2018-08-01T00:43:51.882831: step 12784, loss 0.597523.
Train: 2018-08-01T00:43:52.039045: step 12785, loss 0.457523.
Train: 2018-08-01T00:43:52.195288: step 12786, loss 0.667245.
Train: 2018-08-01T00:43:52.351471: step 12787, loss 0.562429.
Train: 2018-08-01T00:43:52.507684: step 12788, loss 0.51026.
Train: 2018-08-01T00:43:52.663928: step 12789, loss 0.545054.
Train: 2018-08-01T00:43:52.820137: step 12790, loss 0.545069.
Test: 2018-08-01T00:43:53.288783: step 12790, loss 0.547899.
Train: 2018-08-01T00:43:53.444995: step 12791, loss 0.527746.
Train: 2018-08-01T00:43:53.616833: step 12792, loss 0.614401.
Train: 2018-08-01T00:43:53.804287: step 12793, loss 0.51047.
Train: 2018-08-01T00:43:53.960499: step 12794, loss 0.5451.
Train: 2018-08-01T00:43:54.116684: step 12795, loss 0.614345.
Train: 2018-08-01T00:43:54.272927: step 12796, loss 0.44131.
Train: 2018-08-01T00:43:54.413489: step 12797, loss 0.545094.
Train: 2018-08-01T00:43:54.585323: step 12798, loss 0.631756.
Train: 2018-08-01T00:43:54.741570: step 12799, loss 0.545078.
Train: 2018-08-01T00:43:54.929023: step 12800, loss 0.631774.
Test: 2018-08-01T00:43:55.397663: step 12800, loss 0.547903.
Train: 2018-08-01T00:43:56.116216: step 12801, loss 0.614393.
Train: 2018-08-01T00:43:56.288050: step 12802, loss 0.597014.
Train: 2018-08-01T00:43:56.444293: step 12803, loss 0.596951.
Train: 2018-08-01T00:43:56.600506: step 12804, loss 0.596877.
Train: 2018-08-01T00:43:56.756724: step 12805, loss 0.528009.
Train: 2018-08-01T00:43:56.912904: step 12806, loss 0.545233.
Train: 2018-08-01T00:43:57.100359: step 12807, loss 0.493816.
Train: 2018-08-01T00:43:57.256602: step 12808, loss 0.49383.
Train: 2018-08-01T00:43:57.412786: step 12809, loss 0.545245.
Train: 2018-08-01T00:43:57.569029: step 12810, loss 0.528058.
Test: 2018-08-01T00:43:58.037670: step 12810, loss 0.548004.
Train: 2018-08-01T00:43:58.209474: step 12811, loss 0.596789.
Train: 2018-08-01T00:43:58.381317: step 12812, loss 0.545197.
Train: 2018-08-01T00:43:58.521901: step 12813, loss 0.71738.
Train: 2018-08-01T00:43:58.678145: step 12814, loss 0.528008.
Train: 2018-08-01T00:43:58.834358: step 12815, loss 0.493667.
Train: 2018-08-01T00:43:59.006197: step 12816, loss 0.682716.
Train: 2018-08-01T00:43:59.162411: step 12817, loss 0.528074.
Train: 2018-08-01T00:43:59.318590: step 12818, loss 0.5967.
Train: 2018-08-01T00:43:59.490458: step 12819, loss 0.562401.
Train: 2018-08-01T00:43:59.646668: step 12820, loss 0.476847.
Test: 2018-08-01T00:44:00.115279: step 12820, loss 0.54807.
Train: 2018-08-01T00:44:00.302738: step 12821, loss 0.545287.
Train: 2018-08-01T00:44:00.474570: step 12822, loss 0.54528.
Train: 2018-08-01T00:44:00.646404: step 12823, loss 0.545269.
Train: 2018-08-01T00:44:00.818270: step 12824, loss 0.528108.
Train: 2018-08-01T00:44:00.990108: step 12825, loss 0.596734.
Train: 2018-08-01T00:44:01.146311: step 12826, loss 0.631109.
Train: 2018-08-01T00:44:01.302525: step 12827, loss 0.476549.
Train: 2018-08-01T00:44:01.489956: step 12828, loss 0.545217.
Train: 2018-08-01T00:44:01.646170: step 12829, loss 0.562401.
Train: 2018-08-01T00:44:01.802413: step 12830, loss 0.631263.
Test: 2018-08-01T00:44:02.271022: step 12830, loss 0.547989.
Train: 2018-08-01T00:44:02.442859: step 12831, loss 0.527978.
Train: 2018-08-01T00:44:02.614693: step 12832, loss 0.579619.
Train: 2018-08-01T00:44:02.770937: step 12833, loss 0.596837.
Train: 2018-08-01T00:44:02.927155: step 12834, loss 0.614031.
Train: 2018-08-01T00:44:03.083335: step 12835, loss 0.579592.
Train: 2018-08-01T00:44:03.239577: step 12836, loss 0.631078.
Train: 2018-08-01T00:44:03.395791: step 12837, loss 0.545267.
Train: 2018-08-01T00:44:03.552005: step 12838, loss 0.61372.
Train: 2018-08-01T00:44:03.739462: step 12839, loss 0.545334.
Train: 2018-08-01T00:44:03.895642: step 12840, loss 0.579446.
Test: 2018-08-01T00:44:04.364315: step 12840, loss 0.548164.
Train: 2018-08-01T00:44:04.520527: step 12841, loss 0.528387.
Train: 2018-08-01T00:44:04.692332: step 12842, loss 0.579404.
Train: 2018-08-01T00:44:04.848546: step 12843, loss 0.47755.
Train: 2018-08-01T00:44:05.004787: step 12844, loss 0.630315.
Train: 2018-08-01T00:44:05.160971: step 12845, loss 0.562415.
Train: 2018-08-01T00:44:05.317186: step 12846, loss 0.511563.
Train: 2018-08-01T00:44:05.489020: step 12847, loss 0.562416.
Train: 2018-08-01T00:44:05.645234: step 12848, loss 0.528502.
Train: 2018-08-01T00:44:05.801479: step 12849, loss 0.596351.
Train: 2018-08-01T00:44:05.957691: step 12850, loss 0.613327.
Test: 2018-08-01T00:44:06.441951: step 12850, loss 0.548211.
Train: 2018-08-01T00:44:06.598165: step 12851, loss 0.596339.
Train: 2018-08-01T00:44:06.754373: step 12852, loss 0.545471.
Train: 2018-08-01T00:44:06.910562: step 12853, loss 0.528545.
Train: 2018-08-01T00:44:07.066806: step 12854, loss 0.613232.
Train: 2018-08-01T00:44:07.222989: step 12855, loss 0.511641.
Train: 2018-08-01T00:44:07.379236: step 12856, loss 0.714784.
Train: 2018-08-01T00:44:07.535446: step 12857, loss 0.494841.
Train: 2018-08-01T00:44:07.691630: step 12858, loss 0.461127.
Train: 2018-08-01T00:44:07.847873: step 12859, loss 0.511735.
Train: 2018-08-01T00:44:08.019708: step 12860, loss 0.528578.
Test: 2018-08-01T00:44:08.488348: step 12860, loss 0.54822.
Train: 2018-08-01T00:44:08.644531: step 12861, loss 0.596323.
Train: 2018-08-01T00:44:08.800775: step 12862, loss 0.562413.
Train: 2018-08-01T00:44:08.972580: step 12863, loss 0.511431.
Train: 2018-08-01T00:44:09.175692: step 12864, loss 0.613476.
Train: 2018-08-01T00:44:09.331871: step 12865, loss 0.545367.
Train: 2018-08-01T00:44:09.488084: step 12866, loss 0.528292.
Train: 2018-08-01T00:44:09.644327: step 12867, loss 0.528241.
Train: 2018-08-01T00:44:09.800535: step 12868, loss 0.442622.
Train: 2018-08-01T00:44:09.972370: step 12869, loss 0.510899.
Train: 2018-08-01T00:44:10.128559: step 12870, loss 0.459028.
Test: 2018-08-01T00:44:10.597229: step 12870, loss 0.547915.
Train: 2018-08-01T00:44:10.753412: step 12871, loss 0.597026.
Train: 2018-08-01T00:44:10.909626: step 12872, loss 0.631905.
Train: 2018-08-01T00:44:11.065839: step 12873, loss 0.701721.
Train: 2018-08-01T00:44:11.237702: step 12874, loss 0.614672.
Train: 2018-08-01T00:44:11.409508: step 12875, loss 0.61464.
Train: 2018-08-01T00:44:11.565722: step 12876, loss 0.597188.
Train: 2018-08-01T00:44:11.721935: step 12877, loss 0.475637.
Train: 2018-08-01T00:44:11.878148: step 12878, loss 0.597114.
Train: 2018-08-01T00:44:12.034362: step 12879, loss 0.631755.
Train: 2018-08-01T00:44:12.190576: step 12880, loss 0.700861.
Test: 2018-08-01T00:44:12.674867: step 12880, loss 0.54796.
Train: 2018-08-01T00:44:12.831081: step 12881, loss 0.545155.
Train: 2018-08-01T00:44:12.987294: step 12882, loss 0.476406.
Train: 2018-08-01T00:44:13.143478: step 12883, loss 0.682624.
Train: 2018-08-01T00:44:13.299690: step 12884, loss 0.52815.
Train: 2018-08-01T00:44:13.455937: step 12885, loss 0.459872.
Train: 2018-08-01T00:44:13.612153: step 12886, loss 0.494085.
Train: 2018-08-01T00:44:13.768361: step 12887, loss 0.511139.
Train: 2018-08-01T00:44:13.924569: step 12888, loss 0.562401.
Train: 2018-08-01T00:44:14.080788: step 12889, loss 0.579525.
Train: 2018-08-01T00:44:14.236971: step 12890, loss 0.528126.
Test: 2018-08-01T00:44:14.705645: step 12890, loss 0.548034.
Train: 2018-08-01T00:44:14.861855: step 12891, loss 0.596712.
Train: 2018-08-01T00:44:15.018068: step 12892, loss 0.510906.
Train: 2018-08-01T00:44:15.174282: step 12893, loss 0.5624.
Train: 2018-08-01T00:44:15.330496: step 12894, loss 0.596807.
Train: 2018-08-01T00:44:15.486708: step 12895, loss 0.510768.
Train: 2018-08-01T00:44:15.705378: step 12896, loss 0.596862.
Train: 2018-08-01T00:44:15.845999: step 12897, loss 0.61412.
Train: 2018-08-01T00:44:16.017805: step 12898, loss 0.527933.
Train: 2018-08-01T00:44:16.158426: step 12899, loss 0.665836.
Train: 2018-08-01T00:44:16.330256: step 12900, loss 0.527965.
Test: 2018-08-01T00:44:16.798902: step 12900, loss 0.547992.
Train: 2018-08-01T00:44:17.517454: step 12901, loss 0.527986.
Train: 2018-08-01T00:44:17.673696: step 12902, loss 0.614018.
Train: 2018-08-01T00:44:17.845502: step 12903, loss 0.613976.
Train: 2018-08-01T00:44:18.001749: step 12904, loss 0.648236.
Train: 2018-08-01T00:44:18.157954: step 12905, loss 0.5624.
Train: 2018-08-01T00:44:18.329788: step 12906, loss 0.545314.
Train: 2018-08-01T00:44:18.486007: step 12907, loss 0.613576.
Train: 2018-08-01T00:44:18.642190: step 12908, loss 0.460293.
Train: 2018-08-01T00:44:18.798403: step 12909, loss 0.613434.
Train: 2018-08-01T00:44:18.954647: step 12910, loss 0.630363.
Test: 2018-08-01T00:44:19.438877: step 12910, loss 0.548219.
Train: 2018-08-01T00:44:19.595122: step 12911, loss 0.562416.
Train: 2018-08-01T00:44:19.751306: step 12912, loss 0.613192.
Train: 2018-08-01T00:44:19.907543: step 12913, loss 0.511772.
Train: 2018-08-01T00:44:20.095005: step 12914, loss 0.528706.
Train: 2018-08-01T00:44:20.251217: step 12915, loss 0.596141.
Train: 2018-08-01T00:44:20.407402: step 12916, loss 0.612948.
Train: 2018-08-01T00:44:20.563640: step 12917, loss 0.562446.
Train: 2018-08-01T00:44:20.719867: step 12918, loss 0.461725.
Train: 2018-08-01T00:44:20.891688: step 12919, loss 0.629623.
Train: 2018-08-01T00:44:21.047877: step 12920, loss 0.545671.
Test: 2018-08-01T00:44:21.516547: step 12920, loss 0.548405.
Train: 2018-08-01T00:44:21.672761: step 12921, loss 0.495341.
Train: 2018-08-01T00:44:21.828943: step 12922, loss 0.528867.
Train: 2018-08-01T00:44:21.985187: step 12923, loss 0.512006.
Train: 2018-08-01T00:44:22.188271: step 12924, loss 0.528746.
Train: 2018-08-01T00:44:22.360094: step 12925, loss 0.596195.
Train: 2018-08-01T00:44:22.500696: step 12926, loss 0.511692.
Train: 2018-08-01T00:44:22.656875: step 12927, loss 0.562416.
Train: 2018-08-01T00:44:22.813118: step 12928, loss 0.647319.
Train: 2018-08-01T00:44:22.984922: step 12929, loss 0.528425.
Train: 2018-08-01T00:44:23.141137: step 12930, loss 0.545397.
Test: 2018-08-01T00:44:23.609807: step 12930, loss 0.548143.
Train: 2018-08-01T00:44:23.781611: step 12931, loss 0.477244.
Train: 2018-08-01T00:44:23.937855: step 12932, loss 0.630689.
Train: 2018-08-01T00:44:24.094069: step 12933, loss 0.511127.
Train: 2018-08-01T00:44:24.250276: step 12934, loss 0.5624.
Train: 2018-08-01T00:44:24.422118: step 12935, loss 0.5624.
Train: 2018-08-01T00:44:24.578330: step 12936, loss 0.5624.
Train: 2018-08-01T00:44:24.750170: step 12937, loss 0.682765.
Train: 2018-08-01T00:44:24.906347: step 12938, loss 0.545213.
Train: 2018-08-01T00:44:25.062585: step 12939, loss 0.613948.
Train: 2018-08-01T00:44:25.218804: step 12940, loss 0.528065.
Test: 2018-08-01T00:44:25.687445: step 12940, loss 0.548029.
Train: 2018-08-01T00:44:25.859249: step 12941, loss 0.562399.
Train: 2018-08-01T00:44:26.015493: step 12942, loss 0.476618.
Train: 2018-08-01T00:44:26.171676: step 12943, loss 0.580716.
Train: 2018-08-01T00:44:26.327890: step 12944, loss 0.613942.
Train: 2018-08-01T00:44:26.484136: step 12945, loss 0.545222.
Train: 2018-08-01T00:44:26.640347: step 12946, loss 0.510866.
Train: 2018-08-01T00:44:26.796560: step 12947, loss 0.545209.
Train: 2018-08-01T00:44:26.968364: step 12948, loss 0.510783.
Train: 2018-08-01T00:44:27.124604: step 12949, loss 0.614096.
Train: 2018-08-01T00:44:27.280792: step 12950, loss 0.734824.
Test: 2018-08-01T00:44:27.749432: step 12950, loss 0.547988.
Train: 2018-08-01T00:44:27.905671: step 12951, loss 0.527977.
Train: 2018-08-01T00:44:28.061860: step 12952, loss 0.528016.
Train: 2018-08-01T00:44:28.218103: step 12953, loss 0.510854.
Train: 2018-08-01T00:44:28.374315: step 12954, loss 0.545214.
Train: 2018-08-01T00:44:28.530530: step 12955, loss 0.510825.
Train: 2018-08-01T00:44:28.686712: step 12956, loss 0.510771.
Train: 2018-08-01T00:44:28.858547: step 12957, loss 0.493451.
Train: 2018-08-01T00:44:29.014791: step 12958, loss 0.579684.
Train: 2018-08-01T00:44:29.171004: step 12959, loss 0.475852.
Train: 2018-08-01T00:44:29.327218: step 12960, loss 0.579775.
Test: 2018-08-01T00:44:29.795857: step 12960, loss 0.547852.
Train: 2018-08-01T00:44:29.967662: step 12961, loss 0.510224.
Train: 2018-08-01T00:44:30.123876: step 12962, loss 0.527539.
Train: 2018-08-01T00:44:30.280089: step 12963, loss 0.509957.
Train: 2018-08-01T00:44:30.436304: step 12964, loss 0.562458.
Train: 2018-08-01T00:44:30.592517: step 12965, loss 0.492077.
Train: 2018-08-01T00:44:30.748729: step 12966, loss 0.615468.
Train: 2018-08-01T00:44:30.904944: step 12967, loss 0.474028.
Train: 2018-08-01T00:44:31.061188: step 12968, loss 0.509283.
Train: 2018-08-01T00:44:31.217395: step 12969, loss 0.509136.
Train: 2018-08-01T00:44:31.373618: step 12970, loss 0.50898.
Test: 2018-08-01T00:44:31.842254: step 12970, loss 0.547611.
Train: 2018-08-01T00:44:31.998437: step 12971, loss 0.562631.
Train: 2018-08-01T00:44:32.185892: step 12972, loss 0.562666.
Train: 2018-08-01T00:44:32.342136: step 12973, loss 0.562698.
Train: 2018-08-01T00:44:32.498320: step 12974, loss 0.616982.
Train: 2018-08-01T00:44:32.654558: step 12975, loss 0.490313.
Train: 2018-08-01T00:44:32.810747: step 12976, loss 0.61719.
Train: 2018-08-01T00:44:32.966960: step 12977, loss 0.472.
Train: 2018-08-01T00:44:33.123174: step 12978, loss 0.617361.
Train: 2018-08-01T00:44:33.295044: step 12979, loss 0.672003.
Train: 2018-08-01T00:44:33.451252: step 12980, loss 0.65371.
Test: 2018-08-01T00:44:33.935514: step 12980, loss 0.547576.
Train: 2018-08-01T00:44:34.154182: step 12981, loss 0.490192.
Train: 2018-08-01T00:44:34.310395: step 12982, loss 0.508384.
Train: 2018-08-01T00:44:34.466643: step 12983, loss 0.598975.
Train: 2018-08-01T00:44:34.622852: step 12984, loss 0.562733.
Train: 2018-08-01T00:44:34.779035: step 12985, loss 0.616939.
Train: 2018-08-01T00:44:34.935280: step 12986, loss 0.562696.
Train: 2018-08-01T00:44:35.091487: step 12987, loss 0.598689.
Train: 2018-08-01T00:44:35.247710: step 12988, loss 0.418911.
Train: 2018-08-01T00:44:35.435157: step 12989, loss 0.562645.
Train: 2018-08-01T00:44:35.591346: step 12990, loss 0.616498.
Test: 2018-08-01T00:44:36.060020: step 12990, loss 0.547612.
Train: 2018-08-01T00:44:36.216230: step 12991, loss 0.437112.
Train: 2018-08-01T00:44:36.372448: step 12992, loss 0.562631.
Train: 2018-08-01T00:44:36.544248: step 12993, loss 0.580573.
Train: 2018-08-01T00:44:36.700462: step 12994, loss 0.634376.
Train: 2018-08-01T00:44:36.872330: step 12995, loss 0.580532.
Train: 2018-08-01T00:44:37.044131: step 12996, loss 0.616269.
Train: 2018-08-01T00:44:37.200374: step 12997, loss 0.509029.
Train: 2018-08-01T00:44:37.356587: step 12998, loss 0.598225.
Train: 2018-08-01T00:44:37.512770: step 12999, loss 0.651534.
Train: 2018-08-01T00:44:37.668984: step 13000, loss 0.52704.
Test: 2018-08-01T00:44:38.137654: step 13000, loss 0.547687.
Train: 2018-08-01T00:44:38.824964: step 13001, loss 0.562514.
Train: 2018-08-01T00:44:38.981176: step 13002, loss 0.491822.
Train: 2018-08-01T00:44:39.137390: step 13003, loss 0.633094.
Train: 2018-08-01T00:44:39.293603: step 13004, loss 0.544863.
Train: 2018-08-01T00:44:39.449817: step 13005, loss 0.650408.
Train: 2018-08-01T00:44:39.606030: step 13006, loss 0.562455.
Train: 2018-08-01T00:44:39.762277: step 13007, loss 0.614935.
Train: 2018-08-01T00:44:39.934110: step 13008, loss 0.475205.
Train: 2018-08-01T00:44:40.090294: step 13009, loss 0.545007.
Train: 2018-08-01T00:44:40.246535: step 13010, loss 0.492838.
Test: 2018-08-01T00:44:40.715176: step 13010, loss 0.547857.
Train: 2018-08-01T00:44:40.886982: step 13011, loss 0.597202.
Train: 2018-08-01T00:44:41.043194: step 13012, loss 0.562418.
Train: 2018-08-01T00:44:41.199432: step 13013, loss 0.631882.
Train: 2018-08-01T00:44:41.355621: step 13014, loss 0.57975.
Train: 2018-08-01T00:44:41.511834: step 13015, loss 0.545098.
Train: 2018-08-01T00:44:41.668047: step 13016, loss 0.666126.
Train: 2018-08-01T00:44:41.824261: step 13017, loss 0.458951.
Train: 2018-08-01T00:44:41.980474: step 13018, loss 0.7002.
Train: 2018-08-01T00:44:42.136718: step 13019, loss 0.579576.
Train: 2018-08-01T00:44:42.292901: step 13020, loss 0.493875.
Test: 2018-08-01T00:44:42.777193: step 13020, loss 0.548076.
Train: 2018-08-01T00:44:42.933407: step 13021, loss 0.493979.
Train: 2018-08-01T00:44:43.120857: step 13022, loss 0.613694.
Train: 2018-08-01T00:44:43.261424: step 13023, loss 0.66488.
Train: 2018-08-01T00:44:43.417637: step 13024, loss 0.545364.
Train: 2018-08-01T00:44:43.573851: step 13025, loss 0.545399.
Train: 2018-08-01T00:44:43.730064: step 13026, loss 0.545426.
Train: 2018-08-01T00:44:43.886278: step 13027, loss 0.579379.
Train: 2018-08-01T00:44:44.042517: step 13028, loss 0.545468.
Train: 2018-08-01T00:44:44.214327: step 13029, loss 0.630158.
Train: 2018-08-01T00:44:44.370564: step 13030, loss 0.663874.
Test: 2018-08-01T00:44:44.839210: step 13030, loss 0.548312.
Train: 2018-08-01T00:44:44.979803: step 13031, loss 0.579293.
Train: 2018-08-01T00:44:45.151607: step 13032, loss 0.612891.
Train: 2018-08-01T00:44:45.307857: step 13033, loss 0.495402.
Train: 2018-08-01T00:44:45.464033: step 13034, loss 0.478795.
Train: 2018-08-01T00:44:45.620247: step 13035, loss 0.562469.
Train: 2018-08-01T00:44:45.776491: step 13036, loss 0.529018.
Train: 2018-08-01T00:44:45.932674: step 13037, loss 0.562468.
Train: 2018-08-01T00:44:46.088918: step 13038, loss 0.595944.
Train: 2018-08-01T00:44:46.245100: step 13039, loss 0.528988.
Train: 2018-08-01T00:44:46.432556: step 13040, loss 0.696446.
Test: 2018-08-01T00:44:46.901227: step 13040, loss 0.548465.
Train: 2018-08-01T00:44:47.057441: step 13041, loss 0.428669.
Train: 2018-08-01T00:44:47.213655: step 13042, loss 0.478775.
Train: 2018-08-01T00:44:47.385489: step 13043, loss 0.579227.
Train: 2018-08-01T00:44:47.557293: step 13044, loss 0.562448.
Train: 2018-08-01T00:44:47.697916: step 13045, loss 0.596087.
Train: 2018-08-01T00:44:47.854130: step 13046, loss 0.629793.
Train: 2018-08-01T00:44:48.010312: step 13047, loss 0.562438.
Train: 2018-08-01T00:44:48.166527: step 13048, loss 0.545599.
Train: 2018-08-01T00:44:48.322764: step 13049, loss 0.596123.
Train: 2018-08-01T00:44:48.478983: step 13050, loss 0.562437.
Test: 2018-08-01T00:44:48.959658: step 13050, loss 0.548335.
Train: 2018-08-01T00:44:49.115902: step 13051, loss 0.612957.
Train: 2018-08-01T00:44:49.256494: step 13052, loss 0.56244.
Train: 2018-08-01T00:44:49.412710: step 13053, loss 0.596078.
Train: 2018-08-01T00:44:49.584512: step 13054, loss 0.562447.
Train: 2018-08-01T00:44:49.756377: step 13055, loss 0.612817.
Train: 2018-08-01T00:44:49.928215: step 13056, loss 0.478626.
Train: 2018-08-01T00:44:50.084395: step 13057, loss 0.528923.
Train: 2018-08-01T00:44:50.224988: step 13058, loss 0.545677.
Train: 2018-08-01T00:44:50.396823: step 13059, loss 0.545659.
Train: 2018-08-01T00:44:50.553066: step 13060, loss 0.495209.
Test: 2018-08-01T00:44:51.021689: step 13060, loss 0.548333.
Train: 2018-08-01T00:44:51.177919: step 13061, loss 0.545594.
Train: 2018-08-01T00:44:51.334132: step 13062, loss 0.596183.
Train: 2018-08-01T00:44:51.490346: step 13063, loss 0.461014.
Train: 2018-08-01T00:44:51.646553: step 13064, loss 0.579363.
Train: 2018-08-01T00:44:51.802746: step 13065, loss 0.545422.
Train: 2018-08-01T00:44:51.974603: step 13066, loss 0.579431.
Train: 2018-08-01T00:44:52.130790: step 13067, loss 0.664751.
Train: 2018-08-01T00:44:52.287005: step 13068, loss 0.562401.
Train: 2018-08-01T00:44:52.443218: step 13069, loss 0.477063.
Train: 2018-08-01T00:44:52.599461: step 13070, loss 0.494031.
Test: 2018-08-01T00:44:53.068101: step 13070, loss 0.548054.
Train: 2018-08-01T00:44:53.224284: step 13071, loss 0.562398.
Train: 2018-08-01T00:44:53.380499: step 13072, loss 0.493738.
Train: 2018-08-01T00:44:53.552363: step 13073, loss 0.545187.
Train: 2018-08-01T00:44:53.708546: step 13074, loss 0.527885.
Train: 2018-08-01T00:44:53.864759: step 13075, loss 0.648947.
Train: 2018-08-01T00:44:54.020975: step 13076, loss 0.56241.
Train: 2018-08-01T00:44:54.192832: step 13077, loss 0.562413.
Train: 2018-08-01T00:44:54.333434: step 13078, loss 0.545044.
Train: 2018-08-01T00:44:54.489614: step 13079, loss 0.631984.
Train: 2018-08-01T00:44:54.645827: step 13080, loss 0.631988.
Test: 2018-08-01T00:44:55.130116: step 13080, loss 0.547866.
Train: 2018-08-01T00:44:55.286301: step 13081, loss 0.579793.
Train: 2018-08-01T00:44:55.442514: step 13082, loss 0.45827.
Train: 2018-08-01T00:44:55.598728: step 13083, loss 0.614506.
Train: 2018-08-01T00:44:55.754972: step 13084, loss 0.63184.
Train: 2018-08-01T00:44:55.911188: step 13085, loss 0.545076.
Train: 2018-08-01T00:44:56.051748: step 13086, loss 0.614358.
Train: 2018-08-01T00:44:56.223584: step 13087, loss 0.527827.
Train: 2018-08-01T00:44:56.379820: step 13088, loss 0.596945.
Train: 2018-08-01T00:44:56.536009: step 13089, loss 0.648635.
Train: 2018-08-01T00:44:56.692224: step 13090, loss 0.562399.
Test: 2018-08-01T00:44:57.176483: step 13090, loss 0.548023.
Train: 2018-08-01T00:44:57.332710: step 13091, loss 0.562398.
Train: 2018-08-01T00:44:57.488911: step 13092, loss 0.562398.
Train: 2018-08-01T00:44:57.645155: step 13093, loss 0.562399.
Train: 2018-08-01T00:44:57.801338: step 13094, loss 0.562401.
Train: 2018-08-01T00:44:57.957581: step 13095, loss 0.494207.
Train: 2018-08-01T00:44:58.113795: step 13096, loss 0.511273.
Train: 2018-08-01T00:44:58.270002: step 13097, loss 0.681756.
Train: 2018-08-01T00:44:58.426191: step 13098, loss 0.68161.
Train: 2018-08-01T00:44:58.582407: step 13099, loss 0.56241.
Train: 2018-08-01T00:44:58.738642: step 13100, loss 0.562416.
Test: 2018-08-01T00:44:59.222910: step 13100, loss 0.548268.
Train: 2018-08-01T00:44:59.910218: step 13101, loss 0.613134.
Train: 2018-08-01T00:45:00.066432: step 13102, loss 0.646729.
Train: 2018-08-01T00:45:00.222682: step 13103, loss 0.512046.
Train: 2018-08-01T00:45:00.378889: step 13104, loss 0.528938.
Train: 2018-08-01T00:45:00.550718: step 13105, loss 0.5792.
Train: 2018-08-01T00:45:00.706939: step 13106, loss 0.579183.
Train: 2018-08-01T00:45:00.863122: step 13107, loss 0.612525.
Train: 2018-08-01T00:45:01.019335: step 13108, loss 0.579144.
Train: 2018-08-01T00:45:01.175548: step 13109, loss 0.496068.
Train: 2018-08-01T00:45:01.331792: step 13110, loss 0.579117.
Test: 2018-08-01T00:45:01.816053: step 13110, loss 0.548636.
Train: 2018-08-01T00:45:01.972266: step 13111, loss 0.579109.
Train: 2018-08-01T00:45:02.128480: step 13112, loss 0.529389.
Train: 2018-08-01T00:45:02.284664: step 13113, loss 0.612235.
Train: 2018-08-01T00:45:02.440906: step 13114, loss 0.545983.
Train: 2018-08-01T00:45:02.612710: step 13115, loss 0.562541.
Train: 2018-08-01T00:45:02.768961: step 13116, loss 0.397088.
Train: 2018-08-01T00:45:02.940790: step 13117, loss 0.463017.
Train: 2018-08-01T00:45:03.097002: step 13118, loss 0.445979.
Train: 2018-08-01T00:45:03.253217: step 13119, loss 0.595929.
Train: 2018-08-01T00:45:03.409433: step 13120, loss 0.579247.
Test: 2018-08-01T00:45:03.878068: step 13120, loss 0.548314.
Train: 2018-08-01T00:45:04.049905: step 13121, loss 0.596151.
Train: 2018-08-01T00:45:04.206087: step 13122, loss 0.44408.
Train: 2018-08-01T00:45:04.362331: step 13123, loss 0.596364.
Train: 2018-08-01T00:45:04.518545: step 13124, loss 0.579436.
Train: 2018-08-01T00:45:04.674728: step 13125, loss 0.52824.
Train: 2018-08-01T00:45:04.830942: step 13126, loss 0.493877.
Train: 2018-08-01T00:45:05.018423: step 13127, loss 0.562398.
Train: 2018-08-01T00:45:05.174624: step 13128, loss 0.562401.
Train: 2018-08-01T00:45:05.330855: step 13129, loss 0.683484.
Train: 2018-08-01T00:45:05.487068: step 13130, loss 0.493155.
Test: 2018-08-01T00:45:05.955678: step 13130, loss 0.547888.
Train: 2018-08-01T00:45:06.127514: step 13131, loss 0.631783.
Train: 2018-08-01T00:45:06.283759: step 13132, loss 0.527706.
Train: 2018-08-01T00:45:06.439970: step 13133, loss 0.440824.
Train: 2018-08-01T00:45:06.596184: step 13134, loss 0.562423.
Train: 2018-08-01T00:45:06.768021: step 13135, loss 0.562431.
Train: 2018-08-01T00:45:06.924231: step 13136, loss 0.562438.
Train: 2018-08-01T00:45:07.080415: step 13137, loss 0.544934.
Train: 2018-08-01T00:45:07.236653: step 13138, loss 0.615074.
Train: 2018-08-01T00:45:07.392874: step 13139, loss 0.562458.
Train: 2018-08-01T00:45:07.549056: step 13140, loss 0.562461.
Test: 2018-08-01T00:45:08.033349: step 13140, loss 0.54775.
Train: 2018-08-01T00:45:08.189560: step 13141, loss 0.527322.
Train: 2018-08-01T00:45:08.345744: step 13142, loss 0.580052.
Train: 2018-08-01T00:45:08.501957: step 13143, loss 0.597653.
Train: 2018-08-01T00:45:08.673791: step 13144, loss 0.632823.
Train: 2018-08-01T00:45:08.814383: step 13145, loss 0.527326.
Train: 2018-08-01T00:45:08.970597: step 13146, loss 0.509788.
Train: 2018-08-01T00:45:09.126811: step 13147, loss 0.615133.
Train: 2018-08-01T00:45:09.283024: step 13148, loss 0.667726.
Train: 2018-08-01T00:45:09.454858: step 13149, loss 0.50992.
Train: 2018-08-01T00:45:09.595481: step 13150, loss 0.475008.
Test: 2018-08-01T00:45:10.079712: step 13150, loss 0.547797.
Train: 2018-08-01T00:45:10.235927: step 13151, loss 0.562439.
Train: 2018-08-01T00:45:10.392139: step 13152, loss 0.457536.
Train: 2018-08-01T00:45:10.579596: step 13153, loss 0.474918.
Train: 2018-08-01T00:45:10.720188: step 13154, loss 0.63263.
Train: 2018-08-01T00:45:10.876401: step 13155, loss 0.56246.
Train: 2018-08-01T00:45:11.032614: step 13156, loss 0.492163.
Train: 2018-08-01T00:45:11.188828: step 13157, loss 0.59768.
Train: 2018-08-01T00:45:11.345042: step 13158, loss 0.544861.
Train: 2018-08-01T00:45:11.501255: step 13159, loss 0.597755.
Train: 2018-08-01T00:45:11.688711: step 13160, loss 0.562487.
Test: 2018-08-01T00:45:12.157383: step 13160, loss 0.547714.
Train: 2018-08-01T00:45:12.313594: step 13161, loss 0.509556.
Train: 2018-08-01T00:45:12.469808: step 13162, loss 0.562493.
Train: 2018-08-01T00:45:12.625991: step 13163, loss 0.509493.
Train: 2018-08-01T00:45:12.813483: step 13164, loss 0.50944.
Train: 2018-08-01T00:45:12.969661: step 13165, loss 0.456215.
Train: 2018-08-01T00:45:13.125905: step 13166, loss 0.562539.
Train: 2018-08-01T00:45:13.282120: step 13167, loss 0.651593.
Train: 2018-08-01T00:45:13.438302: step 13168, loss 0.491278.
Train: 2018-08-01T00:45:13.578925: step 13169, loss 0.544731.
Train: 2018-08-01T00:45:13.750754: step 13170, loss 0.419582.
Test: 2018-08-01T00:45:14.219367: step 13170, loss 0.547611.
Train: 2018-08-01T00:45:14.391202: step 13171, loss 0.580557.
Train: 2018-08-01T00:45:14.547416: step 13172, loss 0.526705.
Train: 2018-08-01T00:45:14.703660: step 13173, loss 0.61673.
Train: 2018-08-01T00:45:14.875503: step 13174, loss 0.544654.
Train: 2018-08-01T00:45:15.031702: step 13175, loss 0.472387.
Train: 2018-08-01T00:45:15.187891: step 13176, loss 0.617049.
Train: 2018-08-01T00:45:15.344135: step 13177, loss 0.635246.
Train: 2018-08-01T00:45:15.500348: step 13178, loss 0.508386.
Train: 2018-08-01T00:45:15.656556: step 13179, loss 0.490238.
Train: 2018-08-01T00:45:15.812745: step 13180, loss 0.417572.
Test: 2018-08-01T00:45:16.281418: step 13180, loss 0.547571.
Train: 2018-08-01T00:45:16.453220: step 13181, loss 0.581006.
Train: 2018-08-01T00:45:16.609467: step 13182, loss 0.58107.
Train: 2018-08-01T00:45:16.765677: step 13183, loss 0.599373.
Train: 2018-08-01T00:45:16.921891: step 13184, loss 0.599403.
Train: 2018-08-01T00:45:17.078074: step 13185, loss 0.581132.
Train: 2018-08-01T00:45:17.234317: step 13186, loss 0.690661.
Train: 2018-08-01T00:45:17.390533: step 13187, loss 0.544607.
Train: 2018-08-01T00:45:17.546744: step 13188, loss 0.580982.
Train: 2018-08-01T00:45:17.702957: step 13189, loss 0.562769.
Train: 2018-08-01T00:45:17.859140: step 13190, loss 0.598956.
Test: 2018-08-01T00:45:18.312190: step 13190, loss 0.547585.
Train: 2018-08-01T00:45:18.468373: step 13191, loss 0.580773.
Train: 2018-08-01T00:45:18.624587: step 13192, loss 0.598709.
Train: 2018-08-01T00:45:18.780833: step 13193, loss 0.508757.
Train: 2018-08-01T00:45:18.937044: step 13194, loss 0.670168.
Train: 2018-08-01T00:45:19.093262: step 13195, loss 0.598315.
Train: 2018-08-01T00:45:19.265062: step 13196, loss 0.669347.
Train: 2018-08-01T00:45:19.405653: step 13197, loss 0.633373.
Train: 2018-08-01T00:45:19.561867: step 13198, loss 0.456756.
Train: 2018-08-01T00:45:19.718111: step 13199, loss 0.580018.
Train: 2018-08-01T00:45:19.874318: step 13200, loss 0.562442.
Test: 2018-08-01T00:45:20.342964: step 13200, loss 0.547823.
Train: 2018-08-01T00:45:21.014684: step 13201, loss 0.632199.
Train: 2018-08-01T00:45:21.170866: step 13202, loss 0.666669.
Train: 2018-08-01T00:45:21.327109: step 13203, loss 0.562404.
Train: 2018-08-01T00:45:21.498914: step 13204, loss 0.545185.
Train: 2018-08-01T00:45:21.639530: step 13205, loss 0.596694.
Train: 2018-08-01T00:45:21.795719: step 13206, loss 0.5624.
Train: 2018-08-01T00:45:21.951962: step 13207, loss 0.681552.
Train: 2018-08-01T00:45:22.108146: step 13208, loss 0.680992.
Train: 2018-08-01T00:45:22.264360: step 13209, loss 0.427726.
Train: 2018-08-01T00:45:22.420573: step 13210, loss 0.629577.
Test: 2018-08-01T00:45:22.904833: step 13210, loss 0.548476.
Train: 2018-08-01T00:45:23.061078: step 13211, loss 0.512329.
Train: 2018-08-01T00:45:23.217261: step 13212, loss 0.662498.
Train: 2018-08-01T00:45:23.373504: step 13213, loss 0.562515.
Train: 2018-08-01T00:45:23.529687: step 13214, loss 0.579089.
Train: 2018-08-01T00:45:23.701522: step 13215, loss 0.513082.
Train: 2018-08-01T00:45:23.857737: step 13216, loss 0.529661.
Train: 2018-08-01T00:45:24.029604: step 13217, loss 0.480387.
Train: 2018-08-01T00:45:24.185783: step 13218, loss 0.661268.
Train: 2018-08-01T00:45:24.342034: step 13219, loss 0.464035.
Train: 2018-08-01T00:45:24.498212: step 13220, loss 0.579035.
Test: 2018-08-01T00:45:24.966850: step 13220, loss 0.548822.
Train: 2018-08-01T00:45:25.123066: step 13221, loss 0.562593.
Train: 2018-08-01T00:45:25.279312: step 13222, loss 0.546134.
Train: 2018-08-01T00:45:25.451143: step 13223, loss 0.628454.
Train: 2018-08-01T00:45:25.607326: step 13224, loss 0.480245.
Train: 2018-08-01T00:45:25.763564: step 13225, loss 0.529594.
Train: 2018-08-01T00:45:25.935376: step 13226, loss 0.579073.
Train: 2018-08-01T00:45:26.091588: step 13227, loss 0.562544.
Train: 2018-08-01T00:45:26.247802: step 13228, loss 0.545968.
Train: 2018-08-01T00:45:26.404016: step 13229, loss 0.462968.
Train: 2018-08-01T00:45:26.560229: step 13230, loss 0.495931.
Test: 2018-08-01T00:45:27.028868: step 13230, loss 0.548488.
Train: 2018-08-01T00:45:27.200734: step 13231, loss 0.512362.
Train: 2018-08-01T00:45:27.356916: step 13232, loss 0.596003.
Train: 2018-08-01T00:45:27.513130: step 13233, loss 0.545608.
Train: 2018-08-01T00:45:27.669374: step 13234, loss 0.511768.
Train: 2018-08-01T00:45:27.825587: step 13235, loss 0.579362.
Train: 2018-08-01T00:45:27.981771: step 13236, loss 0.528403.
Train: 2018-08-01T00:45:28.153606: step 13237, loss 0.613575.
Train: 2018-08-01T00:45:28.309849: step 13238, loss 0.528205.
Train: 2018-08-01T00:45:28.450441: step 13239, loss 0.596677.
Train: 2018-08-01T00:45:28.622245: step 13240, loss 0.631081.
Test: 2018-08-01T00:45:29.090912: step 13240, loss 0.548009.
Train: 2018-08-01T00:45:29.262751: step 13241, loss 0.665495.
Train: 2018-08-01T00:45:29.418964: step 13242, loss 0.613906.
Train: 2018-08-01T00:45:29.575177: step 13243, loss 0.579543.
Train: 2018-08-01T00:45:29.731385: step 13244, loss 0.617181.
Train: 2018-08-01T00:45:29.887575: step 13245, loss 0.579483.
Train: 2018-08-01T00:45:30.043812: step 13246, loss 0.528306.
Train: 2018-08-01T00:45:30.200026: step 13247, loss 0.54538.
Train: 2018-08-01T00:45:30.371865: step 13248, loss 0.545399.
Train: 2018-08-01T00:45:30.528048: step 13249, loss 0.613393.
Train: 2018-08-01T00:45:30.684293: step 13250, loss 0.409644.
Test: 2018-08-01T00:45:31.152936: step 13250, loss 0.54818.
Train: 2018-08-01T00:45:31.309143: step 13251, loss 0.477452.
Train: 2018-08-01T00:45:31.480981: step 13252, loss 0.528349.
Train: 2018-08-01T00:45:31.637164: step 13253, loss 0.579468.
Train: 2018-08-01T00:45:31.793408: step 13254, loss 0.613701.
Train: 2018-08-01T00:45:31.949621: step 13255, loss 0.682229.
Train: 2018-08-01T00:45:32.105834: step 13256, loss 0.579505.
Train: 2018-08-01T00:45:32.262048: step 13257, loss 0.528213.
Train: 2018-08-01T00:45:32.418268: step 13258, loss 0.528223.
Train: 2018-08-01T00:45:32.590096: step 13259, loss 0.664949.
Train: 2018-08-01T00:45:32.730658: step 13260, loss 0.528257.
Test: 2018-08-01T00:45:33.214950: step 13260, loss 0.548114.
Train: 2018-08-01T00:45:33.371163: step 13261, loss 0.562401.
Train: 2018-08-01T00:45:33.542971: step 13262, loss 0.579454.
Train: 2018-08-01T00:45:33.699181: step 13263, loss 0.562402.
Train: 2018-08-01T00:45:33.855395: step 13264, loss 0.647559.
Train: 2018-08-01T00:45:34.011639: step 13265, loss 0.613414.
Train: 2018-08-01T00:45:34.167852: step 13266, loss 0.477584.
Train: 2018-08-01T00:45:34.324036: step 13267, loss 0.579366.
Train: 2018-08-01T00:45:34.480249: step 13268, loss 0.613228.
Train: 2018-08-01T00:45:34.636492: step 13269, loss 0.579333.
Train: 2018-08-01T00:45:34.792705: step 13270, loss 0.562425.
Test: 2018-08-01T00:45:35.261345: step 13270, loss 0.548308.
Train: 2018-08-01T00:45:35.417529: step 13271, loss 0.697347.
Train: 2018-08-01T00:45:35.573743: step 13272, loss 0.59607.
Train: 2018-08-01T00:45:35.729984: step 13273, loss 0.528936.
Train: 2018-08-01T00:45:35.886202: step 13274, loss 0.595915.
Train: 2018-08-01T00:45:36.042383: step 13275, loss 0.462397.
Train: 2018-08-01T00:45:36.198626: step 13276, loss 0.662506.
Train: 2018-08-01T00:45:36.354840: step 13277, loss 0.495955.
Train: 2018-08-01T00:45:36.511053: step 13278, loss 0.595756.
Train: 2018-08-01T00:45:36.667267: step 13279, loss 0.628944.
Train: 2018-08-01T00:45:36.870314: step 13280, loss 0.512793.
Test: 2018-08-01T00:45:37.338954: step 13280, loss 0.548661.
Train: 2018-08-01T00:45:37.495197: step 13281, loss 0.628792.
Train: 2018-08-01T00:45:37.651414: step 13282, loss 0.579084.
Train: 2018-08-01T00:45:37.807619: step 13283, loss 0.645126.
Train: 2018-08-01T00:45:37.979454: step 13284, loss 0.611997.
Train: 2018-08-01T00:45:38.135676: step 13285, loss 0.513324.
Train: 2018-08-01T00:45:38.291856: step 13286, loss 0.546221.
Train: 2018-08-01T00:45:38.432478: step 13287, loss 0.595391.
Train: 2018-08-01T00:45:38.604313: step 13288, loss 0.562644.
Train: 2018-08-01T00:45:38.760496: step 13289, loss 0.628017.
Train: 2018-08-01T00:45:38.916710: step 13290, loss 0.578985.
Test: 2018-08-01T00:45:39.385380: step 13290, loss 0.549057.
Train: 2018-08-01T00:45:39.541593: step 13291, loss 0.513842.
Train: 2018-08-01T00:45:39.697806: step 13292, loss 0.5627.
Train: 2018-08-01T00:45:39.854020: step 13293, loss 0.562704.
Train: 2018-08-01T00:45:40.010234: step 13294, loss 0.530179.
Train: 2018-08-01T00:45:40.166447: step 13295, loss 0.611516.
Train: 2018-08-01T00:45:40.322630: step 13296, loss 0.497623.
Train: 2018-08-01T00:45:40.478869: step 13297, loss 0.464969.
Train: 2018-08-01T00:45:40.635087: step 13298, loss 0.59532.
Train: 2018-08-01T00:45:40.791301: step 13299, loss 0.513559.
Train: 2018-08-01T00:45:40.947484: step 13300, loss 0.562616.
Test: 2018-08-01T00:45:41.416155: step 13300, loss 0.54882.
Train: 2018-08-01T00:45:42.119085: step 13301, loss 0.546146.
Train: 2018-08-01T00:45:42.290950: step 13302, loss 0.595549.
Train: 2018-08-01T00:45:42.447164: step 13303, loss 0.529505.
Train: 2018-08-01T00:45:42.603377: step 13304, loss 0.562533.
Train: 2018-08-01T00:45:42.775210: step 13305, loss 0.462907.
Train: 2018-08-01T00:45:42.931420: step 13306, loss 0.495847.
Train: 2018-08-01T00:45:43.087638: step 13307, loss 0.512268.
Train: 2018-08-01T00:45:43.243852: step 13308, loss 0.596064.
Train: 2018-08-01T00:45:43.415656: step 13309, loss 0.545555.
Train: 2018-08-01T00:45:43.556248: step 13310, loss 0.630154.
Test: 2018-08-01T00:45:44.040508: step 13310, loss 0.548195.
Train: 2018-08-01T00:45:44.212375: step 13311, loss 0.52846.
Train: 2018-08-01T00:45:44.368588: step 13312, loss 0.477308.
Train: 2018-08-01T00:45:44.556044: step 13313, loss 0.579479.
Train: 2018-08-01T00:45:44.712258: step 13314, loss 0.528136.
Train: 2018-08-01T00:45:44.868442: step 13315, loss 0.528028.
Train: 2018-08-01T00:45:45.024654: step 13316, loss 0.57964.
Train: 2018-08-01T00:45:45.180867: step 13317, loss 0.666127.
Train: 2018-08-01T00:45:45.337106: step 13318, loss 0.493187.
Train: 2018-08-01T00:45:45.493295: step 13319, loss 0.47573.
Train: 2018-08-01T00:45:45.665130: step 13320, loss 0.614567.
Test: 2018-08-01T00:45:46.149424: step 13320, loss 0.54784.
Train: 2018-08-01T00:45:46.305634: step 13321, loss 0.579836.
Train: 2018-08-01T00:45:46.461848: step 13322, loss 0.649605.
Train: 2018-08-01T00:45:46.633679: step 13323, loss 0.632166.
Train: 2018-08-01T00:45:46.789896: step 13324, loss 0.527588.
Train: 2018-08-01T00:45:46.946079: step 13325, loss 0.666872.
Train: 2018-08-01T00:45:47.117939: step 13326, loss 0.527663.
Train: 2018-08-01T00:45:47.274128: step 13327, loss 0.51035.
Train: 2018-08-01T00:45:47.414721: step 13328, loss 0.597102.
Train: 2018-08-01T00:45:47.570934: step 13329, loss 0.51042.
Train: 2018-08-01T00:45:47.727165: step 13330, loss 0.562408.
Test: 2018-08-01T00:45:48.211408: step 13330, loss 0.547901.
Train: 2018-08-01T00:45:48.367621: step 13331, loss 0.562408.
Train: 2018-08-01T00:45:48.523860: step 13332, loss 0.614366.
Train: 2018-08-01T00:45:48.680074: step 13333, loss 0.527797.
Train: 2018-08-01T00:45:48.836262: step 13334, loss 0.614297.
Train: 2018-08-01T00:45:48.992475: step 13335, loss 0.683358.
Train: 2018-08-01T00:45:49.164334: step 13336, loss 0.545165.
Train: 2018-08-01T00:45:49.320554: step 13337, loss 0.562398.
Train: 2018-08-01T00:45:49.476767: step 13338, loss 0.64822.
Train: 2018-08-01T00:45:49.632981: step 13339, loss 0.476823.
Train: 2018-08-01T00:45:49.789194: step 13340, loss 0.545308.
Test: 2018-08-01T00:45:50.257834: step 13340, loss 0.548104.
Train: 2018-08-01T00:45:50.414042: step 13341, loss 0.545328.
Train: 2018-08-01T00:45:50.570230: step 13342, loss 0.596521.
Train: 2018-08-01T00:45:50.726468: step 13343, loss 0.54536.
Train: 2018-08-01T00:45:50.882657: step 13344, loss 0.460227.
Train: 2018-08-01T00:45:51.038871: step 13345, loss 0.61353.
Train: 2018-08-01T00:45:51.195084: step 13346, loss 0.545359.
Train: 2018-08-01T00:45:51.351328: step 13347, loss 0.613545.
Train: 2018-08-01T00:45:51.507542: step 13348, loss 0.613523.
Train: 2018-08-01T00:45:51.663725: step 13349, loss 0.562404.
Train: 2018-08-01T00:45:51.819938: step 13350, loss 0.528394.
Test: 2018-08-01T00:45:52.288578: step 13350, loss 0.548171.
Train: 2018-08-01T00:45:52.444791: step 13351, loss 0.528407.
Train: 2018-08-01T00:45:52.601035: step 13352, loss 0.477391.
Train: 2018-08-01T00:45:52.757218: step 13353, loss 0.596456.
Train: 2018-08-01T00:45:52.913467: step 13354, loss 0.613521.
Train: 2018-08-01T00:45:53.085291: step 13355, loss 0.494242.
Train: 2018-08-01T00:45:53.241480: step 13356, loss 0.528287.
Train: 2018-08-01T00:45:53.397693: step 13357, loss 0.596559.
Train: 2018-08-01T00:45:53.553937: step 13358, loss 0.596585.
Train: 2018-08-01T00:45:53.710150: step 13359, loss 0.562398.
Train: 2018-08-01T00:45:53.866334: step 13360, loss 0.545297.
Test: 2018-08-01T00:45:54.350595: step 13360, loss 0.548071.
Train: 2018-08-01T00:45:54.506809: step 13361, loss 0.493961.
Train: 2018-08-01T00:45:54.663022: step 13362, loss 0.630926.
Train: 2018-08-01T00:45:54.819236: step 13363, loss 0.54526.
Train: 2018-08-01T00:45:54.975449: step 13364, loss 0.613833.
Train: 2018-08-01T00:45:55.131663: step 13365, loss 0.596679.
Train: 2018-08-01T00:45:55.287875: step 13366, loss 0.613784.
Train: 2018-08-01T00:45:55.444090: step 13367, loss 0.59661.
Train: 2018-08-01T00:45:55.600303: step 13368, loss 0.596555.
Train: 2018-08-01T00:45:55.756517: step 13369, loss 0.630579.
Train: 2018-08-01T00:45:55.912760: step 13370, loss 0.545408.
Test: 2018-08-01T00:45:56.381400: step 13370, loss 0.548208.
Train: 2018-08-01T00:45:56.553205: step 13371, loss 0.596335.
Train: 2018-08-01T00:45:56.709448: step 13372, loss 0.579339.
Train: 2018-08-01T00:45:56.850010: step 13373, loss 0.663715.
Train: 2018-08-01T00:45:57.006224: step 13374, loss 0.612907.
Train: 2018-08-01T00:45:57.178089: step 13375, loss 0.595974.
Train: 2018-08-01T00:45:57.334302: step 13376, loss 0.495706.
Train: 2018-08-01T00:45:57.490486: step 13377, loss 0.662412.
Train: 2018-08-01T00:45:57.662319: step 13378, loss 0.545926.
Train: 2018-08-01T00:45:57.818558: step 13379, loss 0.529448.
Train: 2018-08-01T00:45:57.974777: step 13380, loss 0.57907.
Test: 2018-08-01T00:45:58.443419: step 13380, loss 0.548771.
Train: 2018-08-01T00:45:58.599600: step 13381, loss 0.595537.
Train: 2018-08-01T00:45:58.787080: step 13382, loss 0.513248.
Train: 2018-08-01T00:45:58.943301: step 13383, loss 0.529738.
Train: 2018-08-01T00:45:59.099483: step 13384, loss 0.62831.
Train: 2018-08-01T00:45:59.255729: step 13385, loss 0.496979.
Train: 2018-08-01T00:45:59.411910: step 13386, loss 0.546201.
Train: 2018-08-01T00:45:59.568124: step 13387, loss 0.513349.
Train: 2018-08-01T00:45:59.724367: step 13388, loss 0.51327.
Train: 2018-08-01T00:45:59.911793: step 13389, loss 0.546101.
Train: 2018-08-01T00:46:00.068007: step 13390, loss 0.496507.
Test: 2018-08-01T00:46:00.536646: step 13390, loss 0.548662.
Train: 2018-08-01T00:46:00.692890: step 13391, loss 0.479713.
Train: 2018-08-01T00:46:00.849105: step 13392, loss 0.579135.
Train: 2018-08-01T00:46:01.020932: step 13393, loss 0.445641.
Train: 2018-08-01T00:46:01.177148: step 13394, loss 0.596001.
Train: 2018-08-01T00:46:01.333335: step 13395, loss 0.545593.
Train: 2018-08-01T00:46:01.489548: step 13396, loss 0.528606.
Train: 2018-08-01T00:46:01.645795: step 13397, loss 0.613336.
Train: 2018-08-01T00:46:01.802006: step 13398, loss 0.494302.
Train: 2018-08-01T00:46:01.973812: step 13399, loss 0.562399.
Train: 2018-08-01T00:46:02.130054: step 13400, loss 0.596681.
Test: 2018-08-01T00:46:02.598693: step 13400, loss 0.548007.
Train: 2018-08-01T00:46:03.270415: step 13401, loss 0.545213.
Train: 2018-08-01T00:46:03.426626: step 13402, loss 0.545173.
Train: 2018-08-01T00:46:03.582839: step 13403, loss 0.562401.
Train: 2018-08-01T00:46:03.739021: step 13404, loss 0.597013.
Train: 2018-08-01T00:46:03.895269: step 13405, loss 0.631723.
Train: 2018-08-01T00:46:04.051448: step 13406, loss 0.666414.
Train: 2018-08-01T00:46:04.223284: step 13407, loss 0.631664.
Train: 2018-08-01T00:46:04.363876: step 13408, loss 0.545123.
Train: 2018-08-01T00:46:04.520114: step 13409, loss 0.545148.
Train: 2018-08-01T00:46:04.676302: step 13410, loss 0.562399.
Test: 2018-08-01T00:46:05.144975: step 13410, loss 0.547984.
Train: 2018-08-01T00:46:05.332434: step 13411, loss 0.527973.
Train: 2018-08-01T00:46:05.473016: step 13412, loss 0.562398.
Train: 2018-08-01T00:46:05.644825: step 13413, loss 0.528008.
Train: 2018-08-01T00:46:05.801069: step 13414, loss 0.648373.
Train: 2018-08-01T00:46:05.957252: step 13415, loss 0.631098.
Train: 2018-08-01T00:46:06.113496: step 13416, loss 0.562397.
Train: 2018-08-01T00:46:06.254088: step 13417, loss 0.630838.
Train: 2018-08-01T00:46:06.425893: step 13418, loss 0.698931.
Train: 2018-08-01T00:46:06.582130: step 13419, loss 0.511422.
Train: 2018-08-01T00:46:06.722729: step 13420, loss 0.579358.
Test: 2018-08-01T00:46:07.191363: step 13420, loss 0.548277.
Train: 2018-08-01T00:46:07.363203: step 13421, loss 0.511742.
Train: 2018-08-01T00:46:07.519387: step 13422, loss 0.697325.
Train: 2018-08-01T00:46:07.675635: step 13423, loss 0.562445.
Train: 2018-08-01T00:46:07.831838: step 13424, loss 0.461967.
Train: 2018-08-01T00:46:07.988028: step 13425, loss 0.646102.
Train: 2018-08-01T00:46:08.144240: step 13426, loss 0.495729.
Train: 2018-08-01T00:46:08.300453: step 13427, loss 0.495804.
Train: 2018-08-01T00:46:08.472289: step 13428, loss 0.679198.
Train: 2018-08-01T00:46:08.628503: step 13429, loss 0.612441.
Train: 2018-08-01T00:46:08.784745: step 13430, loss 0.612356.
Test: 2018-08-01T00:46:09.268977: step 13430, loss 0.548647.
Train: 2018-08-01T00:46:09.425190: step 13431, loss 0.595679.
Train: 2018-08-01T00:46:09.581404: step 13432, loss 0.595614.
Train: 2018-08-01T00:46:09.753238: step 13433, loss 0.595548.
Train: 2018-08-01T00:46:09.909451: step 13434, loss 0.431042.
Train: 2018-08-01T00:46:10.065696: step 13435, loss 0.480411.
Train: 2018-08-01T00:46:10.221909: step 13436, loss 0.546134.
Train: 2018-08-01T00:46:10.378091: step 13437, loss 0.447254.
Train: 2018-08-01T00:46:10.534306: step 13438, loss 0.628646.
Train: 2018-08-01T00:46:10.690519: step 13439, loss 0.545984.
Train: 2018-08-01T00:46:10.877999: step 13440, loss 0.496176.
Test: 2018-08-01T00:46:11.346649: step 13440, loss 0.548573.
Train: 2018-08-01T00:46:11.502853: step 13441, loss 0.612404.
Train: 2018-08-01T00:46:11.659076: step 13442, loss 0.512491.
Train: 2018-08-01T00:46:11.830906: step 13443, loss 0.529056.
Train: 2018-08-01T00:46:12.002738: step 13444, loss 0.545702.
Train: 2018-08-01T00:46:12.158954: step 13445, loss 0.512029.
Train: 2018-08-01T00:46:12.315170: step 13446, loss 0.596153.
Train: 2018-08-01T00:46:12.471382: step 13447, loss 0.494799.
Train: 2018-08-01T00:46:12.627566: step 13448, loss 0.562411.
Train: 2018-08-01T00:46:12.783809: step 13449, loss 0.562405.
Train: 2018-08-01T00:46:12.939992: step 13450, loss 0.442983.
Test: 2018-08-01T00:46:13.424254: step 13450, loss 0.548053.
Train: 2018-08-01T00:46:13.580497: step 13451, loss 0.562397.
Train: 2018-08-01T00:46:13.736711: step 13452, loss 0.648363.
Train: 2018-08-01T00:46:13.892895: step 13453, loss 0.527939.
Train: 2018-08-01T00:46:14.049148: step 13454, loss 0.596943.
Train: 2018-08-01T00:46:14.205320: step 13455, loss 0.735398.
Train: 2018-08-01T00:46:14.361565: step 13456, loss 0.458696.
Train: 2018-08-01T00:46:14.517773: step 13457, loss 0.493225.
Train: 2018-08-01T00:46:14.689583: step 13458, loss 0.475809.
Train: 2018-08-01T00:46:14.845826: step 13459, loss 0.753385.
Train: 2018-08-01T00:46:15.002042: step 13460, loss 0.562411.
Test: 2018-08-01T00:46:15.470679: step 13460, loss 0.547884.
Train: 2018-08-01T00:46:15.626896: step 13461, loss 0.527716.
Train: 2018-08-01T00:46:15.829971: step 13462, loss 0.597108.
Train: 2018-08-01T00:46:15.986184: step 13463, loss 0.475704.
Train: 2018-08-01T00:46:16.142368: step 13464, loss 0.579765.
Train: 2018-08-01T00:46:16.314232: step 13465, loss 0.406169.
Train: 2018-08-01T00:46:16.470416: step 13466, loss 0.649427.
Train: 2018-08-01T00:46:16.626661: step 13467, loss 0.527587.
Train: 2018-08-01T00:46:16.782843: step 13468, loss 0.579867.
Train: 2018-08-01T00:46:16.939055: step 13469, loss 0.579886.
Train: 2018-08-01T00:46:17.095270: step 13470, loss 0.579896.
Test: 2018-08-01T00:46:17.563908: step 13470, loss 0.547807.
Train: 2018-08-01T00:46:17.720153: step 13471, loss 0.737096.
Train: 2018-08-01T00:46:17.876366: step 13472, loss 0.492712.
Train: 2018-08-01T00:46:18.032580: step 13473, loss 0.492785.
Train: 2018-08-01T00:46:18.188793: step 13474, loss 0.562421.
Train: 2018-08-01T00:46:18.345007: step 13475, loss 0.666845.
Train: 2018-08-01T00:46:18.516845: step 13476, loss 0.545038.
Train: 2018-08-01T00:46:18.673049: step 13477, loss 0.545056.
Train: 2018-08-01T00:46:18.829268: step 13478, loss 0.545069.
Train: 2018-08-01T00:46:19.001106: step 13479, loss 0.475758.
Train: 2018-08-01T00:46:19.157321: step 13480, loss 0.54507.
Test: 2018-08-01T00:46:19.641581: step 13480, loss 0.547881.
Train: 2018-08-01T00:46:19.797792: step 13481, loss 0.562411.
Train: 2018-08-01T00:46:19.969627: step 13482, loss 0.54505.
Train: 2018-08-01T00:46:20.125840: step 13483, loss 0.492914.
Train: 2018-08-01T00:46:20.282022: step 13484, loss 0.649428.
Train: 2018-08-01T00:46:20.453882: step 13485, loss 0.579825.
Train: 2018-08-01T00:46:20.610108: step 13486, loss 0.545016.
Train: 2018-08-01T00:46:20.766284: step 13487, loss 0.579825.
Train: 2018-08-01T00:46:20.922498: step 13488, loss 0.579821.
Train: 2018-08-01T00:46:21.094333: step 13489, loss 0.510235.
Train: 2018-08-01T00:46:21.234955: step 13490, loss 0.597216.
Test: 2018-08-01T00:46:21.703590: step 13490, loss 0.547853.
Train: 2018-08-01T00:46:21.875400: step 13491, loss 0.492842.
Train: 2018-08-01T00:46:22.047235: step 13492, loss 0.56242.
Train: 2018-08-01T00:46:22.203478: step 13493, loss 0.579836.
Train: 2018-08-01T00:46:22.359661: step 13494, loss 0.527588.
Train: 2018-08-01T00:46:22.500284: step 13495, loss 0.614707.
Train: 2018-08-01T00:46:22.656497: step 13496, loss 0.562424.
Train: 2018-08-01T00:46:22.828303: step 13497, loss 0.597263.
Train: 2018-08-01T00:46:22.984539: step 13498, loss 0.49279.
Train: 2018-08-01T00:46:23.140753: step 13499, loss 0.54501.
Train: 2018-08-01T00:46:23.296972: step 13500, loss 0.527586.
Test: 2018-08-01T00:46:23.765584: step 13500, loss 0.547828.
Train: 2018-08-01T00:46:24.484189: step 13501, loss 0.597289.
Train: 2018-08-01T00:46:24.656029: step 13502, loss 0.527556.
Train: 2018-08-01T00:46:24.812213: step 13503, loss 0.527539.
Train: 2018-08-01T00:46:24.968465: step 13504, loss 0.510049.
Train: 2018-08-01T00:46:25.140261: step 13505, loss 0.457519.
Train: 2018-08-01T00:46:25.296473: step 13506, loss 0.527386.
Train: 2018-08-01T00:46:25.452717: step 13507, loss 0.474563.
Train: 2018-08-01T00:46:25.608931: step 13508, loss 0.580129.
Train: 2018-08-01T00:46:25.765113: step 13509, loss 0.615584.
Train: 2018-08-01T00:46:25.921327: step 13510, loss 0.580244.
Test: 2018-08-01T00:46:26.390000: step 13510, loss 0.547668.
Train: 2018-08-01T00:46:26.546206: step 13511, loss 0.544783.
Train: 2018-08-01T00:46:26.718051: step 13512, loss 0.54477.
Train: 2018-08-01T00:46:26.874262: step 13513, loss 0.615928.
Train: 2018-08-01T00:46:27.030467: step 13514, loss 0.491358.
Train: 2018-08-01T00:46:27.186657: step 13515, loss 0.633838.
Train: 2018-08-01T00:46:27.342906: step 13516, loss 0.544745.
Train: 2018-08-01T00:46:27.499082: step 13517, loss 0.509103.
Train: 2018-08-01T00:46:27.655321: step 13518, loss 0.491243.
Train: 2018-08-01T00:46:27.811511: step 13519, loss 0.562583.
Train: 2018-08-01T00:46:27.967723: step 13520, loss 0.544718.
Test: 2018-08-01T00:46:28.436393: step 13520, loss 0.547619.
Train: 2018-08-01T00:46:28.592607: step 13521, loss 0.616292.
Train: 2018-08-01T00:46:28.748791: step 13522, loss 0.491009.
Train: 2018-08-01T00:46:28.920624: step 13523, loss 0.526784.
Train: 2018-08-01T00:46:29.076869: step 13524, loss 0.652314.
Train: 2018-08-01T00:46:29.233076: step 13525, loss 0.598493.
Train: 2018-08-01T00:46:29.389291: step 13526, loss 0.616378.
Train: 2018-08-01T00:46:29.545479: step 13527, loss 0.59839.
Train: 2018-08-01T00:46:29.701721: step 13528, loss 0.562585.
Train: 2018-08-01T00:46:29.857905: step 13529, loss 0.616047.
Train: 2018-08-01T00:46:30.014120: step 13530, loss 0.455849.
Test: 2018-08-01T00:46:30.498406: step 13530, loss 0.547661.
Train: 2018-08-01T00:46:30.654624: step 13531, loss 0.491475.
Train: 2018-08-01T00:46:30.810808: step 13532, loss 0.544773.
Train: 2018-08-01T00:46:30.967020: step 13533, loss 0.580303.
Train: 2018-08-01T00:46:31.123234: step 13534, loss 0.509254.
Train: 2018-08-01T00:46:31.279447: step 13535, loss 0.438176.
Train: 2018-08-01T00:46:31.435660: step 13536, loss 0.562553.
Train: 2018-08-01T00:46:31.591875: step 13537, loss 0.509095.
Train: 2018-08-01T00:46:31.748113: step 13538, loss 0.598298.
Train: 2018-08-01T00:46:31.904302: step 13539, loss 0.52684.
Train: 2018-08-01T00:46:32.060545: step 13540, loss 0.580509.
Test: 2018-08-01T00:46:32.529185: step 13540, loss 0.547614.
Train: 2018-08-01T00:46:32.701019: step 13541, loss 0.562616.
Train: 2018-08-01T00:46:32.857234: step 13542, loss 0.544695.
Train: 2018-08-01T00:46:33.013449: step 13543, loss 0.54469.
Train: 2018-08-01T00:46:33.169667: step 13544, loss 0.544685.
Train: 2018-08-01T00:46:33.341465: step 13545, loss 0.562645.
Train: 2018-08-01T00:46:33.497710: step 13546, loss 0.616572.
Train: 2018-08-01T00:46:33.653916: step 13547, loss 0.47281.
Train: 2018-08-01T00:46:33.841378: step 13548, loss 0.562654.
Train: 2018-08-01T00:46:33.997561: step 13549, loss 0.544672.
Train: 2018-08-01T00:46:34.153805: step 13550, loss 0.562665.
Test: 2018-08-01T00:46:34.622415: step 13550, loss 0.547594.
Train: 2018-08-01T00:46:34.809895: step 13551, loss 0.670677.
Train: 2018-08-01T00:46:34.997359: step 13552, loss 0.616593.
Train: 2018-08-01T00:46:35.153570: step 13553, loss 0.598524.
Train: 2018-08-01T00:46:35.309754: step 13554, loss 0.652131.
Train: 2018-08-01T00:46:35.450346: step 13555, loss 0.616112.
Train: 2018-08-01T00:46:35.606590: step 13556, loss 0.544766.
Train: 2018-08-01T00:46:35.762806: step 13557, loss 0.633391.
Train: 2018-08-01T00:46:35.934638: step 13558, loss 0.509545.
Train: 2018-08-01T00:46:36.122064: step 13559, loss 0.56247.
Train: 2018-08-01T00:46:36.278307: step 13560, loss 0.562453.
Test: 2018-08-01T00:46:36.746947: step 13560, loss 0.547788.
Train: 2018-08-01T00:46:36.903161: step 13561, loss 0.544948.
Train: 2018-08-01T00:46:37.059369: step 13562, loss 0.475124.
Train: 2018-08-01T00:46:37.231203: step 13563, loss 0.387954.
Train: 2018-08-01T00:46:37.403044: step 13564, loss 0.510015.
Train: 2018-08-01T00:46:37.559258: step 13565, loss 0.527429.
Train: 2018-08-01T00:46:37.715470: step 13566, loss 0.61509.
Train: 2018-08-01T00:46:37.871655: step 13567, loss 0.527329.
Train: 2018-08-01T00:46:38.043518: step 13568, loss 0.615243.
Train: 2018-08-01T00:46:38.199702: step 13569, loss 0.562472.
Train: 2018-08-01T00:46:38.355945: step 13570, loss 0.632907.
Test: 2018-08-01T00:46:38.824585: step 13570, loss 0.547735.
Train: 2018-08-01T00:46:38.980799: step 13571, loss 0.544874.
Train: 2018-08-01T00:46:39.136983: step 13572, loss 0.615239.
Train: 2018-08-01T00:46:39.308818: step 13573, loss 0.509751.
Train: 2018-08-01T00:46:39.465061: step 13574, loss 0.61515.
Train: 2018-08-01T00:46:39.621269: step 13575, loss 0.615085.
Train: 2018-08-01T00:46:39.777483: step 13576, loss 0.544933.
Train: 2018-08-01T00:46:39.933701: step 13577, loss 0.579927.
Train: 2018-08-01T00:46:40.089914: step 13578, loss 0.492591.
Train: 2018-08-01T00:46:40.246097: step 13579, loss 0.719488.
Train: 2018-08-01T00:46:40.402340: step 13580, loss 0.614637.
Test: 2018-08-01T00:46:40.886606: step 13580, loss 0.547882.
Train: 2018-08-01T00:46:41.058439: step 13581, loss 0.54506.
Train: 2018-08-01T00:46:41.214620: step 13582, loss 0.475873.
Train: 2018-08-01T00:46:41.370865: step 13583, loss 0.527832.
Train: 2018-08-01T00:46:41.542705: step 13584, loss 0.476031.
Train: 2018-08-01T00:46:41.698907: step 13585, loss 0.562403.
Train: 2018-08-01T00:46:41.855095: step 13586, loss 0.545112.
Train: 2018-08-01T00:46:41.995718: step 13587, loss 0.579709.
Train: 2018-08-01T00:46:42.167553: step 13588, loss 0.562406.
Train: 2018-08-01T00:46:42.323736: step 13589, loss 0.562407.
Train: 2018-08-01T00:46:42.479949: step 13590, loss 0.614357.
Test: 2018-08-01T00:46:42.948590: step 13590, loss 0.547913.
Train: 2018-08-01T00:46:43.104804: step 13591, loss 0.527791.
Train: 2018-08-01T00:46:43.261018: step 13592, loss 0.666244.
Train: 2018-08-01T00:46:43.417231: step 13593, loss 0.562403.
Train: 2018-08-01T00:46:43.589065: step 13594, loss 0.683206.
Train: 2018-08-01T00:46:43.745278: step 13595, loss 0.510772.
Train: 2018-08-01T00:46:43.901492: step 13596, loss 0.631102.
Train: 2018-08-01T00:46:44.057705: step 13597, loss 0.579528.
Train: 2018-08-01T00:46:44.213950: step 13598, loss 0.476967.
Train: 2018-08-01T00:46:44.370164: step 13599, loss 0.528267.
Train: 2018-08-01T00:46:44.526345: step 13600, loss 0.528287.
Test: 2018-08-01T00:46:44.995016: step 13600, loss 0.548118.
Train: 2018-08-01T00:46:45.729188: step 13601, loss 0.681795.
Train: 2018-08-01T00:46:45.901024: step 13602, loss 0.443205.
Train: 2018-08-01T00:46:46.041646: step 13603, loss 0.545371.
Train: 2018-08-01T00:46:46.197859: step 13604, loss 0.494247.
Train: 2018-08-01T00:46:46.354067: step 13605, loss 0.579462.
Train: 2018-08-01T00:46:46.510256: step 13606, loss 0.545321.
Train: 2018-08-01T00:46:46.666499: step 13607, loss 0.5453.
Train: 2018-08-01T00:46:46.822713: step 13608, loss 0.562397.
Train: 2018-08-01T00:46:46.994519: step 13609, loss 0.545258.
Train: 2018-08-01T00:46:47.150731: step 13610, loss 0.61388.
Test: 2018-08-01T00:46:47.619371: step 13610, loss 0.54802.
Train: 2018-08-01T00:46:47.775616: step 13611, loss 0.613903.
Train: 2018-08-01T00:46:47.931835: step 13612, loss 0.545233.
Train: 2018-08-01T00:46:48.119284: step 13613, loss 0.493746.
Train: 2018-08-01T00:46:48.275467: step 13614, loss 0.510863.
Train: 2018-08-01T00:46:48.431705: step 13615, loss 0.648416.
Train: 2018-08-01T00:46:48.587895: step 13616, loss 0.596811.
Train: 2018-08-01T00:46:48.744108: step 13617, loss 0.527995.
Train: 2018-08-01T00:46:48.915943: step 13618, loss 0.579602.
Train: 2018-08-01T00:46:49.072155: step 13619, loss 0.700019.
Train: 2018-08-01T00:46:49.244021: step 13620, loss 0.459382.
Test: 2018-08-01T00:46:49.728282: step 13620, loss 0.548025.
Train: 2018-08-01T00:46:49.884499: step 13621, loss 0.545234.
Train: 2018-08-01T00:46:50.040709: step 13622, loss 0.528074.
Train: 2018-08-01T00:46:50.196892: step 13623, loss 0.631069.
Train: 2018-08-01T00:46:50.384349: step 13624, loss 0.545239.
Train: 2018-08-01T00:46:50.540563: step 13625, loss 0.510938.
Train: 2018-08-01T00:46:50.696775: step 13626, loss 0.510916.
Train: 2018-08-01T00:46:50.852988: step 13627, loss 0.596754.
Train: 2018-08-01T00:46:51.009241: step 13628, loss 0.579584.
Train: 2018-08-01T00:46:51.165446: step 13629, loss 0.510823.
Train: 2018-08-01T00:46:51.337251: step 13630, loss 0.424744.
Test: 2018-08-01T00:46:51.805921: step 13630, loss 0.547953.
Train: 2018-08-01T00:46:51.962135: step 13631, loss 0.614157.
Train: 2018-08-01T00:46:52.133965: step 13632, loss 0.510559.
Train: 2018-08-01T00:46:52.290183: step 13633, loss 0.510451.
Train: 2018-08-01T00:46:52.446393: step 13634, loss 0.440866.
Train: 2018-08-01T00:46:52.602579: step 13635, loss 0.492698.
Train: 2018-08-01T00:46:52.758792: step 13636, loss 0.59746.
Train: 2018-08-01T00:46:52.915006: step 13637, loss 0.650301.
Train: 2018-08-01T00:46:53.071219: step 13638, loss 0.49207.
Train: 2018-08-01T00:46:53.227433: step 13639, loss 0.633064.
Train: 2018-08-01T00:46:53.399298: step 13640, loss 0.580162.
Test: 2018-08-01T00:46:53.867939: step 13640, loss 0.547696.
Train: 2018-08-01T00:46:54.024152: step 13641, loss 0.50946.
Train: 2018-08-01T00:46:54.180335: step 13642, loss 0.580215.
Train: 2018-08-01T00:46:54.352170: step 13643, loss 0.580236.
Train: 2018-08-01T00:46:54.508416: step 13644, loss 0.597975.
Train: 2018-08-01T00:46:54.680249: step 13645, loss 0.580244.
Train: 2018-08-01T00:46:54.836461: step 13646, loss 0.580233.
Train: 2018-08-01T00:46:54.992645: step 13647, loss 0.5094.
Train: 2018-08-01T00:46:55.164479: step 13648, loss 0.633319.
Train: 2018-08-01T00:46:55.320692: step 13649, loss 0.650919.
Train: 2018-08-01T00:46:55.476930: step 13650, loss 0.527198.
Test: 2018-08-01T00:46:55.945576: step 13650, loss 0.547725.
Train: 2018-08-01T00:46:56.101790: step 13651, loss 0.492011.
Train: 2018-08-01T00:46:56.258007: step 13652, loss 0.615291.
Train: 2018-08-01T00:46:56.414217: step 13653, loss 0.580049.
Train: 2018-08-01T00:46:56.570431: step 13654, loss 0.527345.
Train: 2018-08-01T00:46:56.742267: step 13655, loss 0.562453.
Train: 2018-08-01T00:46:56.914100: step 13656, loss 0.47483.
Train: 2018-08-01T00:46:57.070313: step 13657, loss 0.492337.
Train: 2018-08-01T00:46:57.226497: step 13658, loss 0.562455.
Train: 2018-08-01T00:46:57.382743: step 13659, loss 0.492209.
Train: 2018-08-01T00:46:57.538948: step 13660, loss 0.632834.
Test: 2018-08-01T00:46:58.007596: step 13660, loss 0.547734.
Train: 2018-08-01T00:46:58.163778: step 13661, loss 0.492071.
Train: 2018-08-01T00:46:58.320021: step 13662, loss 0.544857.
Train: 2018-08-01T00:46:58.476233: step 13663, loss 0.615424.
Train: 2018-08-01T00:46:58.632450: step 13664, loss 0.56249.
Train: 2018-08-01T00:46:58.788662: step 13665, loss 0.544835.
Train: 2018-08-01T00:46:58.960489: step 13666, loss 0.45651.
Train: 2018-08-01T00:46:59.147922: step 13667, loss 0.562506.
Train: 2018-08-01T00:46:59.304136: step 13668, loss 0.580233.
Train: 2018-08-01T00:46:59.460379: step 13669, loss 0.651188.
Train: 2018-08-01T00:46:59.616563: step 13670, loss 0.668873.
Test: 2018-08-01T00:47:00.100856: step 13670, loss 0.54769.
Train: 2018-08-01T00:47:00.272659: step 13671, loss 0.650971.
Train: 2018-08-01T00:47:00.428903: step 13672, loss 0.50956.
Train: 2018-08-01T00:47:00.585085: step 13673, loss 0.580081.
Train: 2018-08-01T00:47:00.756920: step 13674, loss 0.527322.
Train: 2018-08-01T00:47:00.913133: step 13675, loss 0.685256.
Train: 2018-08-01T00:47:01.084998: step 13676, loss 0.562439.
Train: 2018-08-01T00:47:01.241181: step 13677, loss 0.475221.
Train: 2018-08-01T00:47:01.397394: step 13678, loss 0.47534.
Train: 2018-08-01T00:47:01.553638: step 13679, loss 0.701727.
Train: 2018-08-01T00:47:01.725444: step 13680, loss 0.579793.
Test: 2018-08-01T00:47:02.194113: step 13680, loss 0.547888.
Train: 2018-08-01T00:47:02.365945: step 13681, loss 0.631774.
Train: 2018-08-01T00:47:02.506543: step 13682, loss 0.475946.
Train: 2018-08-01T00:47:02.662724: step 13683, loss 0.631467.
Train: 2018-08-01T00:47:02.818967: step 13684, loss 0.631309.
Train: 2018-08-01T00:47:02.975181: step 13685, loss 0.54522.
Train: 2018-08-01T00:47:03.131365: step 13686, loss 0.493858.
Train: 2018-08-01T00:47:03.287576: step 13687, loss 0.511059.
Train: 2018-08-01T00:47:03.459443: step 13688, loss 0.476871.
Train: 2018-08-01T00:47:03.615658: step 13689, loss 0.511041.
Train: 2018-08-01T00:47:03.771840: step 13690, loss 0.528111.
Test: 2018-08-01T00:47:04.240509: step 13690, loss 0.548017.
Train: 2018-08-01T00:47:04.396724: step 13691, loss 0.596741.
Train: 2018-08-01T00:47:04.568559: step 13692, loss 0.579588.
Train: 2018-08-01T00:47:04.724754: step 13693, loss 0.579601.
Train: 2018-08-01T00:47:04.880978: step 13694, loss 0.562397.
Train: 2018-08-01T00:47:05.037201: step 13695, loss 0.579615.
Train: 2018-08-01T00:47:05.193405: step 13696, loss 0.579617.
Train: 2018-08-01T00:47:05.349625: step 13697, loss 0.59683.
Train: 2018-08-01T00:47:05.505807: step 13698, loss 0.545191.
Train: 2018-08-01T00:47:05.693264: step 13699, loss 0.545197.
Train: 2018-08-01T00:47:05.833886: step 13700, loss 0.579596.
Test: 2018-08-01T00:47:06.318148: step 13700, loss 0.547999.
Train: 2018-08-01T00:47:07.036729: step 13701, loss 0.562397.
Train: 2018-08-01T00:47:07.192944: step 13702, loss 0.52802.
Train: 2018-08-01T00:47:07.364748: step 13703, loss 0.631165.
Train: 2018-08-01T00:47:07.520985: step 13704, loss 0.510859.
Train: 2018-08-01T00:47:07.677205: step 13705, loss 0.424962.
Train: 2018-08-01T00:47:07.849047: step 13706, loss 0.459128.
Train: 2018-08-01T00:47:08.005256: step 13707, loss 0.545136.
Train: 2018-08-01T00:47:08.161467: step 13708, loss 0.614352.
Train: 2018-08-01T00:47:08.317679: step 13709, loss 0.545061.
Train: 2018-08-01T00:47:08.489485: step 13710, loss 0.579799.
Test: 2018-08-01T00:47:08.958125: step 13710, loss 0.547843.
Train: 2018-08-01T00:47:09.114367: step 13711, loss 0.597237.
Train: 2018-08-01T00:47:09.270581: step 13712, loss 0.47531.
Train: 2018-08-01T00:47:09.426765: step 13713, loss 0.59734.
Train: 2018-08-01T00:47:09.583008: step 13714, loss 0.57991.
Train: 2018-08-01T00:47:09.739191: step 13715, loss 0.562439.
Train: 2018-08-01T00:47:09.895436: step 13716, loss 0.544943.
Train: 2018-08-01T00:47:10.082860: step 13717, loss 0.45738.
Train: 2018-08-01T00:47:10.223483: step 13718, loss 0.457185.
Train: 2018-08-01T00:47:10.379700: step 13719, loss 0.404084.
Train: 2018-08-01T00:47:10.535910: step 13720, loss 0.615547.
Test: 2018-08-01T00:47:11.020195: step 13720, loss 0.547672.
Train: 2018-08-01T00:47:11.191977: step 13721, loss 0.544786.
Train: 2018-08-01T00:47:11.348190: step 13722, loss 0.526957.
Train: 2018-08-01T00:47:11.504436: step 13723, loss 0.526871.
Train: 2018-08-01T00:47:11.660646: step 13724, loss 0.490959.
Train: 2018-08-01T00:47:11.832453: step 13725, loss 0.490737.
Train: 2018-08-01T00:47:11.988664: step 13726, loss 0.616861.
Train: 2018-08-01T00:47:12.160513: step 13727, loss 0.689459.
Train: 2018-08-01T00:47:12.301091: step 13728, loss 0.544632.
Train: 2018-08-01T00:47:12.457330: step 13729, loss 0.508365.
Train: 2018-08-01T00:47:12.629164: step 13730, loss 0.599083.
Test: 2018-08-01T00:47:13.097811: step 13730, loss 0.547574.
Train: 2018-08-01T00:47:13.269640: step 13731, loss 0.617269.
Train: 2018-08-01T00:47:13.425858: step 13732, loss 0.490158.
Train: 2018-08-01T00:47:13.582066: step 13733, loss 0.617266.
Train: 2018-08-01T00:47:13.738285: step 13734, loss 0.453863.
Train: 2018-08-01T00:47:13.894468: step 13735, loss 0.653609.
Train: 2018-08-01T00:47:14.050712: step 13736, loss 0.599082.
Train: 2018-08-01T00:47:14.222546: step 13737, loss 0.526497.
Train: 2018-08-01T00:47:14.409998: step 13738, loss 0.580867.
Train: 2018-08-01T00:47:14.550597: step 13739, loss 0.635126.
Train: 2018-08-01T00:47:14.722430: step 13740, loss 0.526588.
Test: 2018-08-01T00:47:15.175448: step 13740, loss 0.54759.
Train: 2018-08-01T00:47:15.331631: step 13741, loss 0.598758.
Train: 2018-08-01T00:47:15.503467: step 13742, loss 0.634659.
Train: 2018-08-01T00:47:15.675331: step 13743, loss 0.4729.
Train: 2018-08-01T00:47:15.831539: step 13744, loss 0.58054.
Train: 2018-08-01T00:47:15.987758: step 13745, loss 0.562602.
Train: 2018-08-01T00:47:16.143941: step 13746, loss 0.634016.
Train: 2018-08-01T00:47:16.300185: step 13747, loss 0.54475.
Train: 2018-08-01T00:47:16.440748: step 13748, loss 0.526998.
Train: 2018-08-01T00:47:16.612581: step 13749, loss 0.527042.
Train: 2018-08-01T00:47:16.768820: step 13750, loss 0.456177.
Test: 2018-08-01T00:47:17.253056: step 13750, loss 0.547678.
Train: 2018-08-01T00:47:17.409300: step 13751, loss 0.544795.
Train: 2018-08-01T00:47:17.565514: step 13752, loss 0.668933.
Train: 2018-08-01T00:47:17.737318: step 13753, loss 0.562517.
Train: 2018-08-01T00:47:17.893561: step 13754, loss 0.456342.
Train: 2018-08-01T00:47:18.049775: step 13755, loss 0.527112.
Train: 2018-08-01T00:47:18.205988: step 13756, loss 0.544805.
Train: 2018-08-01T00:47:18.362201: step 13757, loss 0.527078.
Train: 2018-08-01T00:47:18.518416: step 13758, loss 0.61574.
Train: 2018-08-01T00:47:18.674629: step 13759, loss 0.757657.
Train: 2018-08-01T00:47:18.846459: step 13760, loss 0.597898.
Test: 2018-08-01T00:47:19.315104: step 13760, loss 0.547713.
Train: 2018-08-01T00:47:19.486908: step 13761, loss 0.562489.
Train: 2018-08-01T00:47:19.643153: step 13762, loss 0.632869.
Train: 2018-08-01T00:47:19.799365: step 13763, loss 0.650156.
Train: 2018-08-01T00:47:19.971200: step 13764, loss 0.457636.
Train: 2018-08-01T00:47:20.127383: step 13765, loss 0.492733.
Train: 2018-08-01T00:47:20.283596: step 13766, loss 0.492825.
Train: 2018-08-01T00:47:20.439811: step 13767, loss 0.527634.
Train: 2018-08-01T00:47:20.596024: step 13768, loss 0.579813.
Train: 2018-08-01T00:47:20.752238: step 13769, loss 0.597199.
Train: 2018-08-01T00:47:20.908482: step 13770, loss 0.597173.
Test: 2018-08-01T00:47:21.377091: step 13770, loss 0.547877.
Train: 2018-08-01T00:47:21.548925: step 13771, loss 0.510336.
Train: 2018-08-01T00:47:21.720785: step 13772, loss 0.597119.
Train: 2018-08-01T00:47:21.876999: step 13773, loss 0.545071.
Train: 2018-08-01T00:47:22.033189: step 13774, loss 0.545079.
Train: 2018-08-01T00:47:22.205022: step 13775, loss 0.597059.
Train: 2018-08-01T00:47:22.361266: step 13776, loss 0.597032.
Train: 2018-08-01T00:47:22.517457: step 13777, loss 0.493234.
Train: 2018-08-01T00:47:22.673692: step 13778, loss 0.614274.
Train: 2018-08-01T00:47:22.829906: step 13779, loss 0.683331.
Train: 2018-08-01T00:47:22.986120: step 13780, loss 0.631336.
Test: 2018-08-01T00:47:23.454728: step 13780, loss 0.54801.
Train: 2018-08-01T00:47:23.610944: step 13781, loss 0.545217.
Train: 2018-08-01T00:47:23.767186: step 13782, loss 0.630944.
Train: 2018-08-01T00:47:23.923371: step 13783, loss 0.494075.
Train: 2018-08-01T00:47:24.095204: step 13784, loss 0.63059.
Train: 2018-08-01T00:47:24.251456: step 13785, loss 0.545405.
Train: 2018-08-01T00:47:24.438899: step 13786, loss 0.426698.
Train: 2018-08-01T00:47:24.579468: step 13787, loss 0.528485.
Train: 2018-08-01T00:47:24.735710: step 13788, loss 0.460584.
Train: 2018-08-01T00:47:24.907540: step 13789, loss 0.596411.
Train: 2018-08-01T00:47:25.063728: step 13790, loss 0.54538.
Test: 2018-08-01T00:47:25.532367: step 13790, loss 0.548127.
Train: 2018-08-01T00:47:25.688611: step 13791, loss 0.528309.
Train: 2018-08-01T00:47:25.844825: step 13792, loss 0.545324.
Train: 2018-08-01T00:47:26.016660: step 13793, loss 0.59661.
Train: 2018-08-01T00:47:26.172873: step 13794, loss 0.630899.
Train: 2018-08-01T00:47:26.329056: step 13795, loss 0.613779.
Train: 2018-08-01T00:47:26.500892: step 13796, loss 0.562397.
Train: 2018-08-01T00:47:26.641483: step 13797, loss 0.511074.
Train: 2018-08-01T00:47:26.797697: step 13798, loss 0.528174.
Train: 2018-08-01T00:47:26.969561: step 13799, loss 0.579521.
Train: 2018-08-01T00:47:27.125744: step 13800, loss 0.596657.
Test: 2018-08-01T00:47:27.594384: step 13800, loss 0.548054.
Train: 2018-08-01T00:47:28.297377: step 13801, loss 0.579525.
Train: 2018-08-01T00:47:28.453589: step 13802, loss 0.493907.
Train: 2018-08-01T00:47:28.609797: step 13803, loss 0.52813.
Train: 2018-08-01T00:47:28.797259: step 13804, loss 0.545245.
Train: 2018-08-01T00:47:28.937821: step 13805, loss 0.579568.
Train: 2018-08-01T00:47:29.109688: step 13806, loss 0.459283.
Train: 2018-08-01T00:47:29.265899: step 13807, loss 0.510732.
Train: 2018-08-01T00:47:29.422113: step 13808, loss 0.596935.
Train: 2018-08-01T00:47:29.578326: step 13809, loss 0.493209.
Train: 2018-08-01T00:47:29.734548: step 13810, loss 0.545067.
Test: 2018-08-01T00:47:30.218801: step 13810, loss 0.547858.
Train: 2018-08-01T00:47:30.390606: step 13811, loss 0.579803.
Train: 2018-08-01T00:47:30.531198: step 13812, loss 0.632105.
Train: 2018-08-01T00:47:30.687441: step 13813, loss 0.370647.
Train: 2018-08-01T00:47:30.859247: step 13814, loss 0.544949.
Train: 2018-08-01T00:47:31.015484: step 13815, loss 0.632625.
Train: 2018-08-01T00:47:31.171702: step 13816, loss 0.65033.
Train: 2018-08-01T00:47:31.343538: step 13817, loss 0.544885.
Train: 2018-08-01T00:47:31.499754: step 13818, loss 0.63282.
Train: 2018-08-01T00:47:31.655963: step 13819, loss 0.544886.
Train: 2018-08-01T00:47:31.812173: step 13820, loss 0.650324.
Test: 2018-08-01T00:47:32.280788: step 13820, loss 0.547762.
Train: 2018-08-01T00:47:32.452652: step 13821, loss 0.650183.
Train: 2018-08-01T00:47:32.608866: step 13822, loss 0.544941.
Train: 2018-08-01T00:47:32.765080: step 13823, loss 0.527506.
Train: 2018-08-01T00:47:32.921262: step 13824, loss 0.649609.
Train: 2018-08-01T00:47:33.093097: step 13825, loss 0.562417.
Train: 2018-08-01T00:47:33.249344: step 13826, loss 0.631813.
Train: 2018-08-01T00:47:33.405555: step 13827, loss 0.527809.
Train: 2018-08-01T00:47:33.561737: step 13828, loss 0.61417.
Train: 2018-08-01T00:47:33.717951: step 13829, loss 0.527982.
Train: 2018-08-01T00:47:33.874165: step 13830, loss 0.545225.
Test: 2018-08-01T00:47:34.342805: step 13830, loss 0.548041.
Train: 2018-08-01T00:47:34.499017: step 13831, loss 0.596682.
Train: 2018-08-01T00:47:34.655231: step 13832, loss 0.596616.
Train: 2018-08-01T00:47:34.811445: step 13833, loss 0.613613.
Train: 2018-08-01T00:47:34.967688: step 13834, loss 0.613479.
Train: 2018-08-01T00:47:35.123905: step 13835, loss 0.664243.
Train: 2018-08-01T00:47:35.295706: step 13836, loss 0.562421.
Train: 2018-08-01T00:47:35.436329: step 13837, loss 0.511921.
Train: 2018-08-01T00:47:35.592513: step 13838, loss 0.713596.
Train: 2018-08-01T00:47:35.748759: step 13839, loss 0.545749.
Train: 2018-08-01T00:47:35.904970: step 13840, loss 0.512515.
Test: 2018-08-01T00:47:36.373578: step 13840, loss 0.548594.
Train: 2018-08-01T00:47:36.529822: step 13841, loss 0.628978.
Train: 2018-08-01T00:47:36.686007: step 13842, loss 0.5294.
Train: 2018-08-01T00:47:36.842220: step 13843, loss 0.612134.
Train: 2018-08-01T00:47:36.998433: step 13844, loss 0.562571.
Train: 2018-08-01T00:47:37.154647: step 13845, loss 0.513245.
Train: 2018-08-01T00:47:37.310861: step 13846, loss 0.510026.
Train: 2018-08-01T00:47:37.482694: step 13847, loss 0.628312.
Train: 2018-08-01T00:47:37.623311: step 13848, loss 0.546199.
Train: 2018-08-01T00:47:37.795151: step 13849, loss 0.595424.
Train: 2018-08-01T00:47:37.951360: step 13850, loss 0.595406.
Test: 2018-08-01T00:47:38.435626: step 13850, loss 0.548921.
Train: 2018-08-01T00:47:38.607462: step 13851, loss 0.579008.
Train: 2018-08-01T00:47:38.763645: step 13852, loss 0.546286.
Train: 2018-08-01T00:47:38.919889: step 13853, loss 0.497252.
Train: 2018-08-01T00:47:39.076095: step 13854, loss 0.513563.
Train: 2018-08-01T00:47:39.232285: step 13855, loss 0.562627.
Train: 2018-08-01T00:47:39.388528: step 13856, loss 0.611837.
Train: 2018-08-01T00:47:39.544742: step 13857, loss 0.562606.
Train: 2018-08-01T00:47:39.732198: step 13858, loss 0.480434.
Train: 2018-08-01T00:47:39.888411: step 13859, loss 0.529646.
Train: 2018-08-01T00:47:40.060215: step 13860, loss 0.546051.
Test: 2018-08-01T00:47:40.513266: step 13860, loss 0.548679.
Train: 2018-08-01T00:47:40.685096: step 13861, loss 0.66184.
Train: 2018-08-01T00:47:40.841307: step 13862, loss 0.545964.
Train: 2018-08-01T00:47:40.997521: step 13863, loss 0.628869.
Train: 2018-08-01T00:47:41.153742: step 13864, loss 0.545928.
Train: 2018-08-01T00:47:41.309954: step 13865, loss 0.529314.
Train: 2018-08-01T00:47:41.466167: step 13866, loss 0.579127.
Train: 2018-08-01T00:47:41.622383: step 13867, loss 0.529235.
Train: 2018-08-01T00:47:41.778601: step 13868, loss 0.629116.
Train: 2018-08-01T00:47:41.950423: step 13869, loss 0.645797.
Train: 2018-08-01T00:47:42.106644: step 13870, loss 0.662384.
Test: 2018-08-01T00:47:42.590904: step 13870, loss 0.548598.
Train: 2018-08-01T00:47:42.762738: step 13871, loss 0.512669.
Train: 2018-08-01T00:47:42.934573: step 13872, loss 0.496132.
Train: 2018-08-01T00:47:43.090757: step 13873, loss 0.562516.
Train: 2018-08-01T00:47:43.246970: step 13874, loss 0.512708.
Train: 2018-08-01T00:47:43.403184: step 13875, loss 0.595746.
Train: 2018-08-01T00:47:43.559421: step 13876, loss 0.562504.
Train: 2018-08-01T00:47:43.731232: step 13877, loss 0.47931.
Train: 2018-08-01T00:47:43.887444: step 13878, loss 0.662498.
Train: 2018-08-01T00:47:44.043688: step 13879, loss 0.545813.
Train: 2018-08-01T00:47:44.199902: step 13880, loss 0.595848.
Test: 2018-08-01T00:47:44.668512: step 13880, loss 0.54851.
Train: 2018-08-01T00:47:44.824755: step 13881, loss 0.612538.
Train: 2018-08-01T00:47:44.996593: step 13882, loss 0.612515.
Train: 2018-08-01T00:47:45.168395: step 13883, loss 0.595809.
Train: 2018-08-01T00:47:45.308986: step 13884, loss 0.579137.
Train: 2018-08-01T00:47:45.465200: step 13885, loss 0.496057.
Train: 2018-08-01T00:47:45.621452: step 13886, loss 0.529291.
Train: 2018-08-01T00:47:45.777628: step 13887, loss 0.645595.
Train: 2018-08-01T00:47:45.949492: step 13888, loss 0.61233.
Train: 2018-08-01T00:47:46.105676: step 13889, loss 0.512769.
Train: 2018-08-01T00:47:46.293161: step 13890, loss 0.496208.
Test: 2018-08-01T00:47:46.761801: step 13890, loss 0.548625.
Train: 2018-08-01T00:47:46.918016: step 13891, loss 0.545927.
Train: 2018-08-01T00:47:47.074228: step 13892, loss 0.579121.
Train: 2018-08-01T00:47:47.246067: step 13893, loss 0.612376.
Train: 2018-08-01T00:47:47.402277: step 13894, loss 0.446128.
Train: 2018-08-01T00:47:47.574105: step 13895, loss 0.512523.
Train: 2018-08-01T00:47:47.730327: step 13896, loss 0.562477.
Train: 2018-08-01T00:47:47.886508: step 13897, loss 0.445304.
Train: 2018-08-01T00:47:48.042751: step 13898, loss 0.612849.
Train: 2018-08-01T00:47:48.198964: step 13899, loss 0.495039.
Train: 2018-08-01T00:47:48.370804: step 13900, loss 0.663864.
Test: 2018-08-01T00:47:48.855032: step 13900, loss 0.548231.
Train: 2018-08-01T00:47:49.585128: step 13901, loss 0.545477.
Train: 2018-08-01T00:47:49.741378: step 13902, loss 0.579378.
Train: 2018-08-01T00:47:49.897593: step 13903, loss 0.545412.
Train: 2018-08-01T00:47:50.053767: step 13904, loss 0.545382.
Train: 2018-08-01T00:47:50.209981: step 13905, loss 0.596501.
Train: 2018-08-01T00:47:50.366195: step 13906, loss 0.562399.
Train: 2018-08-01T00:47:50.522407: step 13907, loss 0.476972.
Train: 2018-08-01T00:47:50.709888: step 13908, loss 0.630878.
Train: 2018-08-01T00:47:50.866110: step 13909, loss 0.648077.
Train: 2018-08-01T00:47:51.022291: step 13910, loss 0.579527.
Test: 2018-08-01T00:47:51.506582: step 13910, loss 0.548059.
Train: 2018-08-01T00:47:51.678387: step 13911, loss 0.528153.
Train: 2018-08-01T00:47:51.834636: step 13912, loss 0.49391.
Train: 2018-08-01T00:47:51.990813: step 13913, loss 0.579534.
Train: 2018-08-01T00:47:52.147027: step 13914, loss 0.630989.
Train: 2018-08-01T00:47:52.303240: step 13915, loss 0.493829.
Train: 2018-08-01T00:47:52.459454: step 13916, loss 0.631004.
Train: 2018-08-01T00:47:52.615668: step 13917, loss 0.630977.
Train: 2018-08-01T00:47:52.771881: step 13918, loss 0.493903.
Train: 2018-08-01T00:47:52.928124: step 13919, loss 0.562396.
Train: 2018-08-01T00:47:53.084338: step 13920, loss 0.511048.
Test: 2018-08-01T00:47:53.552977: step 13920, loss 0.548056.
Train: 2018-08-01T00:47:53.709162: step 13921, loss 0.579522.
Train: 2018-08-01T00:47:53.880996: step 13922, loss 0.630915.
Train: 2018-08-01T00:47:54.037240: step 13923, loss 0.545279.
Train: 2018-08-01T00:47:54.193458: step 13924, loss 0.545286.
Train: 2018-08-01T00:47:54.349661: step 13925, loss 0.545288.
Train: 2018-08-01T00:47:54.521471: step 13926, loss 0.528173.
Train: 2018-08-01T00:47:54.677714: step 13927, loss 0.51103.
Train: 2018-08-01T00:47:54.833928: step 13928, loss 0.648113.
Train: 2018-08-01T00:47:54.990111: step 13929, loss 0.64811.
Train: 2018-08-01T00:47:55.130734: step 13930, loss 0.579518.
Test: 2018-08-01T00:47:55.599374: step 13930, loss 0.548078.
Train: 2018-08-01T00:47:55.755591: step 13931, loss 0.562397.
Train: 2018-08-01T00:47:55.911770: step 13932, loss 0.562398.
Train: 2018-08-01T00:47:56.083605: step 13933, loss 0.613585.
Train: 2018-08-01T00:47:56.239818: step 13934, loss 0.630539.
Train: 2018-08-01T00:47:56.396066: step 13935, loss 0.562406.
Train: 2018-08-01T00:47:56.552246: step 13936, loss 0.545454.
Train: 2018-08-01T00:47:56.692838: step 13937, loss 0.545486.
Train: 2018-08-01T00:47:56.864711: step 13938, loss 0.528601.
Train: 2018-08-01T00:47:57.020910: step 13939, loss 0.596221.
Train: 2018-08-01T00:47:57.192745: step 13940, loss 0.596193.
Test: 2018-08-01T00:47:57.676981: step 13940, loss 0.548309.
Train: 2018-08-01T00:47:57.833226: step 13941, loss 0.613017.
Train: 2018-08-01T00:47:57.989433: step 13942, loss 0.562436.
Train: 2018-08-01T00:47:58.145621: step 13943, loss 0.545638.
Train: 2018-08-01T00:47:58.301835: step 13944, loss 0.579236.
Train: 2018-08-01T00:47:58.458049: step 13945, loss 0.595989.
Train: 2018-08-01T00:47:58.614262: step 13946, loss 0.629433.
Train: 2018-08-01T00:47:58.770510: step 13947, loss 0.545768.
Train: 2018-08-01T00:47:58.926720: step 13948, loss 0.645875.
Train: 2018-08-01T00:47:59.082933: step 13949, loss 0.678943.
Train: 2018-08-01T00:47:59.239146: step 13950, loss 0.545961.
Test: 2018-08-01T00:47:59.707756: step 13950, loss 0.548725.
Train: 2018-08-01T00:47:59.863971: step 13951, loss 0.529524.
Train: 2018-08-01T00:48:00.020219: step 13952, loss 0.562574.
Train: 2018-08-01T00:48:00.176427: step 13953, loss 0.513255.
Train: 2018-08-01T00:48:00.332610: step 13954, loss 0.611893.
Train: 2018-08-01T00:48:00.504446: step 13955, loss 0.480573.
Train: 2018-08-01T00:48:00.660659: step 13956, loss 0.496972.
Train: 2018-08-01T00:48:00.816901: step 13957, loss 0.61189.
Train: 2018-08-01T00:48:00.973115: step 13958, loss 0.496843.
Train: 2018-08-01T00:48:01.129329: step 13959, loss 0.611974.
Train: 2018-08-01T00:48:01.301157: step 13960, loss 0.595529.
Test: 2018-08-01T00:48:01.754182: step 13960, loss 0.548768.
Train: 2018-08-01T00:48:01.910397: step 13961, loss 0.595538.
Train: 2018-08-01T00:48:02.066609: step 13962, loss 0.562572.
Train: 2018-08-01T00:48:02.222823: step 13963, loss 0.579055.
Train: 2018-08-01T00:48:02.379006: step 13964, loss 0.546087.
Train: 2018-08-01T00:48:02.535244: step 13965, loss 0.529588.
Train: 2018-08-01T00:48:02.707079: step 13966, loss 0.447023.
Train: 2018-08-01T00:48:02.863305: step 13967, loss 0.496342.
Train: 2018-08-01T00:48:03.019481: step 13968, loss 0.545906.
Train: 2018-08-01T00:48:03.160103: step 13969, loss 0.612482.
Train: 2018-08-01T00:48:03.316287: step 13970, loss 0.512358.
Test: 2018-08-01T00:48:03.784927: step 13970, loss 0.548426.
Train: 2018-08-01T00:48:03.941170: step 13971, loss 0.562458.
Train: 2018-08-01T00:48:04.097378: step 13972, loss 0.579247.
Train: 2018-08-01T00:48:04.253567: step 13973, loss 0.528749.
Train: 2018-08-01T00:48:04.409811: step 13974, loss 0.545537.
Train: 2018-08-01T00:48:04.566024: step 13975, loss 0.494689.
Train: 2018-08-01T00:48:04.722237: step 13976, loss 0.494452.
Train: 2018-08-01T00:48:04.894070: step 13977, loss 0.511229.
Train: 2018-08-01T00:48:05.050289: step 13978, loss 0.613787.
Train: 2018-08-01T00:48:05.206499: step 13979, loss 0.528027.
Train: 2018-08-01T00:48:05.362712: step 13980, loss 0.545157.
Test: 2018-08-01T00:48:05.831352: step 13980, loss 0.547919.
Train: 2018-08-01T00:48:06.003190: step 13981, loss 0.562403.
Train: 2018-08-01T00:48:06.159371: step 13982, loss 0.579755.
Train: 2018-08-01T00:48:06.315614: step 13983, loss 0.614572.
Train: 2018-08-01T00:48:06.471822: step 13984, loss 0.457972.
Train: 2018-08-01T00:48:06.628044: step 13985, loss 0.632237.
Train: 2018-08-01T00:48:06.784255: step 13986, loss 0.597383.
Train: 2018-08-01T00:48:06.940468: step 13987, loss 0.649865.
Train: 2018-08-01T00:48:07.112273: step 13988, loss 0.510011.
Train: 2018-08-01T00:48:07.268485: step 13989, loss 0.527484.
Train: 2018-08-01T00:48:07.424729: step 13990, loss 0.544953.
Test: 2018-08-01T00:48:07.893373: step 13990, loss 0.54779.
Train: 2018-08-01T00:48:08.049553: step 13991, loss 0.579933.
Train: 2018-08-01T00:48:08.221388: step 13992, loss 0.614935.
Train: 2018-08-01T00:48:08.377634: step 13993, loss 0.509972.
Train: 2018-08-01T00:48:08.533845: step 13994, loss 0.544947.
Train: 2018-08-01T00:48:08.690027: step 13995, loss 0.474956.
Train: 2018-08-01T00:48:08.846271: step 13996, loss 0.492363.
Train: 2018-08-01T00:48:09.002485: step 13997, loss 0.457113.
Train: 2018-08-01T00:48:09.158701: step 13998, loss 0.562475.
Train: 2018-08-01T00:48:09.330503: step 13999, loss 0.580156.
Train: 2018-08-01T00:48:09.486717: step 14000, loss 0.59791.
Test: 2018-08-01T00:48:09.955388: step 14000, loss 0.547676.
Train: 2018-08-01T00:48:10.642695: step 14001, loss 0.544794.
Train: 2018-08-01T00:48:10.798934: step 14002, loss 0.56253.
Train: 2018-08-01T00:48:10.955150: step 14003, loss 0.651393.
Train: 2018-08-01T00:48:11.111360: step 14004, loss 0.686907.
Train: 2018-08-01T00:48:11.267583: step 14005, loss 0.544789.
Train: 2018-08-01T00:48:11.423792: step 14006, loss 0.5271.
Train: 2018-08-01T00:48:11.580007: step 14007, loss 0.633251.
Train: 2018-08-01T00:48:11.736230: step 14008, loss 0.633099.
Train: 2018-08-01T00:48:11.892428: step 14009, loss 0.562472.
Train: 2018-08-01T00:48:12.064268: step 14010, loss 0.544899.
Test: 2018-08-01T00:48:12.548530: step 14010, loss 0.547775.
Train: 2018-08-01T00:48:12.704724: step 14011, loss 0.509886.
Train: 2018-08-01T00:48:12.860956: step 14012, loss 0.614931.
Train: 2018-08-01T00:48:13.017139: step 14013, loss 0.510043.
Train: 2018-08-01T00:48:13.173353: step 14014, loss 0.6322.
Train: 2018-08-01T00:48:13.329591: step 14015, loss 0.632055.
Train: 2018-08-01T00:48:13.485781: step 14016, loss 0.562412.
Train: 2018-08-01T00:48:13.673266: step 14017, loss 0.406555.
Train: 2018-08-01T00:48:13.829480: step 14018, loss 0.648983.
Train: 2018-08-01T00:48:13.985692: step 14019, loss 0.562397.
Train: 2018-08-01T00:48:14.141876: step 14020, loss 0.648684.
Test: 2018-08-01T00:48:14.610547: step 14020, loss 0.548018.
Train: 2018-08-01T00:48:14.782381: step 14021, loss 0.493881.
Train: 2018-08-01T00:48:14.938566: step 14022, loss 0.527933.
Train: 2018-08-01T00:48:15.094807: step 14023, loss 0.442038.
Train: 2018-08-01T00:48:15.251024: step 14024, loss 0.510724.
Train: 2018-08-01T00:48:15.407237: step 14025, loss 0.579649.
Train: 2018-08-01T00:48:15.563449: step 14026, loss 0.562419.
Train: 2018-08-01T00:48:15.719631: step 14027, loss 0.545117.
Train: 2018-08-01T00:48:15.938330: step 14028, loss 0.562405.
Train: 2018-08-01T00:48:16.094545: step 14029, loss 0.631711.
Train: 2018-08-01T00:48:16.250757: step 14030, loss 0.51043.
Test: 2018-08-01T00:48:16.735018: step 14030, loss 0.547891.
Train: 2018-08-01T00:48:16.891233: step 14031, loss 0.666434.
Train: 2018-08-01T00:48:17.047446: step 14032, loss 0.649023.
Train: 2018-08-01T00:48:17.203691: step 14033, loss 0.562404.
Train: 2018-08-01T00:48:17.359904: step 14034, loss 0.57966.
Train: 2018-08-01T00:48:17.531738: step 14035, loss 0.596853.
Train: 2018-08-01T00:48:17.672299: step 14036, loss 0.442066.
Train: 2018-08-01T00:48:17.828543: step 14037, loss 0.528027.
Train: 2018-08-01T00:48:18.015995: step 14038, loss 0.510832.
Train: 2018-08-01T00:48:18.172207: step 14039, loss 0.510788.
Train: 2018-08-01T00:48:18.328426: step 14040, loss 0.631313.
Test: 2018-08-01T00:48:18.812656: step 14040, loss 0.547966.
Train: 2018-08-01T00:48:18.968901: step 14041, loss 0.579634.
Train: 2018-08-01T00:48:19.140740: step 14042, loss 0.545162.
Train: 2018-08-01T00:48:19.281328: step 14043, loss 0.527915.
Train: 2018-08-01T00:48:19.437542: step 14044, loss 0.596909.
Train: 2018-08-01T00:48:19.593755: step 14045, loss 0.614173.
Train: 2018-08-01T00:48:19.749968: step 14046, loss 0.648638.
Train: 2018-08-01T00:48:19.906182: step 14047, loss 0.562398.
Train: 2018-08-01T00:48:20.077986: step 14048, loss 0.510821.
Train: 2018-08-01T00:48:20.249821: step 14049, loss 0.596756.
Train: 2018-08-01T00:48:20.390413: step 14050, loss 0.476591.
Test: 2018-08-01T00:48:20.843462: step 14050, loss 0.548023.
Train: 2018-08-01T00:48:20.999680: step 14051, loss 0.442246.
Train: 2018-08-01T00:48:21.155889: step 14052, loss 0.596787.
Train: 2018-08-01T00:48:21.327693: step 14053, loss 0.579613.
Train: 2018-08-01T00:48:21.483908: step 14054, loss 0.596856.
Train: 2018-08-01T00:48:21.640120: step 14055, loss 0.579631.
Train: 2018-08-01T00:48:21.796367: step 14056, loss 0.527935.
Train: 2018-08-01T00:48:21.952547: step 14057, loss 0.476203.
Train: 2018-08-01T00:48:22.108785: step 14058, loss 0.579666.
Train: 2018-08-01T00:48:22.264974: step 14059, loss 0.562402.
Train: 2018-08-01T00:48:22.436808: step 14060, loss 0.597008.
Test: 2018-08-01T00:48:22.905479: step 14060, loss 0.547911.
Train: 2018-08-01T00:48:23.077314: step 14061, loss 0.614331.
Train: 2018-08-01T00:48:23.233522: step 14062, loss 0.493195.
Train: 2018-08-01T00:48:23.389745: step 14063, loss 0.510469.
Train: 2018-08-01T00:48:23.577168: step 14064, loss 0.579741.
Train: 2018-08-01T00:48:23.717783: step 14065, loss 0.545063.
Train: 2018-08-01T00:48:23.874006: step 14066, loss 0.527687.
Train: 2018-08-01T00:48:24.030216: step 14067, loss 0.492878.
Train: 2018-08-01T00:48:24.202021: step 14068, loss 0.771457.
Train: 2018-08-01T00:48:24.373886: step 14069, loss 0.632027.
Train: 2018-08-01T00:48:24.545690: step 14070, loss 0.545044.
Test: 2018-08-01T00:48:25.014330: step 14070, loss 0.547887.
Train: 2018-08-01T00:48:25.170545: step 14071, loss 0.527723.
Train: 2018-08-01T00:48:25.326757: step 14072, loss 0.562407.
Train: 2018-08-01T00:48:25.482970: step 14073, loss 0.700904.
Train: 2018-08-01T00:48:25.639220: step 14074, loss 0.562401.
Train: 2018-08-01T00:48:25.811049: step 14075, loss 0.596847.
Train: 2018-08-01T00:48:25.967232: step 14076, loss 0.545218.
Train: 2018-08-01T00:48:26.123446: step 14077, loss 0.528114.
Train: 2018-08-01T00:48:26.279659: step 14078, loss 0.545281.
Train: 2018-08-01T00:48:26.435904: step 14079, loss 0.528204.
Train: 2018-08-01T00:48:26.592085: step 14080, loss 0.476957.
Test: 2018-08-01T00:48:27.060756: step 14080, loss 0.548078.
Train: 2018-08-01T00:48:27.216970: step 14081, loss 0.562397.
Train: 2018-08-01T00:48:27.373183: step 14082, loss 0.562397.
Train: 2018-08-01T00:48:27.529366: step 14083, loss 0.613764.
Train: 2018-08-01T00:48:27.685610: step 14084, loss 0.630877.
Train: 2018-08-01T00:48:27.841795: step 14085, loss 0.562397.
Train: 2018-08-01T00:48:28.013628: step 14086, loss 0.596569.
Train: 2018-08-01T00:48:28.169871: step 14087, loss 0.477086.
Train: 2018-08-01T00:48:28.326085: step 14088, loss 0.596525.
Train: 2018-08-01T00:48:28.482298: step 14089, loss 0.5624.
Train: 2018-08-01T00:48:28.638515: step 14090, loss 0.545352.
Test: 2018-08-01T00:48:29.122773: step 14090, loss 0.548126.
Train: 2018-08-01T00:48:29.278957: step 14091, loss 0.664684.
Train: 2018-08-01T00:48:29.435171: step 14092, loss 0.545381.
Train: 2018-08-01T00:48:29.591384: step 14093, loss 0.579409.
Train: 2018-08-01T00:48:29.747626: step 14094, loss 0.52844.
Train: 2018-08-01T00:48:29.903811: step 14095, loss 0.596358.
Train: 2018-08-01T00:48:30.075646: step 14096, loss 0.545453.
Train: 2018-08-01T00:48:30.231889: step 14097, loss 0.562413.
Train: 2018-08-01T00:48:30.388097: step 14098, loss 0.613236.
Train: 2018-08-01T00:48:30.544321: step 14099, loss 0.562417.
Train: 2018-08-01T00:48:30.700524: step 14100, loss 0.613137.
Test: 2018-08-01T00:48:31.169169: step 14100, loss 0.548291.
Train: 2018-08-01T00:48:31.872099: step 14101, loss 0.478027.
Train: 2018-08-01T00:48:32.028343: step 14102, loss 0.680569.
Train: 2018-08-01T00:48:32.184551: step 14103, loss 0.528736.
Train: 2018-08-01T00:48:32.356360: step 14104, loss 0.61293.
Train: 2018-08-01T00:48:32.512609: step 14105, loss 0.612856.
Train: 2018-08-01T00:48:32.668788: step 14106, loss 0.478609.
Train: 2018-08-01T00:48:32.825031: step 14107, loss 0.495422.
Train: 2018-08-01T00:48:32.996836: step 14108, loss 0.562455.
Train: 2018-08-01T00:48:33.153049: step 14109, loss 0.545677.
Train: 2018-08-01T00:48:33.356153: step 14110, loss 0.596026.
Test: 2018-08-01T00:48:33.824767: step 14110, loss 0.548385.
Train: 2018-08-01T00:48:33.981004: step 14111, loss 0.52886.
Train: 2018-08-01T00:48:34.137228: step 14112, loss 0.612864.
Train: 2018-08-01T00:48:34.293407: step 14113, loss 0.528827.
Train: 2018-08-01T00:48:34.465243: step 14114, loss 0.461531.
Train: 2018-08-01T00:48:34.621456: step 14115, loss 0.444463.
Train: 2018-08-01T00:48:34.777668: step 14116, loss 0.562419.
Train: 2018-08-01T00:48:34.949534: step 14117, loss 0.477572.
Train: 2018-08-01T00:48:35.105741: step 14118, loss 0.528326.
Train: 2018-08-01T00:48:35.261956: step 14119, loss 0.545288.
Train: 2018-08-01T00:48:35.418174: step 14120, loss 0.61393.
Test: 2018-08-01T00:48:35.886818: step 14120, loss 0.547972.
Train: 2018-08-01T00:48:36.089891: step 14121, loss 0.545171.
Train: 2018-08-01T00:48:36.246108: step 14122, loss 0.579677.
Train: 2018-08-01T00:48:36.402313: step 14123, loss 0.579721.
Train: 2018-08-01T00:48:36.558535: step 14124, loss 0.458334.
Train: 2018-08-01T00:48:36.730337: step 14125, loss 0.527624.
Train: 2018-08-01T00:48:36.886550: step 14126, loss 0.57988.
Train: 2018-08-01T00:48:37.042794: step 14127, loss 0.597428.
Train: 2018-08-01T00:48:37.199002: step 14128, loss 0.474829.
Train: 2018-08-01T00:48:37.370836: step 14129, loss 0.474613.
Train: 2018-08-01T00:48:37.527025: step 14130, loss 0.421443.
Test: 2018-08-01T00:48:37.995695: step 14130, loss 0.547681.
Train: 2018-08-01T00:48:38.151879: step 14131, loss 0.615659.
Train: 2018-08-01T00:48:38.308092: step 14132, loss 0.615875.
Train: 2018-08-01T00:48:38.464306: step 14133, loss 0.580383.
Train: 2018-08-01T00:48:38.620519: step 14134, loss 0.544729.
Train: 2018-08-01T00:48:38.808005: step 14135, loss 0.50895.
Train: 2018-08-01T00:48:38.964219: step 14136, loss 0.580538.
Train: 2018-08-01T00:48:39.120426: step 14137, loss 0.45495.
Train: 2018-08-01T00:48:39.276616: step 14138, loss 0.68862.
Train: 2018-08-01T00:48:39.432859: step 14139, loss 0.616685.
Train: 2018-08-01T00:48:39.589042: step 14140, loss 0.598667.
Test: 2018-08-01T00:48:40.057713: step 14140, loss 0.547597.
Train: 2018-08-01T00:48:40.213896: step 14141, loss 0.508702.
Train: 2018-08-01T00:48:40.370134: step 14142, loss 0.616599.
Train: 2018-08-01T00:48:40.541969: step 14143, loss 0.544681.
Train: 2018-08-01T00:48:40.698190: step 14144, loss 0.508789.
Train: 2018-08-01T00:48:40.854401: step 14145, loss 0.526743.
Train: 2018-08-01T00:48:41.026206: step 14146, loss 0.490845.
Train: 2018-08-01T00:48:41.182419: step 14147, loss 0.600965.
Train: 2018-08-01T00:48:41.338632: step 14148, loss 0.562646.
Train: 2018-08-01T00:48:41.494879: step 14149, loss 0.580613.
Train: 2018-08-01T00:48:41.651060: step 14150, loss 0.50876.
Test: 2018-08-01T00:48:42.119734: step 14150, loss 0.547601.
Train: 2018-08-01T00:48:42.291564: step 14151, loss 0.54468.
Train: 2018-08-01T00:48:42.447747: step 14152, loss 0.616559.
Train: 2018-08-01T00:48:42.603991: step 14153, loss 0.490801.
Train: 2018-08-01T00:48:42.760208: step 14154, loss 0.670436.
Train: 2018-08-01T00:48:42.916418: step 14155, loss 0.61646.
Train: 2018-08-01T00:48:43.088252: step 14156, loss 0.616336.
Train: 2018-08-01T00:48:43.244436: step 14157, loss 0.598311.
Train: 2018-08-01T00:48:43.400680: step 14158, loss 0.509125.
Train: 2018-08-01T00:48:43.556863: step 14159, loss 0.615868.
Train: 2018-08-01T00:48:43.713101: step 14160, loss 0.544793.
Test: 2018-08-01T00:48:44.181747: step 14160, loss 0.547692.
Train: 2018-08-01T00:48:44.337961: step 14161, loss 0.633262.
Train: 2018-08-01T00:48:44.494143: step 14162, loss 0.597756.
Train: 2018-08-01T00:48:44.650384: step 14163, loss 0.650357.
Train: 2018-08-01T00:48:44.806601: step 14164, loss 0.457412.
Train: 2018-08-01T00:48:44.978405: step 14165, loss 0.667207.
Train: 2018-08-01T00:48:45.119028: step 14166, loss 0.562419.
Train: 2018-08-01T00:48:45.275242: step 14167, loss 0.527728.
Train: 2018-08-01T00:48:45.447045: step 14168, loss 0.579701.
Train: 2018-08-01T00:48:45.618881: step 14169, loss 0.510646.
Train: 2018-08-01T00:48:45.775094: step 14170, loss 0.562399.
Test: 2018-08-01T00:48:46.243765: step 14170, loss 0.547997.
Train: 2018-08-01T00:48:46.415598: step 14171, loss 0.562398.
Train: 2018-08-01T00:48:46.587435: step 14172, loss 0.579571.
Train: 2018-08-01T00:48:46.743647: step 14173, loss 0.562397.
Train: 2018-08-01T00:48:46.899860: step 14174, loss 0.528145.
Train: 2018-08-01T00:48:47.056074: step 14175, loss 0.562398.
Train: 2018-08-01T00:48:47.212282: step 14176, loss 0.596605.
Train: 2018-08-01T00:48:47.368501: step 14177, loss 0.494057.
Train: 2018-08-01T00:48:47.524714: step 14178, loss 0.562399.
Train: 2018-08-01T00:48:47.696544: step 14179, loss 0.545312.
Train: 2018-08-01T00:48:47.868378: step 14180, loss 0.545307.
Test: 2018-08-01T00:48:48.337023: step 14180, loss 0.548079.
Train: 2018-08-01T00:48:48.493237: step 14181, loss 0.511098.
Train: 2018-08-01T00:48:48.680664: step 14182, loss 0.493917.
Train: 2018-08-01T00:48:48.836877: step 14183, loss 0.579551.
Train: 2018-08-01T00:48:48.993089: step 14184, loss 0.459308.
Train: 2018-08-01T00:48:49.149303: step 14185, loss 0.527939.
Train: 2018-08-01T00:48:49.305516: step 14186, loss 0.579684.
Train: 2018-08-01T00:48:49.461730: step 14187, loss 0.614377.
Train: 2018-08-01T00:48:49.617974: step 14188, loss 0.649152.
Train: 2018-08-01T00:48:49.774158: step 14189, loss 0.631811.
Train: 2018-08-01T00:48:49.930370: step 14190, loss 0.683752.
Test: 2018-08-01T00:48:50.414662: step 14190, loss 0.547923.
Train: 2018-08-01T00:48:50.570875: step 14191, loss 0.562403.
Train: 2018-08-01T00:48:50.742680: step 14192, loss 0.596907.
Train: 2018-08-01T00:48:50.898894: step 14193, loss 0.545187.
Train: 2018-08-01T00:48:51.055107: step 14194, loss 0.562396.
Train: 2018-08-01T00:48:51.195699: step 14195, loss 0.545253.
Train: 2018-08-01T00:48:51.367565: step 14196, loss 0.51104.
Train: 2018-08-01T00:48:51.523779: step 14197, loss 0.562397.
Train: 2018-08-01T00:48:51.679962: step 14198, loss 0.562397.
Train: 2018-08-01T00:48:51.836175: step 14199, loss 0.596584.
Train: 2018-08-01T00:48:52.008009: step 14200, loss 0.528242.
Test: 2018-08-01T00:48:52.476679: step 14200, loss 0.548102.
Train: 2018-08-01T00:48:53.195266: step 14201, loss 0.579472.
Train: 2018-08-01T00:48:53.351475: step 14202, loss 0.59653.
Train: 2018-08-01T00:48:53.507658: step 14203, loss 0.630601.
Train: 2018-08-01T00:48:53.679501: step 14204, loss 0.511342.
Train: 2018-08-01T00:48:53.820115: step 14205, loss 0.494379.
Train: 2018-08-01T00:48:53.976298: step 14206, loss 0.562404.
Train: 2018-08-01T00:48:54.148165: step 14207, loss 0.630463.
Train: 2018-08-01T00:48:54.319993: step 14208, loss 0.59641.
Train: 2018-08-01T00:48:54.476219: step 14209, loss 0.61336.
Train: 2018-08-01T00:48:54.632434: step 14210, loss 0.613279.
Test: 2018-08-01T00:48:55.116670: step 14210, loss 0.54825.
Train: 2018-08-01T00:48:55.272870: step 14211, loss 0.596255.
Train: 2018-08-01T00:48:55.444740: step 14212, loss 0.629938.
Train: 2018-08-01T00:48:55.600918: step 14213, loss 0.545612.
Train: 2018-08-01T00:48:55.757165: step 14214, loss 0.596018.
Train: 2018-08-01T00:48:55.913345: step 14215, loss 0.545724.
Train: 2018-08-01T00:48:56.069558: step 14216, loss 0.478951.
Train: 2018-08-01T00:48:56.241393: step 14217, loss 0.495697.
Train: 2018-08-01T00:48:56.397608: step 14218, loss 0.629293.
Train: 2018-08-01T00:48:56.553820: step 14219, loss 0.612571.
Train: 2018-08-01T00:48:56.710068: step 14220, loss 0.595846.
Test: 2018-08-01T00:48:57.178703: step 14220, loss 0.548541.
Train: 2018-08-01T00:48:57.334917: step 14221, loss 0.645789.
Train: 2018-08-01T00:48:57.491125: step 14222, loss 0.545885.
Train: 2018-08-01T00:48:57.647344: step 14223, loss 0.529334.
Train: 2018-08-01T00:48:57.803557: step 14224, loss 0.496219.
Train: 2018-08-01T00:48:57.959740: step 14225, loss 0.612266.
Train: 2018-08-01T00:48:58.131609: step 14226, loss 0.678542.
Train: 2018-08-01T00:48:58.287819: step 14227, loss 0.595624.
Train: 2018-08-01T00:48:58.444002: step 14228, loss 0.612075.
Train: 2018-08-01T00:48:58.631458: step 14229, loss 0.579045.
Train: 2018-08-01T00:48:58.787696: step 14230, loss 0.52976.
Test: 2018-08-01T00:48:59.256312: step 14230, loss 0.548889.
Train: 2018-08-01T00:48:59.412555: step 14231, loss 0.513429.
Train: 2018-08-01T00:48:59.568739: step 14232, loss 0.595402.
Train: 2018-08-01T00:48:59.756195: step 14233, loss 0.480756.
Train: 2018-08-01T00:48:59.912408: step 14234, loss 0.579012.
Train: 2018-08-01T00:49:00.068652: step 14235, loss 0.497044.
Train: 2018-08-01T00:49:00.224865: step 14236, loss 0.562606.
Train: 2018-08-01T00:49:00.396669: step 14237, loss 0.579037.
Train: 2018-08-01T00:49:00.552883: step 14238, loss 0.513177.
Train: 2018-08-01T00:49:00.709127: step 14239, loss 0.579063.
Train: 2018-08-01T00:49:00.880965: step 14240, loss 0.546018.
Test: 2018-08-01T00:49:01.349601: step 14240, loss 0.548665.
Train: 2018-08-01T00:49:01.505785: step 14241, loss 0.545972.
Train: 2018-08-01T00:49:01.661998: step 14242, loss 0.612304.
Train: 2018-08-01T00:49:01.818212: step 14243, loss 0.579125.
Train: 2018-08-01T00:49:01.990047: step 14244, loss 0.529238.
Train: 2018-08-01T00:49:02.130638: step 14245, loss 0.679086.
Train: 2018-08-01T00:49:02.302475: step 14246, loss 0.595797.
Train: 2018-08-01T00:49:02.458717: step 14247, loss 0.579139.
Train: 2018-08-01T00:49:02.614925: step 14248, loss 0.595759.
Train: 2018-08-01T00:49:02.771114: step 14249, loss 0.529292.
Train: 2018-08-01T00:49:02.927357: step 14250, loss 0.695343.
Test: 2018-08-01T00:49:03.411620: step 14250, loss 0.548657.
Train: 2018-08-01T00:49:03.567832: step 14251, loss 0.512829.
Train: 2018-08-01T00:49:03.724045: step 14252, loss 0.579087.
Train: 2018-08-01T00:49:03.880263: step 14253, loss 0.479899.
Train: 2018-08-01T00:49:04.036444: step 14254, loss 0.529475.
Train: 2018-08-01T00:49:04.208307: step 14255, loss 0.496338.
Train: 2018-08-01T00:49:04.364515: step 14256, loss 0.595687.
Train: 2018-08-01T00:49:04.520734: step 14257, loss 0.562514.
Train: 2018-08-01T00:49:04.676918: step 14258, loss 0.529254.
Train: 2018-08-01T00:49:04.833130: step 14259, loss 0.545838.
Train: 2018-08-01T00:49:04.989377: step 14260, loss 0.495733.
Test: 2018-08-01T00:49:05.458009: step 14260, loss 0.548452.
Train: 2018-08-01T00:49:05.629819: step 14261, loss 0.49553.
Train: 2018-08-01T00:49:05.786063: step 14262, loss 0.596034.
Train: 2018-08-01T00:49:05.942282: step 14263, loss 0.596115.
Train: 2018-08-01T00:49:06.098490: step 14264, loss 0.545552.
Train: 2018-08-01T00:49:06.254699: step 14265, loss 0.528596.
Train: 2018-08-01T00:49:06.426538: step 14266, loss 0.596318.
Train: 2018-08-01T00:49:06.582751: step 14267, loss 0.596373.
Train: 2018-08-01T00:49:06.738959: step 14268, loss 0.545403.
Train: 2018-08-01T00:49:06.879560: step 14269, loss 0.6305.
Train: 2018-08-01T00:49:07.051392: step 14270, loss 0.57943.
Test: 2018-08-01T00:49:07.520032: step 14270, loss 0.548143.
Train: 2018-08-01T00:49:07.676239: step 14271, loss 0.528346.
Train: 2018-08-01T00:49:07.832460: step 14272, loss 0.545365.
Train: 2018-08-01T00:49:07.988643: step 14273, loss 0.494206.
Train: 2018-08-01T00:49:08.160513: step 14274, loss 0.545322.
Train: 2018-08-01T00:49:08.316690: step 14275, loss 0.562397.
Train: 2018-08-01T00:49:08.472905: step 14276, loss 0.579528.
Train: 2018-08-01T00:49:08.629117: step 14277, loss 0.510941.
Train: 2018-08-01T00:49:08.785331: step 14278, loss 0.596759.
Train: 2018-08-01T00:49:08.941543: step 14279, loss 0.493595.
Train: 2018-08-01T00:49:09.097787: step 14280, loss 0.527931.
Test: 2018-08-01T00:49:09.566435: step 14280, loss 0.547938.
Train: 2018-08-01T00:49:09.738266: step 14281, loss 0.579672.
Train: 2018-08-01T00:49:09.894470: step 14282, loss 0.579705.
Train: 2018-08-01T00:49:10.050683: step 14283, loss 0.545083.
Train: 2018-08-01T00:49:10.206902: step 14284, loss 0.545063.
Train: 2018-08-01T00:49:10.363118: step 14285, loss 0.579785.
Train: 2018-08-01T00:49:10.519299: step 14286, loss 0.527639.
Train: 2018-08-01T00:49:10.691134: step 14287, loss 0.562421.
Train: 2018-08-01T00:49:10.847372: step 14288, loss 0.544993.
Train: 2018-08-01T00:49:11.003594: step 14289, loss 0.667149.
Train: 2018-08-01T00:49:11.159775: step 14290, loss 0.405407.
Test: 2018-08-01T00:49:11.628448: step 14290, loss 0.5478.
Train: 2018-08-01T00:49:11.800249: step 14291, loss 0.579912.
Train: 2018-08-01T00:49:11.956493: step 14292, loss 0.597439.
Train: 2018-08-01T00:49:12.097086: step 14293, loss 0.597463.
Train: 2018-08-01T00:49:12.268920: step 14294, loss 0.632483.
Train: 2018-08-01T00:49:12.440726: step 14295, loss 0.614917.
Train: 2018-08-01T00:49:12.596937: step 14296, loss 0.632287.
Train: 2018-08-01T00:49:12.753152: step 14297, loss 0.649524.
Train: 2018-08-01T00:49:12.924986: step 14298, loss 0.527692.
Train: 2018-08-01T00:49:13.081199: step 14299, loss 0.579718.
Train: 2018-08-01T00:49:13.237413: step 14300, loss 0.6142.
Test: 2018-08-01T00:49:13.706055: step 14300, loss 0.547984.
Train: 2018-08-01T00:49:14.440286: step 14301, loss 0.476338.
Train: 2018-08-01T00:49:14.596500: step 14302, loss 0.493664.
Train: 2018-08-01T00:49:14.752717: step 14303, loss 0.631089.
Train: 2018-08-01T00:49:14.908896: step 14304, loss 0.61384.
Train: 2018-08-01T00:49:15.080731: step 14305, loss 0.52817.
Train: 2018-08-01T00:49:15.221362: step 14306, loss 0.528217.
Train: 2018-08-01T00:49:15.377571: step 14307, loss 0.562398.
Train: 2018-08-01T00:49:15.533751: step 14308, loss 0.596533.
Train: 2018-08-01T00:49:15.689994: step 14309, loss 0.647646.
Train: 2018-08-01T00:49:15.846207: step 14310, loss 0.562404.
Test: 2018-08-01T00:49:16.330456: step 14310, loss 0.548188.
Train: 2018-08-01T00:49:16.486682: step 14311, loss 0.613351.
Train: 2018-08-01T00:49:16.642890: step 14312, loss 0.562414.
Train: 2018-08-01T00:49:16.799103: step 14313, loss 0.444089.
Train: 2018-08-01T00:49:16.970913: step 14314, loss 0.427207.
Train: 2018-08-01T00:49:17.127161: step 14315, loss 0.613213.
Train: 2018-08-01T00:49:17.330243: step 14316, loss 0.596311.
Train: 2018-08-01T00:49:17.486417: step 14317, loss 0.511542.
Train: 2018-08-01T00:49:17.642661: step 14318, loss 0.545433.
Train: 2018-08-01T00:49:17.798869: step 14319, loss 0.511412.
Train: 2018-08-01T00:49:17.955082: step 14320, loss 0.613494.
Test: 2018-08-01T00:49:18.439349: step 14320, loss 0.548124.
Train: 2018-08-01T00:49:18.595534: step 14321, loss 0.443063.
Train: 2018-08-01T00:49:18.751780: step 14322, loss 0.682048.
Train: 2018-08-01T00:49:18.907959: step 14323, loss 0.613711.
Train: 2018-08-01T00:49:19.064172: step 14324, loss 0.613707.
Train: 2018-08-01T00:49:19.220416: step 14325, loss 0.596577.
Train: 2018-08-01T00:49:19.376625: step 14326, loss 0.494119.
Train: 2018-08-01T00:49:19.564092: step 14327, loss 0.596536.
Train: 2018-08-01T00:49:19.720300: step 14328, loss 0.52828.
Train: 2018-08-01T00:49:19.876508: step 14329, loss 0.51122.
Train: 2018-08-01T00:49:20.032722: step 14330, loss 0.477036.
Test: 2018-08-01T00:49:20.516959: step 14330, loss 0.548074.
Train: 2018-08-01T00:49:20.673202: step 14331, loss 0.613711.
Train: 2018-08-01T00:49:20.829415: step 14332, loss 0.545275.
Train: 2018-08-01T00:49:20.985629: step 14333, loss 0.596678.
Train: 2018-08-01T00:49:21.141836: step 14334, loss 0.596696.
Train: 2018-08-01T00:49:21.298025: step 14335, loss 0.579546.
Train: 2018-08-01T00:49:21.454239: step 14336, loss 0.510956.
Train: 2018-08-01T00:49:21.626088: step 14337, loss 0.579551.
Train: 2018-08-01T00:49:21.782317: step 14338, loss 0.493758.
Train: 2018-08-01T00:49:21.938499: step 14339, loss 0.493679.
Train: 2018-08-01T00:49:22.094714: step 14340, loss 0.493543.
Test: 2018-08-01T00:49:22.563354: step 14340, loss 0.547946.
Train: 2018-08-01T00:49:22.735216: step 14341, loss 0.57966.
Train: 2018-08-01T00:49:22.907048: step 14342, loss 0.597.
Train: 2018-08-01T00:49:23.063267: step 14343, loss 0.614377.
Train: 2018-08-01T00:49:23.219480: step 14344, loss 0.458406.
Train: 2018-08-01T00:49:23.375698: step 14345, loss 0.510312.
Train: 2018-08-01T00:49:23.531876: step 14346, loss 0.510196.
Train: 2018-08-01T00:49:23.688091: step 14347, loss 0.475146.
Train: 2018-08-01T00:49:23.844304: step 14348, loss 0.667567.
Train: 2018-08-01T00:49:24.016139: step 14349, loss 0.509801.
Train: 2018-08-01T00:49:24.172382: step 14350, loss 0.544877.
Test: 2018-08-01T00:49:24.640992: step 14350, loss 0.547719.
Train: 2018-08-01T00:49:24.812858: step 14351, loss 0.544852.
Train: 2018-08-01T00:49:24.984696: step 14352, loss 0.597826.
Train: 2018-08-01T00:49:25.125279: step 14353, loss 0.527126.
Train: 2018-08-01T00:49:25.281468: step 14354, loss 0.491649.
Train: 2018-08-01T00:49:25.437681: step 14355, loss 0.598045.
Train: 2018-08-01T00:49:25.593925: step 14356, loss 0.473637.
Train: 2018-08-01T00:49:25.765759: step 14357, loss 0.509096.
Train: 2018-08-01T00:49:25.921967: step 14358, loss 0.634072.
Train: 2018-08-01T00:49:26.093777: step 14359, loss 0.652077.
Train: 2018-08-01T00:49:26.250018: step 14360, loss 0.652071.
Test: 2018-08-01T00:49:26.718631: step 14360, loss 0.547626.
Train: 2018-08-01T00:49:26.890495: step 14361, loss 0.54472.
Train: 2018-08-01T00:49:27.046709: step 14362, loss 0.544729.
Train: 2018-08-01T00:49:27.202928: step 14363, loss 0.455561.
Train: 2018-08-01T00:49:27.374752: step 14364, loss 0.437671.
Train: 2018-08-01T00:49:27.515349: step 14365, loss 0.562594.
Train: 2018-08-01T00:49:27.687184: step 14366, loss 0.65214.
Train: 2018-08-01T00:49:27.843366: step 14367, loss 0.490976.
Train: 2018-08-01T00:49:27.999615: step 14368, loss 0.544696.
Train: 2018-08-01T00:49:28.155819: step 14369, loss 0.562631.
Train: 2018-08-01T00:49:28.327628: step 14370, loss 0.526729.
Test: 2018-08-01T00:49:28.811920: step 14370, loss 0.5476.
Train: 2018-08-01T00:49:28.968134: step 14371, loss 0.616562.
Train: 2018-08-01T00:49:29.124351: step 14372, loss 0.544677.
Train: 2018-08-01T00:49:29.296184: step 14373, loss 0.56265.
Train: 2018-08-01T00:49:29.467986: step 14374, loss 0.56265.
Train: 2018-08-01T00:49:29.624234: step 14375, loss 0.526708.
Train: 2018-08-01T00:49:29.780439: step 14376, loss 0.63454.
Train: 2018-08-01T00:49:29.936652: step 14377, loss 0.580595.
Train: 2018-08-01T00:49:30.108462: step 14378, loss 0.526757.
Train: 2018-08-01T00:49:30.264705: step 14379, loss 0.634304.
Train: 2018-08-01T00:49:30.420914: step 14380, loss 0.544711.
Test: 2018-08-01T00:49:30.905180: step 14380, loss 0.547627.
Train: 2018-08-01T00:49:31.061363: step 14381, loss 0.491128.
Train: 2018-08-01T00:49:31.217608: step 14382, loss 0.473305.
Train: 2018-08-01T00:49:31.389436: step 14383, loss 0.508991.
Train: 2018-08-01T00:49:31.545650: step 14384, loss 0.455291.
Train: 2018-08-01T00:49:31.701863: step 14385, loss 0.670164.
Train: 2018-08-01T00:49:31.858085: step 14386, loss 0.508827.
Train: 2018-08-01T00:49:32.014265: step 14387, loss 0.580586.
Train: 2018-08-01T00:49:32.186130: step 14388, loss 0.526722.
Train: 2018-08-01T00:49:32.342344: step 14389, loss 0.56265.
Train: 2018-08-01T00:49:32.498527: step 14390, loss 0.454755.
Test: 2018-08-01T00:49:32.967197: step 14390, loss 0.547591.
Train: 2018-08-01T00:49:33.123382: step 14391, loss 0.670764.
Train: 2018-08-01T00:49:33.279625: step 14392, loss 0.634738.
Train: 2018-08-01T00:49:33.451459: step 14393, loss 0.634653.
Train: 2018-08-01T00:49:33.607673: step 14394, loss 0.490796.
Train: 2018-08-01T00:49:33.763857: step 14395, loss 0.526744.
Train: 2018-08-01T00:49:33.920099: step 14396, loss 0.508826.
Train: 2018-08-01T00:49:34.076282: step 14397, loss 0.580559.
Train: 2018-08-01T00:49:34.248158: step 14398, loss 0.562622.
Train: 2018-08-01T00:49:34.404362: step 14399, loss 0.490939.
Train: 2018-08-01T00:49:34.560577: step 14400, loss 0.544695.
Test: 2018-08-01T00:49:35.029214: step 14400, loss 0.547608.
Train: 2018-08-01T00:49:35.779039: step 14401, loss 0.472955.
Train: 2018-08-01T00:49:35.950845: step 14402, loss 0.580601.
Train: 2018-08-01T00:49:36.122718: step 14403, loss 0.562651.
Train: 2018-08-01T00:49:36.278922: step 14404, loss 0.526684.
Train: 2018-08-01T00:49:36.435135: step 14405, loss 0.436644.
Train: 2018-08-01T00:49:36.606939: step 14406, loss 0.526607.
Train: 2018-08-01T00:49:36.747566: step 14407, loss 0.63507.
Train: 2018-08-01T00:49:36.919397: step 14408, loss 0.544633.
Train: 2018-08-01T00:49:37.091226: step 14409, loss 0.635242.
Train: 2018-08-01T00:49:37.247449: step 14410, loss 0.617107.
Test: 2018-08-01T00:49:37.716055: step 14410, loss 0.547577.
Train: 2018-08-01T00:49:37.872303: step 14411, loss 0.508431.
Train: 2018-08-01T00:49:38.028514: step 14412, loss 0.490353.
Train: 2018-08-01T00:49:38.215938: step 14413, loss 0.544634.
Train: 2018-08-01T00:49:38.372185: step 14414, loss 0.598959.
Train: 2018-08-01T00:49:38.528396: step 14415, loss 0.580842.
Train: 2018-08-01T00:49:38.684609: step 14416, loss 0.617011.
Train: 2018-08-01T00:49:38.840822: step 14417, loss 0.544643.
Train: 2018-08-01T00:49:38.997040: step 14418, loss 0.670984.
Train: 2018-08-01T00:49:39.137597: step 14419, loss 0.544666.
Train: 2018-08-01T00:49:39.309469: step 14420, loss 0.580603.
Test: 2018-08-01T00:49:39.793724: step 14420, loss 0.547612.
Train: 2018-08-01T00:49:39.949937: step 14421, loss 0.580535.
Train: 2018-08-01T00:49:40.106151: step 14422, loss 0.61621.
Train: 2018-08-01T00:49:40.262364: step 14423, loss 0.633834.
Train: 2018-08-01T00:49:40.449790: step 14424, loss 0.52703.
Train: 2018-08-01T00:49:40.590413: step 14425, loss 0.527116.
Train: 2018-08-01T00:49:40.746596: step 14426, loss 0.580142.
Train: 2018-08-01T00:49:40.902810: step 14427, loss 0.615297.
Train: 2018-08-01T00:49:41.074674: step 14428, loss 0.492239.
Train: 2018-08-01T00:49:41.230858: step 14429, loss 0.579968.
Train: 2018-08-01T00:49:41.387071: step 14430, loss 0.527465.
Test: 2018-08-01T00:49:41.871366: step 14430, loss 0.547809.
Train: 2018-08-01T00:49:42.027547: step 14431, loss 0.527507.
Train: 2018-08-01T00:49:42.199405: step 14432, loss 0.649665.
Train: 2018-08-01T00:49:42.355594: step 14433, loss 0.545008.
Train: 2018-08-01T00:49:42.511808: step 14434, loss 0.510261.
Train: 2018-08-01T00:49:42.668054: step 14435, loss 0.492928.
Train: 2018-08-01T00:49:42.839855: step 14436, loss 0.562414.
Train: 2018-08-01T00:49:42.980448: step 14437, loss 0.614547.
Train: 2018-08-01T00:49:43.136663: step 14438, loss 0.545046.
Train: 2018-08-01T00:49:43.292907: step 14439, loss 0.562412.
Train: 2018-08-01T00:49:43.449112: step 14440, loss 0.579765.
Test: 2018-08-01T00:49:43.933349: step 14440, loss 0.547885.
Train: 2018-08-01T00:49:44.089562: step 14441, loss 0.579753.
Train: 2018-08-01T00:49:44.245810: step 14442, loss 0.527747.
Train: 2018-08-01T00:49:44.402020: step 14443, loss 0.44113.
Train: 2018-08-01T00:49:44.558227: step 14444, loss 0.545061.
Train: 2018-08-01T00:49:44.730072: step 14445, loss 0.54504.
Train: 2018-08-01T00:49:44.870629: step 14446, loss 0.597218.
Train: 2018-08-01T00:49:45.026843: step 14447, loss 0.527593.
Train: 2018-08-01T00:49:45.198705: step 14448, loss 0.711199.
Train: 2018-08-01T00:49:45.354891: step 14449, loss 0.492755.
Train: 2018-08-01T00:49:45.511106: step 14450, loss 0.545005.
Test: 2018-08-01T00:49:45.979775: step 14450, loss 0.547835.
Train: 2018-08-01T00:49:46.135959: step 14451, loss 0.475325.
Train: 2018-08-01T00:49:46.292172: step 14452, loss 0.527543.
Train: 2018-08-01T00:49:46.464037: step 14453, loss 0.63231.
Train: 2018-08-01T00:49:46.620220: step 14454, loss 0.544958.
Train: 2018-08-01T00:49:46.776464: step 14455, loss 0.667355.
Train: 2018-08-01T00:49:46.948300: step 14456, loss 0.562433.
Train: 2018-08-01T00:49:47.104515: step 14457, loss 0.649695.
Train: 2018-08-01T00:49:47.260726: step 14458, loss 0.527587.
Train: 2018-08-01T00:49:47.416910: step 14459, loss 0.562417.
Train: 2018-08-01T00:49:47.588769: step 14460, loss 0.475569.
Test: 2018-08-01T00:49:48.057417: step 14460, loss 0.547869.
Train: 2018-08-01T00:49:48.213597: step 14461, loss 0.527677.
Train: 2018-08-01T00:49:48.369845: step 14462, loss 0.562414.
Train: 2018-08-01T00:49:48.526024: step 14463, loss 0.458137.
Train: 2018-08-01T00:49:48.697859: step 14464, loss 0.545012.
Train: 2018-08-01T00:49:48.854102: step 14465, loss 0.457803.
Train: 2018-08-01T00:49:49.010316: step 14466, loss 0.475002.
Train: 2018-08-01T00:49:49.182151: step 14467, loss 0.527353.
Train: 2018-08-01T00:49:49.338364: step 14468, loss 0.597709.
Train: 2018-08-01T00:49:49.494548: step 14469, loss 0.562494.
Train: 2018-08-01T00:49:49.650793: step 14470, loss 0.491683.
Test: 2018-08-01T00:49:50.119435: step 14470, loss 0.547663.
Train: 2018-08-01T00:49:50.306881: step 14471, loss 0.491495.
Train: 2018-08-01T00:49:50.463101: step 14472, loss 0.580386.
Train: 2018-08-01T00:49:50.619318: step 14473, loss 0.687691.
Train: 2018-08-01T00:49:50.775497: step 14474, loss 0.562598.
Train: 2018-08-01T00:49:50.931711: step 14475, loss 0.616289.
Train: 2018-08-01T00:49:51.087962: step 14476, loss 0.508931.
Train: 2018-08-01T00:49:51.259791: step 14477, loss 0.634182.
Train: 2018-08-01T00:49:51.431623: step 14478, loss 0.562595.
Train: 2018-08-01T00:49:51.587837: step 14479, loss 0.491125.
Train: 2018-08-01T00:49:51.759641: step 14480, loss 0.45539.
Test: 2018-08-01T00:49:52.212690: step 14480, loss 0.54762.
Train: 2018-08-01T00:49:52.384521: step 14481, loss 0.508932.
Train: 2018-08-01T00:49:52.540709: step 14482, loss 0.508858.
Train: 2018-08-01T00:49:52.696923: step 14483, loss 0.616513.
Train: 2018-08-01T00:49:52.853167: step 14484, loss 0.562652.
Train: 2018-08-01T00:49:53.009373: step 14485, loss 0.616634.
Train: 2018-08-01T00:49:53.165563: step 14486, loss 0.616628.
Train: 2018-08-01T00:49:53.321806: step 14487, loss 0.544676.
Train: 2018-08-01T00:49:53.477991: step 14488, loss 0.490803.
Train: 2018-08-01T00:49:53.649823: step 14489, loss 0.490796.
Train: 2018-08-01T00:49:53.806073: step 14490, loss 0.50872.
Test: 2018-08-01T00:49:54.290330: step 14490, loss 0.547593.
Train: 2018-08-01T00:49:54.446543: step 14491, loss 0.634671.
Train: 2018-08-01T00:49:54.618348: step 14492, loss 0.544665.
Train: 2018-08-01T00:49:54.774560: step 14493, loss 0.634699.
Train: 2018-08-01T00:49:54.930773: step 14494, loss 0.562661.
Train: 2018-08-01T00:49:55.086988: step 14495, loss 0.526701.
Train: 2018-08-01T00:49:55.243200: step 14496, loss 0.598575.
Train: 2018-08-01T00:49:55.383824: step 14497, loss 0.598525.
Train: 2018-08-01T00:49:55.555658: step 14498, loss 0.562616.
Train: 2018-08-01T00:49:55.711872: step 14499, loss 0.580491.
Train: 2018-08-01T00:49:55.868089: step 14500, loss 0.580443.
Test: 2018-08-01T00:49:56.352346: step 14500, loss 0.54764.
Train: 2018-08-01T00:49:57.070928: step 14501, loss 0.544741.
Train: 2018-08-01T00:49:57.227112: step 14502, loss 0.491368.
Train: 2018-08-01T00:49:57.383355: step 14503, loss 0.740387.
Train: 2018-08-01T00:49:57.539568: step 14504, loss 0.633445.
Train: 2018-08-01T00:49:57.711374: step 14505, loss 0.5095.
Train: 2018-08-01T00:49:57.867624: step 14506, loss 0.650555.
Train: 2018-08-01T00:49:58.023829: step 14507, loss 0.509805.
Train: 2018-08-01T00:49:58.180049: step 14508, loss 0.527438.
Train: 2018-08-01T00:49:58.336251: step 14509, loss 0.562432.
Train: 2018-08-01T00:49:58.492474: step 14510, loss 0.544993.
Test: 2018-08-01T00:49:58.961107: step 14510, loss 0.547845.
Train: 2018-08-01T00:49:59.117328: step 14511, loss 0.475395.
Train: 2018-08-01T00:49:59.273507: step 14512, loss 0.632019.
Train: 2018-08-01T00:49:59.429751: step 14513, loss 0.649309.
Train: 2018-08-01T00:49:59.585965: step 14514, loss 0.475716.
Train: 2018-08-01T00:49:59.742182: step 14515, loss 0.562406.
Train: 2018-08-01T00:49:59.913983: step 14516, loss 0.510484.
Train: 2018-08-01T00:50:00.070196: step 14517, loss 0.614319.
Train: 2018-08-01T00:50:00.226442: step 14518, loss 0.527822.
Train: 2018-08-01T00:50:00.382653: step 14519, loss 0.527832.
Train: 2018-08-01T00:50:00.538836: step 14520, loss 0.57969.
Test: 2018-08-01T00:50:01.023129: step 14520, loss 0.547927.
Train: 2018-08-01T00:50:01.210578: step 14521, loss 0.493257.
Train: 2018-08-01T00:50:01.351177: step 14522, loss 0.666208.
Train: 2018-08-01T00:50:01.507389: step 14523, loss 0.527825.
Train: 2018-08-01T00:50:01.663602: step 14524, loss 0.545116.
Train: 2018-08-01T00:50:01.835407: step 14525, loss 0.545116.
Train: 2018-08-01T00:50:01.976030: step 14526, loss 0.51053.
Train: 2018-08-01T00:50:02.132212: step 14527, loss 0.562404.
Train: 2018-08-01T00:50:02.304047: step 14528, loss 0.64901.
Train: 2018-08-01T00:50:02.460291: step 14529, loss 0.52778.
Train: 2018-08-01T00:50:02.616474: step 14530, loss 0.597029.
Test: 2018-08-01T00:50:03.085113: step 14530, loss 0.547914.
Train: 2018-08-01T00:50:03.241328: step 14531, loss 0.49319.
Train: 2018-08-01T00:50:03.413193: step 14532, loss 0.666275.
Train: 2018-08-01T00:50:03.569404: step 14533, loss 0.700754.
Train: 2018-08-01T00:50:03.725623: step 14534, loss 0.458929.
Train: 2018-08-01T00:50:03.881839: step 14535, loss 0.545172.
Train: 2018-08-01T00:50:04.038016: step 14536, loss 0.665662.
Train: 2018-08-01T00:50:04.194229: step 14537, loss 0.510875.
Train: 2018-08-01T00:50:04.350444: step 14538, loss 0.562396.
Train: 2018-08-01T00:50:04.522308: step 14539, loss 0.510996.
Train: 2018-08-01T00:50:04.678491: step 14540, loss 0.511011.
Test: 2018-08-01T00:50:05.162786: step 14540, loss 0.548046.
Train: 2018-08-01T00:50:05.303376: step 14541, loss 0.45958.
Train: 2018-08-01T00:50:05.475213: step 14542, loss 0.665401.
Train: 2018-08-01T00:50:05.647015: step 14543, loss 0.493709.
Train: 2018-08-01T00:50:05.787607: step 14544, loss 0.493631.
Train: 2018-08-01T00:50:05.959441: step 14545, loss 0.614073.
Train: 2018-08-01T00:50:06.115689: step 14546, loss 0.631372.
Train: 2018-08-01T00:50:06.271899: step 14547, loss 0.562398.
Train: 2018-08-01T00:50:06.428082: step 14548, loss 0.493427.
Train: 2018-08-01T00:50:06.584325: step 14549, loss 0.596916.
Train: 2018-08-01T00:50:06.756129: step 14550, loss 0.493344.
Test: 2018-08-01T00:50:07.224801: step 14550, loss 0.547928.
Train: 2018-08-01T00:50:07.380984: step 14551, loss 0.614257.
Train: 2018-08-01T00:50:07.552819: step 14552, loss 0.52782.
Train: 2018-08-01T00:50:07.693411: step 14553, loss 0.631622.
Train: 2018-08-01T00:50:07.865245: step 14554, loss 0.510504.
Train: 2018-08-01T00:50:08.021489: step 14555, loss 0.614326.
Train: 2018-08-01T00:50:08.177671: step 14556, loss 0.493198.
Train: 2018-08-01T00:50:08.333924: step 14557, loss 0.579717.
Train: 2018-08-01T00:50:08.490138: step 14558, loss 0.493138.
Train: 2018-08-01T00:50:08.646313: step 14559, loss 0.527734.
Train: 2018-08-01T00:50:08.818175: step 14560, loss 0.614501.
Test: 2018-08-01T00:50:09.302438: step 14560, loss 0.547865.
Train: 2018-08-01T00:50:09.458652: step 14561, loss 0.666653.
Train: 2018-08-01T00:50:09.614835: step 14562, loss 0.458267.
Train: 2018-08-01T00:50:09.771049: step 14563, loss 0.562412.
Train: 2018-08-01T00:50:09.942884: step 14564, loss 0.579789.
Train: 2018-08-01T00:50:10.099121: step 14565, loss 0.545037.
Train: 2018-08-01T00:50:10.255310: step 14566, loss 0.492884.
Train: 2018-08-01T00:50:10.411554: step 14567, loss 0.597226.
Train: 2018-08-01T00:50:10.567768: step 14568, loss 0.562421.
Train: 2018-08-01T00:50:10.723984: step 14569, loss 0.475317.
Train: 2018-08-01T00:50:10.880191: step 14570, loss 0.597323.
Test: 2018-08-01T00:50:11.364459: step 14570, loss 0.547809.
Train: 2018-08-01T00:50:11.520670: step 14571, loss 0.527506.
Train: 2018-08-01T00:50:11.676883: step 14572, loss 0.544953.
Train: 2018-08-01T00:50:11.833096: step 14573, loss 0.684976.
Train: 2018-08-01T00:50:11.989313: step 14574, loss 0.544945.
Train: 2018-08-01T00:50:12.161140: step 14575, loss 0.614903.
Train: 2018-08-01T00:50:12.317358: step 14576, loss 0.510024.
Train: 2018-08-01T00:50:12.473574: step 14577, loss 0.457647.
Train: 2018-08-01T00:50:12.629784: step 14578, loss 0.562436.
Train: 2018-08-01T00:50:12.785992: step 14579, loss 0.579938.
Train: 2018-08-01T00:50:12.942183: step 14580, loss 0.492415.
Test: 2018-08-01T00:50:13.410822: step 14580, loss 0.547769.
Train: 2018-08-01T00:50:13.567060: step 14581, loss 0.597509.
Train: 2018-08-01T00:50:13.723248: step 14582, loss 0.492285.
Train: 2018-08-01T00:50:13.879492: step 14583, loss 0.544893.
Train: 2018-08-01T00:50:14.051321: step 14584, loss 0.668027.
Train: 2018-08-01T00:50:14.191914: step 14585, loss 0.544877.
Train: 2018-08-01T00:50:14.363724: step 14586, loss 0.562468.
Train: 2018-08-01T00:50:14.519967: step 14587, loss 0.650416.
Train: 2018-08-01T00:50:14.676181: step 14588, loss 0.492192.
Train: 2018-08-01T00:50:14.832396: step 14589, loss 0.544897.
Train: 2018-08-01T00:50:14.988602: step 14590, loss 0.580017.
Test: 2018-08-01T00:50:15.457248: step 14590, loss 0.547757.
Train: 2018-08-01T00:50:15.613430: step 14591, loss 0.509798.
Train: 2018-08-01T00:50:15.769644: step 14592, loss 0.580014.
Train: 2018-08-01T00:50:15.972752: step 14593, loss 0.580012.
Train: 2018-08-01T00:50:16.128966: step 14594, loss 0.544905.
Train: 2018-08-01T00:50:16.285148: step 14595, loss 0.474721.
Train: 2018-08-01T00:50:16.441361: step 14596, loss 0.562459.
Train: 2018-08-01T00:50:16.613196: step 14597, loss 0.562463.
Train: 2018-08-01T00:50:16.769409: step 14598, loss 0.45694.
Train: 2018-08-01T00:50:16.925623: step 14599, loss 0.509615.
Train: 2018-08-01T00:50:17.066246: step 14600, loss 0.633138.
Test: 2018-08-01T00:50:17.550477: step 14600, loss 0.547695.
Train: 2018-08-01T00:50:18.222225: step 14601, loss 0.5625.
Train: 2018-08-01T00:50:18.378408: step 14602, loss 0.580201.
Train: 2018-08-01T00:50:18.534623: step 14603, loss 0.544806.
Train: 2018-08-01T00:50:18.706482: step 14604, loss 0.562513.
Train: 2018-08-01T00:50:18.847073: step 14605, loss 0.580235.
Train: 2018-08-01T00:50:19.018913: step 14606, loss 0.509358.
Train: 2018-08-01T00:50:19.175127: step 14607, loss 0.527061.
Train: 2018-08-01T00:50:19.331310: step 14608, loss 0.598021.
Train: 2018-08-01T00:50:19.487557: step 14609, loss 0.580281.
Train: 2018-08-01T00:50:19.643767: step 14610, loss 0.509283.
Test: 2018-08-01T00:50:20.128028: step 14610, loss 0.547664.
Train: 2018-08-01T00:50:20.284248: step 14611, loss 0.580291.
Train: 2018-08-01T00:50:20.440425: step 14612, loss 0.562534.
Train: 2018-08-01T00:50:20.581043: step 14613, loss 0.580293.
Train: 2018-08-01T00:50:20.737265: step 14614, loss 0.562531.
Train: 2018-08-01T00:50:20.909107: step 14615, loss 0.562528.
Train: 2018-08-01T00:50:21.065309: step 14616, loss 0.438366.
Train: 2018-08-01T00:50:21.237148: step 14617, loss 0.633557.
Train: 2018-08-01T00:50:21.393352: step 14618, loss 0.580287.
Train: 2018-08-01T00:50:21.549571: step 14619, loss 0.651271.
Train: 2018-08-01T00:50:21.705784: step 14620, loss 0.580236.
Test: 2018-08-01T00:50:22.174425: step 14620, loss 0.547692.
Train: 2018-08-01T00:50:22.330608: step 14621, loss 0.615568.
Train: 2018-08-01T00:50:22.486855: step 14622, loss 0.562487.
Train: 2018-08-01T00:50:22.643065: step 14623, loss 0.509654.
Train: 2018-08-01T00:50:22.814894: step 14624, loss 0.562464.
Train: 2018-08-01T00:50:22.971117: step 14625, loss 0.544899.
Train: 2018-08-01T00:50:23.142954: step 14626, loss 0.562451.
Train: 2018-08-01T00:50:23.299161: step 14627, loss 0.615011.
Train: 2018-08-01T00:50:23.455375: step 14628, loss 0.527455.
Train: 2018-08-01T00:50:23.611557: step 14629, loss 0.562434.
Train: 2018-08-01T00:50:23.767771: step 14630, loss 0.6497.
Test: 2018-08-01T00:50:24.236445: step 14630, loss 0.547837.
Train: 2018-08-01T00:50:24.392625: step 14631, loss 0.597253.
Train: 2018-08-01T00:50:24.564496: step 14632, loss 0.597158.
Train: 2018-08-01T00:50:24.720705: step 14633, loss 0.527757.
Train: 2018-08-01T00:50:24.908131: step 14634, loss 0.59698.
Train: 2018-08-01T00:50:25.064343: step 14635, loss 0.562399.
Train: 2018-08-01T00:50:25.220558: step 14636, loss 0.631243.
Train: 2018-08-01T00:50:25.392421: step 14637, loss 0.596719.
Train: 2018-08-01T00:50:25.548635: step 14638, loss 0.545288.
Train: 2018-08-01T00:50:25.704848: step 14639, loss 0.528268.
Train: 2018-08-01T00:50:25.876653: step 14640, loss 0.647574.
Test: 2018-08-01T00:50:26.345293: step 14640, loss 0.548182.
Train: 2018-08-01T00:50:26.517128: step 14641, loss 0.613367.
Train: 2018-08-01T00:50:26.673366: step 14642, loss 0.477755.
Train: 2018-08-01T00:50:26.829554: step 14643, loss 0.511708.
Train: 2018-08-01T00:50:26.985768: step 14644, loss 0.545531.
Train: 2018-08-01T00:50:27.157602: step 14645, loss 0.427336.
Train: 2018-08-01T00:50:27.313816: step 14646, loss 0.613161.
Train: 2018-08-01T00:50:27.501272: step 14647, loss 0.528558.
Train: 2018-08-01T00:50:27.657485: step 14648, loss 0.545462.
Train: 2018-08-01T00:50:27.813699: step 14649, loss 0.52846.
Train: 2018-08-01T00:50:27.969913: step 14650, loss 0.40936.
Test: 2018-08-01T00:50:28.438553: step 14650, loss 0.548104.
Train: 2018-08-01T00:50:28.594799: step 14651, loss 0.579468.
Train: 2018-08-01T00:50:28.751010: step 14652, loss 0.57952.
Train: 2018-08-01T00:50:28.907224: step 14653, loss 0.528056.
Train: 2018-08-01T00:50:29.079058: step 14654, loss 0.682927.
Train: 2018-08-01T00:50:29.235280: step 14655, loss 0.648565.
Train: 2018-08-01T00:50:29.391485: step 14656, loss 0.562397.
Train: 2018-08-01T00:50:29.547698: step 14657, loss 0.545178.
Train: 2018-08-01T00:50:29.703882: step 14658, loss 0.510745.
Train: 2018-08-01T00:50:29.860094: step 14659, loss 0.562397.
Train: 2018-08-01T00:50:30.016338: step 14660, loss 0.579634.
Test: 2018-08-01T00:50:30.484982: step 14660, loss 0.547962.
Train: 2018-08-01T00:50:30.641161: step 14661, loss 0.493438.
Train: 2018-08-01T00:50:30.813027: step 14662, loss 0.631437.
Train: 2018-08-01T00:50:30.969211: step 14663, loss 0.57966.
Train: 2018-08-01T00:50:31.125453: step 14664, loss 0.579656.
Train: 2018-08-01T00:50:31.281661: step 14665, loss 0.596896.
Train: 2018-08-01T00:50:31.453472: step 14666, loss 0.614097.
Train: 2018-08-01T00:50:31.609685: step 14667, loss 0.49357.
Train: 2018-08-01T00:50:31.765923: step 14668, loss 0.562396.
Train: 2018-08-01T00:50:31.937732: step 14669, loss 0.528012.
Train: 2018-08-01T00:50:32.078356: step 14670, loss 0.596784.
Test: 2018-08-01T00:50:32.562618: step 14670, loss 0.548004.
Train: 2018-08-01T00:50:32.718824: step 14671, loss 0.510835.
Train: 2018-08-01T00:50:32.875013: step 14672, loss 0.613976.
Train: 2018-08-01T00:50:33.046873: step 14673, loss 0.648328.
Train: 2018-08-01T00:50:33.203092: step 14674, loss 0.545236.
Train: 2018-08-01T00:50:33.359309: step 14675, loss 0.545256.
Train: 2018-08-01T00:50:33.515520: step 14676, loss 0.562396.
Train: 2018-08-01T00:50:33.671701: step 14677, loss 0.47683.
Train: 2018-08-01T00:50:33.827946: step 14678, loss 0.476782.
Train: 2018-08-01T00:50:33.984129: step 14679, loss 0.579547.
Train: 2018-08-01T00:50:34.155963: step 14680, loss 0.613918.
Test: 2018-08-01T00:50:34.640256: step 14680, loss 0.548008.
Train: 2018-08-01T00:50:34.796469: step 14681, loss 0.545214.
Train: 2018-08-01T00:50:34.952652: step 14682, loss 0.562396.
Train: 2018-08-01T00:50:35.108900: step 14683, loss 0.614004.
Train: 2018-08-01T00:50:35.296321: step 14684, loss 0.665589.
Train: 2018-08-01T00:50:35.452559: step 14685, loss 0.493713.
Train: 2018-08-01T00:50:35.608782: step 14686, loss 0.596719.
Train: 2018-08-01T00:50:35.780614: step 14687, loss 0.54525.
Train: 2018-08-01T00:50:35.936827: step 14688, loss 0.57953.
Train: 2018-08-01T00:50:36.093042: step 14689, loss 0.562396.
Train: 2018-08-01T00:50:36.249223: step 14690, loss 0.596614.
Test: 2018-08-01T00:50:36.717893: step 14690, loss 0.548086.
Train: 2018-08-01T00:50:36.920966: step 14691, loss 0.630757.
Train: 2018-08-01T00:50:37.061533: step 14692, loss 0.579456.
Train: 2018-08-01T00:50:37.217777: step 14693, loss 0.596448.
Train: 2018-08-01T00:50:37.373962: step 14694, loss 0.647329.
Train: 2018-08-01T00:50:37.530204: step 14695, loss 0.579345.
Train: 2018-08-01T00:50:37.686387: step 14696, loss 0.579303.
Train: 2018-08-01T00:50:37.842601: step 14697, loss 0.545611.
Train: 2018-08-01T00:50:37.998844: step 14698, loss 0.562448.
Train: 2018-08-01T00:50:38.155057: step 14699, loss 0.411697.
Train: 2018-08-01T00:50:38.311272: step 14700, loss 0.646248.
Test: 2018-08-01T00:50:38.795532: step 14700, loss 0.548439.
Train: 2018-08-01T00:50:39.529706: step 14701, loss 0.579206.
Train: 2018-08-01T00:50:39.701540: step 14702, loss 0.562466.
Train: 2018-08-01T00:50:39.857778: step 14703, loss 0.545751.
Train: 2018-08-01T00:50:40.013997: step 14704, loss 0.529045.
Train: 2018-08-01T00:50:40.170179: step 14705, loss 0.529033.
Train: 2018-08-01T00:50:40.326418: step 14706, loss 0.512267.
Train: 2018-08-01T00:50:40.482608: step 14707, loss 0.612734.
Train: 2018-08-01T00:50:40.654468: step 14708, loss 0.528909.
Train: 2018-08-01T00:50:40.841897: step 14709, loss 0.612825.
Train: 2018-08-01T00:50:40.998143: step 14710, loss 0.495242.
Test: 2018-08-01T00:50:41.466751: step 14710, loss 0.548349.
Train: 2018-08-01T00:50:41.622990: step 14711, loss 0.528787.
Train: 2018-08-01T00:50:41.779205: step 14712, loss 0.56243.
Train: 2018-08-01T00:50:41.935392: step 14713, loss 0.596195.
Train: 2018-08-01T00:50:42.091606: step 14714, loss 0.646944.
Train: 2018-08-01T00:50:42.247819: step 14715, loss 0.56242.
Train: 2018-08-01T00:50:42.404031: step 14716, loss 0.49482.
Train: 2018-08-01T00:50:42.560270: step 14717, loss 0.410174.
Train: 2018-08-01T00:50:42.716490: step 14718, loss 0.630281.
Train: 2018-08-01T00:50:42.888323: step 14719, loss 0.613402.
Train: 2018-08-01T00:50:43.044507: step 14720, loss 0.579418.
Test: 2018-08-01T00:50:43.513146: step 14720, loss 0.548145.
Train: 2018-08-01T00:50:43.669391: step 14721, loss 0.579428.
Train: 2018-08-01T00:50:43.825604: step 14722, loss 0.494275.
Train: 2018-08-01T00:50:43.997450: step 14723, loss 0.69883.
Train: 2018-08-01T00:50:44.153653: step 14724, loss 0.664648.
Train: 2018-08-01T00:50:44.294245: step 14725, loss 0.647432.
Train: 2018-08-01T00:50:44.466082: step 14726, loss 0.596318.
Train: 2018-08-01T00:50:44.622293: step 14727, loss 0.646915.
Train: 2018-08-01T00:50:44.778506: step 14728, loss 0.680247.
Train: 2018-08-01T00:50:44.934719: step 14729, loss 0.595944.
Train: 2018-08-01T00:50:45.106559: step 14730, loss 0.562493.
Test: 2018-08-01T00:50:45.575194: step 14730, loss 0.548645.
Train: 2018-08-01T00:50:45.731378: step 14731, loss 0.595678.
Train: 2018-08-01T00:50:45.887603: step 14732, loss 0.628563.
Train: 2018-08-01T00:50:46.028184: step 14733, loss 0.480519.
Train: 2018-08-01T00:50:46.215672: step 14734, loss 0.448074.
Train: 2018-08-01T00:50:46.371877: step 14735, loss 0.513593.
Train: 2018-08-01T00:50:46.528067: step 14736, loss 0.64441.
Train: 2018-08-01T00:50:46.684280: step 14737, loss 0.595329.
Train: 2018-08-01T00:50:46.840518: step 14738, loss 0.513723.
Train: 2018-08-01T00:50:46.996706: step 14739, loss 0.54636.
Train: 2018-08-01T00:50:47.152950: step 14740, loss 0.513723.
Test: 2018-08-01T00:50:47.637212: step 14740, loss 0.54898.
Train: 2018-08-01T00:50:47.793394: step 14741, loss 0.578992.
Train: 2018-08-01T00:50:47.949608: step 14742, loss 0.578997.
Train: 2018-08-01T00:50:48.105856: step 14743, loss 0.480838.
Train: 2018-08-01T00:50:48.246445: step 14744, loss 0.579015.
Train: 2018-08-01T00:50:48.418248: step 14745, loss 0.628296.
Train: 2018-08-01T00:50:48.574463: step 14746, loss 0.513292.
Train: 2018-08-01T00:50:48.730710: step 14747, loss 0.628424.
Train: 2018-08-01T00:50:48.902511: step 14748, loss 0.529641.
Train: 2018-08-01T00:50:49.058748: step 14749, loss 0.562569.
Train: 2018-08-01T00:50:49.214967: step 14750, loss 0.612075.
Test: 2018-08-01T00:50:49.695147: step 14750, loss 0.54873.
Train: 2018-08-01T00:50:49.851394: step 14751, loss 0.529534.
Train: 2018-08-01T00:50:50.007607: step 14752, loss 0.43033.
Train: 2018-08-01T00:50:50.163820: step 14753, loss 0.645408.
Train: 2018-08-01T00:50:50.320036: step 14754, loss 0.545912.
Train: 2018-08-01T00:50:50.476218: step 14755, loss 0.446087.
Train: 2018-08-01T00:50:50.648087: step 14756, loss 0.462359.
Train: 2018-08-01T00:50:50.804295: step 14757, loss 0.579219.
Train: 2018-08-01T00:50:50.960478: step 14758, loss 0.646584.
Train: 2018-08-01T00:50:51.116692: step 14759, loss 0.562427.
Train: 2018-08-01T00:50:51.272935: step 14760, loss 0.56242.
Test: 2018-08-01T00:50:51.757167: step 14760, loss 0.548228.
Train: 2018-08-01T00:50:51.913410: step 14761, loss 0.477711.
Train: 2018-08-01T00:50:52.069593: step 14762, loss 0.562406.
Train: 2018-08-01T00:50:52.225838: step 14763, loss 0.596479.
Train: 2018-08-01T00:50:52.382046: step 14764, loss 0.511176.
Train: 2018-08-01T00:50:52.538264: step 14765, loss 0.493926.
Train: 2018-08-01T00:50:52.710071: step 14766, loss 0.510876.
Train: 2018-08-01T00:50:52.881927: step 14767, loss 0.579634.
Train: 2018-08-01T00:50:53.038117: step 14768, loss 0.562402.
Train: 2018-08-01T00:50:53.194330: step 14769, loss 0.597075.
Train: 2018-08-01T00:50:53.334922: step 14770, loss 0.440845.
Test: 2018-08-01T00:50:53.834806: step 14770, loss 0.547832.
Train: 2018-08-01T00:50:53.991019: step 14771, loss 0.597272.
Train: 2018-08-01T00:50:54.147262: step 14772, loss 0.562432.
Train: 2018-08-01T00:50:54.303475: step 14773, loss 0.597451.
Train: 2018-08-01T00:50:54.459689: step 14774, loss 0.439745.
Train: 2018-08-01T00:50:54.615902: step 14775, loss 0.650357.
Train: 2018-08-01T00:50:54.772116: step 14776, loss 0.492066.
Train: 2018-08-01T00:50:54.928313: step 14777, loss 0.439026.
Train: 2018-08-01T00:50:55.100158: step 14778, loss 0.544811.
Train: 2018-08-01T00:50:55.256348: step 14779, loss 0.544779.
Train: 2018-08-01T00:50:55.412562: step 14780, loss 0.544752.
Test: 2018-08-01T00:50:55.881231: step 14780, loss 0.547631.
Train: 2018-08-01T00:50:56.037416: step 14781, loss 0.651842.
Train: 2018-08-01T00:50:56.193628: step 14782, loss 0.634087.
Train: 2018-08-01T00:50:56.349841: step 14783, loss 0.508968.
Train: 2018-08-01T00:50:56.506054: step 14784, loss 0.508942.
Train: 2018-08-01T00:50:56.662268: step 14785, loss 0.526799.
Train: 2018-08-01T00:50:56.818481: step 14786, loss 0.508836.
Train: 2018-08-01T00:50:56.974694: step 14787, loss 0.490802.
Train: 2018-08-01T00:50:57.146531: step 14788, loss 0.562667.
Train: 2018-08-01T00:50:57.302744: step 14789, loss 0.472507.
Train: 2018-08-01T00:50:57.458987: step 14790, loss 0.616982.
Test: 2018-08-01T00:50:57.927628: step 14790, loss 0.547576.
Train: 2018-08-01T00:50:58.083841: step 14791, loss 0.54463.
Train: 2018-08-01T00:50:58.255645: step 14792, loss 0.544623.
Train: 2018-08-01T00:50:58.411888: step 14793, loss 0.544616.
Train: 2018-08-01T00:50:58.568097: step 14794, loss 0.617379.
Train: 2018-08-01T00:50:58.724284: step 14795, loss 0.526411.
Train: 2018-08-01T00:50:58.880499: step 14796, loss 0.581025.
Train: 2018-08-01T00:50:59.036712: step 14797, loss 0.562818.
Train: 2018-08-01T00:50:59.192925: step 14798, loss 0.599236.
Train: 2018-08-01T00:50:59.364797: step 14799, loss 0.508215.
Train: 2018-08-01T00:50:59.520973: step 14800, loss 0.471831.
Test: 2018-08-01T00:50:59.989638: step 14800, loss 0.547568.
Train: 2018-08-01T00:51:00.708195: step 14801, loss 0.617447.
Train: 2018-08-01T00:51:00.864439: step 14802, loss 0.435359.
Train: 2018-08-01T00:51:01.020652: step 14803, loss 0.581067.
Train: 2018-08-01T00:51:01.176860: step 14804, loss 0.398634.
Train: 2018-08-01T00:51:01.333080: step 14805, loss 0.617759.
Train: 2018-08-01T00:51:01.489263: step 14806, loss 0.544589.
Train: 2018-08-01T00:51:01.661097: step 14807, loss 0.599609.
Train: 2018-08-01T00:51:01.817310: step 14808, loss 0.489536.
Train: 2018-08-01T00:51:01.973554: step 14809, loss 0.526213.
Train: 2018-08-01T00:51:02.129768: step 14810, loss 0.61816.
Test: 2018-08-01T00:51:02.598405: step 14810, loss 0.547574.
Train: 2018-08-01T00:51:02.754622: step 14811, loss 0.581381.
Train: 2018-08-01T00:51:02.910835: step 14812, loss 0.489394.
Train: 2018-08-01T00:51:03.082670: step 14813, loss 0.562987.
Train: 2018-08-01T00:51:03.238883: step 14814, loss 0.526171.
Train: 2018-08-01T00:51:03.395091: step 14815, loss 0.544581.
Train: 2018-08-01T00:51:03.551310: step 14816, loss 0.470874.
Train: 2018-08-01T00:51:03.707521: step 14817, loss 0.54458.
Train: 2018-08-01T00:51:03.863706: step 14818, loss 0.581522.
Train: 2018-08-01T00:51:04.019945: step 14819, loss 0.784855.
Train: 2018-08-01T00:51:04.176166: step 14820, loss 0.655215.
Test: 2018-08-01T00:51:04.644803: step 14820, loss 0.547571.
Train: 2018-08-01T00:51:04.801018: step 14821, loss 0.50791.
Train: 2018-08-01T00:51:04.972853: step 14822, loss 0.636211.
Train: 2018-08-01T00:51:05.129066: step 14823, loss 0.581129.
Train: 2018-08-01T00:51:05.285273: step 14824, loss 0.490009.
Train: 2018-08-01T00:51:05.441462: step 14825, loss 0.599086.
Train: 2018-08-01T00:51:05.597675: step 14826, loss 0.490329.
Train: 2018-08-01T00:51:05.753890: step 14827, loss 0.580787.
Train: 2018-08-01T00:51:05.910130: step 14828, loss 0.616797.
Train: 2018-08-01T00:51:06.066348: step 14829, loss 0.562659.
Train: 2018-08-01T00:51:06.222560: step 14830, loss 0.544689.
Test: 2018-08-01T00:51:06.706826: step 14830, loss 0.547617.
Train: 2018-08-01T00:51:06.863040: step 14831, loss 0.634219.
Train: 2018-08-01T00:51:07.019224: step 14832, loss 0.455487.
Train: 2018-08-01T00:51:07.191053: step 14833, loss 0.509098.
Train: 2018-08-01T00:51:07.347297: step 14834, loss 0.580367.
Train: 2018-08-01T00:51:07.503509: step 14835, loss 0.61592.
Train: 2018-08-01T00:51:07.659723: step 14836, loss 0.491497.
Train: 2018-08-01T00:51:07.815906: step 14837, loss 0.615768.
Train: 2018-08-01T00:51:07.972120: step 14838, loss 0.580238.
Train: 2018-08-01T00:51:08.128333: step 14839, loss 0.597888.
Train: 2018-08-01T00:51:08.284546: step 14840, loss 0.562491.
Test: 2018-08-01T00:51:08.753217: step 14840, loss 0.547723.
Train: 2018-08-01T00:51:08.925021: step 14841, loss 0.597721.
Train: 2018-08-01T00:51:09.081234: step 14842, loss 0.562465.
Train: 2018-08-01T00:51:09.237448: step 14843, loss 0.632628.
Train: 2018-08-01T00:51:09.393686: step 14844, loss 0.509963.
Train: 2018-08-01T00:51:09.549905: step 14845, loss 0.614803.
Train: 2018-08-01T00:51:09.706089: step 14846, loss 0.492771.
Train: 2018-08-01T00:51:09.862332: step 14847, loss 0.579805.
Train: 2018-08-01T00:51:10.018548: step 14848, loss 0.545052.
Train: 2018-08-01T00:51:10.174729: step 14849, loss 0.510389.
Train: 2018-08-01T00:51:10.346563: step 14850, loss 0.527743.
Test: 2018-08-01T00:51:10.815234: step 14850, loss 0.547893.
Train: 2018-08-01T00:51:10.971448: step 14851, loss 0.510406.
Train: 2018-08-01T00:51:11.127660: step 14852, loss 0.579757.
Train: 2018-08-01T00:51:11.283878: step 14853, loss 0.64918.
Train: 2018-08-01T00:51:11.455678: step 14854, loss 0.562409.
Train: 2018-08-01T00:51:11.611892: step 14855, loss 0.579732.
Train: 2018-08-01T00:51:11.768105: step 14856, loss 0.614328.
Train: 2018-08-01T00:51:11.939973: step 14857, loss 0.476005.
Train: 2018-08-01T00:51:12.080563: step 14858, loss 0.631498.
Train: 2018-08-01T00:51:12.236745: step 14859, loss 0.596905.
Train: 2018-08-01T00:51:12.392989: step 14860, loss 0.579623.
Test: 2018-08-01T00:51:12.877220: step 14860, loss 0.547998.
Train: 2018-08-01T00:51:13.033433: step 14861, loss 0.613983.
Train: 2018-08-01T00:51:13.189680: step 14862, loss 0.562396.
Train: 2018-08-01T00:51:13.361513: step 14863, loss 0.613762.
Train: 2018-08-01T00:51:13.517726: step 14864, loss 0.562399.
Train: 2018-08-01T00:51:13.689530: step 14865, loss 0.511285.
Train: 2018-08-01T00:51:13.861395: step 14866, loss 0.511354.
Train: 2018-08-01T00:51:14.017579: step 14867, loss 0.613432.
Train: 2018-08-01T00:51:14.173793: step 14868, loss 0.562407.
Train: 2018-08-01T00:51:14.330005: step 14869, loss 0.596358.
Train: 2018-08-01T00:51:14.486244: step 14870, loss 0.562413.
Test: 2018-08-01T00:51:14.970511: step 14870, loss 0.548237.
Train: 2018-08-01T00:51:15.126724: step 14871, loss 0.494685.
Train: 2018-08-01T00:51:15.282909: step 14872, loss 0.579348.
Train: 2018-08-01T00:51:15.439151: step 14873, loss 0.528559.
Train: 2018-08-01T00:51:15.595365: step 14874, loss 0.680955.
Train: 2018-08-01T00:51:15.751576: step 14875, loss 0.511685.
Train: 2018-08-01T00:51:15.923413: step 14876, loss 0.680748.
Train: 2018-08-01T00:51:16.063975: step 14877, loss 0.613036.
Train: 2018-08-01T00:51:16.235810: step 14878, loss 0.629745.
Train: 2018-08-01T00:51:16.392022: step 14879, loss 0.495361.
Train: 2018-08-01T00:51:16.548236: step 14880, loss 0.562462.
Test: 2018-08-01T00:51:17.016876: step 14880, loss 0.548473.
Train: 2018-08-01T00:51:17.173090: step 14881, loss 0.462174.
Train: 2018-08-01T00:51:17.329303: step 14882, loss 0.529033.
Train: 2018-08-01T00:51:17.485547: step 14883, loss 0.562467.
Train: 2018-08-01T00:51:17.641760: step 14884, loss 0.579204.
Train: 2018-08-01T00:51:17.797973: step 14885, loss 0.629459.
Train: 2018-08-01T00:51:17.954183: step 14886, loss 0.512238.
Train: 2018-08-01T00:51:18.110401: step 14887, loss 0.595957.
Train: 2018-08-01T00:51:18.266609: step 14888, loss 0.562459.
Train: 2018-08-01T00:51:18.438453: step 14889, loss 0.512251.
Train: 2018-08-01T00:51:18.594663: step 14890, loss 0.495358.
Test: 2018-08-01T00:51:19.063274: step 14890, loss 0.548345.
Train: 2018-08-01T00:51:19.219517: step 14891, loss 0.579344.
Train: 2018-08-01T00:51:19.391320: step 14892, loss 0.495035.
Train: 2018-08-01T00:51:19.531912: step 14893, loss 0.56224.
Train: 2018-08-01T00:51:19.703773: step 14894, loss 0.527736.
Train: 2018-08-01T00:51:19.844339: step 14895, loss 0.56191.
Train: 2018-08-01T00:51:20.000583: step 14896, loss 0.509818.
Train: 2018-08-01T00:51:20.172387: step 14897, loss 0.529063.
Train: 2018-08-01T00:51:20.328631: step 14898, loss 0.565438.
Train: 2018-08-01T00:51:20.469193: step 14899, loss 0.526967.
Train: 2018-08-01T00:51:20.641058: step 14900, loss 0.657797.
Test: 2018-08-01T00:51:21.109667: step 14900, loss 0.547608.
Train: 2018-08-01T00:51:21.843871: step 14901, loss 0.523464.
Train: 2018-08-01T00:51:22.000114: step 14902, loss 0.580701.
Train: 2018-08-01T00:51:22.156328: step 14903, loss 0.471457.
Train: 2018-08-01T00:51:22.312541: step 14904, loss 0.564062.
Train: 2018-08-01T00:51:22.484371: step 14905, loss 0.615334.
Train: 2018-08-01T00:51:22.640591: step 14906, loss 0.506651.
Train: 2018-08-01T00:51:22.796773: step 14907, loss 0.619228.
Train: 2018-08-01T00:51:22.952987: step 14908, loss 0.541291.
Train: 2018-08-01T00:51:23.109231: step 14909, loss 0.455893.
Train: 2018-08-01T00:51:23.249823: step 14910, loss 0.562993.
Test: 2018-08-01T00:51:23.734083: step 14910, loss 0.54762.
Train: 2018-08-01T00:51:23.890266: step 14911, loss 0.564804.
Train: 2018-08-01T00:51:24.046480: step 14912, loss 0.543377.
Train: 2018-08-01T00:51:24.202693: step 14913, loss 0.666962.
Train: 2018-08-01T00:51:24.358907: step 14914, loss 0.545488.
Train: 2018-08-01T00:51:24.515121: step 14915, loss 0.488771.
Train: 2018-08-01T00:51:24.686957: step 14916, loss 0.595501.
Train: 2018-08-01T00:51:24.843193: step 14917, loss 0.614647.
Train: 2018-08-01T00:51:25.015007: step 14918, loss 0.488548.
Train: 2018-08-01T00:51:25.171217: step 14919, loss 0.585248.
Train: 2018-08-01T00:51:25.327461: step 14920, loss 0.579418.
Test: 2018-08-01T00:51:25.811691: step 14920, loss 0.54758.
Train: 2018-08-01T00:51:25.952284: step 14921, loss 0.585639.
Train: 2018-08-01T00:51:26.124120: step 14922, loss 0.563992.
Train: 2018-08-01T00:51:26.280333: step 14923, loss 0.562129.
Train: 2018-08-01T00:51:26.436571: step 14924, loss 0.435051.
Train: 2018-08-01T00:51:26.608412: step 14925, loss 0.578658.
Train: 2018-08-01T00:51:26.764625: step 14926, loss 0.527469.
Train: 2018-08-01T00:51:26.920808: step 14927, loss 0.552143.
Train: 2018-08-01T00:51:27.077052: step 14928, loss 0.616805.
Train: 2018-08-01T00:51:27.233264: step 14929, loss 0.56005.
Train: 2018-08-01T00:51:27.389478: step 14930, loss 0.575828.
Test: 2018-08-01T00:51:27.873709: step 14930, loss 0.547692.
Train: 2018-08-01T00:51:28.014331: step 14931, loss 0.629795.
Train: 2018-08-01T00:51:28.170515: step 14932, loss 0.652185.
Train: 2018-08-01T00:51:28.326728: step 14933, loss 0.545471.
Train: 2018-08-01T00:51:28.482941: step 14934, loss 0.664777.
Train: 2018-08-01T00:51:28.639186: step 14935, loss 0.528396.
Train: 2018-08-01T00:51:28.811014: step 14936, loss 0.526832.
Train: 2018-08-01T00:51:28.967204: step 14937, loss 0.475664.
Train: 2018-08-01T00:51:29.139063: step 14938, loss 0.616313.
Train: 2018-08-01T00:51:29.295281: step 14939, loss 0.459665.
Train: 2018-08-01T00:51:29.451465: step 14940, loss 0.598018.
Test: 2018-08-01T00:51:29.920135: step 14940, loss 0.547933.
Train: 2018-08-01T00:51:30.107560: step 14941, loss 0.562533.
Train: 2018-08-01T00:51:30.263799: step 14942, loss 0.476879.
Train: 2018-08-01T00:51:30.419989: step 14943, loss 0.563813.
Train: 2018-08-01T00:51:30.576231: step 14944, loss 0.544924.
Train: 2018-08-01T00:51:30.732445: step 14945, loss 0.736182.
Train: 2018-08-01T00:51:30.888627: step 14946, loss 0.543783.
Train: 2018-08-01T00:51:31.044873: step 14947, loss 0.493703.
Train: 2018-08-01T00:51:31.232297: step 14948, loss 0.562112.
Train: 2018-08-01T00:51:31.372890: step 14949, loss 0.493988.
Train: 2018-08-01T00:51:31.529133: step 14950, loss 0.526171.
Test: 2018-08-01T00:51:32.013394: step 14950, loss 0.548013.
Train: 2018-08-01T00:51:32.169578: step 14951, loss 0.596509.
Train: 2018-08-01T00:51:32.357064: step 14952, loss 0.474402.
Train: 2018-08-01T00:51:32.497657: step 14953, loss 0.632015.
Train: 2018-08-01T00:51:32.669462: step 14954, loss 0.562541.
Train: 2018-08-01T00:51:32.825674: step 14955, loss 0.510554.
Train: 2018-08-01T00:51:32.981918: step 14956, loss 0.665306.
Train: 2018-08-01T00:51:33.153753: step 14957, loss 0.630847.
Train: 2018-08-01T00:51:33.309935: step 14958, loss 0.647979.
Train: 2018-08-01T00:51:33.466149: step 14959, loss 0.598267.
Train: 2018-08-01T00:51:33.622363: step 14960, loss 0.442764.
Test: 2018-08-01T00:51:34.091032: step 14960, loss 0.548047.
Train: 2018-08-01T00:51:34.262868: step 14961, loss 0.527263.
Train: 2018-08-01T00:51:34.434675: step 14962, loss 0.564028.
Train: 2018-08-01T00:51:34.590886: step 14963, loss 0.651831.
Train: 2018-08-01T00:51:34.747129: step 14964, loss 0.583569.
Train: 2018-08-01T00:51:34.887716: step 14965, loss 0.528866.
Train: 2018-08-01T00:51:35.043935: step 14966, loss 0.544377.
Train: 2018-08-01T00:51:35.200149: step 14967, loss 0.597694.
Train: 2018-08-01T00:51:35.356332: step 14968, loss 0.512085.
Train: 2018-08-01T00:51:35.528192: step 14969, loss 0.630082.
Train: 2018-08-01T00:51:35.684410: step 14970, loss 0.528939.
Test: 2018-08-01T00:51:36.168641: step 14970, loss 0.5484.
Train: 2018-08-01T00:51:36.324855: step 14971, loss 0.595944.
Train: 2018-08-01T00:51:36.481068: step 14972, loss 0.678993.
Train: 2018-08-01T00:51:36.652903: step 14973, loss 0.545636.
Train: 2018-08-01T00:51:36.809117: step 14974, loss 0.578594.
Train: 2018-08-01T00:51:36.965330: step 14975, loss 0.662316.
Train: 2018-08-01T00:51:37.121543: step 14976, loss 0.678514.
Train: 2018-08-01T00:51:37.277787: step 14977, loss 0.463477.
Train: 2018-08-01T00:51:37.433970: step 14978, loss 0.496695.
Train: 2018-08-01T00:51:37.590208: step 14979, loss 0.51271.
Train: 2018-08-01T00:51:37.762044: step 14980, loss 0.611634.
Test: 2018-08-01T00:51:38.246310: step 14980, loss 0.548829.
Train: 2018-08-01T00:51:38.402519: step 14981, loss 0.563218.
Train: 2018-08-01T00:51:38.574358: step 14982, loss 0.662188.
Train: 2018-08-01T00:51:38.730568: step 14983, loss 0.611927.
Train: 2018-08-01T00:51:38.902407: step 14984, loss 0.611919.
Train: 2018-08-01T00:51:39.058591: step 14985, loss 0.530433.
Train: 2018-08-01T00:51:39.214834: step 14986, loss 0.513791.
Train: 2018-08-01T00:51:39.371017: step 14987, loss 0.611484.
Train: 2018-08-01T00:51:39.527260: step 14988, loss 0.513884.
Train: 2018-08-01T00:51:39.683474: step 14989, loss 0.497803.
Train: 2018-08-01T00:51:39.855279: step 14990, loss 0.562687.
Test: 2018-08-01T00:51:40.323918: step 14990, loss 0.549087.
Train: 2018-08-01T00:51:40.480133: step 14991, loss 0.563079.
Train: 2018-08-01T00:51:40.636376: step 14992, loss 0.709598.
Train: 2018-08-01T00:51:40.808214: step 14993, loss 0.611562.
Train: 2018-08-01T00:51:40.964430: step 14994, loss 0.5629.
Train: 2018-08-01T00:51:41.120607: step 14995, loss 0.643855.
Train: 2018-08-01T00:51:41.261229: step 14996, loss 0.530394.
Train: 2018-08-01T00:51:41.417440: step 14997, loss 0.530444.
Train: 2018-08-01T00:51:41.573656: step 14998, loss 0.546688.
Train: 2018-08-01T00:51:41.729869: step 14999, loss 0.530573.
Train: 2018-08-01T00:51:41.886083: step 15000, loss 0.562868.
Test: 2018-08-01T00:51:42.370315: step 15000, loss 0.54925.
Train: 2018-08-01T00:51:43.073274: step 15001, loss 0.514213.
Train: 2018-08-01T00:51:43.260731: step 15002, loss 0.546601.
Train: 2018-08-01T00:51:43.416945: step 15003, loss 0.579068.
Train: 2018-08-01T00:51:43.573157: step 15004, loss 0.611554.
Train: 2018-08-01T00:51:43.729371: step 15005, loss 0.595329.
Train: 2018-08-01T00:51:43.885585: step 15006, loss 0.595313.
Train: 2018-08-01T00:51:44.041828: step 15007, loss 0.513849.
Train: 2018-08-01T00:51:44.213667: step 15008, loss 0.595317.
Train: 2018-08-01T00:51:44.369871: step 15009, loss 0.579013.
Train: 2018-08-01T00:51:44.526084: step 15010, loss 0.627972.
Test: 2018-08-01T00:51:45.010321: step 15010, loss 0.549047.
Train: 2018-08-01T00:51:45.166565: step 15011, loss 0.644274.
Train: 2018-08-01T00:51:45.322748: step 15012, loss 0.595319.
Train: 2018-08-01T00:51:45.478962: step 15013, loss 0.611521.
Train: 2018-08-01T00:51:45.650795: step 15014, loss 0.497846.
Train: 2018-08-01T00:51:45.807009: step 15015, loss 0.611587.
Train: 2018-08-01T00:51:45.963253: step 15016, loss 0.562853.
Train: 2018-08-01T00:51:46.119436: step 15017, loss 0.498053.
Train: 2018-08-01T00:51:46.275650: step 15018, loss 0.611356.
Train: 2018-08-01T00:51:46.431890: step 15019, loss 0.692152.
Train: 2018-08-01T00:51:46.603697: step 15020, loss 0.595048.
Test: 2018-08-01T00:51:47.072368: step 15020, loss 0.549343.
Train: 2018-08-01T00:51:47.228551: step 15021, loss 0.579056.
Train: 2018-08-01T00:51:47.384766: step 15022, loss 0.562864.
Train: 2018-08-01T00:51:47.556601: step 15023, loss 0.563026.
Train: 2018-08-01T00:51:47.697193: step 15024, loss 0.562858.
Train: 2018-08-01T00:51:47.853435: step 15025, loss 0.658755.
Train: 2018-08-01T00:51:48.025240: step 15026, loss 0.62702.
Train: 2018-08-01T00:51:48.181484: step 15027, loss 0.577965.
Train: 2018-08-01T00:51:48.337667: step 15028, loss 0.563433.
Train: 2018-08-01T00:51:48.493880: step 15029, loss 0.515656.
Train: 2018-08-01T00:51:48.665715: step 15030, loss 0.500356.
Test: 2018-08-01T00:51:49.134355: step 15030, loss 0.549466.
Train: 2018-08-01T00:51:49.290569: step 15031, loss 0.611112.
Train: 2018-08-01T00:51:49.462434: step 15032, loss 0.418842.
Train: 2018-08-01T00:51:49.618617: step 15033, loss 0.597977.
Train: 2018-08-01T00:51:49.790452: step 15034, loss 0.627459.
Train: 2018-08-01T00:51:49.931074: step 15035, loss 0.482071.
Train: 2018-08-01T00:51:50.087282: step 15036, loss 0.694916.
Train: 2018-08-01T00:51:50.243471: step 15037, loss 0.547742.
Train: 2018-08-01T00:51:50.399685: step 15038, loss 0.530317.
Train: 2018-08-01T00:51:50.555898: step 15039, loss 0.611104.
Train: 2018-08-01T00:51:50.712141: step 15040, loss 0.563688.
Test: 2018-08-01T00:51:51.180751: step 15040, loss 0.549416.
Train: 2018-08-01T00:51:51.336995: step 15041, loss 0.466572.
Train: 2018-08-01T00:51:51.493177: step 15042, loss 0.595052.
Train: 2018-08-01T00:51:51.649391: step 15043, loss 0.579003.
Train: 2018-08-01T00:51:51.805629: step 15044, loss 0.57903.
Train: 2018-08-01T00:51:51.977471: step 15045, loss 0.465521.
Train: 2018-08-01T00:51:52.133683: step 15046, loss 0.530304.
Train: 2018-08-01T00:51:52.289900: step 15047, loss 0.562741.
Train: 2018-08-01T00:51:52.446105: step 15048, loss 0.480858.
Train: 2018-08-01T00:51:52.602324: step 15049, loss 0.57919.
Train: 2018-08-01T00:51:52.774153: step 15050, loss 0.509855.
Test: 2018-08-01T00:51:53.258393: step 15050, loss 0.548742.
Train: 2018-08-01T00:51:53.414603: step 15051, loss 0.496312.
Train: 2018-08-01T00:51:53.570851: step 15052, loss 0.562492.
Train: 2018-08-01T00:51:53.727055: step 15053, loss 0.629562.
Train: 2018-08-01T00:51:53.883273: step 15054, loss 0.461902.
Train: 2018-08-01T00:51:54.039487: step 15055, loss 0.545757.
Train: 2018-08-01T00:51:54.211292: step 15056, loss 0.494792.
Train: 2018-08-01T00:51:54.367535: step 15057, loss 0.49441.
Train: 2018-08-01T00:51:54.523723: step 15058, loss 0.527897.
Train: 2018-08-01T00:51:54.679962: step 15059, loss 0.560726.
Train: 2018-08-01T00:51:54.836176: step 15060, loss 0.649521.
Test: 2018-08-01T00:51:55.304816: step 15060, loss 0.547663.
Train: 2018-08-01T00:51:55.476644: step 15061, loss 0.622918.
Train: 2018-08-01T00:51:55.632834: step 15062, loss 0.510176.
Train: 2018-08-01T00:51:55.789086: step 15063, loss 0.525906.
Train: 2018-08-01T00:51:55.945291: step 15064, loss 0.524911.
Train: 2018-08-01T00:51:56.101508: step 15065, loss 0.491086.
Train: 2018-08-01T00:51:56.257723: step 15066, loss 0.599271.
Train: 2018-08-01T00:51:56.445168: step 15067, loss 0.585394.
Train: 2018-08-01T00:51:56.585766: step 15068, loss 0.56658.
Train: 2018-08-01T00:51:56.741979: step 15069, loss 0.509439.
Train: 2018-08-01T00:51:56.913784: step 15070, loss 0.650837.
Test: 2018-08-01T00:51:57.382425: step 15070, loss 0.547812.
Train: 2018-08-01T00:51:57.554288: step 15071, loss 0.526983.
Train: 2018-08-01T00:51:57.710472: step 15072, loss 0.562623.
Train: 2018-08-01T00:51:57.866686: step 15073, loss 0.49201.
Train: 2018-08-01T00:51:58.022900: step 15074, loss 0.56272.
Train: 2018-08-01T00:51:58.179146: step 15075, loss 0.598288.
Train: 2018-08-01T00:51:58.335327: step 15076, loss 0.580228.
Train: 2018-08-01T00:51:58.491565: step 15077, loss 0.597978.
Train: 2018-08-01T00:51:58.663373: step 15078, loss 0.527181.
Train: 2018-08-01T00:51:58.819587: step 15079, loss 0.580287.
Train: 2018-08-01T00:51:58.975831: step 15080, loss 0.597504.
Test: 2018-08-01T00:51:59.444476: step 15080, loss 0.547856.
Train: 2018-08-01T00:51:59.616301: step 15081, loss 0.51001.
Train: 2018-08-01T00:51:59.772489: step 15082, loss 0.544825.
Train: 2018-08-01T00:51:59.913112: step 15083, loss 0.580668.
Train: 2018-08-01T00:52:00.084916: step 15084, loss 0.456928.
Train: 2018-08-01T00:52:00.241129: step 15085, loss 0.527206.
Train: 2018-08-01T00:52:00.397373: step 15086, loss 0.59786.
Train: 2018-08-01T00:52:00.553586: step 15087, loss 0.633462.
Train: 2018-08-01T00:52:00.725427: step 15088, loss 0.509941.
Train: 2018-08-01T00:52:00.881630: step 15089, loss 0.58036.
Train: 2018-08-01T00:52:01.053440: step 15090, loss 0.54505.
Test: 2018-08-01T00:52:01.522110: step 15090, loss 0.547824.
Train: 2018-08-01T00:52:01.678323: step 15091, loss 0.562835.
Train: 2018-08-01T00:52:01.834507: step 15092, loss 0.59733.
Train: 2018-08-01T00:52:01.990720: step 15093, loss 0.580055.
Train: 2018-08-01T00:52:02.146964: step 15094, loss 0.632911.
Train: 2018-08-01T00:52:02.303148: step 15095, loss 0.562875.
Train: 2018-08-01T00:52:02.474982: step 15096, loss 0.632654.
Train: 2018-08-01T00:52:02.631195: step 15097, loss 0.579919.
Train: 2018-08-01T00:52:02.787438: step 15098, loss 0.579587.
Train: 2018-08-01T00:52:02.959268: step 15099, loss 0.562884.
Train: 2018-08-01T00:52:03.115456: step 15100, loss 0.597074.
Test: 2018-08-01T00:52:03.584127: step 15100, loss 0.548108.
Train: 2018-08-01T00:52:04.318330: step 15101, loss 0.528242.
Train: 2018-08-01T00:52:04.474538: step 15102, loss 0.596372.
Train: 2018-08-01T00:52:04.630726: step 15103, loss 0.59633.
Train: 2018-08-01T00:52:04.786971: step 15104, loss 0.561801.
Train: 2018-08-01T00:52:04.943178: step 15105, loss 0.513563.
Train: 2018-08-01T00:52:05.114990: step 15106, loss 0.630672.
Train: 2018-08-01T00:52:05.255611: step 15107, loss 0.543398.
Train: 2018-08-01T00:52:05.411832: step 15108, loss 0.529737.
Train: 2018-08-01T00:52:05.568038: step 15109, loss 0.49706.
Train: 2018-08-01T00:52:05.724220: step 15110, loss 0.461406.
Test: 2018-08-01T00:52:06.208484: step 15110, loss 0.548093.
Train: 2018-08-01T00:52:06.364695: step 15111, loss 0.491808.
Train: 2018-08-01T00:52:06.520939: step 15112, loss 0.57899.
Train: 2018-08-01T00:52:06.677122: step 15113, loss 0.51554.
Train: 2018-08-01T00:52:06.833366: step 15114, loss 0.581861.
Train: 2018-08-01T00:52:06.989574: step 15115, loss 0.742405.
Train: 2018-08-01T00:52:07.145763: step 15116, loss 0.544232.
Train: 2018-08-01T00:52:07.333248: step 15117, loss 0.580129.
Train: 2018-08-01T00:52:07.489462: step 15118, loss 0.478048.
Train: 2018-08-01T00:52:07.645645: step 15119, loss 0.578128.
Train: 2018-08-01T00:52:07.801859: step 15120, loss 0.5813.
Test: 2018-08-01T00:52:08.286150: step 15120, loss 0.548184.
Train: 2018-08-01T00:52:08.473576: step 15121, loss 0.596918.
Train: 2018-08-01T00:52:08.629820: step 15122, loss 0.648359.
Train: 2018-08-01T00:52:08.786034: step 15123, loss 0.477411.
Train: 2018-08-01T00:52:08.926596: step 15124, loss 0.562845.
Train: 2018-08-01T00:52:09.098461: step 15125, loss 0.494402.
Train: 2018-08-01T00:52:09.254644: step 15126, loss 0.596956.
Train: 2018-08-01T00:52:09.410896: step 15127, loss 0.802921.
Train: 2018-08-01T00:52:09.598313: step 15128, loss 0.579735.
Train: 2018-08-01T00:52:09.738929: step 15129, loss 0.647742.
Train: 2018-08-01T00:52:09.910739: step 15130, loss 0.562521.
Test: 2018-08-01T00:52:10.379380: step 15130, loss 0.548401.
Train: 2018-08-01T00:52:10.535619: step 15131, loss 0.613495.
Train: 2018-08-01T00:52:10.707428: step 15132, loss 0.528746.
Train: 2018-08-01T00:52:10.863642: step 15133, loss 0.596026.
Train: 2018-08-01T00:52:11.019880: step 15134, loss 0.445631.
Train: 2018-08-01T00:52:11.191691: step 15135, loss 0.662757.
Train: 2018-08-01T00:52:11.347905: step 15136, loss 0.612566.
Train: 2018-08-01T00:52:11.504147: step 15137, loss 0.478772.
Train: 2018-08-01T00:52:11.675952: step 15138, loss 0.529944.
Train: 2018-08-01T00:52:11.816544: step 15139, loss 0.597311.
Train: 2018-08-01T00:52:11.972757: step 15140, loss 0.562549.
Test: 2018-08-01T00:52:12.441398: step 15140, loss 0.548818.
Train: 2018-08-01T00:52:12.597641: step 15141, loss 0.529498.
Train: 2018-08-01T00:52:12.769477: step 15142, loss 0.495988.
Train: 2018-08-01T00:52:12.925693: step 15143, loss 0.529678.
Train: 2018-08-01T00:52:13.097493: step 15144, loss 0.612349.
Train: 2018-08-01T00:52:13.253733: step 15145, loss 0.562953.
Train: 2018-08-01T00:52:13.409921: step 15146, loss 0.562512.
Train: 2018-08-01T00:52:13.566158: step 15147, loss 0.512452.
Train: 2018-08-01T00:52:13.722348: step 15148, loss 0.529167.
Train: 2018-08-01T00:52:13.878563: step 15149, loss 0.545754.
Train: 2018-08-01T00:52:14.034774: step 15150, loss 0.713816.
Test: 2018-08-01T00:52:14.519066: step 15150, loss 0.548551.
Train: 2018-08-01T00:52:14.675274: step 15151, loss 0.461598.
Train: 2018-08-01T00:52:14.831462: step 15152, loss 0.461622.
Train: 2018-08-01T00:52:15.018949: step 15153, loss 0.529001.
Train: 2018-08-01T00:52:15.190784: step 15154, loss 0.528101.
Train: 2018-08-01T00:52:15.346997: step 15155, loss 0.52741.
Train: 2018-08-01T00:52:15.503212: step 15156, loss 0.596136.
Train: 2018-08-01T00:52:15.659424: step 15157, loss 0.602293.
Train: 2018-08-01T00:52:15.815608: step 15158, loss 0.61366.
Train: 2018-08-01T00:52:16.065550: step 15159, loss 0.509534.
Train: 2018-08-01T00:52:16.221762: step 15160, loss 0.562604.
Test: 2018-08-01T00:52:16.690432: step 15160, loss 0.547997.
Train: 2018-08-01T00:52:16.846646: step 15161, loss 0.616048.
Train: 2018-08-01T00:52:17.002859: step 15162, loss 0.581318.
Train: 2018-08-01T00:52:17.174663: step 15163, loss 0.56269.
Train: 2018-08-01T00:52:17.315258: step 15164, loss 0.493426.
Train: 2018-08-01T00:52:17.487091: step 15165, loss 0.666751.
Train: 2018-08-01T00:52:17.643304: step 15166, loss 0.511135.
Train: 2018-08-01T00:52:17.799551: step 15167, loss 0.511616.
Train: 2018-08-01T00:52:17.955768: step 15168, loss 0.528067.
Train: 2018-08-01T00:52:18.111975: step 15169, loss 0.562111.
Train: 2018-08-01T00:52:18.268183: step 15170, loss 0.579758.
Test: 2018-08-01T00:52:18.752449: step 15170, loss 0.548164.
Train: 2018-08-01T00:52:18.908663: step 15171, loss 0.494672.
Train: 2018-08-01T00:52:19.064877: step 15172, loss 0.630996.
Train: 2018-08-01T00:52:19.221090: step 15173, loss 0.61364.
Train: 2018-08-01T00:52:19.392924: step 15174, loss 0.545568.
Train: 2018-08-01T00:52:19.549108: step 15175, loss 0.443265.
Train: 2018-08-01T00:52:19.705321: step 15176, loss 0.58044.
Train: 2018-08-01T00:52:19.877186: step 15177, loss 0.562756.
Train: 2018-08-01T00:52:20.033400: step 15178, loss 0.597752.
Train: 2018-08-01T00:52:20.189614: step 15179, loss 0.596905.
Train: 2018-08-01T00:52:20.361419: step 15180, loss 0.545379.
Test: 2018-08-01T00:52:20.830058: step 15180, loss 0.548065.
Train: 2018-08-01T00:52:20.986302: step 15181, loss 0.510543.
Train: 2018-08-01T00:52:21.142515: step 15182, loss 0.493248.
Train: 2018-08-01T00:52:21.298729: step 15183, loss 0.649351.
Train: 2018-08-01T00:52:21.486179: step 15184, loss 0.580128.
Train: 2018-08-01T00:52:21.642399: step 15185, loss 0.632108.
Train: 2018-08-01T00:52:21.798617: step 15186, loss 0.510424.
Train: 2018-08-01T00:52:21.954826: step 15187, loss 0.61461.
Train: 2018-08-01T00:52:22.111039: step 15188, loss 0.631891.
Train: 2018-08-01T00:52:22.267246: step 15189, loss 0.597219.
Train: 2018-08-01T00:52:22.439086: step 15190, loss 0.458885.
Test: 2018-08-01T00:52:22.907726: step 15190, loss 0.548122.
Train: 2018-08-01T00:52:23.063934: step 15191, loss 0.476311.
Train: 2018-08-01T00:52:23.235778: step 15192, loss 0.579791.
Train: 2018-08-01T00:52:23.391988: step 15193, loss 0.648898.
Train: 2018-08-01T00:52:23.532580: step 15194, loss 0.545144.
Train: 2018-08-01T00:52:23.704386: step 15195, loss 0.545312.
Train: 2018-08-01T00:52:23.860630: step 15196, loss 0.614326.
Train: 2018-08-01T00:52:24.032439: step 15197, loss 0.493232.
Train: 2018-08-01T00:52:24.188671: step 15198, loss 0.614363.
Train: 2018-08-01T00:52:24.329239: step 15199, loss 0.596126.
Train: 2018-08-01T00:52:24.485482: step 15200, loss 0.580289.
Test: 2018-08-01T00:52:24.969744: step 15200, loss 0.548201.
Train: 2018-08-01T00:52:25.657052: step 15201, loss 0.597226.
Train: 2018-08-01T00:52:25.813266: step 15202, loss 0.5455.
Train: 2018-08-01T00:52:26.000746: step 15203, loss 0.529368.
Train: 2018-08-01T00:52:26.141315: step 15204, loss 0.561619.
Train: 2018-08-01T00:52:26.313150: step 15205, loss 0.511353.
Train: 2018-08-01T00:52:26.469393: step 15206, loss 0.562724.
Train: 2018-08-01T00:52:26.625606: step 15207, loss 0.492299.
Train: 2018-08-01T00:52:26.781789: step 15208, loss 0.563406.
Train: 2018-08-01T00:52:26.953651: step 15209, loss 0.675676.
Train: 2018-08-01T00:52:27.109874: step 15210, loss 0.560936.
Test: 2018-08-01T00:52:27.594131: step 15210, loss 0.547947.
Train: 2018-08-01T00:52:27.750313: step 15211, loss 0.492494.
Train: 2018-08-01T00:52:27.906525: step 15212, loss 0.718499.
Train: 2018-08-01T00:52:28.062740: step 15213, loss 0.612167.
Train: 2018-08-01T00:52:28.218953: step 15214, loss 0.596074.
Train: 2018-08-01T00:52:28.375166: step 15215, loss 0.631953.
Train: 2018-08-01T00:52:28.531380: step 15216, loss 0.595632.
Train: 2018-08-01T00:52:28.687623: step 15217, loss 0.562172.
Train: 2018-08-01T00:52:28.843837: step 15218, loss 0.479363.
Train: 2018-08-01T00:52:29.015672: step 15219, loss 0.581395.
Train: 2018-08-01T00:52:29.171856: step 15220, loss 0.62712.
Test: 2018-08-01T00:52:29.656141: step 15220, loss 0.5489.
Train: 2018-08-01T00:52:29.812360: step 15221, loss 0.678767.
Train: 2018-08-01T00:52:29.952953: step 15222, loss 0.497054.
Train: 2018-08-01T00:52:30.124781: step 15223, loss 0.513865.
Train: 2018-08-01T00:52:30.280971: step 15224, loss 0.546938.
Train: 2018-08-01T00:52:30.452805: step 15225, loss 0.547922.
Train: 2018-08-01T00:52:30.609049: step 15226, loss 0.498633.
Train: 2018-08-01T00:52:30.765262: step 15227, loss 0.532819.
Train: 2018-08-01T00:52:30.921445: step 15228, loss 0.561346.
Train: 2018-08-01T00:52:31.077689: step 15229, loss 0.529352.
Train: 2018-08-01T00:52:31.233902: step 15230, loss 0.563166.
Test: 2018-08-01T00:52:31.702542: step 15230, loss 0.54878.
Train: 2018-08-01T00:52:31.874377: step 15231, loss 0.512572.
Train: 2018-08-01T00:52:32.030590: step 15232, loss 0.562102.
Train: 2018-08-01T00:52:32.186798: step 15233, loss 0.596646.
Train: 2018-08-01T00:52:32.342988: step 15234, loss 0.528931.
Train: 2018-08-01T00:52:32.514853: step 15235, loss 0.579519.
Train: 2018-08-01T00:52:32.671060: step 15236, loss 0.579493.
Train: 2018-08-01T00:52:32.827273: step 15237, loss 0.527673.
Train: 2018-08-01T00:52:32.983492: step 15238, loss 0.563706.
Train: 2018-08-01T00:52:33.139706: step 15239, loss 0.546149.
Train: 2018-08-01T00:52:33.295889: step 15240, loss 0.510059.
Test: 2018-08-01T00:52:33.780181: step 15240, loss 0.548121.
Train: 2018-08-01T00:52:33.936363: step 15241, loss 0.544431.
Train: 2018-08-01T00:52:34.092577: step 15242, loss 0.528267.
Train: 2018-08-01T00:52:34.233169: step 15243, loss 0.597285.
Train: 2018-08-01T00:52:34.405035: step 15244, loss 0.652103.
Train: 2018-08-01T00:52:34.561248: step 15245, loss 0.559926.
Train: 2018-08-01T00:52:34.717431: step 15246, loss 0.423717.
Train: 2018-08-01T00:52:34.873645: step 15247, loss 0.612939.
Train: 2018-08-01T00:52:35.029882: step 15248, loss 0.542143.
Train: 2018-08-01T00:52:35.186101: step 15249, loss 0.477008.
Train: 2018-08-01T00:52:35.342314: step 15250, loss 0.619375.
Test: 2018-08-01T00:52:35.810955: step 15250, loss 0.547762.
Train: 2018-08-01T00:52:35.967139: step 15251, loss 0.522364.
Train: 2018-08-01T00:52:36.107761: step 15252, loss 0.591057.
Train: 2018-08-01T00:52:36.279564: step 15253, loss 0.512328.
Train: 2018-08-01T00:52:36.435781: step 15254, loss 0.504236.
Train: 2018-08-01T00:52:36.591993: step 15255, loss 0.629812.
Train: 2018-08-01T00:52:36.748230: step 15256, loss 0.515491.
Train: 2018-08-01T00:52:36.920040: step 15257, loss 0.570232.
Train: 2018-08-01T00:52:37.076254: step 15258, loss 0.688815.
Train: 2018-08-01T00:52:37.216876: step 15259, loss 0.581024.
Train: 2018-08-01T00:52:37.373089: step 15260, loss 0.582289.
Test: 2018-08-01T00:52:37.857350: step 15260, loss 0.547784.
Train: 2018-08-01T00:52:38.076044: step 15261, loss 0.434199.
Train: 2018-08-01T00:52:38.247885: step 15262, loss 0.559149.
Train: 2018-08-01T00:52:38.404068: step 15263, loss 0.613154.
Train: 2018-08-01T00:52:38.560307: step 15264, loss 0.530308.
Train: 2018-08-01T00:52:38.716526: step 15265, loss 0.632561.
Train: 2018-08-01T00:52:38.888331: step 15266, loss 0.618992.
Train: 2018-08-01T00:52:39.044568: step 15267, loss 0.630467.
Train: 2018-08-01T00:52:39.200755: step 15268, loss 0.472796.
Train: 2018-08-01T00:52:39.372621: step 15269, loss 0.526373.
Train: 2018-08-01T00:52:39.528805: step 15270, loss 0.528491.
Test: 2018-08-01T00:52:39.997475: step 15270, loss 0.548275.
Train: 2018-08-01T00:52:40.169305: step 15271, loss 0.630271.
Train: 2018-08-01T00:52:40.325517: step 15272, loss 0.633837.
Train: 2018-08-01T00:52:40.466086: step 15273, loss 0.561079.
Train: 2018-08-01T00:52:40.622299: step 15274, loss 0.528359.
Train: 2018-08-01T00:52:40.778541: step 15275, loss 0.49458.
Train: 2018-08-01T00:52:40.950377: step 15276, loss 0.596634.
Train: 2018-08-01T00:52:41.106591: step 15277, loss 0.597698.
Train: 2018-08-01T00:52:41.278395: step 15278, loss 0.459745.
Train: 2018-08-01T00:52:41.419019: step 15279, loss 0.529464.
Train: 2018-08-01T00:52:41.590821: step 15280, loss 0.615381.
Test: 2018-08-01T00:52:42.075083: step 15280, loss 0.548407.
Train: 2018-08-01T00:52:42.215706: step 15281, loss 0.544239.
Train: 2018-08-01T00:52:42.387535: step 15282, loss 0.527031.
Train: 2018-08-01T00:52:42.543754: step 15283, loss 0.511184.
Train: 2018-08-01T00:52:42.699968: step 15284, loss 0.599358.
Train: 2018-08-01T00:52:42.856180: step 15285, loss 0.632089.
Train: 2018-08-01T00:52:43.012395: step 15286, loss 0.543984.
Train: 2018-08-01T00:52:43.168607: step 15287, loss 0.47814.
Train: 2018-08-01T00:52:43.324821: step 15288, loss 0.597544.
Train: 2018-08-01T00:52:43.496655: step 15289, loss 0.562993.
Train: 2018-08-01T00:52:43.652869: step 15290, loss 0.579598.
Test: 2018-08-01T00:52:44.121508: step 15290, loss 0.548294.
Train: 2018-08-01T00:52:44.293347: step 15291, loss 0.596939.
Train: 2018-08-01T00:52:44.449557: step 15292, loss 0.476576.
Train: 2018-08-01T00:52:44.636983: step 15293, loss 0.545923.
Train: 2018-08-01T00:52:44.777605: step 15294, loss 0.647338.
Train: 2018-08-01T00:52:44.933789: step 15295, loss 0.528104.
Train: 2018-08-01T00:52:45.090032: step 15296, loss 0.494311.
Train: 2018-08-01T00:52:45.246240: step 15297, loss 0.579743.
Train: 2018-08-01T00:52:45.402428: step 15298, loss 0.613246.
Train: 2018-08-01T00:52:45.558672: step 15299, loss 0.579496.
Train: 2018-08-01T00:52:45.714856: step 15300, loss 0.51079.
Test: 2018-08-01T00:52:46.199147: step 15300, loss 0.548205.
Train: 2018-08-01T00:52:46.902108: step 15301, loss 0.597089.
Train: 2018-08-01T00:52:47.058292: step 15302, loss 0.613688.
Train: 2018-08-01T00:52:47.230156: step 15303, loss 0.510846.
Train: 2018-08-01T00:52:47.386366: step 15304, loss 0.51098.
Train: 2018-08-01T00:52:47.542583: step 15305, loss 0.544702.
Train: 2018-08-01T00:52:47.683146: step 15306, loss 0.512094.
Train: 2018-08-01T00:52:47.855006: step 15307, loss 0.631623.
Train: 2018-08-01T00:52:48.011229: step 15308, loss 0.596228.
Train: 2018-08-01T00:52:48.167436: step 15309, loss 0.527105.
Train: 2018-08-01T00:52:48.339272: step 15310, loss 0.63067.
Test: 2018-08-01T00:52:48.807912: step 15310, loss 0.548174.
Train: 2018-08-01T00:52:48.979729: step 15311, loss 0.511262.
Train: 2018-08-01T00:52:49.120308: step 15312, loss 0.597945.
Train: 2018-08-01T00:52:49.276521: step 15313, loss 0.597904.
Train: 2018-08-01T00:52:49.432736: step 15314, loss 0.580445.
Train: 2018-08-01T00:52:49.588949: step 15315, loss 0.613548.
Train: 2018-08-01T00:52:49.745162: step 15316, loss 0.648703.
Train: 2018-08-01T00:52:49.901403: step 15317, loss 0.529535.
Train: 2018-08-01T00:52:50.073211: step 15318, loss 0.718062.
Train: 2018-08-01T00:52:50.213802: step 15319, loss 0.545159.
Train: 2018-08-01T00:52:50.385636: step 15320, loss 0.596506.
Test: 2018-08-01T00:52:50.854307: step 15320, loss 0.548519.
Train: 2018-08-01T00:52:51.010491: step 15321, loss 0.646572.
Train: 2018-08-01T00:52:51.182326: step 15322, loss 0.579456.
Train: 2018-08-01T00:52:51.338538: step 15323, loss 0.496051.
Train: 2018-08-01T00:52:51.494753: step 15324, loss 0.562619.
Train: 2018-08-01T00:52:51.650996: step 15325, loss 0.563234.
Train: 2018-08-01T00:52:51.807179: step 15326, loss 0.545802.
Train: 2018-08-01T00:52:51.963423: step 15327, loss 0.529452.
Train: 2018-08-01T00:52:52.119636: step 15328, loss 0.661886.
Train: 2018-08-01T00:52:52.275850: step 15329, loss 0.530065.
Train: 2018-08-01T00:52:52.432033: step 15330, loss 0.579551.
Test: 2018-08-01T00:52:52.900703: step 15330, loss 0.548913.
Train: 2018-08-01T00:52:53.056886: step 15331, loss 0.529498.
Train: 2018-08-01T00:52:53.228751: step 15332, loss 0.579112.
Train: 2018-08-01T00:52:53.400587: step 15333, loss 0.579323.
Train: 2018-08-01T00:52:53.556799: step 15334, loss 0.529958.
Train: 2018-08-01T00:52:53.713014: step 15335, loss 0.563124.
Train: 2018-08-01T00:52:53.869196: step 15336, loss 0.546352.
Train: 2018-08-01T00:52:54.025411: step 15337, loss 0.513852.
Train: 2018-08-01T00:52:54.181653: step 15338, loss 0.513296.
Train: 2018-08-01T00:52:54.337867: step 15339, loss 0.546493.
Train: 2018-08-01T00:52:54.525325: step 15340, loss 0.479745.
Test: 2018-08-01T00:52:55.009584: step 15340, loss 0.548727.
Train: 2018-08-01T00:52:55.165798: step 15341, loss 0.529243.
Train: 2018-08-01T00:52:55.321981: step 15342, loss 0.495534.
Train: 2018-08-01T00:52:55.493821: step 15343, loss 0.49517.
Train: 2018-08-01T00:52:55.665684: step 15344, loss 0.545004.
Train: 2018-08-01T00:52:55.821900: step 15345, loss 0.528974.
Train: 2018-08-01T00:52:55.978107: step 15346, loss 0.474667.
Train: 2018-08-01T00:52:56.134315: step 15347, loss 0.636863.
Train: 2018-08-01T00:52:56.290541: step 15348, loss 0.470065.
Train: 2018-08-01T00:52:56.446750: step 15349, loss 0.644365.
Train: 2018-08-01T00:52:56.618552: step 15350, loss 0.55664.
Test: 2018-08-01T00:52:57.087223: step 15350, loss 0.547733.
Train: 2018-08-01T00:52:57.243407: step 15351, loss 0.680488.
Train: 2018-08-01T00:52:57.399649: step 15352, loss 0.530264.
Train: 2018-08-01T00:52:57.555834: step 15353, loss 0.528417.
Train: 2018-08-01T00:52:57.712047: step 15354, loss 0.649538.
Train: 2018-08-01T00:52:57.868290: step 15355, loss 0.475694.
Train: 2018-08-01T00:52:58.024503: step 15356, loss 0.545292.
Train: 2018-08-01T00:52:58.196308: step 15357, loss 0.440844.
Train: 2018-08-01T00:52:58.336930: step 15358, loss 0.545318.
Train: 2018-08-01T00:52:58.493114: step 15359, loss 0.5974.
Train: 2018-08-01T00:52:58.649327: step 15360, loss 0.650068.
Test: 2018-08-01T00:52:59.117997: step 15360, loss 0.547916.
Train: 2018-08-01T00:52:59.274180: step 15361, loss 0.527436.
Train: 2018-08-01T00:52:59.430429: step 15362, loss 0.580182.
Train: 2018-08-01T00:52:59.602230: step 15363, loss 0.580377.
Train: 2018-08-01T00:52:59.758443: step 15364, loss 0.474866.
Train: 2018-08-01T00:52:59.930309: step 15365, loss 0.703017.
Train: 2018-08-01T00:53:00.086490: step 15366, loss 0.580206.
Train: 2018-08-01T00:53:00.258355: step 15367, loss 0.72031.
Train: 2018-08-01T00:53:00.414538: step 15368, loss 0.632465.
Train: 2018-08-01T00:53:00.555161: step 15369, loss 0.54515.
Train: 2018-08-01T00:53:00.711374: step 15370, loss 0.458481.
Test: 2018-08-01T00:53:01.195636: step 15370, loss 0.548042.
Train: 2018-08-01T00:53:01.351849: step 15371, loss 0.562569.
Train: 2018-08-01T00:53:01.508063: step 15372, loss 0.545241.
Train: 2018-08-01T00:53:01.664276: step 15373, loss 0.528022.
Train: 2018-08-01T00:53:01.820489: step 15374, loss 0.614295.
Train: 2018-08-01T00:53:01.976703: step 15375, loss 0.597032.
Train: 2018-08-01T00:53:02.148541: step 15376, loss 0.528134.
Train: 2018-08-01T00:53:02.304720: step 15377, loss 0.6141.
Train: 2018-08-01T00:53:02.476586: step 15378, loss 0.596849.
Train: 2018-08-01T00:53:02.632770: step 15379, loss 0.545357.
Train: 2018-08-01T00:53:02.789007: step 15380, loss 0.528287.
Test: 2018-08-01T00:53:03.257652: step 15380, loss 0.548211.
Train: 2018-08-01T00:53:03.413868: step 15381, loss 0.630878.
Train: 2018-08-01T00:53:03.570080: step 15382, loss 0.511354.
Train: 2018-08-01T00:53:03.726293: step 15383, loss 0.477285.
Train: 2018-08-01T00:53:03.898098: step 15384, loss 0.562517.
Train: 2018-08-01T00:53:04.054311: step 15385, loss 0.630792.
Train: 2018-08-01T00:53:04.210555: step 15386, loss 0.613696.
Train: 2018-08-01T00:53:04.382359: step 15387, loss 0.64763.
Train: 2018-08-01T00:53:04.522951: step 15388, loss 0.562447.
Train: 2018-08-01T00:53:04.679164: step 15389, loss 0.596619.
Train: 2018-08-01T00:53:04.835409: step 15390, loss 0.57845.
Test: 2018-08-01T00:53:05.304048: step 15390, loss 0.548911.
Train: 2018-08-01T00:53:05.475884: step 15391, loss 0.57936.
Train: 2018-08-01T00:53:05.632097: step 15392, loss 0.641048.
Train: 2018-08-01T00:53:05.803926: step 15393, loss 0.481259.
Train: 2018-08-01T00:53:05.960114: step 15394, loss 0.545906.
Train: 2018-08-01T00:53:06.100731: step 15395, loss 0.5318.
Train: 2018-08-01T00:53:06.256950: step 15396, loss 0.531112.
Train: 2018-08-01T00:53:06.413166: step 15397, loss 0.494329.
Train: 2018-08-01T00:53:06.584968: step 15398, loss 0.529868.
Train: 2018-08-01T00:53:06.741207: step 15399, loss 0.657941.
Train: 2018-08-01T00:53:06.897426: step 15400, loss 0.497216.
Test: 2018-08-01T00:53:07.381657: step 15400, loss 0.549466.
Train: 2018-08-01T00:53:08.131511: step 15401, loss 0.551975.
Train: 2018-08-01T00:53:08.287695: step 15402, loss 0.629125.
Train: 2018-08-01T00:53:08.443938: step 15403, loss 0.576763.
Train: 2018-08-01T00:53:08.600152: step 15404, loss 0.513288.
Train: 2018-08-01T00:53:08.756360: step 15405, loss 0.527383.
Train: 2018-08-01T00:53:08.912548: step 15406, loss 0.545549.
Train: 2018-08-01T00:53:09.068786: step 15407, loss 0.530539.
Train: 2018-08-01T00:53:09.225000: step 15408, loss 0.444021.
Train: 2018-08-01T00:53:09.381188: step 15409, loss 0.495286.
Train: 2018-08-01T00:53:09.537403: step 15410, loss 0.700925.
Test: 2018-08-01T00:53:10.006072: step 15410, loss 0.547993.
Train: 2018-08-01T00:53:10.162282: step 15411, loss 0.545241.
Train: 2018-08-01T00:53:10.318499: step 15412, loss 0.579978.
Train: 2018-08-01T00:53:10.490334: step 15413, loss 0.544968.
Train: 2018-08-01T00:53:10.646548: step 15414, loss 0.562338.
Train: 2018-08-01T00:53:10.802731: step 15415, loss 0.491748.
Train: 2018-08-01T00:53:10.958970: step 15416, loss 0.509078.
Train: 2018-08-01T00:53:11.115188: step 15417, loss 0.491602.
Train: 2018-08-01T00:53:11.271372: step 15418, loss 0.507966.
Train: 2018-08-01T00:53:11.443207: step 15419, loss 0.453469.
Train: 2018-08-01T00:53:11.583828: step 15420, loss 0.579142.
Test: 2018-08-01T00:53:12.068089: step 15420, loss 0.5477.
Train: 2018-08-01T00:53:12.224303: step 15421, loss 0.638537.
Train: 2018-08-01T00:53:12.380517: step 15422, loss 0.547537.
Train: 2018-08-01T00:53:12.536724: step 15423, loss 0.661785.
Train: 2018-08-01T00:53:12.692944: step 15424, loss 0.588692.
Train: 2018-08-01T00:53:12.849127: step 15425, loss 0.488979.
Train: 2018-08-01T00:53:13.020962: step 15426, loss 0.599418.
Train: 2018-08-01T00:53:13.177175: step 15427, loss 0.580086.
Train: 2018-08-01T00:53:13.333418: step 15428, loss 0.471826.
Train: 2018-08-01T00:53:13.489632: step 15429, loss 0.525804.
Train: 2018-08-01T00:53:13.645814: step 15430, loss 0.581352.
Test: 2018-08-01T00:53:14.114485: step 15430, loss 0.547669.
Train: 2018-08-01T00:53:14.286290: step 15431, loss 0.579426.
Train: 2018-08-01T00:53:14.442534: step 15432, loss 0.527078.
Train: 2018-08-01T00:53:14.598747: step 15433, loss 0.636839.
Train: 2018-08-01T00:53:14.754931: step 15434, loss 0.544884.
Train: 2018-08-01T00:53:14.911144: step 15435, loss 0.545716.
Train: 2018-08-01T00:53:15.067393: step 15436, loss 0.616235.
Train: 2018-08-01T00:53:15.223601: step 15437, loss 0.580728.
Train: 2018-08-01T00:53:15.395435: step 15438, loss 0.63384.
Train: 2018-08-01T00:53:15.551649: step 15439, loss 0.580482.
Train: 2018-08-01T00:53:15.707863: step 15440, loss 0.509751.
Test: 2018-08-01T00:53:16.176472: step 15440, loss 0.547853.
Train: 2018-08-01T00:53:16.332716: step 15441, loss 0.474463.
Train: 2018-08-01T00:53:16.504545: step 15442, loss 0.59721.
Train: 2018-08-01T00:53:16.660770: step 15443, loss 0.474677.
Train: 2018-08-01T00:53:16.816947: step 15444, loss 0.510543.
Train: 2018-08-01T00:53:16.973191: step 15445, loss 0.580422.
Train: 2018-08-01T00:53:17.129405: step 15446, loss 0.667563.
Train: 2018-08-01T00:53:17.285587: step 15447, loss 0.5628.
Train: 2018-08-01T00:53:17.457452: step 15448, loss 0.509356.
Train: 2018-08-01T00:53:17.629257: step 15449, loss 0.561898.
Train: 2018-08-01T00:53:17.785501: step 15450, loss 0.528859.
Test: 2018-08-01T00:53:18.254111: step 15450, loss 0.547979.
Train: 2018-08-01T00:53:18.410355: step 15451, loss 0.493492.
Train: 2018-08-01T00:53:18.566538: step 15452, loss 0.528813.
Train: 2018-08-01T00:53:18.738397: step 15453, loss 0.59774.
Train: 2018-08-01T00:53:18.910237: step 15454, loss 0.633917.
Train: 2018-08-01T00:53:19.050800: step 15455, loss 0.562653.
Train: 2018-08-01T00:53:19.222634: step 15456, loss 0.562698.
Train: 2018-08-01T00:53:19.378847: step 15457, loss 0.527211.
Train: 2018-08-01T00:53:19.535060: step 15458, loss 0.562592.
Train: 2018-08-01T00:53:19.691305: step 15459, loss 0.597866.
Train: 2018-08-01T00:53:19.863109: step 15460, loss 0.56258.
Test: 2018-08-01T00:53:20.331748: step 15460, loss 0.547817.
Train: 2018-08-01T00:53:20.487962: step 15461, loss 0.562551.
Train: 2018-08-01T00:53:20.644201: step 15462, loss 0.615358.
Train: 2018-08-01T00:53:20.816037: step 15463, loss 0.474678.
Train: 2018-08-01T00:53:20.972225: step 15464, loss 0.63286.
Train: 2018-08-01T00:53:21.128468: step 15465, loss 0.615185.
Train: 2018-08-01T00:53:21.300273: step 15466, loss 0.580064.
Train: 2018-08-01T00:53:21.456485: step 15467, loss 0.562524.
Train: 2018-08-01T00:53:21.612699: step 15468, loss 0.579965.
Train: 2018-08-01T00:53:21.768912: step 15469, loss 0.562509.
Train: 2018-08-01T00:53:21.940748: step 15470, loss 0.49297.
Test: 2018-08-01T00:53:22.409418: step 15470, loss 0.547955.
Train: 2018-08-01T00:53:22.565635: step 15471, loss 0.54513.
Train: 2018-08-01T00:53:22.737460: step 15472, loss 0.614588.
Train: 2018-08-01T00:53:22.893649: step 15473, loss 0.562497.
Train: 2018-08-01T00:53:23.049891: step 15474, loss 0.45855.
Train: 2018-08-01T00:53:23.206076: step 15475, loss 0.597158.
Train: 2018-08-01T00:53:23.362290: step 15476, loss 0.493177.
Train: 2018-08-01T00:53:23.518503: step 15477, loss 0.545153.
Train: 2018-08-01T00:53:23.690337: step 15478, loss 0.562498.
Train: 2018-08-01T00:53:23.846581: step 15479, loss 0.527754.
Train: 2018-08-01T00:53:24.002765: step 15480, loss 0.54511.
Test: 2018-08-01T00:53:24.471435: step 15480, loss 0.547924.
Train: 2018-08-01T00:53:24.627648: step 15481, loss 0.492848.
Train: 2018-08-01T00:53:24.783865: step 15482, loss 0.579963.
Train: 2018-08-01T00:53:24.940075: step 15483, loss 0.579995.
Train: 2018-08-01T00:53:25.111910: step 15484, loss 0.597512.
Train: 2018-08-01T00:53:25.283748: step 15485, loss 0.527521.
Train: 2018-08-01T00:53:25.455551: step 15486, loss 0.615076.
Train: 2018-08-01T00:53:25.611762: step 15487, loss 0.580042.
Train: 2018-08-01T00:53:25.767976: step 15488, loss 0.439965.
Train: 2018-08-01T00:53:25.924214: step 15489, loss 0.562531.
Train: 2018-08-01T00:53:26.080403: step 15490, loss 0.597635.
Test: 2018-08-01T00:53:26.549074: step 15490, loss 0.547836.
Train: 2018-08-01T00:53:26.705287: step 15491, loss 0.54498.
Train: 2018-08-01T00:53:26.861501: step 15492, loss 0.650373.
Train: 2018-08-01T00:53:27.017683: step 15493, loss 0.457215.
Train: 2018-08-01T00:53:27.173928: step 15494, loss 0.597668.
Train: 2018-08-01T00:53:27.330146: step 15495, loss 0.580104.
Train: 2018-08-01T00:53:27.501945: step 15496, loss 0.597658.
Train: 2018-08-01T00:53:27.658158: step 15497, loss 0.527436.
Train: 2018-08-01T00:53:27.830019: step 15498, loss 0.527445.
Train: 2018-08-01T00:53:27.986206: step 15499, loss 0.52744.
Train: 2018-08-01T00:53:28.126835: step 15500, loss 0.474764.
Test: 2018-08-01T00:53:28.611091: step 15500, loss 0.547817.
Train: 2018-08-01T00:53:29.314020: step 15501, loss 0.562539.
Train: 2018-08-01T00:53:29.470265: step 15502, loss 0.738589.
Train: 2018-08-01T00:53:29.657690: step 15503, loss 0.650452.
Train: 2018-08-01T00:53:29.813934: step 15504, loss 0.509901.
Train: 2018-08-01T00:53:29.970148: step 15505, loss 0.562517.
Train: 2018-08-01T00:53:30.126361: step 15506, loss 0.632475.
Train: 2018-08-01T00:53:30.282574: step 15507, loss 0.579952.
Train: 2018-08-01T00:53:30.438782: step 15508, loss 0.492848.
Train: 2018-08-01T00:53:30.595001: step 15509, loss 0.492927.
Train: 2018-08-01T00:53:30.766836: step 15510, loss 0.562486.
Test: 2018-08-01T00:53:31.235476: step 15510, loss 0.547927.
Train: 2018-08-01T00:53:31.391690: step 15511, loss 0.527706.
Train: 2018-08-01T00:53:31.563524: step 15512, loss 0.545204.
Train: 2018-08-01T00:53:31.719707: step 15513, loss 0.475508.
Train: 2018-08-01T00:53:31.891543: step 15514, loss 0.527647.
Train: 2018-08-01T00:53:32.032135: step 15515, loss 0.510159.
Train: 2018-08-01T00:53:32.188378: step 15516, loss 0.475034.
Train: 2018-08-01T00:53:32.344597: step 15517, loss 0.474751.
Train: 2018-08-01T00:53:32.500780: step 15518, loss 0.545218.
Train: 2018-08-01T00:53:32.657018: step 15519, loss 0.652009.
Train: 2018-08-01T00:53:32.828824: step 15520, loss 0.6691.
Test: 2018-08-01T00:53:33.313115: step 15520, loss 0.547743.
Train: 2018-08-01T00:53:33.469298: step 15521, loss 0.527156.
Train: 2018-08-01T00:53:33.625511: step 15522, loss 0.668973.
Train: 2018-08-01T00:53:33.797370: step 15523, loss 0.509438.
Train: 2018-08-01T00:53:33.953590: step 15524, loss 0.544869.
Train: 2018-08-01T00:53:34.125424: step 15525, loss 0.544874.
Train: 2018-08-01T00:53:34.281608: step 15526, loss 0.58029.
Train: 2018-08-01T00:53:34.453472: step 15527, loss 0.615694.
Train: 2018-08-01T00:53:34.609656: step 15528, loss 0.56257.
Train: 2018-08-01T00:53:34.765899: step 15529, loss 0.597906.
Train: 2018-08-01T00:53:34.922113: step 15530, loss 0.562541.
Test: 2018-08-01T00:53:35.390753: step 15530, loss 0.547799.
Train: 2018-08-01T00:53:35.546961: step 15531, loss 0.580186.
Train: 2018-08-01T00:53:35.718801: step 15532, loss 0.492293.
Train: 2018-08-01T00:53:35.875018: step 15533, loss 0.580113.
Train: 2018-08-01T00:53:36.031228: step 15534, loss 0.615222.
Train: 2018-08-01T00:53:36.187411: step 15535, loss 0.667746.
Train: 2018-08-01T00:53:36.359276: step 15536, loss 0.492563.
Train: 2018-08-01T00:53:36.515459: step 15537, loss 0.614877.
Train: 2018-08-01T00:53:36.687294: step 15538, loss 0.562497.
Train: 2018-08-01T00:53:36.843538: step 15539, loss 0.56249.
Train: 2018-08-01T00:53:36.999751: step 15540, loss 0.614527.
Test: 2018-08-01T00:53:37.468361: step 15540, loss 0.547991.
Train: 2018-08-01T00:53:37.624599: step 15541, loss 0.527873.
Train: 2018-08-01T00:53:37.780821: step 15542, loss 0.64884.
Train: 2018-08-01T00:53:37.937033: step 15543, loss 0.562474.
Train: 2018-08-01T00:53:38.093245: step 15544, loss 0.648368.
Train: 2018-08-01T00:53:38.265080: step 15545, loss 0.511117.
Train: 2018-08-01T00:53:38.421265: step 15546, loss 0.528322.
Train: 2018-08-01T00:53:38.577501: step 15547, loss 0.59657.
Train: 2018-08-01T00:53:38.733690: step 15548, loss 0.647543.
Train: 2018-08-01T00:53:38.889904: step 15549, loss 0.61337.
Train: 2018-08-01T00:53:39.046152: step 15550, loss 0.528686.
Test: 2018-08-01T00:53:39.530412: step 15550, loss 0.548384.
Train: 2018-08-01T00:53:39.686593: step 15551, loss 0.562503.
Train: 2018-08-01T00:53:39.842836: step 15552, loss 0.596159.
Train: 2018-08-01T00:53:40.014670: step 15553, loss 0.545739.
Train: 2018-08-01T00:53:40.170884: step 15554, loss 0.562531.
Train: 2018-08-01T00:53:40.327097: step 15555, loss 0.595986.
Train: 2018-08-01T00:53:40.483280: step 15556, loss 0.612626.
Train: 2018-08-01T00:53:40.655115: step 15557, loss 0.495951.
Train: 2018-08-01T00:53:40.795707: step 15558, loss 0.595841.
Train: 2018-08-01T00:53:40.967542: step 15559, loss 0.512736.
Train: 2018-08-01T00:53:41.123755: step 15560, loss 0.562579.
Test: 2018-08-01T00:53:41.592425: step 15560, loss 0.548676.
Train: 2018-08-01T00:53:41.764238: step 15561, loss 0.545975.
Train: 2018-08-01T00:53:41.920443: step 15562, loss 0.662226.
Train: 2018-08-01T00:53:42.076658: step 15563, loss 0.628937.
Train: 2018-08-01T00:53:42.248493: step 15564, loss 0.59571.
Train: 2018-08-01T00:53:42.404736: step 15565, loss 0.463509.
Train: 2018-08-01T00:53:42.560918: step 15566, loss 0.579133.
Train: 2018-08-01T00:53:42.717131: step 15567, loss 0.562624.
Train: 2018-08-01T00:53:42.888997: step 15568, loss 0.62863.
Train: 2018-08-01T00:53:43.045205: step 15569, loss 0.612083.
Train: 2018-08-01T00:53:43.201424: step 15570, loss 0.595561.
Test: 2018-08-01T00:53:43.685685: step 15570, loss 0.54891.
Train: 2018-08-01T00:53:43.841883: step 15571, loss 0.513387.
Train: 2018-08-01T00:53:44.013734: step 15572, loss 0.579085.
Train: 2018-08-01T00:53:44.169918: step 15573, loss 0.529877.
Train: 2018-08-01T00:53:44.326161: step 15574, loss 0.579079.
Train: 2018-08-01T00:53:44.482374: step 15575, loss 0.546282.
Train: 2018-08-01T00:53:44.638588: step 15576, loss 0.513472.
Train: 2018-08-01T00:53:44.794801: step 15577, loss 0.529825.
Train: 2018-08-01T00:53:44.951010: step 15578, loss 0.595546.
Train: 2018-08-01T00:53:45.122849: step 15579, loss 0.546173.
Train: 2018-08-01T00:53:45.279065: step 15580, loss 0.595607.
Test: 2018-08-01T00:53:45.763323: step 15580, loss 0.548798.
Train: 2018-08-01T00:53:45.919538: step 15581, loss 0.579124.
Train: 2018-08-01T00:53:46.091362: step 15582, loss 0.546097.
Train: 2018-08-01T00:53:46.231964: step 15583, loss 0.546072.
Train: 2018-08-01T00:53:46.388172: step 15584, loss 0.546041.
Train: 2018-08-01T00:53:46.544392: step 15585, loss 0.612318.
Train: 2018-08-01T00:53:46.716195: step 15586, loss 0.562577.
Train: 2018-08-01T00:53:46.872409: step 15587, loss 0.711996.
Train: 2018-08-01T00:53:47.028623: step 15588, loss 0.612317.
Train: 2018-08-01T00:53:47.184836: step 15589, loss 0.612234.
Train: 2018-08-01T00:53:47.341074: step 15590, loss 0.480083.
Test: 2018-08-01T00:53:47.809714: step 15590, loss 0.548808.
Train: 2018-08-01T00:53:47.965908: step 15591, loss 0.463645.
Train: 2018-08-01T00:53:48.122146: step 15592, loss 0.579077.
Train: 2018-08-01T00:53:48.293982: step 15593, loss 0.546303.
Train: 2018-08-01T00:53:48.450195: step 15594, loss 0.579208.
Train: 2018-08-01T00:53:48.606379: step 15595, loss 0.479531.
Train: 2018-08-01T00:53:48.762621: step 15596, loss 0.595734.
Train: 2018-08-01T00:53:48.918835: step 15597, loss 0.579453.
Train: 2018-08-01T00:53:49.075048: step 15598, loss 0.496157.
Train: 2018-08-01T00:53:49.231262: step 15599, loss 0.494828.
Train: 2018-08-01T00:53:49.403099: step 15600, loss 0.527891.
Test: 2018-08-01T00:53:49.887359: step 15600, loss 0.548148.
Train: 2018-08-01T00:53:50.650898: step 15601, loss 0.681262.
Train: 2018-08-01T00:53:50.807113: step 15602, loss 0.562688.
Train: 2018-08-01T00:53:50.963325: step 15603, loss 0.564817.
Train: 2018-08-01T00:53:51.119538: step 15604, loss 0.546385.
Train: 2018-08-01T00:53:51.275721: step 15605, loss 0.614517.
Train: 2018-08-01T00:53:51.431935: step 15606, loss 0.596453.
Train: 2018-08-01T00:53:51.603795: step 15607, loss 0.527306.
Train: 2018-08-01T00:53:51.759983: step 15608, loss 0.511744.
Train: 2018-08-01T00:53:51.916227: step 15609, loss 0.563033.
Train: 2018-08-01T00:53:52.072441: step 15610, loss 0.478218.
Test: 2018-08-01T00:53:52.541081: step 15610, loss 0.548217.
Train: 2018-08-01T00:53:52.728545: step 15611, loss 0.511654.
Train: 2018-08-01T00:53:52.884720: step 15612, loss 0.596595.
Train: 2018-08-01T00:53:53.040963: step 15613, loss 0.528532.
Train: 2018-08-01T00:53:53.197176: step 15614, loss 0.562098.
Train: 2018-08-01T00:53:53.353384: step 15615, loss 0.528087.
Train: 2018-08-01T00:53:53.525195: step 15616, loss 0.459579.
Train: 2018-08-01T00:53:53.681439: step 15617, loss 0.562477.
Train: 2018-08-01T00:53:53.837622: step 15618, loss 0.510502.
Train: 2018-08-01T00:53:53.993859: step 15619, loss 0.563026.
Train: 2018-08-01T00:53:54.150073: step 15620, loss 0.614746.
Test: 2018-08-01T00:53:54.618687: step 15620, loss 0.547863.
Train: 2018-08-01T00:53:54.774901: step 15621, loss 0.597841.
Train: 2018-08-01T00:53:54.946737: step 15622, loss 0.6672.
Train: 2018-08-01T00:53:55.102974: step 15623, loss 0.49275.
Train: 2018-08-01T00:53:55.259196: step 15624, loss 0.6498.
Train: 2018-08-01T00:53:55.415377: step 15625, loss 0.614644.
Train: 2018-08-01T00:53:55.571615: step 15626, loss 0.579822.
Train: 2018-08-01T00:53:55.727834: step 15627, loss 0.493138.
Train: 2018-08-01T00:53:55.884017: step 15628, loss 0.579776.
Train: 2018-08-01T00:53:56.040232: step 15629, loss 0.579761.
Train: 2018-08-01T00:53:56.196469: step 15630, loss 0.579746.
Test: 2018-08-01T00:53:56.680706: step 15630, loss 0.547984.
Train: 2018-08-01T00:53:56.836950: step 15631, loss 0.476073.
Train: 2018-08-01T00:53:56.993133: step 15632, loss 0.510612.
Train: 2018-08-01T00:53:57.149346: step 15633, loss 0.475976.
Train: 2018-08-01T00:53:57.321181: step 15634, loss 0.510467.
Train: 2018-08-01T00:53:57.477424: step 15635, loss 0.562461.
Train: 2018-08-01T00:53:57.633607: step 15636, loss 0.527648.
Train: 2018-08-01T00:53:57.789846: step 15637, loss 0.59738.
Train: 2018-08-01T00:53:57.946064: step 15638, loss 0.579963.
Train: 2018-08-01T00:53:58.102247: step 15639, loss 0.544988.
Train: 2018-08-01T00:53:58.289729: step 15640, loss 0.509929.
Test: 2018-08-01T00:53:58.758376: step 15640, loss 0.547804.
Train: 2018-08-01T00:53:58.914588: step 15641, loss 0.580054.
Train: 2018-08-01T00:53:59.086424: step 15642, loss 0.580082.
Train: 2018-08-01T00:53:59.242633: step 15643, loss 0.59769.
Train: 2018-08-01T00:53:59.414441: step 15644, loss 0.597697.
Train: 2018-08-01T00:53:59.570679: step 15645, loss 0.63285.
Train: 2018-08-01T00:53:59.726867: step 15646, loss 0.632746.
Train: 2018-08-01T00:53:59.883080: step 15647, loss 0.404803.
Train: 2018-08-01T00:54:00.054946: step 15648, loss 0.54497.
Train: 2018-08-01T00:54:00.195538: step 15649, loss 0.632593.
Train: 2018-08-01T00:54:00.367371: step 15650, loss 0.527467.
Test: 2018-08-01T00:54:00.836012: step 15650, loss 0.547828.
Train: 2018-08-01T00:54:00.992226: step 15651, loss 0.615.
Train: 2018-08-01T00:54:01.148440: step 15652, loss 0.562481.
Train: 2018-08-01T00:54:01.304649: step 15653, loss 0.510074.
Train: 2018-08-01T00:54:01.460868: step 15654, loss 0.597401.
Train: 2018-08-01T00:54:01.632703: step 15655, loss 0.475226.
Train: 2018-08-01T00:54:01.788916: step 15656, loss 0.614844.
Train: 2018-08-01T00:54:01.945131: step 15657, loss 0.475221.
Train: 2018-08-01T00:54:02.101316: step 15658, loss 0.510082.
Train: 2018-08-01T00:54:02.273145: step 15659, loss 0.492528.
Train: 2018-08-01T00:54:02.429360: step 15660, loss 0.615066.
Test: 2018-08-01T00:54:02.898030: step 15660, loss 0.547804.
Train: 2018-08-01T00:54:03.054244: step 15661, loss 0.509861.
Train: 2018-08-01T00:54:03.210426: step 15662, loss 0.509782.
Train: 2018-08-01T00:54:03.366641: step 15663, loss 0.615351.
Train: 2018-08-01T00:54:03.522853: step 15664, loss 0.615417.
Train: 2018-08-01T00:54:03.694688: step 15665, loss 0.527255.
Train: 2018-08-01T00:54:03.850926: step 15666, loss 0.562528.
Train: 2018-08-01T00:54:03.991523: step 15667, loss 0.562531.
Train: 2018-08-01T00:54:04.147737: step 15668, loss 0.597848.
Train: 2018-08-01T00:54:04.303920: step 15669, loss 0.527225.
Train: 2018-08-01T00:54:04.460164: step 15670, loss 0.491912.
Test: 2018-08-01T00:54:04.944427: step 15670, loss 0.547739.
Train: 2018-08-01T00:54:05.100639: step 15671, loss 0.562537.
Train: 2018-08-01T00:54:05.256847: step 15672, loss 0.527172.
Train: 2018-08-01T00:54:05.413037: step 15673, loss 0.509438.
Train: 2018-08-01T00:54:05.569280: step 15674, loss 0.562562.
Train: 2018-08-01T00:54:05.725493: step 15675, loss 0.473796.
Train: 2018-08-01T00:54:05.897323: step 15676, loss 0.580385.
Train: 2018-08-01T00:54:06.037920: step 15677, loss 0.651728.
Train: 2018-08-01T00:54:06.194103: step 15678, loss 0.437809.
Train: 2018-08-01T00:54:06.365938: step 15679, loss 0.616198.
Train: 2018-08-01T00:54:06.537772: step 15680, loss 0.544758.
Test: 2018-08-01T00:54:07.006446: step 15680, loss 0.54766.
Train: 2018-08-01T00:54:07.162656: step 15681, loss 0.508983.
Train: 2018-08-01T00:54:07.318870: step 15682, loss 0.598461.
Train: 2018-08-01T00:54:07.475077: step 15683, loss 0.473075.
Train: 2018-08-01T00:54:07.646888: step 15684, loss 0.580611.
Train: 2018-08-01T00:54:07.803102: step 15685, loss 0.688397.
Train: 2018-08-01T00:54:07.959343: step 15686, loss 0.652388.
Train: 2018-08-01T00:54:08.115570: step 15687, loss 0.544741.
Train: 2018-08-01T00:54:08.271771: step 15688, loss 0.598377.
Train: 2018-08-01T00:54:08.427955: step 15689, loss 0.633947.
Train: 2018-08-01T00:54:08.584199: step 15690, loss 0.633703.
Test: 2018-08-01T00:54:09.052808: step 15690, loss 0.547718.
Train: 2018-08-01T00:54:09.209046: step 15691, loss 0.66883.
Train: 2018-08-01T00:54:09.380881: step 15692, loss 0.509638.
Train: 2018-08-01T00:54:09.552721: step 15693, loss 0.632728.
Train: 2018-08-01T00:54:09.708936: step 15694, loss 0.510031.
Train: 2018-08-01T00:54:09.865119: step 15695, loss 0.5973.
Train: 2018-08-01T00:54:10.021362: step 15696, loss 0.475655.
Train: 2018-08-01T00:54:10.177575: step 15697, loss 0.510475.
Train: 2018-08-01T00:54:10.349381: step 15698, loss 0.527836.
Train: 2018-08-01T00:54:10.505593: step 15699, loss 0.579728.
Train: 2018-08-01T00:54:10.661806: step 15700, loss 0.631542.
Test: 2018-08-01T00:54:11.130479: step 15700, loss 0.547992.
Train: 2018-08-01T00:54:11.833438: step 15701, loss 0.545187.
Train: 2018-08-01T00:54:11.989651: step 15702, loss 0.45909.
Train: 2018-08-01T00:54:12.145834: step 15703, loss 0.545204.
Train: 2018-08-01T00:54:12.302078: step 15704, loss 0.596903.
Train: 2018-08-01T00:54:12.473882: step 15705, loss 0.596899.
Train: 2018-08-01T00:54:12.630095: step 15706, loss 0.493538.
Train: 2018-08-01T00:54:12.786339: step 15707, loss 0.614123.
Train: 2018-08-01T00:54:12.958169: step 15708, loss 0.510758.
Train: 2018-08-01T00:54:13.114357: step 15709, loss 0.5452.
Train: 2018-08-01T00:54:13.270571: step 15710, loss 0.545191.
Test: 2018-08-01T00:54:13.739211: step 15710, loss 0.547985.
Train: 2018-08-01T00:54:13.895456: step 15711, loss 0.683209.
Train: 2018-08-01T00:54:14.051668: step 15712, loss 0.614139.
Train: 2018-08-01T00:54:14.207852: step 15713, loss 0.614052.
Train: 2018-08-01T00:54:14.364065: step 15714, loss 0.407908.
Train: 2018-08-01T00:54:14.520278: step 15715, loss 0.545257.
Train: 2018-08-01T00:54:14.692112: step 15716, loss 0.665497.
Train: 2018-08-01T00:54:14.863948: step 15717, loss 0.493792.
Train: 2018-08-01T00:54:15.020191: step 15718, loss 0.579586.
Train: 2018-08-01T00:54:15.176374: step 15719, loss 0.493813.
Train: 2018-08-01T00:54:15.332587: step 15720, loss 0.579594.
Test: 2018-08-01T00:54:15.816879: step 15720, loss 0.548047.
Train: 2018-08-01T00:54:15.973062: step 15721, loss 0.716985.
Train: 2018-08-01T00:54:16.144927: step 15722, loss 0.596712.
Train: 2018-08-01T00:54:16.301141: step 15723, loss 0.682171.
Train: 2018-08-01T00:54:16.457355: step 15724, loss 0.545387.
Train: 2018-08-01T00:54:16.613537: step 15725, loss 0.664405.
Train: 2018-08-01T00:54:16.785374: step 15726, loss 0.596298.
Train: 2018-08-01T00:54:16.957237: step 15727, loss 0.478187.
Train: 2018-08-01T00:54:17.097830: step 15728, loss 0.596099.
Train: 2018-08-01T00:54:17.269634: step 15729, loss 0.713406.
Train: 2018-08-01T00:54:17.410257: step 15730, loss 0.512429.
Test: 2018-08-01T00:54:17.894519: step 15730, loss 0.548597.
Train: 2018-08-01T00:54:18.066322: step 15731, loss 0.479334.
Train: 2018-08-01T00:54:18.222567: step 15732, loss 0.562541.
Train: 2018-08-01T00:54:18.378750: step 15733, loss 0.61232.
Train: 2018-08-01T00:54:18.534963: step 15734, loss 0.512885.
Train: 2018-08-01T00:54:18.691206: step 15735, loss 0.496385.
Train: 2018-08-01T00:54:18.847390: step 15736, loss 0.546014.
Train: 2018-08-01T00:54:19.034845: step 15737, loss 0.562561.
Train: 2018-08-01T00:54:19.191090: step 15738, loss 0.645439.
Train: 2018-08-01T00:54:19.347273: step 15739, loss 0.595697.
Train: 2018-08-01T00:54:19.503487: step 15740, loss 0.645346.
Test: 2018-08-01T00:54:19.987748: step 15740, loss 0.548741.
Train: 2018-08-01T00:54:20.175229: step 15741, loss 0.47995.
Train: 2018-08-01T00:54:20.331448: step 15742, loss 0.579102.
Train: 2018-08-01T00:54:20.487660: step 15743, loss 0.562584.
Train: 2018-08-01T00:54:20.643874: step 15744, loss 0.46352.
Train: 2018-08-01T00:54:20.800088: step 15745, loss 0.479903.
Train: 2018-08-01T00:54:20.971923: step 15746, loss 0.695176.
Train: 2018-08-01T00:54:21.128105: step 15747, loss 0.512793.
Train: 2018-08-01T00:54:21.315562: step 15748, loss 0.62897.
Train: 2018-08-01T00:54:21.471803: step 15749, loss 0.496091.
Train: 2018-08-01T00:54:21.627989: step 15750, loss 0.678969.
Test: 2018-08-01T00:54:22.096629: step 15750, loss 0.548609.
Train: 2018-08-01T00:54:22.268493: step 15751, loss 0.728805.
Train: 2018-08-01T00:54:22.440323: step 15752, loss 0.62888.
Train: 2018-08-01T00:54:22.596542: step 15753, loss 0.496469.
Train: 2018-08-01T00:54:22.752758: step 15754, loss 0.628575.
Train: 2018-08-01T00:54:22.908969: step 15755, loss 0.546162.
Train: 2018-08-01T00:54:23.065183: step 15756, loss 0.447683.
Train: 2018-08-01T00:54:23.205775: step 15757, loss 0.529785.
Train: 2018-08-01T00:54:23.377604: step 15758, loss 0.529753.
Train: 2018-08-01T00:54:23.549415: step 15759, loss 0.595527.
Train: 2018-08-01T00:54:23.705627: step 15760, loss 0.529664.
Test: 2018-08-01T00:54:24.174268: step 15760, loss 0.548782.
Train: 2018-08-01T00:54:24.346133: step 15761, loss 0.59558.
Train: 2018-08-01T00:54:24.502353: step 15762, loss 0.562586.
Train: 2018-08-01T00:54:24.658529: step 15763, loss 0.595623.
Train: 2018-08-01T00:54:24.830364: step 15764, loss 0.546046.
Train: 2018-08-01T00:54:24.986602: step 15765, loss 0.529486.
Train: 2018-08-01T00:54:25.158413: step 15766, loss 0.645374.
Train: 2018-08-01T00:54:25.314626: step 15767, loss 0.595686.
Train: 2018-08-01T00:54:25.470840: step 15768, loss 0.529445.
Train: 2018-08-01T00:54:25.642674: step 15769, loss 0.430054.
Train: 2018-08-01T00:54:25.798887: step 15770, loss 0.562541.
Test: 2018-08-01T00:54:26.267559: step 15770, loss 0.548593.
Train: 2018-08-01T00:54:26.423771: step 15771, loss 0.545887.
Train: 2018-08-01T00:54:26.579954: step 15772, loss 0.62922.
Train: 2018-08-01T00:54:26.751788: step 15773, loss 0.562503.
Train: 2018-08-01T00:54:26.892412: step 15774, loss 0.495628.
Train: 2018-08-01T00:54:27.048595: step 15775, loss 0.579237.
Train: 2018-08-01T00:54:27.204807: step 15776, loss 0.512132.
Train: 2018-08-01T00:54:27.361045: step 15777, loss 0.562465.
Train: 2018-08-01T00:54:27.517265: step 15778, loss 0.562456.
Train: 2018-08-01T00:54:27.673448: step 15779, loss 0.57934.
Train: 2018-08-01T00:54:27.845282: step 15780, loss 0.59628.
Test: 2018-08-01T00:54:28.313923: step 15780, loss 0.548259.
Train: 2018-08-01T00:54:28.470136: step 15781, loss 0.511633.
Train: 2018-08-01T00:54:28.626349: step 15782, loss 0.426724.
Train: 2018-08-01T00:54:28.798209: step 15783, loss 0.630518.
Train: 2018-08-01T00:54:28.970046: step 15784, loss 0.579484.
Train: 2018-08-01T00:54:29.110644: step 15785, loss 0.528245.
Train: 2018-08-01T00:54:29.266861: step 15786, loss 0.545297.
Train: 2018-08-01T00:54:29.423074: step 15787, loss 0.596739.
Train: 2018-08-01T00:54:29.594898: step 15788, loss 0.476505.
Train: 2018-08-01T00:54:29.735495: step 15789, loss 0.527973.
Train: 2018-08-01T00:54:29.907336: step 15790, loss 0.666047.
Test: 2018-08-01T00:54:30.375972: step 15790, loss 0.547951.
Train: 2018-08-01T00:54:30.532184: step 15791, loss 0.510567.
Train: 2018-08-01T00:54:30.688367: step 15792, loss 0.579742.
Train: 2018-08-01T00:54:30.844611: step 15793, loss 0.562432.
Train: 2018-08-01T00:54:31.016440: step 15794, loss 0.527737.
Train: 2018-08-01T00:54:31.188286: step 15795, loss 0.631923.
Train: 2018-08-01T00:54:31.344463: step 15796, loss 0.614562.
Train: 2018-08-01T00:54:31.500708: step 15797, loss 0.545072.
Train: 2018-08-01T00:54:31.656921: step 15798, loss 0.475639.
Train: 2018-08-01T00:54:31.813134: step 15799, loss 0.562438.
Train: 2018-08-01T00:54:31.969347: step 15800, loss 0.56244.
Test: 2018-08-01T00:54:32.437957: step 15800, loss 0.547873.
Train: 2018-08-01T00:54:33.094084: step 15801, loss 0.510249.
Train: 2018-08-01T00:54:33.265914: step 15802, loss 0.63212.
Train: 2018-08-01T00:54:33.422132: step 15803, loss 0.614707.
Train: 2018-08-01T00:54:33.578345: step 15804, loss 0.562444.
Train: 2018-08-01T00:54:33.734559: step 15805, loss 0.579839.
Train: 2018-08-01T00:54:33.890772: step 15806, loss 0.423373.
Train: 2018-08-01T00:54:34.046980: step 15807, loss 0.614647.
Train: 2018-08-01T00:54:34.203199: step 15808, loss 0.597254.
Train: 2018-08-01T00:54:34.375023: step 15809, loss 0.579841.
Train: 2018-08-01T00:54:34.531248: step 15810, loss 0.475488.
Test: 2018-08-01T00:54:34.999890: step 15810, loss 0.54787.
Train: 2018-08-01T00:54:35.156096: step 15811, loss 0.597244.
Train: 2018-08-01T00:54:35.327936: step 15812, loss 0.510236.
Train: 2018-08-01T00:54:35.484144: step 15813, loss 0.510202.
Train: 2018-08-01T00:54:35.640334: step 15814, loss 0.632194.
Train: 2018-08-01T00:54:35.796571: step 15815, loss 0.597328.
Train: 2018-08-01T00:54:35.952784: step 15816, loss 0.562448.
Train: 2018-08-01T00:54:36.108973: step 15817, loss 0.719285.
Train: 2018-08-01T00:54:36.265187: step 15818, loss 0.597204.
Train: 2018-08-01T00:54:36.421400: step 15819, loss 0.56243.
Train: 2018-08-01T00:54:36.577652: step 15820, loss 0.631592.
Test: 2018-08-01T00:54:37.061904: step 15820, loss 0.547987.
Train: 2018-08-01T00:54:37.233742: step 15821, loss 0.700306.
Train: 2018-08-01T00:54:37.389953: step 15822, loss 0.528112.
Train: 2018-08-01T00:54:37.546167: step 15823, loss 0.528247.
Train: 2018-08-01T00:54:37.702349: step 15824, loss 0.511319.
Train: 2018-08-01T00:54:37.858562: step 15825, loss 0.647431.
Train: 2018-08-01T00:54:38.030398: step 15826, loss 0.528533.
Train: 2018-08-01T00:54:38.186611: step 15827, loss 0.630096.
Train: 2018-08-01T00:54:38.342854: step 15828, loss 0.461256.
Train: 2018-08-01T00:54:38.499038: step 15829, loss 0.579302.
Train: 2018-08-01T00:54:38.655252: step 15830, loss 0.528803.
Test: 2018-08-01T00:54:39.123923: step 15830, loss 0.548377.
Train: 2018-08-01T00:54:39.326969: step 15831, loss 0.61292.
Train: 2018-08-01T00:54:39.483214: step 15832, loss 0.528864.
Train: 2018-08-01T00:54:39.639427: step 15833, loss 0.512088.
Train: 2018-08-01T00:54:39.795645: step 15834, loss 0.545666.
Train: 2018-08-01T00:54:39.967445: step 15835, loss 0.612896.
Train: 2018-08-01T00:54:40.139310: step 15836, loss 0.512034.
Train: 2018-08-01T00:54:40.295522: step 15837, loss 0.56246.
Train: 2018-08-01T00:54:40.467328: step 15838, loss 0.528788.
Train: 2018-08-01T00:54:40.623540: step 15839, loss 0.59616.
Train: 2018-08-01T00:54:40.779784: step 15840, loss 0.562449.
Test: 2018-08-01T00:54:41.264045: step 15840, loss 0.548315.
Train: 2018-08-01T00:54:41.420260: step 15841, loss 0.562447.
Train: 2018-08-01T00:54:41.576473: step 15842, loss 0.562445.
Train: 2018-08-01T00:54:41.732681: step 15843, loss 0.47796.
Train: 2018-08-01T00:54:41.888900: step 15844, loss 0.511656.
Train: 2018-08-01T00:54:42.060731: step 15845, loss 0.528495.
Train: 2018-08-01T00:54:42.216956: step 15846, loss 0.579436.
Train: 2018-08-01T00:54:42.373132: step 15847, loss 0.494223.
Train: 2018-08-01T00:54:42.529374: step 15848, loss 0.528219.
Train: 2018-08-01T00:54:42.685582: step 15849, loss 0.631025.
Train: 2018-08-01T00:54:42.841796: step 15850, loss 0.631152.
Test: 2018-08-01T00:54:43.310410: step 15850, loss 0.548017.
Train: 2018-08-01T00:54:43.482278: step 15851, loss 0.510828.
Train: 2018-08-01T00:54:43.638491: step 15852, loss 0.579636.
Train: 2018-08-01T00:54:43.810294: step 15853, loss 0.63136.
Train: 2018-08-01T00:54:43.966507: step 15854, loss 0.562418.
Train: 2018-08-01T00:54:44.122721: step 15855, loss 0.562418.
Train: 2018-08-01T00:54:44.278935: step 15856, loss 0.493498.
Train: 2018-08-01T00:54:44.435148: step 15857, loss 0.545174.
Train: 2018-08-01T00:54:44.591392: step 15858, loss 0.579681.
Train: 2018-08-01T00:54:44.747607: step 15859, loss 0.614236.
Train: 2018-08-01T00:54:44.903819: step 15860, loss 0.666032.
Test: 2018-08-01T00:54:45.372460: step 15860, loss 0.54798.
Train: 2018-08-01T00:54:45.528672: step 15861, loss 0.476212.
Train: 2018-08-01T00:54:45.684855: step 15862, loss 0.493471.
Train: 2018-08-01T00:54:45.841099: step 15863, loss 0.64866.
Train: 2018-08-01T00:54:46.012903: step 15864, loss 0.64861.
Train: 2018-08-01T00:54:46.169116: step 15865, loss 0.49358.
Train: 2018-08-01T00:54:46.325361: step 15866, loss 0.734399.
Train: 2018-08-01T00:54:46.497166: step 15867, loss 0.61386.
Train: 2018-08-01T00:54:46.653379: step 15868, loss 0.562416.
Train: 2018-08-01T00:54:46.825213: step 15869, loss 0.54538.
Train: 2018-08-01T00:54:46.981428: step 15870, loss 0.545426.
Test: 2018-08-01T00:54:47.450097: step 15870, loss 0.548223.
Train: 2018-08-01T00:54:47.637524: step 15871, loss 0.545464.
Train: 2018-08-01T00:54:47.793736: step 15872, loss 0.545493.
Train: 2018-08-01T00:54:47.949949: step 15873, loss 0.562436.
Train: 2018-08-01T00:54:48.106188: step 15874, loss 0.579345.
Train: 2018-08-01T00:54:48.262412: step 15875, loss 0.477995.
Train: 2018-08-01T00:54:48.418591: step 15876, loss 0.579336.
Train: 2018-08-01T00:54:48.574804: step 15877, loss 0.528646.
Train: 2018-08-01T00:54:48.762260: step 15878, loss 0.54553.
Train: 2018-08-01T00:54:48.902852: step 15879, loss 0.647047.
Train: 2018-08-01T00:54:49.059095: step 15880, loss 0.596268.
Test: 2018-08-01T00:54:49.512114: step 15880, loss 0.548285.
Train: 2018-08-01T00:54:49.683949: step 15881, loss 0.545536.
Train: 2018-08-01T00:54:49.871376: step 15882, loss 0.528649.
Train: 2018-08-01T00:54:50.011967: step 15883, loss 0.444154.
Train: 2018-08-01T00:54:50.183801: step 15884, loss 0.528575.
Train: 2018-08-01T00:54:50.340015: step 15885, loss 0.44366.
Train: 2018-08-01T00:54:50.496229: step 15886, loss 0.579449.
Train: 2018-08-01T00:54:50.652443: step 15887, loss 0.613662.
Train: 2018-08-01T00:54:50.808697: step 15888, loss 0.579532.
Train: 2018-08-01T00:54:50.980520: step 15889, loss 0.545268.
Train: 2018-08-01T00:54:51.136734: step 15890, loss 0.528064.
Test: 2018-08-01T00:54:51.620996: step 15890, loss 0.548004.
Train: 2018-08-01T00:54:51.777178: step 15891, loss 0.493577.
Train: 2018-08-01T00:54:51.933417: step 15892, loss 0.458879.
Train: 2018-08-01T00:54:52.105259: step 15893, loss 0.545101.
Train: 2018-08-01T00:54:52.261464: step 15894, loss 0.579819.
Train: 2018-08-01T00:54:52.417684: step 15895, loss 0.457813.
Train: 2018-08-01T00:54:52.558276: step 15896, loss 0.56246.
Train: 2018-08-01T00:54:52.730113: step 15897, loss 0.474622.
Train: 2018-08-01T00:54:52.870705: step 15898, loss 0.597798.
Train: 2018-08-01T00:54:53.042534: step 15899, loss 0.615641.
Train: 2018-08-01T00:54:53.214380: step 15900, loss 0.527058.
Test: 2018-08-01T00:54:53.682982: step 15900, loss 0.547671.
Train: 2018-08-01T00:54:54.385942: step 15901, loss 0.45586.
Train: 2018-08-01T00:54:54.542156: step 15902, loss 0.580435.
Train: 2018-08-01T00:54:54.698400: step 15903, loss 0.652068.
Train: 2018-08-01T00:54:54.870204: step 15904, loss 0.490989.
Train: 2018-08-01T00:54:55.026417: step 15905, loss 0.59853.
Train: 2018-08-01T00:54:55.182661: step 15906, loss 0.562658.
Train: 2018-08-01T00:54:55.354465: step 15907, loss 0.58064.
Train: 2018-08-01T00:54:55.510710: step 15908, loss 0.490754.
Train: 2018-08-01T00:54:55.666924: step 15909, loss 0.526686.
Train: 2018-08-01T00:54:55.823136: step 15910, loss 0.616758.
Test: 2018-08-01T00:54:56.307369: step 15910, loss 0.547605.
Train: 2018-08-01T00:54:56.479203: step 15911, loss 0.688882.
Train: 2018-08-01T00:54:56.635446: step 15912, loss 0.652682.
Train: 2018-08-01T00:54:56.791659: step 15913, loss 0.508794.
Train: 2018-08-01T00:54:56.947873: step 15914, loss 0.580556.
Train: 2018-08-01T00:54:57.104056: step 15915, loss 0.526843.
Train: 2018-08-01T00:54:57.260294: step 15916, loss 0.580461.
Train: 2018-08-01T00:54:57.432138: step 15917, loss 0.544755.
Train: 2018-08-01T00:54:57.588317: step 15918, loss 0.580378.
Train: 2018-08-01T00:54:57.744531: step 15919, loss 0.509226.
Train: 2018-08-01T00:54:57.900774: step 15920, loss 0.633601.
Test: 2018-08-01T00:54:58.369417: step 15920, loss 0.54769.
Train: 2018-08-01T00:54:58.525633: step 15921, loss 0.544807.
Train: 2018-08-01T00:54:58.697464: step 15922, loss 0.58023.
Train: 2018-08-01T00:54:58.853679: step 15923, loss 0.47414.
Train: 2018-08-01T00:54:59.009884: step 15924, loss 0.633179.
Train: 2018-08-01T00:54:59.150483: step 15925, loss 0.562502.
Train: 2018-08-01T00:54:59.306696: step 15926, loss 0.597729.
Train: 2018-08-01T00:54:59.462910: step 15927, loss 0.50972.
Train: 2018-08-01T00:54:59.634715: step 15928, loss 0.527319.
Train: 2018-08-01T00:54:59.790927: step 15929, loss 0.527346.
Train: 2018-08-01T00:54:59.947171: step 15930, loss 0.597709.
Test: 2018-08-01T00:55:00.415780: step 15930, loss 0.547735.
Train: 2018-08-01T00:55:00.571994: step 15931, loss 0.579198.
Train: 2018-08-01T00:55:00.743860: step 15932, loss 0.544307.
Train: 2018-08-01T00:55:00.900042: step 15933, loss 0.56118.
Train: 2018-08-01T00:55:01.056256: step 15934, loss 0.510396.
Train: 2018-08-01T00:55:01.212507: step 15935, loss 0.490139.
Train: 2018-08-01T00:55:01.368682: step 15936, loss 0.524453.
Train: 2018-08-01T00:55:01.524926: step 15937, loss 0.623158.
Train: 2018-08-01T00:55:01.681134: step 15938, loss 0.658006.
Train: 2018-08-01T00:55:01.837352: step 15939, loss 0.526274.
Train: 2018-08-01T00:55:02.009183: step 15940, loss 0.597847.
Test: 2018-08-01T00:55:02.477830: step 15940, loss 0.547585.
Train: 2018-08-01T00:55:02.634012: step 15941, loss 0.544664.
Train: 2018-08-01T00:55:02.790255: step 15942, loss 0.455078.
Train: 2018-08-01T00:55:02.962091: step 15943, loss 0.599311.
Train: 2018-08-01T00:55:03.118305: step 15944, loss 0.56476.
Train: 2018-08-01T00:55:03.274517: step 15945, loss 0.561801.
Train: 2018-08-01T00:55:03.430699: step 15946, loss 0.526305.
Train: 2018-08-01T00:55:03.586944: step 15947, loss 0.561986.
Train: 2018-08-01T00:55:03.758778: step 15948, loss 0.685629.
Train: 2018-08-01T00:55:03.914962: step 15949, loss 0.56114.
Train: 2018-08-01T00:55:04.086822: step 15950, loss 0.562008.
Test: 2018-08-01T00:55:04.555466: step 15950, loss 0.547835.
Train: 2018-08-01T00:55:04.711680: step 15951, loss 0.52574.
Train: 2018-08-01T00:55:04.867895: step 15952, loss 0.544025.
Train: 2018-08-01T00:55:05.039698: step 15953, loss 0.544408.
Train: 2018-08-01T00:55:05.195948: step 15954, loss 0.494278.
Train: 2018-08-01T00:55:05.352154: step 15955, loss 0.579356.
Train: 2018-08-01T00:55:05.508368: step 15956, loss 0.442005.
Train: 2018-08-01T00:55:05.648961: step 15957, loss 0.492817.
Train: 2018-08-01T00:55:05.820764: step 15958, loss 0.546303.
Train: 2018-08-01T00:55:05.976978: step 15959, loss 0.492248.
Train: 2018-08-01T00:55:06.133222: step 15960, loss 0.492746.
Test: 2018-08-01T00:55:06.601862: step 15960, loss 0.547662.
Train: 2018-08-01T00:55:06.758076: step 15961, loss 0.527078.
Train: 2018-08-01T00:55:06.929914: step 15962, loss 0.563288.
Train: 2018-08-01T00:55:07.086118: step 15963, loss 0.582603.
Train: 2018-08-01T00:55:07.242345: step 15964, loss 0.581508.
Train: 2018-08-01T00:55:07.398520: step 15965, loss 0.544053.
Train: 2018-08-01T00:55:07.554735: step 15966, loss 0.562488.
Train: 2018-08-01T00:55:07.710948: step 15967, loss 0.615841.
Train: 2018-08-01T00:55:07.867192: step 15968, loss 0.616094.
Train: 2018-08-01T00:55:08.023374: step 15969, loss 0.598785.
Train: 2018-08-01T00:55:08.179587: step 15970, loss 0.509987.
Test: 2018-08-01T00:55:08.648253: step 15970, loss 0.54768.
Train: 2018-08-01T00:55:08.804471: step 15971, loss 0.526776.
Train: 2018-08-01T00:55:08.960685: step 15972, loss 0.474196.
Train: 2018-08-01T00:55:09.116892: step 15973, loss 0.420534.
Train: 2018-08-01T00:55:09.273112: step 15974, loss 0.491203.
Train: 2018-08-01T00:55:09.429294: step 15975, loss 0.527065.
Train: 2018-08-01T00:55:09.585509: step 15976, loss 0.652367.
Train: 2018-08-01T00:55:09.741754: step 15977, loss 0.472644.
Train: 2018-08-01T00:55:09.897935: step 15978, loss 0.52639.
Train: 2018-08-01T00:55:10.054173: step 15979, loss 0.562408.
Train: 2018-08-01T00:55:10.210363: step 15980, loss 0.525757.
Test: 2018-08-01T00:55:10.694653: step 15980, loss 0.547586.
Train: 2018-08-01T00:55:10.835217: step 15981, loss 0.489963.
Train: 2018-08-01T00:55:10.991461: step 15982, loss 0.544712.
Train: 2018-08-01T00:55:11.147672: step 15983, loss 0.61711.
Train: 2018-08-01T00:55:11.303880: step 15984, loss 0.564382.
Train: 2018-08-01T00:55:11.475715: step 15985, loss 0.600451.
Train: 2018-08-01T00:55:11.616283: step 15986, loss 0.488752.
Train: 2018-08-01T00:55:11.788148: step 15987, loss 0.599602.
Train: 2018-08-01T00:55:11.944361: step 15988, loss 0.526693.
Train: 2018-08-01T00:55:12.100577: step 15989, loss 0.598845.
Train: 2018-08-01T00:55:12.256782: step 15990, loss 0.544752.
Test: 2018-08-01T00:55:12.725428: step 15990, loss 0.547587.
Train: 2018-08-01T00:55:12.897265: step 15991, loss 0.561987.
Train: 2018-08-01T00:55:13.053477: step 15992, loss 0.748338.
Train: 2018-08-01T00:55:13.209659: step 15993, loss 0.507765.
Train: 2018-08-01T00:55:13.365898: step 15994, loss 0.544324.
Train: 2018-08-01T00:55:13.522117: step 15995, loss 0.526426.
Train: 2018-08-01T00:55:13.678300: step 15996, loss 0.599683.
Train: 2018-08-01T00:55:13.834514: step 15997, loss 0.508191.
Train: 2018-08-01T00:55:14.006348: step 15998, loss 0.617111.
Train: 2018-08-01T00:55:14.162592: step 15999, loss 0.707041.
Train: 2018-08-01T00:55:14.318774: step 16000, loss 0.508354.
Test: 2018-08-01T00:55:14.787445: step 16000, loss 0.547643.
Train: 2018-08-01T00:55:15.474755: step 16001, loss 0.61613.
Train: 2018-08-01T00:55:15.630999: step 16002, loss 0.562311.
Train: 2018-08-01T00:55:15.787181: step 16003, loss 0.580322.
Train: 2018-08-01T00:55:15.943395: step 16004, loss 0.579989.
Train: 2018-08-01T00:55:16.115255: step 16005, loss 0.580138.
Train: 2018-08-01T00:55:16.271472: step 16006, loss 0.50993.
Train: 2018-08-01T00:55:16.427656: step 16007, loss 0.562394.
Train: 2018-08-01T00:55:16.599523: step 16008, loss 0.510189.
Train: 2018-08-01T00:55:16.755704: step 16009, loss 0.579893.
Train: 2018-08-01T00:55:16.911948: step 16010, loss 0.562426.
Test: 2018-08-01T00:55:17.380559: step 16010, loss 0.547888.
Train: 2018-08-01T00:55:17.536802: step 16011, loss 0.614498.
Train: 2018-08-01T00:55:17.692985: step 16012, loss 0.562439.
Train: 2018-08-01T00:55:17.849198: step 16013, loss 0.562443.
Train: 2018-08-01T00:55:18.005412: step 16014, loss 0.614242.
Train: 2018-08-01T00:55:18.161625: step 16015, loss 0.631375.
Train: 2018-08-01T00:55:18.333461: step 16016, loss 0.596787.
Train: 2018-08-01T00:55:18.489705: step 16017, loss 0.613812.
Train: 2018-08-01T00:55:18.645920: step 16018, loss 0.698981.
Train: 2018-08-01T00:55:18.802101: step 16019, loss 0.698294.
Train: 2018-08-01T00:55:18.958343: step 16020, loss 0.494955.
Test: 2018-08-01T00:55:19.426955: step 16020, loss 0.548407.
Train: 2018-08-01T00:55:19.583166: step 16021, loss 0.596049.
Train: 2018-08-01T00:55:19.739380: step 16022, loss 0.562493.
Train: 2018-08-01T00:55:19.895624: step 16023, loss 0.629074.
Train: 2018-08-01T00:55:20.051832: step 16024, loss 0.562553.
Train: 2018-08-01T00:55:20.208052: step 16025, loss 0.628549.
Train: 2018-08-01T00:55:20.364266: step 16026, loss 0.496971.
Train: 2018-08-01T00:55:20.536107: step 16027, loss 0.529929.
Train: 2018-08-01T00:55:20.692307: step 16028, loss 0.579008.
Train: 2018-08-01T00:55:20.848529: step 16029, loss 0.611591.
Train: 2018-08-01T00:55:21.004740: step 16030, loss 0.660277.
Test: 2018-08-01T00:55:21.473350: step 16030, loss 0.549199.
Train: 2018-08-01T00:55:21.629563: step 16031, loss 0.59517.
Train: 2018-08-01T00:55:21.785776: step 16032, loss 0.498225.
Train: 2018-08-01T00:55:21.942022: step 16033, loss 0.627294.
Train: 2018-08-01T00:55:22.098230: step 16034, loss 0.530718.
Train: 2018-08-01T00:55:22.270067: step 16035, loss 0.659183.
Train: 2018-08-01T00:55:22.426281: step 16036, loss 0.514909.
Train: 2018-08-01T00:55:22.582489: step 16037, loss 0.515.
Train: 2018-08-01T00:55:22.738680: step 16038, loss 0.546974.
Train: 2018-08-01T00:55:22.894892: step 16039, loss 0.515005.
Train: 2018-08-01T00:55:23.066756: step 16040, loss 0.610931.
Test: 2018-08-01T00:55:23.535397: step 16040, loss 0.549516.
Train: 2018-08-01T00:55:23.707231: step 16041, loss 0.514895.
Train: 2018-08-01T00:55:23.879061: step 16042, loss 0.562901.
Train: 2018-08-01T00:55:24.035274: step 16043, loss 0.466533.
Train: 2018-08-01T00:55:24.175841: step 16044, loss 0.546728.
Train: 2018-08-01T00:55:24.332086: step 16045, loss 0.627438.
Train: 2018-08-01T00:55:24.488269: step 16046, loss 0.676136.
Train: 2018-08-01T00:55:24.644481: step 16047, loss 0.562763.
Train: 2018-08-01T00:55:24.800695: step 16048, loss 0.578966.
Train: 2018-08-01T00:55:24.972555: step 16049, loss 0.676258.
Train: 2018-08-01T00:55:25.128773: step 16050, loss 0.578962.
Test: 2018-08-01T00:55:25.597413: step 16050, loss 0.549236.
Train: 2018-08-01T00:55:25.784872: step 16051, loss 0.595133.
Train: 2018-08-01T00:55:25.941054: step 16052, loss 0.498185.
Train: 2018-08-01T00:55:26.112888: step 16053, loss 0.530493.
Train: 2018-08-01T00:55:26.269101: step 16054, loss 0.530463.
Train: 2018-08-01T00:55:26.425315: step 16055, loss 0.546589.
Train: 2018-08-01T00:55:26.597150: step 16056, loss 0.562755.
Train: 2018-08-01T00:55:26.753363: step 16057, loss 0.562735.
Train: 2018-08-01T00:55:26.893955: step 16058, loss 0.578981.
Train: 2018-08-01T00:55:27.065826: step 16059, loss 0.546412.
Train: 2018-08-01T00:55:27.237657: step 16060, loss 0.595313.
Test: 2018-08-01T00:55:27.706297: step 16060, loss 0.54899.
Train: 2018-08-01T00:55:27.862510: step 16061, loss 0.546334.
Train: 2018-08-01T00:55:28.018722: step 16062, loss 0.497218.
Train: 2018-08-01T00:55:28.174946: step 16063, loss 0.562629.
Train: 2018-08-01T00:55:28.346740: step 16064, loss 0.562607.
Train: 2018-08-01T00:55:28.502954: step 16065, loss 0.54611.
Train: 2018-08-01T00:55:28.659197: step 16066, loss 0.612113.
Train: 2018-08-01T00:55:28.815380: step 16067, loss 0.612178.
Train: 2018-08-01T00:55:28.971624: step 16068, loss 0.61221.
Train: 2018-08-01T00:55:29.143464: step 16069, loss 0.562546.
Train: 2018-08-01T00:55:29.299643: step 16070, loss 0.529428.
Test: 2018-08-01T00:55:29.768312: step 16070, loss 0.548663.
Train: 2018-08-01T00:55:29.924495: step 16071, loss 0.562539.
Train: 2018-08-01T00:55:30.080709: step 16072, loss 0.512779.
Train: 2018-08-01T00:55:30.236922: step 16073, loss 0.479468.
Train: 2018-08-01T00:55:30.408758: step 16074, loss 0.52919.
Train: 2018-08-01T00:55:30.549348: step 16075, loss 0.529069.
Train: 2018-08-01T00:55:30.705564: step 16076, loss 0.663044.
Train: 2018-08-01T00:55:30.861813: step 16077, loss 0.478509.
Train: 2018-08-01T00:55:31.018019: step 16078, loss 0.495105.
Train: 2018-08-01T00:55:31.174233: step 16079, loss 0.562433.
Train: 2018-08-01T00:55:31.330447: step 16080, loss 0.477686.
Test: 2018-08-01T00:55:31.814708: step 16080, loss 0.548164.
Train: 2018-08-01T00:55:31.970923: step 16081, loss 0.57943.
Train: 2018-08-01T00:55:32.142756: step 16082, loss 0.579484.
Train: 2018-08-01T00:55:32.298970: step 16083, loss 0.528158.
Train: 2018-08-01T00:55:32.455183: step 16084, loss 0.493699.
Train: 2018-08-01T00:55:32.611367: step 16085, loss 0.68309.
Train: 2018-08-01T00:55:32.767610: step 16086, loss 0.579679.
Train: 2018-08-01T00:55:32.939445: step 16087, loss 0.631569.
Train: 2018-08-01T00:55:33.080038: step 16088, loss 0.579704.
Train: 2018-08-01T00:55:33.236244: step 16089, loss 0.545124.
Train: 2018-08-01T00:55:33.408054: step 16090, loss 0.493253.
Test: 2018-08-01T00:55:33.876725: step 16090, loss 0.547922.
Train: 2018-08-01T00:55:34.032939: step 16091, loss 0.579721.
Train: 2018-08-01T00:55:34.189153: step 16092, loss 0.545098.
Train: 2018-08-01T00:55:34.345365: step 16093, loss 0.527755.
Train: 2018-08-01T00:55:34.501579: step 16094, loss 0.56242.
Train: 2018-08-01T00:55:34.657793: step 16095, loss 0.545055.
Train: 2018-08-01T00:55:34.813975: step 16096, loss 0.545039.
Train: 2018-08-01T00:55:34.970189: step 16097, loss 0.632057.
Train: 2018-08-01T00:55:35.126432: step 16098, loss 0.562429.
Train: 2018-08-01T00:55:35.298238: step 16099, loss 0.632062.
Train: 2018-08-01T00:55:35.470071: step 16100, loss 0.631991.
Test: 2018-08-01T00:55:35.954332: step 16100, loss 0.547885.
Train: 2018-08-01T00:55:36.641673: step 16101, loss 0.475628.
Train: 2018-08-01T00:55:36.797886: step 16102, loss 0.493023.
Train: 2018-08-01T00:55:36.969753: step 16103, loss 0.510351.
Train: 2018-08-01T00:55:37.125965: step 16104, loss 0.527674.
Train: 2018-08-01T00:55:37.282178: step 16105, loss 0.632024.
Train: 2018-08-01T00:55:37.438388: step 16106, loss 0.492815.
Train: 2018-08-01T00:55:37.594607: step 16107, loss 0.562432.
Train: 2018-08-01T00:55:37.750812: step 16108, loss 0.510116.
Train: 2018-08-01T00:55:37.907025: step 16109, loss 0.544975.
Train: 2018-08-01T00:55:38.063216: step 16110, loss 0.579942.
Test: 2018-08-01T00:55:38.547509: step 16110, loss 0.547788.
Train: 2018-08-01T00:55:38.703689: step 16111, loss 0.492401.
Train: 2018-08-01T00:55:38.859927: step 16112, loss 0.562463.
Train: 2018-08-01T00:55:39.016147: step 16113, loss 0.650341.
Train: 2018-08-01T00:55:39.187982: step 16114, loss 0.650359.
Train: 2018-08-01T00:55:39.344197: step 16115, loss 0.527349.
Train: 2018-08-01T00:55:39.500414: step 16116, loss 0.544915.
Train: 2018-08-01T00:55:39.656622: step 16117, loss 0.562462.
Train: 2018-08-01T00:55:39.812835: step 16118, loss 0.527388.
Train: 2018-08-01T00:55:39.984671: step 16119, loss 0.492312.
Train: 2018-08-01T00:55:40.125231: step 16120, loss 0.544912.
Test: 2018-08-01T00:55:40.609525: step 16120, loss 0.547757.
Train: 2018-08-01T00:55:40.765707: step 16121, loss 0.650323.
Train: 2018-08-01T00:55:40.937571: step 16122, loss 0.667855.
Train: 2018-08-01T00:55:41.093756: step 16123, loss 0.615058.
Train: 2018-08-01T00:55:41.249969: step 16124, loss 0.492483.
Train: 2018-08-01T00:55:41.421827: step 16125, loss 0.544973.
Train: 2018-08-01T00:55:41.578047: step 16126, loss 0.614793.
Train: 2018-08-01T00:55:41.749882: step 16127, loss 0.632125.
Train: 2018-08-01T00:55:41.906095: step 16128, loss 0.545043.
Train: 2018-08-01T00:55:42.062279: step 16129, loss 0.475693.
Train: 2018-08-01T00:55:42.218492: step 16130, loss 0.545083.
Test: 2018-08-01T00:55:42.702787: step 16130, loss 0.547907.
Train: 2018-08-01T00:55:42.858966: step 16131, loss 0.49311.
Train: 2018-08-01T00:55:43.030831: step 16132, loss 0.475737.
Train: 2018-08-01T00:55:43.187044: step 16133, loss 0.579785.
Train: 2018-08-01T00:55:43.343258: step 16134, loss 0.475497.
Train: 2018-08-01T00:55:43.499443: step 16135, loss 0.545007.
Train: 2018-08-01T00:55:43.655685: step 16136, loss 0.510053.
Train: 2018-08-01T00:55:43.811895: step 16137, loss 0.527435.
Train: 2018-08-01T00:55:43.968114: step 16138, loss 0.562465.
Train: 2018-08-01T00:55:44.124325: step 16139, loss 0.562479.
Train: 2018-08-01T00:55:44.280539: step 16140, loss 0.615398.
Test: 2018-08-01T00:55:44.749179: step 16140, loss 0.547715.
Train: 2018-08-01T00:55:44.905362: step 16141, loss 0.597808.
Train: 2018-08-01T00:55:45.061606: step 16142, loss 0.650811.
Train: 2018-08-01T00:55:45.217789: step 16143, loss 0.580142.
Train: 2018-08-01T00:55:45.374004: step 16144, loss 0.527235.
Train: 2018-08-01T00:55:45.514624: step 16145, loss 0.597716.
Train: 2018-08-01T00:55:45.686440: step 16146, loss 0.474496.
Train: 2018-08-01T00:55:45.842675: step 16147, loss 0.492087.
Train: 2018-08-01T00:55:46.014477: step 16148, loss 0.615328.
Train: 2018-08-01T00:55:46.170690: step 16149, loss 0.492022.
Train: 2018-08-01T00:55:46.326904: step 16150, loss 0.580122.
Test: 2018-08-01T00:55:46.795571: step 16150, loss 0.547722.
Train: 2018-08-01T00:55:46.951783: step 16151, loss 0.633056.
Train: 2018-08-01T00:55:47.108004: step 16152, loss 0.56249.
Train: 2018-08-01T00:55:47.264209: step 16153, loss 0.615346.
Train: 2018-08-01T00:55:47.436019: step 16154, loss 0.492091.
Train: 2018-08-01T00:55:47.592265: step 16155, loss 0.597658.
Train: 2018-08-01T00:55:47.748482: step 16156, loss 0.509743.
Train: 2018-08-01T00:55:47.920281: step 16157, loss 0.544897.
Train: 2018-08-01T00:55:48.076496: step 16158, loss 0.597619.
Train: 2018-08-01T00:55:48.232709: step 16159, loss 0.562468.
Train: 2018-08-01T00:55:48.388952: step 16160, loss 0.562465.
Test: 2018-08-01T00:55:48.857562: step 16160, loss 0.547769.
Train: 2018-08-01T00:55:49.029428: step 16161, loss 0.650193.
Train: 2018-08-01T00:55:49.170020: step 16162, loss 0.632516.
Train: 2018-08-01T00:55:49.341856: step 16163, loss 0.597382.
Train: 2018-08-01T00:55:49.498070: step 16164, loss 0.457907.
Train: 2018-08-01T00:55:49.654251: step 16165, loss 0.458029.
Train: 2018-08-01T00:55:49.810463: step 16166, loss 0.510213.
Train: 2018-08-01T00:55:49.966709: step 16167, loss 0.527588.
Train: 2018-08-01T00:55:50.138512: step 16168, loss 0.527549.
Train: 2018-08-01T00:55:50.294755: step 16169, loss 0.649792.
Train: 2018-08-01T00:55:50.450963: step 16170, loss 0.510023.
Test: 2018-08-01T00:55:50.919578: step 16170, loss 0.547802.
Train: 2018-08-01T00:55:51.075822: step 16171, loss 0.544958.
Train: 2018-08-01T00:55:51.232006: step 16172, loss 0.597454.
Train: 2018-08-01T00:55:51.388219: step 16173, loss 0.614972.
Train: 2018-08-01T00:55:51.544432: step 16174, loss 0.54495.
Train: 2018-08-01T00:55:51.700681: step 16175, loss 0.562447.
Train: 2018-08-01T00:55:51.872480: step 16176, loss 0.527471.
Train: 2018-08-01T00:55:52.044315: step 16177, loss 0.544957.
Train: 2018-08-01T00:55:52.200560: step 16178, loss 0.57994.
Train: 2018-08-01T00:55:52.372363: step 16179, loss 0.562447.
Train: 2018-08-01T00:55:52.528577: step 16180, loss 0.562446.
Test: 2018-08-01T00:55:53.012839: step 16180, loss 0.547801.
Train: 2018-08-01T00:55:53.169082: step 16181, loss 0.527469.
Train: 2018-08-01T00:55:53.325293: step 16182, loss 0.57994.
Train: 2018-08-01T00:55:53.497101: step 16183, loss 0.562446.
Train: 2018-08-01T00:55:53.653344: step 16184, loss 0.614917.
Train: 2018-08-01T00:55:53.809558: step 16185, loss 0.492541.
Train: 2018-08-01T00:55:53.965740: step 16186, loss 0.492533.
Train: 2018-08-01T00:55:54.121954: step 16187, loss 0.544952.
Train: 2018-08-01T00:55:54.278167: step 16188, loss 0.492399.
Train: 2018-08-01T00:55:54.465623: step 16189, loss 0.52737.
Train: 2018-08-01T00:55:54.621836: step 16190, loss 0.597635.
Test: 2018-08-01T00:55:55.090515: step 16190, loss 0.547738.
Train: 2018-08-01T00:55:55.246691: step 16191, loss 0.580084.
Train: 2018-08-01T00:55:55.402904: step 16192, loss 0.527246.
Train: 2018-08-01T00:55:55.574740: step 16193, loss 0.562492.
Train: 2018-08-01T00:55:55.730984: step 16194, loss 0.491872.
Train: 2018-08-01T00:55:55.887196: step 16195, loss 0.544824.
Train: 2018-08-01T00:55:56.043410: step 16196, loss 0.597955.
Train: 2018-08-01T00:55:56.199623: step 16197, loss 0.722126.
Train: 2018-08-01T00:55:56.371427: step 16198, loss 0.668772.
Train: 2018-08-01T00:55:56.527671: step 16199, loss 0.615481.
Train: 2018-08-01T00:55:56.699506: step 16200, loss 0.492068.
Test: 2018-08-01T00:55:57.168115: step 16200, loss 0.547758.
Train: 2018-08-01T00:55:57.902349: step 16201, loss 0.562467.
Train: 2018-08-01T00:55:58.058562: step 16202, loss 0.509861.
Train: 2018-08-01T00:55:58.230398: step 16203, loss 0.614988.
Train: 2018-08-01T00:55:58.386610: step 16204, loss 0.649849.
Train: 2018-08-01T00:55:58.542794: step 16205, loss 0.510138.
Train: 2018-08-01T00:55:58.699006: step 16206, loss 0.684211.
Train: 2018-08-01T00:55:58.870842: step 16207, loss 0.597092.
Train: 2018-08-01T00:55:59.011464: step 16208, loss 0.59696.
Train: 2018-08-01T00:55:59.167647: step 16209, loss 0.545193.
Train: 2018-08-01T00:55:59.323862: step 16210, loss 0.596716.
Test: 2018-08-01T00:55:59.792531: step 16210, loss 0.548085.
Train: 2018-08-01T00:55:59.979982: step 16211, loss 0.596603.
Train: 2018-08-01T00:56:00.136172: step 16212, loss 0.596487.
Train: 2018-08-01T00:56:00.292414: step 16213, loss 0.511481.
Train: 2018-08-01T00:56:00.464251: step 16214, loss 0.494679.
Train: 2018-08-01T00:56:00.620462: step 16215, loss 0.528596.
Train: 2018-08-01T00:56:00.776675: step 16216, loss 0.528618.
Train: 2018-08-01T00:56:00.932890: step 16217, loss 0.646952.
Train: 2018-08-01T00:56:01.104694: step 16218, loss 0.562431.
Train: 2018-08-01T00:56:01.245316: step 16219, loss 0.511829.
Train: 2018-08-01T00:56:01.417147: step 16220, loss 0.613035.
Test: 2018-08-01T00:56:01.885761: step 16220, loss 0.548325.
Train: 2018-08-01T00:56:02.041974: step 16221, loss 0.528731.
Train: 2018-08-01T00:56:02.213810: step 16222, loss 0.461333.
Train: 2018-08-01T00:56:02.370023: step 16223, loss 0.596182.
Train: 2018-08-01T00:56:02.526266: step 16224, loss 0.545542.
Train: 2018-08-01T00:56:02.682449: step 16225, loss 0.460993.
Train: 2018-08-01T00:56:02.838664: step 16226, loss 0.61326.
Train: 2018-08-01T00:56:02.994906: step 16227, loss 0.511499.
Train: 2018-08-01T00:56:03.166741: step 16228, loss 0.545403.
Train: 2018-08-01T00:56:03.338570: step 16229, loss 0.511272.
Train: 2018-08-01T00:56:03.494791: step 16230, loss 0.613677.
Test: 2018-08-01T00:56:03.963429: step 16230, loss 0.548067.
Train: 2018-08-01T00:56:04.119644: step 16231, loss 0.528162.
Train: 2018-08-01T00:56:04.275856: step 16232, loss 0.459472.
Train: 2018-08-01T00:56:04.447662: step 16233, loss 0.648458.
Train: 2018-08-01T00:56:04.603899: step 16234, loss 0.476202.
Train: 2018-08-01T00:56:04.760112: step 16235, loss 0.579696.
Train: 2018-08-01T00:56:04.916301: step 16236, loss 0.562413.
Train: 2018-08-01T00:56:05.072540: step 16237, loss 0.614494.
Train: 2018-08-01T00:56:05.228727: step 16238, loss 0.614548.
Train: 2018-08-01T00:56:05.384943: step 16239, loss 0.684067.
Train: 2018-08-01T00:56:05.556776: step 16240, loss 0.649168.
Test: 2018-08-01T00:56:06.025446: step 16240, loss 0.54792.
Train: 2018-08-01T00:56:06.197281: step 16241, loss 0.562411.
Train: 2018-08-01T00:56:06.353465: step 16242, loss 0.476095.
Train: 2018-08-01T00:56:06.509707: step 16243, loss 0.631385.
Train: 2018-08-01T00:56:06.681513: step 16244, loss 0.631253.
Train: 2018-08-01T00:56:06.822136: step 16245, loss 0.545236.
Train: 2018-08-01T00:56:06.978319: step 16246, loss 0.545273.
Train: 2018-08-01T00:56:07.134562: step 16247, loss 0.579503.
Train: 2018-08-01T00:56:07.306367: step 16248, loss 0.528266.
Train: 2018-08-01T00:56:07.462581: step 16249, loss 0.579457.
Train: 2018-08-01T00:56:07.634416: step 16250, loss 0.511318.
Test: 2018-08-01T00:56:08.118706: step 16250, loss 0.548153.
Train: 2018-08-01T00:56:08.274920: step 16251, loss 0.511336.
Train: 2018-08-01T00:56:08.431133: step 16252, loss 0.613504.
Train: 2018-08-01T00:56:08.587346: step 16253, loss 0.545382.
Train: 2018-08-01T00:56:08.743555: step 16254, loss 0.635055.
Train: 2018-08-01T00:56:08.899774: step 16255, loss 0.613438.
Train: 2018-08-01T00:56:09.055993: step 16256, loss 0.596377.
Train: 2018-08-01T00:56:09.227792: step 16257, loss 0.562419.
Train: 2018-08-01T00:56:09.384029: step 16258, loss 0.528582.
Train: 2018-08-01T00:56:09.540248: step 16259, loss 0.596234.
Train: 2018-08-01T00:56:09.696462: step 16260, loss 0.478025.
Test: 2018-08-01T00:56:10.180718: step 16260, loss 0.548294.
Train: 2018-08-01T00:56:10.336937: step 16261, loss 0.613079.
Train: 2018-08-01T00:56:10.493151: step 16262, loss 0.545561.
Train: 2018-08-01T00:56:10.649363: step 16263, loss 0.478094.
Train: 2018-08-01T00:56:10.805547: step 16264, loss 0.613087.
Train: 2018-08-01T00:56:10.977381: step 16265, loss 0.494869.
Train: 2018-08-01T00:56:11.133627: step 16266, loss 0.477867.
Train: 2018-08-01T00:56:11.289839: step 16267, loss 0.562418.
Train: 2018-08-01T00:56:11.446021: step 16268, loss 0.426496.
Train: 2018-08-01T00:56:11.602237: step 16269, loss 0.579462.
Train: 2018-08-01T00:56:11.774101: step 16270, loss 0.545289.
Test: 2018-08-01T00:56:12.258332: step 16270, loss 0.548025.
Train: 2018-08-01T00:56:12.398955: step 16271, loss 0.545233.
Train: 2018-08-01T00:56:12.570759: step 16272, loss 0.562403.
Train: 2018-08-01T00:56:12.711383: step 16273, loss 0.527865.
Train: 2018-08-01T00:56:12.867595: step 16274, loss 0.614378.
Train: 2018-08-01T00:56:13.023808: step 16275, loss 0.458285.
Train: 2018-08-01T00:56:13.211261: step 16276, loss 0.492789.
Train: 2018-08-01T00:56:13.367477: step 16277, loss 0.544966.
Train: 2018-08-01T00:56:13.523691: step 16278, loss 0.579991.
Train: 2018-08-01T00:56:13.695526: step 16279, loss 0.66798.
Train: 2018-08-01T00:56:13.851740: step 16280, loss 0.509668.
Test: 2018-08-01T00:56:14.320379: step 16280, loss 0.547724.
Train: 2018-08-01T00:56:14.476594: step 16281, loss 0.509595.
Train: 2018-08-01T00:56:14.632776: step 16282, loss 0.421167.
Train: 2018-08-01T00:56:14.789019: step 16283, loss 0.580258.
Train: 2018-08-01T00:56:14.945202: step 16284, loss 0.562551.
Train: 2018-08-01T00:56:15.101417: step 16285, loss 0.491269.
Train: 2018-08-01T00:56:15.257630: step 16286, loss 0.580481.
Train: 2018-08-01T00:56:15.413843: step 16287, loss 0.544702.
Train: 2018-08-01T00:56:15.570056: step 16288, loss 0.598574.
Train: 2018-08-01T00:56:15.726270: step 16289, loss 0.544677.
Train: 2018-08-01T00:56:15.882483: step 16290, loss 0.472621.
Test: 2018-08-01T00:56:16.351149: step 16290, loss 0.54759.
Train: 2018-08-01T00:56:16.507337: step 16291, loss 0.544655.
Train: 2018-08-01T00:56:16.741687: step 16292, loss 0.580821.
Train: 2018-08-01T00:56:16.897900: step 16293, loss 0.562751.
Train: 2018-08-01T00:56:17.054115: step 16294, loss 0.617174.
Train: 2018-08-01T00:56:17.210298: step 16295, loss 0.417656.
Train: 2018-08-01T00:56:17.366541: step 16296, loss 0.526449.
Train: 2018-08-01T00:56:17.538375: step 16297, loss 0.544614.
Train: 2018-08-01T00:56:17.694588: step 16298, loss 0.526369.
Train: 2018-08-01T00:56:17.850805: step 16299, loss 0.508057.
Train: 2018-08-01T00:56:18.007017: step 16300, loss 0.581219.
Test: 2018-08-01T00:56:18.491247: step 16300, loss 0.547575.
Train: 2018-08-01T00:56:19.209859: step 16301, loss 0.599611.
Train: 2018-08-01T00:56:19.366042: step 16302, loss 0.654705.
Train: 2018-08-01T00:56:19.522257: step 16303, loss 0.562932.
Train: 2018-08-01T00:56:19.709742: step 16304, loss 0.691189.
Train: 2018-08-01T00:56:19.865926: step 16305, loss 0.562879.
Train: 2018-08-01T00:56:20.022168: step 16306, loss 0.599307.
Train: 2018-08-01T00:56:20.193998: step 16307, loss 0.599161.
Train: 2018-08-01T00:56:20.350186: step 16308, loss 0.562756.
Train: 2018-08-01T00:56:20.506436: step 16309, loss 0.526583.
Train: 2018-08-01T00:56:20.662614: step 16310, loss 0.508621.
Test: 2018-08-01T00:56:21.146874: step 16310, loss 0.547601.
Train: 2018-08-01T00:56:21.303119: step 16311, loss 0.580658.
Train: 2018-08-01T00:56:21.459303: step 16312, loss 0.490817.
Train: 2018-08-01T00:56:21.631173: step 16313, loss 0.688217.
Train: 2018-08-01T00:56:21.787350: step 16314, loss 0.598396.
Train: 2018-08-01T00:56:21.959217: step 16315, loss 0.544739.
Train: 2018-08-01T00:56:22.099809: step 16316, loss 0.437984.
Train: 2018-08-01T00:56:22.271612: step 16317, loss 0.615898.
Train: 2018-08-01T00:56:22.412236: step 16318, loss 0.580294.
Train: 2018-08-01T00:56:22.568418: step 16319, loss 0.527073.
Train: 2018-08-01T00:56:22.740252: step 16320, loss 0.527106.
Test: 2018-08-01T00:56:23.208923: step 16320, loss 0.547695.
Train: 2018-08-01T00:56:23.365136: step 16321, loss 0.580204.
Train: 2018-08-01T00:56:23.521319: step 16322, loss 0.491799.
Train: 2018-08-01T00:56:23.693178: step 16323, loss 0.58018.
Train: 2018-08-01T00:56:23.849399: step 16324, loss 0.49182.
Train: 2018-08-01T00:56:24.005609: step 16325, loss 0.474105.
Train: 2018-08-01T00:56:24.161824: step 16326, loss 0.668764.
Train: 2018-08-01T00:56:24.318038: step 16327, loss 0.597929.
Train: 2018-08-01T00:56:24.474221: step 16328, loss 0.527122.
Train: 2018-08-01T00:56:24.630434: step 16329, loss 0.544819.
Train: 2018-08-01T00:56:24.786648: step 16330, loss 0.56251.
Test: 2018-08-01T00:56:25.270910: step 16330, loss 0.547697.
Train: 2018-08-01T00:56:25.442774: step 16331, loss 0.544821.
Train: 2018-08-01T00:56:25.614580: step 16332, loss 0.562509.
Train: 2018-08-01T00:56:25.770793: step 16333, loss 0.509449.
Train: 2018-08-01T00:56:25.927008: step 16334, loss 0.544816.
Train: 2018-08-01T00:56:26.083219: step 16335, loss 0.527103.
Train: 2018-08-01T00:56:26.255055: step 16336, loss 0.562523.
Train: 2018-08-01T00:56:26.426889: step 16337, loss 0.527057.
Train: 2018-08-01T00:56:26.583133: step 16338, loss 0.704572.
Train: 2018-08-01T00:56:26.739316: step 16339, loss 0.456115.
Train: 2018-08-01T00:56:26.895561: step 16340, loss 0.562532.
Test: 2018-08-01T00:56:27.364199: step 16340, loss 0.547673.
Train: 2018-08-01T00:56:27.520412: step 16341, loss 0.722243.
Train: 2018-08-01T00:56:27.676626: step 16342, loss 0.615648.
Train: 2018-08-01T00:56:27.832809: step 16343, loss 0.544835.
Train: 2018-08-01T00:56:27.989023: step 16344, loss 0.562484.
Train: 2018-08-01T00:56:28.145236: step 16345, loss 0.597648.
Train: 2018-08-01T00:56:28.301475: step 16346, loss 0.474731.
Train: 2018-08-01T00:56:28.488936: step 16347, loss 0.650086.
Train: 2018-08-01T00:56:28.645120: step 16348, loss 0.649882.
Train: 2018-08-01T00:56:28.801363: step 16349, loss 0.440411.
Train: 2018-08-01T00:56:28.957580: step 16350, loss 0.527608.
Test: 2018-08-01T00:56:29.426187: step 16350, loss 0.547856.
Train: 2018-08-01T00:56:29.598053: step 16351, loss 0.666794.
Train: 2018-08-01T00:56:29.769881: step 16352, loss 0.597132.
Train: 2018-08-01T00:56:29.926069: step 16353, loss 0.441201.
Train: 2018-08-01T00:56:30.082284: step 16354, loss 0.562409.
Train: 2018-08-01T00:56:30.238496: step 16355, loss 0.562408.
Train: 2018-08-01T00:56:30.394710: step 16356, loss 0.579695.
Train: 2018-08-01T00:56:30.550974: step 16357, loss 0.596956.
Train: 2018-08-01T00:56:30.722790: step 16358, loss 0.596915.
Train: 2018-08-01T00:56:30.879002: step 16359, loss 0.631318.
Train: 2018-08-01T00:56:31.035216: step 16360, loss 0.579589.
Test: 2018-08-01T00:56:31.519446: step 16360, loss 0.548041.
Train: 2018-08-01T00:56:31.691281: step 16361, loss 0.596696.
Train: 2018-08-01T00:56:31.847496: step 16362, loss 0.579505.
Train: 2018-08-01T00:56:32.019359: step 16363, loss 0.562404.
Train: 2018-08-01T00:56:32.175568: step 16364, loss 0.613465.
Train: 2018-08-01T00:56:32.331756: step 16365, loss 0.528471.
Train: 2018-08-01T00:56:32.503590: step 16366, loss 0.477731.
Train: 2018-08-01T00:56:32.659829: step 16367, loss 0.46085.
Train: 2018-08-01T00:56:32.847293: step 16368, loss 0.579363.
Train: 2018-08-01T00:56:33.003504: step 16369, loss 0.579373.
Train: 2018-08-01T00:56:33.159687: step 16370, loss 0.579379.
Test: 2018-08-01T00:56:33.628357: step 16370, loss 0.548206.
Train: 2018-08-01T00:56:33.784540: step 16371, loss 0.732091.
Train: 2018-08-01T00:56:33.956405: step 16372, loss 0.664.
Train: 2018-08-01T00:56:34.097000: step 16373, loss 0.579304.
Train: 2018-08-01T00:56:34.253211: step 16374, loss 0.528811.
Train: 2018-08-01T00:56:34.409424: step 16375, loss 0.562456.
Train: 2018-08-01T00:56:34.565638: step 16376, loss 0.528985.
Train: 2018-08-01T00:56:34.721846: step 16377, loss 0.662788.
Train: 2018-08-01T00:56:34.878066: step 16378, loss 0.579165.
Train: 2018-08-01T00:56:35.049900: step 16379, loss 0.512603.
Train: 2018-08-01T00:56:35.206108: step 16380, loss 0.628959.
Test: 2018-08-01T00:56:35.690344: step 16380, loss 0.548651.
Train: 2018-08-01T00:56:35.830967: step 16381, loss 0.512805.
Train: 2018-08-01T00:56:35.987176: step 16382, loss 0.579097.
Train: 2018-08-01T00:56:36.174631: step 16383, loss 0.579087.
Train: 2018-08-01T00:56:36.330819: step 16384, loss 0.546037.
Train: 2018-08-01T00:56:36.487061: step 16385, loss 0.579072.
Train: 2018-08-01T00:56:36.643246: step 16386, loss 0.562568.
Train: 2018-08-01T00:56:36.799459: step 16387, loss 0.463635.
Train: 2018-08-01T00:56:36.955706: step 16388, loss 0.612089.
Train: 2018-08-01T00:56:37.111926: step 16389, loss 0.562559.
Train: 2018-08-01T00:56:37.283722: step 16390, loss 0.595604.
Test: 2018-08-01T00:56:37.752391: step 16390, loss 0.548716.
Train: 2018-08-01T00:56:37.908575: step 16391, loss 0.612131.
Train: 2018-08-01T00:56:38.064789: step 16392, loss 0.513009.
Train: 2018-08-01T00:56:38.221003: step 16393, loss 0.612124.
Train: 2018-08-01T00:56:38.392862: step 16394, loss 0.446931.
Train: 2018-08-01T00:56:38.549080: step 16395, loss 0.645268.
Train: 2018-08-01T00:56:38.705289: step 16396, loss 0.430143.
Train: 2018-08-01T00:56:38.861508: step 16397, loss 0.562524.
Train: 2018-08-01T00:56:39.017720: step 16398, loss 0.496002.
Train: 2018-08-01T00:56:39.173935: step 16399, loss 0.54581.
Train: 2018-08-01T00:56:39.330137: step 16400, loss 0.595931.
Test: 2018-08-01T00:56:39.814379: step 16400, loss 0.548414.
Train: 2018-08-01T00:56:40.486098: step 16401, loss 0.512146.
Train: 2018-08-01T00:56:40.642340: step 16402, loss 0.528803.
Train: 2018-08-01T00:56:40.798554: step 16403, loss 0.579305.
Train: 2018-08-01T00:56:40.970384: step 16404, loss 0.427065.
Train: 2018-08-01T00:56:41.126572: step 16405, loss 0.42646.
Train: 2018-08-01T00:56:41.282815: step 16406, loss 0.579495.
Train: 2018-08-01T00:56:41.454619: step 16407, loss 0.510861.
Train: 2018-08-01T00:56:41.626454: step 16408, loss 0.510597.
Train: 2018-08-01T00:56:41.767077: step 16409, loss 0.51033.
Train: 2018-08-01T00:56:41.923260: step 16410, loss 0.597348.
Test: 2018-08-01T00:56:42.407552: step 16410, loss 0.547772.
Train: 2018-08-01T00:56:42.563765: step 16411, loss 0.579988.
Train: 2018-08-01T00:56:42.735600: step 16412, loss 0.580071.
Train: 2018-08-01T00:56:42.891814: step 16413, loss 0.633087.
Train: 2018-08-01T00:56:43.048028: step 16414, loss 0.562503.
Train: 2018-08-01T00:56:43.204211: step 16415, loss 0.580215.
Train: 2018-08-01T00:56:43.360424: step 16416, loss 0.527085.
Train: 2018-08-01T00:56:43.516637: step 16417, loss 0.544791.
Train: 2018-08-01T00:56:43.672875: step 16418, loss 0.562538.
Train: 2018-08-01T00:56:43.860331: step 16419, loss 0.686979.
Train: 2018-08-01T00:56:44.000899: step 16420, loss 0.615822.
Test: 2018-08-01T00:56:44.469570: step 16420, loss 0.547677.
Train: 2018-08-01T00:56:44.641404: step 16421, loss 0.615725.
Train: 2018-08-01T00:56:44.797625: step 16422, loss 0.527123.
Train: 2018-08-01T00:56:44.969446: step 16423, loss 0.544834.
Train: 2018-08-01T00:56:45.125659: step 16424, loss 0.56249.
Train: 2018-08-01T00:56:45.281850: step 16425, loss 0.5801.
Train: 2018-08-01T00:56:45.438062: step 16426, loss 0.54488.
Train: 2018-08-01T00:56:45.594307: step 16427, loss 0.597611.
Train: 2018-08-01T00:56:45.750519: step 16428, loss 0.685267.
Train: 2018-08-01T00:56:45.922356: step 16429, loss 0.544953.
Train: 2018-08-01T00:56:46.078538: step 16430, loss 0.440332.
Test: 2018-08-01T00:56:46.547208: step 16430, loss 0.547834.
Train: 2018-08-01T00:56:46.703390: step 16431, loss 0.492714.
Train: 2018-08-01T00:56:46.875226: step 16432, loss 0.667017.
Train: 2018-08-01T00:56:47.031440: step 16433, loss 0.510198.
Train: 2018-08-01T00:56:47.187652: step 16434, loss 0.597221.
Train: 2018-08-01T00:56:47.343865: step 16435, loss 0.492889.
Train: 2018-08-01T00:56:47.500079: step 16436, loss 0.510271.
Train: 2018-08-01T00:56:47.656322: step 16437, loss 0.562421.
Train: 2018-08-01T00:56:47.812536: step 16438, loss 0.579828.
Train: 2018-08-01T00:56:47.968751: step 16439, loss 0.562424.
Train: 2018-08-01T00:56:48.140579: step 16440, loss 0.492779.
Test: 2018-08-01T00:56:48.609224: step 16440, loss 0.547833.
Train: 2018-08-01T00:56:48.765438: step 16441, loss 0.51014.
Train: 2018-08-01T00:56:48.921653: step 16442, loss 0.475148.
Train: 2018-08-01T00:56:49.077834: step 16443, loss 0.579947.
Train: 2018-08-01T00:56:49.234079: step 16444, loss 0.720284.
Train: 2018-08-01T00:56:49.405908: step 16445, loss 0.527393.
Train: 2018-08-01T00:56:49.562096: step 16446, loss 0.527391.
Train: 2018-08-01T00:56:49.718342: step 16447, loss 0.509839.
Train: 2018-08-01T00:56:49.874559: step 16448, loss 0.544904.
Train: 2018-08-01T00:56:50.030768: step 16449, loss 0.615196.
Train: 2018-08-01T00:56:50.186975: step 16450, loss 0.474567.
Test: 2018-08-01T00:56:50.654070: step 16450, loss 0.547736.
Train: 2018-08-01T00:56:50.810253: step 16451, loss 0.562476.
Train: 2018-08-01T00:56:50.966497: step 16452, loss 0.562482.
Train: 2018-08-01T00:56:51.122711: step 16453, loss 0.562488.
Train: 2018-08-01T00:56:51.278924: step 16454, loss 0.544843.
Train: 2018-08-01T00:56:51.450729: step 16455, loss 0.527171.
Train: 2018-08-01T00:56:51.606975: step 16456, loss 0.580187.
Train: 2018-08-01T00:56:51.763186: step 16457, loss 0.633284.
Train: 2018-08-01T00:56:51.919399: step 16458, loss 0.597878.
Train: 2018-08-01T00:56:52.075616: step 16459, loss 0.474155.
Train: 2018-08-01T00:56:52.231827: step 16460, loss 0.562501.
Test: 2018-08-01T00:56:52.700467: step 16460, loss 0.547702.
Train: 2018-08-01T00:56:52.856674: step 16461, loss 0.721571.
Train: 2018-08-01T00:56:53.028484: step 16462, loss 0.491938.
Train: 2018-08-01T00:56:53.184728: step 16463, loss 0.650577.
Train: 2018-08-01T00:56:53.340942: step 16464, loss 0.474564.
Train: 2018-08-01T00:56:53.512776: step 16465, loss 0.492201.
Train: 2018-08-01T00:56:53.668991: step 16466, loss 0.615164.
Train: 2018-08-01T00:56:53.825204: step 16467, loss 0.597568.
Train: 2018-08-01T00:56:53.981386: step 16468, loss 0.615054.
Train: 2018-08-01T00:56:54.137630: step 16469, loss 0.544943.
Train: 2018-08-01T00:56:54.309459: step 16470, loss 0.579914.
Test: 2018-08-01T00:56:54.778076: step 16470, loss 0.547822.
Train: 2018-08-01T00:56:54.934319: step 16471, loss 0.579879.
Train: 2018-08-01T00:56:55.090532: step 16472, loss 0.632093.
Train: 2018-08-01T00:56:55.262368: step 16473, loss 0.666652.
Train: 2018-08-01T00:56:55.418580: step 16474, loss 0.458565.
Train: 2018-08-01T00:56:55.574796: step 16475, loss 0.545132.
Train: 2018-08-01T00:56:55.730977: step 16476, loss 0.614137.
Train: 2018-08-01T00:56:55.887226: step 16477, loss 0.579608.
Train: 2018-08-01T00:56:56.043434: step 16478, loss 0.545229.
Train: 2018-08-01T00:56:56.199647: step 16479, loss 0.51098.
Train: 2018-08-01T00:56:56.355860: step 16480, loss 0.682276.
Test: 2018-08-01T00:56:56.824501: step 16480, loss 0.548096.
Train: 2018-08-01T00:56:56.980685: step 16481, loss 0.562401.
Train: 2018-08-01T00:56:57.136928: step 16482, loss 0.630589.
Train: 2018-08-01T00:56:57.308732: step 16483, loss 0.528416.
Train: 2018-08-01T00:56:57.464946: step 16484, loss 0.664179.
Train: 2018-08-01T00:56:57.621194: step 16485, loss 0.596233.
Train: 2018-08-01T00:56:57.777372: step 16486, loss 0.495049.
Train: 2018-08-01T00:56:57.917995: step 16487, loss 0.579257.
Train: 2018-08-01T00:56:58.089801: step 16488, loss 0.562455.
Train: 2018-08-01T00:56:58.246038: step 16489, loss 0.545716.
Train: 2018-08-01T00:56:58.402261: step 16490, loss 0.696282.
Test: 2018-08-01T00:56:58.870896: step 16490, loss 0.548524.
Train: 2018-08-01T00:56:59.027080: step 16491, loss 0.529137.
Train: 2018-08-01T00:56:59.214536: step 16492, loss 0.662344.
Train: 2018-08-01T00:56:59.370779: step 16493, loss 0.54594.
Train: 2018-08-01T00:56:59.526994: step 16494, loss 0.496379.
Train: 2018-08-01T00:56:59.683206: step 16495, loss 0.595597.
Train: 2018-08-01T00:56:59.839419: step 16496, loss 0.645046.
Train: 2018-08-01T00:56:59.995627: step 16497, loss 0.628409.
Train: 2018-08-01T00:57:00.151816: step 16498, loss 0.562619.
Train: 2018-08-01T00:57:00.323651: step 16499, loss 0.595366.
Train: 2018-08-01T00:57:00.479890: step 16500, loss 0.530041.
Test: 2018-08-01T00:57:00.964156: step 16500, loss 0.549055.
Train: 2018-08-01T00:57:01.667117: step 16501, loss 0.562693.
Train: 2018-08-01T00:57:01.838921: step 16502, loss 0.51392.
Train: 2018-08-01T00:57:01.995170: step 16503, loss 0.513944.
Train: 2018-08-01T00:57:02.151378: step 16504, loss 0.644037.
Train: 2018-08-01T00:57:02.307563: step 16505, loss 0.546456.
Train: 2018-08-01T00:57:02.463777: step 16506, loss 0.546458.
Train: 2018-08-01T00:57:02.620018: step 16507, loss 0.497663.
Train: 2018-08-01T00:57:02.791854: step 16508, loss 0.481262.
Train: 2018-08-01T00:57:02.948037: step 16509, loss 0.53.
Train: 2018-08-01T00:57:03.104250: step 16510, loss 0.628162.
Test: 2018-08-01T00:57:03.572921: step 16510, loss 0.548866.
Train: 2018-08-01T00:57:03.729103: step 16511, loss 0.529781.
Train: 2018-08-01T00:57:03.885347: step 16512, loss 0.513225.
Train: 2018-08-01T00:57:04.041561: step 16513, loss 0.546058.
Train: 2018-08-01T00:57:04.197774: step 16514, loss 0.628764.
Train: 2018-08-01T00:57:04.353990: step 16515, loss 0.529347.
Train: 2018-08-01T00:57:04.525822: step 16516, loss 0.529254.
Train: 2018-08-01T00:57:04.682036: step 16517, loss 0.579161.
Train: 2018-08-01T00:57:04.838249: step 16518, loss 0.646021.
Train: 2018-08-01T00:57:05.010078: step 16519, loss 0.562471.
Train: 2018-08-01T00:57:05.181889: step 16520, loss 0.62942.
Test: 2018-08-01T00:57:05.650555: step 16520, loss 0.548452.
Train: 2018-08-01T00:57:05.838012: step 16521, loss 0.579204.
Train: 2018-08-01T00:57:05.994198: step 16522, loss 0.579201.
Train: 2018-08-01T00:57:06.150442: step 16523, loss 0.562471.
Train: 2018-08-01T00:57:06.306655: step 16524, loss 0.646077.
Train: 2018-08-01T00:57:06.462868: step 16525, loss 0.56248.
Train: 2018-08-01T00:57:06.619053: step 16526, loss 0.662557.
Train: 2018-08-01T00:57:06.790887: step 16527, loss 0.545865.
Train: 2018-08-01T00:57:06.947130: step 16528, loss 0.42966.
Train: 2018-08-01T00:57:07.118936: step 16529, loss 0.545899.
Train: 2018-08-01T00:57:07.275149: step 16530, loss 0.612385.
Test: 2018-08-01T00:57:07.743819: step 16530, loss 0.548586.
Train: 2018-08-01T00:57:07.915625: step 16531, loss 0.545882.
Train: 2018-08-01T00:57:08.071867: step 16532, loss 0.595769.
Train: 2018-08-01T00:57:08.228084: step 16533, loss 0.562506.
Train: 2018-08-01T00:57:08.384264: step 16534, loss 0.446089.
Train: 2018-08-01T00:57:08.540507: step 16535, loss 0.545832.
Train: 2018-08-01T00:57:08.696720: step 16536, loss 0.562481.
Train: 2018-08-01T00:57:08.852937: step 16537, loss 0.595923.
Train: 2018-08-01T00:57:09.009117: step 16538, loss 0.612707.
Train: 2018-08-01T00:57:09.165355: step 16539, loss 0.528948.
Train: 2018-08-01T00:57:09.321574: step 16540, loss 0.545682.
Test: 2018-08-01T00:57:09.805836: step 16540, loss 0.548387.
Train: 2018-08-01T00:57:09.962043: step 16541, loss 0.64642.
Train: 2018-08-01T00:57:10.133885: step 16542, loss 0.61283.
Train: 2018-08-01T00:57:10.290098: step 16543, loss 0.495327.
Train: 2018-08-01T00:57:10.446311: step 16544, loss 0.629605.
Train: 2018-08-01T00:57:10.602524: step 16545, loss 0.629572.
Train: 2018-08-01T00:57:10.758738: step 16546, loss 0.579217.
Train: 2018-08-01T00:57:10.914951: step 16547, loss 0.595933.
Train: 2018-08-01T00:57:11.071135: step 16548, loss 0.545773.
Train: 2018-08-01T00:57:11.243004: step 16549, loss 0.479062.
Train: 2018-08-01T00:57:11.399182: step 16550, loss 0.579172.
Test: 2018-08-01T00:57:11.867858: step 16550, loss 0.548507.
Train: 2018-08-01T00:57:12.024036: step 16551, loss 0.645931.
Train: 2018-08-01T00:57:12.180280: step 16552, loss 0.545818.
Train: 2018-08-01T00:57:12.352110: step 16553, loss 0.445866.
Train: 2018-08-01T00:57:12.508328: step 16554, loss 0.495759.
Train: 2018-08-01T00:57:12.664511: step 16555, loss 0.54464.
Train: 2018-08-01T00:57:12.836377: step 16556, loss 0.595974.
Train: 2018-08-01T00:57:12.992595: step 16557, loss 0.62959.
Train: 2018-08-01T00:57:13.148808: step 16558, loss 0.495272.
Train: 2018-08-01T00:57:13.304986: step 16559, loss 0.528801.
Train: 2018-08-01T00:57:13.476822: step 16560, loss 0.562434.
Test: 2018-08-01T00:57:13.945492: step 16560, loss 0.548289.
Train: 2018-08-01T00:57:14.101705: step 16561, loss 0.562427.
Train: 2018-08-01T00:57:14.257889: step 16562, loss 0.528597.
Train: 2018-08-01T00:57:14.414137: step 16563, loss 0.528522.
Train: 2018-08-01T00:57:14.601557: step 16564, loss 0.596384.
Train: 2018-08-01T00:57:14.757796: step 16565, loss 0.545391.
Train: 2018-08-01T00:57:14.913984: step 16566, loss 0.528313.
Train: 2018-08-01T00:57:15.070228: step 16567, loss 0.613643.
Train: 2018-08-01T00:57:15.226412: step 16568, loss 0.511098.
Train: 2018-08-01T00:57:15.382624: step 16569, loss 0.545268.
Train: 2018-08-01T00:57:15.538839: step 16570, loss 0.665376.
Test: 2018-08-01T00:57:16.023130: step 16570, loss 0.548024.
Train: 2018-08-01T00:57:16.179343: step 16571, loss 0.631065.
Train: 2018-08-01T00:57:16.335527: step 16572, loss 0.562399.
Train: 2018-08-01T00:57:16.491741: step 16573, loss 0.596683.
Train: 2018-08-01T00:57:16.663576: step 16574, loss 0.545276.
Train: 2018-08-01T00:57:16.835410: step 16575, loss 0.528178.
Train: 2018-08-01T00:57:16.991623: step 16576, loss 0.511076.
Train: 2018-08-01T00:57:17.147837: step 16577, loss 0.579517.
Train: 2018-08-01T00:57:17.304080: step 16578, loss 0.49391.
Train: 2018-08-01T00:57:17.460294: step 16579, loss 0.528112.
Train: 2018-08-01T00:57:17.632098: step 16580, loss 0.562399.
Test: 2018-08-01T00:57:18.100768: step 16580, loss 0.548001.
Train: 2018-08-01T00:57:18.256982: step 16581, loss 0.613982.
Train: 2018-08-01T00:57:18.413195: step 16582, loss 0.510788.
Train: 2018-08-01T00:57:18.569378: step 16583, loss 0.682972.
Train: 2018-08-01T00:57:18.725622: step 16584, loss 0.527971.
Train: 2018-08-01T00:57:18.897458: step 16585, loss 0.476335.
Train: 2018-08-01T00:57:19.053670: step 16586, loss 0.562401.
Train: 2018-08-01T00:57:19.209884: step 16587, loss 0.545153.
Train: 2018-08-01T00:57:19.366097: step 16588, loss 0.614208.
Train: 2018-08-01T00:57:19.522305: step 16589, loss 0.527858.
Train: 2018-08-01T00:57:19.678518: step 16590, loss 0.631543.
Test: 2018-08-01T00:57:20.162785: step 16590, loss 0.547935.
Train: 2018-08-01T00:57:20.318968: step 16591, loss 0.510569.
Train: 2018-08-01T00:57:20.475182: step 16592, loss 0.54512.
Train: 2018-08-01T00:57:20.631426: step 16593, loss 0.5797.
Train: 2018-08-01T00:57:20.787634: step 16594, loss 0.579705.
Train: 2018-08-01T00:57:20.943853: step 16595, loss 0.527811.
Train: 2018-08-01T00:57:21.100036: step 16596, loss 0.683539.
Train: 2018-08-01T00:57:21.256249: step 16597, loss 0.441433.
Train: 2018-08-01T00:57:21.412462: step 16598, loss 0.510537.
Train: 2018-08-01T00:57:21.568706: step 16599, loss 0.527791.
Train: 2018-08-01T00:57:21.724920: step 16600, loss 0.545078.
Test: 2018-08-01T00:57:22.193531: step 16600, loss 0.547878.
Train: 2018-08-01T00:57:22.912142: step 16601, loss 0.49298.
Train: 2018-08-01T00:57:23.068326: step 16602, loss 0.510229.
Train: 2018-08-01T00:57:23.224539: step 16603, loss 0.457767.
Train: 2018-08-01T00:57:23.412026: step 16604, loss 0.544937.
Train: 2018-08-01T00:57:23.568207: step 16605, loss 0.597607.
Train: 2018-08-01T00:57:23.724454: step 16606, loss 0.456773.
Train: 2018-08-01T00:57:23.880665: step 16607, loss 0.544822.
Train: 2018-08-01T00:57:24.036878: step 16608, loss 0.580273.
Train: 2018-08-01T00:57:24.193062: step 16609, loss 0.651514.
Train: 2018-08-01T00:57:24.349301: step 16610, loss 0.526936.
Test: 2018-08-01T00:57:24.817916: step 16610, loss 0.547638.
Train: 2018-08-01T00:57:24.989780: step 16611, loss 0.509059.
Train: 2018-08-01T00:57:25.145963: step 16612, loss 0.473232.
Train: 2018-08-01T00:57:25.317799: step 16613, loss 0.580541.
Train: 2018-08-01T00:57:25.474011: step 16614, loss 0.598557.
Train: 2018-08-01T00:57:25.630255: step 16615, loss 0.526697.
Train: 2018-08-01T00:57:25.802059: step 16616, loss 0.562673.
Train: 2018-08-01T00:57:25.942652: step 16617, loss 0.598738.
Train: 2018-08-01T00:57:26.114487: step 16618, loss 0.526624.
Train: 2018-08-01T00:57:26.286352: step 16619, loss 0.562699.
Train: 2018-08-01T00:57:26.442563: step 16620, loss 0.634922.
Test: 2018-08-01T00:57:26.911205: step 16620, loss 0.547589.
Train: 2018-08-01T00:57:27.083035: step 16621, loss 0.544655.
Train: 2018-08-01T00:57:27.239223: step 16622, loss 0.598758.
Train: 2018-08-01T00:57:27.395462: step 16623, loss 0.652749.
Train: 2018-08-01T00:57:27.551650: step 16624, loss 0.562653.
Train: 2018-08-01T00:57:27.723510: step 16625, loss 0.508825.
Train: 2018-08-01T00:57:27.879735: step 16626, loss 0.526795.
Train: 2018-08-01T00:57:28.035911: step 16627, loss 0.473142.
Train: 2018-08-01T00:57:28.192125: step 16628, loss 0.652085.
Train: 2018-08-01T00:57:28.348368: step 16629, loss 0.526844.
Train: 2018-08-01T00:57:28.520174: step 16630, loss 0.669771.
Test: 2018-08-01T00:57:28.988814: step 16630, loss 0.547642.
Train: 2018-08-01T00:57:29.145057: step 16631, loss 0.544743.
Train: 2018-08-01T00:57:29.301241: step 16632, loss 0.776082.
Train: 2018-08-01T00:57:29.457483: step 16633, loss 0.509374.
Train: 2018-08-01T00:57:29.613697: step 16634, loss 0.491879.
Train: 2018-08-01T00:57:29.769910: step 16635, loss 0.580091.
Train: 2018-08-01T00:57:29.957370: step 16636, loss 0.580036.
Train: 2018-08-01T00:57:30.113580: step 16637, loss 0.57998.
Train: 2018-08-01T00:57:30.269794: step 16638, loss 0.475015.
Train: 2018-08-01T00:57:30.441628: step 16639, loss 0.47511.
Train: 2018-08-01T00:57:30.597836: step 16640, loss 0.702165.
Test: 2018-08-01T00:57:31.066452: step 16640, loss 0.547829.
Train: 2018-08-01T00:57:31.222667: step 16641, loss 0.457824.
Train: 2018-08-01T00:57:31.378878: step 16642, loss 0.579855.
Train: 2018-08-01T00:57:31.535093: step 16643, loss 0.475331.
Train: 2018-08-01T00:57:31.691305: step 16644, loss 0.49271.
Train: 2018-08-01T00:57:31.847519: step 16645, loss 0.457706.
Train: 2018-08-01T00:57:32.003733: step 16646, loss 0.422441.
Train: 2018-08-01T00:57:32.159946: step 16647, loss 0.527319.
Train: 2018-08-01T00:57:32.331781: step 16648, loss 0.650716.
Train: 2018-08-01T00:57:32.472373: step 16649, loss 0.597883.
Train: 2018-08-01T00:57:32.644238: step 16650, loss 0.473931.
Test: 2018-08-01T00:57:33.112849: step 16650, loss 0.547664.
Train: 2018-08-01T00:57:33.269062: step 16651, loss 0.598063.
Train: 2018-08-01T00:57:33.425308: step 16652, loss 0.598138.
Train: 2018-08-01T00:57:33.581487: step 16653, loss 0.580371.
Train: 2018-08-01T00:57:33.737731: step 16654, loss 0.616024.
Train: 2018-08-01T00:57:33.893945: step 16655, loss 0.580376.
Train: 2018-08-01T00:57:34.050158: step 16656, loss 0.615964.
Train: 2018-08-01T00:57:34.221964: step 16657, loss 0.544768.
Train: 2018-08-01T00:57:34.378178: step 16658, loss 0.598053.
Train: 2018-08-01T00:57:34.534420: step 16659, loss 0.597985.
Train: 2018-08-01T00:57:34.690634: step 16660, loss 0.509423.
Test: 2018-08-01T00:57:35.159274: step 16660, loss 0.5477.
Train: 2018-08-01T00:57:35.315458: step 16661, loss 0.615525.
Train: 2018-08-01T00:57:35.471670: step 16662, loss 0.615414.
Train: 2018-08-01T00:57:35.627884: step 16663, loss 0.650468.
Train: 2018-08-01T00:57:35.784127: step 16664, loss 0.562454.
Train: 2018-08-01T00:57:35.940341: step 16665, loss 0.614888.
Train: 2018-08-01T00:57:36.096524: step 16666, loss 0.649523.
Train: 2018-08-01T00:57:36.252738: step 16667, loss 0.631778.
Train: 2018-08-01T00:57:36.424574: step 16668, loss 0.527892.
Train: 2018-08-01T00:57:36.580785: step 16669, loss 0.613951.
Train: 2018-08-01T00:57:36.737023: step 16670, loss 0.528182.
Test: 2018-08-01T00:57:37.205669: step 16670, loss 0.548127.
Train: 2018-08-01T00:57:37.361883: step 16671, loss 0.749937.
Train: 2018-08-01T00:57:37.549334: step 16672, loss 0.630217.
Train: 2018-08-01T00:57:37.705561: step 16673, loss 0.629823.
Train: 2018-08-01T00:57:37.861771: step 16674, loss 0.579204.
Train: 2018-08-01T00:57:38.017949: step 16675, loss 0.595778.
Train: 2018-08-01T00:57:38.174193: step 16676, loss 0.62871.
Train: 2018-08-01T00:57:38.330377: step 16677, loss 0.546157.
Train: 2018-08-01T00:57:38.486625: step 16678, loss 0.464518.
Train: 2018-08-01T00:57:38.689668: step 16679, loss 0.513763.
Train: 2018-08-01T00:57:38.845881: step 16680, loss 0.530148.
Test: 2018-08-01T00:57:39.330143: step 16680, loss 0.549095.
Train: 2018-08-01T00:57:39.486356: step 16681, loss 0.481413.
Train: 2018-08-01T00:57:39.642570: step 16682, loss 0.644045.
Train: 2018-08-01T00:57:39.830054: step 16683, loss 0.562711.
Train: 2018-08-01T00:57:39.986238: step 16684, loss 0.546462.
Train: 2018-08-01T00:57:40.142484: step 16685, loss 0.578968.
Train: 2018-08-01T00:57:40.314312: step 16686, loss 0.578968.
Train: 2018-08-01T00:57:40.470532: step 16687, loss 0.595222.
Train: 2018-08-01T00:57:40.626747: step 16688, loss 0.643957.
Train: 2018-08-01T00:57:40.798548: step 16689, loss 0.595185.
Train: 2018-08-01T00:57:40.954761: step 16690, loss 0.578953.
Test: 2018-08-01T00:57:41.439053: step 16690, loss 0.549228.
Train: 2018-08-01T00:57:41.595236: step 16691, loss 0.578947.
Train: 2018-08-01T00:57:41.751450: step 16692, loss 0.498182.
Train: 2018-08-01T00:57:41.907700: step 16693, loss 0.54664.
Train: 2018-08-01T00:57:42.063877: step 16694, loss 0.546629.
Train: 2018-08-01T00:57:42.220114: step 16695, loss 0.578946.
Train: 2018-08-01T00:57:42.376304: step 16696, loss 0.578949.
Train: 2018-08-01T00:57:42.516895: step 16697, loss 0.481814.
Train: 2018-08-01T00:57:42.673109: step 16698, loss 0.578959.
Train: 2018-08-01T00:57:42.829322: step 16699, loss 0.627709.
Train: 2018-08-01T00:57:43.001158: step 16700, loss 0.709036.
Test: 2018-08-01T00:57:43.485448: step 16700, loss 0.549134.
Train: 2018-08-01T00:57:44.204025: step 16701, loss 0.481556.
Train: 2018-08-01T00:57:44.360244: step 16702, loss 0.530254.
Train: 2018-08-01T00:57:44.516427: step 16703, loss 0.627713.
Train: 2018-08-01T00:57:44.672641: step 16704, loss 0.562719.
Train: 2018-08-01T00:57:44.828855: step 16705, loss 0.578966.
Train: 2018-08-01T00:57:44.985067: step 16706, loss 0.530224.
Train: 2018-08-01T00:57:45.141322: step 16707, loss 0.562711.
Train: 2018-08-01T00:57:45.313146: step 16708, loss 0.546432.
Train: 2018-08-01T00:57:45.484950: step 16709, loss 0.660423.
Train: 2018-08-01T00:57:45.641164: step 16710, loss 0.578977.
Test: 2018-08-01T00:57:46.109804: step 16710, loss 0.549067.
Train: 2018-08-01T00:57:46.297291: step 16711, loss 0.627808.
Train: 2018-08-01T00:57:46.453474: step 16712, loss 0.660262.
Train: 2018-08-01T00:57:46.609717: step 16713, loss 0.562738.
Train: 2018-08-01T00:57:46.765900: step 16714, loss 0.627516.
Train: 2018-08-01T00:57:46.922144: step 16715, loss 0.578941.
Train: 2018-08-01T00:57:47.078357: step 16716, loss 0.498391.
Train: 2018-08-01T00:57:47.234571: step 16717, loss 0.578931.
Train: 2018-08-01T00:57:47.390754: step 16718, loss 0.450294.
Train: 2018-08-01T00:57:47.562614: step 16719, loss 0.530637.
Train: 2018-08-01T00:57:47.718835: step 16720, loss 0.530556.
Test: 2018-08-01T00:57:48.187472: step 16720, loss 0.549245.
Train: 2018-08-01T00:57:48.343680: step 16721, loss 0.611273.
Train: 2018-08-01T00:57:48.531136: step 16722, loss 0.57895.
Train: 2018-08-01T00:57:48.687325: step 16723, loss 0.611374.
Train: 2018-08-01T00:57:48.843572: step 16724, loss 0.54652.
Train: 2018-08-01T00:57:48.999782: step 16725, loss 0.514024.
Train: 2018-08-01T00:57:49.155996: step 16726, loss 0.562707.
Train: 2018-08-01T00:57:49.312179: step 16727, loss 0.497514.
Train: 2018-08-01T00:57:49.468423: step 16728, loss 0.578996.
Train: 2018-08-01T00:57:49.640227: step 16729, loss 0.529878.
Train: 2018-08-01T00:57:49.796441: step 16730, loss 0.480489.
Test: 2018-08-01T00:57:50.280733: step 16730, loss 0.548765.
Train: 2018-08-01T00:57:50.436945: step 16731, loss 0.595546.
Train: 2018-08-01T00:57:50.593129: step 16732, loss 0.512929.
Train: 2018-08-01T00:57:50.780586: step 16733, loss 0.695312.
Train: 2018-08-01T00:57:50.936800: step 16734, loss 0.479393.
Train: 2018-08-01T00:57:51.093013: step 16735, loss 0.529159.
Train: 2018-08-01T00:57:51.233640: step 16736, loss 0.595903.
Train: 2018-08-01T00:57:51.389848: step 16737, loss 0.512206.
Train: 2018-08-01T00:57:51.546032: step 16738, loss 0.562447.
Train: 2018-08-01T00:57:51.702278: step 16739, loss 0.49507.
Train: 2018-08-01T00:57:51.874105: step 16740, loss 0.562424.
Test: 2018-08-01T00:57:52.358371: step 16740, loss 0.548222.
Train: 2018-08-01T00:57:52.514586: step 16741, loss 0.545466.
Train: 2018-08-01T00:57:52.670796: step 16742, loss 0.596406.
Train: 2018-08-01T00:57:52.826983: step 16743, loss 0.545365.
Train: 2018-08-01T00:57:52.998816: step 16744, loss 0.477017.
Train: 2018-08-01T00:57:53.155060: step 16745, loss 0.511002.
Train: 2018-08-01T00:57:53.326894: step 16746, loss 0.579592.
Train: 2018-08-01T00:57:53.483077: step 16747, loss 0.510663.
Train: 2018-08-01T00:57:53.639291: step 16748, loss 0.493189.
Train: 2018-08-01T00:57:53.795537: step 16749, loss 0.562416.
Train: 2018-08-01T00:57:53.967339: step 16750, loss 0.632162.
Test: 2018-08-01T00:57:54.435978: step 16750, loss 0.547805.
Train: 2018-08-01T00:57:54.607844: step 16751, loss 0.579907.
Train: 2018-08-01T00:57:54.764059: step 16752, loss 0.527442.
Train: 2018-08-01T00:57:54.920241: step 16753, loss 0.527385.
Train: 2018-08-01T00:57:55.092076: step 16754, loss 0.509752.
Train: 2018-08-01T00:57:55.248289: step 16755, loss 0.615321.
Train: 2018-08-01T00:57:55.404502: step 16756, loss 0.491926.
Train: 2018-08-01T00:57:55.560716: step 16757, loss 0.544823.
Train: 2018-08-01T00:57:55.716959: step 16758, loss 0.562517.
Train: 2018-08-01T00:57:55.873173: step 16759, loss 0.598024.
Train: 2018-08-01T00:57:56.029387: step 16760, loss 0.669128.
Test: 2018-08-01T00:57:56.513648: step 16760, loss 0.547667.
Train: 2018-08-01T00:57:56.685483: step 16761, loss 0.65131.
Train: 2018-08-01T00:57:56.841698: step 16762, loss 0.544797.
Train: 2018-08-01T00:57:56.997909: step 16763, loss 0.633304.
Train: 2018-08-01T00:57:57.154094: step 16764, loss 0.615466.
Train: 2018-08-01T00:57:57.325928: step 16765, loss 0.492047.
Train: 2018-08-01T00:57:57.482141: step 16766, loss 0.474584.
Train: 2018-08-01T00:57:57.622734: step 16767, loss 0.474624.
Train: 2018-08-01T00:57:57.794569: step 16768, loss 0.544887.
Train: 2018-08-01T00:57:57.950811: step 16769, loss 0.597654.
Train: 2018-08-01T00:57:58.107024: step 16770, loss 0.544877.
Test: 2018-08-01T00:57:58.575634: step 16770, loss 0.547736.
Train: 2018-08-01T00:57:58.731873: step 16771, loss 0.580071.
Train: 2018-08-01T00:57:58.903713: step 16772, loss 0.527277.
Train: 2018-08-01T00:57:59.059927: step 16773, loss 0.544871.
Train: 2018-08-01T00:57:59.216142: step 16774, loss 0.63292.
Train: 2018-08-01T00:57:59.372324: step 16775, loss 0.615273.
Train: 2018-08-01T00:57:59.544158: step 16776, loss 0.492158.
Train: 2018-08-01T00:57:59.700371: step 16777, loss 0.615176.
Train: 2018-08-01T00:57:59.856615: step 16778, loss 0.597562.
Train: 2018-08-01T00:58:00.012828: step 16779, loss 0.509872.
Train: 2018-08-01T00:58:00.169011: step 16780, loss 0.544933.
Test: 2018-08-01T00:58:00.668894: step 16780, loss 0.547786.
Train: 2018-08-01T00:58:00.825139: step 16781, loss 0.614959.
Train: 2018-08-01T00:58:00.981346: step 16782, loss 0.684826.
Train: 2018-08-01T00:58:01.137565: step 16783, loss 0.63217.
Train: 2018-08-01T00:58:01.293749: step 16784, loss 0.51029.
Train: 2018-08-01T00:58:01.449961: step 16785, loss 0.614406.
Train: 2018-08-01T00:58:01.606176: step 16786, loss 0.527842.
Train: 2018-08-01T00:58:01.778040: step 16787, loss 0.579643.
Train: 2018-08-01T00:58:01.934224: step 16788, loss 0.562398.
Train: 2018-08-01T00:58:02.090437: step 16789, loss 0.493725.
Train: 2018-08-01T00:58:02.246650: step 16790, loss 0.528093.
Test: 2018-08-01T00:58:02.715327: step 16790, loss 0.548039.
Train: 2018-08-01T00:58:02.871504: step 16791, loss 0.459517.
Train: 2018-08-01T00:58:03.027718: step 16792, loss 0.545232.
Train: 2018-08-01T00:58:03.183962: step 16793, loss 0.631147.
Train: 2018-08-01T00:58:03.340175: step 16794, loss 0.510828.
Train: 2018-08-01T00:58:03.496358: step 16795, loss 0.579603.
Train: 2018-08-01T00:58:03.652596: step 16796, loss 0.562399.
Train: 2018-08-01T00:58:03.824433: step 16797, loss 0.596842.
Train: 2018-08-01T00:58:03.980644: step 16798, loss 0.579619.
Train: 2018-08-01T00:58:04.136863: step 16799, loss 0.527969.
Train: 2018-08-01T00:58:04.293071: step 16800, loss 0.579617.
Test: 2018-08-01T00:58:04.761716: step 16800, loss 0.547982.
Train: 2018-08-01T00:58:05.433404: step 16801, loss 0.527966.
Train: 2018-08-01T00:58:05.589648: step 16802, loss 0.631292.
Train: 2018-08-01T00:58:05.761484: step 16803, loss 0.562399.
Train: 2018-08-01T00:58:05.917696: step 16804, loss 0.545195.
Train: 2018-08-01T00:58:06.089534: step 16805, loss 0.493605.
Train: 2018-08-01T00:58:06.245714: step 16806, loss 0.64845.
Train: 2018-08-01T00:58:06.401960: step 16807, loss 0.579599.
Train: 2018-08-01T00:58:06.558171: step 16808, loss 0.631147.
Train: 2018-08-01T00:58:06.714387: step 16809, loss 0.51092.
Train: 2018-08-01T00:58:06.870598: step 16810, loss 0.493814.
Test: 2018-08-01T00:58:07.339238: step 16810, loss 0.548036.
Train: 2018-08-01T00:58:07.495452: step 16811, loss 0.562398.
Train: 2018-08-01T00:58:07.667287: step 16812, loss 0.510934.
Train: 2018-08-01T00:58:07.823471: step 16813, loss 0.562398.
Train: 2018-08-01T00:58:07.995304: step 16814, loss 0.613952.
Train: 2018-08-01T00:58:08.151519: step 16815, loss 0.545212.
Train: 2018-08-01T00:58:08.323353: step 16816, loss 0.648347.
Train: 2018-08-01T00:58:08.479596: step 16817, loss 0.613918.
Train: 2018-08-01T00:58:08.635809: step 16818, loss 0.562398.
Train: 2018-08-01T00:58:08.791993: step 16819, loss 0.562398.
Train: 2018-08-01T00:58:08.948236: step 16820, loss 0.511099.
Test: 2018-08-01T00:58:09.416876: step 16820, loss 0.548086.
Train: 2018-08-01T00:58:09.573084: step 16821, loss 0.562399.
Train: 2018-08-01T00:58:09.729272: step 16822, loss 0.613658.
Train: 2018-08-01T00:58:09.885520: step 16823, loss 0.545332.
Train: 2018-08-01T00:58:10.041731: step 16824, loss 0.528288.
Train: 2018-08-01T00:58:10.197939: step 16825, loss 0.664731.
Train: 2018-08-01T00:58:10.354161: step 16826, loss 0.443201.
Train: 2018-08-01T00:58:10.525993: step 16827, loss 0.511299.
Train: 2018-08-01T00:58:10.682207: step 16828, loss 0.613559.
Train: 2018-08-01T00:58:10.838418: step 16829, loss 0.630627.
Train: 2018-08-01T00:58:10.994602: step 16830, loss 0.460138.
Test: 2018-08-01T00:58:11.463274: step 16830, loss 0.548117.
Train: 2018-08-01T00:58:11.635108: step 16831, loss 0.528286.
Train: 2018-08-01T00:58:11.791291: step 16832, loss 0.494086.
Train: 2018-08-01T00:58:11.947534: step 16833, loss 0.596626.
Train: 2018-08-01T00:58:12.119369: step 16834, loss 0.510985.
Train: 2018-08-01T00:58:12.275551: step 16835, loss 0.425028.
Train: 2018-08-01T00:58:12.431765: step 16836, loss 0.5624.
Train: 2018-08-01T00:58:12.588006: step 16837, loss 0.545114.
Train: 2018-08-01T00:58:12.744193: step 16838, loss 0.5971.
Train: 2018-08-01T00:58:12.900405: step 16839, loss 0.510263.
Train: 2018-08-01T00:58:13.056619: step 16840, loss 0.527561.
Test: 2018-08-01T00:58:13.540881: step 16840, loss 0.547798.
Train: 2018-08-01T00:58:13.712751: step 16841, loss 0.63237.
Train: 2018-08-01T00:58:13.853332: step 16842, loss 0.614978.
Train: 2018-08-01T00:58:14.025142: step 16843, loss 0.509881.
Train: 2018-08-01T00:58:14.181356: step 16844, loss 0.527367.
Train: 2018-08-01T00:58:14.337602: step 16845, loss 0.650316.
Train: 2018-08-01T00:58:14.493813: step 16846, loss 0.509745.
Train: 2018-08-01T00:58:14.650027: step 16847, loss 0.544882.
Train: 2018-08-01T00:58:14.837451: step 16848, loss 0.421673.
Train: 2018-08-01T00:58:14.993701: step 16849, loss 0.474268.
Train: 2018-08-01T00:58:15.149880: step 16850, loss 0.509404.
Test: 2018-08-01T00:58:15.618549: step 16850, loss 0.547662.
Train: 2018-08-01T00:58:15.774732: step 16851, loss 0.615836.
Train: 2018-08-01T00:58:15.946567: step 16852, loss 0.687219.
Train: 2018-08-01T00:58:16.087192: step 16853, loss 0.491298.
Train: 2018-08-01T00:58:16.243404: step 16854, loss 0.544737.
Train: 2018-08-01T00:58:16.399586: step 16855, loss 0.598304.
Train: 2018-08-01T00:58:16.555830: step 16856, loss 0.619767.
Train: 2018-08-01T00:58:16.774529: step 16857, loss 0.544726.
Train: 2018-08-01T00:58:16.930742: step 16858, loss 0.419737.
Train: 2018-08-01T00:58:17.102546: step 16859, loss 0.562598.
Train: 2018-08-01T00:58:17.258790: step 16860, loss 0.526803.
Test: 2018-08-01T00:58:17.727399: step 16860, loss 0.547612.
Train: 2018-08-01T00:58:17.899235: step 16861, loss 0.652265.
Train: 2018-08-01T00:58:18.055480: step 16862, loss 0.544696.
Train: 2018-08-01T00:58:18.227282: step 16863, loss 0.472977.
Train: 2018-08-01T00:58:18.383496: step 16864, loss 0.50879.
Train: 2018-08-01T00:58:18.539709: step 16865, loss 0.598605.
Train: 2018-08-01T00:58:18.680302: step 16866, loss 0.526682.
Train: 2018-08-01T00:58:18.852161: step 16867, loss 0.43662.
Train: 2018-08-01T00:58:19.008380: step 16868, loss 0.562701.
Train: 2018-08-01T00:58:19.164596: step 16869, loss 0.598894.
Train: 2018-08-01T00:58:19.336432: step 16870, loss 0.580845.
Test: 2018-08-01T00:58:19.820690: step 16870, loss 0.547577.
Train: 2018-08-01T00:58:19.976908: step 16871, loss 0.490281.
Train: 2018-08-01T00:58:20.133117: step 16872, loss 0.580905.
Train: 2018-08-01T00:58:20.289334: step 16873, loss 0.490158.
Train: 2018-08-01T00:58:20.461165: step 16874, loss 0.526435.
Train: 2018-08-01T00:58:20.617379: step 16875, loss 0.562818.
Train: 2018-08-01T00:58:20.773593: step 16876, loss 0.599298.
Train: 2018-08-01T00:58:20.929806: step 16877, loss 0.654042.
Train: 2018-08-01T00:58:21.086014: step 16878, loss 0.435262.
Train: 2018-08-01T00:58:21.242227: step 16879, loss 0.654013.
Train: 2018-08-01T00:58:21.414062: step 16880, loss 0.581049.
Test: 2018-08-01T00:58:21.882707: step 16880, loss 0.54757.
Train: 2018-08-01T00:58:22.054551: step 16881, loss 0.508208.
Train: 2018-08-01T00:58:22.210725: step 16882, loss 0.653767.
Train: 2018-08-01T00:58:22.351347: step 16883, loss 0.471976.
Train: 2018-08-01T00:58:22.523154: step 16884, loss 0.562772.
Train: 2018-08-01T00:58:22.679365: step 16885, loss 0.562763.
Train: 2018-08-01T00:58:22.835604: step 16886, loss 0.526507.
Train: 2018-08-01T00:58:22.991819: step 16887, loss 0.562746.
Train: 2018-08-01T00:58:23.148005: step 16888, loss 0.544635.
Train: 2018-08-01T00:58:23.319871: step 16889, loss 0.598924.
Train: 2018-08-01T00:58:23.460433: step 16890, loss 0.56272.
Test: 2018-08-01T00:58:23.944724: step 16890, loss 0.547585.
Train: 2018-08-01T00:58:24.116553: step 16891, loss 0.598823.
Train: 2018-08-01T00:58:24.272743: step 16892, loss 0.616777.
Train: 2018-08-01T00:58:24.428987: step 16893, loss 0.59864.
Train: 2018-08-01T00:58:24.585202: step 16894, loss 0.652344.
Train: 2018-08-01T00:58:24.757004: step 16895, loss 0.562595.
Train: 2018-08-01T00:58:24.897626: step 16896, loss 0.473482.
Train: 2018-08-01T00:58:25.069455: step 16897, loss 0.562545.
Train: 2018-08-01T00:58:25.210053: step 16898, loss 0.562529.
Train: 2018-08-01T00:58:25.381887: step 16899, loss 0.580227.
Train: 2018-08-01T00:58:25.538072: step 16900, loss 0.438766.
Test: 2018-08-01T00:58:26.006741: step 16900, loss 0.547701.
Train: 2018-08-01T00:58:26.694081: step 16901, loss 0.597841.
Train: 2018-08-01T00:58:26.865887: step 16902, loss 0.562493.
Train: 2018-08-01T00:58:27.022129: step 16903, loss 0.633057.
Train: 2018-08-01T00:58:27.178343: step 16904, loss 0.615311.
Train: 2018-08-01T00:58:27.334526: step 16905, loss 0.509752.
Train: 2018-08-01T00:58:27.506393: step 16906, loss 0.527367.
Train: 2018-08-01T00:58:27.662604: step 16907, loss 0.544923.
Train: 2018-08-01T00:58:27.818787: step 16908, loss 0.562446.
Train: 2018-08-01T00:58:27.975002: step 16909, loss 0.632454.
Train: 2018-08-01T00:58:28.131213: step 16910, loss 0.702232.
Test: 2018-08-01T00:58:28.615506: step 16910, loss 0.547839.
Train: 2018-08-01T00:58:28.771690: step 16911, loss 0.49276.
Train: 2018-08-01T00:58:28.943548: step 16912, loss 0.631928.
Train: 2018-08-01T00:58:29.115390: step 16913, loss 0.649045.
Train: 2018-08-01T00:58:29.271602: step 16914, loss 0.614184.
Train: 2018-08-01T00:58:29.427816: step 16915, loss 0.596774.
Train: 2018-08-01T00:58:29.584031: step 16916, loss 0.562398.
Train: 2018-08-01T00:58:29.755834: step 16917, loss 0.477156.
Train: 2018-08-01T00:58:29.912047: step 16918, loss 0.511374.
Train: 2018-08-01T00:58:30.068292: step 16919, loss 0.511443.
Train: 2018-08-01T00:58:30.240121: step 16920, loss 0.477504.
Test: 2018-08-01T00:58:30.693144: step 16920, loss 0.548175.
Train: 2018-08-01T00:58:30.864979: step 16921, loss 0.596398.
Train: 2018-08-01T00:58:31.005571: step 16922, loss 0.681412.
Train: 2018-08-01T00:58:31.177405: step 16923, loss 0.63032.
Train: 2018-08-01T00:58:31.364867: step 16924, loss 0.511592.
Train: 2018-08-01T00:58:31.521075: step 16925, loss 0.630103.
Train: 2018-08-01T00:58:31.692904: step 16926, loss 0.477987.
Train: 2018-08-01T00:58:31.849123: step 16927, loss 0.579306.
Train: 2018-08-01T00:58:32.005337: step 16928, loss 0.646766.
Train: 2018-08-01T00:58:32.161551: step 16929, loss 0.444572.
Train: 2018-08-01T00:58:32.317764: step 16930, loss 0.528754.
Test: 2018-08-01T00:58:32.786398: step 16930, loss 0.548321.
Train: 2018-08-01T00:58:32.942588: step 16931, loss 0.511876.
Train: 2018-08-01T00:58:33.083179: step 16932, loss 0.663683.
Train: 2018-08-01T00:58:33.239422: step 16933, loss 0.697417.
Train: 2018-08-01T00:58:33.395606: step 16934, loss 0.562436.
Train: 2018-08-01T00:58:33.567471: step 16935, loss 0.545632.
Train: 2018-08-01T00:58:33.723654: step 16936, loss 0.646399.
Train: 2018-08-01T00:58:33.895519: step 16937, loss 0.612716.
Train: 2018-08-01T00:58:34.051732: step 16938, loss 0.562475.
Train: 2018-08-01T00:58:34.207915: step 16939, loss 0.562489.
Train: 2018-08-01T00:58:34.364159: step 16940, loss 0.545869.
Test: 2018-08-01T00:58:34.832800: step 16940, loss 0.548605.
Train: 2018-08-01T00:58:35.004605: step 16941, loss 0.496077.
Train: 2018-08-01T00:58:35.160848: step 16942, loss 0.529305.
Train: 2018-08-01T00:58:35.317062: step 16943, loss 0.529291.
Train: 2018-08-01T00:58:35.473244: step 16944, loss 0.562506.
Train: 2018-08-01T00:58:35.629491: step 16945, loss 0.5625.
Train: 2018-08-01T00:58:35.816944: step 16946, loss 0.429241.
Train: 2018-08-01T00:58:35.973162: step 16947, loss 0.562476.
Train: 2018-08-01T00:58:36.129371: step 16948, loss 0.57921.
Train: 2018-08-01T00:58:36.285554: step 16949, loss 0.612808.
Train: 2018-08-01T00:58:36.441768: step 16950, loss 0.461593.
Test: 2018-08-01T00:58:36.910441: step 16950, loss 0.548319.
Train: 2018-08-01T00:58:37.066652: step 16951, loss 0.51187.
Train: 2018-08-01T00:58:37.238486: step 16952, loss 0.511696.
Train: 2018-08-01T00:58:37.394670: step 16953, loss 0.494531.
Train: 2018-08-01T00:58:37.550915: step 16954, loss 0.630571.
Train: 2018-08-01T00:58:37.707129: step 16955, loss 0.562399.
Train: 2018-08-01T00:58:37.863314: step 16956, loss 0.528126.
Train: 2018-08-01T00:58:38.019548: step 16957, loss 0.493661.
Train: 2018-08-01T00:58:38.175736: step 16958, loss 0.493426.
Train: 2018-08-01T00:58:38.347571: step 16959, loss 0.545094.
Train: 2018-08-01T00:58:38.503815: step 16960, loss 0.545037.
Test: 2018-08-01T00:58:38.988062: step 16960, loss 0.547823.
Train: 2018-08-01T00:58:39.128640: step 16961, loss 0.562428.
Train: 2018-08-01T00:58:39.300503: step 16962, loss 0.632432.
Train: 2018-08-01T00:58:39.456687: step 16963, loss 0.422207.
Train: 2018-08-01T00:58:39.612930: step 16964, loss 0.562469.
Train: 2018-08-01T00:58:39.769143: step 16965, loss 0.650711.
Train: 2018-08-01T00:58:39.925326: step 16966, loss 0.633181.
Train: 2018-08-01T00:58:40.081541: step 16967, loss 0.5625.
Train: 2018-08-01T00:58:40.237754: step 16968, loss 0.49178.
Train: 2018-08-01T00:58:40.393997: step 16969, loss 0.438621.
Train: 2018-08-01T00:58:40.550211: step 16970, loss 0.580268.
Test: 2018-08-01T00:58:41.018820: step 16970, loss 0.547659.
Train: 2018-08-01T00:58:41.253173: step 16971, loss 0.633636.
Train: 2018-08-01T00:58:41.409385: step 16972, loss 0.580332.
Train: 2018-08-01T00:58:41.565598: step 16973, loss 0.598127.
Train: 2018-08-01T00:58:41.721816: step 16974, loss 0.544764.
Train: 2018-08-01T00:58:41.878025: step 16975, loss 0.526987.
Train: 2018-08-01T00:58:42.034238: step 16976, loss 0.526982.
Train: 2018-08-01T00:58:42.206043: step 16977, loss 0.669296.
Train: 2018-08-01T00:58:42.377879: step 16978, loss 0.491451.
Train: 2018-08-01T00:58:42.534121: step 16979, loss 0.615853.
Train: 2018-08-01T00:58:42.690305: step 16980, loss 0.580288.
Test: 2018-08-01T00:58:43.158975: step 16980, loss 0.547674.
Train: 2018-08-01T00:58:43.330781: step 16981, loss 0.509321.
Train: 2018-08-01T00:58:43.502639: step 16982, loss 0.473888.
Train: 2018-08-01T00:58:43.643238: step 16983, loss 0.52705.
Train: 2018-08-01T00:58:43.815065: step 16984, loss 0.420497.
Train: 2018-08-01T00:58:43.971290: step 16985, loss 0.615954.
Train: 2018-08-01T00:58:44.127468: step 16986, loss 0.580395.
Train: 2018-08-01T00:58:44.283712: step 16987, loss 0.562577.
Train: 2018-08-01T00:58:44.439896: step 16988, loss 0.634019.
Train: 2018-08-01T00:58:44.611729: step 16989, loss 0.562582.
Train: 2018-08-01T00:58:44.767970: step 16990, loss 0.491195.
Test: 2018-08-01T00:58:45.236583: step 16990, loss 0.547632.
Train: 2018-08-01T00:58:45.392827: step 16991, loss 0.544729.
Train: 2018-08-01T00:58:45.564633: step 16992, loss 0.526863.
Train: 2018-08-01T00:58:45.720845: step 16993, loss 0.544719.
Train: 2018-08-01T00:58:45.861467: step 16994, loss 0.580492.
Train: 2018-08-01T00:58:46.017651: step 16995, loss 0.562605.
Train: 2018-08-01T00:58:46.173864: step 16996, loss 0.634207.
Train: 2018-08-01T00:58:46.330077: step 16997, loss 0.562599.
Train: 2018-08-01T00:58:46.501942: step 16998, loss 0.598327.
Train: 2018-08-01T00:58:46.658126: step 16999, loss 0.651797.
Train: 2018-08-01T00:58:46.814377: step 17000, loss 0.526956.
Test: 2018-08-01T00:58:47.282979: step 17000, loss 0.547662.
Train: 2018-08-01T00:58:48.235882: step 17001, loss 0.580304.
Train: 2018-08-01T00:58:48.423369: step 17002, loss 0.562522.
Train: 2018-08-01T00:58:48.579550: step 17003, loss 0.580201.
Train: 2018-08-01T00:58:48.735764: step 17004, loss 0.509521.
Train: 2018-08-01T00:58:48.907598: step 17005, loss 0.615388.
Train: 2018-08-01T00:58:49.063812: step 17006, loss 0.580073.
Train: 2018-08-01T00:58:49.204437: step 17007, loss 0.580025.
Train: 2018-08-01T00:58:49.376275: step 17008, loss 0.439762.
Train: 2018-08-01T00:58:49.532453: step 17009, loss 0.650047.
Train: 2018-08-01T00:58:49.688666: step 17010, loss 0.614918.
Test: 2018-08-01T00:58:50.157336: step 17010, loss 0.547815.
Train: 2018-08-01T00:58:50.313549: step 17011, loss 0.492612.
Train: 2018-08-01T00:58:50.469732: step 17012, loss 0.579863.
Train: 2018-08-01T00:58:50.625946: step 17013, loss 0.545008.
Train: 2018-08-01T00:58:50.782184: step 17014, loss 0.562419.
Train: 2018-08-01T00:58:50.938373: step 17015, loss 0.684091.
Train: 2018-08-01T00:58:51.125829: step 17016, loss 0.545071.
Train: 2018-08-01T00:58:51.282073: step 17017, loss 0.475886.
Train: 2018-08-01T00:58:51.438257: step 17018, loss 0.52782.
Train: 2018-08-01T00:58:51.594499: step 17019, loss 0.493248.
Train: 2018-08-01T00:58:51.750716: step 17020, loss 0.545103.
Test: 2018-08-01T00:58:52.234974: step 17020, loss 0.547906.
Train: 2018-08-01T00:58:52.391158: step 17021, loss 0.562407.
Train: 2018-08-01T00:58:52.547371: step 17022, loss 0.59707.
Train: 2018-08-01T00:58:52.703617: step 17023, loss 0.614411.
Train: 2018-08-01T00:58:52.859829: step 17024, loss 0.527759.
Train: 2018-08-01T00:58:53.016011: step 17025, loss 0.510438.
Train: 2018-08-01T00:58:53.172262: step 17026, loss 0.527741.
Train: 2018-08-01T00:58:53.344094: step 17027, loss 0.458306.
Train: 2018-08-01T00:58:53.500303: step 17028, loss 0.545028.
Train: 2018-08-01T00:58:53.656517: step 17029, loss 0.492711.
Train: 2018-08-01T00:58:53.812730: step 17030, loss 0.544958.
Test: 2018-08-01T00:58:54.281340: step 17030, loss 0.547772.
Train: 2018-08-01T00:58:54.437588: step 17031, loss 0.579976.
Train: 2018-08-01T00:58:54.593802: step 17032, loss 0.615156.
Train: 2018-08-01T00:58:54.750006: step 17033, loss 0.544881.
Train: 2018-08-01T00:58:54.906224: step 17034, loss 0.632904.
Train: 2018-08-01T00:58:55.062407: step 17035, loss 0.492038.
Train: 2018-08-01T00:58:55.218651: step 17036, loss 0.544855.
Train: 2018-08-01T00:58:55.390456: step 17037, loss 0.58013.
Train: 2018-08-01T00:58:55.546694: step 17038, loss 0.597797.
Train: 2018-08-01T00:58:55.702916: step 17039, loss 0.527186.
Train: 2018-08-01T00:58:55.859121: step 17040, loss 0.491859.
Test: 2018-08-01T00:58:56.343387: step 17040, loss 0.547697.
Train: 2018-08-01T00:58:56.499571: step 17041, loss 0.544822.
Train: 2018-08-01T00:58:56.655814: step 17042, loss 0.580209.
Train: 2018-08-01T00:58:56.812028: step 17043, loss 0.562515.
Train: 2018-08-01T00:58:56.968210: step 17044, loss 0.562519.
Train: 2018-08-01T00:58:57.124448: step 17045, loss 0.615709.
Train: 2018-08-01T00:58:57.280638: step 17046, loss 0.70429.
Train: 2018-08-01T00:58:57.436851: step 17047, loss 0.562501.
Train: 2018-08-01T00:58:57.624307: step 17048, loss 0.544845.
Train: 2018-08-01T00:58:57.780520: step 17049, loss 0.738569.
Train: 2018-08-01T00:58:57.921143: step 17050, loss 0.59753.
Test: 2018-08-01T00:58:58.405398: step 17050, loss 0.547808.
Train: 2018-08-01T00:58:58.577209: step 17051, loss 0.61483.
Train: 2018-08-01T00:58:58.733422: step 17052, loss 0.666736.
Train: 2018-08-01T00:58:58.889637: step 17053, loss 0.545113.
Train: 2018-08-01T00:58:59.045850: step 17054, loss 0.614021.
Train: 2018-08-01T00:58:59.202062: step 17055, loss 0.579518.
Train: 2018-08-01T00:58:59.358276: step 17056, loss 0.562402.
Train: 2018-08-01T00:58:59.514520: step 17057, loss 0.409723.
Train: 2018-08-01T00:58:59.670728: step 17058, loss 0.545479.
Train: 2018-08-01T00:58:59.842538: step 17059, loss 0.545504.
Train: 2018-08-01T00:58:59.983130: step 17060, loss 0.477919.
Test: 2018-08-01T00:59:00.467421: step 17060, loss 0.548261.
Train: 2018-08-01T00:59:00.623635: step 17061, loss 0.477878.
Train: 2018-08-01T00:59:00.779849: step 17062, loss 0.460795.
Train: 2018-08-01T00:59:00.951653: step 17063, loss 0.562408.
Train: 2018-08-01T00:59:01.107892: step 17064, loss 0.579436.
Train: 2018-08-01T00:59:01.264110: step 17065, loss 0.545329.
Train: 2018-08-01T00:59:01.420325: step 17066, loss 0.459746.
Train: 2018-08-01T00:59:01.592129: step 17067, loss 0.545229.
Train: 2018-08-01T00:59:01.748341: step 17068, loss 0.682968.
Train: 2018-08-01T00:59:01.920178: step 17069, loss 0.61414.
Train: 2018-08-01T00:59:02.092036: step 17070, loss 0.5624.
Test: 2018-08-01T00:59:02.560652: step 17070, loss 0.547946.
Train: 2018-08-01T00:59:02.732516: step 17071, loss 0.545139.
Train: 2018-08-01T00:59:02.888731: step 17072, loss 0.614217.
Train: 2018-08-01T00:59:03.044914: step 17073, loss 0.66601.
Train: 2018-08-01T00:59:03.216773: step 17074, loss 0.665841.
Train: 2018-08-01T00:59:03.357371: step 17075, loss 0.631161.
Train: 2018-08-01T00:59:03.513585: step 17076, loss 0.665178.
Train: 2018-08-01T00:59:03.669767: step 17077, loss 0.647658.
Train: 2018-08-01T00:59:03.841631: step 17078, loss 0.52849.
Train: 2018-08-01T00:59:03.997845: step 17079, loss 0.562424.
Train: 2018-08-01T00:59:04.169681: step 17080, loss 0.646556.
Test: 2018-08-01T00:59:04.638319: step 17080, loss 0.548439.
Train: 2018-08-01T00:59:04.794534: step 17081, loss 0.545716.
Train: 2018-08-01T00:59:04.950749: step 17082, loss 0.545802.
Train: 2018-08-01T00:59:05.106931: step 17083, loss 0.678908.
Train: 2018-08-01T00:59:05.263145: step 17084, loss 0.612203.
Train: 2018-08-01T00:59:05.419388: step 17085, loss 0.529617.
Train: 2018-08-01T00:59:05.575595: step 17086, loss 0.562607.
Train: 2018-08-01T00:59:05.731808: step 17087, loss 0.529898.
Train: 2018-08-01T00:59:05.888027: step 17088, loss 0.546324.
Train: 2018-08-01T00:59:06.044241: step 17089, loss 0.644223.
Train: 2018-08-01T00:59:06.200457: step 17090, loss 0.644051.
Test: 2018-08-01T00:59:06.669094: step 17090, loss 0.54916.
Train: 2018-08-01T00:59:06.825278: step 17091, loss 0.578956.
Train: 2018-08-01T00:59:06.981492: step 17092, loss 0.562777.
Train: 2018-08-01T00:59:07.137705: step 17093, loss 0.530556.
Train: 2018-08-01T00:59:07.293942: step 17094, loss 0.546729.
Train: 2018-08-01T00:59:07.465754: step 17095, loss 0.627184.
Train: 2018-08-01T00:59:07.621996: step 17096, loss 0.627099.
Train: 2018-08-01T00:59:07.778181: step 17097, loss 0.594941.
Train: 2018-08-01T00:59:07.934418: step 17098, loss 0.594899.
Train: 2018-08-01T00:59:08.090637: step 17099, loss 0.562968.
Train: 2018-08-01T00:59:08.246845: step 17100, loss 0.419765.
Test: 2018-08-01T00:59:08.731111: step 17100, loss 0.549648.
Train: 2018-08-01T00:59:09.418420: step 17101, loss 0.59484.
Train: 2018-08-01T00:59:09.574634: step 17102, loss 0.515174.
Train: 2018-08-01T00:59:09.777712: step 17103, loss 0.483171.
Train: 2018-08-01T00:59:09.933924: step 17104, loss 0.514912.
Train: 2018-08-01T00:59:10.090168: step 17105, loss 0.546811.
Train: 2018-08-01T00:59:10.246353: step 17106, loss 0.611161.
Train: 2018-08-01T00:59:10.402565: step 17107, loss 0.546628.
Train: 2018-08-01T00:59:10.558809: step 17108, loss 0.676168.
Train: 2018-08-01T00:59:10.715019: step 17109, loss 0.578957.
Train: 2018-08-01T00:59:10.886827: step 17110, loss 0.57896.
Test: 2018-08-01T00:59:11.355466: step 17110, loss 0.549119.
Train: 2018-08-01T00:59:11.511680: step 17111, loss 0.595206.
Train: 2018-08-01T00:59:11.667893: step 17112, loss 0.513976.
Train: 2018-08-01T00:59:11.855350: step 17113, loss 0.481373.
Train: 2018-08-01T00:59:12.011593: step 17114, loss 0.59529.
Train: 2018-08-01T00:59:12.167778: step 17115, loss 0.562657.
Train: 2018-08-01T00:59:12.324020: step 17116, loss 0.595373.
Train: 2018-08-01T00:59:12.480234: step 17117, loss 0.513458.
Train: 2018-08-01T00:59:12.636447: step 17118, loss 0.546182.
Train: 2018-08-01T00:59:12.792661: step 17119, loss 0.611964.
Train: 2018-08-01T00:59:12.964467: step 17120, loss 0.463674.
Test: 2018-08-01T00:59:13.433104: step 17120, loss 0.548706.
Train: 2018-08-01T00:59:13.589318: step 17121, loss 0.529488.
Train: 2018-08-01T00:59:13.745532: step 17122, loss 0.545941.
Train: 2018-08-01T00:59:13.901745: step 17123, loss 0.579137.
Train: 2018-08-01T00:59:14.073581: step 17124, loss 0.595847.
Train: 2018-08-01T00:59:14.229824: step 17125, loss 0.545756.
Train: 2018-08-01T00:59:14.386038: step 17126, loss 0.64622.
Train: 2018-08-01T00:59:14.542251: step 17127, loss 0.54569.
Train: 2018-08-01T00:59:14.698435: step 17128, loss 0.461749.
Train: 2018-08-01T00:59:14.854678: step 17129, loss 0.612913.
Train: 2018-08-01T00:59:15.010890: step 17130, loss 0.528731.
Test: 2018-08-01T00:59:15.495152: step 17130, loss 0.548288.
Train: 2018-08-01T00:59:15.651336: step 17131, loss 0.528659.
Train: 2018-08-01T00:59:15.807550: step 17132, loss 0.579339.
Train: 2018-08-01T00:59:15.963793: step 17133, loss 0.647175.
Train: 2018-08-01T00:59:16.120007: step 17134, loss 0.630255.
Train: 2018-08-01T00:59:16.291847: step 17135, loss 0.579365.
Train: 2018-08-01T00:59:16.448024: step 17136, loss 0.52853.
Train: 2018-08-01T00:59:16.604269: step 17137, loss 0.562414.
Train: 2018-08-01T00:59:16.776072: step 17138, loss 0.579356.
Train: 2018-08-01T00:59:16.932316: step 17139, loss 0.680981.
Train: 2018-08-01T00:59:17.088529: step 17140, loss 0.528606.
Test: 2018-08-01T00:59:17.557140: step 17140, loss 0.548282.
Train: 2018-08-01T00:59:17.728998: step 17141, loss 0.579313.
Train: 2018-08-01T00:59:17.869597: step 17142, loss 0.494954.
Train: 2018-08-01T00:59:18.025811: step 17143, loss 0.528694.
Train: 2018-08-01T00:59:18.197639: step 17144, loss 0.562427.
Train: 2018-08-01T00:59:18.353862: step 17145, loss 0.579309.
Train: 2018-08-01T00:59:18.525688: step 17146, loss 0.511761.
Train: 2018-08-01T00:59:18.697530: step 17147, loss 0.511707.
Train: 2018-08-01T00:59:18.853737: step 17148, loss 0.596281.
Train: 2018-08-01T00:59:19.009949: step 17149, loss 0.545463.
Train: 2018-08-01T00:59:19.166174: step 17150, loss 0.545439.
Test: 2018-08-01T00:59:19.634778: step 17150, loss 0.548176.
Train: 2018-08-01T00:59:19.790991: step 17151, loss 0.596395.
Train: 2018-08-01T00:59:19.947204: step 17152, loss 0.52839.
Train: 2018-08-01T00:59:20.103418: step 17153, loss 0.49429.
Train: 2018-08-01T00:59:20.259663: step 17154, loss 0.374702.
Train: 2018-08-01T00:59:20.415845: step 17155, loss 0.493838.
Train: 2018-08-01T00:59:20.587681: step 17156, loss 0.596847.
Train: 2018-08-01T00:59:20.743894: step 17157, loss 0.617739.
Train: 2018-08-01T00:59:20.900138: step 17158, loss 0.59709.
Train: 2018-08-01T00:59:21.071974: step 17159, loss 0.579789.
Train: 2018-08-01T00:59:21.228185: step 17160, loss 0.649424.
Test: 2018-08-01T00:59:21.696795: step 17160, loss 0.547846.
Train: 2018-08-01T00:59:21.853008: step 17161, loss 0.440595.
Train: 2018-08-01T00:59:22.009253: step 17162, loss 0.63216.
Train: 2018-08-01T00:59:22.165466: step 17163, loss 0.527541.
Train: 2018-08-01T00:59:22.321649: step 17164, loss 0.527513.
Train: 2018-08-01T00:59:22.477862: step 17165, loss 0.509993.
Train: 2018-08-01T00:59:22.634075: step 17166, loss 0.632492.
Train: 2018-08-01T00:59:22.805911: step 17167, loss 0.57997.
Train: 2018-08-01T00:59:22.962124: step 17168, loss 0.579975.
Train: 2018-08-01T00:59:23.118337: step 17169, loss 0.562448.
Train: 2018-08-01T00:59:23.274550: step 17170, loss 0.562448.
Test: 2018-08-01T00:59:23.743221: step 17170, loss 0.547777.
Train: 2018-08-01T00:59:23.915027: step 17171, loss 0.702598.
Train: 2018-08-01T00:59:24.071239: step 17172, loss 0.64985.
Train: 2018-08-01T00:59:24.227482: step 17173, loss 0.63214.
Train: 2018-08-01T00:59:24.383665: step 17174, loss 0.54505.
Train: 2018-08-01T00:59:24.539879: step 17175, loss 0.52779.
Train: 2018-08-01T00:59:24.696092: step 17176, loss 0.596932.
Train: 2018-08-01T00:59:24.852307: step 17177, loss 0.476303.
Train: 2018-08-01T00:59:25.024177: step 17178, loss 0.493609.
Train: 2018-08-01T00:59:25.180354: step 17179, loss 0.596784.
Train: 2018-08-01T00:59:25.336569: step 17180, loss 0.613942.
Test: 2018-08-01T00:59:25.820830: step 17180, loss 0.548028.
Train: 2018-08-01T00:59:25.977043: step 17181, loss 0.596715.
Train: 2018-08-01T00:59:26.164536: step 17182, loss 0.579528.
Train: 2018-08-01T00:59:26.320746: step 17183, loss 0.562398.
Train: 2018-08-01T00:59:26.492547: step 17184, loss 0.613624.
Train: 2018-08-01T00:59:26.648761: step 17185, loss 0.562402.
Train: 2018-08-01T00:59:26.820619: step 17186, loss 0.579413.
Train: 2018-08-01T00:59:26.976808: step 17187, loss 0.579385.
Train: 2018-08-01T00:59:27.133053: step 17188, loss 0.5963.
Train: 2018-08-01T00:59:27.289266: step 17189, loss 0.596234.
Train: 2018-08-01T00:59:27.461070: step 17190, loss 0.697359.
Test: 2018-08-01T00:59:27.929710: step 17190, loss 0.548379.
Train: 2018-08-01T00:59:28.085923: step 17191, loss 0.461654.
Train: 2018-08-01T00:59:28.242163: step 17192, loss 0.512166.
Train: 2018-08-01T00:59:28.413971: step 17193, loss 0.545717.
Train: 2018-08-01T00:59:28.570215: step 17194, loss 0.579199.
Train: 2018-08-01T00:59:28.726429: step 17195, loss 0.512309.
Train: 2018-08-01T00:59:28.882643: step 17196, loss 0.512303.
Train: 2018-08-01T00:59:29.038858: step 17197, loss 0.579202.
Train: 2018-08-01T00:59:29.195069: step 17198, loss 0.528964.
Train: 2018-08-01T00:59:29.398117: step 17199, loss 0.562455.
Train: 2018-08-01T00:59:29.554360: step 17200, loss 0.56245.
Test: 2018-08-01T00:59:30.023001: step 17200, loss 0.548374.
Train: 2018-08-01T00:59:30.772795: step 17201, loss 0.579248.
Train: 2018-08-01T00:59:30.929038: step 17202, loss 0.562441.
Train: 2018-08-01T00:59:31.085252: step 17203, loss 0.51195.
Train: 2018-08-01T00:59:31.257088: step 17204, loss 0.545578.
Train: 2018-08-01T00:59:31.413300: step 17205, loss 0.545544.
Train: 2018-08-01T00:59:31.585135: step 17206, loss 0.596241.
Train: 2018-08-01T00:59:31.741318: step 17207, loss 0.562416.
Train: 2018-08-01T00:59:31.897562: step 17208, loss 0.613257.
Train: 2018-08-01T00:59:32.053775: step 17209, loss 0.477649.
Train: 2018-08-01T00:59:32.209958: step 17210, loss 0.562409.
Test: 2018-08-01T00:59:32.678625: step 17210, loss 0.548169.
Train: 2018-08-01T00:59:32.834842: step 17211, loss 0.630409.
Train: 2018-08-01T00:59:32.991050: step 17212, loss 0.630429.
Train: 2018-08-01T00:59:33.147270: step 17213, loss 0.443443.
Train: 2018-08-01T00:59:33.303483: step 17214, loss 0.528377.
Train: 2018-08-01T00:59:33.475287: step 17215, loss 0.579441.
Train: 2018-08-01T00:59:33.615909: step 17216, loss 0.5624.
Train: 2018-08-01T00:59:33.787715: step 17217, loss 0.562399.
Train: 2018-08-01T00:59:33.943927: step 17218, loss 0.528214.
Train: 2018-08-01T00:59:34.084550: step 17219, loss 0.630857.
Train: 2018-08-01T00:59:34.240763: step 17220, loss 0.545278.
Test: 2018-08-01T00:59:34.725024: step 17220, loss 0.548054.
Train: 2018-08-01T00:59:34.896860: step 17221, loss 0.511014.
Train: 2018-08-01T00:59:35.068664: step 17222, loss 0.579544.
Train: 2018-08-01T00:59:35.224877: step 17223, loss 0.545235.
Train: 2018-08-01T00:59:35.381121: step 17224, loss 0.528042.
Train: 2018-08-01T00:59:35.537304: step 17225, loss 0.527997.
Train: 2018-08-01T00:59:35.677927: step 17226, loss 0.579627.
Train: 2018-08-01T00:59:35.834110: step 17227, loss 0.4934.
Train: 2018-08-01T00:59:36.005981: step 17228, loss 0.545117.
Train: 2018-08-01T00:59:36.162158: step 17229, loss 0.614368.
Train: 2018-08-01T00:59:36.318401: step 17230, loss 0.51039.
Test: 2018-08-01T00:59:36.787042: step 17230, loss 0.54787.
Train: 2018-08-01T00:59:36.943258: step 17231, loss 0.510308.
Train: 2018-08-01T00:59:37.115087: step 17232, loss 0.666856.
Train: 2018-08-01T00:59:37.255682: step 17233, loss 0.545007.
Train: 2018-08-01T00:59:37.427487: step 17234, loss 0.544999.
Train: 2018-08-01T00:59:37.568109: step 17235, loss 0.544988.
Train: 2018-08-01T00:59:37.739944: step 17236, loss 0.597337.
Train: 2018-08-01T00:59:37.896162: step 17237, loss 0.597347.
Train: 2018-08-01T00:59:38.052375: step 17238, loss 0.510071.
Train: 2018-08-01T00:59:38.224174: step 17239, loss 0.579891.
Train: 2018-08-01T00:59:38.380419: step 17240, loss 0.579893.
Test: 2018-08-01T00:59:38.864680: step 17240, loss 0.547813.
Train: 2018-08-01T00:59:39.020896: step 17241, loss 0.614801.
Train: 2018-08-01T00:59:39.177078: step 17242, loss 0.527548.
Train: 2018-08-01T00:59:39.364533: step 17243, loss 0.70188.
Train: 2018-08-01T00:59:39.520776: step 17244, loss 0.510243.
Train: 2018-08-01T00:59:39.676961: step 17245, loss 0.562413.
Train: 2018-08-01T00:59:39.833208: step 17246, loss 0.597096.
Train: 2018-08-01T00:59:39.989422: step 17247, loss 0.545092.
Train: 2018-08-01T00:59:40.145626: step 17248, loss 0.545113.
Train: 2018-08-01T00:59:40.301845: step 17249, loss 0.596949.
Train: 2018-08-01T00:59:40.489295: step 17250, loss 0.579649.
Test: 2018-08-01T00:59:40.957939: step 17250, loss 0.547975.
Train: 2018-08-01T00:59:41.114153: step 17251, loss 0.510727.
Train: 2018-08-01T00:59:41.270338: step 17252, loss 0.493548.
Train: 2018-08-01T00:59:41.426581: step 17253, loss 0.493524.
Train: 2018-08-01T00:59:41.598384: step 17254, loss 0.665838.
Train: 2018-08-01T00:59:41.754598: step 17255, loss 0.476226.
Train: 2018-08-01T00:59:41.910842: step 17256, loss 0.476151.
Train: 2018-08-01T00:59:42.067025: step 17257, loss 0.545119.
Train: 2018-08-01T00:59:42.223268: step 17258, loss 0.579724.
Train: 2018-08-01T00:59:42.379482: step 17259, loss 0.56241.
Train: 2018-08-01T00:59:42.535666: step 17260, loss 0.388744.
Test: 2018-08-01T00:59:43.004305: step 17260, loss 0.547831.
Train: 2018-08-01T00:59:43.160543: step 17261, loss 0.492715.
Train: 2018-08-01T00:59:43.332378: step 17262, loss 0.579938.
Train: 2018-08-01T00:59:43.488599: step 17263, loss 0.580012.
Train: 2018-08-01T00:59:43.660428: step 17264, loss 0.527268.
Train: 2018-08-01T00:59:43.816615: step 17265, loss 0.491887.
Train: 2018-08-01T00:59:43.972854: step 17266, loss 0.66877.
Train: 2018-08-01T00:59:44.129072: step 17267, loss 0.615733.
Train: 2018-08-01T00:59:44.285256: step 17268, loss 0.509291.
Train: 2018-08-01T00:59:44.441502: step 17269, loss 0.580304.
Train: 2018-08-01T00:59:44.597713: step 17270, loss 0.509212.
Test: 2018-08-01T00:59:45.081974: step 17270, loss 0.54765.
Train: 2018-08-01T00:59:45.238158: step 17271, loss 0.615947.
Train: 2018-08-01T00:59:45.394398: step 17272, loss 0.633764.
Train: 2018-08-01T00:59:45.550615: step 17273, loss 0.544761.
Train: 2018-08-01T00:59:45.706828: step 17274, loss 0.651429.
Train: 2018-08-01T00:59:45.878633: step 17275, loss 0.544783.
Train: 2018-08-01T00:59:46.034845: step 17276, loss 0.456205.
Train: 2018-08-01T00:59:46.191089: step 17277, loss 0.562517.
Train: 2018-08-01T00:59:46.347303: step 17278, loss 0.509371.
Train: 2018-08-01T00:59:46.503516: step 17279, loss 0.456182.
Train: 2018-08-01T00:59:46.659724: step 17280, loss 0.580284.
Test: 2018-08-01T00:59:47.143991: step 17280, loss 0.547658.
Train: 2018-08-01T00:59:47.300205: step 17281, loss 0.598088.
Train: 2018-08-01T00:59:47.456388: step 17282, loss 0.615892.
Train: 2018-08-01T00:59:47.612631: step 17283, loss 0.544767.
Train: 2018-08-01T00:59:47.768845: step 17284, loss 0.491451.
Train: 2018-08-01T00:59:47.925058: step 17285, loss 0.687032.
Train: 2018-08-01T00:59:48.096887: step 17286, loss 0.52701.
Train: 2018-08-01T00:59:48.253102: step 17287, loss 0.54478.
Train: 2018-08-01T00:59:48.409320: step 17288, loss 0.491556.
Train: 2018-08-01T00:59:48.565536: step 17289, loss 0.615779.
Train: 2018-08-01T00:59:48.721747: step 17290, loss 0.580269.
Test: 2018-08-01T00:59:49.190387: step 17290, loss 0.547676.
Train: 2018-08-01T00:59:49.346601: step 17291, loss 0.45615.
Train: 2018-08-01T00:59:49.502783: step 17292, loss 0.580266.
Train: 2018-08-01T00:59:49.659028: step 17293, loss 0.544784.
Train: 2018-08-01T00:59:49.815244: step 17294, loss 0.456036.
Train: 2018-08-01T00:59:49.971450: step 17295, loss 0.420328.
Train: 2018-08-01T00:59:50.127637: step 17296, loss 0.598235.
Train: 2018-08-01T00:59:50.299473: step 17297, loss 0.562591.
Train: 2018-08-01T00:59:50.455686: step 17298, loss 0.652138.
Train: 2018-08-01T00:59:50.611924: step 17299, loss 0.616354.
Train: 2018-08-01T00:59:50.768112: step 17300, loss 0.473083.
Test: 2018-08-01T00:59:51.248354: step 17300, loss 0.547613.
Train: 2018-08-01T00:59:51.951323: step 17301, loss 0.5447.
Train: 2018-08-01T00:59:52.107525: step 17302, loss 0.580551.
Train: 2018-08-01T00:59:52.263739: step 17303, loss 0.652287.
Train: 2018-08-01T00:59:52.451190: step 17304, loss 0.670094.
Train: 2018-08-01T00:59:52.607409: step 17305, loss 0.598329.
Train: 2018-08-01T00:59:52.763591: step 17306, loss 0.509104.
Train: 2018-08-01T00:59:52.919805: step 17307, loss 0.562547.
Train: 2018-08-01T00:59:53.076018: step 17308, loss 0.615789.
Train: 2018-08-01T00:59:53.232262: step 17309, loss 0.59793.
Train: 2018-08-01T00:59:53.388470: step 17310, loss 0.70377.
Test: 2018-08-01T00:59:53.857116: step 17310, loss 0.547743.
Train: 2018-08-01T00:59:54.028932: step 17311, loss 0.527302.
Train: 2018-08-01T00:59:54.185135: step 17312, loss 0.544928.
Train: 2018-08-01T00:59:54.341347: step 17313, loss 0.492577.
Train: 2018-08-01T00:59:54.497560: step 17314, loss 0.475273.
Train: 2018-08-01T00:59:54.653774: step 17315, loss 0.545003.
Train: 2018-08-01T00:59:54.809988: step 17316, loss 0.649486.
Train: 2018-08-01T00:59:54.966201: step 17317, loss 0.684119.
Train: 2018-08-01T00:59:55.138065: step 17318, loss 0.614407.
Train: 2018-08-01T00:59:55.294280: step 17319, loss 0.527856.
Train: 2018-08-01T00:59:55.450462: step 17320, loss 0.665753.
Test: 2018-08-01T00:59:55.919133: step 17320, loss 0.548027.
Train: 2018-08-01T00:59:56.090967: step 17321, loss 0.631034.
Train: 2018-08-01T00:59:56.247175: step 17322, loss 0.545315.
Train: 2018-08-01T00:59:56.403394: step 17323, loss 0.477307.
Train: 2018-08-01T00:59:56.559608: step 17324, loss 0.562408.
Train: 2018-08-01T00:59:56.715822: step 17325, loss 0.613261.
Train: 2018-08-01T00:59:56.903278: step 17326, loss 0.56242.
Train: 2018-08-01T00:59:57.059490: step 17327, loss 0.545555.
Train: 2018-08-01T00:59:57.215674: step 17328, loss 0.579279.
Train: 2018-08-01T00:59:57.371912: step 17329, loss 0.528807.
Train: 2018-08-01T00:59:57.528125: step 17330, loss 0.512043.
Test: 2018-08-01T00:59:57.996771: step 17330, loss 0.548378.
Train: 2018-08-01T00:59:58.152985: step 17331, loss 0.612844.
Train: 2018-08-01T00:59:58.309201: step 17332, loss 0.579236.
Train: 2018-08-01T00:59:58.465381: step 17333, loss 0.596.
Train: 2018-08-01T00:59:58.621629: step 17334, loss 0.595968.
Train: 2018-08-01T00:59:58.777808: step 17335, loss 0.595927.
Train: 2018-08-01T00:59:58.934048: step 17336, loss 0.495669.
Train: 2018-08-01T00:59:59.105886: step 17337, loss 0.529092.
Train: 2018-08-01T00:59:59.262069: step 17338, loss 0.51239.
Train: 2018-08-01T00:59:59.418284: step 17339, loss 0.478914.
Train: 2018-08-01T00:59:59.590143: step 17340, loss 0.545714.
Test: 2018-08-01T01:00:00.058794: step 17340, loss 0.548394.
Train: 2018-08-01T01:00:00.230593: step 17341, loss 0.56245.
Train: 2018-08-01T01:00:00.386837: step 17342, loss 0.478341.
Train: 2018-08-01T01:00:00.543050: step 17343, loss 0.596172.
Train: 2018-08-01T01:00:00.683646: step 17344, loss 0.545507.
Train: 2018-08-01T01:00:00.839851: step 17345, loss 0.511551.
Train: 2018-08-01T01:00:00.996070: step 17346, loss 0.528398.
Train: 2018-08-01T01:00:01.167899: step 17347, loss 0.579457.
Train: 2018-08-01T01:00:01.339742: step 17348, loss 0.630802.
Train: 2018-08-01T01:00:01.495958: step 17349, loss 0.562397.
Train: 2018-08-01T01:00:01.652160: step 17350, loss 0.562396.
Test: 2018-08-01T01:00:02.136427: step 17350, loss 0.548022.
Train: 2018-08-01T01:00:02.292610: step 17351, loss 0.510898.
Train: 2018-08-01T01:00:02.448858: step 17352, loss 0.562397.
Train: 2018-08-01T01:00:02.605038: step 17353, loss 0.527954.
Train: 2018-08-01T01:00:02.761251: step 17354, loss 0.596908.
Train: 2018-08-01T01:00:02.917494: step 17355, loss 0.545127.
Train: 2018-08-01T01:00:03.073677: step 17356, loss 0.631588.
Train: 2018-08-01T01:00:03.229922: step 17357, loss 0.597002.
Train: 2018-08-01T01:00:03.386132: step 17358, loss 0.54511.
Train: 2018-08-01T01:00:03.557972: step 17359, loss 0.579695.
Train: 2018-08-01T01:00:03.714178: step 17360, loss 0.527831.
Test: 2018-08-01T01:00:04.182823: step 17360, loss 0.547926.
Train: 2018-08-01T01:00:04.354658: step 17361, loss 0.596979.
Train: 2018-08-01T01:00:04.526498: step 17362, loss 0.648811.
Train: 2018-08-01T01:00:04.667055: step 17363, loss 0.52789.
Train: 2018-08-01T01:00:04.823292: step 17364, loss 0.52792.
Train: 2018-08-01T01:00:04.979481: step 17365, loss 0.631329.
Train: 2018-08-01T01:00:05.135694: step 17366, loss 0.527977.
Train: 2018-08-01T01:00:05.291938: step 17367, loss 0.528001.
Train: 2018-08-01T01:00:05.448156: step 17368, loss 0.562397.
Train: 2018-08-01T01:00:05.619982: step 17369, loss 0.596781.
Train: 2018-08-01T01:00:05.776200: step 17370, loss 0.562396.
Test: 2018-08-01T01:00:06.244810: step 17370, loss 0.548017.
Train: 2018-08-01T01:00:06.401047: step 17371, loss 0.682598.
Train: 2018-08-01T01:00:06.557270: step 17372, loss 0.579531.
Train: 2018-08-01T01:00:06.729071: step 17373, loss 0.528204.
Train: 2018-08-01T01:00:06.885286: step 17374, loss 0.494114.
Train: 2018-08-01T01:00:07.041522: step 17375, loss 0.511205.
Train: 2018-08-01T01:00:07.197746: step 17376, loss 0.545328.
Train: 2018-08-01T01:00:07.353955: step 17377, loss 0.545316.
Train: 2018-08-01T01:00:07.510169: step 17378, loss 0.528207.
Train: 2018-08-01T01:00:07.666377: step 17379, loss 0.579513.
Train: 2018-08-01T01:00:07.838223: step 17380, loss 0.528135.
Test: 2018-08-01T01:00:08.322482: step 17380, loss 0.548033.
Train: 2018-08-01T01:00:08.478692: step 17381, loss 0.425177.
Train: 2018-08-01T01:00:08.650521: step 17382, loss 0.665623.
Train: 2018-08-01T01:00:08.806711: step 17383, loss 0.596851.
Train: 2018-08-01T01:00:08.994166: step 17384, loss 0.545161.
Train: 2018-08-01T01:00:09.150379: step 17385, loss 0.545148.
Train: 2018-08-01T01:00:09.306592: step 17386, loss 0.596938.
Train: 2018-08-01T01:00:09.462836: step 17387, loss 0.527852.
Train: 2018-08-01T01:00:09.619052: step 17388, loss 0.562403.
Train: 2018-08-01T01:00:09.775257: step 17389, loss 0.545104.
Train: 2018-08-01T01:00:09.931447: step 17390, loss 0.562406.
Test: 2018-08-01T01:00:10.400118: step 17390, loss 0.547898.
Train: 2018-08-01T01:00:10.556331: step 17391, loss 0.562407.
Train: 2018-08-01T01:00:10.712544: step 17392, loss 0.527734.
Train: 2018-08-01T01:00:10.868727: step 17393, loss 0.59712.
Train: 2018-08-01T01:00:11.040588: step 17394, loss 0.562412.
Train: 2018-08-01T01:00:11.196776: step 17395, loss 0.510314.
Train: 2018-08-01T01:00:11.353019: step 17396, loss 0.52765.
Train: 2018-08-01T01:00:11.509233: step 17397, loss 0.510204.
Train: 2018-08-01T01:00:11.665416: step 17398, loss 0.5973.
Train: 2018-08-01T01:00:11.821629: step 17399, loss 0.562431.
Train: 2018-08-01T01:00:11.977873: step 17400, loss 0.527489.
Test: 2018-08-01T01:00:12.462134: step 17400, loss 0.54779.
Train: 2018-08-01T01:00:13.211959: step 17401, loss 0.544945.
Train: 2018-08-01T01:00:13.383763: step 17402, loss 0.509894.
Train: 2018-08-01T01:00:13.540001: step 17403, loss 0.580004.
Train: 2018-08-01T01:00:13.696190: step 17404, loss 0.4746.
Train: 2018-08-01T01:00:13.852403: step 17405, loss 0.580088.
Train: 2018-08-01T01:00:14.008618: step 17406, loss 0.509557.
Train: 2018-08-01T01:00:14.180485: step 17407, loss 0.562501.
Train: 2018-08-01T01:00:14.352287: step 17408, loss 0.562515.
Train: 2018-08-01T01:00:14.508524: step 17409, loss 0.598012.
Train: 2018-08-01T01:00:14.664738: step 17410, loss 0.651321.
Test: 2018-08-01T01:00:15.149004: step 17410, loss 0.547668.
Train: 2018-08-01T01:00:15.305187: step 17411, loss 0.56253.
Train: 2018-08-01T01:00:15.477023: step 17412, loss 0.527048.
Train: 2018-08-01T01:00:15.633236: step 17413, loss 0.49158.
Train: 2018-08-01T01:00:15.789451: step 17414, loss 0.56253.
Train: 2018-08-01T01:00:15.945697: step 17415, loss 0.509261.
Train: 2018-08-01T01:00:16.101907: step 17416, loss 0.58032.
Train: 2018-08-01T01:00:16.258090: step 17417, loss 0.526973.
Train: 2018-08-01T01:00:16.414333: step 17418, loss 0.544752.
Train: 2018-08-01T01:00:16.570547: step 17419, loss 0.651665.
Train: 2018-08-01T01:00:16.789215: step 17420, loss 0.63381.
Test: 2018-08-01T01:00:17.257886: step 17420, loss 0.547653.
Train: 2018-08-01T01:00:17.414103: step 17421, loss 0.633696.
Train: 2018-08-01T01:00:17.570283: step 17422, loss 0.686748.
Train: 2018-08-01T01:00:17.742117: step 17423, loss 0.544822.
Train: 2018-08-01T01:00:17.898331: step 17424, loss 0.562478.
Train: 2018-08-01T01:00:18.054545: step 17425, loss 0.597591.
Train: 2018-08-01T01:00:18.210788: step 17426, loss 0.544936.
Train: 2018-08-01T01:00:18.367001: step 17427, loss 0.475143.
Train: 2018-08-01T01:00:18.523215: step 17428, loss 0.440396.
Train: 2018-08-01T01:00:18.679430: step 17429, loss 0.649618.
Train: 2018-08-01T01:00:18.851263: step 17430, loss 0.562423.
Test: 2018-08-01T01:00:19.319873: step 17430, loss 0.547844.
Train: 2018-08-01T01:00:19.476087: step 17431, loss 0.527608.
Train: 2018-08-01T01:00:19.647921: step 17432, loss 0.632017.
Train: 2018-08-01T01:00:19.804134: step 17433, loss 0.527662.
Train: 2018-08-01T01:00:19.975969: step 17434, loss 0.562413.
Train: 2018-08-01T01:00:20.116561: step 17435, loss 0.475658.
Train: 2018-08-01T01:00:20.272810: step 17436, loss 0.527694.
Train: 2018-08-01T01:00:20.429021: step 17437, loss 0.684034.
Train: 2018-08-01T01:00:20.600847: step 17438, loss 0.545053.
Train: 2018-08-01T01:00:20.757066: step 17439, loss 0.527714.
Train: 2018-08-01T01:00:20.913280: step 17440, loss 0.510372.
Test: 2018-08-01T01:00:21.381920: step 17440, loss 0.547878.
Train: 2018-08-01T01:00:21.538136: step 17441, loss 0.579767.
Train: 2018-08-01T01:00:21.694351: step 17442, loss 0.527692.
Train: 2018-08-01T01:00:21.850531: step 17443, loss 0.597157.
Train: 2018-08-01T01:00:22.006745: step 17444, loss 0.71877.
Train: 2018-08-01T01:00:22.178578: step 17445, loss 0.441053.
Train: 2018-08-01T01:00:22.334791: step 17446, loss 0.649068.
Train: 2018-08-01T01:00:22.506627: step 17447, loss 0.527791.
Train: 2018-08-01T01:00:22.662870: step 17448, loss 0.527819.
Train: 2018-08-01T01:00:22.803463: step 17449, loss 0.52783.
Train: 2018-08-01T01:00:22.975297: step 17450, loss 0.527825.
Test: 2018-08-01T01:00:23.459529: step 17450, loss 0.547918.
Train: 2018-08-01T01:00:23.615772: step 17451, loss 0.700797.
Train: 2018-08-01T01:00:23.771981: step 17452, loss 0.631502.
Train: 2018-08-01T01:00:23.928168: step 17453, loss 0.596872.
Train: 2018-08-01T01:00:24.084412: step 17454, loss 0.631173.
Train: 2018-08-01T01:00:24.256217: step 17455, loss 0.476701.
Train: 2018-08-01T01:00:24.412461: step 17456, loss 0.476847.
Train: 2018-08-01T01:00:24.568645: step 17457, loss 0.61371.
Train: 2018-08-01T01:00:24.724887: step 17458, loss 0.544172.
Train: 2018-08-01T01:00:24.896692: step 17459, loss 0.630705.
Train: 2018-08-01T01:00:25.052939: step 17460, loss 0.494198.
Test: 2018-08-01T01:00:25.521576: step 17460, loss 0.548129.
Train: 2018-08-01T01:00:25.677784: step 17461, loss 0.613533.
Train: 2018-08-01T01:00:25.834006: step 17462, loss 0.477271.
Train: 2018-08-01T01:00:25.990185: step 17463, loss 0.477247.
Train: 2018-08-01T01:00:26.146399: step 17464, loss 0.664737.
Train: 2018-08-01T01:00:26.302614: step 17465, loss 0.579455.
Train: 2018-08-01T01:00:26.490069: step 17466, loss 0.511252.
Train: 2018-08-01T01:00:26.646283: step 17467, loss 0.613572.
Train: 2018-08-01T01:00:26.802495: step 17468, loss 0.477138.
Train: 2018-08-01T01:00:26.958709: step 17469, loss 0.630675.
Train: 2018-08-01T01:00:27.114922: step 17470, loss 0.562399.
Test: 2018-08-01T01:00:27.583593: step 17470, loss 0.548108.
Train: 2018-08-01T01:00:27.739776: step 17471, loss 0.579466.
Train: 2018-08-01T01:00:27.895990: step 17472, loss 0.545337.
Train: 2018-08-01T01:00:28.067824: step 17473, loss 0.579462.
Train: 2018-08-01T01:00:28.208446: step 17474, loss 0.528282.
Train: 2018-08-01T01:00:28.364631: step 17475, loss 0.613592.
Train: 2018-08-01T01:00:28.536464: step 17476, loss 0.596514.
Train: 2018-08-01T01:00:28.708330: step 17477, loss 0.494231.
Train: 2018-08-01T01:00:28.864514: step 17478, loss 0.61354.
Train: 2018-08-01T01:00:29.036372: step 17479, loss 0.562402.
Train: 2018-08-01T01:00:29.192586: step 17480, loss 0.562402.
Test: 2018-08-01T01:00:29.661201: step 17480, loss 0.548147.
Train: 2018-08-01T01:00:29.833066: step 17481, loss 0.715623.
Train: 2018-08-01T01:00:29.989280: step 17482, loss 0.494477.
Train: 2018-08-01T01:00:30.129871: step 17483, loss 0.511525.
Train: 2018-08-01T01:00:30.301691: step 17484, loss 0.664148.
Train: 2018-08-01T01:00:30.457890: step 17485, loss 0.579343.
Train: 2018-08-01T01:00:30.598482: step 17486, loss 0.697602.
Train: 2018-08-01T01:00:30.770342: step 17487, loss 0.579274.
Train: 2018-08-01T01:00:30.942152: step 17488, loss 0.747072.
Train: 2018-08-01T01:00:31.098390: step 17489, loss 0.595861.
Train: 2018-08-01T01:00:31.254578: step 17490, loss 0.628917.
Test: 2018-08-01T01:00:31.738839: step 17490, loss 0.54874.
Train: 2018-08-01T01:00:31.910678: step 17491, loss 0.529552.
Train: 2018-08-01T01:00:32.066888: step 17492, loss 0.546173.
Train: 2018-08-01T01:00:32.223131: step 17493, loss 0.546272.
Train: 2018-08-01T01:00:32.379345: step 17494, loss 0.481086.
Train: 2018-08-01T01:00:32.535528: step 17495, loss 0.464913.
Train: 2018-08-01T01:00:32.691741: step 17496, loss 0.530073.
Train: 2018-08-01T01:00:32.847955: step 17497, loss 0.513706.
Train: 2018-08-01T01:00:33.019790: step 17498, loss 0.562648.
Train: 2018-08-01T01:00:33.160406: step 17499, loss 0.562629.
Train: 2018-08-01T01:00:33.316629: step 17500, loss 0.496969.
Test: 2018-08-01T01:00:33.785236: step 17500, loss 0.548806.
Train: 2018-08-01T01:00:34.472574: step 17501, loss 0.677777.
Train: 2018-08-01T01:00:34.628788: step 17502, loss 0.579049.
Train: 2018-08-01T01:00:34.785032: step 17503, loss 0.628499.
Train: 2018-08-01T01:00:34.941249: step 17504, loss 0.59553.
Train: 2018-08-01T01:00:35.113051: step 17505, loss 0.513176.
Train: 2018-08-01T01:00:35.284885: step 17506, loss 0.562577.
Train: 2018-08-01T01:00:35.441132: step 17507, loss 0.628496.
Train: 2018-08-01T01:00:35.597336: step 17508, loss 0.447264.
Train: 2018-08-01T01:00:35.769145: step 17509, loss 0.727534.
Train: 2018-08-01T01:00:35.925359: step 17510, loss 0.562573.
Test: 2018-08-01T01:00:36.394030: step 17510, loss 0.548791.
Train: 2018-08-01T01:00:36.550214: step 17511, loss 0.496713.
Train: 2018-08-01T01:00:36.706457: step 17512, loss 0.595523.
Train: 2018-08-01T01:00:36.878261: step 17513, loss 0.562577.
Train: 2018-08-01T01:00:37.034474: step 17514, loss 0.612001.
Train: 2018-08-01T01:00:37.175100: step 17515, loss 0.56258.
Train: 2018-08-01T01:00:37.346903: step 17516, loss 0.562583.
Train: 2018-08-01T01:00:37.503146: step 17517, loss 0.710718.
Train: 2018-08-01T01:00:37.659329: step 17518, loss 0.546181.
Train: 2018-08-01T01:00:37.815542: step 17519, loss 0.628207.
Train: 2018-08-01T01:00:37.971755: step 17520, loss 0.529924.
Test: 2018-08-01T01:00:38.440430: step 17520, loss 0.548978.
Train: 2018-08-01T01:00:38.596610: step 17521, loss 0.611665.
Train: 2018-08-01T01:00:38.752822: step 17522, loss 0.562677.
Train: 2018-08-01T01:00:38.909035: step 17523, loss 0.627818.
Train: 2018-08-01T01:00:39.065283: step 17524, loss 0.497736.
Train: 2018-08-01T01:00:39.237108: step 17525, loss 0.530263.
Train: 2018-08-01T01:00:39.393298: step 17526, loss 0.546496.
Train: 2018-08-01T01:00:39.565133: step 17527, loss 0.497771.
Train: 2018-08-01T01:00:39.721370: step 17528, loss 0.660282.
Train: 2018-08-01T01:00:39.877589: step 17529, loss 0.546442.
Train: 2018-08-01T01:00:40.033773: step 17530, loss 0.481345.
Test: 2018-08-01T01:00:40.502442: step 17530, loss 0.54903.
Train: 2018-08-01T01:00:40.674249: step 17531, loss 0.530079.
Train: 2018-08-01T01:00:40.830461: step 17532, loss 0.677024.
Train: 2018-08-01T01:00:40.971053: step 17533, loss 0.61169.
Train: 2018-08-01T01:00:41.127292: step 17534, loss 0.562652.
Train: 2018-08-01T01:00:41.283511: step 17535, loss 0.464583.
Train: 2018-08-01T01:00:41.455314: step 17536, loss 0.546263.
Train: 2018-08-01T01:00:41.611552: step 17537, loss 0.579019.
Train: 2018-08-01T01:00:41.783400: step 17538, loss 0.513314.
Train: 2018-08-01T01:00:41.923987: step 17539, loss 0.579047.
Train: 2018-08-01T01:00:42.080167: step 17540, loss 0.529565.
Test: 2018-08-01T01:00:42.548839: step 17540, loss 0.548695.
Train: 2018-08-01T01:00:42.767538: step 17541, loss 0.512929.
Train: 2018-08-01T01:00:42.939376: step 17542, loss 0.529346.
Train: 2018-08-01T01:00:43.095579: step 17543, loss 0.545857.
Train: 2018-08-01T01:00:43.251799: step 17544, loss 0.462301.
Train: 2018-08-01T01:00:43.407983: step 17545, loss 0.512141.
Train: 2018-08-01T01:00:43.564229: step 17546, loss 0.511879.
Train: 2018-08-01T01:00:43.720439: step 17547, loss 0.545478.
Train: 2018-08-01T01:00:43.892275: step 17548, loss 0.68153.
Train: 2018-08-01T01:00:44.064078: step 17549, loss 0.528272.
Train: 2018-08-01T01:00:44.220292: step 17550, loss 0.493945.
Test: 2018-08-01T01:00:44.688966: step 17550, loss 0.548015.
Train: 2018-08-01T01:00:44.845176: step 17551, loss 0.596743.
Train: 2018-08-01T01:00:45.017020: step 17552, loss 0.596838.
Train: 2018-08-01T01:00:45.173218: step 17553, loss 0.510638.
Train: 2018-08-01T01:00:45.329443: step 17554, loss 0.545108.
Train: 2018-08-01T01:00:45.485621: step 17555, loss 0.527734.
Train: 2018-08-01T01:00:45.641835: step 17556, loss 0.492887.
Train: 2018-08-01T01:00:45.798048: step 17557, loss 0.579864.
Train: 2018-08-01T01:00:45.969907: step 17558, loss 0.509987.
Train: 2018-08-01T01:00:46.157338: step 17559, loss 0.597521.
Train: 2018-08-01T01:00:46.313551: step 17560, loss 0.527317.
Test: 2018-08-01T01:00:46.782222: step 17560, loss 0.547727.
Train: 2018-08-01T01:00:46.938405: step 17561, loss 0.509637.
Train: 2018-08-01T01:00:47.094619: step 17562, loss 0.509512.
Train: 2018-08-01T01:00:47.266454: step 17563, loss 0.544801.
Train: 2018-08-01T01:00:47.407045: step 17564, loss 0.438193.
Train: 2018-08-01T01:00:47.578916: step 17565, loss 0.687414.
Train: 2018-08-01T01:00:47.735094: step 17566, loss 0.526852.
Train: 2018-08-01T01:00:47.891310: step 17567, loss 0.562609.
Train: 2018-08-01T01:00:48.047554: step 17568, loss 0.544692.
Train: 2018-08-01T01:00:48.188113: step 17569, loss 0.598574.
Train: 2018-08-01T01:00:48.359947: step 17570, loss 0.544674.
Test: 2018-08-01T01:00:48.844208: step 17570, loss 0.547595.
Train: 2018-08-01T01:00:49.000422: step 17571, loss 0.526673.
Train: 2018-08-01T01:00:49.172290: step 17572, loss 0.562677.
Train: 2018-08-01T01:00:49.312850: step 17573, loss 0.616777.
Train: 2018-08-01T01:00:49.500306: step 17574, loss 0.544657.
Train: 2018-08-01T01:00:49.656549: step 17575, loss 0.490569.
Train: 2018-08-01T01:00:49.812732: step 17576, loss 0.59878.
Train: 2018-08-01T01:00:49.968976: step 17577, loss 0.562696.
Train: 2018-08-01T01:00:50.125189: step 17578, loss 0.580738.
Train: 2018-08-01T01:00:50.281372: step 17579, loss 0.544655.
Train: 2018-08-01T01:00:50.453245: step 17580, loss 0.508599.
Test: 2018-08-01T01:00:50.921878: step 17580, loss 0.547588.
Train: 2018-08-01T01:00:51.078091: step 17581, loss 0.454489.
Train: 2018-08-01T01:00:51.234306: step 17582, loss 0.580764.
Train: 2018-08-01T01:00:51.390518: step 17583, loss 0.526567.
Train: 2018-08-01T01:00:51.562350: step 17584, loss 0.707485.
Train: 2018-08-01T01:00:51.734157: step 17585, loss 0.526564.
Train: 2018-08-01T01:00:51.890371: step 17586, loss 0.562711.
Train: 2018-08-01T01:00:52.046614: step 17587, loss 0.544648.
Train: 2018-08-01T01:00:52.202831: step 17588, loss 0.670963.
Train: 2018-08-01T01:00:52.359011: step 17589, loss 0.562672.
Train: 2018-08-01T01:00:52.515224: step 17590, loss 0.454806.
Test: 2018-08-01T01:00:52.983895: step 17590, loss 0.547601.
Train: 2018-08-01T01:00:53.140103: step 17591, loss 0.706362.
Train: 2018-08-01T01:00:53.296292: step 17592, loss 0.670147.
Train: 2018-08-01T01:00:53.452505: step 17593, loss 0.562583.
Train: 2018-08-01T01:00:53.608743: step 17594, loss 0.598142.
Train: 2018-08-01T01:00:53.780584: step 17595, loss 0.47387.
Train: 2018-08-01T01:00:53.936792: step 17596, loss 0.403292.
Train: 2018-08-01T01:00:54.093010: step 17597, loss 0.63326.
Train: 2018-08-01T01:00:54.249193: step 17598, loss 0.580166.
Train: 2018-08-01T01:00:54.405406: step 17599, loss 0.491899.
Train: 2018-08-01T01:00:54.561654: step 17600, loss 0.438996.
Test: 2018-08-01T01:00:55.030291: step 17600, loss 0.547703.
Train: 2018-08-01T01:00:55.748844: step 17601, loss 0.562494.
Train: 2018-08-01T01:00:55.920677: step 17602, loss 0.597861.
Train: 2018-08-01T01:00:56.108133: step 17603, loss 0.63325.
Train: 2018-08-01T01:00:56.248758: step 17604, loss 0.456451.
Train: 2018-08-01T01:00:56.420585: step 17605, loss 0.52713.
Train: 2018-08-01T01:00:56.592431: step 17606, loss 0.668729.
Train: 2018-08-01T01:00:56.748633: step 17607, loss 0.544813.
Train: 2018-08-01T01:00:56.904852: step 17608, loss 0.527132.
Train: 2018-08-01T01:00:57.076685: step 17609, loss 0.562503.
Train: 2018-08-01T01:00:57.232900: step 17610, loss 0.50945.
Test: 2018-08-01T01:00:57.701540: step 17610, loss 0.54769.
Train: 2018-08-01T01:00:57.857723: step 17611, loss 0.491734.
Train: 2018-08-01T01:00:58.013967: step 17612, loss 0.597946.
Train: 2018-08-01T01:00:58.185807: step 17613, loss 0.544794.
Train: 2018-08-01T01:00:58.342018: step 17614, loss 0.615738.
Train: 2018-08-01T01:00:58.498229: step 17615, loss 0.491586.
Train: 2018-08-01T01:00:58.654442: step 17616, loss 0.509291.
Train: 2018-08-01T01:00:58.810625: step 17617, loss 0.615837.
Train: 2018-08-01T01:00:58.966869: step 17618, loss 0.686936.
Train: 2018-08-01T01:00:59.123077: step 17619, loss 0.562528.
Train: 2018-08-01T01:00:59.294888: step 17620, loss 0.473918.
Test: 2018-08-01T01:00:59.763557: step 17620, loss 0.54768.
Train: 2018-08-01T01:00:59.919765: step 17621, loss 0.651093.
Train: 2018-08-01T01:01:00.075985: step 17622, loss 0.562505.
Train: 2018-08-01T01:01:00.247819: step 17623, loss 0.527164.
Train: 2018-08-01T01:01:00.419648: step 17624, loss 0.50954.
Train: 2018-08-01T01:01:00.560216: step 17625, loss 0.650718.
Train: 2018-08-01T01:01:00.716460: step 17626, loss 0.632963.
Train: 2018-08-01T01:01:00.872644: step 17627, loss 0.527302.
Train: 2018-08-01T01:01:01.044478: step 17628, loss 0.580008.
Train: 2018-08-01T01:01:01.185071: step 17629, loss 0.562447.
Train: 2018-08-01T01:01:01.356934: step 17630, loss 0.579931.
Test: 2018-08-01T01:01:01.825574: step 17630, loss 0.54781.
Train: 2018-08-01T01:01:01.981758: step 17631, loss 0.544971.
Train: 2018-08-01T01:01:02.137972: step 17632, loss 0.597295.
Train: 2018-08-01T01:01:02.294184: step 17633, loss 0.579822.
Train: 2018-08-01T01:01:02.466049: step 17634, loss 0.631893.
Train: 2018-08-01T01:01:02.637884: step 17635, loss 0.42382.
Train: 2018-08-01T01:01:02.794092: step 17636, loss 0.545092.
Train: 2018-08-01T01:01:02.950282: step 17637, loss 0.510483.
Train: 2018-08-01T01:01:03.106524: step 17638, loss 0.545092.
Train: 2018-08-01T01:01:03.262732: step 17639, loss 0.631697.
Train: 2018-08-01T01:01:03.418954: step 17640, loss 0.597035.
Test: 2018-08-01T01:01:03.903214: step 17640, loss 0.547918.
Train: 2018-08-01T01:01:04.059430: step 17641, loss 0.510508.
Train: 2018-08-01T01:01:04.215640: step 17642, loss 0.510516.
Train: 2018-08-01T01:01:04.371854: step 17643, loss 0.527794.
Train: 2018-08-01T01:01:04.528067: step 17644, loss 0.63169.
Train: 2018-08-01T01:01:04.699871: step 17645, loss 0.441176.
Train: 2018-08-01T01:01:04.871707: step 17646, loss 0.631785.
Train: 2018-08-01T01:01:05.027920: step 17647, loss 0.52771.
Train: 2018-08-01T01:01:05.184133: step 17648, loss 0.475595.
Train: 2018-08-01T01:01:05.340347: step 17649, loss 0.597207.
Train: 2018-08-01T01:01:05.496560: step 17650, loss 0.545007.
Test: 2018-08-01T01:01:05.965230: step 17650, loss 0.547826.
Train: 2018-08-01T01:01:06.137035: step 17651, loss 0.597295.
Train: 2018-08-01T01:01:06.293281: step 17652, loss 0.49265.
Train: 2018-08-01T01:01:06.449492: step 17653, loss 0.562433.
Train: 2018-08-01T01:01:06.605705: step 17654, loss 0.614904.
Train: 2018-08-01T01:01:06.761919: step 17655, loss 0.562439.
Train: 2018-08-01T01:01:06.918130: step 17656, loss 0.579939.
Train: 2018-08-01T01:01:07.074315: step 17657, loss 0.509951.
Train: 2018-08-01T01:01:07.230529: step 17658, loss 0.527431.
Train: 2018-08-01T01:01:07.386772: step 17659, loss 0.579969.
Train: 2018-08-01T01:01:07.542956: step 17660, loss 0.509858.
Test: 2018-08-01T01:01:08.011614: step 17660, loss 0.547759.
Train: 2018-08-01T01:01:08.183458: step 17661, loss 0.615103.
Train: 2018-08-01T01:01:08.339643: step 17662, loss 0.650222.
Train: 2018-08-01T01:01:08.480266: step 17663, loss 0.544915.
Train: 2018-08-01T01:01:08.652100: step 17664, loss 0.579969.
Train: 2018-08-01T01:01:08.808318: step 17665, loss 0.684976.
Train: 2018-08-01T01:01:08.964527: step 17666, loss 0.667193.
Train: 2018-08-01T01:01:09.136332: step 17667, loss 0.579813.
Train: 2018-08-01T01:01:09.292546: step 17668, loss 0.631735.
Train: 2018-08-01T01:01:09.448759: step 17669, loss 0.510625.
Train: 2018-08-01T01:01:09.604973: step 17670, loss 0.510786.
Test: 2018-08-01T01:01:10.073643: step 17670, loss 0.548021.
Train: 2018-08-01T01:01:10.245479: step 17671, loss 0.510896.
Train: 2018-08-01T01:01:10.401662: step 17672, loss 0.545251.
Train: 2018-08-01T01:01:10.557875: step 17673, loss 0.613786.
Train: 2018-08-01T01:01:10.714118: step 17674, loss 0.562397.
Train: 2018-08-01T01:01:10.870302: step 17675, loss 0.494073.
Train: 2018-08-01T01:01:11.026545: step 17676, loss 0.528245.
Train: 2018-08-01T01:01:11.182762: step 17677, loss 0.545317.
Train: 2018-08-01T01:01:11.338960: step 17678, loss 0.476951.
Train: 2018-08-01T01:01:11.495186: step 17679, loss 0.579513.
Train: 2018-08-01T01:01:11.651398: step 17680, loss 0.562396.
Test: 2018-08-01T01:01:12.120038: step 17680, loss 0.548029.
Train: 2018-08-01T01:01:12.276222: step 17681, loss 0.510925.
Train: 2018-08-01T01:01:12.463678: step 17682, loss 0.459279.
Train: 2018-08-01T01:01:12.619891: step 17683, loss 0.45898.
Train: 2018-08-01T01:01:12.760508: step 17684, loss 0.562404.
Train: 2018-08-01T01:01:12.932352: step 17685, loss 0.57978.
Train: 2018-08-01T01:01:13.088533: step 17686, loss 0.597258.
Train: 2018-08-01T01:01:13.244775: step 17687, loss 0.59734.
Train: 2018-08-01T01:01:13.400988: step 17688, loss 0.492518.
Train: 2018-08-01T01:01:13.557197: step 17689, loss 0.544929.
Train: 2018-08-01T01:01:13.713385: step 17690, loss 0.667771.
Test: 2018-08-01T01:01:14.182059: step 17690, loss 0.547754.
Train: 2018-08-01T01:01:14.338264: step 17691, loss 0.509779.
Train: 2018-08-01T01:01:14.510073: step 17692, loss 0.667926.
Train: 2018-08-01T01:01:14.681942: step 17693, loss 0.527326.
Train: 2018-08-01T01:01:14.838122: step 17694, loss 0.544894.
Train: 2018-08-01T01:01:14.994335: step 17695, loss 0.597592.
Train: 2018-08-01T01:01:15.150548: step 17696, loss 0.580015.
Train: 2018-08-01T01:01:15.306762: step 17697, loss 0.527364.
Train: 2018-08-01T01:01:15.462975: step 17698, loss 0.597532.
Train: 2018-08-01T01:01:15.619220: step 17699, loss 0.615028.
Train: 2018-08-01T01:01:15.791025: step 17700, loss 0.597444.
Test: 2018-08-01T01:01:16.275285: step 17700, loss 0.547805.
Train: 2018-08-01T01:01:17.009490: step 17701, loss 0.544964.
Train: 2018-08-01T01:01:17.181323: step 17702, loss 0.510097.
Train: 2018-08-01T01:01:17.337536: step 17703, loss 0.579856.
Train: 2018-08-01T01:01:17.493781: step 17704, loss 0.579838.
Train: 2018-08-01T01:01:17.649988: step 17705, loss 0.597212.
Train: 2018-08-01T01:01:17.806178: step 17706, loss 0.492929.
Train: 2018-08-01T01:01:17.993664: step 17707, loss 0.527685.
Train: 2018-08-01T01:01:18.149877: step 17708, loss 0.579776.
Train: 2018-08-01T01:01:18.306060: step 17709, loss 0.510333.
Train: 2018-08-01T01:01:18.462305: step 17710, loss 0.492944.
Test: 2018-08-01T01:01:18.946560: step 17710, loss 0.547855.
Train: 2018-08-01T01:01:19.102748: step 17711, loss 0.597196.
Train: 2018-08-01T01:01:19.258961: step 17712, loss 0.458013.
Train: 2018-08-01T01:01:19.430797: step 17713, loss 0.667033.
Train: 2018-08-01T01:01:19.587011: step 17714, loss 0.544987.
Train: 2018-08-01T01:01:19.743224: step 17715, loss 0.649666.
Train: 2018-08-01T01:01:19.915083: step 17716, loss 0.510124.
Train: 2018-08-01T01:01:20.071273: step 17717, loss 0.492696.
Train: 2018-08-01T01:01:20.227521: step 17718, loss 0.562428.
Train: 2018-08-01T01:01:20.383730: step 17719, loss 0.597347.
Train: 2018-08-01T01:01:20.555567: step 17720, loss 0.579891.
Test: 2018-08-01T01:01:21.024172: step 17720, loss 0.547813.
Train: 2018-08-01T01:01:21.196009: step 17721, loss 0.527518.
Train: 2018-08-01T01:01:21.352223: step 17722, loss 0.492591.
Train: 2018-08-01T01:01:21.524086: step 17723, loss 0.457562.
Train: 2018-08-01T01:01:21.680304: step 17724, loss 0.509889.
Train: 2018-08-01T01:01:21.820887: step 17725, loss 0.597592.
Train: 2018-08-01T01:01:21.992697: step 17726, loss 0.58007.
Train: 2018-08-01T01:01:22.148910: step 17727, loss 0.580103.
Train: 2018-08-01T01:01:22.305158: step 17728, loss 0.509565.
Train: 2018-08-01T01:01:22.476988: step 17729, loss 0.597826.
Train: 2018-08-01T01:01:22.633201: step 17730, loss 0.633214.
Test: 2018-08-01T01:01:23.101812: step 17730, loss 0.547699.
Train: 2018-08-01T01:01:23.258056: step 17731, loss 0.597843.
Train: 2018-08-01T01:01:23.445481: step 17732, loss 0.58015.
Train: 2018-08-01T01:01:23.586073: step 17733, loss 0.668318.
Train: 2018-08-01T01:01:23.742286: step 17734, loss 0.632854.
Train: 2018-08-01T01:01:23.898531: step 17735, loss 0.544912.
Train: 2018-08-01T01:01:24.054748: step 17736, loss 0.544947.
Train: 2018-08-01T01:01:24.210964: step 17737, loss 0.457714.
Train: 2018-08-01T01:01:24.367142: step 17738, loss 0.649627.
Train: 2018-08-01T01:01:24.539008: step 17739, loss 0.545012.
Train: 2018-08-01T01:01:24.695188: step 17740, loss 0.614561.
Test: 2018-08-01T01:01:25.179484: step 17740, loss 0.547884.
Train: 2018-08-01T01:01:25.335664: step 17741, loss 0.527718.
Train: 2018-08-01T01:01:25.507526: step 17742, loss 0.562406.
Train: 2018-08-01T01:01:25.679367: step 17743, loss 0.579701.
Train: 2018-08-01T01:01:25.835576: step 17744, loss 0.700582.
Train: 2018-08-01T01:01:25.976169: step 17745, loss 0.579615.
Train: 2018-08-01T01:01:26.147973: step 17746, loss 0.562396.
Train: 2018-08-01T01:01:26.304221: step 17747, loss 0.562397.
Train: 2018-08-01T01:01:26.460425: step 17748, loss 0.511185.
Train: 2018-08-01T01:01:26.632263: step 17749, loss 0.630578.
Train: 2018-08-01T01:01:26.804095: step 17750, loss 0.477383.
Test: 2018-08-01T01:01:27.288332: step 17750, loss 0.54818.
Train: 2018-08-01T01:01:27.444576: step 17751, loss 0.579396.
Train: 2018-08-01T01:01:27.600788: step 17752, loss 0.766068.
Train: 2018-08-01T01:01:27.803870: step 17753, loss 0.494786.
Train: 2018-08-01T01:01:27.944458: step 17754, loss 0.528691.
Train: 2018-08-01T01:01:28.100672: step 17755, loss 0.545593.
Train: 2018-08-01T01:01:28.256856: step 17756, loss 0.545617.
Train: 2018-08-01T01:01:28.413099: step 17757, loss 0.478394.
Train: 2018-08-01T01:01:28.569283: step 17758, loss 0.596079.
Train: 2018-08-01T01:01:28.725525: step 17759, loss 0.526553.
Train: 2018-08-01T01:01:28.897360: step 17760, loss 0.629769.
Test: 2018-08-01T01:01:29.366000: step 17760, loss 0.548346.
Train: 2018-08-01T01:01:29.522184: step 17761, loss 0.52878.
Train: 2018-08-01T01:01:29.678431: step 17762, loss 0.579269.
Train: 2018-08-01T01:01:29.834640: step 17763, loss 0.562436.
Train: 2018-08-01T01:01:30.006471: step 17764, loss 0.596108.
Train: 2018-08-01T01:01:30.147075: step 17765, loss 0.612931.
Train: 2018-08-01T01:01:30.303251: step 17766, loss 0.461546.
Train: 2018-08-01T01:01:30.459464: step 17767, loss 0.663399.
Train: 2018-08-01T01:01:30.615678: step 17768, loss 0.495186.
Train: 2018-08-01T01:01:30.771891: step 17769, loss 0.56244.
Train: 2018-08-01T01:01:30.928104: step 17770, loss 0.612913.
Test: 2018-08-01T01:01:31.381123: step 17770, loss 0.548356.
Train: 2018-08-01T01:01:31.537367: step 17771, loss 0.579259.
Train: 2018-08-01T01:01:31.709171: step 17772, loss 0.545631.
Train: 2018-08-01T01:01:31.865416: step 17773, loss 0.545634.
Train: 2018-08-01T01:01:32.021598: step 17774, loss 0.478382.
Train: 2018-08-01T01:01:32.177811: step 17775, loss 0.579271.
Train: 2018-08-01T01:01:32.334025: step 17776, loss 0.646703.
Train: 2018-08-01T01:01:32.490238: step 17777, loss 0.54558.
Train: 2018-08-01T01:01:32.662104: step 17778, loss 0.528722.
Train: 2018-08-01T01:01:32.802699: step 17779, loss 0.613027.
Train: 2018-08-01T01:01:32.958909: step 17780, loss 0.596159.
Test: 2018-08-01T01:01:33.443142: step 17780, loss 0.548314.
Train: 2018-08-01T01:01:33.583763: step 17781, loss 0.663574.
Train: 2018-08-01T01:01:33.739977: step 17782, loss 0.612919.
Train: 2018-08-01T01:01:33.911814: step 17783, loss 0.495294.
Train: 2018-08-01T01:01:34.052398: step 17784, loss 0.595996.
Train: 2018-08-01T01:01:34.208616: step 17785, loss 0.579209.
Train: 2018-08-01T01:01:34.380420: step 17786, loss 0.612645.
Train: 2018-08-01T01:01:34.536664: step 17787, loss 0.612562.
Train: 2018-08-01T01:01:34.692847: step 17788, loss 0.595804.
Train: 2018-08-01T01:01:34.849091: step 17789, loss 0.56251.
Train: 2018-08-01T01:01:35.005304: step 17790, loss 0.562525.
Test: 2018-08-01T01:01:35.473944: step 17790, loss 0.548682.
Train: 2018-08-01T01:01:35.630127: step 17791, loss 0.612183.
Train: 2018-08-01T01:01:35.786341: step 17792, loss 0.480005.
Train: 2018-08-01T01:01:35.942586: step 17793, loss 0.546064.
Train: 2018-08-01T01:01:36.098768: step 17794, loss 0.562565.
Train: 2018-08-01T01:01:36.254982: step 17795, loss 0.595552.
Train: 2018-08-01T01:01:36.426851: step 17796, loss 0.628511.
Train: 2018-08-01T01:01:36.598652: step 17797, loss 0.579046.
Train: 2018-08-01T01:01:36.754865: step 17798, loss 0.661254.
Train: 2018-08-01T01:01:36.911077: step 17799, loss 0.513407.
Train: 2018-08-01T01:01:37.067291: step 17800, loss 0.497105.
Test: 2018-08-01T01:01:37.551574: step 17800, loss 0.548914.
Train: 2018-08-01T01:01:38.270159: step 17801, loss 0.52987.
Train: 2018-08-01T01:01:38.426382: step 17802, loss 0.562624.
Train: 2018-08-01T01:01:38.582592: step 17803, loss 0.693817.
Train: 2018-08-01T01:01:38.754396: step 17804, loss 0.52987.
Train: 2018-08-01T01:01:38.910642: step 17805, loss 0.579006.
Train: 2018-08-01T01:01:39.066855: step 17806, loss 0.529912.
Train: 2018-08-01T01:01:39.223067: step 17807, loss 0.497171.
Train: 2018-08-01T01:01:39.379281: step 17808, loss 0.562625.
Train: 2018-08-01T01:01:39.535498: step 17809, loss 0.546202.
Train: 2018-08-01T01:01:39.691707: step 17810, loss 0.595468.
Test: 2018-08-01T01:01:40.160317: step 17810, loss 0.54881.
Train: 2018-08-01T01:01:40.316555: step 17811, loss 0.562588.
Train: 2018-08-01T01:01:40.472774: step 17812, loss 0.595519.
Train: 2018-08-01T01:01:40.628958: step 17813, loss 0.513129.
Train: 2018-08-01T01:01:40.785204: step 17814, loss 0.694596.
Train: 2018-08-01T01:01:40.988279: step 17815, loss 0.496584.
Train: 2018-08-01T01:01:41.128870: step 17816, loss 0.480034.
Train: 2018-08-01T01:01:41.285084: step 17817, loss 0.595617.
Train: 2018-08-01T01:01:41.441297: step 17818, loss 0.579093.
Train: 2018-08-01T01:01:41.597481: step 17819, loss 0.496223.
Train: 2018-08-01T01:01:41.753724: step 17820, loss 0.595731.
Test: 2018-08-01T01:01:42.237986: step 17820, loss 0.548573.
Train: 2018-08-01T01:01:42.409821: step 17821, loss 0.662304.
Train: 2018-08-01T01:01:42.566030: step 17822, loss 0.512604.
Train: 2018-08-01T01:01:42.722217: step 17823, loss 0.545851.
Train: 2018-08-01T01:01:42.878430: step 17824, loss 0.529164.
Train: 2018-08-01T01:01:43.034680: step 17825, loss 0.645921.
Train: 2018-08-01T01:01:43.206479: step 17826, loss 0.595863.
Train: 2018-08-01T01:01:43.378318: step 17827, loss 0.56248.
Train: 2018-08-01T01:01:43.534527: step 17828, loss 0.529106.
Train: 2018-08-01T01:01:43.690742: step 17829, loss 0.545782.
Train: 2018-08-01T01:01:43.846954: step 17830, loss 0.545764.
Test: 2018-08-01T01:01:44.315619: step 17830, loss 0.548461.
Train: 2018-08-01T01:01:44.471808: step 17831, loss 0.646097.
Train: 2018-08-01T01:01:44.628022: step 17832, loss 0.646081.
Train: 2018-08-01T01:01:44.784234: step 17833, loss 0.579177.
Train: 2018-08-01T01:01:44.940447: step 17834, loss 0.579162.
Train: 2018-08-01T01:01:45.096661: step 17835, loss 0.662426.
Train: 2018-08-01T01:01:45.268521: step 17836, loss 0.56251.
Train: 2018-08-01T01:01:45.424710: step 17837, loss 0.595677.
Train: 2018-08-01T01:01:45.580954: step 17838, loss 0.529473.
Train: 2018-08-01T01:01:45.737161: step 17839, loss 0.595578.
Train: 2018-08-01T01:01:45.893350: step 17840, loss 0.562573.
Test: 2018-08-01T01:01:46.362022: step 17840, loss 0.548805.
Train: 2018-08-01T01:01:46.533857: step 17841, loss 0.595499.
Train: 2018-08-01T01:01:46.674451: step 17842, loss 0.628317.
Train: 2018-08-01T01:01:46.830661: step 17843, loss 0.611794.
Train: 2018-08-01T01:01:46.986874: step 17844, loss 0.628034.
Train: 2018-08-01T01:01:47.158711: step 17845, loss 0.530102.
Train: 2018-08-01T01:01:47.314922: step 17846, loss 0.530203.
Train: 2018-08-01T01:01:47.471105: step 17847, loss 0.627654.
Train: 2018-08-01T01:01:47.627319: step 17848, loss 0.57895.
Train: 2018-08-01T01:01:47.783532: step 17849, loss 0.595109.
Train: 2018-08-01T01:01:47.939745: step 17850, loss 0.562803.
Test: 2018-08-01T01:01:48.408416: step 17850, loss 0.549338.
Train: 2018-08-01T01:01:48.580258: step 17851, loss 0.659459.
Train: 2018-08-01T01:01:48.736467: step 17852, loss 0.530742.
Train: 2018-08-01T01:01:48.892648: step 17853, loss 0.530825.
Train: 2018-08-01T01:01:49.048894: step 17854, loss 0.498832.
Train: 2018-08-01T01:01:49.205106: step 17855, loss 0.626991.
Train: 2018-08-01T01:01:49.361287: step 17856, loss 0.530865.
Train: 2018-08-01T01:01:49.533155: step 17857, loss 0.514825.
Train: 2018-08-01T01:01:49.689337: step 17858, loss 0.562877.
Train: 2018-08-01T01:01:49.845580: step 17859, loss 0.594991.
Train: 2018-08-01T01:01:50.017383: step 17860, loss 0.530679.
Test: 2018-08-01T01:01:50.470433: step 17860, loss 0.549334.
Train: 2018-08-01T01:01:50.626647: step 17861, loss 0.466173.
Train: 2018-08-01T01:01:50.798452: step 17862, loss 0.578941.
Train: 2018-08-01T01:01:50.939073: step 17863, loss 0.416916.
Train: 2018-08-01T01:01:51.095256: step 17864, loss 0.611541.
Train: 2018-08-01T01:01:51.251471: step 17865, loss 0.52996.
Train: 2018-08-01T01:01:51.407714: step 17866, loss 0.562611.
Train: 2018-08-01T01:01:51.563927: step 17867, loss 0.529628.
Train: 2018-08-01T01:01:51.720111: step 17868, loss 0.579083.
Train: 2018-08-01T01:01:51.891970: step 17869, loss 0.579115.
Train: 2018-08-01T01:01:52.048192: step 17870, loss 0.545848.
Test: 2018-08-01T01:01:52.516798: step 17870, loss 0.548494.
Train: 2018-08-01T01:01:52.673013: step 17871, loss 0.645968.
Train: 2018-08-01T01:01:52.829255: step 17872, loss 0.478845.
Train: 2018-08-01T01:01:53.001090: step 17873, loss 0.562453.
Train: 2018-08-01T01:01:53.157304: step 17874, loss 0.495193.
Train: 2018-08-01T01:01:53.313487: step 17875, loss 0.562428.
Train: 2018-08-01T01:01:53.469701: step 17876, loss 0.613171.
Train: 2018-08-01T01:01:53.625945: step 17877, loss 0.477653.
Train: 2018-08-01T01:01:53.782158: step 17878, loss 0.613415.
Train: 2018-08-01T01:01:53.938340: step 17879, loss 0.562401.
Train: 2018-08-01T01:01:54.110175: step 17880, loss 0.647748.
Test: 2018-08-01T01:01:54.594467: step 17880, loss 0.548097.
Train: 2018-08-01T01:01:54.750681: step 17881, loss 0.562398.
Train: 2018-08-01T01:01:54.906894: step 17882, loss 0.630742.
Train: 2018-08-01T01:01:55.063078: step 17883, loss 0.61363.
Train: 2018-08-01T01:01:55.234912: step 17884, loss 0.596514.
Train: 2018-08-01T01:01:55.391156: step 17885, loss 0.511307.
Train: 2018-08-01T01:01:55.547340: step 17886, loss 0.460277.
Train: 2018-08-01T01:01:55.703583: step 17887, loss 0.630546.
Train: 2018-08-01T01:01:55.859765: step 17888, loss 0.579436.
Train: 2018-08-01T01:01:56.015978: step 17889, loss 0.613487.
Train: 2018-08-01T01:01:56.172226: step 17890, loss 0.579416.
Test: 2018-08-01T01:01:56.640863: step 17890, loss 0.548177.
Train: 2018-08-01T01:01:56.812667: step 17891, loss 0.647371.
Train: 2018-08-01T01:01:56.968912: step 17892, loss 0.562411.
Train: 2018-08-01T01:01:57.125095: step 17893, loss 0.545493.
Train: 2018-08-01T01:01:57.296958: step 17894, loss 0.545522.
Train: 2018-08-01T01:01:57.453167: step 17895, loss 0.562425.
Train: 2018-08-01T01:01:57.609387: step 17896, loss 0.461219.
Train: 2018-08-01T01:01:57.765569: step 17897, loss 0.494904.
Train: 2018-08-01T01:01:57.937429: step 17898, loss 0.511694.
Train: 2018-08-01T01:01:58.077996: step 17899, loss 0.579359.
Train: 2018-08-01T01:01:58.234209: step 17900, loss 0.613341.
Test: 2018-08-01T01:01:58.702880: step 17900, loss 0.548176.
Train: 2018-08-01T01:01:59.390190: step 17901, loss 0.5794.
Train: 2018-08-01T01:01:59.562025: step 17902, loss 0.630425.
Train: 2018-08-01T01:01:59.718237: step 17903, loss 0.494408.
Train: 2018-08-01T01:01:59.874481: step 17904, loss 0.528382.
Train: 2018-08-01T01:02:00.030664: step 17905, loss 0.579432.
Train: 2018-08-01T01:02:00.186908: step 17906, loss 0.579444.
Train: 2018-08-01T01:02:00.343121: step 17907, loss 0.511245.
Train: 2018-08-01T01:02:00.514950: step 17908, loss 0.630685.
Train: 2018-08-01T01:02:00.671140: step 17909, loss 0.528251.
Train: 2018-08-01T01:02:00.827383: step 17910, loss 0.562398.
Test: 2018-08-01T01:02:01.311614: step 17910, loss 0.548083.
Train: 2018-08-01T01:02:01.467829: step 17911, loss 0.511117.
Train: 2018-08-01T01:02:01.624071: step 17912, loss 0.511054.
Train: 2018-08-01T01:02:01.795909: step 17913, loss 0.613832.
Train: 2018-08-01T01:02:01.952121: step 17914, loss 0.545234.
Train: 2018-08-01T01:02:02.108327: step 17915, loss 0.493677.
Train: 2018-08-01T01:02:02.264517: step 17916, loss 0.562397.
Train: 2018-08-01T01:02:02.420730: step 17917, loss 0.596882.
Train: 2018-08-01T01:02:02.592595: step 17918, loss 0.510621.
Train: 2018-08-01T01:02:02.748808: step 17919, loss 0.596978.
Train: 2018-08-01T01:02:02.920646: step 17920, loss 0.683535.
Test: 2018-08-01T01:02:03.404874: step 17920, loss 0.547924.
Train: 2018-08-01T01:02:03.561118: step 17921, loss 0.596984.
Train: 2018-08-01T01:02:03.732923: step 17922, loss 0.458784.
Train: 2018-08-01T01:02:03.889169: step 17923, loss 0.562401.
Train: 2018-08-01T01:02:04.045383: step 17924, loss 0.527844.
Train: 2018-08-01T01:02:04.201592: step 17925, loss 0.493242.
Train: 2018-08-01T01:02:04.357806: step 17926, loss 0.579722.
Train: 2018-08-01T01:02:04.514020: step 17927, loss 0.510402.
Train: 2018-08-01T01:02:04.685854: step 17928, loss 0.614505.
Train: 2018-08-01T01:02:04.842068: step 17929, loss 0.562414.
Train: 2018-08-01T01:02:05.029519: step 17930, loss 0.545028.
Test: 2018-08-01T01:02:05.498164: step 17930, loss 0.547847.
Train: 2018-08-01T01:02:05.654377: step 17931, loss 0.545017.
Train: 2018-08-01T01:02:05.810590: step 17932, loss 0.75401.
Train: 2018-08-01T01:02:05.966804: step 17933, loss 0.54503.
Train: 2018-08-01T01:02:06.138610: step 17934, loss 0.562412.
Train: 2018-08-01T01:02:06.294846: step 17935, loss 0.683766.
Train: 2018-08-01T01:02:06.451060: step 17936, loss 0.614263.
Train: 2018-08-01T01:02:06.607249: step 17937, loss 0.49348.
Train: 2018-08-01T01:02:06.763488: step 17938, loss 0.682752.
Train: 2018-08-01T01:02:06.919676: step 17939, loss 0.476731.
Train: 2018-08-01T01:02:07.075920: step 17940, loss 0.579496.
Test: 2018-08-01T01:02:07.544563: step 17940, loss 0.54811.
Train: 2018-08-01T01:02:07.716365: step 17941, loss 0.511206.
Train: 2018-08-01T01:02:07.872578: step 17942, loss 0.579446.
Train: 2018-08-01T01:02:08.028825: step 17943, loss 0.545378.
Train: 2018-08-01T01:02:08.185034: step 17944, loss 0.460339.
Train: 2018-08-01T01:02:08.341249: step 17945, loss 0.54538.
Train: 2018-08-01T01:02:08.513083: step 17946, loss 0.562401.
Train: 2018-08-01T01:02:08.669266: step 17947, loss 0.596505.
Train: 2018-08-01T01:02:08.825511: step 17948, loss 0.698859.
Train: 2018-08-01T01:02:08.981693: step 17949, loss 0.477253.
Train: 2018-08-01T01:02:09.137906: step 17950, loss 0.664556.
Test: 2018-08-01T01:02:09.606576: step 17950, loss 0.548171.
Train: 2018-08-01T01:02:09.762761: step 17951, loss 0.545407.
Train: 2018-08-01T01:02:09.918974: step 17952, loss 0.562408.
Train: 2018-08-01T01:02:10.075217: step 17953, loss 0.51153.
Train: 2018-08-01T01:02:10.247052: step 17954, loss 0.562411.
Train: 2018-08-01T01:02:10.403236: step 17955, loss 0.579366.
Train: 2018-08-01T01:02:10.575069: step 17956, loss 0.545463.
Train: 2018-08-01T01:02:10.715693: step 17957, loss 0.613259.
Train: 2018-08-01T01:02:10.871875: step 17958, loss 0.477728.
Train: 2018-08-01T01:02:11.028088: step 17959, loss 0.528517.
Train: 2018-08-01T01:02:11.184302: step 17960, loss 0.613307.
Test: 2018-08-01T01:02:11.668598: step 17960, loss 0.548198.
Train: 2018-08-01T01:02:11.824778: step 17961, loss 0.59635.
Train: 2018-08-01T01:02:11.996623: step 17962, loss 0.494541.
Train: 2018-08-01T01:02:12.137204: step 17963, loss 0.630332.
Train: 2018-08-01T01:02:12.293417: step 17964, loss 0.596364.
Train: 2018-08-01T01:02:12.449661: step 17965, loss 0.596345.
Train: 2018-08-01T01:02:12.605874: step 17966, loss 0.579363.
Train: 2018-08-01T01:02:12.793325: step 17967, loss 0.511619.
Train: 2018-08-01T01:02:12.949545: step 17968, loss 0.647057.
Train: 2018-08-01T01:02:13.105751: step 17969, loss 0.494799.
Train: 2018-08-01T01:02:13.277586: step 17970, loss 0.562421.
Test: 2018-08-01T01:02:13.746230: step 17970, loss 0.548271.
Train: 2018-08-01T01:02:13.933683: step 17971, loss 0.613118.
Train: 2018-08-01T01:02:14.089902: step 17972, loss 0.629965.
Train: 2018-08-01T01:02:14.246110: step 17973, loss 0.478142.
Train: 2018-08-01T01:02:14.402298: step 17974, loss 0.596139.
Train: 2018-08-01T01:02:14.558512: step 17975, loss 0.49506.
Train: 2018-08-01T01:02:14.714755: step 17976, loss 0.579283.
Train: 2018-08-01T01:02:14.886561: step 17977, loss 0.596141.
Train: 2018-08-01T01:02:15.042773: step 17978, loss 0.562432.
Train: 2018-08-01T01:02:15.198988: step 17979, loss 0.59613.
Train: 2018-08-01T01:02:15.339579: step 17980, loss 0.495075.
Test: 2018-08-01T01:02:15.823841: step 17980, loss 0.548324.
Train: 2018-08-01T01:02:15.995675: step 17981, loss 0.579281.
Train: 2018-08-01T01:02:16.136267: step 17982, loss 0.629845.
Train: 2018-08-01T01:02:16.308102: step 17983, loss 0.612962.
Train: 2018-08-01T01:02:16.448725: step 17984, loss 0.612904.
Train: 2018-08-01T01:02:16.620561: step 17985, loss 0.562447.
Train: 2018-08-01T01:02:16.839228: step 17986, loss 0.562455.
Train: 2018-08-01T01:02:16.995472: step 17987, loss 0.478743.
Train: 2018-08-01T01:02:17.167276: step 17988, loss 0.595952.
Train: 2018-08-01T01:02:17.323514: step 17989, loss 0.445281.
Train: 2018-08-01T01:02:17.479704: step 17990, loss 0.512159.
Test: 2018-08-01T01:02:17.948344: step 17990, loss 0.548375.
Train: 2018-08-01T01:02:18.104587: step 17991, loss 0.49524.
Train: 2018-08-01T01:02:18.276419: step 17992, loss 0.51188.
Train: 2018-08-01T01:02:18.432604: step 17993, loss 0.528602.
Train: 2018-08-01T01:02:18.604464: step 17994, loss 0.460593.
Train: 2018-08-01T01:02:18.760691: step 17995, loss 0.545351.
Train: 2018-08-01T01:02:18.916891: step 17996, loss 0.545271.
Train: 2018-08-01T01:02:19.073080: step 17997, loss 0.545198.
Train: 2018-08-01T01:02:19.229324: step 17998, loss 0.510599.
Train: 2018-08-01T01:02:19.416783: step 17999, loss 0.57975.
Train: 2018-08-01T01:02:19.572992: step 18000, loss 0.423189.
Test: 2018-08-01T01:02:20.041637: step 18000, loss 0.547792.
Train: 2018-08-01T01:02:20.713352: step 18001, loss 0.509965.
Train: 2018-08-01T01:02:20.885187: step 18002, loss 0.544883.
Train: 2018-08-01T01:02:21.041403: step 18003, loss 0.58016.
Train: 2018-08-01T01:02:21.197584: step 18004, loss 0.47385.
Train: 2018-08-01T01:02:21.353821: step 18005, loss 0.473482.
Train: 2018-08-01T01:02:21.525664: step 18006, loss 0.562611.
Train: 2018-08-01T01:02:21.681874: step 18007, loss 0.544671.
Train: 2018-08-01T01:02:21.838087: step 18008, loss 0.490464.
Train: 2018-08-01T01:02:21.994271: step 18009, loss 0.580904.
Train: 2018-08-01T01:02:22.150514: step 18010, loss 0.453584.
Test: 2018-08-01T01:02:22.619124: step 18010, loss 0.547568.
Train: 2018-08-01T01:02:22.759716: step 18011, loss 0.636015.
Train: 2018-08-01T01:02:22.915931: step 18012, loss 0.471245.
Train: 2018-08-01T01:02:23.087766: step 18013, loss 0.599778.
Train: 2018-08-01T01:02:23.243979: step 18014, loss 0.489249.
Train: 2018-08-01T01:02:23.400221: step 18015, loss 0.637061.
Train: 2018-08-01T01:02:23.556405: step 18016, loss 0.507533.
Train: 2018-08-01T01:02:23.743891: step 18017, loss 0.618804.
Train: 2018-08-01T01:02:23.900074: step 18018, loss 0.526013.
Train: 2018-08-01T01:02:24.056319: step 18019, loss 0.43308.
Train: 2018-08-01T01:02:24.212531: step 18020, loss 0.488721.
Test: 2018-08-01T01:02:24.681172: step 18020, loss 0.547627.
Train: 2018-08-01T01:02:24.868633: step 18021, loss 0.525924.
Train: 2018-08-01T01:02:25.024811: step 18022, loss 0.451038.
Train: 2018-08-01T01:02:25.181024: step 18023, loss 0.582153.
Train: 2018-08-01T01:02:25.337237: step 18024, loss 0.619886.
Train: 2018-08-01T01:02:25.493451: step 18025, loss 0.525785.
Train: 2018-08-01T01:02:25.649664: step 18026, loss 0.48804.
Train: 2018-08-01T01:02:25.790257: step 18027, loss 0.487952.
Train: 2018-08-01T01:02:25.977712: step 18028, loss 0.677209.
Train: 2018-08-01T01:02:26.133957: step 18029, loss 0.696199.
Train: 2018-08-01T01:02:26.290174: step 18030, loss 0.525731.
Test: 2018-08-01T01:02:26.758810: step 18030, loss 0.547712.
Train: 2018-08-01T01:02:26.930615: step 18031, loss 0.639104.
Train: 2018-08-01T01:02:27.102480: step 18032, loss 0.620034.
Train: 2018-08-01T01:02:27.258663: step 18033, loss 0.469427.
Train: 2018-08-01T01:02:27.414877: step 18034, loss 0.544607.
Train: 2018-08-01T01:02:27.586712: step 18035, loss 0.694456.
Train: 2018-08-01T01:02:27.742924: step 18036, loss 0.600604.
Train: 2018-08-01T01:02:27.899168: step 18037, loss 0.6376.
Train: 2018-08-01T01:02:28.055387: step 18038, loss 0.54458.
Train: 2018-08-01T01:02:28.227186: step 18039, loss 0.563028.
Train: 2018-08-01T01:02:28.383430: step 18040, loss 0.489447.
Test: 2018-08-01T01:02:28.867692: step 18040, loss 0.547569.
Train: 2018-08-01T01:02:29.023905: step 18041, loss 0.581245.
Train: 2018-08-01T01:02:29.195710: step 18042, loss 0.52632.
Train: 2018-08-01T01:02:29.351922: step 18043, loss 0.581067.
Train: 2018-08-01T01:02:29.508166: step 18044, loss 0.562798.
Train: 2018-08-01T01:02:29.664350: step 18045, loss 0.544623.
Train: 2018-08-01T01:02:29.820593: step 18046, loss 0.598939.
Train: 2018-08-01T01:02:29.976777: step 18047, loss 0.454369.
Train: 2018-08-01T01:02:30.132989: step 18048, loss 0.544654.
Train: 2018-08-01T01:02:30.304855: step 18049, loss 0.652772.
Train: 2018-08-01T01:02:30.461062: step 18050, loss 0.526693.
Test: 2018-08-01T01:02:30.929679: step 18050, loss 0.547604.
Train: 2018-08-01T01:02:31.085922: step 18051, loss 0.580589.
Train: 2018-08-01T01:02:31.242105: step 18052, loss 0.490938.
Train: 2018-08-01T01:02:31.413939: step 18053, loss 0.473085.
Train: 2018-08-01T01:02:31.570184: step 18054, loss 0.59843.
Train: 2018-08-01T01:02:31.741988: step 18055, loss 0.490998.
Train: 2018-08-01T01:02:31.898231: step 18056, loss 0.544702.
Train: 2018-08-01T01:02:32.054445: step 18057, loss 0.544698.
Train: 2018-08-01T01:02:32.210658: step 18058, loss 0.490907.
Train: 2018-08-01T01:02:32.366872: step 18059, loss 0.526733.
Train: 2018-08-01T01:02:32.538677: step 18060, loss 0.505124.
Test: 2018-08-01T01:02:33.007347: step 18060, loss 0.547591.
Train: 2018-08-01T01:02:33.163564: step 18061, loss 0.544663.
Train: 2018-08-01T01:02:33.319774: step 18062, loss 0.526608.
Train: 2018-08-01T01:02:33.475957: step 18063, loss 0.671182.
Train: 2018-08-01T01:02:33.647792: step 18064, loss 0.490397.
Train: 2018-08-01T01:02:33.804004: step 18065, loss 0.562732.
Train: 2018-08-01T01:02:33.960244: step 18066, loss 0.508413.
Train: 2018-08-01T01:02:34.132083: step 18067, loss 0.526497.
Train: 2018-08-01T01:02:34.288266: step 18068, loss 0.526466.
Train: 2018-08-01T01:02:34.444511: step 18069, loss 0.580989.
Train: 2018-08-01T01:02:34.600724: step 18070, loss 0.508216.
Test: 2018-08-01T01:02:35.069334: step 18070, loss 0.547568.
Train: 2018-08-01T01:02:35.225548: step 18071, loss 0.544599.
Train: 2018-08-01T01:02:35.381791: step 18072, loss 0.544627.
Train: 2018-08-01T01:02:35.538008: step 18073, loss 0.471479.
Train: 2018-08-01T01:02:35.694218: step 18074, loss 0.562933.
Train: 2018-08-01T01:02:35.866023: step 18075, loss 0.470628.
Train: 2018-08-01T01:02:36.022237: step 18076, loss 0.507799.
Train: 2018-08-01T01:02:36.178449: step 18077, loss 0.507365.
Train: 2018-08-01T01:02:36.334693: step 18078, loss 0.542231.
Train: 2018-08-01T01:02:36.506497: step 18079, loss 0.602938.
Train: 2018-08-01T01:02:36.662710: step 18080, loss 0.607449.
Test: 2018-08-01T01:02:37.131381: step 18080, loss 0.547802.
Train: 2018-08-01T01:02:37.287599: step 18081, loss 0.583504.
Train: 2018-08-01T01:02:37.443808: step 18082, loss 0.526762.
Train: 2018-08-01T01:02:37.600016: step 18083, loss 0.601103.
Train: 2018-08-01T01:02:37.756236: step 18084, loss 0.581433.
Train: 2018-08-01T01:02:37.912454: step 18085, loss 0.655615.
Train: 2018-08-01T01:02:38.084278: step 18086, loss 0.489188.
Train: 2018-08-01T01:02:38.240502: step 18087, loss 0.618527.
Train: 2018-08-01T01:02:38.396712: step 18088, loss 0.599747.
Train: 2018-08-01T01:02:38.568545: step 18089, loss 0.489577.
Train: 2018-08-01T01:02:38.724729: step 18090, loss 0.507981.
Test: 2018-08-01T01:02:39.193399: step 18090, loss 0.547568.
Train: 2018-08-01T01:02:39.349582: step 18091, loss 0.544594.
Train: 2018-08-01T01:02:39.505795: step 18092, loss 0.489789.
Train: 2018-08-01T01:02:39.662009: step 18093, loss 0.562864.
Train: 2018-08-01T01:02:39.818252: step 18094, loss 0.453291.
Train: 2018-08-01T01:02:39.974436: step 18095, loss 0.599428.
Train: 2018-08-01T01:02:40.146270: step 18096, loss 0.617717.
Train: 2018-08-01T01:02:40.302509: step 18097, loss 0.617667.
Train: 2018-08-01T01:02:40.458696: step 18098, loss 0.508122.
Train: 2018-08-01T01:02:40.614911: step 18099, loss 0.471708.
Train: 2018-08-01T01:02:40.771155: step 18100, loss 0.562832.
Test: 2018-08-01T01:02:41.255386: step 18100, loss 0.547569.
Train: 2018-08-01T01:02:41.942749: step 18101, loss 0.599285.
Train: 2018-08-01T01:02:42.098968: step 18102, loss 0.508178.
Train: 2018-08-01T01:02:42.255183: step 18103, loss 0.562821.
Train: 2018-08-01T01:02:42.427017: step 18104, loss 0.489986.
Train: 2018-08-01T01:02:42.598820: step 18105, loss 0.63569.
Train: 2018-08-01T01:02:42.755034: step 18106, loss 0.635633.
Train: 2018-08-01T01:02:42.895627: step 18107, loss 0.671838.
Train: 2018-08-01T01:02:43.051870: step 18108, loss 0.61711.
Train: 2018-08-01T01:02:43.208053: step 18109, loss 0.598816.
Train: 2018-08-01T01:02:43.379888: step 18110, loss 0.706555.
Test: 2018-08-01T01:02:43.848558: step 18110, loss 0.547622.
Train: 2018-08-01T01:02:44.067257: step 18111, loss 0.580493.
Train: 2018-08-01T01:02:44.223465: step 18112, loss 0.544757.
Train: 2018-08-01T01:02:44.395275: step 18113, loss 0.491658.
Train: 2018-08-01T01:02:44.551490: step 18114, loss 0.509526.
Train: 2018-08-01T01:02:44.723329: step 18115, loss 0.492013.
Train: 2018-08-01T01:02:44.879566: step 18116, loss 0.562467.
Train: 2018-08-01T01:02:45.035749: step 18117, loss 0.598163.
Train: 2018-08-01T01:02:45.191994: step 18118, loss 0.509803.
Train: 2018-08-01T01:02:45.348207: step 18119, loss 0.597488.
Train: 2018-08-01T01:02:45.504420: step 18120, loss 0.527448.
Test: 2018-08-01T01:02:45.988651: step 18120, loss 0.547799.
Train: 2018-08-01T01:02:46.144866: step 18121, loss 0.509992.
Train: 2018-08-01T01:02:46.301109: step 18122, loss 0.719762.
Train: 2018-08-01T01:02:46.441701: step 18123, loss 0.632195.
Train: 2018-08-01T01:02:46.613536: step 18124, loss 0.597197.
Train: 2018-08-01T01:02:46.769719: step 18125, loss 0.527744.
Train: 2018-08-01T01:02:46.925932: step 18126, loss 0.596987.
Train: 2018-08-01T01:02:47.082146: step 18127, loss 0.562401.
Train: 2018-08-01T01:02:47.238360: step 18128, loss 0.510796.
Train: 2018-08-01T01:02:47.394573: step 18129, loss 0.545224.
Train: 2018-08-01T01:02:47.550788: step 18130, loss 0.66533.
Test: 2018-08-01T01:02:48.019456: step 18130, loss 0.548069.
Train: 2018-08-01T01:02:48.175673: step 18131, loss 0.528173.
Train: 2018-08-01T01:02:48.331884: step 18132, loss 0.562401.
Train: 2018-08-01T01:02:48.488091: step 18133, loss 0.613574.
Train: 2018-08-01T01:02:48.644280: step 18134, loss 0.562406.
Train: 2018-08-01T01:02:48.800493: step 18135, loss 0.54542.
Train: 2018-08-01T01:02:48.972329: step 18136, loss 0.579379.
Train: 2018-08-01T01:02:49.128542: step 18137, loss 0.511594.
Train: 2018-08-01T01:02:49.284789: step 18138, loss 0.57935.
Train: 2018-08-01T01:02:49.440969: step 18139, loss 0.562421.
Train: 2018-08-01T01:02:49.597182: step 18140, loss 0.494786.
Test: 2018-08-01T01:02:50.065821: step 18140, loss 0.548255.
Train: 2018-08-01T01:02:50.222066: step 18141, loss 0.647007.
Train: 2018-08-01T01:02:50.393871: step 18142, loss 0.562424.
Train: 2018-08-01T01:02:50.550083: step 18143, loss 0.545532.
Train: 2018-08-01T01:02:50.690707: step 18144, loss 0.579317.
Train: 2018-08-01T01:02:50.862541: step 18145, loss 0.596194.
Train: 2018-08-01T01:02:51.018754: step 18146, loss 0.562431.
Train: 2018-08-01T01:02:51.190558: step 18147, loss 0.646721.
Train: 2018-08-01T01:02:51.346772: step 18148, loss 0.629751.
Train: 2018-08-01T01:02:51.502986: step 18149, loss 0.562453.
Train: 2018-08-01T01:02:51.670712: step 18150, loss 0.579212.
Test: 2018-08-01T01:02:52.139381: step 18150, loss 0.548481.
Train: 2018-08-01T01:02:52.311186: step 18151, loss 0.579189.
Train: 2018-08-01T01:02:52.483020: step 18152, loss 0.54581.
Train: 2018-08-01T01:02:52.639264: step 18153, loss 0.545846.
Train: 2018-08-01T01:02:52.795477: step 18154, loss 0.562505.
Train: 2018-08-01T01:02:52.951660: step 18155, loss 0.612371.
Train: 2018-08-01T01:02:53.107874: step 18156, loss 0.579117.
Train: 2018-08-01T01:02:53.264088: step 18157, loss 0.628825.
Train: 2018-08-01T01:02:53.435923: step 18158, loss 0.479858.
Train: 2018-08-01T01:02:53.592165: step 18159, loss 0.546024.
Train: 2018-08-01T01:02:53.748381: step 18160, loss 0.546028.
Test: 2018-08-01T01:02:54.216988: step 18160, loss 0.54871.
Train: 2018-08-01T01:02:54.373230: step 18161, loss 0.512963.
Train: 2018-08-01T01:02:54.545068: step 18162, loss 0.57909.
Train: 2018-08-01T01:02:54.701276: step 18163, loss 0.678465.
Train: 2018-08-01T01:02:54.857495: step 18164, loss 0.52945.
Train: 2018-08-01T01:02:55.013677: step 18165, loss 0.595633.
Train: 2018-08-01T01:02:55.169922: step 18166, loss 0.546014.
Train: 2018-08-01T01:02:55.326137: step 18167, loss 0.56255.
Train: 2018-08-01T01:02:55.482319: step 18168, loss 0.595617.
Train: 2018-08-01T01:02:55.638567: step 18169, loss 0.546024.
Train: 2018-08-01T01:02:55.794775: step 18170, loss 0.512966.
Test: 2018-08-01T01:02:56.263415: step 18170, loss 0.548691.
Train: 2018-08-01T01:02:56.435249: step 18171, loss 0.612176.
Train: 2018-08-01T01:02:56.607080: step 18172, loss 0.57909.
Train: 2018-08-01T01:02:56.747677: step 18173, loss 0.612186.
Train: 2018-08-01T01:02:56.903886: step 18174, loss 0.562548.
Train: 2018-08-01T01:02:57.060103: step 18175, loss 0.529489.
Train: 2018-08-01T01:02:57.216312: step 18176, loss 0.595619.
Train: 2018-08-01T01:02:57.372501: step 18177, loss 0.595615.
Train: 2018-08-01T01:02:57.528744: step 18178, loss 0.54603.
Train: 2018-08-01T01:02:57.700587: step 18179, loss 0.5956.
Train: 2018-08-01T01:02:57.856793: step 18180, loss 0.612103.
Test: 2018-08-01T01:02:58.325434: step 18180, loss 0.548752.
Train: 2018-08-01T01:02:58.497267: step 18181, loss 0.447083.
Train: 2018-08-01T01:02:58.653481: step 18182, loss 0.579073.
Train: 2018-08-01T01:02:58.809693: step 18183, loss 0.546029.
Train: 2018-08-01T01:02:58.965908: step 18184, loss 0.496378.
Train: 2018-08-01T01:02:59.122090: step 18185, loss 0.529379.
Train: 2018-08-01T01:02:59.278329: step 18186, loss 0.545897.
Train: 2018-08-01T01:02:59.434550: step 18187, loss 0.52918.
Train: 2018-08-01T01:02:59.590761: step 18188, loss 0.629296.
Train: 2018-08-01T01:02:59.746944: step 18189, loss 0.512341.
Train: 2018-08-01T01:02:59.918779: step 18190, loss 0.646317.
Test: 2018-08-01T01:03:00.387451: step 18190, loss 0.548394.
Train: 2018-08-01T01:03:00.559284: step 18191, loss 0.545664.
Train: 2018-08-01T01:03:00.699878: step 18192, loss 0.59606.
Train: 2018-08-01T01:03:00.856090: step 18193, loss 0.495176.
Train: 2018-08-01T01:03:01.027894: step 18194, loss 0.579281.
Train: 2018-08-01T01:03:01.184140: step 18195, loss 0.528703.
Train: 2018-08-01T01:03:01.340357: step 18196, loss 0.545534.
Train: 2018-08-01T01:03:01.496559: step 18197, loss 0.579344.
Train: 2018-08-01T01:03:01.652749: step 18198, loss 0.477684.
Train: 2018-08-01T01:03:01.808991: step 18199, loss 0.630369.
Train: 2018-08-01T01:03:01.965205: step 18200, loss 0.494362.
Test: 2018-08-01T01:03:02.433845: step 18200, loss 0.548129.
Train: 2018-08-01T01:03:03.089942: step 18201, loss 0.613552.
Train: 2018-08-01T01:03:03.277369: step 18202, loss 0.459982.
Train: 2018-08-01T01:03:03.433613: step 18203, loss 0.682204.
Train: 2018-08-01T01:03:03.589794: step 18204, loss 0.545276.
Train: 2018-08-01T01:03:03.746032: step 18205, loss 0.545262.
Train: 2018-08-01T01:03:03.917873: step 18206, loss 0.579558.
Train: 2018-08-01T01:03:04.074055: step 18207, loss 0.49373.
Train: 2018-08-01T01:03:04.230310: step 18208, loss 0.613985.
Train: 2018-08-01T01:03:04.402104: step 18209, loss 0.545197.
Train: 2018-08-01T01:03:04.558318: step 18210, loss 0.648503.
Test: 2018-08-01T01:03:05.026988: step 18210, loss 0.54799.
Train: 2018-08-01T01:03:05.183204: step 18211, loss 0.596827.
Train: 2018-08-01T01:03:05.355021: step 18212, loss 0.442028.
Train: 2018-08-01T01:03:05.526877: step 18213, loss 0.424716.
Train: 2018-08-01T01:03:05.683087: step 18214, loss 0.614175.
Train: 2018-08-01T01:03:05.839297: step 18215, loss 0.510553.
Train: 2018-08-01T01:03:05.995512: step 18216, loss 0.441154.
Train: 2018-08-01T01:03:06.151719: step 18217, loss 0.614575.
Train: 2018-08-01T01:03:06.307940: step 18218, loss 0.545003.
Train: 2018-08-01T01:03:06.495396: step 18219, loss 0.562439.
Train: 2018-08-01T01:03:06.651578: step 18220, loss 0.562448.
Test: 2018-08-01T01:03:07.120247: step 18220, loss 0.547772.
Train: 2018-08-01T01:03:07.276433: step 18221, loss 0.527383.
Train: 2018-08-01T01:03:07.432674: step 18222, loss 0.50975.
Train: 2018-08-01T01:03:07.604505: step 18223, loss 0.703409.
Train: 2018-08-01T01:03:07.760693: step 18224, loss 0.615345.
Train: 2018-08-01T01:03:07.916907: step 18225, loss 0.580091.
Train: 2018-08-01T01:03:08.073151: step 18226, loss 0.580072.
Train: 2018-08-01T01:03:08.229365: step 18227, loss 0.544891.
Train: 2018-08-01T01:03:08.385571: step 18228, loss 0.509771.
Train: 2018-08-01T01:03:08.557406: step 18229, loss 0.597592.
Train: 2018-08-01T01:03:08.729217: step 18230, loss 0.509803.
Test: 2018-08-01T01:03:09.213477: step 18230, loss 0.547762.
Train: 2018-08-01T01:03:09.369715: step 18231, loss 0.580016.
Train: 2018-08-01T01:03:09.525931: step 18232, loss 0.562461.
Train: 2018-08-01T01:03:09.682155: step 18233, loss 0.580005.
Train: 2018-08-01T01:03:09.869604: step 18234, loss 0.54492.
Train: 2018-08-01T01:03:10.010166: step 18235, loss 0.509864.
Train: 2018-08-01T01:03:10.166379: step 18236, loss 0.562456.
Train: 2018-08-01T01:03:10.322624: step 18237, loss 0.527377.
Train: 2018-08-01T01:03:10.478842: step 18238, loss 0.54491.
Train: 2018-08-01T01:03:10.635050: step 18239, loss 0.509774.
Train: 2018-08-01T01:03:10.806888: step 18240, loss 0.562471.
Test: 2018-08-01T01:03:11.275494: step 18240, loss 0.547736.
Train: 2018-08-01T01:03:11.431708: step 18241, loss 0.527268.
Train: 2018-08-01T01:03:11.603542: step 18242, loss 0.580114.
Train: 2018-08-01T01:03:11.759786: step 18243, loss 0.491915.
Train: 2018-08-01T01:03:11.931592: step 18244, loss 0.562503.
Train: 2018-08-01T01:03:12.087804: step 18245, loss 0.58021.
Train: 2018-08-01T01:03:12.244049: step 18246, loss 0.509377.
Train: 2018-08-01T01:03:12.400232: step 18247, loss 0.651228.
Train: 2018-08-01T01:03:12.556475: step 18248, loss 0.509311.
Train: 2018-08-01T01:03:12.712682: step 18249, loss 0.68679.
Train: 2018-08-01T01:03:12.868872: step 18250, loss 0.509337.
Test: 2018-08-01T01:03:13.321891: step 18250, loss 0.547683.
Train: 2018-08-01T01:03:13.478134: step 18251, loss 0.544801.
Train: 2018-08-01T01:03:13.649938: step 18252, loss 0.686535.
Train: 2018-08-01T01:03:13.806176: step 18253, loss 0.438736.
Train: 2018-08-01T01:03:13.962365: step 18254, loss 0.509473.
Train: 2018-08-01T01:03:14.118580: step 18255, loss 0.562506.
Train: 2018-08-01T01:03:14.274817: step 18256, loss 0.597884.
Train: 2018-08-01T01:03:14.431030: step 18257, loss 0.562506.
Train: 2018-08-01T01:03:14.602865: step 18258, loss 0.633203.
Train: 2018-08-01T01:03:14.743463: step 18259, loss 0.597795.
Train: 2018-08-01T01:03:14.899676: step 18260, loss 0.456768.
Test: 2018-08-01T01:03:15.383908: step 18260, loss 0.547731.
Train: 2018-08-01T01:03:15.540151: step 18261, loss 0.650548.
Train: 2018-08-01T01:03:15.696334: step 18262, loss 0.580058.
Train: 2018-08-01T01:03:15.852578: step 18263, loss 0.702922.
Train: 2018-08-01T01:03:16.008762: step 18264, loss 0.614936.
Train: 2018-08-01T01:03:16.165001: step 18265, loss 0.562428.
Train: 2018-08-01T01:03:16.336834: step 18266, loss 0.579785.
Train: 2018-08-01T01:03:16.493053: step 18267, loss 0.562409.
Train: 2018-08-01T01:03:16.664860: step 18268, loss 0.545151.
Train: 2018-08-01T01:03:16.821102: step 18269, loss 0.527987.
Train: 2018-08-01T01:03:16.977315: step 18270, loss 0.5624.
Test: 2018-08-01T01:03:17.445956: step 18270, loss 0.548044.
Train: 2018-08-01T01:03:17.602168: step 18271, loss 0.596687.
Train: 2018-08-01T01:03:17.758382: step 18272, loss 0.596618.
Train: 2018-08-01T01:03:17.914566: step 18273, loss 0.528264.
Train: 2018-08-01T01:03:18.070810: step 18274, loss 0.511278.
Train: 2018-08-01T01:03:18.226991: step 18275, loss 0.443193.
Train: 2018-08-01T01:03:18.383206: step 18276, loss 0.749943.
Train: 2018-08-01T01:03:18.570694: step 18277, loss 0.511343.
Train: 2018-08-01T01:03:18.726905: step 18278, loss 0.562408.
Train: 2018-08-01T01:03:18.883087: step 18279, loss 0.596405.
Train: 2018-08-01T01:03:19.039301: step 18280, loss 0.579392.
Test: 2018-08-01T01:03:19.507972: step 18280, loss 0.548211.
Train: 2018-08-01T01:03:19.695429: step 18281, loss 0.51153.
Train: 2018-08-01T01:03:19.836015: step 18282, loss 0.47763.
Train: 2018-08-01T01:03:19.992234: step 18283, loss 0.51149.
Train: 2018-08-01T01:03:20.148448: step 18284, loss 0.613415.
Train: 2018-08-01T01:03:20.304660: step 18285, loss 0.494343.
Train: 2018-08-01T01:03:20.460869: step 18286, loss 0.613539.
Train: 2018-08-01T01:03:20.632704: step 18287, loss 0.528285.
Train: 2018-08-01T01:03:20.804514: step 18288, loss 0.51116.
Train: 2018-08-01T01:03:20.960726: step 18289, loss 0.733521.
Train: 2018-08-01T01:03:21.116970: step 18290, loss 0.5966.
Test: 2018-08-01T01:03:21.585610: step 18290, loss 0.548098.
Train: 2018-08-01T01:03:21.741826: step 18291, loss 0.494077.
Train: 2018-08-01T01:03:21.913628: step 18292, loss 0.596562.
Train: 2018-08-01T01:03:22.069873: step 18293, loss 0.647763.
Train: 2018-08-01T01:03:22.226056: step 18294, loss 0.562404.
Train: 2018-08-01T01:03:22.382269: step 18295, loss 0.579426.
Train: 2018-08-01T01:03:22.538507: step 18296, loss 0.613392.
Train: 2018-08-01T01:03:22.694721: step 18297, loss 0.460657.
Train: 2018-08-01T01:03:22.850939: step 18298, loss 0.494602.
Train: 2018-08-01T01:03:23.022769: step 18299, loss 0.545449.
Train: 2018-08-01T01:03:23.178989: step 18300, loss 0.613349.
Test: 2018-08-01T01:03:23.647598: step 18300, loss 0.548191.
Train: 2018-08-01T01:03:24.397453: step 18301, loss 0.477506.
Train: 2018-08-01T01:03:24.553667: step 18302, loss 0.613418.
Train: 2018-08-01T01:03:24.709879: step 18303, loss 0.49436.
Train: 2018-08-01T01:03:24.866063: step 18304, loss 0.57944.
Train: 2018-08-01T01:03:25.022310: step 18305, loss 0.664729.
Train: 2018-08-01T01:03:25.194142: step 18306, loss 0.63059.
Train: 2018-08-01T01:03:25.350354: step 18307, loss 0.545382.
Train: 2018-08-01T01:03:25.506537: step 18308, loss 0.477369.
Train: 2018-08-01T01:03:25.662780: step 18309, loss 0.579421.
Train: 2018-08-01T01:03:25.818989: step 18310, loss 0.579422.
Test: 2018-08-01T01:03:26.303255: step 18310, loss 0.548159.
Train: 2018-08-01T01:03:26.459469: step 18311, loss 0.613449.
Train: 2018-08-01T01:03:26.615652: step 18312, loss 0.528406.
Train: 2018-08-01T01:03:26.771891: step 18313, loss 0.494419.
Train: 2018-08-01T01:03:26.928112: step 18314, loss 0.528384.
Train: 2018-08-01T01:03:27.084293: step 18315, loss 0.68163.
Train: 2018-08-01T01:03:27.271786: step 18316, loss 0.52836.
Train: 2018-08-01T01:03:27.427994: step 18317, loss 0.511336.
Train: 2018-08-01T01:03:27.584205: step 18318, loss 0.511296.
Train: 2018-08-01T01:03:27.740419: step 18319, loss 0.562402.
Train: 2018-08-01T01:03:27.896603: step 18320, loss 0.596565.
Test: 2018-08-01T01:03:28.365244: step 18320, loss 0.548086.
Train: 2018-08-01T01:03:28.521457: step 18321, loss 0.630776.
Train: 2018-08-01T01:03:28.677699: step 18322, loss 0.5624.
Train: 2018-08-01T01:03:28.833913: step 18323, loss 0.47698.
Train: 2018-08-01T01:03:28.990127: step 18324, loss 0.596601.
Train: 2018-08-01T01:03:29.146340: step 18325, loss 0.613722.
Train: 2018-08-01T01:03:29.302548: step 18326, loss 0.511095.
Train: 2018-08-01T01:03:29.474384: step 18327, loss 0.493965.
Train: 2018-08-01T01:03:29.614980: step 18328, loss 0.442479.
Train: 2018-08-01T01:03:29.786810: step 18329, loss 0.61394.
Train: 2018-08-01T01:03:29.943030: step 18330, loss 0.665673.
Test: 2018-08-01T01:03:30.411639: step 18330, loss 0.547983.
Train: 2018-08-01T01:03:30.583497: step 18331, loss 0.527967.
Train: 2018-08-01T01:03:30.739688: step 18332, loss 0.493488.
Train: 2018-08-01T01:03:30.895931: step 18333, loss 0.510639.
Train: 2018-08-01T01:03:31.052146: step 18334, loss 0.579695.
Train: 2018-08-01T01:03:31.208357: step 18335, loss 0.54509.
Train: 2018-08-01T01:03:31.380192: step 18336, loss 0.527719.
Train: 2018-08-01T01:03:31.536405: step 18337, loss 0.527658.
Train: 2018-08-01T01:03:31.692615: step 18338, loss 0.614675.
Train: 2018-08-01T01:03:31.848803: step 18339, loss 0.475241.
Train: 2018-08-01T01:03:32.005046: step 18340, loss 0.527486.
Test: 2018-08-01T01:03:32.473685: step 18340, loss 0.54778.
Train: 2018-08-01T01:03:32.629900: step 18341, loss 0.632515.
Train: 2018-08-01T01:03:32.801703: step 18342, loss 0.562454.
Train: 2018-08-01T01:03:32.942328: step 18343, loss 0.509799.
Train: 2018-08-01T01:03:33.114161: step 18344, loss 0.615204.
Train: 2018-08-01T01:03:33.270345: step 18345, loss 0.56247.
Train: 2018-08-01T01:03:33.426590: step 18346, loss 0.562472.
Train: 2018-08-01T01:03:33.582770: step 18347, loss 0.544872.
Train: 2018-08-01T01:03:33.754640: step 18348, loss 0.492038.
Train: 2018-08-01T01:03:33.926440: step 18349, loss 0.721166.
Train: 2018-08-01T01:03:34.082684: step 18350, loss 0.492027.
Test: 2018-08-01T01:03:34.551326: step 18350, loss 0.54773.
Train: 2018-08-01T01:03:34.707538: step 18351, loss 0.615309.
Train: 2018-08-01T01:03:34.863751: step 18352, loss 0.527281.
Train: 2018-08-01T01:03:35.051178: step 18353, loss 0.580058.
Train: 2018-08-01T01:03:35.207390: step 18354, loss 0.527312.
Train: 2018-08-01T01:03:35.347983: step 18355, loss 0.580037.
Train: 2018-08-01T01:03:35.519847: step 18356, loss 0.650284.
Train: 2018-08-01T01:03:35.676063: step 18357, loss 0.509848.
Train: 2018-08-01T01:03:35.832275: step 18358, loss 0.50989.
Train: 2018-08-01T01:03:36.019701: step 18359, loss 0.632514.
Train: 2018-08-01T01:03:36.175914: step 18360, loss 0.527449.
Test: 2018-08-01T01:03:36.660205: step 18360, loss 0.547797.
Train: 2018-08-01T01:03:36.816389: step 18361, loss 0.637046.
Train: 2018-08-01T01:03:36.972601: step 18362, loss 0.492602.
Train: 2018-08-01T01:03:37.144437: step 18363, loss 0.440297.
Train: 2018-08-01T01:03:37.285029: step 18364, loss 0.544968.
Train: 2018-08-01T01:03:37.441242: step 18365, loss 0.492496.
Train: 2018-08-01T01:03:37.597486: step 18366, loss 0.597486.
Train: 2018-08-01T01:03:37.753670: step 18367, loss 0.597533.
Train: 2018-08-01T01:03:37.909882: step 18368, loss 0.562457.
Train: 2018-08-01T01:03:38.066121: step 18369, loss 0.492236.
Train: 2018-08-01T01:03:38.237935: step 18370, loss 0.65035.
Test: 2018-08-01T01:03:38.706601: step 18370, loss 0.547748.
Train: 2018-08-01T01:03:38.862817: step 18371, loss 0.615188.
Train: 2018-08-01T01:03:39.019028: step 18372, loss 0.597577.
Train: 2018-08-01T01:03:39.175212: step 18373, loss 0.562453.
Train: 2018-08-01T01:03:39.347072: step 18374, loss 0.597472.
Train: 2018-08-01T01:03:39.503260: step 18375, loss 0.579922.
Train: 2018-08-01T01:03:39.659473: step 18376, loss 0.649692.
Train: 2018-08-01T01:03:39.815686: step 18377, loss 0.545019.
Train: 2018-08-01T01:03:39.971930: step 18378, loss 0.527692.
Train: 2018-08-01T01:03:40.143759: step 18379, loss 0.545078.
Train: 2018-08-01T01:03:40.299947: step 18380, loss 0.545099.
Test: 2018-08-01T01:03:40.768618: step 18380, loss 0.547926.
Train: 2018-08-01T01:03:40.924802: step 18381, loss 0.493242.
Train: 2018-08-01T01:03:41.081045: step 18382, loss 0.579696.
Train: 2018-08-01T01:03:41.237229: step 18383, loss 0.510544.
Train: 2018-08-01T01:03:41.393472: step 18384, loss 0.475932.
Train: 2018-08-01T01:03:41.565301: step 18385, loss 0.597052.
Train: 2018-08-01T01:03:41.721520: step 18386, loss 0.614424.
Train: 2018-08-01T01:03:41.877739: step 18387, loss 0.423698.
Train: 2018-08-01T01:03:42.033956: step 18388, loss 0.492927.
Train: 2018-08-01T01:03:42.174533: step 18389, loss 0.614678.
Train: 2018-08-01T01:03:42.330723: step 18390, loss 0.510093.
Test: 2018-08-01T01:03:42.815015: step 18390, loss 0.547799.
Train: 2018-08-01T01:03:42.971228: step 18391, loss 0.597403.
Train: 2018-08-01T01:03:43.127411: step 18392, loss 0.527433.
Train: 2018-08-01T01:03:43.283650: step 18393, loss 0.457247.
Train: 2018-08-01T01:03:43.439869: step 18394, loss 0.562467.
Train: 2018-08-01T01:03:43.596081: step 18395, loss 0.703487.
Train: 2018-08-01T01:03:43.767916: step 18396, loss 0.650633.
Train: 2018-08-01T01:03:43.924100: step 18397, loss 0.544865.
Train: 2018-08-01T01:03:44.080314: step 18398, loss 0.509677.
Train: 2018-08-01T01:03:44.236556: step 18399, loss 0.456889.
Train: 2018-08-01T01:03:44.392740: step 18400, loss 0.56248.
Test: 2018-08-01T01:03:44.861410: step 18400, loss 0.547717.
Train: 2018-08-01T01:03:45.595613: step 18401, loss 0.668309.
Train: 2018-08-01T01:03:45.751826: step 18402, loss 0.544855.
Train: 2018-08-01T01:03:45.908010: step 18403, loss 0.527237.
Train: 2018-08-01T01:03:46.064222: step 18404, loss 0.527235.
Train: 2018-08-01T01:03:46.220467: step 18405, loss 0.580115.
Train: 2018-08-01T01:03:46.376650: step 18406, loss 0.509587.
Train: 2018-08-01T01:03:46.532889: step 18407, loss 0.615423.
Train: 2018-08-01T01:03:46.689108: step 18408, loss 0.527204.
Train: 2018-08-01T01:03:46.845315: step 18409, loss 0.580135.
Train: 2018-08-01T01:03:47.017125: step 18410, loss 0.615421.
Test: 2018-08-01T01:03:47.501417: step 18410, loss 0.547721.
Train: 2018-08-01T01:03:47.657600: step 18411, loss 0.774029.
Train: 2018-08-01T01:03:47.813815: step 18412, loss 0.474648.
Train: 2018-08-01T01:03:47.970026: step 18413, loss 0.56245.
Train: 2018-08-01T01:03:48.157519: step 18414, loss 0.579932.
Train: 2018-08-01T01:03:48.313698: step 18415, loss 0.527524.
Train: 2018-08-01T01:03:48.469940: step 18416, loss 0.579854.
Train: 2018-08-01T01:03:48.626123: step 18417, loss 0.57982.
Train: 2018-08-01T01:03:48.782367: step 18418, loss 0.458207.
Train: 2018-08-01T01:03:48.938549: step 18419, loss 0.666602.
Train: 2018-08-01T01:03:49.094794: step 18420, loss 0.545076.
Test: 2018-08-01T01:03:49.563435: step 18420, loss 0.54791.
Train: 2018-08-01T01:03:49.719618: step 18421, loss 0.579723.
Train: 2018-08-01T01:03:49.875830: step 18422, loss 0.475959.
Train: 2018-08-01T01:03:50.032044: step 18423, loss 0.614269.
Train: 2018-08-01T01:03:50.203880: step 18424, loss 0.527859.
Train: 2018-08-01T01:03:50.375713: step 18425, loss 0.579673.
Train: 2018-08-01T01:03:50.531926: step 18426, loss 0.579663.
Train: 2018-08-01T01:03:50.688140: step 18427, loss 0.614141.
Train: 2018-08-01T01:03:50.844385: step 18428, loss 0.562402.
Train: 2018-08-01T01:03:50.984976: step 18429, loss 0.459198.
Train: 2018-08-01T01:03:51.156781: step 18430, loss 0.45917.
Test: 2018-08-01T01:03:51.625420: step 18430, loss 0.547972.
Train: 2018-08-01T01:03:51.781664: step 18431, loss 0.562403.
Train: 2018-08-01T01:03:51.937847: step 18432, loss 0.527887.
Train: 2018-08-01T01:03:52.094060: step 18433, loss 0.614276.
Train: 2018-08-01T01:03:52.250290: step 18434, loss 0.614322.
Train: 2018-08-01T01:03:52.406519: step 18435, loss 0.597019.
Train: 2018-08-01T01:03:52.578323: step 18436, loss 0.493218.
Train: 2018-08-01T01:03:52.734535: step 18437, loss 0.562409.
Train: 2018-08-01T01:03:52.890780: step 18438, loss 0.545101.
Train: 2018-08-01T01:03:53.046964: step 18439, loss 0.545087.
Train: 2018-08-01T01:03:53.203201: step 18440, loss 0.52774.
Test: 2018-08-01T01:03:53.687438: step 18440, loss 0.547883.
Train: 2018-08-01T01:03:53.828060: step 18441, loss 0.510349.
Train: 2018-08-01T01:03:53.984277: step 18442, loss 0.597189.
Train: 2018-08-01T01:03:54.140487: step 18443, loss 0.614627.
Train: 2018-08-01T01:03:54.296700: step 18444, loss 0.545021.
Train: 2018-08-01T01:03:54.468505: step 18445, loss 0.579834.
Train: 2018-08-01T01:03:54.624719: step 18446, loss 0.527607.
Train: 2018-08-01T01:03:54.780932: step 18447, loss 0.59726.
Train: 2018-08-01T01:03:54.952797: step 18448, loss 0.614669.
Train: 2018-08-01T01:03:55.108980: step 18449, loss 0.614621.
Train: 2018-08-01T01:03:55.265193: step 18450, loss 0.458183.
Test: 2018-08-01T01:03:55.733835: step 18450, loss 0.547871.
Train: 2018-08-01T01:03:55.890047: step 18451, loss 0.545046.
Train: 2018-08-01T01:03:56.046260: step 18452, loss 0.527668.
Train: 2018-08-01T01:03:56.202499: step 18453, loss 0.492877.
Train: 2018-08-01T01:03:56.358712: step 18454, loss 0.545015.
Train: 2018-08-01T01:03:56.514928: step 18455, loss 0.527557.
Train: 2018-08-01T01:03:56.671144: step 18456, loss 0.632306.
Train: 2018-08-01T01:03:56.842950: step 18457, loss 0.422622.
Train: 2018-08-01T01:03:56.999163: step 18458, loss 0.597486.
Train: 2018-08-01T01:03:57.155376: step 18459, loss 0.544913.
Train: 2018-08-01T01:03:57.295997: step 18460, loss 0.474604.
Test: 2018-08-01T01:03:57.764638: step 18460, loss 0.54773.
Train: 2018-08-01T01:03:57.936443: step 18461, loss 0.4744.
Train: 2018-08-01T01:03:58.108278: step 18462, loss 0.597851.
Train: 2018-08-01T01:03:58.264522: step 18463, loss 0.61567.
Train: 2018-08-01T01:03:58.420705: step 18464, loss 0.491565.
Train: 2018-08-01T01:03:58.592539: step 18465, loss 0.580325.
Train: 2018-08-01T01:03:58.748783: step 18466, loss 0.544755.
Train: 2018-08-01T01:03:58.904990: step 18467, loss 0.580404.
Train: 2018-08-01T01:03:59.076826: step 18468, loss 0.544734.
Train: 2018-08-01T01:03:59.233045: step 18469, loss 0.616189.
Train: 2018-08-01T01:03:59.373636: step 18470, loss 0.50899.
Test: 2018-08-01T01:03:59.842277: step 18470, loss 0.547627.
Train: 2018-08-01T01:04:00.014111: step 18471, loss 0.508962.
Train: 2018-08-01T01:04:00.170296: step 18472, loss 0.54471.
Train: 2018-08-01T01:04:00.326508: step 18473, loss 0.473026.
Train: 2018-08-01T01:04:00.498342: step 18474, loss 0.562642.
Train: 2018-08-01T01:04:00.654587: step 18475, loss 0.598629.
Train: 2018-08-01T01:04:00.810771: step 18476, loss 0.56267.
Train: 2018-08-01T01:04:00.966982: step 18477, loss 0.562678.
Train: 2018-08-01T01:04:01.123227: step 18478, loss 0.652789.
Train: 2018-08-01T01:04:01.295031: step 18479, loss 0.562673.
Train: 2018-08-01T01:04:01.451244: step 18480, loss 0.508696.
Test: 2018-08-01T01:04:01.919915: step 18480, loss 0.547599.
Train: 2018-08-01T01:04:02.076123: step 18481, loss 0.526692.
Train: 2018-08-01T01:04:02.232347: step 18482, loss 0.670563.
Train: 2018-08-01T01:04:02.404171: step 18483, loss 0.670388.
Train: 2018-08-01T01:04:02.560392: step 18484, loss 0.508891.
Train: 2018-08-01T01:04:02.716598: step 18485, loss 0.562593.
Train: 2018-08-01T01:04:02.872817: step 18486, loss 0.705272.
Train: 2018-08-01T01:04:03.029000: step 18487, loss 0.580314.
Train: 2018-08-01T01:04:03.185214: step 18488, loss 0.527099.
Train: 2018-08-01T01:04:03.341455: step 18489, loss 0.527183.
Train: 2018-08-01T01:04:03.497665: step 18490, loss 0.597708.
Test: 2018-08-01T01:04:03.981901: step 18490, loss 0.547751.
Train: 2018-08-01T01:04:04.138146: step 18491, loss 0.703017.
Train: 2018-08-01T01:04:04.294354: step 18492, loss 0.492463.
Train: 2018-08-01T01:04:04.450573: step 18493, loss 0.597314.
Train: 2018-08-01T01:04:04.622408: step 18494, loss 0.64935.
Train: 2018-08-01T01:04:04.778590: step 18495, loss 0.597038.
Train: 2018-08-01T01:04:04.934804: step 18496, loss 0.596885.
Train: 2018-08-01T01:04:05.091018: step 18497, loss 0.562398.
Train: 2018-08-01T01:04:05.247264: step 18498, loss 0.511092.
Train: 2018-08-01T01:04:05.403446: step 18499, loss 0.511238.
Train: 2018-08-01T01:04:05.575280: step 18500, loss 0.715621.
Test: 2018-08-01T01:04:06.059547: step 18500, loss 0.548209.
Train: 2018-08-01T01:04:06.762501: step 18501, loss 0.52849.
Train: 2018-08-01T01:04:06.918715: step 18502, loss 0.680809.
Train: 2018-08-01T01:04:07.074927: step 18503, loss 0.495068.
Train: 2018-08-01T01:04:07.231141: step 18504, loss 0.562448.
Train: 2018-08-01T01:04:07.387386: step 18505, loss 0.545705.
Train: 2018-08-01T01:04:07.543593: step 18506, loss 0.595916.
Train: 2018-08-01T01:04:07.699818: step 18507, loss 0.545794.
Train: 2018-08-01T01:04:07.871617: step 18508, loss 0.412536.
Train: 2018-08-01T01:04:08.012208: step 18509, loss 0.54581.
Train: 2018-08-01T01:04:08.184075: step 18510, loss 0.52909.
Test: 2018-08-01T01:04:08.652713: step 18510, loss 0.548468.
Train: 2018-08-01T01:04:08.808929: step 18511, loss 0.478865.
Train: 2018-08-01T01:04:08.980732: step 18512, loss 0.54569.
Train: 2018-08-01T01:04:09.121323: step 18513, loss 0.528819.
Train: 2018-08-01T01:04:09.277537: step 18514, loss 0.579293.
Train: 2018-08-01T01:04:09.433782: step 18515, loss 0.579327.
Train: 2018-08-01T01:04:09.589994: step 18516, loss 0.528535.
Train: 2018-08-01T01:04:09.746179: step 18517, loss 0.664289.
Train: 2018-08-01T01:04:09.902416: step 18518, loss 0.630377.
Train: 2018-08-01T01:04:10.074226: step 18519, loss 0.511444.
Train: 2018-08-01T01:04:10.230464: step 18520, loss 0.5964.
Test: 2018-08-01T01:04:10.699109: step 18520, loss 0.548174.
Train: 2018-08-01T01:04:10.855294: step 18521, loss 0.426433.
Train: 2018-08-01T01:04:11.011532: step 18522, loss 0.562403.
Train: 2018-08-01T01:04:11.183342: step 18523, loss 0.494162.
Train: 2018-08-01T01:04:11.323933: step 18524, loss 0.511089.
Train: 2018-08-01T01:04:11.480146: step 18525, loss 0.545243.
Train: 2018-08-01T01:04:11.636360: step 18526, loss 0.700037.
Train: 2018-08-01T01:04:11.792603: step 18527, loss 0.510745.
Train: 2018-08-01T01:04:11.948817: step 18528, loss 0.631364.
Train: 2018-08-01T01:04:12.120622: step 18529, loss 0.5624.
Train: 2018-08-01T01:04:12.292456: step 18530, loss 0.648649.
Test: 2018-08-01T01:04:12.776747: step 18530, loss 0.547969.
Train: 2018-08-01T01:04:12.932963: step 18531, loss 0.579632.
Train: 2018-08-01T01:04:13.089144: step 18532, loss 0.631252.
Train: 2018-08-01T01:04:13.245388: step 18533, loss 0.682655.
Train: 2018-08-01T01:04:13.417194: step 18534, loss 0.579519.
Train: 2018-08-01T01:04:13.573406: step 18535, loss 0.528271.
Train: 2018-08-01T01:04:13.729644: step 18536, loss 0.613469.
Train: 2018-08-01T01:04:13.885863: step 18537, loss 0.46058.
Train: 2018-08-01T01:04:14.042046: step 18538, loss 0.511559.
Train: 2018-08-01T01:04:14.198259: step 18539, loss 0.477685.
Train: 2018-08-01T01:04:14.354473: step 18540, loss 0.494566.
Test: 2018-08-01T01:04:14.838734: step 18540, loss 0.548178.
Train: 2018-08-01T01:04:14.994978: step 18541, loss 0.51143.
Train: 2018-08-01T01:04:15.151192: step 18542, loss 0.579436.
Train: 2018-08-01T01:04:15.307374: step 18543, loss 0.494139.
Train: 2018-08-01T01:04:15.479237: step 18544, loss 0.613731.
Train: 2018-08-01T01:04:15.635424: step 18545, loss 0.596678.
Train: 2018-08-01T01:04:15.791669: step 18546, loss 0.579556.
Train: 2018-08-01T01:04:15.963471: step 18547, loss 0.510883.
Train: 2018-08-01T01:04:16.119715: step 18548, loss 0.562397.
Train: 2018-08-01T01:04:16.275899: step 18549, loss 0.527968.
Train: 2018-08-01T01:04:16.432112: step 18550, loss 0.458948.
Test: 2018-08-01T01:04:16.900752: step 18550, loss 0.547925.
Train: 2018-08-01T01:04:17.072587: step 18551, loss 0.562404.
Train: 2018-08-01T01:04:17.275664: step 18552, loss 0.510411.
Train: 2018-08-01T01:04:17.431909: step 18553, loss 0.562416.
Train: 2018-08-01T01:04:17.588092: step 18554, loss 0.684412.
Train: 2018-08-01T01:04:17.759961: step 18555, loss 0.492677.
Train: 2018-08-01T01:04:17.900548: step 18556, loss 0.510045.
Train: 2018-08-01T01:04:18.056731: step 18557, loss 0.527449.
Train: 2018-08-01T01:04:18.212944: step 18558, loss 0.615051.
Train: 2018-08-01T01:04:18.369188: step 18559, loss 0.615118.
Train: 2018-08-01T01:04:18.525372: step 18560, loss 0.474666.
Test: 2018-08-01T01:04:19.009664: step 18560, loss 0.547743.
Train: 2018-08-01T01:04:19.165884: step 18561, loss 0.580048.
Train: 2018-08-01T01:04:19.322059: step 18562, loss 0.597666.
Train: 2018-08-01T01:04:19.478273: step 18563, loss 0.685689.
Train: 2018-08-01T01:04:19.634517: step 18564, loss 0.562465.
Train: 2018-08-01T01:04:19.790733: step 18565, loss 0.650222.
Train: 2018-08-01T01:04:19.962535: step 18566, loss 0.632485.
Train: 2018-08-01T01:04:20.118779: step 18567, loss 0.544977.
Train: 2018-08-01T01:04:20.274992: step 18568, loss 0.666864.
Train: 2018-08-01T01:04:20.431212: step 18569, loss 0.57975.
Train: 2018-08-01T01:04:20.603040: step 18570, loss 0.614226.
Test: 2018-08-01T01:04:21.071680: step 18570, loss 0.547992.
Train: 2018-08-01T01:04:21.227894: step 18571, loss 0.631212.
Train: 2018-08-01T01:04:21.384077: step 18572, loss 0.511027.
Train: 2018-08-01T01:04:21.540291: step 18573, loss 0.460019.
Train: 2018-08-01T01:04:21.696504: step 18574, loss 0.579437.
Train: 2018-08-01T01:04:21.852748: step 18575, loss 0.494391.
Train: 2018-08-01T01:04:22.008930: step 18576, loss 0.596393.
Train: 2018-08-01T01:04:22.180766: step 18577, loss 0.47753.
Train: 2018-08-01T01:04:22.336980: step 18578, loss 0.57939.
Train: 2018-08-01T01:04:22.493192: step 18579, loss 0.664303.
Train: 2018-08-01T01:04:22.665027: step 18580, loss 0.579372.
Test: 2018-08-01T01:04:23.133696: step 18580, loss 0.548233.
Train: 2018-08-01T01:04:23.305503: step 18581, loss 0.545479.
Train: 2018-08-01T01:04:23.477361: step 18582, loss 0.714697.
Train: 2018-08-01T01:04:23.633587: step 18583, loss 0.528689.
Train: 2018-08-01T01:04:23.789763: step 18584, loss 0.646604.
Train: 2018-08-01T01:04:23.946013: step 18585, loss 0.545669.
Train: 2018-08-01T01:04:24.102190: step 18586, loss 0.646165.
Train: 2018-08-01T01:04:24.289648: step 18587, loss 0.495745.
Train: 2018-08-01T01:04:24.461482: step 18588, loss 0.562495.
Train: 2018-08-01T01:04:24.602104: step 18589, loss 0.57913.
Train: 2018-08-01T01:04:24.758287: step 18590, loss 0.545922.
Test: 2018-08-01T01:04:25.226927: step 18590, loss 0.548646.
Train: 2018-08-01T01:04:25.398802: step 18591, loss 0.612257.
Train: 2018-08-01T01:04:25.555013: step 18592, loss 0.512891.
Train: 2018-08-01T01:04:25.711225: step 18593, loss 0.529467.
Train: 2018-08-01T01:04:25.867434: step 18594, loss 0.546005.
Train: 2018-08-01T01:04:26.023640: step 18595, loss 0.579087.
Train: 2018-08-01T01:04:26.179860: step 18596, loss 0.595637.
Train: 2018-08-01T01:04:26.336073: step 18597, loss 0.579087.
Train: 2018-08-01T01:04:26.507914: step 18598, loss 0.512921.
Train: 2018-08-01T01:04:26.679744: step 18599, loss 0.529438.
Train: 2018-08-01T01:04:26.835926: step 18600, loss 0.661945.
Test: 2018-08-01T01:04:27.320187: step 18600, loss 0.548663.
Train: 2018-08-01T01:04:28.023178: step 18601, loss 0.59566.
Train: 2018-08-01T01:04:28.179393: step 18602, loss 0.545986.
Train: 2018-08-01T01:04:28.335575: step 18603, loss 0.595636.
Train: 2018-08-01T01:04:28.507441: step 18604, loss 0.628698.
Train: 2018-08-01T01:04:28.663622: step 18605, loss 0.529525.
Train: 2018-08-01T01:04:28.835493: step 18606, loss 0.529552.
Train: 2018-08-01T01:04:28.991671: step 18607, loss 0.480036.
Train: 2018-08-01T01:04:29.132288: step 18608, loss 0.479912.
Train: 2018-08-01T01:04:29.288476: step 18609, loss 0.5791.
Train: 2018-08-01T01:04:29.444720: step 18610, loss 0.645543.
Test: 2018-08-01T01:04:29.913359: step 18610, loss 0.548591.
Train: 2018-08-01T01:04:30.085164: step 18611, loss 0.512649.
Train: 2018-08-01T01:04:30.241408: step 18612, loss 0.579144.
Train: 2018-08-01T01:04:30.397591: step 18613, loss 0.529155.
Train: 2018-08-01T01:04:30.553836: step 18614, loss 0.529087.
Train: 2018-08-01T01:04:30.710019: step 18615, loss 0.545735.
Train: 2018-08-01T01:04:30.866233: step 18616, loss 0.579223.
Train: 2018-08-01T01:04:31.022470: step 18617, loss 0.478451.
Train: 2018-08-01T01:04:31.178658: step 18618, loss 0.444499.
Train: 2018-08-01T01:04:31.334902: step 18619, loss 0.596259.
Train: 2018-08-01T01:04:31.491115: step 18620, loss 0.664283.
Test: 2018-08-01T01:04:31.959750: step 18620, loss 0.548163.
Train: 2018-08-01T01:04:32.115940: step 18621, loss 0.562405.
Train: 2018-08-01T01:04:32.272153: step 18622, loss 0.562402.
Train: 2018-08-01T01:04:32.428397: step 18623, loss 0.596518.
Train: 2018-08-01T01:04:32.584579: step 18624, loss 0.579472.
Train: 2018-08-01T01:04:32.740792: step 18625, loss 0.545317.
Train: 2018-08-01T01:04:32.897036: step 18626, loss 0.579492.
Train: 2018-08-01T01:04:33.084492: step 18627, loss 0.545297.
Train: 2018-08-01T01:04:33.240705: step 18628, loss 0.630844.
Train: 2018-08-01T01:04:33.396889: step 18629, loss 0.511081.
Train: 2018-08-01T01:04:33.553102: step 18630, loss 0.511062.
Test: 2018-08-01T01:04:34.037363: step 18630, loss 0.548052.
Train: 2018-08-01T01:04:34.209198: step 18631, loss 0.493877.
Train: 2018-08-01T01:04:34.365442: step 18632, loss 0.510909.
Train: 2018-08-01T01:04:34.521656: step 18633, loss 0.614009.
Train: 2018-08-01T01:04:34.677871: step 18634, loss 0.562399.
Train: 2018-08-01T01:04:34.849709: step 18635, loss 0.752162.
Train: 2018-08-01T01:04:35.005887: step 18636, loss 0.562399.
Train: 2018-08-01T01:04:35.162133: step 18637, loss 0.631215.
Train: 2018-08-01T01:04:35.349558: step 18638, loss 0.510893.
Train: 2018-08-01T01:04:35.505800: step 18639, loss 0.648134.
Train: 2018-08-01T01:04:35.662013: step 18640, loss 0.562398.
Test: 2018-08-01T01:04:36.130654: step 18640, loss 0.548101.
Train: 2018-08-01T01:04:36.286838: step 18641, loss 0.545325.
Train: 2018-08-01T01:04:36.458702: step 18642, loss 0.647638.
Train: 2018-08-01T01:04:36.614910: step 18643, loss 0.511395.
Train: 2018-08-01T01:04:36.771123: step 18644, loss 0.494503.
Train: 2018-08-01T01:04:36.927312: step 18645, loss 0.56241.
Train: 2018-08-01T01:04:37.083556: step 18646, loss 0.562411.
Train: 2018-08-01T01:04:37.239769: step 18647, loss 0.528497.
Train: 2018-08-01T01:04:37.395990: step 18648, loss 0.528488.
Train: 2018-08-01T01:04:37.567812: step 18649, loss 0.528462.
Train: 2018-08-01T01:04:37.724031: step 18650, loss 0.562407.
Test: 2018-08-01T01:04:38.177051: step 18650, loss 0.54816.
Train: 2018-08-01T01:04:38.333263: step 18651, loss 0.528381.
Train: 2018-08-01T01:04:38.520689: step 18652, loss 0.579439.
Train: 2018-08-01T01:04:38.676903: step 18653, loss 0.562401.
Train: 2018-08-01T01:04:38.833146: step 18654, loss 0.545327.
Train: 2018-08-01T01:04:38.989360: step 18655, loss 0.613675.
Train: 2018-08-01T01:04:39.145543: step 18656, loss 0.579496.
Train: 2018-08-01T01:04:39.301788: step 18657, loss 0.562398.
Train: 2018-08-01T01:04:39.473621: step 18658, loss 0.528195.
Train: 2018-08-01T01:04:39.629829: step 18659, loss 0.511065.
Train: 2018-08-01T01:04:39.786018: step 18660, loss 0.511002.
Test: 2018-08-01T01:04:40.270309: step 18660, loss 0.548025.
Train: 2018-08-01T01:04:40.426524: step 18661, loss 0.562397.
Train: 2018-08-01T01:04:40.582740: step 18662, loss 0.654081.
Train: 2018-08-01T01:04:40.754541: step 18663, loss 0.510815.
Train: 2018-08-01T01:04:40.910787: step 18664, loss 0.527979.
Train: 2018-08-01T01:04:41.067000: step 18665, loss 0.562399.
Train: 2018-08-01T01:04:41.223182: step 18666, loss 0.5624.
Train: 2018-08-01T01:04:41.379425: step 18667, loss 0.545134.
Train: 2018-08-01T01:04:41.535607: step 18668, loss 0.666118.
Train: 2018-08-01T01:04:41.691852: step 18669, loss 0.648793.
Train: 2018-08-01T01:04:41.863656: step 18670, loss 0.510648.
Test: 2018-08-01T01:04:42.332298: step 18670, loss 0.547964.
Train: 2018-08-01T01:04:42.504131: step 18671, loss 0.562399.
Train: 2018-08-01T01:04:42.660375: step 18672, loss 0.648529.
Train: 2018-08-01T01:04:42.816589: step 18673, loss 0.562397.
Train: 2018-08-01T01:04:43.004045: step 18674, loss 0.699733.
Train: 2018-08-01T01:04:43.160260: step 18675, loss 0.579507.
Train: 2018-08-01T01:04:43.316471: step 18676, loss 0.64767.
Train: 2018-08-01T01:04:43.472685: step 18677, loss 0.61336.
Train: 2018-08-01T01:04:43.628898: step 18678, loss 0.477872.
Train: 2018-08-01T01:04:43.785113: step 18679, loss 0.56243.
Train: 2018-08-01T01:04:43.972571: step 18680, loss 0.495148.
Test: 2018-08-01T01:04:44.456829: step 18680, loss 0.548374.
Train: 2018-08-01T01:04:44.675529: step 18681, loss 0.663266.
Train: 2018-08-01T01:04:44.831710: step 18682, loss 0.612746.
Train: 2018-08-01T01:04:45.003576: step 18683, loss 0.495608.
Train: 2018-08-01T01:04:45.175406: step 18684, loss 0.54579.
Train: 2018-08-01T01:04:45.331594: step 18685, loss 0.612508.
Train: 2018-08-01T01:04:45.487807: step 18686, loss 0.545849.
Train: 2018-08-01T01:04:45.644021: step 18687, loss 0.529244.
Train: 2018-08-01T01:04:45.800235: step 18688, loss 0.562507.
Train: 2018-08-01T01:04:45.956448: step 18689, loss 0.496027.
Train: 2018-08-01T01:04:46.112692: step 18690, loss 0.612415.
Test: 2018-08-01T01:04:46.581301: step 18690, loss 0.54857.
Train: 2018-08-01T01:04:46.753137: step 18691, loss 0.479319.
Train: 2018-08-01T01:04:46.909350: step 18692, loss 0.645792.
Train: 2018-08-01T01:04:47.065563: step 18693, loss 0.579142.
Train: 2018-08-01T01:04:47.237400: step 18694, loss 0.495783.
Train: 2018-08-01T01:04:47.409233: step 18695, loss 0.561958.
Train: 2018-08-01T01:04:47.549856: step 18696, loss 0.6124.
Train: 2018-08-01T01:04:47.706068: step 18697, loss 0.561407.
Train: 2018-08-01T01:04:47.862282: step 18698, loss 0.564606.
Train: 2018-08-01T01:04:48.018495: step 18699, loss 0.516914.
Train: 2018-08-01T01:04:48.190331: step 18700, loss 0.482008.
Test: 2018-08-01T01:04:48.658940: step 18700, loss 0.548733.
Train: 2018-08-01T01:04:49.315067: step 18701, loss 0.49627.
Train: 2018-08-01T01:04:49.471281: step 18702, loss 0.64706.
Train: 2018-08-01T01:04:49.627494: step 18703, loss 0.512092.
Train: 2018-08-01T01:04:49.783709: step 18704, loss 0.579396.
Train: 2018-08-01T01:04:49.939889: step 18705, loss 0.579376.
Train: 2018-08-01T01:04:50.096135: step 18706, loss 0.562407.
Train: 2018-08-01T01:04:50.252347: step 18707, loss 0.579425.
Train: 2018-08-01T01:04:50.408531: step 18708, loss 0.511279.
Train: 2018-08-01T01:04:50.580366: step 18709, loss 0.528257.
Train: 2018-08-01T01:04:50.720982: step 18710, loss 0.511074.
Test: 2018-08-01T01:04:51.189627: step 18710, loss 0.548035.
Train: 2018-08-01T01:04:51.345811: step 18711, loss 0.562399.
Train: 2018-08-01T01:04:51.502024: step 18712, loss 0.579593.
Train: 2018-08-01T01:04:51.673877: step 18713, loss 0.510724.
Train: 2018-08-01T01:04:51.814451: step 18714, loss 0.700536.
Train: 2018-08-01T01:04:51.970665: step 18715, loss 0.631487.
Train: 2018-08-01T01:04:52.126909: step 18716, loss 0.527889.
Train: 2018-08-01T01:04:52.298744: step 18717, loss 0.562404.
Train: 2018-08-01T01:04:52.454956: step 18718, loss 0.510654.
Train: 2018-08-01T01:04:52.611170: step 18719, loss 0.510629.
Train: 2018-08-01T01:04:52.782976: step 18720, loss 0.562407.
Test: 2018-08-01T01:04:53.267235: step 18720, loss 0.547926.
Train: 2018-08-01T01:04:53.423482: step 18721, loss 0.666182.
Train: 2018-08-01T01:04:53.579693: step 18722, loss 0.596981.
Train: 2018-08-01T01:04:53.735876: step 18723, loss 0.596946.
Train: 2018-08-01T01:04:53.892089: step 18724, loss 0.424439.
Train: 2018-08-01T01:04:54.048302: step 18725, loss 0.527893.
Train: 2018-08-01T01:04:54.204546: step 18726, loss 0.596956.
Train: 2018-08-01T01:04:54.360762: step 18727, loss 0.562409.
Train: 2018-08-01T01:04:54.532602: step 18728, loss 0.666136.
Train: 2018-08-01T01:04:54.688777: step 18729, loss 0.596945.
Train: 2018-08-01T01:04:54.845022: step 18730, loss 0.562406.
Test: 2018-08-01T01:04:55.313661: step 18730, loss 0.547985.
Train: 2018-08-01T01:04:55.469875: step 18731, loss 0.579625.
Train: 2018-08-01T01:04:55.626089: step 18732, loss 0.579599.
Train: 2018-08-01T01:04:55.797925: step 18733, loss 0.579571.
Train: 2018-08-01T01:04:55.954131: step 18734, loss 0.579543.
Train: 2018-08-01T01:04:56.125941: step 18735, loss 0.493964.
Train: 2018-08-01T01:04:56.282154: step 18736, loss 0.579505.
Train: 2018-08-01T01:04:56.438368: step 18737, loss 0.630754.
Train: 2018-08-01T01:04:56.594582: step 18738, loss 0.579467.
Train: 2018-08-01T01:04:56.750826: step 18739, loss 0.596471.
Train: 2018-08-01T01:04:56.907041: step 18740, loss 0.511422.
Test: 2018-08-01T01:04:57.375679: step 18740, loss 0.548197.
Train: 2018-08-01T01:04:57.531892: step 18741, loss 0.528457.
Train: 2018-08-01T01:04:57.688106: step 18742, loss 0.545444.
Train: 2018-08-01T01:04:57.844320: step 18743, loss 0.596359.
Train: 2018-08-01T01:04:58.016148: step 18744, loss 0.460649.
Train: 2018-08-01T01:04:58.172362: step 18745, loss 0.477525.
Train: 2018-08-01T01:04:58.344173: step 18746, loss 0.562412.
Train: 2018-08-01T01:04:58.500386: step 18747, loss 0.698783.
Train: 2018-08-01T01:04:58.656598: step 18748, loss 0.511276.
Train: 2018-08-01T01:04:58.812812: step 18749, loss 0.494191.
Train: 2018-08-01T01:04:58.969026: step 18750, loss 0.545326.
Test: 2018-08-01T01:04:59.453317: step 18750, loss 0.54808.
Train: 2018-08-01T01:04:59.609500: step 18751, loss 0.528191.
Train: 2018-08-01T01:04:59.765739: step 18752, loss 0.493844.
Train: 2018-08-01T01:04:59.921928: step 18753, loss 0.545219.
Train: 2018-08-01T01:05:00.093787: step 18754, loss 0.596868.
Train: 2018-08-01T01:05:00.250011: step 18755, loss 0.562408.
Train: 2018-08-01T01:05:00.421812: step 18756, loss 0.545119.
Train: 2018-08-01T01:05:00.578059: step 18757, loss 0.597058.
Train: 2018-08-01T01:05:00.734237: step 18758, loss 0.545077.
Train: 2018-08-01T01:05:00.890450: step 18759, loss 0.579779.
Train: 2018-08-01T01:05:01.046696: step 18760, loss 0.527677.
Test: 2018-08-01T01:05:01.515335: step 18760, loss 0.547862.
Train: 2018-08-01T01:05:01.671549: step 18761, loss 0.545034.
Train: 2018-08-01T01:05:01.827731: step 18762, loss 0.701725.
Train: 2018-08-01T01:05:01.983969: step 18763, loss 0.458043.
Train: 2018-08-01T01:05:02.140188: step 18764, loss 0.54502.
Train: 2018-08-01T01:05:02.280782: step 18765, loss 0.579851.
Train: 2018-08-01T01:05:02.436994: step 18766, loss 0.510152.
Train: 2018-08-01T01:05:02.640042: step 18767, loss 0.527548.
Train: 2018-08-01T01:05:02.796285: step 18768, loss 0.579907.
Train: 2018-08-01T01:05:02.952498: step 18769, loss 0.667334.
Train: 2018-08-01T01:05:03.108712: step 18770, loss 0.597382.
Test: 2018-08-01T01:05:03.577351: step 18770, loss 0.547824.
Train: 2018-08-01T01:05:03.749187: step 18771, loss 0.544986.
Train: 2018-08-01T01:05:03.889748: step 18772, loss 0.527561.
Train: 2018-08-01T01:05:04.045962: step 18773, loss 0.492709.
Train: 2018-08-01T01:05:04.202176: step 18774, loss 0.562434.
Train: 2018-08-01T01:05:04.374035: step 18775, loss 0.475166.
Train: 2018-08-01T01:05:04.530248: step 18776, loss 0.597478.
Train: 2018-08-01T01:05:04.686466: step 18777, loss 0.492283.
Train: 2018-08-01T01:05:04.858272: step 18778, loss 0.597762.
Train: 2018-08-01T01:05:04.998894: step 18779, loss 0.633219.
Train: 2018-08-01T01:05:05.155109: step 18780, loss 0.509742.
Test: 2018-08-01T01:05:05.639338: step 18780, loss 0.547763.
Train: 2018-08-01T01:05:05.795584: step 18781, loss 0.45714.
Train: 2018-08-01T01:05:05.967387: step 18782, loss 0.492234.
Train: 2018-08-01T01:05:06.123625: step 18783, loss 0.615326.
Train: 2018-08-01T01:05:06.279814: step 18784, loss 0.544855.
Train: 2018-08-01T01:05:06.436053: step 18785, loss 0.527178.
Train: 2018-08-01T01:05:06.592274: step 18786, loss 0.509441.
Train: 2018-08-01T01:05:06.748484: step 18787, loss 0.491621.
Train: 2018-08-01T01:05:06.904697: step 18788, loss 0.651419.
Train: 2018-08-01T01:05:07.076541: step 18789, loss 0.509177.
Train: 2018-08-01T01:05:07.232719: step 18790, loss 0.473461.
Test: 2018-08-01T01:05:07.701356: step 18790, loss 0.547635.
Train: 2018-08-01T01:05:07.857569: step 18791, loss 0.455399.
Train: 2018-08-01T01:05:08.013782: step 18792, loss 0.455065.
Train: 2018-08-01T01:05:08.185618: step 18793, loss 0.724722.
Train: 2018-08-01T01:05:08.341830: step 18794, loss 0.580733.
Train: 2018-08-01T01:05:08.498069: step 18795, loss 0.562712.
Train: 2018-08-01T01:05:08.654290: step 18796, loss 0.52658.
Train: 2018-08-01T01:05:08.810471: step 18797, loss 0.508464.
Train: 2018-08-01T01:05:08.966685: step 18798, loss 0.52652.
Train: 2018-08-01T01:05:09.122899: step 18799, loss 0.508336.
Train: 2018-08-01T01:05:09.279143: step 18800, loss 0.52644.
Test: 2018-08-01T01:05:09.747782: step 18800, loss 0.547577.
Train: 2018-08-01T01:05:10.450742: step 18801, loss 0.562834.
Train: 2018-08-01T01:05:10.622570: step 18802, loss 0.635856.
Train: 2018-08-01T01:05:10.778792: step 18803, loss 0.581121.
Train: 2018-08-01T01:05:10.935004: step 18804, loss 0.599376.
Train: 2018-08-01T01:05:11.091187: step 18805, loss 0.654074.
Train: 2018-08-01T01:05:11.247401: step 18806, loss 0.581036.
Train: 2018-08-01T01:05:11.419238: step 18807, loss 0.599139.
Train: 2018-08-01T01:05:11.575474: step 18808, loss 0.52651.
Train: 2018-08-01T01:05:11.731692: step 18809, loss 0.508466.
Train: 2018-08-01T01:05:11.887875: step 18810, loss 0.580787.
Test: 2018-08-01T01:05:12.356516: step 18810, loss 0.547595.
Train: 2018-08-01T01:05:12.512730: step 18811, loss 0.418387.
Train: 2018-08-01T01:05:12.668974: step 18812, loss 0.508572.
Train: 2018-08-01T01:05:12.825155: step 18813, loss 0.634945.
Train: 2018-08-01T01:05:12.997021: step 18814, loss 0.490504.
Train: 2018-08-01T01:05:13.153206: step 18815, loss 0.598832.
Train: 2018-08-01T01:05:13.309417: step 18816, loss 0.436328.
Train: 2018-08-01T01:05:13.465631: step 18817, loss 0.526573.
Train: 2018-08-01T01:05:13.637466: step 18818, loss 0.526541.
Train: 2018-08-01T01:05:13.793710: step 18819, loss 0.526506.
Train: 2018-08-01T01:05:13.949923: step 18820, loss 0.617264.
Test: 2018-08-01T01:05:14.418564: step 18820, loss 0.547579.
Train: 2018-08-01T01:05:14.574777: step 18821, loss 0.508282.
Train: 2018-08-01T01:05:14.746581: step 18822, loss 0.599192.
Train: 2018-08-01T01:05:14.902794: step 18823, loss 0.490027.
Train: 2018-08-01T01:05:15.059037: step 18824, loss 0.599262.
Train: 2018-08-01T01:05:15.215221: step 18825, loss 0.489949.
Train: 2018-08-01T01:05:15.387086: step 18826, loss 0.599328.
Train: 2018-08-01T01:05:15.543270: step 18827, loss 0.581098.
Train: 2018-08-01T01:05:15.715103: step 18828, loss 0.471645.
Train: 2018-08-01T01:05:15.886969: step 18829, loss 0.581118.
Train: 2018-08-01T01:05:16.043184: step 18830, loss 0.508085.
Test: 2018-08-01T01:05:16.511822: step 18830, loss 0.547576.
Train: 2018-08-01T01:05:16.683628: step 18831, loss 0.52633.
Train: 2018-08-01T01:05:16.824220: step 18832, loss 0.636057.
Train: 2018-08-01T01:05:17.011676: step 18833, loss 0.562889.
Train: 2018-08-01T01:05:17.167920: step 18834, loss 0.690837.
Train: 2018-08-01T01:05:17.324132: step 18835, loss 0.489887.
Train: 2018-08-01T01:05:17.480346: step 18836, loss 0.653928.
Train: 2018-08-01T01:05:17.636560: step 18837, loss 0.453742.
Train: 2018-08-01T01:05:17.792774: step 18838, loss 0.490151.
Train: 2018-08-01T01:05:17.948957: step 18839, loss 0.544627.
Train: 2018-08-01T01:05:18.120791: step 18840, loss 0.544628.
Test: 2018-08-01T01:05:18.589461: step 18840, loss 0.54758.
Train: 2018-08-01T01:05:18.761295: step 18841, loss 0.453857.
Train: 2018-08-01T01:05:18.917479: step 18842, loss 0.508273.
Train: 2018-08-01T01:05:19.073697: step 18843, loss 0.781254.
Train: 2018-08-01T01:05:19.245528: step 18844, loss 0.544623.
Train: 2018-08-01T01:05:19.386150: step 18845, loss 0.653549.
Train: 2018-08-01T01:05:19.542333: step 18846, loss 0.580859.
Train: 2018-08-01T01:05:19.714198: step 18847, loss 0.616907.
Train: 2018-08-01T01:05:19.870382: step 18848, loss 0.580686.
Train: 2018-08-01T01:05:20.026624: step 18849, loss 0.544693.
Train: 2018-08-01T01:05:20.198457: step 18850, loss 0.473116.
Test: 2018-08-01T01:05:20.682721: step 18850, loss 0.547633.
Train: 2018-08-01T01:05:20.838935: step 18851, loss 0.544726.
Train: 2018-08-01T01:05:20.995148: step 18852, loss 0.544737.
Train: 2018-08-01T01:05:21.166984: step 18853, loss 0.526915.
Train: 2018-08-01T01:05:21.338787: step 18854, loss 0.633854.
Train: 2018-08-01T01:05:21.495031: step 18855, loss 0.562558.
Train: 2018-08-01T01:05:21.651214: step 18856, loss 0.544779.
Train: 2018-08-01T01:05:21.807427: step 18857, loss 0.509304.
Train: 2018-08-01T01:05:21.963671: step 18858, loss 0.580265.
Train: 2018-08-01T01:05:22.119884: step 18859, loss 0.615684.
Train: 2018-08-01T01:05:22.276105: step 18860, loss 0.650978.
Test: 2018-08-01T01:05:22.744739: step 18860, loss 0.547718.
Train: 2018-08-01T01:05:22.900922: step 18861, loss 0.527201.
Train: 2018-08-01T01:05:23.072786: step 18862, loss 0.54487.
Train: 2018-08-01T01:05:23.228999: step 18863, loss 0.667974.
Train: 2018-08-01T01:05:23.385213: step 18864, loss 0.57999.
Train: 2018-08-01T01:05:23.572669: step 18865, loss 0.51.
Train: 2018-08-01T01:05:23.728853: step 18866, loss 0.544989.
Train: 2018-08-01T01:05:23.885067: step 18867, loss 0.666934.
Train: 2018-08-01T01:05:24.041279: step 18868, loss 0.545053.
Train: 2018-08-01T01:05:24.197493: step 18869, loss 0.458465.
Train: 2018-08-01T01:05:24.353737: step 18870, loss 0.579723.
Test: 2018-08-01T01:05:24.837998: step 18870, loss 0.547929.
Train: 2018-08-01T01:05:24.994211: step 18871, loss 0.596997.
Train: 2018-08-01T01:05:25.150424: step 18872, loss 0.545139.
Train: 2018-08-01T01:05:25.306638: step 18873, loss 0.476151.
Train: 2018-08-01T01:05:25.478443: step 18874, loss 0.579662.
Train: 2018-08-01T01:05:25.634656: step 18875, loss 0.57966.
Train: 2018-08-01T01:05:25.806492: step 18876, loss 0.596903.
Train: 2018-08-01T01:05:25.962729: step 18877, loss 0.614111.
Train: 2018-08-01T01:05:26.118919: step 18878, loss 0.665671.
Train: 2018-08-01T01:05:26.275161: step 18879, loss 0.493743.
Train: 2018-08-01T01:05:26.431375: step 18880, loss 0.562403.
Test: 2018-08-01T01:05:26.900014: step 18880, loss 0.54807.
Train: 2018-08-01T01:05:27.071846: step 18881, loss 0.52817.
Train: 2018-08-01T01:05:27.228064: step 18882, loss 0.596614.
Train: 2018-08-01T01:05:27.384277: step 18883, loss 0.442805.
Train: 2018-08-01T01:05:27.556114: step 18884, loss 0.630793.
Train: 2018-08-01T01:05:27.712294: step 18885, loss 0.545313.
Train: 2018-08-01T01:05:27.884130: step 18886, loss 0.545314.
Train: 2018-08-01T01:05:28.024721: step 18887, loss 0.562404.
Train: 2018-08-01T01:05:28.180965: step 18888, loss 0.511113.
Train: 2018-08-01T01:05:28.337148: step 18889, loss 0.613741.
Train: 2018-08-01T01:05:28.493363: step 18890, loss 0.647974.
Test: 2018-08-01T01:05:28.962033: step 18890, loss 0.548089.
Train: 2018-08-01T01:05:29.118245: step 18891, loss 0.511117.
Train: 2018-08-01T01:05:29.274461: step 18892, loss 0.647861.
Train: 2018-08-01T01:05:29.430673: step 18893, loss 0.647743.
Train: 2018-08-01T01:05:29.586886: step 18894, loss 0.613488.
Train: 2018-08-01T01:05:29.743100: step 18895, loss 0.528461.
Train: 2018-08-01T01:05:29.899282: step 18896, loss 0.511594.
Train: 2018-08-01T01:05:30.086738: step 18897, loss 0.562424.
Train: 2018-08-01T01:05:30.242982: step 18898, loss 0.59624.
Train: 2018-08-01T01:05:30.399195: step 18899, loss 0.528663.
Train: 2018-08-01T01:05:30.555409: step 18900, loss 0.427446.
Test: 2018-08-01T01:05:31.024049: step 18900, loss 0.54828.
Train: 2018-08-01T01:05:31.695738: step 18901, loss 0.579326.
Train: 2018-08-01T01:05:31.851982: step 18902, loss 0.613169.
Train: 2018-08-01T01:05:32.023815: step 18903, loss 0.663938.
Train: 2018-08-01T01:05:32.180023: step 18904, loss 0.630027.
Train: 2018-08-01T01:05:32.351833: step 18905, loss 0.528701.
Train: 2018-08-01T01:05:32.492425: step 18906, loss 0.478207.
Train: 2018-08-01T01:05:32.648639: step 18907, loss 0.596138.
Train: 2018-08-01T01:05:32.804853: step 18908, loss 0.528751.
Train: 2018-08-01T01:05:32.961066: step 18909, loss 0.629837.
Train: 2018-08-01T01:05:33.117279: step 18910, loss 0.545603.
Test: 2018-08-01T01:05:33.601539: step 18910, loss 0.548347.
Train: 2018-08-01T01:05:33.757784: step 18911, loss 0.629779.
Train: 2018-08-01T01:05:33.913999: step 18912, loss 0.512004.
Train: 2018-08-01T01:05:34.085803: step 18913, loss 0.512018.
Train: 2018-08-01T01:05:34.242015: step 18914, loss 0.528807.
Train: 2018-08-01T01:05:34.413851: step 18915, loss 0.646628.
Train: 2018-08-01T01:05:34.554473: step 18916, loss 0.612944.
Train: 2018-08-01T01:05:34.710656: step 18917, loss 0.612906.
Train: 2018-08-01T01:05:34.866900: step 18918, loss 0.579249.
Train: 2018-08-01T01:05:35.038736: step 18919, loss 0.66309.
Train: 2018-08-01T01:05:35.194950: step 18920, loss 0.47884.
Test: 2018-08-01T01:05:35.663589: step 18920, loss 0.548489.
Train: 2018-08-01T01:05:35.835422: step 18921, loss 0.679436.
Train: 2018-08-01T01:05:35.991641: step 18922, loss 0.529168.
Train: 2018-08-01T01:05:36.147849: step 18923, loss 0.612412.
Train: 2018-08-01T01:05:36.304033: step 18924, loss 0.645511.
Train: 2018-08-01T01:05:36.460276: step 18925, loss 0.579093.
Train: 2018-08-01T01:05:36.647727: step 18926, loss 0.51308.
Train: 2018-08-01T01:05:36.803915: step 18927, loss 0.562587.
Train: 2018-08-01T01:05:36.960153: step 18928, loss 0.595485.
Train: 2018-08-01T01:05:37.116372: step 18929, loss 0.644688.
Train: 2018-08-01T01:05:37.272588: step 18930, loss 0.497155.
Test: 2018-08-01T01:05:37.741226: step 18930, loss 0.548961.
Train: 2018-08-01T01:05:37.913062: step 18931, loss 0.628059.
Train: 2018-08-01T01:05:38.069274: step 18932, loss 0.513715.
Train: 2018-08-01T01:05:38.225458: step 18933, loss 0.595295.
Train: 2018-08-01T01:05:38.381703: step 18934, loss 0.644135.
Train: 2018-08-01T01:05:38.537884: step 18935, loss 0.497699.
Train: 2018-08-01T01:05:38.694123: step 18936, loss 0.6277.
Train: 2018-08-01T01:05:38.865932: step 18937, loss 0.514082.
Train: 2018-08-01T01:05:39.022147: step 18938, loss 0.49789.
Train: 2018-08-01T01:05:39.193981: step 18939, loss 0.627649.
Train: 2018-08-01T01:05:39.334598: step 18940, loss 0.530283.
Test: 2018-08-01T01:05:39.818840: step 18940, loss 0.549133.
Train: 2018-08-01T01:05:39.990694: step 18941, loss 0.578968.
Train: 2018-08-01T01:05:40.146883: step 18942, loss 0.497743.
Train: 2018-08-01T01:05:40.303096: step 18943, loss 0.660335.
Train: 2018-08-01T01:05:40.474930: step 18944, loss 0.432515.
Train: 2018-08-01T01:05:40.631169: step 18945, loss 0.627922.
Train: 2018-08-01T01:05:40.787390: step 18946, loss 0.595327.
Train: 2018-08-01T01:05:40.959231: step 18947, loss 0.595344.
Train: 2018-08-01T01:05:41.115431: step 18948, loss 0.529959.
Train: 2018-08-01T01:05:41.271649: step 18949, loss 0.562646.
Train: 2018-08-01T01:05:41.443484: step 18950, loss 0.513495.
Test: 2018-08-01T01:05:41.912126: step 18950, loss 0.548877.
Train: 2018-08-01T01:05:42.083951: step 18951, loss 0.579028.
Train: 2018-08-01T01:05:42.224552: step 18952, loss 0.595473.
Train: 2018-08-01T01:05:42.380736: step 18953, loss 0.694201.
Train: 2018-08-01T01:05:42.536980: step 18954, loss 0.61191.
Train: 2018-08-01T01:05:42.693162: step 18955, loss 0.431318.
Train: 2018-08-01T01:05:42.849376: step 18956, loss 0.480481.
Train: 2018-08-01T01:05:43.005590: step 18957, loss 0.59551.
Train: 2018-08-01T01:05:43.208665: step 18958, loss 0.595547.
Train: 2018-08-01T01:05:43.364879: step 18959, loss 0.612073.
Train: 2018-08-01T01:05:43.521093: step 18960, loss 0.562566.
Test: 2018-08-01T01:05:43.989763: step 18960, loss 0.548734.
Train: 2018-08-01T01:05:44.161592: step 18961, loss 0.49651.
Train: 2018-08-01T01:05:44.349023: step 18962, loss 0.413718.
Train: 2018-08-01T01:05:44.505267: step 18963, loss 0.527118.
Train: 2018-08-01T01:05:44.661482: step 18964, loss 0.512518.
Train: 2018-08-01T01:05:44.817695: step 18965, loss 0.49555.
Train: 2018-08-01T01:05:44.973878: step 18966, loss 0.579259.
Train: 2018-08-01T01:05:45.130121: step 18967, loss 0.579312.
Train: 2018-08-01T01:05:45.286336: step 18968, loss 0.630184.
Train: 2018-08-01T01:05:45.458170: step 18969, loss 0.596373.
Train: 2018-08-01T01:05:45.614383: step 18970, loss 0.545404.
Test: 2018-08-01T01:05:46.098644: step 18970, loss 0.548142.
Train: 2018-08-01T01:05:46.254860: step 18971, loss 0.579443.
Train: 2018-08-01T01:05:46.426692: step 18972, loss 0.630638.
Train: 2018-08-01T01:05:46.582911: step 18973, loss 0.52828.
Train: 2018-08-01T01:05:46.739089: step 18974, loss 0.477029.
Train: 2018-08-01T01:05:46.895328: step 18975, loss 0.493977.
Train: 2018-08-01T01:05:47.051546: step 18976, loss 0.510949.
Train: 2018-08-01T01:05:47.223368: step 18977, loss 0.510794.
Train: 2018-08-01T01:05:47.379564: step 18978, loss 0.648713.
Train: 2018-08-01T01:05:47.535809: step 18979, loss 0.545115.
Train: 2018-08-01T01:05:47.707614: step 18980, loss 0.545086.
Test: 2018-08-01T01:05:48.176283: step 18980, loss 0.547881.
Train: 2018-08-01T01:05:48.332500: step 18981, loss 0.545058.
Train: 2018-08-01T01:05:48.504330: step 18982, loss 0.527638.
Train: 2018-08-01T01:05:48.660514: step 18983, loss 0.492712.
Train: 2018-08-01T01:05:48.816757: step 18984, loss 0.579919.
Train: 2018-08-01T01:05:48.972965: step 18985, loss 0.562451.
Train: 2018-08-01T01:05:49.129186: step 18986, loss 0.544911.
Train: 2018-08-01T01:05:49.285368: step 18987, loss 0.615222.
Train: 2018-08-01T01:05:49.441581: step 18988, loss 0.544877.
Train: 2018-08-01T01:05:49.597819: step 18989, loss 0.597718.
Train: 2018-08-01T01:05:49.769663: step 18990, loss 0.491989.
Test: 2018-08-01T01:05:50.238270: step 18990, loss 0.547717.
Train: 2018-08-01T01:05:50.394515: step 18991, loss 0.615426.
Train: 2018-08-01T01:05:50.566342: step 18992, loss 0.509547.
Train: 2018-08-01T01:05:50.722556: step 18993, loss 0.456515.
Train: 2018-08-01T01:05:50.894398: step 18994, loss 0.527114.
Train: 2018-08-01T01:05:51.050604: step 18995, loss 0.527054.
Train: 2018-08-01T01:05:51.206793: step 18996, loss 0.633668.
Train: 2018-08-01T01:05:51.363006: step 18997, loss 0.526962.
Train: 2018-08-01T01:05:51.534841: step 18998, loss 0.526927.
Train: 2018-08-01T01:05:51.691084: step 18999, loss 0.616129.
Train: 2018-08-01T01:05:51.847300: step 19000, loss 0.705457.
Test: 2018-08-01T01:05:52.311796: step 19000, loss 0.547643.
Train: 2018-08-01T01:05:53.030407: step 19001, loss 0.633909.
Train: 2018-08-01T01:05:53.186592: step 19002, loss 0.526971.
Train: 2018-08-01T01:05:53.342806: step 19003, loss 0.509255.
Train: 2018-08-01T01:05:53.499019: step 19004, loss 0.562533.
Train: 2018-08-01T01:05:53.655233: step 19005, loss 0.544799.
Train: 2018-08-01T01:05:53.811446: step 19006, loss 0.473951.
Train: 2018-08-01T01:05:53.967659: step 19007, loss 0.580243.
Train: 2018-08-01T01:05:54.139494: step 19008, loss 0.562523.
Train: 2018-08-01T01:05:54.295738: step 19009, loss 0.615676.
Train: 2018-08-01T01:05:54.451921: step 19010, loss 0.580218.
Test: 2018-08-01T01:05:54.920591: step 19010, loss 0.5477.
Train: 2018-08-01T01:05:55.076805: step 19011, loss 0.597874.
Train: 2018-08-01T01:05:55.233015: step 19012, loss 0.544841.
Train: 2018-08-01T01:05:55.389203: step 19013, loss 0.562488.
Train: 2018-08-01T01:05:55.545445: step 19014, loss 0.562481.
Train: 2018-08-01T01:05:55.701629: step 19015, loss 0.52729.
Train: 2018-08-01T01:05:55.857843: step 19016, loss 0.58005.
Train: 2018-08-01T01:05:56.014091: step 19017, loss 0.632722.
Train: 2018-08-01T01:05:56.170302: step 19018, loss 0.597521.
Train: 2018-08-01T01:05:56.326482: step 19019, loss 0.562445.
Train: 2018-08-01T01:05:56.482695: step 19020, loss 0.632276.
Test: 2018-08-01T01:05:56.951366: step 19020, loss 0.547846.
Train: 2018-08-01T01:05:57.107580: step 19021, loss 0.579837.
Train: 2018-08-01T01:05:57.263793: step 19022, loss 0.562418.
Train: 2018-08-01T01:05:57.420006: step 19023, loss 0.57973.
Train: 2018-08-01T01:05:57.576220: step 19024, loss 0.562406.
Train: 2018-08-01T01:05:57.732402: step 19025, loss 0.596871.
Train: 2018-08-01T01:05:57.888647: step 19026, loss 0.493645.
Train: 2018-08-01T01:05:58.044859: step 19027, loss 0.493742.
Train: 2018-08-01T01:05:58.216665: step 19028, loss 0.59672.
Train: 2018-08-01T01:05:58.372879: step 19029, loss 0.510963.
Train: 2018-08-01T01:05:58.544713: step 19030, loss 0.648133.
Test: 2018-08-01T01:05:59.013353: step 19030, loss 0.54806.
Train: 2018-08-01T01:05:59.169597: step 19031, loss 0.476769.
Train: 2018-08-01T01:05:59.341426: step 19032, loss 0.528144.
Train: 2018-08-01T01:05:59.497645: step 19033, loss 0.528123.
Train: 2018-08-01T01:05:59.669449: step 19034, loss 0.665341.
Train: 2018-08-01T01:05:59.825688: step 19035, loss 0.493809.
Train: 2018-08-01T01:05:59.981900: step 19036, loss 0.579558.
Train: 2018-08-01T01:06:00.138126: step 19037, loss 0.596721.
Train: 2018-08-01T01:06:00.294329: step 19038, loss 0.510935.
Train: 2018-08-01T01:06:00.450547: step 19039, loss 0.510912.
Train: 2018-08-01T01:06:00.606729: step 19040, loss 0.613947.
Test: 2018-08-01T01:06:01.075400: step 19040, loss 0.548009.
Train: 2018-08-01T01:06:01.215993: step 19041, loss 0.528027.
Train: 2018-08-01T01:06:01.372175: step 19042, loss 0.596801.
Train: 2018-08-01T01:06:01.544048: step 19043, loss 0.545199.
Train: 2018-08-01T01:06:01.700254: step 19044, loss 0.527984.
Train: 2018-08-01T01:06:01.856462: step 19045, loss 0.493511.
Train: 2018-08-01T01:06:02.012682: step 19046, loss 0.407143.
Train: 2018-08-01T01:06:02.168894: step 19047, loss 0.631661.
Train: 2018-08-01T01:06:02.325102: step 19048, loss 0.61447.
Train: 2018-08-01T01:06:02.481321: step 19049, loss 0.545045.
Train: 2018-08-01T01:06:02.637535: step 19050, loss 0.684201.
Test: 2018-08-01T01:06:03.121767: step 19050, loss 0.54786.
Train: 2018-08-01T01:06:03.277980: step 19051, loss 0.562422.
Train: 2018-08-01T01:06:03.434217: step 19052, loss 0.492896.
Train: 2018-08-01T01:06:03.590406: step 19053, loss 0.492864.
Train: 2018-08-01T01:06:03.746620: step 19054, loss 0.562426.
Train: 2018-08-01T01:06:03.902833: step 19055, loss 0.667022.
Train: 2018-08-01T01:06:04.074667: step 19056, loss 0.562428.
Train: 2018-08-01T01:06:04.230882: step 19057, loss 0.475339.
Train: 2018-08-01T01:06:04.387125: step 19058, loss 0.719302.
Train: 2018-08-01T01:06:04.543308: step 19059, loss 0.562424.
Train: 2018-08-01T01:06:04.699521: step 19060, loss 0.527658.
Test: 2018-08-01T01:06:05.168192: step 19060, loss 0.547875.
Train: 2018-08-01T01:06:05.324406: step 19061, loss 0.527684.
Train: 2018-08-01T01:06:05.480588: step 19062, loss 0.631864.
Train: 2018-08-01T01:06:05.636832: step 19063, loss 0.579754.
Train: 2018-08-01T01:06:05.793015: step 19064, loss 0.562411.
Train: 2018-08-01T01:06:05.949229: step 19065, loss 0.441345.
Train: 2018-08-01T01:06:06.105442: step 19066, loss 0.683527.
Train: 2018-08-01T01:06:06.277276: step 19067, loss 0.510563.
Train: 2018-08-01T01:06:06.433490: step 19068, loss 0.527859.
Train: 2018-08-01T01:06:06.589703: step 19069, loss 0.545132.
Train: 2018-08-01T01:06:06.745947: step 19070, loss 0.631522.
Test: 2018-08-01T01:06:07.230207: step 19070, loss 0.547947.
Train: 2018-08-01T01:06:07.402044: step 19071, loss 0.579672.
Train: 2018-08-01T01:06:07.558252: step 19072, loss 0.596906.
Train: 2018-08-01T01:06:07.714465: step 19073, loss 0.579631.
Train: 2018-08-01T01:06:07.870685: step 19074, loss 0.476381.
Train: 2018-08-01T01:06:08.026892: step 19075, loss 0.562401.
Train: 2018-08-01T01:06:08.183117: step 19076, loss 0.4764.
Train: 2018-08-01T01:06:08.339326: step 19077, loss 0.493528.
Train: 2018-08-01T01:06:08.526775: step 19078, loss 0.510652.
Train: 2018-08-01T01:06:08.682965: step 19079, loss 0.579699.
Train: 2018-08-01T01:06:08.839177: step 19080, loss 0.493117.
Test: 2018-08-01T01:06:09.307848: step 19080, loss 0.547874.
Train: 2018-08-01T01:06:09.464031: step 19081, loss 0.510313.
Train: 2018-08-01T01:06:09.635865: step 19082, loss 0.510168.
Train: 2018-08-01T01:06:09.776482: step 19083, loss 0.544963.
Train: 2018-08-01T01:06:09.948293: step 19084, loss 0.615051.
Train: 2018-08-01T01:06:10.104506: step 19085, loss 0.597602.
Train: 2018-08-01T01:06:10.260744: step 19086, loss 0.615248.
Train: 2018-08-01T01:06:10.416963: step 19087, loss 0.650471.
Train: 2018-08-01T01:06:10.573178: step 19088, loss 0.527301.
Train: 2018-08-01T01:06:10.729359: step 19089, loss 0.492156.
Train: 2018-08-01T01:06:10.885603: step 19090, loss 0.580058.
Test: 2018-08-01T01:06:11.354244: step 19090, loss 0.547743.
Train: 2018-08-01T01:06:11.510457: step 19091, loss 0.509703.
Train: 2018-08-01T01:06:11.682261: step 19092, loss 0.527271.
Train: 2018-08-01T01:06:11.838474: step 19093, loss 0.474375.
Train: 2018-08-01T01:06:11.979097: step 19094, loss 0.686095.
Train: 2018-08-01T01:06:12.135280: step 19095, loss 0.580156.
Train: 2018-08-01T01:06:12.291494: step 19096, loss 0.456563.
Train: 2018-08-01T01:06:12.463328: step 19097, loss 0.509479.
Train: 2018-08-01T01:06:12.603951: step 19098, loss 0.597919.
Train: 2018-08-01T01:06:12.760167: step 19099, loss 0.527085.
Train: 2018-08-01T01:06:12.931999: step 19100, loss 0.509315.
Test: 2018-08-01T01:06:13.400609: step 19100, loss 0.547665.
Train: 2018-08-01T01:06:14.119222: step 19101, loss 0.651375.
Train: 2018-08-01T01:06:14.291025: step 19102, loss 0.509234.
Train: 2018-08-01T01:06:14.447238: step 19103, loss 0.704818.
Train: 2018-08-01T01:06:14.603482: step 19104, loss 0.509255.
Train: 2018-08-01T01:06:14.759696: step 19105, loss 0.59804.
Train: 2018-08-01T01:06:14.931538: step 19106, loss 0.651196.
Train: 2018-08-01T01:06:15.103335: step 19107, loss 0.544816.
Train: 2018-08-01T01:06:15.259549: step 19108, loss 0.580162.
Train: 2018-08-01T01:06:15.400165: step 19109, loss 0.597743.
Train: 2018-08-01T01:06:15.571975: step 19110, loss 0.615236.
Test: 2018-08-01T01:06:16.040642: step 19110, loss 0.54777.
Train: 2018-08-01T01:06:16.212476: step 19111, loss 0.597533.
Train: 2018-08-01T01:06:16.384285: step 19112, loss 0.579926.
Train: 2018-08-01T01:06:16.540523: step 19113, loss 0.57986.
Train: 2018-08-01T01:06:16.696712: step 19114, loss 0.527664.
Train: 2018-08-01T01:06:16.852926: step 19115, loss 0.614424.
Train: 2018-08-01T01:06:17.009163: step 19116, loss 0.648847.
Train: 2018-08-01T01:06:17.165353: step 19117, loss 0.614072.
Train: 2018-08-01T01:06:17.352838: step 19118, loss 0.579553.
Train: 2018-08-01T01:06:17.509052: step 19119, loss 0.750345.
Train: 2018-08-01T01:06:17.665266: step 19120, loss 0.579394.
Test: 2018-08-01T01:06:18.133905: step 19120, loss 0.54829.
Train: 2018-08-01T01:06:18.305747: step 19121, loss 0.596198.
Train: 2018-08-01T01:06:18.461923: step 19122, loss 0.428134.
Train: 2018-08-01T01:06:18.618171: step 19123, loss 0.612682.
Train: 2018-08-01T01:06:18.774381: step 19124, loss 0.529127.
Train: 2018-08-01T01:06:18.930595: step 19125, loss 0.579142.
Train: 2018-08-01T01:06:19.086777: step 19126, loss 0.545923.
Train: 2018-08-01T01:06:19.242990: step 19127, loss 0.64537.
Train: 2018-08-01T01:06:19.414825: step 19128, loss 0.512992.
Train: 2018-08-01T01:06:19.571069: step 19129, loss 0.579064.
Train: 2018-08-01T01:06:19.727282: step 19130, loss 0.546116.
Test: 2018-08-01T01:06:20.195922: step 19130, loss 0.548818.
Train: 2018-08-01T01:06:20.352106: step 19131, loss 0.496794.
Train: 2018-08-01T01:06:20.508319: step 19132, loss 0.579044.
Train: 2018-08-01T01:06:20.680156: step 19133, loss 0.61195.
Train: 2018-08-01T01:06:20.836398: step 19134, loss 0.546154.
Train: 2018-08-01T01:06:20.992611: step 19135, loss 0.431075.
Train: 2018-08-01T01:06:21.148825: step 19136, loss 0.513164.
Train: 2018-08-01T01:06:21.320628: step 19137, loss 0.579075.
Train: 2018-08-01T01:06:21.476843: step 19138, loss 0.529438.
Train: 2018-08-01T01:06:21.648677: step 19139, loss 0.529333.
Train: 2018-08-01T01:06:21.804915: step 19140, loss 0.562502.
Test: 2018-08-01T01:06:22.273530: step 19140, loss 0.548511.
Train: 2018-08-01T01:06:22.429775: step 19141, loss 0.579173.
Train: 2018-08-01T01:06:22.601579: step 19142, loss 0.495567.
Train: 2018-08-01T01:06:22.789035: step 19143, loss 0.596011.
Train: 2018-08-01T01:06:22.945249: step 19144, loss 0.562444.
Train: 2018-08-01T01:06:23.101462: step 19145, loss 0.579289.
Train: 2018-08-01T01:06:23.257675: step 19146, loss 0.663732.
Train: 2018-08-01T01:06:23.413919: step 19147, loss 0.579315.
Train: 2018-08-01T01:06:23.570102: step 19148, loss 0.596204.
Train: 2018-08-01T01:06:23.741938: step 19149, loss 0.528667.
Train: 2018-08-01T01:06:23.898150: step 19150, loss 0.596196.
Test: 2018-08-01T01:06:24.366821: step 19150, loss 0.548296.
Train: 2018-08-01T01:06:24.523004: step 19151, loss 0.56243.
Train: 2018-08-01T01:06:24.679217: step 19152, loss 0.646806.
Train: 2018-08-01T01:06:24.835470: step 19153, loss 0.52873.
Train: 2018-08-01T01:06:24.991675: step 19154, loss 0.57928.
Train: 2018-08-01T01:06:25.163512: step 19155, loss 0.545613.
Train: 2018-08-01T01:06:25.319692: step 19156, loss 0.579265.
Train: 2018-08-01T01:06:25.491528: step 19157, loss 0.629697.
Train: 2018-08-01T01:06:25.632120: step 19158, loss 0.629611.
Train: 2018-08-01T01:06:25.788333: step 19159, loss 0.562462.
Train: 2018-08-01T01:06:25.960169: step 19160, loss 0.662812.
Test: 2018-08-01T01:06:26.428838: step 19160, loss 0.548529.
Train: 2018-08-01T01:06:26.585052: step 19161, loss 0.579163.
Train: 2018-08-01T01:06:26.756888: step 19162, loss 0.52926.
Train: 2018-08-01T01:06:26.913070: step 19163, loss 0.51275.
Train: 2018-08-01T01:06:27.084909: step 19164, loss 0.496231.
Train: 2018-08-01T01:06:27.241119: step 19165, loss 0.562529.
Train: 2018-08-01T01:06:27.397331: step 19166, loss 0.512779.
Train: 2018-08-01T01:06:27.553544: step 19167, loss 0.545919.
Train: 2018-08-01T01:06:27.725409: step 19168, loss 0.612378.
Train: 2018-08-01T01:06:27.881592: step 19169, loss 0.612402.
Train: 2018-08-01T01:06:28.037806: step 19170, loss 0.629027.
Test: 2018-08-01T01:06:28.506476: step 19170, loss 0.548602.
Train: 2018-08-01T01:06:28.662660: step 19171, loss 0.579127.
Train: 2018-08-01T01:06:28.834495: step 19172, loss 0.51273.
Train: 2018-08-01T01:06:28.990738: step 19173, loss 0.595712.
Train: 2018-08-01T01:06:29.146952: step 19174, loss 0.562525.
Train: 2018-08-01T01:06:29.318757: step 19175, loss 0.57911.
Train: 2018-08-01T01:06:29.474971: step 19176, loss 0.545954.
Train: 2018-08-01T01:06:29.631183: step 19177, loss 0.545954.
Train: 2018-08-01T01:06:29.787396: step 19178, loss 0.529365.
Train: 2018-08-01T01:06:29.943610: step 19179, loss 0.579117.
Train: 2018-08-01T01:06:30.099849: step 19180, loss 0.678768.
Test: 2018-08-01T01:06:30.568495: step 19180, loss 0.54863.
Train: 2018-08-01T01:06:30.724677: step 19181, loss 0.579114.
Train: 2018-08-01T01:06:30.880890: step 19182, loss 0.512809.
Train: 2018-08-01T01:06:31.037134: step 19183, loss 0.512815.
Train: 2018-08-01T01:06:31.193316: step 19184, loss 0.512771.
Train: 2018-08-01T01:06:31.349561: step 19185, loss 0.529295.
Train: 2018-08-01T01:06:31.521389: step 19186, loss 0.545859.
Train: 2018-08-01T01:06:31.677603: step 19187, loss 0.712587.
Train: 2018-08-01T01:06:31.833792: step 19188, loss 0.595838.
Train: 2018-08-01T01:06:31.974415: step 19189, loss 0.5125.
Train: 2018-08-01T01:06:32.146245: step 19190, loss 0.579161.
Test: 2018-08-01T01:06:32.614890: step 19190, loss 0.54853.
Train: 2018-08-01T01:06:32.755482: step 19191, loss 0.512477.
Train: 2018-08-01T01:06:32.911664: step 19192, loss 0.529112.
Train: 2018-08-01T01:06:33.083530: step 19193, loss 0.595897.
Train: 2018-08-01T01:06:33.239747: step 19194, loss 0.562472.
Train: 2018-08-01T01:06:33.411573: step 19195, loss 0.629423.
Train: 2018-08-01T01:06:33.567791: step 19196, loss 0.662889.
Train: 2018-08-01T01:06:33.739621: step 19197, loss 0.529052.
Train: 2018-08-01T01:06:33.895839: step 19198, loss 0.562481.
Train: 2018-08-01T01:06:34.052053: step 19199, loss 0.462349.
Train: 2018-08-01T01:06:34.208267: step 19200, loss 0.529067.
Test: 2018-08-01T01:06:34.676877: step 19200, loss 0.548461.
Train: 2018-08-01T01:06:35.364216: step 19201, loss 0.395167.
Train: 2018-08-01T01:06:35.536081: step 19202, loss 0.562451.
Train: 2018-08-01T01:06:35.692264: step 19203, loss 0.629843.
Train: 2018-08-01T01:06:35.864100: step 19204, loss 0.545539.
Train: 2018-08-01T01:06:36.020353: step 19205, loss 0.613203.
Train: 2018-08-01T01:06:36.176556: step 19206, loss 0.579367.
Train: 2018-08-01T01:06:36.332738: step 19207, loss 0.579382.
Train: 2018-08-01T01:06:36.488982: step 19208, loss 0.494491.
Train: 2018-08-01T01:06:36.645190: step 19209, loss 0.460361.
Train: 2018-08-01T01:06:36.801410: step 19210, loss 0.562404.
Test: 2018-08-01T01:06:37.270020: step 19210, loss 0.54808.
Train: 2018-08-01T01:06:37.441884: step 19211, loss 0.528197.
Train: 2018-08-01T01:06:37.598067: step 19212, loss 0.631003.
Train: 2018-08-01T01:06:37.754281: step 19213, loss 0.5624.
Train: 2018-08-01T01:06:37.910525: step 19214, loss 0.579604.
Train: 2018-08-01T01:06:38.082365: step 19215, loss 0.682952.
Train: 2018-08-01T01:06:38.238573: step 19216, loss 0.579611.
Train: 2018-08-01T01:06:38.394786: step 19217, loss 0.510817.
Train: 2018-08-01T01:06:38.551000: step 19218, loss 0.631173.
Train: 2018-08-01T01:06:38.691562: step 19219, loss 0.476522.
Train: 2018-08-01T01:06:38.863397: step 19220, loss 0.5624.
Test: 2018-08-01T01:06:39.332036: step 19220, loss 0.548011.
Train: 2018-08-01T01:06:39.488280: step 19221, loss 0.5624.
Train: 2018-08-01T01:06:39.644494: step 19222, loss 0.596774.
Train: 2018-08-01T01:06:39.816329: step 19223, loss 0.545218.
Train: 2018-08-01T01:06:39.972542: step 19224, loss 0.5624.
Train: 2018-08-01T01:06:40.128750: step 19225, loss 0.648301.
Train: 2018-08-01T01:06:40.300559: step 19226, loss 0.528081.
Train: 2018-08-01T01:06:40.456772: step 19227, loss 0.476656.
Train: 2018-08-01T01:06:40.612986: step 19228, loss 0.528081.
Train: 2018-08-01T01:06:40.784820: step 19229, loss 0.596753.
Train: 2018-08-01T01:06:40.941065: step 19230, loss 0.528031.
Test: 2018-08-01T01:06:41.409675: step 19230, loss 0.547998.
Train: 2018-08-01T01:06:41.565918: step 19231, loss 0.5624.
Train: 2018-08-01T01:06:41.722132: step 19232, loss 0.596825.
Train: 2018-08-01T01:06:41.878345: step 19233, loss 0.527969.
Train: 2018-08-01T01:06:42.034528: step 19234, loss 0.63131.
Train: 2018-08-01T01:06:42.190741: step 19235, loss 0.54518.
Train: 2018-08-01T01:06:42.362614: step 19236, loss 0.476305.
Train: 2018-08-01T01:06:42.534442: step 19237, loss 0.562402.
Train: 2018-08-01T01:06:42.690656: step 19238, loss 0.665925.
Train: 2018-08-01T01:06:42.846837: step 19239, loss 0.510671.
Train: 2018-08-01T01:06:43.003052: step 19240, loss 0.527909.
Test: 2018-08-01T01:06:43.487313: step 19240, loss 0.547952.
Train: 2018-08-01T01:06:43.643557: step 19241, loss 0.476117.
Train: 2018-08-01T01:06:43.784149: step 19242, loss 0.631551.
Train: 2018-08-01T01:06:43.955985: step 19243, loss 0.562407.
Train: 2018-08-01T01:06:44.112197: step 19244, loss 0.579712.
Train: 2018-08-01T01:06:44.268411: step 19245, loss 0.614331.
Train: 2018-08-01T01:06:44.424593: step 19246, loss 0.527811.
Train: 2018-08-01T01:06:44.596468: step 19247, loss 0.458627.
Train: 2018-08-01T01:06:44.752643: step 19248, loss 0.631686.
Train: 2018-08-01T01:06:44.924508: step 19249, loss 0.510441.
Train: 2018-08-01T01:06:45.080721: step 19250, loss 0.562412.
Test: 2018-08-01T01:06:45.564951: step 19250, loss 0.547884.
Train: 2018-08-01T01:06:45.799273: step 19251, loss 0.597115.
Train: 2018-08-01T01:06:45.955485: step 19252, loss 0.527706.
Train: 2018-08-01T01:06:46.111700: step 19253, loss 0.510324.
Train: 2018-08-01T01:06:46.252321: step 19254, loss 0.614573.
Train: 2018-08-01T01:06:46.408535: step 19255, loss 0.57981.
Train: 2018-08-01T01:06:46.580369: step 19256, loss 0.527639.
Train: 2018-08-01T01:06:46.736585: step 19257, loss 0.597218.
Train: 2018-08-01T01:06:46.924039: step 19258, loss 0.475439.
Train: 2018-08-01T01:06:47.064601: step 19259, loss 0.54501.
Train: 2018-08-01T01:06:47.220844: step 19260, loss 0.544995.
Test: 2018-08-01T01:06:47.705076: step 19260, loss 0.547817.
Train: 2018-08-01T01:06:47.876936: step 19261, loss 0.597341.
Train: 2018-08-01T01:06:48.048745: step 19262, loss 0.492582.
Train: 2018-08-01T01:06:48.204958: step 19263, loss 0.527467.
Train: 2018-08-01T01:06:48.361172: step 19264, loss 0.506399.
Train: 2018-08-01T01:06:48.517385: step 19265, loss 0.580012.
Train: 2018-08-01T01:06:48.673600: step 19266, loss 0.650374.
Train: 2018-08-01T01:06:48.829842: step 19267, loss 0.509714.
Train: 2018-08-01T01:06:48.986027: step 19268, loss 0.544874.
Train: 2018-08-01T01:06:49.142274: step 19269, loss 0.59771.
Train: 2018-08-01T01:06:49.298452: step 19270, loss 0.544861.
Test: 2018-08-01T01:06:49.767123: step 19270, loss 0.547723.
Train: 2018-08-01T01:06:49.923306: step 19271, loss 0.544857.
Train: 2018-08-01T01:06:50.079521: step 19272, loss 0.527216.
Train: 2018-08-01T01:06:50.251355: step 19273, loss 0.615441.
Train: 2018-08-01T01:06:50.391982: step 19274, loss 0.544856.
Train: 2018-08-01T01:06:50.548160: step 19275, loss 0.491888.
Train: 2018-08-01T01:06:50.704404: step 19276, loss 0.615501.
Train: 2018-08-01T01:06:50.860586: step 19277, loss 0.509494.
Train: 2018-08-01T01:06:51.016831: step 19278, loss 0.491784.
Train: 2018-08-01T01:06:51.188635: step 19279, loss 0.562514.
Train: 2018-08-01T01:06:51.344849: step 19280, loss 0.580249.
Test: 2018-08-01T01:06:51.813519: step 19280, loss 0.547675.
Train: 2018-08-01T01:06:51.969702: step 19281, loss 0.54479.
Train: 2018-08-01T01:06:52.125945: step 19282, loss 0.562535.
Train: 2018-08-01T01:06:52.282154: step 19283, loss 0.686883.
Train: 2018-08-01T01:06:52.453996: step 19284, loss 0.491561.
Train: 2018-08-01T01:06:52.610178: step 19285, loss 0.527052.
Train: 2018-08-01T01:06:52.766421: step 19286, loss 0.544789.
Train: 2018-08-01T01:06:52.922635: step 19287, loss 0.580278.
Train: 2018-08-01T01:06:53.078848: step 19288, loss 0.580275.
Train: 2018-08-01T01:06:53.235061: step 19289, loss 0.668945.
Train: 2018-08-01T01:06:53.406875: step 19290, loss 0.420889.
Test: 2018-08-01T01:06:53.875535: step 19290, loss 0.547689.
Train: 2018-08-01T01:06:54.031720: step 19291, loss 0.580219.
Train: 2018-08-01T01:06:54.187932: step 19292, loss 0.544813.
Train: 2018-08-01T01:06:54.344147: step 19293, loss 0.597908.
Train: 2018-08-01T01:06:54.516005: step 19294, loss 0.580194.
Train: 2018-08-01T01:06:54.672195: step 19295, loss 0.633183.
Train: 2018-08-01T01:06:54.828438: step 19296, loss 0.580127.
Train: 2018-08-01T01:06:54.984621: step 19297, loss 0.544873.
Train: 2018-08-01T01:06:55.140834: step 19298, loss 0.43944.
Train: 2018-08-01T01:06:55.297048: step 19299, loss 0.439429.
Train: 2018-08-01T01:06:55.453261: step 19300, loss 0.509661.
Test: 2018-08-01T01:06:55.921902: step 19300, loss 0.547717.
Train: 2018-08-01T01:06:56.624892: step 19301, loss 0.527207.
Train: 2018-08-01T01:06:56.796728: step 19302, loss 0.597867.
Train: 2018-08-01T01:06:56.952941: step 19303, loss 0.544809.
Train: 2018-08-01T01:06:57.109153: step 19304, loss 0.704383.
Train: 2018-08-01T01:06:57.265367: step 19305, loss 0.473918.
Train: 2018-08-01T01:06:57.421575: step 19306, loss 0.562525.
Train: 2018-08-01T01:06:57.577765: step 19307, loss 0.544793.
Train: 2018-08-01T01:06:57.734007: step 19308, loss 0.615758.
Train: 2018-08-01T01:06:57.921470: step 19309, loss 0.473852.
Train: 2018-08-01T01:06:58.077677: step 19310, loss 0.527039.
Test: 2018-08-01T01:06:58.546323: step 19310, loss 0.547665.
Train: 2018-08-01T01:06:58.702530: step 19311, loss 0.527012.
Train: 2018-08-01T01:06:58.874336: step 19312, loss 0.52698.
Train: 2018-08-01T01:06:59.046169: step 19313, loss 0.562563.
Train: 2018-08-01T01:06:59.202413: step 19314, loss 0.473413.
Train: 2018-08-01T01:06:59.358596: step 19315, loss 0.508986.
Train: 2018-08-01T01:06:59.514841: step 19316, loss 0.490968.
Train: 2018-08-01T01:06:59.671054: step 19317, loss 0.616544.
Train: 2018-08-01T01:06:59.827268: step 19318, loss 0.526673.
Train: 2018-08-01T01:06:59.999073: step 19319, loss 0.508592.
Train: 2018-08-01T01:07:00.155284: step 19320, loss 0.526571.
Test: 2018-08-01T01:07:00.623955: step 19320, loss 0.547579.
Train: 2018-08-01T01:07:00.795761: step 19321, loss 0.526516.
Train: 2018-08-01T01:07:00.951973: step 19322, loss 0.508302.
Train: 2018-08-01T01:07:01.108187: step 19323, loss 0.453571.
Train: 2018-08-01T01:07:01.264431: step 19324, loss 0.635961.
Train: 2018-08-01T01:07:01.420645: step 19325, loss 0.617836.
Train: 2018-08-01T01:07:01.592479: step 19326, loss 0.452945.
Train: 2018-08-01T01:07:01.748661: step 19327, loss 0.489487.
Train: 2018-08-01T01:07:01.904875: step 19328, loss 0.470932.
Train: 2018-08-01T01:07:02.061088: step 19329, loss 0.65541.
Train: 2018-08-01T01:07:02.217302: step 19330, loss 0.544582.
Test: 2018-08-01T01:07:02.685973: step 19330, loss 0.547595.
Train: 2018-08-01T01:07:02.842156: step 19331, loss 0.61868.
Train: 2018-08-01T01:07:02.998370: step 19332, loss 0.507522.
Train: 2018-08-01T01:07:03.170230: step 19333, loss 0.507495.
Train: 2018-08-01T01:07:03.342050: step 19334, loss 0.52602.
Train: 2018-08-01T01:07:03.498252: step 19335, loss 0.581759.
Train: 2018-08-01T01:07:03.654496: step 19336, loss 0.581783.
Train: 2018-08-01T01:07:03.810678: step 19337, loss 0.488787.
Train: 2018-08-01T01:07:03.966923: step 19338, loss 0.451521.
Train: 2018-08-01T01:07:04.123131: step 19339, loss 0.5073.
Train: 2018-08-01T01:07:04.279349: step 19340, loss 0.525914.
Test: 2018-08-01T01:07:04.763611: step 19340, loss 0.547646.
Train: 2018-08-01T01:07:04.935415: step 19341, loss 0.600757.
Train: 2018-08-01T01:07:05.091660: step 19342, loss 0.413439.
Train: 2018-08-01T01:07:05.232251: step 19343, loss 0.563398.
Train: 2018-08-01T01:07:05.404056: step 19344, loss 0.582262.
Train: 2018-08-01T01:07:05.575892: step 19345, loss 0.582314.
Train: 2018-08-01T01:07:05.732136: step 19346, loss 0.582341.
Train: 2018-08-01T01:07:05.888317: step 19347, loss 0.6012.
Train: 2018-08-01T01:07:06.044530: step 19348, loss 0.544629.
Train: 2018-08-01T01:07:06.200769: step 19349, loss 0.619954.
Train: 2018-08-01T01:07:06.341337: step 19350, loss 0.563423.
Test: 2018-08-01T01:07:06.825628: step 19350, loss 0.547665.
Train: 2018-08-01T01:07:06.981841: step 19351, loss 0.600934.
Train: 2018-08-01T01:07:07.138024: step 19352, loss 0.544604.
Train: 2018-08-01T01:07:07.294269: step 19353, loss 0.600689.
Train: 2018-08-01T01:07:07.450484: step 19354, loss 0.50729.
Train: 2018-08-01T01:07:07.606696: step 19355, loss 0.581823.
Train: 2018-08-01T01:07:07.762905: step 19356, loss 0.526007.
Train: 2018-08-01T01:07:07.934744: step 19357, loss 0.507489.
Train: 2018-08-01T01:07:08.090959: step 19358, loss 0.600163.
Train: 2018-08-01T01:07:08.247171: step 19359, loss 0.60007.
Train: 2018-08-01T01:07:08.418975: step 19360, loss 0.544582.
Test: 2018-08-01T01:07:08.887645: step 19360, loss 0.547579.
Train: 2018-08-01T01:07:09.043859: step 19361, loss 0.4709.
Train: 2018-08-01T01:07:09.200066: step 19362, loss 0.489368.
Train: 2018-08-01T01:07:09.340634: step 19363, loss 0.618199.
Train: 2018-08-01T01:07:09.512469: step 19364, loss 0.710061.
Train: 2018-08-01T01:07:09.668682: step 19365, loss 0.507922.
Train: 2018-08-01T01:07:09.824926: step 19366, loss 0.416522.
Train: 2018-08-01T01:07:09.996762: step 19367, loss 0.489723.
Train: 2018-08-01T01:07:10.152945: step 19368, loss 0.709283.
Train: 2018-08-01T01:07:10.324808: step 19369, loss 0.562869.
Train: 2018-08-01T01:07:10.481022: step 19370, loss 0.544604.
Test: 2018-08-01T01:07:10.965279: step 19370, loss 0.547571.
Train: 2018-08-01T01:07:11.137114: step 19371, loss 0.562824.
Train: 2018-08-01T01:07:11.293326: step 19372, loss 0.508236.
Train: 2018-08-01T01:07:11.449515: step 19373, loss 0.508269.
Train: 2018-08-01T01:07:11.605730: step 19374, loss 0.580959.
Train: 2018-08-01T01:07:11.761973: step 19375, loss 0.56278.
Train: 2018-08-01T01:07:11.933807: step 19376, loss 0.653502.
Train: 2018-08-01T01:07:12.089992: step 19377, loss 0.454077.
Train: 2018-08-01T01:07:12.246203: step 19378, loss 0.562738.
Train: 2018-08-01T01:07:12.402416: step 19379, loss 0.653176.
Train: 2018-08-01T01:07:12.558656: step 19380, loss 0.526594.
Test: 2018-08-01T01:07:13.042932: step 19380, loss 0.54759.
Train: 2018-08-01T01:07:13.199107: step 19381, loss 0.508597.
Train: 2018-08-01T01:07:13.370940: step 19382, loss 0.544663.
Train: 2018-08-01T01:07:13.527184: step 19383, loss 0.454631.
Train: 2018-08-01T01:07:13.683397: step 19384, loss 0.544662.
Train: 2018-08-01T01:07:13.839610: step 19385, loss 0.490562.
Train: 2018-08-01T01:07:13.995818: step 19386, loss 0.59882.
Train: 2018-08-01T01:07:14.152038: step 19387, loss 0.562714.
Train: 2018-08-01T01:07:14.308246: step 19388, loss 0.454267.
Train: 2018-08-01T01:07:14.464464: step 19389, loss 0.61705.
Train: 2018-08-01T01:07:14.620648: step 19390, loss 0.562747.
Test: 2018-08-01T01:07:15.089319: step 19390, loss 0.547578.
Train: 2018-08-01T01:07:15.245502: step 19391, loss 0.50839.
Train: 2018-08-01T01:07:15.417369: step 19392, loss 0.45395.
Train: 2018-08-01T01:07:15.573551: step 19393, loss 0.471938.
Train: 2018-08-01T01:07:15.729792: step 19394, loss 0.581045.
Train: 2018-08-01T01:07:15.886006: step 19395, loss 0.65413.
Train: 2018-08-01T01:07:16.042221: step 19396, loss 0.617655.
Train: 2018-08-01T01:07:16.198433: step 19397, loss 0.581114.
Train: 2018-08-01T01:07:16.354618: step 19398, loss 0.581088.
Train: 2018-08-01T01:07:16.526462: step 19399, loss 0.635718.
Train: 2018-08-01T01:07:16.682695: step 19400, loss 0.617354.
Test: 2018-08-01T01:07:17.166957: step 19400, loss 0.547576.
Train: 2018-08-01T01:07:17.823053: step 19401, loss 0.508355.
Train: 2018-08-01T01:07:17.994857: step 19402, loss 0.671342.
Train: 2018-08-01T01:07:18.151101: step 19403, loss 0.688992.
Train: 2018-08-01T01:07:18.322905: step 19404, loss 0.562643.
Train: 2018-08-01T01:07:18.463528: step 19405, loss 0.616241.
Train: 2018-08-01T01:07:18.619741: step 19406, loss 0.580351.
Train: 2018-08-01T01:07:18.791547: step 19407, loss 0.544802.
Train: 2018-08-01T01:07:18.947760: step 19408, loss 0.685993.
Train: 2018-08-01T01:07:19.119625: step 19409, loss 0.474709.
Train: 2018-08-01T01:07:19.275837: step 19410, loss 0.562439.
Test: 2018-08-01T01:07:19.744482: step 19410, loss 0.547835.
Train: 2018-08-01T01:07:19.931934: step 19411, loss 0.614698.
Train: 2018-08-01T01:07:20.088118: step 19412, loss 0.492984.
Train: 2018-08-01T01:07:20.244331: step 19413, loss 0.597032.
Train: 2018-08-01T01:07:20.400544: step 19414, loss 0.545139.
Train: 2018-08-01T01:07:20.556757: step 19415, loss 0.545176.
Train: 2018-08-01T01:07:20.713001: step 19416, loss 0.579589.
Train: 2018-08-01T01:07:20.884831: step 19417, loss 0.562398.
Train: 2018-08-01T01:07:21.056640: step 19418, loss 0.511015.
Train: 2018-08-01T01:07:21.197264: step 19419, loss 0.545286.
Train: 2018-08-01T01:07:21.353477: step 19420, loss 0.61371.
Test: 2018-08-01T01:07:21.837738: step 19420, loss 0.548095.
Train: 2018-08-01T01:07:22.009543: step 19421, loss 0.511149.
Train: 2018-08-01T01:07:22.165755: step 19422, loss 0.528245.
Train: 2018-08-01T01:07:22.322000: step 19423, loss 0.528238.
Train: 2018-08-01T01:07:22.478217: step 19424, loss 0.545307.
Train: 2018-08-01T01:07:22.634426: step 19425, loss 0.528186.
Train: 2018-08-01T01:07:22.790641: step 19426, loss 0.630908.
Train: 2018-08-01T01:07:22.946853: step 19427, loss 0.511007.
Train: 2018-08-01T01:07:23.103065: step 19428, loss 0.562398.
Train: 2018-08-01T01:07:23.274895: step 19429, loss 0.476605.
Train: 2018-08-01T01:07:23.431115: step 19430, loss 0.648352.
Test: 2018-08-01T01:07:23.899725: step 19430, loss 0.547996.
Train: 2018-08-01T01:07:24.055938: step 19431, loss 0.527999.
Train: 2018-08-01T01:07:24.212153: step 19432, loss 0.441892.
Train: 2018-08-01T01:07:24.384016: step 19433, loss 0.545144.
Train: 2018-08-01T01:07:24.540200: step 19434, loss 0.597005.
Train: 2018-08-01T01:07:24.696444: step 19435, loss 0.614395.
Train: 2018-08-01T01:07:24.852627: step 19436, loss 0.701148.
Train: 2018-08-01T01:07:25.008871: step 19437, loss 0.614373.
Train: 2018-08-01T01:07:25.180674: step 19438, loss 0.700726.
Train: 2018-08-01T01:07:25.368156: step 19439, loss 0.631318.
Train: 2018-08-01T01:07:25.524344: step 19440, loss 0.510923.
Test: 2018-08-01T01:07:26.008635: step 19440, loss 0.548074.
Train: 2018-08-01T01:07:26.164850: step 19441, loss 0.665039.
Train: 2018-08-01T01:07:26.336655: step 19442, loss 0.66462.
Train: 2018-08-01T01:07:26.492867: step 19443, loss 0.409876.
Train: 2018-08-01T01:07:26.649080: step 19444, loss 0.596236.
Train: 2018-08-01T01:07:26.805319: step 19445, loss 0.562431.
Train: 2018-08-01T01:07:26.961538: step 19446, loss 0.579264.
Train: 2018-08-01T01:07:27.117752: step 19447, loss 0.713516.
Train: 2018-08-01T01:07:27.289555: step 19448, loss 0.495611.
Train: 2018-08-01T01:07:27.461391: step 19449, loss 0.57916.
Train: 2018-08-01T01:07:27.617604: step 19450, loss 0.662271.
Test: 2018-08-01T01:07:28.086244: step 19450, loss 0.54866.
Train: 2018-08-01T01:07:28.242489: step 19451, loss 0.562533.
Train: 2018-08-01T01:07:28.398701: step 19452, loss 0.513018.
Train: 2018-08-01T01:07:28.570506: step 19453, loss 0.546096.
Train: 2018-08-01T01:07:28.726719: step 19454, loss 0.595499.
Train: 2018-08-01T01:07:28.882933: step 19455, loss 0.611886.
Train: 2018-08-01T01:07:29.039172: step 19456, loss 0.529839.
Train: 2018-08-01T01:07:29.195395: step 19457, loss 0.59538.
Train: 2018-08-01T01:07:29.351573: step 19458, loss 0.578999.
Train: 2018-08-01T01:07:29.507817: step 19459, loss 0.49737.
Train: 2018-08-01T01:07:29.679659: step 19460, loss 0.611633.
Test: 2018-08-01T01:07:30.148291: step 19460, loss 0.549018.
Train: 2018-08-01T01:07:30.304506: step 19461, loss 0.578986.
Train: 2018-08-01T01:07:30.460718: step 19462, loss 0.59528.
Train: 2018-08-01T01:07:30.632554: step 19463, loss 0.595259.
Train: 2018-08-01T01:07:30.788738: step 19464, loss 0.481395.
Train: 2018-08-01T01:07:30.944974: step 19465, loss 0.59524.
Train: 2018-08-01T01:07:31.085543: step 19466, loss 0.611506.
Train: 2018-08-01T01:07:31.241781: step 19467, loss 0.497682.
Train: 2018-08-01T01:07:31.397969: step 19468, loss 0.513902.
Train: 2018-08-01T01:07:31.554215: step 19469, loss 0.578979.
Train: 2018-08-01T01:07:31.710395: step 19470, loss 0.530052.
Test: 2018-08-01T01:07:32.194687: step 19470, loss 0.548973.
Train: 2018-08-01T01:07:32.350901: step 19471, loss 0.595337.
Train: 2018-08-01T01:07:32.507114: step 19472, loss 0.562643.
Train: 2018-08-01T01:07:32.663328: step 19473, loss 0.56263.
Train: 2018-08-01T01:07:32.819535: step 19474, loss 0.644633.
Train: 2018-08-01T01:07:32.991347: step 19475, loss 0.644639.
Train: 2018-08-01T01:07:33.147560: step 19476, loss 0.562627.
Train: 2018-08-01T01:07:33.303803: step 19477, loss 0.595385.
Train: 2018-08-01T01:07:33.460016: step 19478, loss 0.562644.
Train: 2018-08-01T01:07:33.616199: step 19479, loss 0.660729.
Train: 2018-08-01T01:07:33.772444: step 19480, loss 0.497421.
Test: 2018-08-01T01:07:34.256704: step 19480, loss 0.54903.
Train: 2018-08-01T01:07:34.412918: step 19481, loss 0.660494.
Train: 2018-08-01T01:07:34.569132: step 19482, loss 0.611515.
Train: 2018-08-01T01:07:34.725345: step 19483, loss 0.497794.
Train: 2018-08-01T01:07:34.881552: step 19484, loss 0.643833.
Train: 2018-08-01T01:07:35.037772: step 19485, loss 0.659892.
Train: 2018-08-01T01:07:35.209601: step 19486, loss 0.562799.
Train: 2018-08-01T01:07:35.350192: step 19487, loss 0.530633.
Train: 2018-08-01T01:07:35.506412: step 19488, loss 0.578927.
Train: 2018-08-01T01:07:35.662626: step 19489, loss 0.53077.
Train: 2018-08-01T01:07:35.818808: step 19490, loss 0.546839.
Test: 2018-08-01T01:07:36.287484: step 19490, loss 0.549449.
Train: 2018-08-01T01:07:36.443663: step 19491, loss 0.54684.
Train: 2018-08-01T01:07:36.599906: step 19492, loss 0.546827.
Train: 2018-08-01T01:07:36.756089: step 19493, loss 0.498617.
Train: 2018-08-01T01:07:36.912333: step 19494, loss 0.546743.
Train: 2018-08-01T01:07:37.068546: step 19495, loss 0.595066.
Train: 2018-08-01T01:07:37.240375: step 19496, loss 0.627414.
Train: 2018-08-01T01:07:37.396598: step 19497, loss 0.465763.
Train: 2018-08-01T01:07:37.552777: step 19498, loss 0.611368.
Train: 2018-08-01T01:07:37.708990: step 19499, loss 0.578961.
Train: 2018-08-01T01:07:37.865204: step 19500, loss 0.562714.
Test: 2018-08-01T01:07:38.349496: step 19500, loss 0.54907.
Train: 2018-08-01T01:07:39.161808: step 19501, loss 0.513872.
Train: 2018-08-01T01:07:39.349232: step 19502, loss 0.595296.
Train: 2018-08-01T01:07:39.536688: step 19503, loss 0.529986.
Train: 2018-08-01T01:07:39.677280: step 19504, loss 0.497157.
Train: 2018-08-01T01:07:39.833519: step 19505, loss 0.562608.
Train: 2018-08-01T01:07:39.989731: step 19506, loss 0.628445.
Train: 2018-08-01T01:07:40.145921: step 19507, loss 0.612049.
Train: 2018-08-01T01:07:40.302134: step 19508, loss 0.595577.
Train: 2018-08-01T01:07:40.458348: step 19509, loss 0.579073.
Train: 2018-08-01T01:07:40.614587: step 19510, loss 0.628638.
Test: 2018-08-01T01:07:41.098852: step 19510, loss 0.548732.
Train: 2018-08-01T01:07:41.255035: step 19511, loss 0.57907.
Train: 2018-08-01T01:07:41.411284: step 19512, loss 0.612065.
Train: 2018-08-01T01:07:41.567494: step 19513, loss 0.579055.
Train: 2018-08-01T01:07:41.723676: step 19514, loss 0.562585.
Train: 2018-08-01T01:07:41.895510: step 19515, loss 0.579039.
Train: 2018-08-01T01:07:42.051755: step 19516, loss 0.579032.
Train: 2018-08-01T01:07:42.207937: step 19517, loss 0.546198.
Train: 2018-08-01T01:07:42.364181: step 19518, loss 0.546211.
Train: 2018-08-01T01:07:42.520388: step 19519, loss 0.628234.
Train: 2018-08-01T01:07:42.676577: step 19520, loss 0.497066.
Test: 2018-08-01T01:07:43.145248: step 19520, loss 0.548893.
Train: 2018-08-01T01:07:43.317052: step 19521, loss 0.611808.
Train: 2018-08-01T01:07:43.473296: step 19522, loss 0.611796.
Train: 2018-08-01T01:07:43.629510: step 19523, loss 0.546257.
Train: 2018-08-01T01:07:43.770071: step 19524, loss 0.677228.
Train: 2018-08-01T01:07:43.973181: step 19525, loss 0.546318.
Train: 2018-08-01T01:07:44.129363: step 19526, loss 0.530036.
Train: 2018-08-01T01:07:44.285607: step 19527, loss 0.562676.
Train: 2018-08-01T01:07:44.441789: step 19528, loss 0.51377.
Train: 2018-08-01T01:07:44.598002: step 19529, loss 0.513733.
Train: 2018-08-01T01:07:44.754246: step 19530, loss 0.529983.
Test: 2018-08-01T01:07:45.222887: step 19530, loss 0.54893.
Train: 2018-08-01T01:07:45.379100: step 19531, loss 0.497159.
Train: 2018-08-01T01:07:45.535314: step 19532, loss 0.546192.
Train: 2018-08-01T01:07:45.691527: step 19533, loss 0.579048.
Train: 2018-08-01T01:07:45.847734: step 19534, loss 0.446995.
Train: 2018-08-01T01:07:46.003925: step 19535, loss 0.529371.
Train: 2018-08-01T01:07:46.191405: step 19536, loss 0.629095.
Train: 2018-08-01T01:07:46.332002: step 19537, loss 0.579178.
Train: 2018-08-01T01:07:46.503837: step 19538, loss 0.545722.
Train: 2018-08-01T01:07:46.644428: step 19539, loss 0.579236.
Train: 2018-08-01T01:07:46.816263: step 19540, loss 0.579261.
Test: 2018-08-01T01:07:47.284874: step 19540, loss 0.548329.
Train: 2018-08-01T01:07:47.441087: step 19541, loss 0.562444.
Train: 2018-08-01T01:07:47.612921: step 19542, loss 0.562428.
Train: 2018-08-01T01:07:47.769136: step 19543, loss 0.579326.
Train: 2018-08-01T01:07:47.925379: step 19544, loss 0.562418.
Train: 2018-08-01T01:07:48.065971: step 19545, loss 0.545472.
Train: 2018-08-01T01:07:48.237777: step 19546, loss 0.579377.
Train: 2018-08-01T01:07:48.393989: step 19547, loss 0.613352.
Train: 2018-08-01T01:07:48.550233: step 19548, loss 0.596376.
Train: 2018-08-01T01:07:48.706416: step 19549, loss 0.647301.
Train: 2018-08-01T01:07:48.862628: step 19550, loss 0.613276.
Test: 2018-08-01T01:07:49.346922: step 19550, loss 0.548252.
Train: 2018-08-01T01:07:49.503134: step 19551, loss 0.47782.
Train: 2018-08-01T01:07:49.659318: step 19552, loss 0.460957.
Train: 2018-08-01T01:07:49.815532: step 19553, loss 0.663987.
Train: 2018-08-01T01:07:49.971768: step 19554, loss 0.61318.
Train: 2018-08-01T01:07:50.127982: step 19555, loss 0.545524.
Train: 2018-08-01T01:07:50.284172: step 19556, loss 0.562428.
Train: 2018-08-01T01:07:50.456031: step 19557, loss 0.663699.
Train: 2018-08-01T01:07:50.612250: step 19558, loss 0.495055.
Train: 2018-08-01T01:07:50.768467: step 19559, loss 0.545607.
Train: 2018-08-01T01:07:50.924676: step 19560, loss 0.528787.
Test: 2018-08-01T01:07:51.393316: step 19560, loss 0.548346.
Train: 2018-08-01T01:07:51.549536: step 19561, loss 0.562441.
Train: 2018-08-01T01:07:51.705744: step 19562, loss 0.596111.
Train: 2018-08-01T01:07:51.861927: step 19563, loss 0.511942.
Train: 2018-08-01T01:07:52.018170: step 19564, loss 0.562438.
Train: 2018-08-01T01:07:52.174384: step 19565, loss 0.52648.
Train: 2018-08-01T01:07:52.330600: step 19566, loss 0.478067.
Train: 2018-08-01T01:07:52.486811: step 19567, loss 0.663888.
Train: 2018-08-01T01:07:52.658615: step 19568, loss 0.545499.
Train: 2018-08-01T01:07:52.830458: step 19569, loss 0.528545.
Train: 2018-08-01T01:07:52.986663: step 19570, loss 0.51154.
Test: 2018-08-01T01:07:53.455304: step 19570, loss 0.548182.
Train: 2018-08-01T01:07:53.611518: step 19571, loss 0.5794.
Train: 2018-08-01T01:07:53.799004: step 19572, loss 0.511357.
Train: 2018-08-01T01:07:53.955217: step 19573, loss 0.562403.
Train: 2018-08-01T01:07:54.111430: step 19574, loss 0.545316.
Train: 2018-08-01T01:07:54.267644: step 19575, loss 0.630873.
Train: 2018-08-01T01:07:54.423857: step 19576, loss 0.63093.
Train: 2018-08-01T01:07:54.580070: step 19577, loss 0.596657.
Train: 2018-08-01T01:07:54.751912: step 19578, loss 0.682225.
Train: 2018-08-01T01:07:54.908119: step 19579, loss 0.459923.
Train: 2018-08-01T01:07:55.064326: step 19580, loss 0.579471.
Test: 2018-08-01T01:07:55.532941: step 19580, loss 0.548119.
Train: 2018-08-01T01:07:55.704810: step 19581, loss 0.562402.
Train: 2018-08-01T01:07:55.860992: step 19582, loss 0.545357.
Train: 2018-08-01T01:07:56.017234: step 19583, loss 0.596484.
Train: 2018-08-01T01:07:56.189038: step 19584, loss 0.681596.
Train: 2018-08-01T01:07:56.329630: step 19585, loss 0.562409.
Train: 2018-08-01T01:07:56.501465: step 19586, loss 0.562414.
Train: 2018-08-01T01:07:56.642089: step 19587, loss 0.47781.
Train: 2018-08-01T01:07:56.813922: step 19588, loss 0.52859.
Train: 2018-08-01T01:07:56.970106: step 19589, loss 0.579337.
Train: 2018-08-01T01:07:57.126343: step 19590, loss 0.697755.
Test: 2018-08-01T01:07:57.594989: step 19590, loss 0.548287.
Train: 2018-08-01T01:07:57.751202: step 19591, loss 0.511773.
Train: 2018-08-01T01:07:57.907417: step 19592, loss 0.478088.
Train: 2018-08-01T01:07:58.094874: step 19593, loss 0.494929.
Train: 2018-08-01T01:07:58.251082: step 19594, loss 0.444138.
Train: 2018-08-01T01:07:58.407300: step 19595, loss 0.528518.
Train: 2018-08-01T01:07:58.563482: step 19596, loss 0.596449.
Train: 2018-08-01T01:07:58.719695: step 19597, loss 0.715782.
Train: 2018-08-01T01:07:58.875939: step 19598, loss 0.47719.
Train: 2018-08-01T01:07:59.032122: step 19599, loss 0.613591.
Train: 2018-08-01T01:07:59.203958: step 19600, loss 0.54533.
Test: 2018-08-01T01:07:59.672628: step 19600, loss 0.548097.
Train: 2018-08-01T01:08:00.406825: step 19601, loss 0.511157.
Train: 2018-08-01T01:08:00.547423: step 19602, loss 0.545296.
Train: 2018-08-01T01:08:00.703637: step 19603, loss 0.61378.
Train: 2018-08-01T01:08:00.859819: step 19604, loss 0.528126.
Train: 2018-08-01T01:08:01.016063: step 19605, loss 0.528092.
Train: 2018-08-01T01:08:01.172277: step 19606, loss 0.579576.
Train: 2018-08-01T01:08:01.344083: step 19607, loss 0.579594.
Train: 2018-08-01T01:08:01.500295: step 19608, loss 0.527992.
Train: 2018-08-01T01:08:01.640917: step 19609, loss 0.648512.
Train: 2018-08-01T01:08:01.797100: step 19610, loss 0.510749.
Test: 2018-08-01T01:08:02.265741: step 19610, loss 0.547978.
Train: 2018-08-01T01:08:02.437607: step 19611, loss 0.665756.
Train: 2018-08-01T01:08:02.593819: step 19612, loss 0.545193.
Train: 2018-08-01T01:08:02.750032: step 19613, loss 0.459222.
Train: 2018-08-01T01:08:02.906216: step 19614, loss 0.562402.
Train: 2018-08-01T01:08:03.062428: step 19615, loss 0.579625.
Train: 2018-08-01T01:08:03.218673: step 19616, loss 0.665776.
Train: 2018-08-01T01:08:03.374855: step 19617, loss 0.527982.
Train: 2018-08-01T01:08:03.531070: step 19618, loss 0.562402.
Train: 2018-08-01T01:08:03.702903: step 19619, loss 0.510821.
Train: 2018-08-01T01:08:03.859118: step 19620, loss 0.528005.
Test: 2018-08-01T01:08:04.327756: step 19620, loss 0.54799.
Train: 2018-08-01T01:08:04.484001: step 19621, loss 0.562402.
Train: 2018-08-01T01:08:04.640184: step 19622, loss 0.562402.
Train: 2018-08-01T01:08:04.796436: step 19623, loss 0.596865.
Train: 2018-08-01T01:08:04.952612: step 19624, loss 0.596866.
Train: 2018-08-01T01:08:05.124446: step 19625, loss 0.596849.
Train: 2018-08-01T01:08:05.280684: step 19626, loss 0.57961.
Train: 2018-08-01T01:08:05.436904: step 19627, loss 0.562401.
Train: 2018-08-01T01:08:05.608743: step 19628, loss 0.476535.
Train: 2018-08-01T01:08:05.764922: step 19629, loss 0.528044.
Train: 2018-08-01T01:08:05.921134: step 19630, loss 0.665549.
Test: 2018-08-01T01:08:06.389805: step 19630, loss 0.548015.
Train: 2018-08-01T01:08:06.545987: step 19631, loss 0.493687.
Train: 2018-08-01T01:08:06.702226: step 19632, loss 0.579583.
Train: 2018-08-01T01:08:06.858441: step 19633, loss 0.613949.
Train: 2018-08-01T01:08:07.014631: step 19634, loss 0.459375.
Train: 2018-08-01T01:08:07.170842: step 19635, loss 0.631136.
Train: 2018-08-01T01:08:07.327085: step 19636, loss 0.613939.
Train: 2018-08-01T01:08:07.483269: step 19637, loss 0.545236.
Train: 2018-08-01T01:08:07.639482: step 19638, loss 0.528094.
Train: 2018-08-01T01:08:07.795720: step 19639, loss 0.648158.
Train: 2018-08-01T01:08:07.967530: step 19640, loss 0.57953.
Test: 2018-08-01T01:08:08.436200: step 19640, loss 0.548075.
Train: 2018-08-01T01:08:08.592414: step 19641, loss 0.51108.
Train: 2018-08-01T01:08:08.764244: step 19642, loss 0.613695.
Train: 2018-08-01T01:08:08.920463: step 19643, loss 0.494088.
Train: 2018-08-01T01:08:09.092268: step 19644, loss 0.562402.
Train: 2018-08-01T01:08:09.232858: step 19645, loss 0.630706.
Train: 2018-08-01T01:08:09.389097: step 19646, loss 0.562403.
Train: 2018-08-01T01:08:09.545320: step 19647, loss 0.545359.
Train: 2018-08-01T01:08:09.701530: step 19648, loss 0.545369.
Train: 2018-08-01T01:08:09.857743: step 19649, loss 0.596469.
Train: 2018-08-01T01:08:10.029548: step 19650, loss 0.528364.
Test: 2018-08-01T01:08:10.513833: step 19650, loss 0.548154.
Train: 2018-08-01T01:08:10.670022: step 19651, loss 0.511347.
Train: 2018-08-01T01:08:10.826266: step 19652, loss 0.64756.
Train: 2018-08-01T01:08:10.982479: step 19653, loss 0.528363.
Train: 2018-08-01T01:08:11.138696: step 19654, loss 0.579427.
Train: 2018-08-01T01:08:11.310523: step 19655, loss 0.562406.
Train: 2018-08-01T01:08:11.451120: step 19656, loss 0.664493.
Train: 2018-08-01T01:08:11.607334: step 19657, loss 0.47747.
Train: 2018-08-01T01:08:11.779162: step 19658, loss 0.596379.
Train: 2018-08-01T01:08:11.935351: step 19659, loss 0.613334.
Train: 2018-08-01T01:08:12.091594: step 19660, loss 0.545461.
Test: 2018-08-01T01:08:12.560235: step 19660, loss 0.548231.
Train: 2018-08-01T01:08:12.700797: step 19661, loss 0.477719.
Train: 2018-08-01T01:08:12.857011: step 19662, loss 0.545467.
Train: 2018-08-01T01:08:13.028844: step 19663, loss 0.613292.
Train: 2018-08-01T01:08:13.185059: step 19664, loss 0.579372.
Train: 2018-08-01T01:08:13.356924: step 19665, loss 0.596324.
Train: 2018-08-01T01:08:13.528753: step 19666, loss 0.630191.
Train: 2018-08-01T01:08:13.684972: step 19667, loss 0.545501.
Train: 2018-08-01T01:08:13.841155: step 19668, loss 0.444122.
Train: 2018-08-01T01:08:13.997369: step 19669, loss 0.56242.
Train: 2018-08-01T01:08:14.153612: step 19670, loss 0.579344.
Test: 2018-08-01T01:08:14.622252: step 19670, loss 0.548237.
Train: 2018-08-01T01:08:14.778435: step 19671, loss 0.511618.
Train: 2018-08-01T01:08:14.934679: step 19672, loss 0.596319.
Train: 2018-08-01T01:08:15.090862: step 19673, loss 0.562412.
Train: 2018-08-01T01:08:15.247076: step 19674, loss 0.56241.
Train: 2018-08-01T01:08:15.403314: step 19675, loss 0.596375.
Train: 2018-08-01T01:08:15.559538: step 19676, loss 0.69828.
Train: 2018-08-01T01:08:15.731337: step 19677, loss 0.613272.
Train: 2018-08-01T01:08:15.887584: step 19678, loss 0.545507.
Train: 2018-08-01T01:08:16.043788: step 19679, loss 0.663722.
Train: 2018-08-01T01:08:16.199978: step 19680, loss 0.562438.
Test: 2018-08-01T01:08:16.684239: step 19680, loss 0.548394.
Train: 2018-08-01T01:08:16.856074: step 19681, loss 0.646382.
Train: 2018-08-01T01:08:17.012317: step 19682, loss 0.562469.
Train: 2018-08-01T01:08:17.168501: step 19683, loss 0.562487.
Train: 2018-08-01T01:08:17.355957: step 19684, loss 0.512619.
Train: 2018-08-01T01:08:17.512195: step 19685, loss 0.496111.
Train: 2018-08-01T01:08:17.684035: step 19686, loss 0.479545.
Train: 2018-08-01T01:08:17.840245: step 19687, loss 0.612345.
Train: 2018-08-01T01:08:17.996431: step 19688, loss 0.512665.
Train: 2018-08-01T01:08:18.152645: step 19689, loss 0.645668.
Train: 2018-08-01T01:08:18.308858: step 19690, loss 0.479354.
Test: 2018-08-01T01:08:18.777534: step 19690, loss 0.548554.
Train: 2018-08-01T01:08:18.933712: step 19691, loss 0.595796.
Train: 2018-08-01T01:08:19.105578: step 19692, loss 0.529171.
Train: 2018-08-01T01:08:19.261760: step 19693, loss 0.612525.
Train: 2018-08-01T01:08:19.417974: step 19694, loss 0.645917.
Train: 2018-08-01T01:08:19.574187: step 19695, loss 0.512463.
Train: 2018-08-01T01:08:19.714810: step 19696, loss 0.562486.
Train: 2018-08-01T01:08:19.871023: step 19697, loss 0.579165.
Train: 2018-08-01T01:08:20.042854: step 19698, loss 0.64589.
Train: 2018-08-01T01:08:20.199041: step 19699, loss 0.61248.
Train: 2018-08-01T01:08:20.355285: step 19700, loss 0.52923.
Test: 2018-08-01T01:08:20.823893: step 19700, loss 0.548589.
Train: 2018-08-01T01:08:21.542476: step 19701, loss 0.529265.
Train: 2018-08-01T01:08:21.714341: step 19702, loss 0.562509.
Train: 2018-08-01T01:08:21.870555: step 19703, loss 0.628977.
Train: 2018-08-01T01:08:22.026737: step 19704, loss 0.47951.
Train: 2018-08-01T01:08:22.182952: step 19705, loss 0.595731.
Train: 2018-08-01T01:08:22.370437: step 19706, loss 0.529293.
Train: 2018-08-01T01:08:22.511029: step 19707, loss 0.462785.
Train: 2018-08-01T01:08:22.682864: step 19708, loss 0.545838.
Train: 2018-08-01T01:08:22.839073: step 19709, loss 0.545786.
Train: 2018-08-01T01:08:22.995292: step 19710, loss 0.4788.
Test: 2018-08-01T01:08:23.479552: step 19710, loss 0.548389.
Train: 2018-08-01T01:08:23.635766: step 19711, loss 0.545658.
Train: 2018-08-01T01:08:23.791980: step 19712, loss 0.478199.
Train: 2018-08-01T01:08:23.948193: step 19713, loss 0.663934.
Train: 2018-08-01T01:08:24.104406: step 19714, loss 0.494569.
Train: 2018-08-01T01:08:24.260590: step 19715, loss 0.511361.
Train: 2018-08-01T01:08:24.416805: step 19716, loss 0.511172.
Train: 2018-08-01T01:08:24.588663: step 19717, loss 0.493823.
Train: 2018-08-01T01:08:24.744851: step 19718, loss 0.61406.
Train: 2018-08-01T01:08:24.901096: step 19719, loss 0.51057.
Train: 2018-08-01T01:08:25.057308: step 19720, loss 0.701135.
Test: 2018-08-01T01:08:25.525918: step 19720, loss 0.547873.
Train: 2018-08-01T01:08:25.682132: step 19721, loss 0.51032.
Train: 2018-08-01T01:08:25.838345: step 19722, loss 0.545022.
Train: 2018-08-01T01:08:25.994589: step 19723, loss 0.510135.
Train: 2018-08-01T01:08:26.150803: step 19724, loss 0.422666.
Train: 2018-08-01T01:08:26.307016: step 19725, loss 0.492296.
Train: 2018-08-01T01:08:26.463229: step 19726, loss 0.527246.
Train: 2018-08-01T01:08:26.635059: step 19727, loss 0.544815.
Train: 2018-08-01T01:08:26.791248: step 19728, loss 0.544775.
Train: 2018-08-01T01:08:26.947460: step 19729, loss 0.491261.
Train: 2018-08-01T01:08:27.103673: step 19730, loss 0.598407.
Test: 2018-08-01T01:08:27.572344: step 19730, loss 0.547604.
Train: 2018-08-01T01:08:27.759801: step 19731, loss 0.580595.
Train: 2018-08-01T01:08:27.900362: step 19732, loss 0.544668.
Train: 2018-08-01T01:08:28.072197: step 19733, loss 0.490537.
Train: 2018-08-01T01:08:28.228441: step 19734, loss 0.490371.
Train: 2018-08-01T01:08:28.400276: step 19735, loss 0.49018.
Train: 2018-08-01T01:08:28.556489: step 19736, loss 0.435329.
Train: 2018-08-01T01:08:28.712703: step 19737, loss 0.489701.
Train: 2018-08-01T01:08:28.884506: step 19738, loss 0.691671.
Train: 2018-08-01T01:08:29.040744: step 19739, loss 0.636748.
Train: 2018-08-01T01:08:29.196935: step 19740, loss 0.599948.
Test: 2018-08-01T01:08:29.665574: step 19740, loss 0.547583.
Train: 2018-08-01T01:08:29.821818: step 19741, loss 0.581509.
Train: 2018-08-01T01:08:29.993623: step 19742, loss 0.452262.
Train: 2018-08-01T01:08:30.149836: step 19743, loss 0.563064.
Train: 2018-08-01T01:08:30.306073: step 19744, loss 0.618569.
Train: 2018-08-01T01:08:30.477914: step 19745, loss 0.54458.
Train: 2018-08-01T01:08:30.634098: step 19746, loss 0.48911.
Train: 2018-08-01T01:08:30.790311: step 19747, loss 0.581578.
Train: 2018-08-01T01:08:30.946554: step 19748, loss 0.581578.
Train: 2018-08-01T01:08:31.118359: step 19749, loss 0.54458.
Train: 2018-08-01T01:08:31.274573: step 19750, loss 0.618514.
Test: 2018-08-01T01:08:31.743243: step 19750, loss 0.547582.
Train: 2018-08-01T01:08:31.899427: step 19751, loss 0.655345.
Train: 2018-08-01T01:08:32.055669: step 19752, loss 0.50775.
Train: 2018-08-01T01:08:32.243129: step 19753, loss 0.5262.
Train: 2018-08-01T01:08:32.399333: step 19754, loss 0.691464.
Train: 2018-08-01T01:08:32.555553: step 19755, loss 0.654427.
Train: 2018-08-01T01:08:32.727357: step 19756, loss 0.562837.
Train: 2018-08-01T01:08:32.883571: step 19757, loss 0.544618.
Train: 2018-08-01T01:08:33.039814: step 19758, loss 0.436003.
Train: 2018-08-01T01:08:33.196028: step 19759, loss 0.41811.
Train: 2018-08-01T01:08:33.383492: step 19760, loss 0.56272.
Test: 2018-08-01T01:08:33.852123: step 19760, loss 0.547581.
Train: 2018-08-01T01:08:34.008337: step 19761, loss 0.61696.
Train: 2018-08-01T01:08:34.164521: step 19762, loss 0.56271.
Train: 2018-08-01T01:08:34.320736: step 19763, loss 0.689041.
Train: 2018-08-01T01:08:34.508220: step 19764, loss 0.56267.
Train: 2018-08-01T01:08:34.664403: step 19765, loss 0.562643.
Train: 2018-08-01T01:08:34.820647: step 19766, loss 0.544699.
Train: 2018-08-01T01:08:34.976831: step 19767, loss 0.526832.
Train: 2018-08-01T01:08:35.133043: step 19768, loss 0.63401.
Train: 2018-08-01T01:08:35.289288: step 19769, loss 0.526932.
Train: 2018-08-01T01:08:35.461092: step 19770, loss 0.509197.
Test: 2018-08-01T01:08:35.929732: step 19770, loss 0.547662.
Train: 2018-08-01T01:08:36.101568: step 19771, loss 0.438184.
Train: 2018-08-01T01:08:36.257781: step 19772, loss 0.526993.
Train: 2018-08-01T01:08:36.413993: step 19773, loss 0.651497.
Train: 2018-08-01T01:08:36.585830: step 19774, loss 0.615888.
Train: 2018-08-01T01:08:36.726451: step 19775, loss 0.527017.
Train: 2018-08-01T01:08:36.898255: step 19776, loss 0.651259.
Train: 2018-08-01T01:08:37.054505: step 19777, loss 0.52709.
Train: 2018-08-01T01:08:37.210718: step 19778, loss 0.562504.
Train: 2018-08-01T01:08:37.366926: step 19779, loss 0.509502.
Train: 2018-08-01T01:08:37.523108: step 19780, loss 0.562491.
Test: 2018-08-01T01:08:38.007370: step 19780, loss 0.547713.
Train: 2018-08-01T01:08:38.163584: step 19781, loss 0.509558.
Train: 2018-08-01T01:08:38.319828: step 19782, loss 0.491913.
Train: 2018-08-01T01:08:38.476011: step 19783, loss 0.597811.
Train: 2018-08-01T01:08:38.632262: step 19784, loss 0.562494.
Train: 2018-08-01T01:08:38.804095: step 19785, loss 0.597825.
Train: 2018-08-01T01:08:38.960303: step 19786, loss 0.597807.
Train: 2018-08-01T01:08:39.116510: step 19787, loss 0.42136.
Train: 2018-08-01T01:08:39.272700: step 19788, loss 0.580149.
Train: 2018-08-01T01:08:39.428913: step 19789, loss 0.562495.
Train: 2018-08-01T01:08:39.569504: step 19790, loss 0.58017.
Test: 2018-08-01T01:08:40.053796: step 19790, loss 0.5477.
Train: 2018-08-01T01:08:40.210010: step 19791, loss 0.527154.
Train: 2018-08-01T01:08:40.366223: step 19792, loss 0.686249.
Train: 2018-08-01T01:08:40.522437: step 19793, loss 0.544837.
Train: 2018-08-01T01:08:40.678650: step 19794, loss 0.580119.
Train: 2018-08-01T01:08:40.834863: step 19795, loss 0.685764.
Train: 2018-08-01T01:08:41.006669: step 19796, loss 0.544896.
Train: 2018-08-01T01:08:41.162918: step 19797, loss 0.579967.
Train: 2018-08-01T01:08:41.334747: step 19798, loss 0.510011.
Train: 2018-08-01T01:08:41.475339: step 19799, loss 0.562429.
Train: 2018-08-01T01:08:41.647174: step 19800, loss 0.597271.
Test: 2018-08-01T01:08:42.115814: step 19800, loss 0.547854.
Train: 2018-08-01T01:08:42.803153: step 19801, loss 0.475459.
Train: 2018-08-01T01:08:42.959336: step 19802, loss 0.631952.
Train: 2018-08-01T01:08:43.131172: step 19803, loss 0.527699.
Train: 2018-08-01T01:08:43.287385: step 19804, loss 0.562409.
Train: 2018-08-01T01:08:43.443628: step 19805, loss 0.579734.
Train: 2018-08-01T01:08:43.599811: step 19806, loss 0.493169.
Train: 2018-08-01T01:08:43.756055: step 19807, loss 0.787422.
Train: 2018-08-01T01:08:43.927890: step 19808, loss 0.458863.
Train: 2018-08-01T01:08:44.068482: step 19809, loss 0.579631.
Train: 2018-08-01T01:08:44.240287: step 19810, loss 0.545191.
Test: 2018-08-01T01:08:44.724578: step 19810, loss 0.548004.
Train: 2018-08-01T01:08:44.880795: step 19811, loss 0.424894.
Train: 2018-08-01T01:08:45.036975: step 19812, loss 0.51079.
Train: 2018-08-01T01:08:45.193188: step 19813, loss 0.63131.
Train: 2018-08-01T01:08:45.380682: step 19814, loss 0.527931.
Train: 2018-08-01T01:08:45.536888: step 19815, loss 0.49341.
Train: 2018-08-01T01:08:45.693071: step 19816, loss 0.510576.
Train: 2018-08-01T01:08:45.849309: step 19817, loss 0.579718.
Train: 2018-08-01T01:08:46.005528: step 19818, loss 0.579751.
Train: 2018-08-01T01:08:46.161742: step 19819, loss 0.527689.
Train: 2018-08-01T01:08:46.317955: step 19820, loss 0.562418.
Test: 2018-08-01T01:08:46.802216: step 19820, loss 0.547842.
Train: 2018-08-01T01:08:47.005263: step 19821, loss 0.753949.
Train: 2018-08-01T01:08:47.161508: step 19822, loss 0.475479.
Train: 2018-08-01T01:08:47.317691: step 19823, loss 0.614573.
Train: 2018-08-01T01:08:47.473928: step 19824, loss 0.631896.
Train: 2018-08-01T01:08:47.645770: step 19825, loss 0.649113.
Train: 2018-08-01T01:08:47.801953: step 19826, loss 0.579697.
Train: 2018-08-01T01:08:47.958196: step 19827, loss 0.5624.
Train: 2018-08-01T01:08:48.114379: step 19828, loss 0.545194.
Train: 2018-08-01T01:08:48.286244: step 19829, loss 0.562397.
Train: 2018-08-01T01:08:48.442457: step 19830, loss 0.510984.
Test: 2018-08-01T01:08:48.926688: step 19830, loss 0.54806.
Train: 2018-08-01T01:08:49.067311: step 19831, loss 0.596641.
Train: 2018-08-01T01:08:49.239116: step 19832, loss 0.528199.
Train: 2018-08-01T01:08:49.395330: step 19833, loss 0.647836.
Train: 2018-08-01T01:08:49.551573: step 19834, loss 0.562401.
Train: 2018-08-01T01:08:49.723406: step 19835, loss 0.613492.
Train: 2018-08-01T01:08:49.879590: step 19836, loss 0.562407.
Train: 2018-08-01T01:08:50.020213: step 19837, loss 0.494564.
Train: 2018-08-01T01:08:50.176432: step 19838, loss 0.494615.
Train: 2018-08-01T01:08:50.332640: step 19839, loss 0.562412.
Train: 2018-08-01T01:08:50.504470: step 19840, loss 0.528489.
Test: 2018-08-01T01:08:50.973114: step 19840, loss 0.548195.
Train: 2018-08-01T01:08:51.144950: step 19841, loss 0.698209.
Train: 2018-08-01T01:08:51.301157: step 19842, loss 0.494589.
Train: 2018-08-01T01:08:51.457376: step 19843, loss 0.528502.
Train: 2018-08-01T01:08:51.613584: step 19844, loss 0.545447.
Train: 2018-08-01T01:08:51.769772: step 19845, loss 0.630311.
Train: 2018-08-01T01:08:51.941607: step 19846, loss 0.56241.
Train: 2018-08-01T01:08:52.097821: step 19847, loss 0.596345.
Train: 2018-08-01T01:08:52.238443: step 19848, loss 0.528499.
Train: 2018-08-01T01:08:52.410273: step 19849, loss 0.545457.
Train: 2018-08-01T01:08:52.561882: step 19850, loss 0.562412.
Test: 2018-08-01T01:08:53.030524: step 19850, loss 0.548206.
Train: 2018-08-01T01:08:53.186706: step 19851, loss 0.494559.
Train: 2018-08-01T01:08:53.342919: step 19852, loss 0.562408.
Train: 2018-08-01T01:08:53.499132: step 19853, loss 0.528402.
Train: 2018-08-01T01:08:53.655371: step 19854, loss 0.494294.
Train: 2018-08-01T01:08:53.811559: step 19855, loss 0.5624.
Train: 2018-08-01T01:08:53.967799: step 19856, loss 0.5795.
Train: 2018-08-01T01:08:54.139608: step 19857, loss 0.613788.
Train: 2018-08-01T01:08:54.280199: step 19858, loss 0.562397.
Train: 2018-08-01T01:08:54.452034: step 19859, loss 0.613864.
Train: 2018-08-01T01:08:54.608272: step 19860, loss 0.562396.
Test: 2018-08-01T01:08:55.076918: step 19860, loss 0.548032.
Train: 2018-08-01T01:08:55.248723: step 19861, loss 0.562396.
Train: 2018-08-01T01:08:55.404936: step 19862, loss 0.562396.
Train: 2018-08-01T01:08:55.545559: step 19863, loss 0.562396.
Train: 2018-08-01T01:08:55.717390: step 19864, loss 0.528094.
Train: 2018-08-01T01:08:55.857985: step 19865, loss 0.682509.
Train: 2018-08-01T01:08:56.029790: step 19866, loss 0.635516.
Train: 2018-08-01T01:08:56.186004: step 19867, loss 0.579499.
Train: 2018-08-01T01:08:56.357839: step 19868, loss 0.5624.
Train: 2018-08-01T01:08:56.498430: step 19869, loss 0.511307.
Train: 2018-08-01T01:08:56.654675: step 19870, loss 0.613449.
Test: 2018-08-01T01:08:57.138935: step 19870, loss 0.548182.
Train: 2018-08-01T01:08:57.295144: step 19871, loss 0.732286.
Train: 2018-08-01T01:08:57.466983: step 19872, loss 0.511644.
Train: 2018-08-01T01:08:57.623168: step 19873, loss 0.511787.
Train: 2018-08-01T01:08:57.795002: step 19874, loss 0.511875.
Train: 2018-08-01T01:08:57.951246: step 19875, loss 0.646639.
Train: 2018-08-01T01:08:58.107464: step 19876, loss 0.562442.
Train: 2018-08-01T01:08:58.263666: step 19877, loss 0.679951.
Train: 2018-08-01T01:08:58.419857: step 19878, loss 0.562465.
Train: 2018-08-01T01:08:58.591714: step 19879, loss 0.462323.
Train: 2018-08-01T01:08:58.747928: step 19880, loss 0.579163.
Test: 2018-08-01T01:08:59.216542: step 19880, loss 0.548536.
Train: 2018-08-01T01:08:59.388378: step 19881, loss 0.595818.
Train: 2018-08-01T01:08:59.544593: step 19882, loss 0.545853.
Train: 2018-08-01T01:08:59.700829: step 19883, loss 0.54587.
Train: 2018-08-01T01:08:59.857019: step 19884, loss 0.579132.
Train: 2018-08-01T01:09:00.013264: step 19885, loss 0.595747.
Train: 2018-08-01T01:09:00.169445: step 19886, loss 0.512693.
Train: 2018-08-01T01:09:00.325689: step 19887, loss 0.645557.
Train: 2018-08-01T01:09:00.481875: step 19888, loss 0.545927.
Train: 2018-08-01T01:09:00.638087: step 19889, loss 0.54594.
Train: 2018-08-01T01:09:00.809922: step 19890, loss 0.496199.
Test: 2018-08-01T01:09:01.294181: step 19890, loss 0.548619.
Train: 2018-08-01T01:09:01.450420: step 19891, loss 0.496129.
Train: 2018-08-01T01:09:01.606609: step 19892, loss 0.562504.
Train: 2018-08-01T01:09:01.778446: step 19893, loss 0.595811.
Train: 2018-08-01T01:09:01.919068: step 19894, loss 0.645886.
Train: 2018-08-01T01:09:02.075249: step 19895, loss 0.562484.
Train: 2018-08-01T01:09:02.231463: step 19896, loss 0.662577.
Train: 2018-08-01T01:09:02.387706: step 19897, loss 0.512507.
Train: 2018-08-01T01:09:02.543920: step 19898, loss 0.545837.
Train: 2018-08-01T01:09:02.700133: step 19899, loss 0.495867.
Train: 2018-08-01T01:09:02.871968: step 19900, loss 0.579161.
Test: 2018-08-01T01:09:03.324986: step 19900, loss 0.548506.
Train: 2018-08-01T01:09:04.059191: step 19901, loss 0.462348.
Train: 2018-08-01T01:09:04.215374: step 19902, loss 0.595921.
Train: 2018-08-01T01:09:04.371586: step 19903, loss 0.595967.
Train: 2018-08-01T01:09:04.527800: step 19904, loss 0.461819.
Train: 2018-08-01T01:09:04.684013: step 19905, loss 0.612883.
Train: 2018-08-01T01:09:04.855879: step 19906, loss 0.629795.
Train: 2018-08-01T01:09:05.012094: step 19907, loss 0.545584.
Train: 2018-08-01T01:09:05.183921: step 19908, loss 0.528707.
Train: 2018-08-01T01:09:05.340141: step 19909, loss 0.545543.
Train: 2018-08-01T01:09:05.496323: step 19910, loss 0.579326.
Test: 2018-08-01T01:09:05.964962: step 19910, loss 0.548246.
Train: 2018-08-01T01:09:06.136824: step 19911, loss 0.57934.
Train: 2018-08-01T01:09:06.293042: step 19912, loss 0.494673.
Train: 2018-08-01T01:09:06.449255: step 19913, loss 0.613302.
Train: 2018-08-01T01:09:06.605468: step 19914, loss 0.562409.
Train: 2018-08-01T01:09:06.761685: step 19915, loss 0.596388.
Train: 2018-08-01T01:09:06.917890: step 19916, loss 0.511422.
Train: 2018-08-01T01:09:07.089731: step 19917, loss 0.49436.
Train: 2018-08-01T01:09:07.245944: step 19918, loss 0.545359.
Train: 2018-08-01T01:09:07.402128: step 19919, loss 0.545324.
Train: 2018-08-01T01:09:07.558371: step 19920, loss 0.476854.
Test: 2018-08-01T01:09:08.026979: step 19920, loss 0.548028.
Train: 2018-08-01T01:09:08.183226: step 19921, loss 0.596714.
Train: 2018-08-01T01:09:08.355055: step 19922, loss 0.493611.
Train: 2018-08-01T01:09:08.495621: step 19923, loss 0.665875.
Train: 2018-08-01T01:09:08.651866: step 19924, loss 0.596933.
Train: 2018-08-01T01:09:08.808049: step 19925, loss 0.579677.
Train: 2018-08-01T01:09:08.964292: step 19926, loss 0.45872.
Train: 2018-08-01T01:09:09.120505: step 19927, loss 0.510481.
Train: 2018-08-01T01:09:09.276720: step 19928, loss 0.458342.
Train: 2018-08-01T01:09:09.432902: step 19929, loss 0.597221.
Train: 2018-08-01T01:09:09.604735: step 19930, loss 0.492656.
Test: 2018-08-01T01:09:10.073406: step 19930, loss 0.547789.
Train: 2018-08-01T01:09:10.229623: step 19931, loss 0.544944.
Train: 2018-08-01T01:09:10.385836: step 19932, loss 0.597547.
Train: 2018-08-01T01:09:10.557664: step 19933, loss 0.421802.
Train: 2018-08-01T01:09:10.713876: step 19934, loss 0.544841.
Train: 2018-08-01T01:09:10.870064: step 19935, loss 0.580217.
Train: 2018-08-01T01:09:11.026277: step 19936, loss 0.704565.
Train: 2018-08-01T01:09:11.182492: step 19937, loss 0.562537.
Train: 2018-08-01T01:09:11.338705: step 19938, loss 0.527.
Train: 2018-08-01T01:09:11.494919: step 19939, loss 0.562545.
Train: 2018-08-01T01:09:11.666777: step 19940, loss 0.562549.
Test: 2018-08-01T01:09:12.135392: step 19940, loss 0.54765.
Train: 2018-08-01T01:09:12.291637: step 19941, loss 0.687129.
Train: 2018-08-01T01:09:12.463466: step 19942, loss 0.580313.
Train: 2018-08-01T01:09:12.619656: step 19943, loss 0.61576.
Train: 2018-08-01T01:09:12.775868: step 19944, loss 0.651037.
Train: 2018-08-01T01:09:12.932081: step 19945, loss 0.491895.
Train: 2018-08-01T01:09:13.088295: step 19946, loss 0.50964.
Train: 2018-08-01T01:09:13.244508: step 19947, loss 0.49211.
Train: 2018-08-01T01:09:13.400721: step 19948, loss 0.615218.
Train: 2018-08-01T01:09:13.556935: step 19949, loss 0.492196.
Train: 2018-08-01T01:09:13.713148: step 19950, loss 0.650281.
Test: 2018-08-01T01:09:14.181789: step 19950, loss 0.547764.
Train: 2018-08-01T01:09:14.338002: step 19951, loss 0.544911.
Train: 2018-08-01T01:09:14.494215: step 19952, loss 0.597496.
Train: 2018-08-01T01:09:14.650454: step 19953, loss 0.562441.
Train: 2018-08-01T01:09:14.806642: step 19954, loss 0.562435.
Train: 2018-08-01T01:09:14.978478: step 19955, loss 0.544976.
Train: 2018-08-01T01:09:15.134715: step 19956, loss 0.544989.
Train: 2018-08-01T01:09:15.275284: step 19957, loss 0.527575.
Train: 2018-08-01T01:09:15.431496: step 19958, loss 0.527581.
Train: 2018-08-01T01:09:15.603332: step 19959, loss 0.544999.
Train: 2018-08-01T01:09:15.759545: step 19960, loss 0.667014.
Test: 2018-08-01T01:09:16.228215: step 19960, loss 0.54784.
Train: 2018-08-01T01:09:16.384428: step 19961, loss 0.49277.
Train: 2018-08-01T01:09:16.540642: step 19962, loss 0.54501.
Train: 2018-08-01T01:09:16.696857: step 19963, loss 0.49277.
Train: 2018-08-01T01:09:16.853069: step 19964, loss 0.544995.
Train: 2018-08-01T01:09:17.009282: step 19965, loss 0.579876.
Train: 2018-08-01T01:09:17.196709: step 19966, loss 0.440215.
Train: 2018-08-01T01:09:17.337300: step 19967, loss 0.597434.
Train: 2018-08-01T01:09:17.493513: step 19968, loss 0.527404.
Train: 2018-08-01T01:09:17.649727: step 19969, loss 0.597557.
Train: 2018-08-01T01:09:17.821592: step 19970, loss 0.597597.
Test: 2018-08-01T01:09:18.305853: step 19970, loss 0.547746.
Train: 2018-08-01T01:09:18.462038: step 19971, loss 0.544889.
Train: 2018-08-01T01:09:18.618280: step 19972, loss 0.615212.
Train: 2018-08-01T01:09:18.758843: step 19973, loss 0.544887.
Train: 2018-08-01T01:09:18.915057: step 19974, loss 0.492168.
Train: 2018-08-01T01:09:19.071301: step 19975, loss 0.544881.
Train: 2018-08-01T01:09:19.243143: step 19976, loss 0.63287.
Train: 2018-08-01T01:09:19.414975: step 19977, loss 0.52728.
Train: 2018-08-01T01:09:19.571153: step 19978, loss 0.527276.
Train: 2018-08-01T01:09:19.727396: step 19979, loss 0.562473.
Train: 2018-08-01T01:09:19.883580: step 19980, loss 0.492027.
Test: 2018-08-01T01:09:20.352219: step 19980, loss 0.547717.
Train: 2018-08-01T01:09:20.524054: step 19981, loss 0.509585.
Train: 2018-08-01T01:09:20.680299: step 19982, loss 0.52717.
Train: 2018-08-01T01:09:20.836508: step 19983, loss 0.527118.
Train: 2018-08-01T01:09:20.992729: step 19984, loss 0.633444.
Train: 2018-08-01T01:09:21.148939: step 19985, loss 0.509294.
Train: 2018-08-01T01:09:21.305121: step 19986, loss 0.633611.
Train: 2018-08-01T01:09:21.461368: step 19987, loss 0.686937.
Train: 2018-08-01T01:09:21.633169: step 19988, loss 0.598015.
Train: 2018-08-01T01:09:21.789383: step 19989, loss 0.562513.
Train: 2018-08-01T01:09:21.945596: step 19990, loss 0.491795.
Test: 2018-08-01T01:09:22.414267: step 19990, loss 0.547704.
Train: 2018-08-01T01:09:22.570450: step 19991, loss 0.527171.
Train: 2018-08-01T01:09:22.742285: step 19992, loss 0.509528.
Train: 2018-08-01T01:09:22.914120: step 19993, loss 0.509517.
Train: 2018-08-01T01:09:23.085954: step 19994, loss 0.527152.
Train: 2018-08-01T01:09:23.242168: step 19995, loss 0.509429.
Train: 2018-08-01T01:09:23.398380: step 19996, loss 0.580237.
Train: 2018-08-01T01:09:23.554594: step 19997, loss 0.598005.
Train: 2018-08-01T01:09:23.710808: step 19998, loss 0.544782.
Train: 2018-08-01T01:09:23.867021: step 19999, loss 0.544777.
Train: 2018-08-01T01:09:24.023234: step 20000, loss 0.580305.
Test: 2018-08-01T01:09:24.507528: step 20000, loss 0.547659.
Train: 2018-08-01T01:09:25.210487: step 20001, loss 0.45592.
Train: 2018-08-01T01:09:25.382291: step 20002, loss 0.544756.
Train: 2018-08-01T01:09:25.522915: step 20003, loss 0.651665.
Train: 2018-08-01T01:09:25.694748: step 20004, loss 0.580385.
Train: 2018-08-01T01:09:25.850931: step 20005, loss 0.544747.
Train: 2018-08-01T01:09:26.022766: step 20006, loss 0.740673.
Train: 2018-08-01T01:09:26.179009: step 20007, loss 0.669135.
Train: 2018-08-01T01:09:26.335225: step 20008, loss 0.562509.
Train: 2018-08-01T01:09:26.491437: step 20009, loss 0.491933.
Train: 2018-08-01T01:09:26.647621: step 20010, loss 0.456888.
Test: 2018-08-01T01:09:27.131911: step 20010, loss 0.547742.
Train: 2018-08-01T01:09:27.272505: step 20011, loss 0.597632.
Train: 2018-08-01T01:09:27.444309: step 20012, loss 0.685387.
Train: 2018-08-01T01:09:27.600522: step 20013, loss 0.562444.
Train: 2018-08-01T01:09:27.756736: step 20014, loss 0.614833.
Train: 2018-08-01T01:09:27.912948: step 20015, loss 0.614661.
Train: 2018-08-01T01:09:28.084785: step 20016, loss 0.545059.
Train: 2018-08-01T01:09:28.256619: step 20017, loss 0.597005.
Train: 2018-08-01T01:09:28.412832: step 20018, loss 0.510663.
Train: 2018-08-01T01:09:28.569075: step 20019, loss 0.493567.
Train: 2018-08-01T01:09:28.725289: step 20020, loss 0.596775.
Test: 2018-08-01T01:09:29.193924: step 20020, loss 0.548022.
Train: 2018-08-01T01:09:29.350142: step 20021, loss 0.528066.
Train: 2018-08-01T01:09:29.521979: step 20022, loss 0.562396.
Train: 2018-08-01T01:09:29.678190: step 20023, loss 0.493841.
Train: 2018-08-01T01:09:29.834374: step 20024, loss 0.510962.
Train: 2018-08-01T01:09:29.990615: step 20025, loss 0.545243.
Train: 2018-08-01T01:09:30.146832: step 20026, loss 0.682698.
Train: 2018-08-01T01:09:30.303015: step 20027, loss 0.562406.
Train: 2018-08-01T01:09:30.459227: step 20028, loss 0.562396.
Train: 2018-08-01T01:09:30.615466: step 20029, loss 0.545248.
Train: 2018-08-01T01:09:30.787305: step 20030, loss 0.699547.
Test: 2018-08-01T01:09:31.240324: step 20030, loss 0.548072.
Train: 2018-08-01T01:09:31.412140: step 20031, loss 0.613721.
Train: 2018-08-01T01:09:31.552751: step 20032, loss 0.545337.
Train: 2018-08-01T01:09:31.708936: step 20033, loss 0.59646.
Train: 2018-08-01T01:09:31.880799: step 20034, loss 0.664339.
Train: 2018-08-01T01:09:32.037007: step 20035, loss 0.393125.
Train: 2018-08-01T01:09:32.193226: step 20036, loss 0.494753.
Train: 2018-08-01T01:09:32.349409: step 20037, loss 0.528575.
Train: 2018-08-01T01:09:32.505624: step 20038, loss 0.664035.
Train: 2018-08-01T01:09:32.661867: step 20039, loss 0.630121.
Train: 2018-08-01T01:09:32.818051: step 20040, loss 0.613125.
Test: 2018-08-01T01:09:33.286723: step 20040, loss 0.548308.
Train: 2018-08-01T01:09:33.442929: step 20041, loss 0.528699.
Train: 2018-08-01T01:09:33.614739: step 20042, loss 0.427678.
Train: 2018-08-01T01:09:33.755372: step 20043, loss 0.629868.
Train: 2018-08-01T01:09:33.911544: step 20044, loss 0.680424.
Train: 2018-08-01T01:09:34.067788: step 20045, loss 0.511964.
Train: 2018-08-01T01:09:34.223995: step 20046, loss 0.680133.
Train: 2018-08-01T01:09:34.395843: step 20047, loss 0.562457.
Train: 2018-08-01T01:09:34.552027: step 20048, loss 0.495509.
Train: 2018-08-01T01:09:34.708268: step 20049, loss 0.495567.
Train: 2018-08-01T01:09:34.864476: step 20050, loss 0.646127.
Test: 2018-08-01T01:09:35.348737: step 20050, loss 0.548476.
Train: 2018-08-01T01:09:35.504953: step 20051, loss 0.445452.
Train: 2018-08-01T01:09:35.661135: step 20052, loss 0.529001.
Train: 2018-08-01T01:09:35.832969: step 20053, loss 0.629495.
Train: 2018-08-01T01:09:35.989182: step 20054, loss 0.512162.
Train: 2018-08-01T01:09:36.129804: step 20055, loss 0.596023.
Train: 2018-08-01T01:09:36.301640: step 20056, loss 0.696818.
Train: 2018-08-01T01:09:36.457823: step 20057, loss 0.663106.
Train: 2018-08-01T01:09:36.614036: step 20058, loss 0.4788.
Train: 2018-08-01T01:09:36.785871: step 20059, loss 0.595909.
Train: 2018-08-01T01:09:36.942084: step 20060, loss 0.462303.
Test: 2018-08-01T01:09:37.410754: step 20060, loss 0.548493.
Train: 2018-08-01T01:09:37.566968: step 20061, loss 0.462264.
Train: 2018-08-01T01:09:37.723176: step 20062, loss 0.545735.
Train: 2018-08-01T01:09:37.894986: step 20063, loss 0.579224.
Train: 2018-08-01T01:09:38.066851: step 20064, loss 0.646415.
Train: 2018-08-01T01:09:38.223064: step 20065, loss 0.461658.
Train: 2018-08-01T01:09:38.379277: step 20066, loss 0.646581.
Train: 2018-08-01T01:09:38.535491: step 20067, loss 0.629783.
Train: 2018-08-01T01:09:38.691700: step 20068, loss 0.663411.
Train: 2018-08-01T01:09:38.847889: step 20069, loss 0.579247.
Train: 2018-08-01T01:09:39.004127: step 20070, loss 0.512148.
Test: 2018-08-01T01:09:39.472771: step 20070, loss 0.548429.
Train: 2018-08-01T01:09:39.628987: step 20071, loss 0.545704.
Train: 2018-08-01T01:09:39.800790: step 20072, loss 0.512215.
Train: 2018-08-01T01:09:39.957028: step 20073, loss 0.528948.
Train: 2018-08-01T01:09:40.113249: step 20074, loss 0.696624.
Train: 2018-08-01T01:09:40.285052: step 20075, loss 0.512197.
Train: 2018-08-01T01:09:40.441264: step 20076, loss 0.495451.
Train: 2018-08-01T01:09:40.597478: step 20077, loss 0.528921.
Train: 2018-08-01T01:09:40.753693: step 20078, loss 0.461706.
Train: 2018-08-01T01:09:40.909906: step 20079, loss 0.612945.
Train: 2018-08-01T01:09:41.066119: step 20080, loss 0.511833.
Test: 2018-08-01T01:09:41.550410: step 20080, loss 0.548265.
Train: 2018-08-01T01:09:41.706594: step 20081, loss 0.630044.
Train: 2018-08-01T01:09:41.862806: step 20082, loss 0.59627.
Train: 2018-08-01T01:09:42.019020: step 20083, loss 0.46079.
Train: 2018-08-01T01:09:42.175264: step 20084, loss 0.579383.
Train: 2018-08-01T01:09:42.331449: step 20085, loss 0.579407.
Train: 2018-08-01T01:09:42.503314: step 20086, loss 0.647511.
Train: 2018-08-01T01:09:42.659495: step 20087, loss 0.647512.
Train: 2018-08-01T01:09:42.831331: step 20088, loss 0.579409.
Train: 2018-08-01T01:09:42.987544: step 20089, loss 0.630335.
Train: 2018-08-01T01:09:43.128166: step 20090, loss 0.596309.
Test: 2018-08-01T01:09:43.596776: step 20090, loss 0.548261.
Train: 2018-08-01T01:09:43.768642: step 20091, loss 0.630059.
Train: 2018-08-01T01:09:43.924854: step 20092, loss 0.528709.
Train: 2018-08-01T01:09:44.081038: step 20093, loss 0.562439.
Train: 2018-08-01T01:09:44.221630: step 20094, loss 0.461681.
Train: 2018-08-01T01:09:44.377843: step 20095, loss 0.528865.
Train: 2018-08-01T01:09:44.549680: step 20096, loss 0.663233.
Train: 2018-08-01T01:09:44.705891: step 20097, loss 0.512108.
Train: 2018-08-01T01:09:44.862105: step 20098, loss 0.545673.
Train: 2018-08-01T01:09:45.002696: step 20099, loss 0.579233.
Train: 2018-08-01T01:09:45.158941: step 20100, loss 0.545669.
Test: 2018-08-01T01:09:45.627576: step 20100, loss 0.548392.
Train: 2018-08-01T01:09:46.346162: step 20101, loss 0.545662.
Train: 2018-08-01T01:09:46.502346: step 20102, loss 0.562446.
Train: 2018-08-01T01:09:46.658559: step 20103, loss 0.545637.
Train: 2018-08-01T01:09:46.830393: step 20104, loss 0.495159.
Train: 2018-08-01T01:09:46.986637: step 20105, loss 0.545583.
Train: 2018-08-01T01:09:47.142845: step 20106, loss 0.494903.
Train: 2018-08-01T01:09:47.299035: step 20107, loss 0.494715.
Train: 2018-08-01T01:09:47.455278: step 20108, loss 0.545425.
Train: 2018-08-01T01:09:47.627114: step 20109, loss 0.562407.
Train: 2018-08-01T01:09:47.798942: step 20110, loss 0.596575.
Test: 2018-08-01T01:09:48.283179: step 20110, loss 0.548056.
Train: 2018-08-01T01:09:48.439423: step 20111, loss 0.511018.
Train: 2018-08-01T01:09:48.595606: step 20112, loss 0.390676.
Train: 2018-08-01T01:09:48.751851: step 20113, loss 0.476081.
Train: 2018-08-01T01:09:48.908034: step 20114, loss 0.64931.
Train: 2018-08-01T01:09:49.064245: step 20115, loss 0.510049.
Train: 2018-08-01T01:09:49.220460: step 20116, loss 0.632431.
Train: 2018-08-01T01:09:49.376704: step 20117, loss 0.633103.
Train: 2018-08-01T01:09:49.532886: step 20118, loss 0.545009.
Train: 2018-08-01T01:09:49.689130: step 20119, loss 0.615157.
Train: 2018-08-01T01:09:49.845313: step 20120, loss 0.738152.
Test: 2018-08-01T01:09:50.329604: step 20120, loss 0.547769.
Train: 2018-08-01T01:09:50.485818: step 20121, loss 0.509848.
Train: 2018-08-01T01:09:50.642033: step 20122, loss 0.527418.
Train: 2018-08-01T01:09:50.813866: step 20123, loss 0.562445.
Train: 2018-08-01T01:09:50.970079: step 20124, loss 0.474979.
Train: 2018-08-01T01:09:51.126263: step 20125, loss 0.509941.
Train: 2018-08-01T01:09:51.282501: step 20126, loss 0.54493.
Train: 2018-08-01T01:09:51.438689: step 20127, loss 0.527377.
Train: 2018-08-01T01:09:51.594933: step 20128, loss 0.509772.
Train: 2018-08-01T01:09:51.751146: step 20129, loss 0.527281.
Train: 2018-08-01T01:09:51.907368: step 20130, loss 0.615382.
Test: 2018-08-01T01:09:52.391592: step 20130, loss 0.547713.
Train: 2018-08-01T01:09:52.547835: step 20131, loss 0.615446.
Train: 2018-08-01T01:09:52.704019: step 20132, loss 0.597805.
Train: 2018-08-01T01:09:52.860261: step 20133, loss 0.509548.
Train: 2018-08-01T01:09:53.016477: step 20134, loss 0.597803.
Train: 2018-08-01T01:09:53.172688: step 20135, loss 0.527197.
Train: 2018-08-01T01:09:53.360144: step 20136, loss 0.509543.
Train: 2018-08-01T01:09:53.516357: step 20137, loss 0.527174.
Train: 2018-08-01T01:09:53.672572: step 20138, loss 0.509466.
Train: 2018-08-01T01:09:53.828785: step 20139, loss 0.580223.
Train: 2018-08-01T01:09:53.984969: step 20140, loss 0.527078.
Test: 2018-08-01T01:09:54.469262: step 20140, loss 0.547675.
Train: 2018-08-01T01:09:54.625475: step 20141, loss 0.544791.
Train: 2018-08-01T01:09:54.781657: step 20142, loss 0.509243.
Train: 2018-08-01T01:09:54.937870: step 20143, loss 0.598155.
Train: 2018-08-01T01:09:55.094113: step 20144, loss 0.669456.
Train: 2018-08-01T01:09:55.250326: step 20145, loss 0.491347.
Train: 2018-08-01T01:09:55.406510: step 20146, loss 0.562566.
Train: 2018-08-01T01:09:55.578376: step 20147, loss 0.615999.
Train: 2018-08-01T01:09:55.734583: step 20148, loss 0.509171.
Train: 2018-08-01T01:09:55.906417: step 20149, loss 0.580356.
Train: 2018-08-01T01:09:56.062638: step 20150, loss 0.562564.
Test: 2018-08-01T01:09:56.531247: step 20150, loss 0.547668.
Train: 2018-08-01T01:09:56.703081: step 20151, loss 0.651417.
Train: 2018-08-01T01:09:56.843674: step 20152, loss 0.544659.
Train: 2018-08-01T01:09:56.999887: step 20153, loss 0.58033.
Train: 2018-08-01T01:09:57.171752: step 20154, loss 0.544978.
Train: 2018-08-01T01:09:57.327935: step 20155, loss 0.668574.
Train: 2018-08-01T01:09:57.484179: step 20156, loss 0.422206.
Train: 2018-08-01T01:09:57.656010: step 20157, loss 0.614758.
Train: 2018-08-01T01:09:57.812229: step 20158, loss 0.543498.
Train: 2018-08-01T01:09:57.968442: step 20159, loss 0.511014.
Train: 2018-08-01T01:09:58.124656: step 20160, loss 0.578238.
Test: 2018-08-01T01:09:58.608885: step 20160, loss 0.548127.
Train: 2018-08-01T01:09:58.780723: step 20161, loss 0.681495.
Train: 2018-08-01T01:09:58.936933: step 20162, loss 0.528177.
Train: 2018-08-01T01:09:59.093174: step 20163, loss 0.582788.
Train: 2018-08-01T01:09:59.249385: step 20164, loss 0.660103.
Train: 2018-08-01T01:09:59.405604: step 20165, loss 0.496366.
Train: 2018-08-01T01:09:59.577440: step 20166, loss 0.567139.
Train: 2018-08-01T01:09:59.733652: step 20167, loss 0.670674.
Train: 2018-08-01T01:09:59.889837: step 20168, loss 0.612397.
Train: 2018-08-01T01:10:00.046074: step 20169, loss 0.684938.
Train: 2018-08-01T01:10:00.202263: step 20170, loss 0.632919.
Test: 2018-08-01T01:10:00.670932: step 20170, loss 0.548968.
Train: 2018-08-01T01:10:00.827117: step 20171, loss 0.513796.
Train: 2018-08-01T01:10:00.998951: step 20172, loss 0.592146.
Train: 2018-08-01T01:10:01.139542: step 20173, loss 0.660935.
Train: 2018-08-01T01:10:01.295756: step 20174, loss 0.519549.
Train: 2018-08-01T01:10:01.452000: step 20175, loss 0.562597.
Train: 2018-08-01T01:10:01.608184: step 20176, loss 0.5505.
Train: 2018-08-01T01:10:01.780019: step 20177, loss 0.435654.
Train: 2018-08-01T01:10:01.936231: step 20178, loss 0.584391.
Train: 2018-08-01T01:10:02.123687: step 20179, loss 0.58612.
Train: 2018-08-01T01:10:02.264279: step 20180, loss 0.542419.
Test: 2018-08-01T01:10:02.732950: step 20180, loss 0.548249.
Train: 2018-08-01T01:10:02.904755: step 20181, loss 0.525483.
Train: 2018-08-01T01:10:03.060999: step 20182, loss 0.546915.
Train: 2018-08-01T01:10:03.217181: step 20183, loss 0.588576.
Train: 2018-08-01T01:10:03.389015: step 20184, loss 0.616256.
Train: 2018-08-01T01:10:03.545261: step 20185, loss 0.541296.
Train: 2018-08-01T01:10:03.701473: step 20186, loss 0.566062.
Train: 2018-08-01T01:10:03.857657: step 20187, loss 0.670746.
Train: 2018-08-01T01:10:04.013870: step 20188, loss 0.560724.
Train: 2018-08-01T01:10:04.170083: step 20189, loss 0.50963.
Train: 2018-08-01T01:10:04.341919: step 20190, loss 0.529721.
Test: 2018-08-01T01:10:04.826211: step 20190, loss 0.549957.
Train: 2018-08-01T01:10:04.982423: step 20191, loss 0.595818.
Train: 2018-08-01T01:10:05.138638: step 20192, loss 0.547912.
Train: 2018-08-01T01:10:05.294850: step 20193, loss 0.669592.
Train: 2018-08-01T01:10:05.482276: step 20194, loss 0.536037.
Train: 2018-08-01T01:10:05.622868: step 20195, loss 0.547051.
Train: 2018-08-01T01:10:05.794727: step 20196, loss 0.566808.
Train: 2018-08-01T01:10:05.950947: step 20197, loss 0.551444.
Train: 2018-08-01T01:10:06.107160: step 20198, loss 0.58133.
Train: 2018-08-01T01:10:06.263375: step 20199, loss 0.562744.
Train: 2018-08-01T01:10:06.419583: step 20200, loss 0.509508.
Test: 2018-08-01T01:10:06.888228: step 20200, loss 0.549473.
Train: 2018-08-01T01:10:07.653642: step 20201, loss 0.544273.
Train: 2018-08-01T01:10:07.809886: step 20202, loss 0.59265.
Train: 2018-08-01T01:10:07.981721: step 20203, loss 0.594617.
Train: 2018-08-01T01:10:08.137904: step 20204, loss 0.532147.
Train: 2018-08-01T01:10:08.294117: step 20205, loss 0.545974.
Train: 2018-08-01T01:10:08.450332: step 20206, loss 0.607187.
Train: 2018-08-01T01:10:08.606574: step 20207, loss 0.460039.
Train: 2018-08-01T01:10:08.778379: step 20208, loss 0.532576.
Train: 2018-08-01T01:10:08.934593: step 20209, loss 0.636287.
Train: 2018-08-01T01:10:09.090836: step 20210, loss 0.563182.
Test: 2018-08-01T01:10:09.559471: step 20210, loss 0.548997.
Train: 2018-08-01T01:10:09.715690: step 20211, loss 0.547927.
Train: 2018-08-01T01:10:09.903145: step 20212, loss 0.454298.
Train: 2018-08-01T01:10:10.059329: step 20213, loss 0.601788.
Train: 2018-08-01T01:10:10.215542: step 20214, loss 0.562704.
Train: 2018-08-01T01:10:10.371757: step 20215, loss 0.541795.
Train: 2018-08-01T01:10:10.528000: step 20216, loss 0.483111.
Train: 2018-08-01T01:10:10.684182: step 20217, loss 0.526786.
Train: 2018-08-01T01:10:10.840422: step 20218, loss 0.599296.
Train: 2018-08-01T01:10:11.012255: step 20219, loss 0.58021.
Train: 2018-08-01T01:10:11.184091: step 20220, loss 0.683813.
Test: 2018-08-01T01:10:11.652736: step 20220, loss 0.549093.
Train: 2018-08-01T01:10:11.808949: step 20221, loss 0.645019.
Train: 2018-08-01T01:10:11.980754: step 20222, loss 0.42938.
Train: 2018-08-01T01:10:12.137000: step 20223, loss 0.56845.
Train: 2018-08-01T01:10:12.293182: step 20224, loss 0.543379.
Train: 2018-08-01T01:10:12.449395: step 20225, loss 0.644513.
Train: 2018-08-01T01:10:12.605638: step 20226, loss 0.521925.
Train: 2018-08-01T01:10:12.761853: step 20227, loss 0.671854.
Train: 2018-08-01T01:10:12.933687: step 20228, loss 0.570818.
Train: 2018-08-01T01:10:13.089894: step 20229, loss 0.504049.
Train: 2018-08-01T01:10:13.261741: step 20230, loss 0.547125.
Test: 2018-08-01T01:10:13.730345: step 20230, loss 0.549775.
Train: 2018-08-01T01:10:13.886582: step 20231, loss 0.562976.
Train: 2018-08-01T01:10:14.058417: step 20232, loss 0.529765.
Train: 2018-08-01T01:10:14.214643: step 20233, loss 0.649421.
Train: 2018-08-01T01:10:14.370852: step 20234, loss 0.65177.
Train: 2018-08-01T01:10:14.527069: step 20235, loss 0.546363.
Train: 2018-08-01T01:10:14.683272: step 20236, loss 0.682443.
Train: 2018-08-01T01:10:14.839490: step 20237, loss 0.700873.
Train: 2018-08-01T01:10:14.995706: step 20238, loss 0.496725.
Train: 2018-08-01T01:10:15.151918: step 20239, loss 0.59701.
Train: 2018-08-01T01:10:15.323721: step 20240, loss 0.614529.
Test: 2018-08-01T01:10:15.792391: step 20240, loss 0.549273.
Train: 2018-08-01T01:10:15.948606: step 20241, loss 0.579737.
Train: 2018-08-01T01:10:16.120410: step 20242, loss 0.613301.
Train: 2018-08-01T01:10:16.276623: step 20243, loss 0.530519.
Train: 2018-08-01T01:10:16.448488: step 20244, loss 0.580709.
Train: 2018-08-01T01:10:16.620325: step 20245, loss 0.546496.
Train: 2018-08-01T01:10:16.776533: step 20246, loss 0.646615.
Train: 2018-08-01T01:10:16.932752: step 20247, loss 0.546856.
Train: 2018-08-01T01:10:17.088933: step 20248, loss 0.597919.
Train: 2018-08-01T01:10:17.245147: step 20249, loss 0.514212.
Train: 2018-08-01T01:10:17.448252: step 20250, loss 0.64651.
Test: 2018-08-01T01:10:17.901273: step 20250, loss 0.549603.
Train: 2018-08-01T01:10:18.073102: step 20251, loss 0.580182.
Train: 2018-08-01T01:10:18.229322: step 20252, loss 0.530775.
Train: 2018-08-01T01:10:18.385529: step 20253, loss 0.480987.
Train: 2018-08-01T01:10:18.541719: step 20254, loss 0.563352.
Train: 2018-08-01T01:10:18.697962: step 20255, loss 0.57986.
Train: 2018-08-01T01:10:18.854170: step 20256, loss 0.529801.
Train: 2018-08-01T01:10:19.010359: step 20257, loss 0.614059.
Train: 2018-08-01T01:10:19.166602: step 20258, loss 0.630416.
Train: 2018-08-01T01:10:19.322784: step 20259, loss 0.546193.
Train: 2018-08-01T01:10:19.478999: step 20260, loss 0.546149.
Test: 2018-08-01T01:10:19.963290: step 20260, loss 0.549395.
Train: 2018-08-01T01:10:20.119506: step 20261, loss 0.580088.
Train: 2018-08-01T01:10:20.275716: step 20262, loss 0.51382.
Train: 2018-08-01T01:10:20.431930: step 20263, loss 0.581157.
Train: 2018-08-01T01:10:20.588143: step 20264, loss 0.547158.
Train: 2018-08-01T01:10:20.759976: step 20265, loss 0.563731.
Train: 2018-08-01T01:10:20.916161: step 20266, loss 0.648152.
Train: 2018-08-01T01:10:21.072374: step 20267, loss 0.532342.
Train: 2018-08-01T01:10:21.212968: step 20268, loss 0.51443.
Train: 2018-08-01T01:10:21.369213: step 20269, loss 0.464977.
Train: 2018-08-01T01:10:21.525424: step 20270, loss 0.579481.
Test: 2018-08-01T01:10:22.009687: step 20270, loss 0.549351.
Train: 2018-08-01T01:10:22.165894: step 20271, loss 0.613253.
Train: 2018-08-01T01:10:22.322113: step 20272, loss 0.546963.
Train: 2018-08-01T01:10:22.493949: step 20273, loss 0.479892.
Train: 2018-08-01T01:10:22.650161: step 20274, loss 0.596676.
Train: 2018-08-01T01:10:22.806374: step 20275, loss 0.479199.
Train: 2018-08-01T01:10:22.978180: step 20276, loss 0.613711.
Train: 2018-08-01T01:10:23.118770: step 20277, loss 0.630407.
Train: 2018-08-01T01:10:23.290636: step 20278, loss 0.580244.
Train: 2018-08-01T01:10:23.446820: step 20279, loss 0.59702.
Train: 2018-08-01T01:10:23.603063: step 20280, loss 0.512414.
Test: 2018-08-01T01:10:24.071673: step 20280, loss 0.549072.
Train: 2018-08-01T01:10:24.243537: step 20281, loss 0.664937.
Train: 2018-08-01T01:10:24.399720: step 20282, loss 0.478628.
Train: 2018-08-01T01:10:24.555934: step 20283, loss 0.47867.
Train: 2018-08-01T01:10:24.712178: step 20284, loss 0.648003.
Train: 2018-08-01T01:10:24.868360: step 20285, loss 0.58001.
Train: 2018-08-01T01:10:25.024574: step 20286, loss 0.58.
Train: 2018-08-01T01:10:25.196410: step 20287, loss 0.461804.
Train: 2018-08-01T01:10:25.352624: step 20288, loss 0.579929.
Train: 2018-08-01T01:10:25.508868: step 20289, loss 0.563032.
Train: 2018-08-01T01:10:25.665081: step 20290, loss 0.562935.
Test: 2018-08-01T01:10:26.149341: step 20290, loss 0.548877.
Train: 2018-08-01T01:10:26.321146: step 20291, loss 0.546421.
Train: 2018-08-01T01:10:26.477359: step 20292, loss 0.529147.
Train: 2018-08-01T01:10:26.633604: step 20293, loss 0.529038.
Train: 2018-08-01T01:10:26.789787: step 20294, loss 0.460459.
Train: 2018-08-01T01:10:26.946000: step 20295, loss 0.511087.
Train: 2018-08-01T01:10:27.102244: step 20296, loss 0.597675.
Train: 2018-08-01T01:10:27.274073: step 20297, loss 0.597394.
Train: 2018-08-01T01:10:27.445883: step 20298, loss 0.545854.
Train: 2018-08-01T01:10:27.602097: step 20299, loss 0.458875.
Train: 2018-08-01T01:10:27.758341: step 20300, loss 0.528531.
Test: 2018-08-01T01:10:28.226980: step 20300, loss 0.548502.
Train: 2018-08-01T01:10:28.929940: step 20301, loss 0.44118.
Train: 2018-08-01T01:10:29.086155: step 20302, loss 0.59811.
Train: 2018-08-01T01:10:29.257990: step 20303, loss 0.580867.
Train: 2018-08-01T01:10:29.414172: step 20304, loss 0.581072.
Train: 2018-08-01T01:10:29.586031: step 20305, loss 0.599048.
Train: 2018-08-01T01:10:29.742250: step 20306, loss 0.508611.
Train: 2018-08-01T01:10:29.898463: step 20307, loss 0.576557.
Train: 2018-08-01T01:10:30.054683: step 20308, loss 0.631774.
Train: 2018-08-01T01:10:30.210890: step 20309, loss 0.621314.
Train: 2018-08-01T01:10:30.382695: step 20310, loss 0.571776.
Test: 2018-08-01T01:10:30.851334: step 20310, loss 0.553072.
Train: 2018-08-01T01:10:31.007580: step 20311, loss 0.634205.
Train: 2018-08-01T01:10:31.163792: step 20312, loss 0.585204.
Train: 2018-08-01T01:10:31.320005: step 20313, loss 0.714534.
Train: 2018-08-01T01:10:31.476220: step 20314, loss 0.564746.
Train: 2018-08-01T01:10:31.648050: step 20315, loss 0.584748.
Train: 2018-08-01T01:10:31.804236: step 20316, loss 0.496154.
Train: 2018-08-01T01:10:31.960450: step 20317, loss 0.670361.
Train: 2018-08-01T01:10:32.132286: step 20318, loss 0.633483.
Train: 2018-08-01T01:10:32.288499: step 20319, loss 0.572065.
Train: 2018-08-01T01:10:32.444712: step 20320, loss 0.587671.
Test: 2018-08-01T01:10:32.913382: step 20320, loss 0.548741.
Train: 2018-08-01T01:10:33.069597: step 20321, loss 0.496373.
Train: 2018-08-01T01:10:33.241432: step 20322, loss 0.733739.
Train: 2018-08-01T01:10:33.397615: step 20323, loss 0.512453.
Train: 2018-08-01T01:10:33.553827: step 20324, loss 0.578951.
Train: 2018-08-01T01:10:33.710071: step 20325, loss 0.683536.
Train: 2018-08-01T01:10:33.866256: step 20326, loss 0.509969.
Train: 2018-08-01T01:10:34.022493: step 20327, loss 0.527865.
Train: 2018-08-01T01:10:34.194334: step 20328, loss 0.562264.
Train: 2018-08-01T01:10:34.350546: step 20329, loss 0.581627.
Train: 2018-08-01T01:10:34.506728: step 20330, loss 0.47459.
Test: 2018-08-01T01:10:34.975406: step 20330, loss 0.548306.
Train: 2018-08-01T01:10:35.131614: step 20331, loss 0.561712.
Train: 2018-08-01T01:10:35.303418: step 20332, loss 0.476456.
Train: 2018-08-01T01:10:35.459661: step 20333, loss 0.508124.
Train: 2018-08-01T01:10:35.615844: step 20334, loss 0.492368.
Train: 2018-08-01T01:10:35.772082: step 20335, loss 0.733369.
Train: 2018-08-01T01:10:35.928307: step 20336, loss 0.587836.
Train: 2018-08-01T01:10:36.100106: step 20337, loss 0.6003.
Train: 2018-08-01T01:10:36.256351: step 20338, loss 0.634927.
Train: 2018-08-01T01:10:36.412566: step 20339, loss 0.491574.
Train: 2018-08-01T01:10:36.568747: step 20340, loss 0.529232.
Test: 2018-08-01T01:10:37.037417: step 20340, loss 0.548374.
Train: 2018-08-01T01:10:37.193601: step 20341, loss 0.615548.
Train: 2018-08-01T01:10:37.349813: step 20342, loss 0.579948.
Train: 2018-08-01T01:10:37.506051: step 20343, loss 0.631611.
Train: 2018-08-01T01:10:37.662240: step 20344, loss 0.631658.
Train: 2018-08-01T01:10:37.834076: step 20345, loss 0.494108.
Train: 2018-08-01T01:10:37.990313: step 20346, loss 0.512005.
Train: 2018-08-01T01:10:38.146533: step 20347, loss 0.494263.
Train: 2018-08-01T01:10:38.318338: step 20348, loss 0.528516.
Train: 2018-08-01T01:10:38.458953: step 20349, loss 0.562048.
Train: 2018-08-01T01:10:38.615143: step 20350, loss 0.596759.
Test: 2018-08-01T01:10:39.099434: step 20350, loss 0.548274.
Train: 2018-08-01T01:10:39.255617: step 20351, loss 0.387474.
Train: 2018-08-01T01:10:39.427453: step 20352, loss 0.419975.
Train: 2018-08-01T01:10:39.583665: step 20353, loss 0.631036.
Train: 2018-08-01T01:10:39.755531: step 20354, loss 0.561201.
Train: 2018-08-01T01:10:39.911744: step 20355, loss 0.496704.
Train: 2018-08-01T01:10:40.067927: step 20356, loss 0.461562.
Train: 2018-08-01T01:10:40.224140: step 20357, loss 0.557178.
Train: 2018-08-01T01:10:40.380354: step 20358, loss 0.649894.
Train: 2018-08-01T01:10:40.567810: step 20359, loss 0.515049.
Train: 2018-08-01T01:10:40.724024: step 20360, loss 0.524243.
Test: 2018-08-01T01:10:41.192693: step 20360, loss 0.548099.
Train: 2018-08-01T01:10:41.348877: step 20361, loss 0.543707.
Train: 2018-08-01T01:10:41.505122: step 20362, loss 0.491981.
Train: 2018-08-01T01:10:41.676955: step 20363, loss 0.474154.
Train: 2018-08-01T01:10:41.833168: step 20364, loss 0.546224.
Train: 2018-08-01T01:10:41.989351: step 20365, loss 0.475137.
Train: 2018-08-01T01:10:42.145596: step 20366, loss 0.633965.
Train: 2018-08-01T01:10:42.301809: step 20367, loss 0.634708.
Train: 2018-08-01T01:10:42.457992: step 20368, loss 0.669845.
Train: 2018-08-01T01:10:42.614207: step 20369, loss 0.616743.
Train: 2018-08-01T01:10:42.786065: step 20370, loss 0.545418.
Test: 2018-08-01T01:10:43.270332: step 20370, loss 0.548225.
Train: 2018-08-01T01:10:43.426516: step 20371, loss 0.509827.
Train: 2018-08-01T01:10:43.582759: step 20372, loss 0.545692.
Train: 2018-08-01T01:10:43.754582: step 20373, loss 0.509995.
Train: 2018-08-01T01:10:43.910807: step 20374, loss 0.580952.
Train: 2018-08-01T01:10:44.067021: step 20375, loss 0.686899.
Train: 2018-08-01T01:10:44.223234: step 20376, loss 0.597799.
Train: 2018-08-01T01:10:44.379441: step 20377, loss 0.510086.
Train: 2018-08-01T01:10:44.551276: step 20378, loss 0.545372.
Train: 2018-08-01T01:10:44.707465: step 20379, loss 0.510405.
Train: 2018-08-01T01:10:44.879300: step 20380, loss 0.492849.
Test: 2018-08-01T01:10:45.347970: step 20380, loss 0.548259.
Train: 2018-08-01T01:10:45.519776: step 20381, loss 0.563514.
Train: 2018-08-01T01:10:45.676020: step 20382, loss 0.56271.
Train: 2018-08-01T01:10:45.832228: step 20383, loss 0.562969.
Train: 2018-08-01T01:10:46.004074: step 20384, loss 0.597653.
Train: 2018-08-01T01:10:46.160275: step 20385, loss 0.509992.
Train: 2018-08-01T01:10:46.316494: step 20386, loss 0.616201.
Train: 2018-08-01T01:10:46.472676: step 20387, loss 0.527949.
Train: 2018-08-01T01:10:46.628891: step 20388, loss 0.651059.
Train: 2018-08-01T01:10:46.785128: step 20389, loss 0.615907.
Train: 2018-08-01T01:10:46.941351: step 20390, loss 0.562389.
Test: 2018-08-01T01:10:47.425609: step 20390, loss 0.548252.
Train: 2018-08-01T01:10:47.628688: step 20391, loss 0.632773.
Train: 2018-08-01T01:10:47.784900: step 20392, loss 0.51049.
Train: 2018-08-01T01:10:47.941084: step 20393, loss 0.457713.
Train: 2018-08-01T01:10:48.097299: step 20394, loss 0.59746.
Train: 2018-08-01T01:10:48.269156: step 20395, loss 0.475892.
Train: 2018-08-01T01:10:48.425376: step 20396, loss 0.493572.
Train: 2018-08-01T01:10:48.581558: step 20397, loss 0.615038.
Train: 2018-08-01T01:10:48.753425: step 20398, loss 0.4417.
Train: 2018-08-01T01:10:48.909606: step 20399, loss 0.5975.
Train: 2018-08-01T01:10:49.065820: step 20400, loss 0.667021.
Test: 2018-08-01T01:10:49.534490: step 20400, loss 0.548203.
Train: 2018-08-01T01:10:50.268695: step 20401, loss 0.545944.
Train: 2018-08-01T01:10:50.440522: step 20402, loss 0.598208.
Train: 2018-08-01T01:10:50.596744: step 20403, loss 0.510867.
Train: 2018-08-01T01:10:50.752924: step 20404, loss 0.511414.
Train: 2018-08-01T01:10:50.924789: step 20405, loss 0.615247.
Train: 2018-08-01T01:10:51.080972: step 20406, loss 0.580912.
Train: 2018-08-01T01:10:51.237219: step 20407, loss 0.527995.
Train: 2018-08-01T01:10:51.409022: step 20408, loss 0.528215.
Train: 2018-08-01T01:10:51.565265: step 20409, loss 0.580262.
Train: 2018-08-01T01:10:51.721478: step 20410, loss 0.440266.
Test: 2018-08-01T01:10:52.190118: step 20410, loss 0.548151.
Train: 2018-08-01T01:10:52.361952: step 20411, loss 0.54492.
Train: 2018-08-01T01:10:52.518166: step 20412, loss 0.492143.
Train: 2018-08-01T01:10:52.674384: step 20413, loss 0.545213.
Train: 2018-08-01T01:10:52.830564: step 20414, loss 0.721838.
Train: 2018-08-01T01:10:52.986777: step 20415, loss 0.616019.
Train: 2018-08-01T01:10:53.143020: step 20416, loss 0.439435.
Train: 2018-08-01T01:10:53.299204: step 20417, loss 0.598111.
Train: 2018-08-01T01:10:53.471038: step 20418, loss 0.474428.
Train: 2018-08-01T01:10:53.642873: step 20419, loss 0.492225.
Train: 2018-08-01T01:10:53.799086: step 20420, loss 0.562975.
Test: 2018-08-01T01:10:54.267728: step 20420, loss 0.548042.
Train: 2018-08-01T01:10:54.423970: step 20421, loss 0.580977.
Train: 2018-08-01T01:10:54.580183: step 20422, loss 0.52709.
Train: 2018-08-01T01:10:54.736393: step 20423, loss 0.544593.
Train: 2018-08-01T01:10:54.892580: step 20424, loss 0.674067.
Train: 2018-08-01T01:10:55.048795: step 20425, loss 0.508167.
Train: 2018-08-01T01:10:55.205008: step 20426, loss 0.491412.
Train: 2018-08-01T01:10:55.361221: step 20427, loss 0.52696.
Train: 2018-08-01T01:10:55.517434: step 20428, loss 0.617387.
Train: 2018-08-01T01:10:55.673678: step 20429, loss 0.509274.
Train: 2018-08-01T01:10:55.845482: step 20430, loss 0.563423.
Test: 2018-08-01T01:10:56.329743: step 20430, loss 0.548006.
Train: 2018-08-01T01:10:56.485987: step 20431, loss 0.562966.
Train: 2018-08-01T01:10:56.642201: step 20432, loss 0.58074.
Train: 2018-08-01T01:10:56.798385: step 20433, loss 0.509322.
Train: 2018-08-01T01:10:56.970218: step 20434, loss 0.526961.
Train: 2018-08-01T01:10:57.126432: step 20435, loss 0.635112.
Train: 2018-08-01T01:10:57.282646: step 20436, loss 0.455401.
Train: 2018-08-01T01:10:57.438889: step 20437, loss 0.598923.
Train: 2018-08-01T01:10:57.595072: step 20438, loss 0.509238.
Train: 2018-08-01T01:10:57.766907: step 20439, loss 0.59883.
Train: 2018-08-01T01:10:57.923152: step 20440, loss 0.509127.
Test: 2018-08-01T01:10:58.391791: step 20440, loss 0.547966.
Train: 2018-08-01T01:10:58.547998: step 20441, loss 0.527012.
Train: 2018-08-01T01:10:58.704218: step 20442, loss 0.56306.
Train: 2018-08-01T01:10:58.860434: step 20443, loss 0.527088.
Train: 2018-08-01T01:10:59.032237: step 20444, loss 0.671017.
Train: 2018-08-01T01:10:59.204070: step 20445, loss 0.580942.
Train: 2018-08-01T01:10:59.360321: step 20446, loss 0.509136.
Train: 2018-08-01T01:10:59.516529: step 20447, loss 0.706568.
Train: 2018-08-01T01:10:59.688332: step 20448, loss 0.509237.
Train: 2018-08-01T01:10:59.828924: step 20449, loss 0.652456.
Train: 2018-08-01T01:11:00.016382: step 20450, loss 0.580828.
Test: 2018-08-01T01:11:00.485021: step 20450, loss 0.547984.
Train: 2018-08-01T01:11:00.641234: step 20451, loss 0.544969.
Train: 2018-08-01T01:11:00.797448: step 20452, loss 0.474169.
Train: 2018-08-01T01:11:00.969282: step 20453, loss 0.544985.
Train: 2018-08-01T01:11:01.109874: step 20454, loss 0.545355.
Train: 2018-08-01T01:11:01.297368: step 20455, loss 0.580412.
Train: 2018-08-01T01:11:01.453543: step 20456, loss 0.562663.
Train: 2018-08-01T01:11:01.609782: step 20457, loss 0.63352.
Train: 2018-08-01T01:11:01.781593: step 20458, loss 0.50984.
Train: 2018-08-01T01:11:01.937806: step 20459, loss 0.633225.
Train: 2018-08-01T01:11:02.094020: step 20460, loss 0.527687.
Test: 2018-08-01T01:11:02.578281: step 20460, loss 0.548082.
Train: 2018-08-01T01:11:02.734526: step 20461, loss 0.668066.
Train: 2018-08-01T01:11:02.890737: step 20462, loss 0.616038.
Train: 2018-08-01T01:11:03.046953: step 20463, loss 0.528184.
Train: 2018-08-01T01:11:03.203134: step 20464, loss 0.475834.
Train: 2018-08-01T01:11:03.359348: step 20465, loss 0.580145.
Train: 2018-08-01T01:11:03.515562: step 20466, loss 0.683917.
Train: 2018-08-01T01:11:03.671804: step 20467, loss 0.562914.
Train: 2018-08-01T01:11:03.827988: step 20468, loss 0.489489.
Train: 2018-08-01T01:11:03.984202: step 20469, loss 0.476418.
Train: 2018-08-01T01:11:04.156067: step 20470, loss 0.648951.
Test: 2018-08-01T01:11:04.624708: step 20470, loss 0.548254.
Train: 2018-08-01T01:11:04.780922: step 20471, loss 0.493696.
Train: 2018-08-01T01:11:04.937103: step 20472, loss 0.528421.
Train: 2018-08-01T01:11:05.093347: step 20473, loss 0.614555.
Train: 2018-08-01T01:11:05.249530: step 20474, loss 0.545201.
Train: 2018-08-01T01:11:05.405743: step 20475, loss 0.545511.
Train: 2018-08-01T01:11:05.561956: step 20476, loss 0.528042.
Train: 2018-08-01T01:11:05.733791: step 20477, loss 0.615012.
Train: 2018-08-01T01:11:05.874383: step 20478, loss 0.580108.
Train: 2018-08-01T01:11:06.030598: step 20479, loss 0.562714.
Train: 2018-08-01T01:11:06.186811: step 20480, loss 0.510785.
Test: 2018-08-01T01:11:06.655451: step 20480, loss 0.548204.
Train: 2018-08-01T01:11:06.827317: step 20481, loss 0.631627.
Train: 2018-08-01T01:11:06.983500: step 20482, loss 0.545387.
Train: 2018-08-01T01:11:07.139742: step 20483, loss 0.545175.
Train: 2018-08-01T01:11:07.311578: step 20484, loss 0.614568.
Train: 2018-08-01T01:11:07.467791: step 20485, loss 0.596862.
Train: 2018-08-01T01:11:07.608382: step 20486, loss 0.563076.
Train: 2018-08-01T01:11:07.764596: step 20487, loss 0.511263.
Train: 2018-08-01T01:11:07.936401: step 20488, loss 0.56292.
Train: 2018-08-01T01:11:08.092615: step 20489, loss 0.510802.
Train: 2018-08-01T01:11:08.248828: step 20490, loss 0.562916.
Test: 2018-08-01T01:11:08.733114: step 20490, loss 0.548409.
Train: 2018-08-01T01:11:08.873713: step 20491, loss 0.629961.
Train: 2018-08-01T01:11:09.045516: step 20492, loss 0.562627.
Train: 2018-08-01T01:11:09.201754: step 20493, loss 0.562247.
Train: 2018-08-01T01:11:09.357973: step 20494, loss 0.495954.
Train: 2018-08-01T01:11:09.514157: step 20495, loss 0.650016.
Train: 2018-08-01T01:11:09.670370: step 20496, loss 0.647696.
Train: 2018-08-01T01:11:09.826582: step 20497, loss 0.679293.
Train: 2018-08-01T01:11:09.982826: step 20498, loss 0.597819.
Train: 2018-08-01T01:11:10.154668: step 20499, loss 0.562777.
Train: 2018-08-01T01:11:10.310881: step 20500, loss 0.513946.
Test: 2018-08-01T01:11:10.779485: step 20500, loss 0.548863.
Train: 2018-08-01T01:11:11.544955: step 20501, loss 0.496709.
Train: 2018-08-01T01:11:11.701175: step 20502, loss 0.49625.
Train: 2018-08-01T01:11:11.857387: step 20503, loss 0.527736.
Train: 2018-08-01T01:11:12.029192: step 20504, loss 0.53004.
Train: 2018-08-01T01:11:12.201028: step 20505, loss 0.528096.
Train: 2018-08-01T01:11:12.372887: step 20506, loss 0.545444.
Train: 2018-08-01T01:11:12.529100: step 20507, loss 0.528647.
Train: 2018-08-01T01:11:12.685320: step 20508, loss 0.443641.
Train: 2018-08-01T01:11:12.841533: step 20509, loss 0.545345.
Train: 2018-08-01T01:11:12.997747: step 20510, loss 0.54543.
Test: 2018-08-01T01:11:13.466386: step 20510, loss 0.548144.
Train: 2018-08-01T01:11:13.622569: step 20511, loss 0.510477.
Train: 2018-08-01T01:11:13.778813: step 20512, loss 0.527533.
Train: 2018-08-01T01:11:13.935027: step 20513, loss 0.616095.
Train: 2018-08-01T01:11:14.091240: step 20514, loss 0.544786.
Train: 2018-08-01T01:11:14.247423: step 20515, loss 0.580545.
Train: 2018-08-01T01:11:14.434906: step 20516, loss 0.580979.
Train: 2018-08-01T01:11:14.591092: step 20517, loss 0.61555.
Train: 2018-08-01T01:11:14.747305: step 20518, loss 0.5451.
Train: 2018-08-01T01:11:14.903519: step 20519, loss 0.598741.
Train: 2018-08-01T01:11:15.059732: step 20520, loss 0.528034.
Test: 2018-08-01T01:11:15.528373: step 20520, loss 0.547915.
Train: 2018-08-01T01:11:15.684616: step 20521, loss 0.545192.
Train: 2018-08-01T01:11:15.840830: step 20522, loss 0.527691.
Train: 2018-08-01T01:11:15.997037: step 20523, loss 0.63375.
Train: 2018-08-01T01:11:16.153257: step 20524, loss 0.527591.
Train: 2018-08-01T01:11:16.325091: step 20525, loss 0.616074.
Train: 2018-08-01T01:11:16.496896: step 20526, loss 0.59793.
Train: 2018-08-01T01:11:16.653135: step 20527, loss 0.509686.
Train: 2018-08-01T01:11:16.809353: step 20528, loss 0.615486.
Train: 2018-08-01T01:11:16.965537: step 20529, loss 0.615423.
Train: 2018-08-01T01:11:17.121751: step 20530, loss 0.510137.
Test: 2018-08-01T01:11:17.590390: step 20530, loss 0.547999.
Train: 2018-08-01T01:11:17.762249: step 20531, loss 0.475044.
Train: 2018-08-01T01:11:17.918438: step 20532, loss 0.545122.
Train: 2018-08-01T01:11:18.074652: step 20533, loss 0.527605.
Train: 2018-08-01T01:11:18.230865: step 20534, loss 0.597813.
Train: 2018-08-01T01:11:18.387109: step 20535, loss 0.562594.
Train: 2018-08-01T01:11:18.543323: step 20536, loss 0.597706.
Train: 2018-08-01T01:11:18.699505: step 20537, loss 0.650334.
Train: 2018-08-01T01:11:18.855719: step 20538, loss 0.562562.
Train: 2018-08-01T01:11:19.011963: step 20539, loss 0.475316.
Train: 2018-08-01T01:11:19.168147: step 20540, loss 0.579969.
Test: 2018-08-01T01:11:19.652437: step 20540, loss 0.548026.
Train: 2018-08-01T01:11:19.808620: step 20541, loss 0.492736.
Train: 2018-08-01T01:11:19.980480: step 20542, loss 0.562617.
Train: 2018-08-01T01:11:20.136699: step 20543, loss 0.580154.
Train: 2018-08-01T01:11:20.292912: step 20544, loss 0.597581.
Train: 2018-08-01T01:11:20.449126: step 20545, loss 0.492821.
Train: 2018-08-01T01:11:20.620962: step 20546, loss 0.580034.
Train: 2018-08-01T01:11:20.777144: step 20547, loss 0.579966.
Train: 2018-08-01T01:11:20.933357: step 20548, loss 0.632252.
Train: 2018-08-01T01:11:21.120813: step 20549, loss 0.579875.
Train: 2018-08-01T01:11:21.261436: step 20550, loss 0.475613.
Test: 2018-08-01T01:11:21.745667: step 20550, loss 0.548047.
Train: 2018-08-01T01:11:21.886260: step 20551, loss 0.510378.
Train: 2018-08-01T01:11:22.058096: step 20552, loss 0.458228.
Train: 2018-08-01T01:11:22.229929: step 20553, loss 0.492578.
Train: 2018-08-01T01:11:22.386172: step 20554, loss 0.54509.
Train: 2018-08-01T01:11:22.542387: step 20555, loss 0.562642.
Train: 2018-08-01T01:11:22.714221: step 20556, loss 0.562813.
Train: 2018-08-01T01:11:22.870441: step 20557, loss 0.439699.
Train: 2018-08-01T01:11:23.026653: step 20558, loss 0.615936.
Train: 2018-08-01T01:11:23.214105: step 20559, loss 0.491996.
Train: 2018-08-01T01:11:23.370318: step 20560, loss 0.598246.
Test: 2018-08-01T01:11:23.838957: step 20560, loss 0.547852.
Train: 2018-08-01T01:11:23.995172: step 20561, loss 0.473778.
Train: 2018-08-01T01:11:24.151384: step 20562, loss 0.70518.
Train: 2018-08-01T01:11:24.323225: step 20563, loss 0.49152.
Train: 2018-08-01T01:11:24.463781: step 20564, loss 0.580763.
Train: 2018-08-01T01:11:24.620025: step 20565, loss 0.545187.
Train: 2018-08-01T01:11:24.776238: step 20566, loss 0.527098.
Train: 2018-08-01T01:11:24.932451: step 20567, loss 0.562784.
Train: 2018-08-01T01:11:25.088634: step 20568, loss 0.616627.
Train: 2018-08-01T01:11:25.244879: step 20569, loss 0.491161.
Train: 2018-08-01T01:11:25.416683: step 20570, loss 0.527003.
Test: 2018-08-01T01:11:25.885323: step 20570, loss 0.547789.
Train: 2018-08-01T01:11:26.041566: step 20571, loss 0.509063.
Train: 2018-08-01T01:11:26.213371: step 20572, loss 0.616641.
Train: 2018-08-01T01:11:26.353993: step 20573, loss 0.527028.
Train: 2018-08-01T01:11:26.525834: step 20574, loss 0.50882.
Train: 2018-08-01T01:11:26.682012: step 20575, loss 0.562984.
Train: 2018-08-01T01:11:26.838225: step 20576, loss 0.490835.
Train: 2018-08-01T01:11:26.978816: step 20577, loss 0.508596.
Train: 2018-08-01T01:11:27.150651: step 20578, loss 0.580872.
Train: 2018-08-01T01:11:27.291273: step 20579, loss 0.436423.
Train: 2018-08-01T01:11:27.463078: step 20580, loss 0.490124.
Test: 2018-08-01T01:11:27.931752: step 20580, loss 0.547764.
Train: 2018-08-01T01:11:28.103579: step 20581, loss 0.745241.
Train: 2018-08-01T01:11:28.259766: step 20582, loss 0.490289.
Train: 2018-08-01T01:11:28.415980: step 20583, loss 0.563115.
Train: 2018-08-01T01:11:28.603437: step 20584, loss 0.471792.
Train: 2018-08-01T01:11:28.775296: step 20585, loss 0.746091.
Train: 2018-08-01T01:11:28.931514: step 20586, loss 0.74577.
Train: 2018-08-01T01:11:29.103343: step 20587, loss 0.490149.
Train: 2018-08-01T01:11:29.259533: step 20588, loss 0.490286.
Train: 2018-08-01T01:11:29.415746: step 20589, loss 0.363169.
Train: 2018-08-01T01:11:29.571990: step 20590, loss 0.50845.
Test: 2018-08-01T01:11:30.040630: step 20590, loss 0.547754.
Train: 2018-08-01T01:11:30.196837: step 20591, loss 0.672283.
Train: 2018-08-01T01:11:30.353027: step 20592, loss 0.526613.
Train: 2018-08-01T01:11:30.509274: step 20593, loss 0.526614.
Train: 2018-08-01T01:11:30.681081: step 20594, loss 0.563019.
Train: 2018-08-01T01:11:30.837320: step 20595, loss 0.435496.
Train: 2018-08-01T01:11:30.993533: step 20596, loss 0.599541.
Train: 2018-08-01T01:11:31.149716: step 20597, loss 0.471758.
Train: 2018-08-01T01:11:31.305958: step 20598, loss 0.526506.
Train: 2018-08-01T01:11:31.462171: step 20599, loss 0.563078.
Train: 2018-08-01T01:11:31.633976: step 20600, loss 0.563099.
Test: 2018-08-01T01:11:32.102646: step 20600, loss 0.547745.
Train: 2018-08-01T01:11:32.789956: step 20601, loss 0.544748.
Train: 2018-08-01T01:11:32.946169: step 20602, loss 0.526392.
Train: 2018-08-01T01:11:33.133625: step 20603, loss 0.655109.
Train: 2018-08-01T01:11:33.289869: step 20604, loss 0.618309.
Train: 2018-08-01T01:11:33.446082: step 20605, loss 0.581488.
Train: 2018-08-01T01:11:33.602295: step 20606, loss 0.581428.
Train: 2018-08-01T01:11:33.758479: step 20607, loss 0.709528.
Train: 2018-08-01T01:11:33.930313: step 20608, loss 0.599493.
Train: 2018-08-01T01:11:34.086527: step 20609, loss 0.490258.
Train: 2018-08-01T01:11:34.258392: step 20610, loss 0.581042.
Test: 2018-08-01T01:11:34.742648: step 20610, loss 0.547747.
Train: 2018-08-01T01:11:34.898861: step 20611, loss 0.544807.
Train: 2018-08-01T01:11:35.055051: step 20612, loss 0.58089.
Train: 2018-08-01T01:11:35.211291: step 20613, loss 0.56282.
Train: 2018-08-01T01:11:35.383098: step 20614, loss 0.616626.
Train: 2018-08-01T01:11:35.539312: step 20615, loss 0.491208.
Train: 2018-08-01T01:11:35.695525: step 20616, loss 0.616313.
Train: 2018-08-01T01:11:35.851739: step 20617, loss 0.580523.
Train: 2018-08-01T01:11:36.007982: step 20618, loss 0.527178.
Train: 2018-08-01T01:11:36.164196: step 20619, loss 0.63358.
Train: 2018-08-01T01:11:36.336001: step 20620, loss 0.456605.
Test: 2018-08-01T01:11:36.820292: step 20620, loss 0.547865.
Train: 2018-08-01T01:11:36.976505: step 20621, loss 0.56265.
Train: 2018-08-01T01:11:37.132689: step 20622, loss 0.597903.
Train: 2018-08-01T01:11:37.288932: step 20623, loss 0.474615.
Train: 2018-08-01T01:11:37.460736: step 20624, loss 0.439461.
Train: 2018-08-01T01:11:37.632603: step 20625, loss 0.633084.
Train: 2018-08-01T01:11:37.788815: step 20626, loss 0.685924.
Train: 2018-08-01T01:11:37.945029: step 20627, loss 0.509863.
Train: 2018-08-01T01:11:38.101242: step 20628, loss 0.509906.
Train: 2018-08-01T01:11:38.257455: step 20629, loss 0.615313.
Train: 2018-08-01T01:11:38.413669: step 20630, loss 0.597705.
Test: 2018-08-01T01:11:38.882309: step 20630, loss 0.54792.
Train: 2018-08-01T01:11:39.038495: step 20631, loss 0.545069.
Train: 2018-08-01T01:11:39.194707: step 20632, loss 0.597608.
Train: 2018-08-01T01:11:39.350920: step 20633, loss 0.580069.
Train: 2018-08-01T01:11:39.522754: step 20634, loss 0.632402.
Train: 2018-08-01T01:11:39.678967: step 20635, loss 0.492905.
Train: 2018-08-01T01:11:39.835215: step 20636, loss 0.510383.
Train: 2018-08-01T01:11:39.991394: step 20637, loss 0.579942.
Train: 2018-08-01T01:11:40.147632: step 20638, loss 0.562555.
Train: 2018-08-01T01:11:40.303821: step 20639, loss 0.579915.
Train: 2018-08-01T01:11:40.460063: step 20640, loss 0.614579.
Test: 2018-08-01T01:11:40.928705: step 20640, loss 0.548047.
Train: 2018-08-01T01:11:41.084889: step 20641, loss 0.579864.
Train: 2018-08-01T01:11:41.241102: step 20642, loss 0.527967.
Train: 2018-08-01T01:11:41.412936: step 20643, loss 0.527996.
Train: 2018-08-01T01:11:41.569151: step 20644, loss 0.579805.
Train: 2018-08-01T01:11:41.725364: step 20645, loss 0.528032.
Train: 2018-08-01T01:11:41.897198: step 20646, loss 0.683264.
Train: 2018-08-01T01:11:42.053442: step 20647, loss 0.751909.
Train: 2018-08-01T01:11:42.209663: step 20648, loss 0.665417.
Train: 2018-08-01T01:11:42.365862: step 20649, loss 0.494301.
Train: 2018-08-01T01:11:42.522082: step 20650, loss 0.545547.
Test: 2018-08-01T01:11:42.990723: step 20650, loss 0.54836.
Train: 2018-08-01T01:11:43.146906: step 20651, loss 0.664216.
Train: 2018-08-01T01:11:43.318741: step 20652, loss 0.495057.
Train: 2018-08-01T01:11:43.474954: step 20653, loss 0.528916.
Train: 2018-08-01T01:11:43.615546: step 20654, loss 0.629765.
Train: 2018-08-01T01:11:43.771790: step 20655, loss 0.596099.
Train: 2018-08-01T01:11:43.943630: step 20656, loss 0.646143.
Train: 2018-08-01T01:11:44.115454: step 20657, loss 0.645858.
Train: 2018-08-01T01:11:44.271643: step 20658, loss 0.628963.
Train: 2018-08-01T01:11:44.427855: step 20659, loss 0.463712.
Train: 2018-08-01T01:11:44.584068: step 20660, loss 0.644977.
Test: 2018-08-01T01:11:45.052734: step 20660, loss 0.549023.
Train: 2018-08-01T01:11:45.224576: step 20661, loss 0.579143.
Train: 2018-08-01T01:11:45.380787: step 20662, loss 0.513758.
Train: 2018-08-01T01:11:45.537001: step 20663, loss 0.595419.
Train: 2018-08-01T01:11:45.693185: step 20664, loss 0.66045.
Train: 2018-08-01T01:11:45.849398: step 20665, loss 0.579087.
Train: 2018-08-01T01:11:46.021234: step 20666, loss 0.57907.
Train: 2018-08-01T01:11:46.177471: step 20667, loss 0.433947.
Train: 2018-08-01T01:11:46.333690: step 20668, loss 0.546826.
Train: 2018-08-01T01:11:46.489904: step 20669, loss 0.579065.
Train: 2018-08-01T01:11:46.646122: step 20670, loss 0.579058.
Test: 2018-08-01T01:11:47.130377: step 20670, loss 0.54944.
Train: 2018-08-01T01:11:47.286588: step 20671, loss 0.579055.
Train: 2018-08-01T01:11:47.442799: step 20672, loss 0.627415.
Train: 2018-08-01T01:11:47.598989: step 20673, loss 0.434098.
Train: 2018-08-01T01:11:47.770852: step 20674, loss 0.579058.
Train: 2018-08-01T01:11:47.927066: step 20675, loss 0.514469.
Train: 2018-08-01T01:11:48.083279: step 20676, loss 0.498164.
Train: 2018-08-01T01:11:48.239464: step 20677, loss 0.660224.
Train: 2018-08-01T01:11:48.395676: step 20678, loss 0.562835.
Train: 2018-08-01T01:11:48.567537: step 20679, loss 0.562819.
Train: 2018-08-01T01:11:48.723725: step 20680, loss 0.660586.
Test: 2018-08-01T01:11:49.208016: step 20680, loss 0.549156.
Train: 2018-08-01T01:11:49.364231: step 20681, loss 0.497617.
Train: 2018-08-01T01:11:49.536035: step 20682, loss 0.579107.
Train: 2018-08-01T01:11:49.692278: step 20683, loss 0.595438.
Train: 2018-08-01T01:11:49.848461: step 20684, loss 0.546435.
Train: 2018-08-01T01:11:50.004674: step 20685, loss 0.644529.
Train: 2018-08-01T01:11:50.160888: step 20686, loss 0.595465.
Train: 2018-08-01T01:11:50.317132: step 20687, loss 0.464741.
Train: 2018-08-01T01:11:50.473315: step 20688, loss 0.660899.
Train: 2018-08-01T01:11:50.660771: step 20689, loss 0.546417.
Train: 2018-08-01T01:11:50.817015: step 20690, loss 0.611819.
Test: 2018-08-01T01:11:51.301247: step 20690, loss 0.549081.
Train: 2018-08-01T01:11:51.457489: step 20691, loss 0.481044.
Train: 2018-08-01T01:11:51.613710: step 20692, loss 0.513682.
Train: 2018-08-01T01:11:51.785508: step 20693, loss 0.480807.
Train: 2018-08-01T01:11:51.941722: step 20694, loss 0.612011.
Train: 2018-08-01T01:11:52.097935: step 20695, loss 0.612091.
Train: 2018-08-01T01:11:52.269800: step 20696, loss 0.529712.
Train: 2018-08-01T01:11:52.426012: step 20697, loss 0.529646.
Train: 2018-08-01T01:11:52.582226: step 20698, loss 0.562654.
Train: 2018-08-01T01:11:52.754069: step 20699, loss 0.562636.
Train: 2018-08-01T01:11:52.925866: step 20700, loss 0.678902.
Test: 2018-08-01T01:11:53.406070: step 20700, loss 0.548709.
Train: 2018-08-01T01:11:54.124623: step 20701, loss 0.595848.
Train: 2018-08-01T01:11:54.280836: step 20702, loss 0.56262.
Train: 2018-08-01T01:11:54.437050: step 20703, loss 0.529406.
Train: 2018-08-01T01:11:54.593262: step 20704, loss 0.59585.
Train: 2018-08-01T01:11:54.749506: step 20705, loss 0.479534.
Train: 2018-08-01T01:11:54.905720: step 20706, loss 0.595887.
Train: 2018-08-01T01:11:55.093170: step 20707, loss 0.512648.
Train: 2018-08-01T01:11:55.233737: step 20708, loss 0.629305.
Train: 2018-08-01T01:11:55.389953: step 20709, loss 0.545903.
Train: 2018-08-01T01:11:55.546194: step 20710, loss 0.595988.
Test: 2018-08-01T01:11:56.030456: step 20710, loss 0.548594.
Train: 2018-08-01T01:11:56.202262: step 20711, loss 0.562582.
Train: 2018-08-01T01:11:56.358475: step 20712, loss 0.596004.
Train: 2018-08-01T01:11:56.514688: step 20713, loss 0.49574.
Train: 2018-08-01T01:11:56.670931: step 20714, loss 0.596029.
Train: 2018-08-01T01:11:56.827115: step 20715, loss 0.596042.
Train: 2018-08-01T01:11:56.983329: step 20716, loss 0.729923.
Train: 2018-08-01T01:11:57.139542: step 20717, loss 0.595977.
Train: 2018-08-01T01:11:57.326997: step 20718, loss 0.595914.
Train: 2018-08-01T01:11:57.467589: step 20719, loss 0.629077.
Train: 2018-08-01T01:11:57.623803: step 20720, loss 0.496378.
Test: 2018-08-01T01:11:58.108094: step 20720, loss 0.548803.
Train: 2018-08-01T01:11:58.264305: step 20721, loss 0.66186.
Train: 2018-08-01T01:11:58.436151: step 20722, loss 0.546185.
Train: 2018-08-01T01:11:58.592326: step 20723, loss 0.562692.
Train: 2018-08-01T01:11:58.748570: step 20724, loss 0.611966.
Train: 2018-08-01T01:11:58.904784: step 20725, loss 0.611875.
Train: 2018-08-01T01:11:59.076587: step 20726, loss 0.53008.
Train: 2018-08-01T01:11:59.232802: step 20727, loss 0.481229.
Train: 2018-08-01T01:11:59.389015: step 20728, loss 0.464943.
Train: 2018-08-01T01:11:59.545254: step 20729, loss 0.530107.
Train: 2018-08-01T01:11:59.701474: step 20730, loss 0.628179.
Test: 2018-08-01T01:12:00.170111: step 20730, loss 0.549023.
Train: 2018-08-01T01:12:00.341942: step 20731, loss 0.562734.
Train: 2018-08-01T01:12:00.513751: step 20732, loss 0.46439.
Train: 2018-08-01T01:12:00.654344: step 20733, loss 0.496986.
Train: 2018-08-01T01:12:00.810581: step 20734, loss 0.496743.
Train: 2018-08-01T01:12:00.966801: step 20735, loss 0.512996.
Train: 2018-08-01T01:12:01.122985: step 20736, loss 0.695565.
Train: 2018-08-01T01:12:01.279197: step 20737, loss 0.579247.
Train: 2018-08-01T01:12:01.435411: step 20738, loss 0.59595.
Train: 2018-08-01T01:12:01.607246: step 20739, loss 0.562571.
Train: 2018-08-01T01:12:01.747837: step 20740, loss 0.495662.
Test: 2018-08-01T01:12:02.232129: step 20740, loss 0.548518.
Train: 2018-08-01T01:12:02.388312: step 20741, loss 0.579313.
Train: 2018-08-01T01:12:02.528905: step 20742, loss 0.579333.
Train: 2018-08-01T01:12:02.700767: step 20743, loss 0.579349.
Train: 2018-08-01T01:12:02.856984: step 20744, loss 0.512043.
Train: 2018-08-01T01:12:03.013196: step 20745, loss 0.54567.
Train: 2018-08-01T01:12:03.169405: step 20746, loss 0.461187.
Train: 2018-08-01T01:12:03.325593: step 20747, loss 0.562509.
Train: 2018-08-01T01:12:03.497453: step 20748, loss 0.528527.
Train: 2018-08-01T01:12:03.669301: step 20749, loss 0.477306.
Train: 2018-08-01T01:12:03.825475: step 20750, loss 0.545389.
Test: 2018-08-01T01:12:04.309737: step 20750, loss 0.548116.
Train: 2018-08-01T01:12:04.465975: step 20751, loss 0.631158.
Train: 2018-08-01T01:12:04.637786: step 20752, loss 0.665738.
Train: 2018-08-01T01:12:04.794029: step 20753, loss 0.631377.
Train: 2018-08-01T01:12:04.950237: step 20754, loss 0.596926.
Train: 2018-08-01T01:12:05.106450: step 20755, loss 0.476458.
Train: 2018-08-01T01:12:05.262676: step 20756, loss 0.596921.
Train: 2018-08-01T01:12:05.418884: step 20757, loss 0.528057.
Train: 2018-08-01T01:12:05.575067: step 20758, loss 0.493593.
Train: 2018-08-01T01:12:05.746931: step 20759, loss 0.648764.
Train: 2018-08-01T01:12:05.887524: step 20760, loss 0.63147.
Test: 2018-08-01T01:12:06.356163: step 20760, loss 0.548067.
Train: 2018-08-01T01:12:06.527968: step 20761, loss 0.579734.
Train: 2018-08-01T01:12:06.684182: step 20762, loss 0.59688.
Train: 2018-08-01T01:12:06.840425: step 20763, loss 0.545385.
Train: 2018-08-01T01:12:06.996638: step 20764, loss 0.614158.
Train: 2018-08-01T01:12:07.168444: step 20765, loss 0.510817.
Train: 2018-08-01T01:12:07.309061: step 20766, loss 0.494803.
Train: 2018-08-01T01:12:07.465249: step 20767, loss 0.528363.
Train: 2018-08-01T01:12:07.637083: step 20768, loss 0.596654.
Train: 2018-08-01T01:12:07.793296: step 20769, loss 0.416381.
Train: 2018-08-01T01:12:07.949542: step 20770, loss 0.614046.
Test: 2018-08-01T01:12:08.418181: step 20770, loss 0.548076.
Train: 2018-08-01T01:12:08.574396: step 20771, loss 0.51084.
Train: 2018-08-01T01:12:08.746229: step 20772, loss 0.49351.
Train: 2018-08-01T01:12:08.902437: step 20773, loss 0.545295.
Train: 2018-08-01T01:12:09.058655: step 20774, loss 0.528155.
Train: 2018-08-01T01:12:09.214838: step 20775, loss 0.475474.
Train: 2018-08-01T01:12:09.402296: step 20776, loss 0.615216.
Train: 2018-08-01T01:12:09.558509: step 20777, loss 0.562653.
Train: 2018-08-01T01:12:09.714752: step 20778, loss 0.702511.
Train: 2018-08-01T01:12:09.886581: step 20779, loss 0.632544.
Train: 2018-08-01T01:12:10.042800: step 20780, loss 0.492764.
Test: 2018-08-01T01:12:10.511440: step 20780, loss 0.547935.
Train: 2018-08-01T01:12:10.667654: step 20781, loss 0.45764.
Train: 2018-08-01T01:12:10.839459: step 20782, loss 0.527616.
Train: 2018-08-01T01:12:10.995703: step 20783, loss 0.615023.
Train: 2018-08-01T01:12:11.151885: step 20784, loss 0.597372.
Train: 2018-08-01T01:12:11.308131: step 20785, loss 0.649454.
Train: 2018-08-01T01:12:11.464332: step 20786, loss 0.631035.
Train: 2018-08-01T01:12:11.620561: step 20787, loss 0.599359.
Train: 2018-08-01T01:12:11.776769: step 20788, loss 0.562406.
Train: 2018-08-01T01:12:11.932953: step 20789, loss 0.541437.
Train: 2018-08-01T01:12:12.089166: step 20790, loss 0.68311.
Test: 2018-08-01T01:12:12.557833: step 20790, loss 0.549219.
Train: 2018-08-01T01:12:12.714050: step 20791, loss 0.547092.
Train: 2018-08-01T01:12:12.870232: step 20792, loss 0.670651.
Train: 2018-08-01T01:12:13.042071: step 20793, loss 0.495736.
Train: 2018-08-01T01:12:13.182692: step 20794, loss 0.498936.
Train: 2018-08-01T01:12:13.338904: step 20795, loss 0.568665.
Train: 2018-08-01T01:12:13.495088: step 20796, loss 0.533968.
Train: 2018-08-01T01:12:13.698197: step 20797, loss 0.63054.
Train: 2018-08-01T01:12:13.854377: step 20798, loss 0.565199.
Train: 2018-08-01T01:12:13.995000: step 20799, loss 0.586211.
Train: 2018-08-01T01:12:14.166834: step 20800, loss 0.53029.
Test: 2018-08-01T01:12:14.635474: step 20800, loss 0.549182.
Train: 2018-08-01T01:12:15.385302: step 20801, loss 0.512311.
Train: 2018-08-01T01:12:15.541513: step 20802, loss 0.613102.
Train: 2018-08-01T01:12:15.697697: step 20803, loss 0.529143.
Train: 2018-08-01T01:12:15.869562: step 20804, loss 0.545957.
Train: 2018-08-01T01:12:16.025774: step 20805, loss 0.581933.
Train: 2018-08-01T01:12:16.181991: step 20806, loss 0.627569.
Train: 2018-08-01T01:12:16.338206: step 20807, loss 0.717394.
Train: 2018-08-01T01:12:16.494408: step 20808, loss 0.592259.
Train: 2018-08-01T01:12:16.650628: step 20809, loss 0.576072.
Train: 2018-08-01T01:12:16.806836: step 20810, loss 0.559885.
Test: 2018-08-01T01:12:17.291072: step 20810, loss 0.548948.
Train: 2018-08-01T01:12:17.447319: step 20811, loss 0.528432.
Train: 2018-08-01T01:12:17.650393: step 20812, loss 0.597782.
Train: 2018-08-01T01:12:17.806607: step 20813, loss 0.499453.
Train: 2018-08-01T01:12:17.962820: step 20814, loss 0.579879.
Train: 2018-08-01T01:12:18.150277: step 20815, loss 0.480416.
Train: 2018-08-01T01:12:18.306484: step 20816, loss 0.547957.
Train: 2018-08-01T01:12:18.462704: step 20817, loss 0.513496.
Train: 2018-08-01T01:12:18.618916: step 20818, loss 0.512273.
Train: 2018-08-01T01:12:18.775130: step 20819, loss 0.613766.
Train: 2018-08-01T01:12:18.931313: step 20820, loss 0.612646.
Test: 2018-08-01T01:12:19.399984: step 20820, loss 0.548334.
Train: 2018-08-01T01:12:19.556192: step 20821, loss 0.545501.
Train: 2018-08-01T01:12:19.712411: step 20822, loss 0.630886.
Train: 2018-08-01T01:12:19.868624: step 20823, loss 0.629874.
Train: 2018-08-01T01:12:20.040429: step 20824, loss 0.596784.
Train: 2018-08-01T01:12:20.196667: step 20825, loss 0.544785.
Train: 2018-08-01T01:12:20.352886: step 20826, loss 0.561859.
Train: 2018-08-01T01:12:20.509099: step 20827, loss 0.614824.
Train: 2018-08-01T01:12:20.680903: step 20828, loss 0.545893.
Train: 2018-08-01T01:12:20.837148: step 20829, loss 0.679547.
Train: 2018-08-01T01:12:20.993331: step 20830, loss 0.629285.
Test: 2018-08-01T01:12:21.461971: step 20830, loss 0.548492.
Train: 2018-08-01T01:12:21.618184: step 20831, loss 0.730162.
Train: 2018-08-01T01:12:21.774398: step 20832, loss 0.5092.
Train: 2018-08-01T01:12:21.930644: step 20833, loss 0.56378.
Train: 2018-08-01T01:12:22.102476: step 20834, loss 0.478608.
Train: 2018-08-01T01:12:22.258689: step 20835, loss 0.485007.
Train: 2018-08-01T01:12:22.414873: step 20836, loss 0.527535.
Train: 2018-08-01T01:12:22.571119: step 20837, loss 0.483711.
Train: 2018-08-01T01:12:22.727330: step 20838, loss 0.626177.
Train: 2018-08-01T01:12:22.883513: step 20839, loss 0.495413.
Train: 2018-08-01T01:12:23.039757: step 20840, loss 0.57992.
Test: 2018-08-01T01:12:23.523989: step 20840, loss 0.548861.
Train: 2018-08-01T01:12:23.680234: step 20841, loss 0.530746.
Train: 2018-08-01T01:12:23.836414: step 20842, loss 0.595048.
Train: 2018-08-01T01:12:23.992658: step 20843, loss 0.5625.
Train: 2018-08-01T01:12:24.148842: step 20844, loss 0.514551.
Train: 2018-08-01T01:12:24.305055: step 20845, loss 0.613865.
Train: 2018-08-01T01:12:24.461299: step 20846, loss 0.530738.
Train: 2018-08-01T01:12:24.633103: step 20847, loss 0.57849.
Train: 2018-08-01T01:12:24.789347: step 20848, loss 0.513521.
Train: 2018-08-01T01:12:24.929947: step 20849, loss 0.52952.
Train: 2018-08-01T01:12:25.101744: step 20850, loss 0.666085.
Test: 2018-08-01T01:12:25.570408: step 20850, loss 0.548068.
Train: 2018-08-01T01:12:25.742220: step 20851, loss 0.595286.
Train: 2018-08-01T01:12:25.898432: step 20852, loss 0.476431.
Train: 2018-08-01T01:12:26.054646: step 20853, loss 0.561884.
Train: 2018-08-01T01:12:26.210890: step 20854, loss 0.596447.
Train: 2018-08-01T01:12:26.382693: step 20855, loss 0.648607.
Train: 2018-08-01T01:12:26.538937: step 20856, loss 0.510052.
Train: 2018-08-01T01:12:26.695121: step 20857, loss 0.614056.
Train: 2018-08-01T01:12:26.866955: step 20858, loss 0.579668.
Train: 2018-08-01T01:12:27.007578: step 20859, loss 0.614158.
Train: 2018-08-01T01:12:27.163785: step 20860, loss 0.442947.
Test: 2018-08-01T01:12:27.632431: step 20860, loss 0.548068.
Train: 2018-08-01T01:12:27.788644: step 20861, loss 0.57991.
Train: 2018-08-01T01:12:27.960449: step 20862, loss 0.579142.
Train: 2018-08-01T01:12:28.116663: step 20863, loss 0.509889.
Train: 2018-08-01T01:12:28.272878: step 20864, loss 0.545917.
Train: 2018-08-01T01:12:28.429089: step 20865, loss 0.424004.
Train: 2018-08-01T01:12:28.585332: step 20866, loss 0.562708.
Train: 2018-08-01T01:12:28.757138: step 20867, loss 0.52774.
Train: 2018-08-01T01:12:28.913350: step 20868, loss 0.684533.
Train: 2018-08-01T01:12:29.085221: step 20869, loss 0.562145.
Train: 2018-08-01T01:12:29.241400: step 20870, loss 0.563316.
Test: 2018-08-01T01:12:29.710069: step 20870, loss 0.547937.
Train: 2018-08-01T01:12:29.866253: step 20871, loss 0.579606.
Train: 2018-08-01T01:12:30.022499: step 20872, loss 0.578956.
Train: 2018-08-01T01:12:30.209953: step 20873, loss 0.527696.
Train: 2018-08-01T01:12:30.366136: step 20874, loss 0.510115.
Train: 2018-08-01T01:12:30.522349: step 20875, loss 0.649302.
Train: 2018-08-01T01:12:30.678562: step 20876, loss 0.59729.
Train: 2018-08-01T01:12:30.834806: step 20877, loss 0.562332.
Train: 2018-08-01T01:12:30.991020: step 20878, loss 0.685186.
Train: 2018-08-01T01:12:31.147229: step 20879, loss 0.526995.
Train: 2018-08-01T01:12:31.319038: step 20880, loss 0.493107.
Test: 2018-08-01T01:12:31.787678: step 20880, loss 0.548054.
Train: 2018-08-01T01:12:31.959512: step 20881, loss 0.458264.
Train: 2018-08-01T01:12:32.115756: step 20882, loss 0.596629.
Train: 2018-08-01T01:12:32.271970: step 20883, loss 0.613211.
Train: 2018-08-01T01:12:32.443807: step 20884, loss 0.561483.
Train: 2018-08-01T01:12:32.600018: step 20885, loss 0.527682.
Train: 2018-08-01T01:12:32.756202: step 20886, loss 0.596896.
Train: 2018-08-01T01:12:32.912439: step 20887, loss 0.529174.
Train: 2018-08-01T01:12:33.068660: step 20888, loss 0.493817.
Train: 2018-08-01T01:12:33.224871: step 20889, loss 0.578534.
Train: 2018-08-01T01:12:33.396676: step 20890, loss 0.530367.
Test: 2018-08-01T01:12:33.880968: step 20890, loss 0.548115.
Train: 2018-08-01T01:12:34.037151: step 20891, loss 0.647404.
Train: 2018-08-01T01:12:34.193397: step 20892, loss 0.578831.
Train: 2018-08-01T01:12:34.349607: step 20893, loss 0.477308.
Train: 2018-08-01T01:12:34.505816: step 20894, loss 0.425693.
Train: 2018-08-01T01:12:34.662029: step 20895, loss 0.612029.
Train: 2018-08-01T01:12:34.818243: step 20896, loss 0.59834.
Train: 2018-08-01T01:12:34.990077: step 20897, loss 0.494025.
Train: 2018-08-01T01:12:35.146297: step 20898, loss 0.44227.
Train: 2018-08-01T01:12:35.302512: step 20899, loss 0.68209.
Train: 2018-08-01T01:12:35.458724: step 20900, loss 0.614684.
Test: 2018-08-01T01:12:35.927366: step 20900, loss 0.547917.
Train: 2018-08-01T01:12:36.645947: step 20901, loss 0.510064.
Train: 2018-08-01T01:12:36.833372: step 20902, loss 0.508835.
Train: 2018-08-01T01:12:36.989585: step 20903, loss 0.545614.
Train: 2018-08-01T01:12:37.145823: step 20904, loss 0.543742.
Train: 2018-08-01T01:12:37.286391: step 20905, loss 0.527427.
Train: 2018-08-01T01:12:37.458225: step 20906, loss 0.545161.
Train: 2018-08-01T01:12:37.614468: step 20907, loss 0.564989.
Train: 2018-08-01T01:12:37.770653: step 20908, loss 0.545745.
Train: 2018-08-01T01:12:37.942487: step 20909, loss 0.598303.
Train: 2018-08-01T01:12:38.098731: step 20910, loss 0.385065.
Test: 2018-08-01T01:12:38.567372: step 20910, loss 0.547734.
Train: 2018-08-01T01:12:38.723554: step 20911, loss 0.57973.
Train: 2018-08-01T01:12:38.895388: step 20912, loss 0.455434.
Train: 2018-08-01T01:12:39.051602: step 20913, loss 0.509756.
Train: 2018-08-01T01:12:39.207848: step 20914, loss 0.562915.
Train: 2018-08-01T01:12:39.364058: step 20915, loss 0.509153.
Train: 2018-08-01T01:12:39.520243: step 20916, loss 0.580872.
Train: 2018-08-01T01:12:39.676485: step 20917, loss 0.581066.
Train: 2018-08-01T01:12:39.832699: step 20918, loss 0.708881.
Train: 2018-08-01T01:12:40.004505: step 20919, loss 0.508317.
Train: 2018-08-01T01:12:40.145097: step 20920, loss 0.562505.
Test: 2018-08-01T01:12:40.629387: step 20920, loss 0.547626.
Train: 2018-08-01T01:12:40.785601: step 20921, loss 0.690643.
Train: 2018-08-01T01:12:40.941783: step 20922, loss 0.562979.
Train: 2018-08-01T01:12:41.098025: step 20923, loss 0.563018.
Train: 2018-08-01T01:12:41.254241: step 20924, loss 0.599151.
Train: 2018-08-01T01:12:41.410424: step 20925, loss 0.580944.
Train: 2018-08-01T01:12:41.582289: step 20926, loss 0.670884.
Train: 2018-08-01T01:12:41.738503: step 20927, loss 0.562447.
Train: 2018-08-01T01:12:41.894687: step 20928, loss 0.580517.
Train: 2018-08-01T01:12:42.050899: step 20929, loss 0.509079.
Train: 2018-08-01T01:12:42.222736: step 20930, loss 0.509232.
Test: 2018-08-01T01:12:42.691407: step 20930, loss 0.547704.
Train: 2018-08-01T01:12:42.847617: step 20931, loss 0.526954.
Train: 2018-08-01T01:12:43.019422: step 20932, loss 0.615766.
Train: 2018-08-01T01:12:43.175666: step 20933, loss 0.562789.
Train: 2018-08-01T01:12:43.363116: step 20934, loss 0.492043.
Train: 2018-08-01T01:12:43.503714: step 20935, loss 0.509472.
Train: 2018-08-01T01:12:43.675549: step 20936, loss 0.615427.
Train: 2018-08-01T01:12:43.831732: step 20937, loss 0.633489.
Train: 2018-08-01T01:12:43.987945: step 20938, loss 0.562648.
Train: 2018-08-01T01:12:44.144160: step 20939, loss 0.421357.
Train: 2018-08-01T01:12:44.300402: step 20940, loss 0.615783.
Test: 2018-08-01T01:12:44.769042: step 20940, loss 0.547777.
Train: 2018-08-01T01:12:44.925259: step 20941, loss 0.562567.
Train: 2018-08-01T01:12:45.097091: step 20942, loss 0.509879.
Train: 2018-08-01T01:12:45.253305: step 20943, loss 0.650848.
Train: 2018-08-01T01:12:45.409518: step 20944, loss 0.545007.
Train: 2018-08-01T01:12:45.581323: step 20945, loss 0.580135.
Train: 2018-08-01T01:12:45.753188: step 20946, loss 0.685517.
Train: 2018-08-01T01:12:45.909396: step 20947, loss 0.56284.
Train: 2018-08-01T01:12:46.065619: step 20948, loss 0.632626.
Train: 2018-08-01T01:12:46.221828: step 20949, loss 0.57998.
Train: 2018-08-01T01:12:46.393663: step 20950, loss 0.440869.
Test: 2018-08-01T01:12:46.862302: step 20950, loss 0.547922.
Train: 2018-08-01T01:12:47.018486: step 20951, loss 0.510309.
Train: 2018-08-01T01:12:47.174729: step 20952, loss 0.614494.
Train: 2018-08-01T01:12:47.330944: step 20953, loss 0.510496.
Train: 2018-08-01T01:12:47.502778: step 20954, loss 0.649156.
Train: 2018-08-01T01:12:47.658962: step 20955, loss 0.527897.
Train: 2018-08-01T01:12:47.830826: step 20956, loss 0.579795.
Train: 2018-08-01T01:12:47.987010: step 20957, loss 0.614364.
Train: 2018-08-01T01:12:48.143223: step 20958, loss 0.562438.
Train: 2018-08-01T01:12:48.299436: step 20959, loss 0.579668.
Train: 2018-08-01T01:12:48.455680: step 20960, loss 0.459148.
Test: 2018-08-01T01:12:48.924319: step 20960, loss 0.54804.
Train: 2018-08-01T01:12:49.143022: step 20961, loss 0.54529.
Train: 2018-08-01T01:12:49.299235: step 20962, loss 0.545168.
Train: 2018-08-01T01:12:49.455439: step 20963, loss 0.562471.
Train: 2018-08-01T01:12:49.611659: step 20964, loss 0.648503.
Train: 2018-08-01T01:12:49.767873: step 20965, loss 0.562437.
Train: 2018-08-01T01:12:49.955323: step 20966, loss 0.596873.
Train: 2018-08-01T01:12:50.095890: step 20967, loss 0.493789.
Train: 2018-08-01T01:12:50.252134: step 20968, loss 0.54536.
Train: 2018-08-01T01:12:50.423938: step 20969, loss 0.631145.
Train: 2018-08-01T01:12:50.580186: step 20970, loss 0.493823.
Test: 2018-08-01T01:12:51.048825: step 20970, loss 0.548073.
Train: 2018-08-01T01:12:51.205006: step 20971, loss 0.596805.
Train: 2018-08-01T01:12:51.361219: step 20972, loss 0.545213.
Train: 2018-08-01T01:12:51.517433: step 20973, loss 0.545272.
Train: 2018-08-01T01:12:51.673645: step 20974, loss 0.51097.
Train: 2018-08-01T01:12:51.829889: step 20975, loss 0.528104.
Train: 2018-08-01T01:12:51.986103: step 20976, loss 0.407688.
Train: 2018-08-01T01:12:52.173553: step 20977, loss 0.545219.
Train: 2018-08-01T01:12:52.329772: step 20978, loss 0.562445.
Train: 2018-08-01T01:12:52.470364: step 20979, loss 0.666577.
Train: 2018-08-01T01:12:52.626578: step 20980, loss 0.63194.
Test: 2018-08-01T01:12:53.110843: step 20980, loss 0.547914.
Train: 2018-08-01T01:12:53.282683: step 20981, loss 0.562455.
Train: 2018-08-01T01:12:53.438895: step 20982, loss 0.492986.
Train: 2018-08-01T01:12:53.595072: step 20983, loss 0.649382.
Train: 2018-08-01T01:12:53.766938: step 20984, loss 0.666718.
Train: 2018-08-01T01:12:53.923152: step 20985, loss 0.545108.
Train: 2018-08-01T01:12:54.079363: step 20986, loss 0.45852.
Train: 2018-08-01T01:12:54.266790: step 20987, loss 0.510484.
Train: 2018-08-01T01:12:54.423035: step 20988, loss 0.527781.
Train: 2018-08-01T01:12:54.579216: step 20989, loss 0.579809.
Train: 2018-08-01T01:12:54.719839: step 20990, loss 0.631919.
Test: 2018-08-01T01:12:55.204093: step 20990, loss 0.547919.
Train: 2018-08-01T01:12:55.375905: step 20991, loss 0.475656.
Train: 2018-08-01T01:12:55.516496: step 20992, loss 0.545083.
Train: 2018-08-01T01:12:55.672734: step 20993, loss 0.614628.
Train: 2018-08-01T01:12:55.844569: step 20994, loss 0.562453.
Train: 2018-08-01T01:12:56.000783: step 20995, loss 0.597249.
Train: 2018-08-01T01:12:56.157009: step 20996, loss 0.423382.
Train: 2018-08-01T01:12:56.313217: step 20997, loss 0.527638.
Train: 2018-08-01T01:12:56.469398: step 20998, loss 0.527585.
Train: 2018-08-01T01:12:56.625641: step 20999, loss 0.510064.
Train: 2018-08-01T01:12:56.797445: step 21000, loss 0.597532.
Test: 2018-08-01T01:12:57.266116: step 21000, loss 0.547808.
Train: 2018-08-01T01:12:58.047154: step 21001, loss 0.457273.
Train: 2018-08-01T01:12:58.219018: step 21002, loss 0.562508.
Train: 2018-08-01T01:12:58.375232: step 21003, loss 0.562546.
Train: 2018-08-01T01:12:58.531445: step 21004, loss 0.580199.
Train: 2018-08-01T01:12:58.703250: step 21005, loss 0.509469.
Train: 2018-08-01T01:12:58.859464: step 21006, loss 0.668861.
Train: 2018-08-01T01:12:59.031329: step 21007, loss 0.509371.
Train: 2018-08-01T01:12:59.187544: step 21008, loss 0.598048.
Train: 2018-08-01T01:12:59.343724: step 21009, loss 0.45609.
Train: 2018-08-01T01:12:59.515560: step 21010, loss 0.615919.
Test: 2018-08-01T01:12:59.984230: step 21010, loss 0.547697.
Train: 2018-08-01T01:13:00.156034: step 21011, loss 0.580372.
Train: 2018-08-01T01:13:00.312248: step 21012, loss 0.580372.
Train: 2018-08-01T01:13:00.468492: step 21013, loss 0.509229.
Train: 2018-08-01T01:13:00.624706: step 21014, loss 0.598146.
Train: 2018-08-01T01:13:00.796543: step 21015, loss 0.615935.
Train: 2018-08-01T01:13:00.968374: step 21016, loss 0.43825.
Train: 2018-08-01T01:13:01.124588: step 21017, loss 0.615924.
Train: 2018-08-01T01:13:01.296426: step 21018, loss 0.598128.
Train: 2018-08-01T01:13:01.452636: step 21019, loss 0.615875.
Train: 2018-08-01T01:13:01.608850: step 21020, loss 0.615736.
Test: 2018-08-01T01:13:02.077460: step 21020, loss 0.547729.
Train: 2018-08-01T01:13:02.249294: step 21021, loss 0.580208.
Train: 2018-08-01T01:13:02.405538: step 21022, loss 0.562546.
Train: 2018-08-01T01:13:02.561754: step 21023, loss 0.562535.
Train: 2018-08-01T01:13:02.717965: step 21024, loss 0.544917.
Train: 2018-08-01T01:13:02.874179: step 21025, loss 0.509823.
Train: 2018-08-01T01:13:03.045983: step 21026, loss 0.562497.
Train: 2018-08-01T01:13:03.202227: step 21027, loss 0.527424.
Train: 2018-08-01T01:13:03.358439: step 21028, loss 0.474886.
Train: 2018-08-01T01:13:03.514654: step 21029, loss 0.509896.
Train: 2018-08-01T01:13:03.670869: step 21030, loss 0.457162.
Test: 2018-08-01T01:13:04.155128: step 21030, loss 0.547772.
Train: 2018-08-01T01:13:04.311345: step 21031, loss 0.615315.
Train: 2018-08-01T01:13:04.483177: step 21032, loss 0.527266.
Train: 2018-08-01T01:13:04.639359: step 21033, loss 0.580181.
Train: 2018-08-01T01:13:04.795606: step 21034, loss 0.580203.
Train: 2018-08-01T01:13:04.951787: step 21035, loss 0.562546.
Train: 2018-08-01T01:13:05.108031: step 21036, loss 0.47406.
Train: 2018-08-01T01:13:05.279834: step 21037, loss 0.473944.
Train: 2018-08-01T01:13:05.420457: step 21038, loss 0.544804.
Train: 2018-08-01T01:13:05.576670: step 21039, loss 0.526976.
Train: 2018-08-01T01:13:05.732853: step 21040, loss 0.669697.
Test: 2018-08-01T01:13:06.217115: step 21040, loss 0.547666.
Train: 2018-08-01T01:13:06.404596: step 21041, loss 0.50903.
Train: 2018-08-01T01:13:06.560817: step 21042, loss 0.580521.
Train: 2018-08-01T01:13:06.717028: step 21043, loss 0.526844.
Train: 2018-08-01T01:13:06.873247: step 21044, loss 0.544726.
Train: 2018-08-01T01:13:07.029456: step 21045, loss 0.580597.
Train: 2018-08-01T01:13:07.185638: step 21046, loss 0.455039.
Train: 2018-08-01T01:13:07.341892: step 21047, loss 0.616595.
Train: 2018-08-01T01:13:07.513722: step 21048, loss 0.544677.
Train: 2018-08-01T01:13:07.669900: step 21049, loss 0.544719.
Train: 2018-08-01T01:13:07.826144: step 21050, loss 0.634709.
Test: 2018-08-01T01:13:08.294784: step 21050, loss 0.547631.
Train: 2018-08-01T01:13:08.451000: step 21051, loss 0.616675.
Train: 2018-08-01T01:13:08.622803: step 21052, loss 0.544716.
Train: 2018-08-01T01:13:08.779016: step 21053, loss 0.706464.
Train: 2018-08-01T01:13:08.935261: step 21054, loss 0.50892.
Train: 2018-08-01T01:13:09.091443: step 21055, loss 0.616283.
Train: 2018-08-01T01:13:09.247656: step 21056, loss 0.65179.
Train: 2018-08-01T01:13:09.403868: step 21057, loss 0.544801.
Train: 2018-08-01T01:13:09.575739: step 21058, loss 0.615707.
Train: 2018-08-01T01:13:09.731942: step 21059, loss 0.650798.
Train: 2018-08-01T01:13:09.888161: step 21060, loss 0.63281.
Test: 2018-08-01T01:13:10.356801: step 21060, loss 0.547827.
Train: 2018-08-01T01:13:10.512984: step 21061, loss 0.562476.
Train: 2018-08-01T01:13:10.684846: step 21062, loss 0.57987.
Train: 2018-08-01T01:13:10.841069: step 21063, loss 0.614457.
Train: 2018-08-01T01:13:10.997246: step 21064, loss 0.51066.
Train: 2018-08-01T01:13:11.153459: step 21065, loss 0.510844.
Train: 2018-08-01T01:13:11.309697: step 21066, loss 0.579585.
Train: 2018-08-01T01:13:11.465886: step 21067, loss 0.528214.
Train: 2018-08-01T01:13:11.622129: step 21068, loss 0.494106.
Train: 2018-08-01T01:13:11.778345: step 21069, loss 0.511222.
Train: 2018-08-01T01:13:11.950183: step 21070, loss 0.580651.
Test: 2018-08-01T01:13:12.418788: step 21070, loss 0.548139.
Train: 2018-08-01T01:13:12.590653: step 21071, loss 0.579506.
Train: 2018-08-01T01:13:12.746866: step 21072, loss 0.579501.
Train: 2018-08-01T01:13:12.918672: step 21073, loss 0.664771.
Train: 2018-08-01T01:13:13.074885: step 21074, loss 0.579464.
Train: 2018-08-01T01:13:13.231098: step 21075, loss 0.630417.
Train: 2018-08-01T01:13:13.387341: step 21076, loss 0.528545.
Train: 2018-08-01T01:13:13.543525: step 21077, loss 0.52861.
Train: 2018-08-01T01:13:13.699738: step 21078, loss 0.461046.
Train: 2018-08-01T01:13:13.855982: step 21079, loss 0.562457.
Train: 2018-08-01T01:13:14.043432: step 21080, loss 0.545537.
Test: 2018-08-01T01:13:14.527699: step 21080, loss 0.548277.
Train: 2018-08-01T01:13:14.683916: step 21081, loss 0.477818.
Train: 2018-08-01T01:13:14.840096: step 21082, loss 0.494621.
Train: 2018-08-01T01:13:14.996341: step 21083, loss 0.52844.
Train: 2018-08-01T01:13:15.183798: step 21084, loss 0.596531.
Train: 2018-08-01T01:13:15.339979: step 21085, loss 0.54535.
Train: 2018-08-01T01:13:15.496193: step 21086, loss 0.613786.
Train: 2018-08-01T01:13:15.652436: step 21087, loss 0.408181.
Train: 2018-08-01T01:13:15.808619: step 21088, loss 0.528046.
Train: 2018-08-01T01:13:15.980453: step 21089, loss 0.49344.
Train: 2018-08-01T01:13:16.136686: step 21090, loss 0.579753.
Test: 2018-08-01T01:13:16.605332: step 21090, loss 0.547902.
Train: 2018-08-01T01:13:16.761551: step 21091, loss 0.597184.
Train: 2018-08-01T01:13:16.917764: step 21092, loss 0.510225.
Train: 2018-08-01T01:13:17.073978: step 21093, loss 0.492635.
Train: 2018-08-01T01:13:17.230191: step 21094, loss 0.527448.
Train: 2018-08-01T01:13:17.402020: step 21095, loss 0.544921.
Train: 2018-08-01T01:13:17.558211: step 21096, loss 0.439111.
Train: 2018-08-01T01:13:17.714422: step 21097, loss 0.544838.
Train: 2018-08-01T01:13:17.870661: step 21098, loss 0.509248.
Train: 2018-08-01T01:13:18.026880: step 21099, loss 0.598307.
Train: 2018-08-01T01:13:18.183063: step 21100, loss 0.491022.
Test: 2018-08-01T01:13:18.667355: step 21100, loss 0.547632.
Train: 2018-08-01T01:13:19.385937: step 21101, loss 0.598616.
Train: 2018-08-01T01:13:19.573363: step 21102, loss 0.580724.
Train: 2018-08-01T01:13:19.713986: step 21103, loss 0.562732.
Train: 2018-08-01T01:13:19.870167: step 21104, loss 0.580835.
Train: 2018-08-01T01:13:20.026412: step 21105, loss 0.490358.
Train: 2018-08-01T01:13:20.198247: step 21106, loss 0.653456.
Train: 2018-08-01T01:13:20.354460: step 21107, loss 0.562794.
Train: 2018-08-01T01:13:20.510644: step 21108, loss 0.599077.
Train: 2018-08-01T01:13:20.698099: step 21109, loss 0.544656.
Train: 2018-08-01T01:13:20.854313: step 21110, loss 0.562783.
Test: 2018-08-01T01:13:21.322982: step 21110, loss 0.547606.
Train: 2018-08-01T01:13:21.479196: step 21111, loss 0.435964.
Train: 2018-08-01T01:13:21.651001: step 21112, loss 0.580921.
Train: 2018-08-01T01:13:21.807247: step 21113, loss 0.508373.
Train: 2018-08-01T01:13:21.963428: step 21114, loss 0.526493.
Train: 2018-08-01T01:13:22.104050: step 21115, loss 0.599171.
Train: 2018-08-01T01:13:22.275855: step 21116, loss 0.581007.
Train: 2018-08-01T01:13:22.432068: step 21117, loss 0.508282.
Train: 2018-08-01T01:13:22.588281: step 21118, loss 0.599207.
Train: 2018-08-01T01:13:22.744533: step 21119, loss 0.617381.
Train: 2018-08-01T01:13:22.900708: step 21120, loss 0.653644.
Test: 2018-08-01T01:13:23.384971: step 21120, loss 0.547604.
Train: 2018-08-01T01:13:23.541183: step 21121, loss 0.58091.
Train: 2018-08-01T01:13:23.697396: step 21122, loss 0.472328.
Train: 2018-08-01T01:13:23.853645: step 21123, loss 0.508546.
Train: 2018-08-01T01:13:24.025475: step 21124, loss 0.544677.
Train: 2018-08-01T01:13:24.166038: step 21125, loss 0.65296.
Train: 2018-08-01T01:13:24.322280: step 21126, loss 0.634778.
Train: 2018-08-01T01:13:24.478494: step 21127, loss 0.724439.
Train: 2018-08-01T01:13:24.634678: step 21128, loss 0.616321.
Train: 2018-08-01T01:13:24.790923: step 21129, loss 0.473526.
Train: 2018-08-01T01:13:24.978348: step 21130, loss 0.633581.
Test: 2018-08-01T01:13:25.462607: step 21130, loss 0.547722.
Train: 2018-08-01T01:13:25.618855: step 21131, loss 0.456416.
Train: 2018-08-01T01:13:25.775066: step 21132, loss 0.54487.
Train: 2018-08-01T01:13:25.931281: step 21133, loss 0.562503.
Train: 2018-08-01T01:13:26.087498: step 21134, loss 0.457015.
Train: 2018-08-01T01:13:26.243712: step 21135, loss 0.597637.
Train: 2018-08-01T01:13:26.399920: step 21136, loss 0.562486.
Train: 2018-08-01T01:13:26.556140: step 21137, loss 0.615112.
Train: 2018-08-01T01:13:26.712346: step 21138, loss 0.650061.
Train: 2018-08-01T01:13:26.884181: step 21139, loss 0.457622.
Train: 2018-08-01T01:13:27.040365: step 21140, loss 0.510089.
Test: 2018-08-01T01:13:27.509034: step 21140, loss 0.547843.
Train: 2018-08-01T01:13:27.665248: step 21141, loss 0.59736.
Train: 2018-08-01T01:13:27.821430: step 21142, loss 0.562454.
Train: 2018-08-01T01:13:27.977644: step 21143, loss 0.545025.
Train: 2018-08-01T01:13:28.133888: step 21144, loss 0.66696.
Train: 2018-08-01T01:13:28.290117: step 21145, loss 0.562444.
Train: 2018-08-01T01:13:28.446285: step 21146, loss 0.579797.
Train: 2018-08-01T01:13:28.602498: step 21147, loss 0.52778.
Train: 2018-08-01T01:13:28.758742: step 21148, loss 0.579739.
Train: 2018-08-01T01:13:28.930574: step 21149, loss 0.562429.
Train: 2018-08-01T01:13:29.086760: step 21150, loss 0.545164.
Test: 2018-08-01T01:13:29.555400: step 21150, loss 0.547982.
Train: 2018-08-01T01:13:29.711643: step 21151, loss 0.493431.
Train: 2018-08-01T01:13:29.867827: step 21152, loss 0.545176.
Train: 2018-08-01T01:13:30.024070: step 21153, loss 0.527915.
Train: 2018-08-01T01:13:30.180279: step 21154, loss 0.510624.
Train: 2018-08-01T01:13:30.336497: step 21155, loss 0.545139.
Train: 2018-08-01T01:13:30.492681: step 21156, loss 0.700945.
Train: 2018-08-01T01:13:30.648894: step 21157, loss 0.597038.
Train: 2018-08-01T01:13:30.805108: step 21158, loss 0.631573.
Train: 2018-08-01T01:13:30.961351: step 21159, loss 0.527918.
Train: 2018-08-01T01:13:31.117565: step 21160, loss 0.59689.
Test: 2018-08-01T01:13:31.601826: step 21160, loss 0.548015.
Train: 2018-08-01T01:13:31.758040: step 21161, loss 0.528011.
Train: 2018-08-01T01:13:31.914223: step 21162, loss 0.5968.
Train: 2018-08-01T01:13:32.070467: step 21163, loss 0.579588.
Train: 2018-08-01T01:13:32.226680: step 21164, loss 0.648129.
Train: 2018-08-01T01:13:32.382894: step 21165, loss 0.511124.
Train: 2018-08-01T01:13:32.539107: step 21166, loss 0.596572.
Train: 2018-08-01T01:13:32.726535: step 21167, loss 0.613557.
Train: 2018-08-01T01:13:32.882746: step 21168, loss 0.613444.
Train: 2018-08-01T01:13:33.054606: step 21169, loss 0.732017.
Train: 2018-08-01T01:13:33.210824: step 21170, loss 0.562451.
Test: 2018-08-01T01:13:33.679434: step 21170, loss 0.548395.
Train: 2018-08-01T01:13:33.851269: step 21171, loss 0.562469.
Train: 2018-08-01T01:13:34.007514: step 21172, loss 0.529.
Train: 2018-08-01T01:13:34.163696: step 21173, loss 0.545807.
Train: 2018-08-01T01:13:34.319940: step 21174, loss 0.62915.
Train: 2018-08-01T01:13:34.476123: step 21175, loss 0.545926.
Train: 2018-08-01T01:13:34.632336: step 21176, loss 0.61227.
Train: 2018-08-01T01:13:34.788580: step 21177, loss 0.546045.
Train: 2018-08-01T01:13:34.960385: step 21178, loss 0.480116.
Train: 2018-08-01T01:13:35.132249: step 21179, loss 0.694484.
Train: 2018-08-01T01:13:35.288462: step 21180, loss 0.513267.
Test: 2018-08-01T01:13:35.772741: step 21180, loss 0.548867.
Train: 2018-08-01T01:13:35.928909: step 21181, loss 0.480477.
Train: 2018-08-01T01:13:36.100743: step 21182, loss 0.529755.
Train: 2018-08-01T01:13:36.256986: step 21183, loss 0.496825.
Train: 2018-08-01T01:13:36.413170: step 21184, loss 0.595554.
Train: 2018-08-01T01:13:36.569413: step 21185, loss 0.595586.
Train: 2018-08-01T01:13:36.725595: step 21186, loss 0.612119.
Train: 2018-08-01T01:13:36.881840: step 21187, loss 0.546065.
Train: 2018-08-01T01:13:37.053674: step 21188, loss 0.496484.
Train: 2018-08-01T01:13:37.209857: step 21189, loss 0.397087.
Train: 2018-08-01T01:13:37.366071: step 21190, loss 0.71203.
Test: 2018-08-01T01:13:37.834741: step 21190, loss 0.548597.
Train: 2018-08-01T01:13:37.990924: step 21191, loss 0.529258.
Train: 2018-08-01T01:13:38.162760: step 21192, loss 0.562514.
Train: 2018-08-01T01:13:38.303376: step 21193, loss 0.595888.
Train: 2018-08-01T01:13:38.459595: step 21194, loss 0.712906.
Train: 2018-08-01T01:13:38.615803: step 21195, loss 0.645982.
Train: 2018-08-01T01:13:38.772022: step 21196, loss 0.562514.
Train: 2018-08-01T01:13:38.928238: step 21197, loss 0.562524.
Train: 2018-08-01T01:13:39.084449: step 21198, loss 0.612371.
Train: 2018-08-01T01:13:39.256284: step 21199, loss 0.479641.
Train: 2018-08-01T01:13:39.412499: step 21200, loss 0.479679.
Test: 2018-08-01T01:13:39.881137: step 21200, loss 0.548652.
Train: 2018-08-01T01:13:40.615309: step 21201, loss 0.612312.
Train: 2018-08-01T01:13:40.755902: step 21202, loss 0.612321.
Train: 2018-08-01T01:13:40.912145: step 21203, loss 0.595717.
Train: 2018-08-01T01:13:41.068359: step 21204, loss 0.645421.
Train: 2018-08-01T01:13:41.224573: step 21205, loss 0.6122.
Train: 2018-08-01T01:13:41.380786: step 21206, loss 0.562581.
Train: 2018-08-01T01:13:41.568237: step 21207, loss 0.562596.
Train: 2018-08-01T01:13:41.724455: step 21208, loss 0.546154.
Train: 2018-08-01T01:13:41.880669: step 21209, loss 0.529742.
Train: 2018-08-01T01:13:42.036876: step 21210, loss 0.562621.
Test: 2018-08-01T01:13:42.505527: step 21210, loss 0.548863.
Train: 2018-08-01T01:13:42.692948: step 21211, loss 0.546191.
Train: 2018-08-01T01:13:42.833572: step 21212, loss 0.56262.
Train: 2018-08-01T01:13:42.989784: step 21213, loss 0.562617.
Train: 2018-08-01T01:13:43.145998: step 21214, loss 0.529715.
Train: 2018-08-01T01:13:43.302182: step 21215, loss 0.562603.
Train: 2018-08-01T01:13:43.474046: step 21216, loss 0.645007.
Train: 2018-08-01T01:13:43.630258: step 21217, loss 0.546115.
Train: 2018-08-01T01:13:43.786442: step 21218, loss 0.595562.
Train: 2018-08-01T01:13:43.942686: step 21219, loss 0.546112.
Train: 2018-08-01T01:13:44.098894: step 21220, loss 0.496646.
Test: 2018-08-01T01:13:44.567539: step 21220, loss 0.548758.
Train: 2018-08-01T01:13:44.723725: step 21221, loss 0.546073.
Train: 2018-08-01T01:13:44.879967: step 21222, loss 0.562569.
Train: 2018-08-01T01:13:45.051772: step 21223, loss 0.628786.
Train: 2018-08-01T01:13:45.208014: step 21224, loss 0.579119.
Train: 2018-08-01T01:13:45.364197: step 21225, loss 0.628833.
Train: 2018-08-01T01:13:45.520411: step 21226, loss 0.446624.
Train: 2018-08-01T01:13:45.676658: step 21227, loss 0.562545.
Train: 2018-08-01T01:13:45.832838: step 21228, loss 0.41311.
Train: 2018-08-01T01:13:45.989076: step 21229, loss 0.495881.
Train: 2018-08-01T01:13:46.145264: step 21230, loss 0.56249.
Test: 2018-08-01T01:13:46.629557: step 21230, loss 0.548414.
Train: 2018-08-01T01:13:46.785741: step 21231, loss 0.528898.
Train: 2018-08-01T01:13:46.941953: step 21232, loss 0.545603.
Train: 2018-08-01T01:13:47.098166: step 21233, loss 0.460964.
Train: 2018-08-01T01:13:47.254380: step 21234, loss 0.545435.
Train: 2018-08-01T01:13:47.410627: step 21235, loss 0.613629.
Train: 2018-08-01T01:13:47.566837: step 21236, loss 0.47678.
Train: 2018-08-01T01:13:47.723050: step 21237, loss 0.52802.
Train: 2018-08-01T01:13:47.879264: step 21238, loss 0.527881.
Train: 2018-08-01T01:13:48.051108: step 21239, loss 0.493059.
Train: 2018-08-01T01:13:48.207282: step 21240, loss 0.614713.
Test: 2018-08-01T01:13:48.675955: step 21240, loss 0.547818.
Train: 2018-08-01T01:13:48.832167: step 21241, loss 0.684835.
Train: 2018-08-01T01:13:49.003995: step 21242, loss 0.527449.
Train: 2018-08-01T01:13:49.191451: step 21243, loss 0.527398.
Train: 2018-08-01T01:13:49.332019: step 21244, loss 0.562482.
Train: 2018-08-01T01:13:49.488263: step 21245, loss 0.59769.
Train: 2018-08-01T01:13:49.660073: step 21246, loss 0.615345.
Train: 2018-08-01T01:13:49.800692: step 21247, loss 0.509644.
Train: 2018-08-01T01:13:49.956903: step 21248, loss 0.509612.
Train: 2018-08-01T01:13:50.113117: step 21249, loss 0.686069.
Train: 2018-08-01T01:13:50.284946: step 21250, loss 0.580148.
Test: 2018-08-01T01:13:50.753561: step 21250, loss 0.54774.
Train: 2018-08-01T01:13:50.909804: step 21251, loss 0.580129.
Train: 2018-08-01T01:13:51.081609: step 21252, loss 0.720982.
Train: 2018-08-01T01:13:51.222232: step 21253, loss 0.580035.
Train: 2018-08-01T01:13:51.409657: step 21254, loss 0.614978.
Train: 2018-08-01T01:13:51.550274: step 21255, loss 0.597339.
Train: 2018-08-01T01:13:51.722083: step 21256, loss 0.475521.
Train: 2018-08-01T01:13:51.878298: step 21257, loss 0.493047.
Train: 2018-08-01T01:13:52.034544: step 21258, loss 0.631735.
Train: 2018-08-01T01:13:52.190725: step 21259, loss 0.614306.
Train: 2018-08-01T01:13:52.331347: step 21260, loss 0.614177.
Test: 2018-08-01T01:13:52.815608: step 21260, loss 0.548011.
Train: 2018-08-01T01:13:52.971822: step 21261, loss 0.545213.
Train: 2018-08-01T01:13:53.112383: step 21262, loss 0.579578.
Train: 2018-08-01T01:13:53.284218: step 21263, loss 0.545294.
Train: 2018-08-01T01:13:53.440432: step 21264, loss 0.49406.
Train: 2018-08-01T01:13:53.612267: step 21265, loss 0.59657.
Train: 2018-08-01T01:13:53.768505: step 21266, loss 0.528307.
Train: 2018-08-01T01:13:53.924718: step 21267, loss 0.596513.
Train: 2018-08-01T01:13:54.080937: step 21268, loss 0.545391.
Train: 2018-08-01T01:13:54.237121: step 21269, loss 0.528383.
Train: 2018-08-01T01:13:54.393334: step 21270, loss 0.528385.
Test: 2018-08-01T01:13:54.861972: step 21270, loss 0.548164.
Train: 2018-08-01T01:13:55.033841: step 21271, loss 0.579448.
Train: 2018-08-01T01:13:55.190052: step 21272, loss 0.59648.
Train: 2018-08-01T01:13:55.346266: step 21273, loss 0.63052.
Train: 2018-08-01T01:13:55.502479: step 21274, loss 0.579429.
Train: 2018-08-01T01:13:55.674285: step 21275, loss 0.49449.
Train: 2018-08-01T01:13:55.846118: step 21276, loss 0.562427.
Train: 2018-08-01T01:13:56.002332: step 21277, loss 0.460549.
Train: 2018-08-01T01:13:56.158570: step 21278, loss 0.528421.
Train: 2018-08-01T01:13:56.314759: step 21279, loss 0.647571.
Train: 2018-08-01T01:13:56.471002: step 21280, loss 0.494275.
Test: 2018-08-01T01:13:56.939612: step 21280, loss 0.548134.
Train: 2018-08-01T01:13:57.080234: step 21281, loss 0.494186.
Train: 2018-08-01T01:13:57.236448: step 21282, loss 0.545323.
Train: 2018-08-01T01:13:57.392663: step 21283, loss 0.511027.
Train: 2018-08-01T01:13:57.548869: step 21284, loss 0.562415.
Train: 2018-08-01T01:13:57.705088: step 21285, loss 0.631268.
Train: 2018-08-01T01:13:57.876893: step 21286, loss 0.562417.
Train: 2018-08-01T01:13:58.033106: step 21287, loss 0.476164.
Train: 2018-08-01T01:13:58.204942: step 21288, loss 0.64885.
Train: 2018-08-01T01:13:58.361184: step 21289, loss 0.545124.
Train: 2018-08-01T01:13:58.517368: step 21290, loss 0.666294.
Test: 2018-08-01T01:13:58.986009: step 21290, loss 0.547935.
Train: 2018-08-01T01:13:59.126633: step 21291, loss 0.562422.
Train: 2018-08-01T01:13:59.298468: step 21292, loss 0.614291.
Train: 2018-08-01T01:13:59.454681: step 21293, loss 0.562419.
Train: 2018-08-01T01:13:59.610863: step 21294, loss 0.562417.
Train: 2018-08-01T01:13:59.767106: step 21295, loss 0.665799.
Train: 2018-08-01T01:13:59.923321: step 21296, loss 0.562414.
Train: 2018-08-01T01:14:00.095124: step 21297, loss 0.579569.
Train: 2018-08-01T01:14:00.251367: step 21298, loss 0.562415.
Train: 2018-08-01T01:14:00.407550: step 21299, loss 0.494073.
Train: 2018-08-01T01:14:00.563763: step 21300, loss 0.681922.
Test: 2018-08-01T01:14:01.048058: step 21300, loss 0.548157.
Train: 2018-08-01T01:14:01.782259: step 21301, loss 0.460221.
Train: 2018-08-01T01:14:01.938472: step 21302, loss 0.477313.
Train: 2018-08-01T01:14:02.094685: step 21303, loss 0.477264.
Train: 2018-08-01T01:14:02.250898: step 21304, loss 0.579477.
Train: 2018-08-01T01:14:02.422728: step 21305, loss 0.562416.
Train: 2018-08-01T01:14:02.578947: step 21306, loss 0.494008.
Train: 2018-08-01T01:14:02.735160: step 21307, loss 0.596685.
Train: 2018-08-01T01:14:02.891373: step 21308, loss 0.442307.
Train: 2018-08-01T01:14:03.047556: step 21309, loss 0.45918.
Train: 2018-08-01T01:14:03.203770: step 21310, loss 0.614234.
Test: 2018-08-01T01:14:03.672411: step 21310, loss 0.547921.
Train: 2018-08-01T01:14:03.828654: step 21311, loss 0.6317.
Train: 2018-08-01T01:14:03.984862: step 21312, loss 0.527735.
Train: 2018-08-01T01:14:04.141051: step 21313, loss 0.579809.
Train: 2018-08-01T01:14:04.297303: step 21314, loss 0.597237.
Train: 2018-08-01T01:14:04.453478: step 21315, loss 0.545025.
Train: 2018-08-01T01:14:04.609691: step 21316, loss 0.510158.
Train: 2018-08-01T01:14:04.765905: step 21317, loss 0.544995.
Train: 2018-08-01T01:14:04.922119: step 21318, loss 0.562452.
Train: 2018-08-01T01:14:05.078331: step 21319, loss 0.54496.
Train: 2018-08-01T01:14:05.250197: step 21320, loss 0.650061.
Test: 2018-08-01T01:14:05.718836: step 21320, loss 0.547793.
Train: 2018-08-01T01:14:05.875025: step 21321, loss 0.562463.
Train: 2018-08-01T01:14:06.031263: step 21322, loss 0.667564.
Train: 2018-08-01T01:14:06.187447: step 21323, loss 0.544965.
Train: 2018-08-01T01:14:06.359306: step 21324, loss 0.579921.
Train: 2018-08-01T01:14:06.515525: step 21325, loss 0.579892.
Train: 2018-08-01T01:14:06.671742: step 21326, loss 0.562439.
Train: 2018-08-01T01:14:06.827922: step 21327, loss 0.492847.
Train: 2018-08-01T01:14:06.984160: step 21328, loss 0.614604.
Train: 2018-08-01T01:14:07.140350: step 21329, loss 0.527687.
Train: 2018-08-01T01:14:07.296594: step 21330, loss 0.545066.
Test: 2018-08-01T01:14:07.780824: step 21330, loss 0.547893.
Train: 2018-08-01T01:14:07.937038: step 21331, loss 0.527714.
Train: 2018-08-01T01:14:08.093251: step 21332, loss 0.45827.
Train: 2018-08-01T01:14:08.249494: step 21333, loss 0.527663.
Train: 2018-08-01T01:14:08.405710: step 21334, loss 0.632096.
Train: 2018-08-01T01:14:08.561921: step 21335, loss 0.475316.
Train: 2018-08-01T01:14:08.733726: step 21336, loss 0.579899.
Train: 2018-08-01T01:14:08.889938: step 21337, loss 0.492557.
Train: 2018-08-01T01:14:09.061799: step 21338, loss 0.474927.
Train: 2018-08-01T01:14:09.217986: step 21339, loss 0.615137.
Train: 2018-08-01T01:14:09.374200: step 21340, loss 0.544897.
Test: 2018-08-01T01:14:09.842841: step 21340, loss 0.547742.
Train: 2018-08-01T01:14:10.014700: step 21341, loss 0.544877.
Train: 2018-08-01T01:14:10.170889: step 21342, loss 0.527213.
Train: 2018-08-01T01:14:10.327102: step 21343, loss 0.491804.
Train: 2018-08-01T01:14:10.498938: step 21344, loss 0.456202.
Train: 2018-08-01T01:14:10.655180: step 21345, loss 0.562562.
Train: 2018-08-01T01:14:10.811395: step 21346, loss 0.526915.
Train: 2018-08-01T01:14:10.967608: step 21347, loss 0.616287.
Train: 2018-08-01T01:14:11.155033: step 21348, loss 0.544712.
Train: 2018-08-01T01:14:11.311247: step 21349, loss 0.616528.
Train: 2018-08-01T01:14:11.467461: step 21350, loss 0.52672.
Test: 2018-08-01T01:14:11.936132: step 21350, loss 0.547611.
Train: 2018-08-01T01:14:12.092340: step 21351, loss 0.652636.
Train: 2018-08-01T01:14:12.264148: step 21352, loss 0.634622.
Train: 2018-08-01T01:14:12.420362: step 21353, loss 0.616554.
Train: 2018-08-01T01:14:12.576605: step 21354, loss 0.706081.
Train: 2018-08-01T01:14:12.732819: step 21355, loss 0.49114.
Train: 2018-08-01T01:14:12.889002: step 21356, loss 0.616044.
Train: 2018-08-01T01:14:13.045241: step 21357, loss 0.580322.
Train: 2018-08-01T01:14:13.232672: step 21358, loss 0.509389.
Train: 2018-08-01T01:14:13.388885: step 21359, loss 0.562514.
Train: 2018-08-01T01:14:13.545109: step 21360, loss 0.615417.
Test: 2018-08-01T01:14:14.013769: step 21360, loss 0.547752.
Train: 2018-08-01T01:14:14.169952: step 21361, loss 0.580077.
Train: 2018-08-01T01:14:14.357439: step 21362, loss 0.544923.
Train: 2018-08-01T01:14:14.513660: step 21363, loss 0.527443.
Train: 2018-08-01T01:14:14.669860: step 21364, loss 0.614888.
Train: 2018-08-01T01:14:14.826049: step 21365, loss 0.667087.
Train: 2018-08-01T01:14:14.982262: step 21366, loss 0.510284.
Train: 2018-08-01T01:14:15.138505: step 21367, loss 0.545084.
Train: 2018-08-01T01:14:15.294721: step 21368, loss 0.545114.
Train: 2018-08-01T01:14:15.466523: step 21369, loss 0.579695.
Train: 2018-08-01T01:14:15.622761: step 21370, loss 0.545165.
Test: 2018-08-01T01:14:16.107028: step 21370, loss 0.547987.
Train: 2018-08-01T01:14:16.263242: step 21371, loss 0.599164.
Train: 2018-08-01T01:14:16.419450: step 21372, loss 0.493618.
Train: 2018-08-01T01:14:16.606881: step 21373, loss 0.579599.
Train: 2018-08-01T01:14:16.747498: step 21374, loss 0.562411.
Train: 2018-08-01T01:14:16.903717: step 21375, loss 0.545248.
Train: 2018-08-01T01:14:17.059931: step 21376, loss 0.596722.
Train: 2018-08-01T01:14:17.216144: step 21377, loss 0.596694.
Train: 2018-08-01T01:14:17.372358: step 21378, loss 0.630896.
Train: 2018-08-01T01:14:17.528571: step 21379, loss 0.630761.
Train: 2018-08-01T01:14:17.747271: step 21380, loss 0.613539.
Test: 2018-08-01T01:14:18.200259: step 21380, loss 0.548196.
Train: 2018-08-01T01:14:18.356503: step 21381, loss 0.681337.
Train: 2018-08-01T01:14:18.528344: step 21382, loss 0.562433.
Train: 2018-08-01T01:14:18.684557: step 21383, loss 0.612988.
Train: 2018-08-01T01:14:18.856355: step 21384, loss 0.54569.
Train: 2018-08-01T01:14:18.996947: step 21385, loss 0.579203.
Train: 2018-08-01T01:14:19.153161: step 21386, loss 0.545842.
Train: 2018-08-01T01:14:19.309404: step 21387, loss 0.429575.
Train: 2018-08-01T01:14:19.465586: step 21388, loss 0.545914.
Train: 2018-08-01T01:14:19.621830: step 21389, loss 0.512692.
Train: 2018-08-01T01:14:19.778014: step 21390, loss 0.529272.
Test: 2018-08-01T01:14:20.246655: step 21390, loss 0.548573.
Train: 2018-08-01T01:14:20.402898: step 21391, loss 0.529221.
Train: 2018-08-01T01:14:20.559113: step 21392, loss 0.495806.
Train: 2018-08-01T01:14:20.715295: step 21393, loss 0.445471.
Train: 2018-08-01T01:14:20.871510: step 21394, loss 0.679948.
Train: 2018-08-01T01:14:21.043342: step 21395, loss 0.512002.
Train: 2018-08-01T01:14:21.199556: step 21396, loss 0.596166.
Train: 2018-08-01T01:14:21.340179: step 21397, loss 0.596223.
Train: 2018-08-01T01:14:21.511982: step 21398, loss 0.494772.
Train: 2018-08-01T01:14:21.668196: step 21399, loss 0.47767.
Train: 2018-08-01T01:14:21.824409: step 21400, loss 0.562419.
Test: 2018-08-01T01:14:22.293049: step 21400, loss 0.548135.
Train: 2018-08-01T01:14:23.027253: step 21401, loss 0.52831.
Train: 2018-08-01T01:14:23.183467: step 21402, loss 0.511101.
Train: 2018-08-01T01:14:23.339711: step 21403, loss 0.545249.
Train: 2018-08-01T01:14:23.511544: step 21404, loss 0.459106.
Train: 2018-08-01T01:14:23.667761: step 21405, loss 0.545125.
Train: 2018-08-01T01:14:23.823972: step 21406, loss 0.631871.
Train: 2018-08-01T01:14:23.995776: step 21407, loss 0.457986.
Train: 2018-08-01T01:14:24.151994: step 21408, loss 0.562448.
Train: 2018-08-01T01:14:24.323855: step 21409, loss 0.579993.
Train: 2018-08-01T01:14:24.495683: step 21410, loss 0.632784.
Test: 2018-08-01T01:14:24.964300: step 21410, loss 0.547746.
Train: 2018-08-01T01:14:25.120543: step 21411, loss 0.492078.
Train: 2018-08-01T01:14:25.276728: step 21412, loss 0.527221.
Train: 2018-08-01T01:14:25.448591: step 21413, loss 0.59787.
Train: 2018-08-01T01:14:25.604805: step 21414, loss 0.615637.
Train: 2018-08-01T01:14:25.761018: step 21415, loss 0.562528.
Train: 2018-08-01T01:14:25.917234: step 21416, loss 0.615698.
Train: 2018-08-01T01:14:26.089066: step 21417, loss 0.562529.
Train: 2018-08-01T01:14:26.245249: step 21418, loss 0.633356.
Train: 2018-08-01T01:14:26.401465: step 21419, loss 0.474098.
Train: 2018-08-01T01:14:26.573322: step 21420, loss 0.544834.
Test: 2018-08-01T01:14:27.041970: step 21420, loss 0.547709.
Train: 2018-08-01T01:14:27.198182: step 21421, loss 0.59787.
Train: 2018-08-01T01:14:27.354365: step 21422, loss 0.491836.
Train: 2018-08-01T01:14:27.526200: step 21423, loss 0.580184.
Train: 2018-08-01T01:14:27.682415: step 21424, loss 0.527167.
Train: 2018-08-01T01:14:27.838657: step 21425, loss 0.544835.
Train: 2018-08-01T01:14:27.994868: step 21426, loss 0.474093.
Train: 2018-08-01T01:14:28.166707: step 21427, loss 0.49169.
Train: 2018-08-01T01:14:28.322888: step 21428, loss 0.473816.
Train: 2018-08-01T01:14:28.479133: step 21429, loss 0.651542.
Train: 2018-08-01T01:14:28.682204: step 21430, loss 0.616034.
Test: 2018-08-01T01:14:29.166439: step 21430, loss 0.547652.
Train: 2018-08-01T01:14:29.322655: step 21431, loss 0.56258.
Train: 2018-08-01T01:14:29.478868: step 21432, loss 0.633909.
Train: 2018-08-01T01:14:29.650731: step 21433, loss 0.616031.
Train: 2018-08-01T01:14:29.822536: step 21434, loss 0.54477.
Train: 2018-08-01T01:14:29.978750: step 21435, loss 0.704725.
Train: 2018-08-01T01:14:30.134994: step 21436, loss 0.597968.
Train: 2018-08-01T01:14:30.291210: step 21437, loss 0.509518.
Train: 2018-08-01T01:14:30.447415: step 21438, loss 0.47438.
Train: 2018-08-01T01:14:30.603630: step 21439, loss 0.597693.
Train: 2018-08-01T01:14:30.759851: step 21440, loss 0.562477.
Test: 2018-08-01T01:14:31.228488: step 21440, loss 0.54777.
Train: 2018-08-01T01:14:31.384704: step 21441, loss 0.527361.
Train: 2018-08-01T01:14:31.556507: step 21442, loss 0.527387.
Train: 2018-08-01T01:14:31.728341: step 21443, loss 0.597525.
Train: 2018-08-01T01:14:31.900177: step 21444, loss 0.492393.
Train: 2018-08-01T01:14:32.040767: step 21445, loss 0.49239.
Train: 2018-08-01T01:14:32.196982: step 21446, loss 0.457268.
Train: 2018-08-01T01:14:32.353194: step 21447, loss 0.615179.
Train: 2018-08-01T01:14:32.509438: step 21448, loss 0.65042.
Train: 2018-08-01T01:14:32.665654: step 21449, loss 0.580063.
Train: 2018-08-01T01:14:32.837486: step 21450, loss 0.439438.
Test: 2018-08-01T01:14:33.306096: step 21450, loss 0.547748.
Train: 2018-08-01T01:14:33.462310: step 21451, loss 0.580078.
Train: 2018-08-01T01:14:33.618553: step 21452, loss 0.439234.
Train: 2018-08-01T01:14:33.774761: step 21453, loss 0.580143.
Train: 2018-08-01T01:14:33.946601: step 21454, loss 0.633196.
Train: 2018-08-01T01:14:34.102785: step 21455, loss 0.527154.
Train: 2018-08-01T01:14:34.258998: step 21456, loss 0.491749.
Train: 2018-08-01T01:14:34.415235: step 21457, loss 0.615683.
Train: 2018-08-01T01:14:34.571425: step 21458, loss 0.597989.
Train: 2018-08-01T01:14:34.727663: step 21459, loss 0.597987.
Train: 2018-08-01T01:14:34.883882: step 21460, loss 0.562528.
Test: 2018-08-01T01:14:35.352522: step 21460, loss 0.547696.
Train: 2018-08-01T01:14:35.508735: step 21461, loss 0.52711.
Train: 2018-08-01T01:14:35.680571: step 21462, loss 0.544819.
Train: 2018-08-01T01:14:35.836753: step 21463, loss 0.580224.
Train: 2018-08-01T01:14:35.992968: step 21464, loss 0.633302.
Train: 2018-08-01T01:14:36.149210: step 21465, loss 0.509491.
Train: 2018-08-01T01:14:36.321051: step 21466, loss 0.43887.
Train: 2018-08-01T01:14:36.461608: step 21467, loss 0.580191.
Train: 2018-08-01T01:14:36.633443: step 21468, loss 0.509451.
Train: 2018-08-01T01:14:36.789688: step 21469, loss 0.52711.
Train: 2018-08-01T01:14:36.945899: step 21470, loss 0.509344.
Test: 2018-08-01T01:14:37.414541: step 21470, loss 0.547675.
Train: 2018-08-01T01:14:37.586374: step 21471, loss 0.544786.
Train: 2018-08-01T01:14:37.742558: step 21472, loss 0.580351.
Train: 2018-08-01T01:14:37.898770: step 21473, loss 0.580382.
Train: 2018-08-01T01:14:38.054985: step 21474, loss 0.598226.
Train: 2018-08-01T01:14:38.211198: step 21475, loss 0.544752.
Train: 2018-08-01T01:14:38.367412: step 21476, loss 0.56258.
Train: 2018-08-01T01:14:38.539246: step 21477, loss 0.669567.
Train: 2018-08-01T01:14:38.695460: step 21478, loss 0.615988.
Train: 2018-08-01T01:14:38.851672: step 21479, loss 0.615864.
Train: 2018-08-01T01:14:39.007917: step 21480, loss 0.509356.
Test: 2018-08-01T01:14:39.476557: step 21480, loss 0.547701.
Train: 2018-08-01T01:14:39.648360: step 21481, loss 0.562518.
Train: 2018-08-01T01:14:39.820220: step 21482, loss 0.544842.
Train: 2018-08-01T01:14:39.976439: step 21483, loss 0.509577.
Train: 2018-08-01T01:14:40.132653: step 21484, loss 0.527236.
Train: 2018-08-01T01:14:40.288868: step 21485, loss 0.527242.
Train: 2018-08-01T01:14:40.445080: step 21486, loss 0.474355.
Train: 2018-08-01T01:14:40.601294: step 21487, loss 0.668389.
Train: 2018-08-01T01:14:40.788739: step 21488, loss 0.527213.
Train: 2018-08-01T01:14:40.944932: step 21489, loss 0.527212.
Train: 2018-08-01T01:14:41.101145: step 21490, loss 0.5272.
Test: 2018-08-01T01:14:41.569785: step 21490, loss 0.547714.
Train: 2018-08-01T01:14:41.741622: step 21491, loss 0.544842.
Train: 2018-08-01T01:14:41.897867: step 21492, loss 0.56251.
Train: 2018-08-01T01:14:42.054047: step 21493, loss 0.474076.
Train: 2018-08-01T01:14:42.210291: step 21494, loss 0.79283.
Train: 2018-08-01T01:14:42.366499: step 21495, loss 0.650956.
Train: 2018-08-01T01:14:42.522712: step 21496, loss 0.580139.
Train: 2018-08-01T01:14:42.678931: step 21497, loss 0.632863.
Train: 2018-08-01T01:14:42.850762: step 21498, loss 0.632608.
Train: 2018-08-01T01:14:43.006949: step 21499, loss 0.57991.
Train: 2018-08-01T01:14:43.163195: step 21500, loss 0.614626.
Test: 2018-08-01T01:14:43.631833: step 21500, loss 0.54791.
Train: 2018-08-01T01:14:44.350385: step 21501, loss 0.44114.
Train: 2018-08-01T01:14:44.506629: step 21502, loss 0.510554.
Train: 2018-08-01T01:14:44.662812: step 21503, loss 0.614198.
Train: 2018-08-01T01:14:44.819025: step 21504, loss 0.596866.
Train: 2018-08-01T01:14:44.975239: step 21505, loss 0.613979.
Train: 2018-08-01T01:14:45.147074: step 21506, loss 0.562407.
Train: 2018-08-01T01:14:45.303318: step 21507, loss 0.5111.
Train: 2018-08-01T01:14:45.459499: step 21508, loss 0.596563.
Train: 2018-08-01T01:14:45.615713: step 21509, loss 0.579458.
Train: 2018-08-01T01:14:45.771952: step 21510, loss 0.477338.
Test: 2018-08-01T01:14:46.240598: step 21510, loss 0.548174.
Train: 2018-08-01T01:14:46.396811: step 21511, loss 0.494386.
Train: 2018-08-01T01:14:46.552994: step 21512, loss 0.477333.
Train: 2018-08-01T01:14:46.709207: step 21513, loss 0.545367.
Train: 2018-08-01T01:14:46.881042: step 21514, loss 0.579483.
Train: 2018-08-01T01:14:47.037271: step 21515, loss 0.562408.
Train: 2018-08-01T01:14:47.193506: step 21516, loss 0.459703.
Train: 2018-08-01T01:14:47.349713: step 21517, loss 0.493768.
Train: 2018-08-01T01:14:47.521542: step 21518, loss 0.493554.
Train: 2018-08-01T01:14:47.677731: step 21519, loss 0.614243.
Train: 2018-08-01T01:14:47.833969: step 21520, loss 0.510449.
Test: 2018-08-01T01:14:48.302586: step 21520, loss 0.547875.
Train: 2018-08-01T01:14:48.474449: step 21521, loss 0.579799.
Train: 2018-08-01T01:14:48.630662: step 21522, loss 0.545015.
Train: 2018-08-01T01:14:48.786878: step 21523, loss 0.544983.
Train: 2018-08-01T01:14:48.958681: step 21524, loss 0.614946.
Train: 2018-08-01T01:14:49.114894: step 21525, loss 0.544936.
Train: 2018-08-01T01:14:49.271151: step 21526, loss 0.58001.
Train: 2018-08-01T01:14:49.427346: step 21527, loss 0.632717.
Train: 2018-08-01T01:14:49.583534: step 21528, loss 0.509789.
Train: 2018-08-01T01:14:49.739779: step 21529, loss 0.580039.
Train: 2018-08-01T01:14:49.895987: step 21530, loss 0.632755.
Test: 2018-08-01T01:14:50.380253: step 21530, loss 0.547766.
Train: 2018-08-01T01:14:50.645786: step 21531, loss 0.527355.
Train: 2018-08-01T01:14:50.801999: step 21532, loss 0.632664.
Train: 2018-08-01T01:14:50.958243: step 21533, loss 0.544932.
Train: 2018-08-01T01:14:51.130072: step 21534, loss 0.509925.
Train: 2018-08-01T01:14:51.286260: step 21535, loss 0.632469.
Train: 2018-08-01T01:14:51.442474: step 21536, loss 0.509998.
Train: 2018-08-01T01:14:51.614309: step 21537, loss 0.597393.
Train: 2018-08-01T01:14:51.770522: step 21538, loss 0.475151.
Train: 2018-08-01T01:14:51.926735: step 21539, loss 0.562442.
Train: 2018-08-01T01:14:52.082974: step 21540, loss 0.457655.
Test: 2018-08-01T01:14:52.551620: step 21540, loss 0.547803.
Train: 2018-08-01T01:14:52.723466: step 21541, loss 0.527469.
Train: 2018-08-01T01:14:52.879668: step 21542, loss 0.632532.
Train: 2018-08-01T01:14:53.035883: step 21543, loss 0.685159.
Train: 2018-08-01T01:14:53.192064: step 21544, loss 0.47491.
Train: 2018-08-01T01:14:53.348308: step 21545, loss 0.597472.
Train: 2018-08-01T01:14:53.516027: step 21546, loss 0.527449.
Train: 2018-08-01T01:14:53.672241: step 21547, loss 0.614952.
Train: 2018-08-01T01:14:53.828465: step 21548, loss 0.632395.
Train: 2018-08-01T01:14:53.984643: step 21549, loss 0.527524.
Train: 2018-08-01T01:14:54.156503: step 21550, loss 0.562436.
Test: 2018-08-01T01:14:54.625148: step 21550, loss 0.547844.
Train: 2018-08-01T01:14:54.796952: step 21551, loss 0.510169.
Train: 2018-08-01T01:14:54.968819: step 21552, loss 0.666928.
Train: 2018-08-01T01:14:55.140653: step 21553, loss 0.545039.
Train: 2018-08-01T01:14:55.296836: step 21554, loss 0.597151.
Train: 2018-08-01T01:14:55.453048: step 21555, loss 0.510412.
Train: 2018-08-01T01:14:55.609262: step 21556, loss 0.683659.
Train: 2018-08-01T01:14:55.765510: step 21557, loss 0.596969.
Train: 2018-08-01T01:14:55.921719: step 21558, loss 0.614109.
Train: 2018-08-01T01:14:56.093548: step 21559, loss 0.510863.
Train: 2018-08-01T01:14:56.249767: step 21560, loss 0.510971.
Test: 2018-08-01T01:14:56.718407: step 21560, loss 0.548066.
Train: 2018-08-01T01:14:56.874609: step 21561, loss 0.562406.
Train: 2018-08-01T01:14:57.030804: step 21562, loss 0.5453.
Train: 2018-08-01T01:14:57.202639: step 21563, loss 0.494033.
Train: 2018-08-01T01:14:57.343262: step 21564, loss 0.562407.
Train: 2018-08-01T01:14:57.499475: step 21565, loss 0.665022.
Train: 2018-08-01T01:14:57.655658: step 21566, loss 0.562407.
Train: 2018-08-01T01:14:57.827492: step 21567, loss 0.477079.
Train: 2018-08-01T01:14:57.983706: step 21568, loss 0.579478.
Train: 2018-08-01T01:14:58.139944: step 21569, loss 0.528267.
Train: 2018-08-01T01:14:58.311791: step 21570, loss 0.562408.
Test: 2018-08-01T01:14:58.796046: step 21570, loss 0.548099.
Train: 2018-08-01T01:14:58.952254: step 21571, loss 0.64784.
Train: 2018-08-01T01:14:59.124094: step 21572, loss 0.579482.
Train: 2018-08-01T01:14:59.280279: step 21573, loss 0.562409.
Train: 2018-08-01T01:14:59.452143: step 21574, loss 0.528318.
Train: 2018-08-01T01:14:59.608357: step 21575, loss 0.56241.
Train: 2018-08-01T01:14:59.764565: step 21576, loss 0.57945.
Train: 2018-08-01T01:14:59.920783: step 21577, loss 0.613511.
Train: 2018-08-01T01:15:00.076991: step 21578, loss 0.52838.
Train: 2018-08-01T01:15:00.233210: step 21579, loss 0.477366.
Train: 2018-08-01T01:15:00.405014: step 21580, loss 0.528365.
Test: 2018-08-01T01:15:00.889277: step 21580, loss 0.548138.
Train: 2018-08-01T01:15:01.029898: step 21581, loss 0.528322.
Train: 2018-08-01T01:15:01.201733: step 21582, loss 0.579479.
Train: 2018-08-01T01:15:01.357946: step 21583, loss 0.425675.
Train: 2018-08-01T01:15:01.514131: step 21584, loss 0.665254.
Train: 2018-08-01T01:15:01.670342: step 21585, loss 0.579568.
Train: 2018-08-01T01:15:01.826588: step 21586, loss 0.596762.
Train: 2018-08-01T01:15:01.998421: step 21587, loss 0.545221.
Train: 2018-08-01T01:15:02.154634: step 21588, loss 0.510825.
Train: 2018-08-01T01:15:02.295227: step 21589, loss 0.562406.
Train: 2018-08-01T01:15:02.467061: step 21590, loss 0.562407.
Test: 2018-08-01T01:15:02.951293: step 21590, loss 0.547965.
Train: 2018-08-01T01:15:03.107536: step 21591, loss 0.493419.
Train: 2018-08-01T01:15:03.279372: step 21592, loss 0.527856.
Train: 2018-08-01T01:15:03.435585: step 21593, loss 0.475857.
Train: 2018-08-01T01:15:03.591768: step 21594, loss 0.440891.
Train: 2018-08-01T01:15:03.747981: step 21595, loss 0.649601.
Train: 2018-08-01T01:15:03.904226: step 21596, loss 0.632354.
Train: 2018-08-01T01:15:04.060439: step 21597, loss 0.597451.
Train: 2018-08-01T01:15:04.232244: step 21598, loss 0.562453.
Train: 2018-08-01T01:15:04.388486: step 21599, loss 0.492367.
Train: 2018-08-01T01:15:04.544669: step 21600, loss 0.562463.
Test: 2018-08-01T01:15:05.013341: step 21600, loss 0.54776.
Train: 2018-08-01T01:15:05.747514: step 21601, loss 0.650295.
Train: 2018-08-01T01:15:05.903727: step 21602, loss 0.544905.
Train: 2018-08-01T01:15:06.059971: step 21603, loss 0.597591.
Train: 2018-08-01T01:15:06.216153: step 21604, loss 0.737922.
Train: 2018-08-01T01:15:06.372367: step 21605, loss 0.544937.
Train: 2018-08-01T01:15:06.544232: step 21606, loss 0.614179.
Train: 2018-08-01T01:15:06.716036: step 21607, loss 0.492666.
Train: 2018-08-01T01:15:06.856658: step 21608, loss 0.63115.
Train: 2018-08-01T01:15:07.028464: step 21609, loss 0.545805.
Train: 2018-08-01T01:15:07.169081: step 21610, loss 0.44774.
Test: 2018-08-01T01:15:07.653346: step 21610, loss 0.548438.
Train: 2018-08-01T01:15:07.809561: step 21611, loss 0.560638.
Train: 2018-08-01T01:15:07.981390: step 21612, loss 0.512528.
Train: 2018-08-01T01:15:08.137610: step 21613, loss 0.495091.
Train: 2018-08-01T01:15:08.293817: step 21614, loss 0.560006.
Train: 2018-08-01T01:15:08.450036: step 21615, loss 0.648893.
Train: 2018-08-01T01:15:08.606218: step 21616, loss 0.546071.
Train: 2018-08-01T01:15:08.762457: step 21617, loss 0.614358.
Train: 2018-08-01T01:15:08.918647: step 21618, loss 0.614101.
Train: 2018-08-01T01:15:09.074890: step 21619, loss 0.579474.
Train: 2018-08-01T01:15:09.246693: step 21620, loss 0.699827.
Test: 2018-08-01T01:15:09.715364: step 21620, loss 0.548031.
Train: 2018-08-01T01:15:09.871578: step 21621, loss 0.647465.
Train: 2018-08-01T01:15:10.027760: step 21622, loss 0.545274.
Train: 2018-08-01T01:15:10.184005: step 21623, loss 0.649106.
Train: 2018-08-01T01:15:10.355809: step 21624, loss 0.563544.
Train: 2018-08-01T01:15:10.512022: step 21625, loss 0.49494.
Train: 2018-08-01T01:15:10.683857: step 21626, loss 0.562639.
Train: 2018-08-01T01:15:10.824480: step 21627, loss 0.528642.
Train: 2018-08-01T01:15:10.996314: step 21628, loss 0.529672.
Train: 2018-08-01T01:15:11.152498: step 21629, loss 0.579134.
Train: 2018-08-01T01:15:11.293120: step 21630, loss 0.562297.
Test: 2018-08-01T01:15:11.777381: step 21630, loss 0.548414.
Train: 2018-08-01T01:15:11.917943: step 21631, loss 0.561239.
Train: 2018-08-01T01:15:12.089778: step 21632, loss 0.596371.
Train: 2018-08-01T01:15:12.245992: step 21633, loss 0.595722.
Train: 2018-08-01T01:15:12.402235: step 21634, loss 0.646893.
Train: 2018-08-01T01:15:12.574070: step 21635, loss 0.412468.
Train: 2018-08-01T01:15:12.730284: step 21636, loss 0.512179.
Train: 2018-08-01T01:15:12.886497: step 21637, loss 0.612819.
Train: 2018-08-01T01:15:13.042718: step 21638, loss 0.563035.
Train: 2018-08-01T01:15:13.198924: step 21639, loss 0.513281.
Train: 2018-08-01T01:15:13.355137: step 21640, loss 0.596325.
Test: 2018-08-01T01:15:13.839398: step 21640, loss 0.548278.
Train: 2018-08-01T01:15:13.995581: step 21641, loss 0.579128.
Train: 2018-08-01T01:15:14.151825: step 21642, loss 0.613179.
Train: 2018-08-01T01:15:14.308009: step 21643, loss 0.562291.
Train: 2018-08-01T01:15:14.464252: step 21644, loss 0.64701.
Train: 2018-08-01T01:15:14.620466: step 21645, loss 0.545522.
Train: 2018-08-01T01:15:14.807916: step 21646, loss 0.528589.
Train: 2018-08-01T01:15:14.948514: step 21647, loss 0.545528.
Train: 2018-08-01T01:15:15.120349: step 21648, loss 0.545547.
Train: 2018-08-01T01:15:15.276532: step 21649, loss 0.511719.
Train: 2018-08-01T01:15:15.432745: step 21650, loss 0.562421.
Test: 2018-08-01T01:15:15.901415: step 21650, loss 0.54824.
Train: 2018-08-01T01:15:16.057623: step 21651, loss 0.579354.
Train: 2018-08-01T01:15:16.213842: step 21652, loss 0.613272.
Train: 2018-08-01T01:15:16.370027: step 21653, loss 0.613258.
Train: 2018-08-01T01:15:16.526238: step 21654, loss 0.477758.
Train: 2018-08-01T01:15:16.698105: step 21655, loss 0.562425.
Train: 2018-08-01T01:15:16.869910: step 21656, loss 0.528515.
Train: 2018-08-01T01:15:17.026123: step 21657, loss 0.562417.
Train: 2018-08-01T01:15:17.182335: step 21658, loss 0.528445.
Train: 2018-08-01T01:15:17.354200: step 21659, loss 0.664455.
Train: 2018-08-01T01:15:17.526005: step 21660, loss 0.613425.
Test: 2018-08-01T01:15:18.010267: step 21660, loss 0.548187.
Train: 2018-08-01T01:15:18.166510: step 21661, loss 0.579404.
Train: 2018-08-01T01:15:18.322724: step 21662, loss 0.647284.
Train: 2018-08-01T01:15:18.478908: step 21663, loss 0.630181.
Train: 2018-08-01T01:15:18.650772: step 21664, loss 0.494852.
Train: 2018-08-01T01:15:18.806986: step 21665, loss 0.511825.
Train: 2018-08-01T01:15:18.963169: step 21666, loss 0.596159.
Train: 2018-08-01T01:15:19.135036: step 21667, loss 0.596132.
Train: 2018-08-01T01:15:19.291247: step 21668, loss 0.579271.
Train: 2018-08-01T01:15:19.447461: step 21669, loss 0.612861.
Train: 2018-08-01T01:15:19.603677: step 21670, loss 0.478595.
Test: 2018-08-01T01:15:20.072314: step 21670, loss 0.548422.
Train: 2018-08-01T01:15:20.259770: step 21671, loss 0.595996.
Train: 2018-08-01T01:15:20.415983: step 21672, loss 0.61608.
Train: 2018-08-01T01:15:20.572199: step 21673, loss 0.562473.
Train: 2018-08-01T01:15:20.728410: step 21674, loss 0.529054.
Train: 2018-08-01T01:15:20.884595: step 21675, loss 0.612597.
Train: 2018-08-01T01:15:21.040837: step 21676, loss 0.579176.
Train: 2018-08-01T01:15:21.212645: step 21677, loss 0.562495.
Train: 2018-08-01T01:15:21.368891: step 21678, loss 0.562501.
Train: 2018-08-01T01:15:21.525098: step 21679, loss 0.579148.
Train: 2018-08-01T01:15:21.681283: step 21680, loss 0.678916.
Test: 2018-08-01T01:15:22.149922: step 21680, loss 0.548633.
Train: 2018-08-01T01:15:22.321758: step 21681, loss 0.529344.
Train: 2018-08-01T01:15:22.477970: step 21682, loss 0.579105.
Train: 2018-08-01T01:15:22.634214: step 21683, loss 0.612178.
Train: 2018-08-01T01:15:22.790428: step 21684, loss 0.562564.
Train: 2018-08-01T01:15:22.946641: step 21685, loss 0.579063.
Train: 2018-08-01T01:15:23.102824: step 21686, loss 0.595509.
Train: 2018-08-01T01:15:23.259037: step 21687, loss 0.644756.
Train: 2018-08-01T01:15:23.477737: step 21688, loss 0.595405.
Train: 2018-08-01T01:15:23.633950: step 21689, loss 0.54632.
Train: 2018-08-01T01:15:23.790193: step 21690, loss 0.660526.
Test: 2018-08-01T01:15:24.258804: step 21690, loss 0.549106.
Train: 2018-08-01T01:15:24.415017: step 21691, loss 0.578974.
Train: 2018-08-01T01:15:24.571255: step 21692, loss 0.546545.
Train: 2018-08-01T01:15:24.727474: step 21693, loss 0.514264.
Train: 2018-08-01T01:15:24.883688: step 21694, loss 0.51433.
Train: 2018-08-01T01:15:25.039901: step 21695, loss 0.562794.
Train: 2018-08-01T01:15:25.196114: step 21696, loss 0.546636.
Train: 2018-08-01T01:15:25.352297: step 21697, loss 0.481958.
Train: 2018-08-01T01:15:25.508511: step 21698, loss 0.595154.
Train: 2018-08-01T01:15:25.664725: step 21699, loss 0.611403.
Train: 2018-08-01T01:15:25.820974: step 21700, loss 0.514041.
Test: 2018-08-01T01:15:26.289577: step 21700, loss 0.549104.
Train: 2018-08-01T01:15:27.008190: step 21701, loss 0.54646.
Train: 2018-08-01T01:15:27.164403: step 21702, loss 0.562697.
Train: 2018-08-01T01:15:27.320617: step 21703, loss 0.546361.
Train: 2018-08-01T01:15:27.476799: step 21704, loss 0.546307.
Train: 2018-08-01T01:15:27.633013: step 21705, loss 0.546248.
Train: 2018-08-01T01:15:27.804848: step 21706, loss 0.579035.
Train: 2018-08-01T01:15:27.961062: step 21707, loss 0.57905.
Train: 2018-08-01T01:15:28.117275: step 21708, loss 0.612034.
Train: 2018-08-01T01:15:28.273518: step 21709, loss 0.513066.
Train: 2018-08-01T01:15:28.429733: step 21710, loss 0.529497.
Test: 2018-08-01T01:15:28.898341: step 21710, loss 0.548668.
Train: 2018-08-01T01:15:29.054591: step 21711, loss 0.545974.
Train: 2018-08-01T01:15:29.226420: step 21712, loss 0.512717.
Train: 2018-08-01T01:15:29.382603: step 21713, loss 0.629098.
Train: 2018-08-01T01:15:29.554469: step 21714, loss 0.579169.
Train: 2018-08-01T01:15:29.710681: step 21715, loss 0.512383.
Train: 2018-08-01T01:15:29.866896: step 21716, loss 0.495536.
Train: 2018-08-01T01:15:30.038701: step 21717, loss 0.49533.
Train: 2018-08-01T01:15:30.194944: step 21718, loss 0.629809.
Train: 2018-08-01T01:15:30.351157: step 21719, loss 0.545551.
Train: 2018-08-01T01:15:30.507371: step 21720, loss 0.630108.
Test: 2018-08-01T01:15:30.991632: step 21720, loss 0.548234.
Train: 2018-08-01T01:15:31.163436: step 21721, loss 0.579362.
Train: 2018-08-01T01:15:31.319649: step 21722, loss 0.596333.
Train: 2018-08-01T01:15:31.460271: step 21723, loss 0.511525.
Train: 2018-08-01T01:15:31.616456: step 21724, loss 0.579397.
Train: 2018-08-01T01:15:31.788291: step 21725, loss 0.511426.
Train: 2018-08-01T01:15:31.944504: step 21726, loss 0.54539.
Train: 2018-08-01T01:15:32.100716: step 21727, loss 0.68173.
Train: 2018-08-01T01:15:32.272551: step 21728, loss 0.596492.
Train: 2018-08-01T01:15:32.428766: step 21729, loss 0.477253.
Train: 2018-08-01T01:15:32.569388: step 21730, loss 0.613532.
Test: 2018-08-01T01:15:33.053649: step 21730, loss 0.54814.
Train: 2018-08-01T01:15:33.225484: step 21731, loss 0.647603.
Train: 2018-08-01T01:15:33.397318: step 21732, loss 0.528375.
Train: 2018-08-01T01:15:33.553533: step 21733, loss 0.61343.
Train: 2018-08-01T01:15:33.725366: step 21734, loss 0.664322.
Train: 2018-08-01T01:15:33.881580: step 21735, loss 0.545478.
Train: 2018-08-01T01:15:34.037793: step 21736, loss 0.545518.
Train: 2018-08-01T01:15:34.193977: step 21737, loss 0.596196.
Train: 2018-08-01T01:15:34.350217: step 21738, loss 0.612995.
Train: 2018-08-01T01:15:34.522026: step 21739, loss 0.663331.
Train: 2018-08-01T01:15:34.678239: step 21740, loss 0.595977.
Test: 2018-08-01T01:15:35.146909: step 21740, loss 0.548501.
Train: 2018-08-01T01:15:35.318744: step 21741, loss 0.662674.
Train: 2018-08-01T01:15:35.521826: step 21742, loss 0.579136.
Train: 2018-08-01T01:15:35.678035: step 21743, loss 0.545989.
Train: 2018-08-01T01:15:35.834217: step 21744, loss 0.628558.
Train: 2018-08-01T01:15:35.990431: step 21745, loss 0.49688.
Train: 2018-08-01T01:15:36.146675: step 21746, loss 0.464283.
Train: 2018-08-01T01:15:36.302889: step 21747, loss 0.595397.
Train: 2018-08-01T01:15:36.474723: step 21748, loss 0.546278.
Train: 2018-08-01T01:15:36.630908: step 21749, loss 0.546289.
Train: 2018-08-01T01:15:36.787151: step 21750, loss 0.529929.
Test: 2018-08-01T01:15:37.271410: step 21750, loss 0.548933.
Train: 2018-08-01T01:15:37.427626: step 21751, loss 0.579012.
Train: 2018-08-01T01:15:37.583832: step 21752, loss 0.431607.
Train: 2018-08-01T01:15:37.755673: step 21753, loss 0.496931.
Train: 2018-08-01T01:15:37.911886: step 21754, loss 0.562582.
Train: 2018-08-01T01:15:38.068093: step 21755, loss 0.579083.
Train: 2018-08-01T01:15:38.224313: step 21756, loss 0.479669.
Train: 2018-08-01T01:15:38.380527: step 21757, loss 0.612412.
Train: 2018-08-01T01:15:38.536740: step 21758, loss 0.595851.
Train: 2018-08-01T01:15:38.692954: step 21759, loss 0.612623.
Train: 2018-08-01T01:15:38.864794: step 21760, loss 0.495528.
Test: 2018-08-01T01:15:39.333398: step 21760, loss 0.548416.
Train: 2018-08-01T01:15:39.489612: step 21761, loss 0.545688.
Train: 2018-08-01T01:15:39.645824: step 21762, loss 0.579257.
Train: 2018-08-01T01:15:39.802039: step 21763, loss 0.562441.
Train: 2018-08-01T01:15:39.973873: step 21764, loss 0.461228.
Train: 2018-08-01T01:15:40.145707: step 21765, loss 0.545506.
Train: 2018-08-01T01:15:40.301922: step 21766, loss 0.494542.
Train: 2018-08-01T01:15:40.458134: step 21767, loss 0.460228.
Train: 2018-08-01T01:15:40.614378: step 21768, loss 0.459744.
Train: 2018-08-01T01:15:40.770592: step 21769, loss 0.510787.
Train: 2018-08-01T01:15:40.942431: step 21770, loss 0.56241.
Test: 2018-08-01T01:15:41.426689: step 21770, loss 0.54786.
Train: 2018-08-01T01:15:41.582902: step 21771, loss 0.614596.
Train: 2018-08-01T01:15:41.739115: step 21772, loss 0.527522.
Train: 2018-08-01T01:15:41.895328: step 21773, loss 0.527406.
Train: 2018-08-01T01:15:42.067174: step 21774, loss 0.509701.
Train: 2018-08-01T01:15:42.223376: step 21775, loss 0.438867.
Train: 2018-08-01T01:15:42.379590: step 21776, loss 0.527034.
Train: 2018-08-01T01:15:42.535804: step 21777, loss 0.509063.
Train: 2018-08-01T01:15:42.691986: step 21778, loss 0.526774.
Train: 2018-08-01T01:15:42.863821: step 21779, loss 0.490631.
Train: 2018-08-01T01:15:43.020065: step 21780, loss 0.508435.
Test: 2018-08-01T01:15:43.504297: step 21780, loss 0.547575.
Train: 2018-08-01T01:15:43.660540: step 21781, loss 0.490039.
Train: 2018-08-01T01:15:43.816754: step 21782, loss 0.5446.
Train: 2018-08-01T01:15:43.972969: step 21783, loss 0.709937.
Train: 2018-08-01T01:15:44.129180: step 21784, loss 0.563.
Train: 2018-08-01T01:15:44.285384: step 21785, loss 0.52614.
Train: 2018-08-01T01:15:44.441608: step 21786, loss 0.618505.
Train: 2018-08-01T01:15:44.597820: step 21787, loss 0.544585.
Train: 2018-08-01T01:15:44.769650: step 21788, loss 0.544585.
Train: 2018-08-01T01:15:44.925838: step 21789, loss 0.581625.
Train: 2018-08-01T01:15:45.082083: step 21790, loss 0.600152.
Test: 2018-08-01T01:15:45.550693: step 21790, loss 0.547596.
Train: 2018-08-01T01:15:45.706905: step 21791, loss 0.674173.
Train: 2018-08-01T01:15:45.878741: step 21792, loss 0.489158.
Train: 2018-08-01T01:15:46.034984: step 21793, loss 0.581495.
Train: 2018-08-01T01:15:46.191167: step 21794, loss 0.470875.
Train: 2018-08-01T01:15:46.347380: step 21795, loss 0.507747.
Train: 2018-08-01T01:15:46.519215: step 21796, loss 0.599849.
Train: 2018-08-01T01:15:46.659808: step 21797, loss 0.673457.
Train: 2018-08-01T01:15:46.831672: step 21798, loss 0.61808.
Train: 2018-08-01T01:15:46.987885: step 21799, loss 0.507948.
Train: 2018-08-01T01:15:47.144100: step 21800, loss 0.526312.
Test: 2018-08-01T01:15:47.612710: step 21800, loss 0.547573.
Train: 2018-08-01T01:15:48.315701: step 21801, loss 0.562864.
Train: 2018-08-01T01:15:48.471883: step 21802, loss 0.581072.
Train: 2018-08-01T01:15:48.659370: step 21803, loss 0.544616.
Train: 2018-08-01T01:15:48.831204: step 21804, loss 0.562792.
Train: 2018-08-01T01:15:48.987418: step 21805, loss 0.580911.
Train: 2018-08-01T01:15:49.143631: step 21806, loss 0.490313.
Train: 2018-08-01T01:15:49.299815: step 21807, loss 0.617009.
Train: 2018-08-01T01:15:49.456058: step 21808, loss 0.436279.
Train: 2018-08-01T01:15:49.612272: step 21809, loss 0.562712.
Train: 2018-08-01T01:15:49.784075: step 21810, loss 0.526597.
Test: 2018-08-01T01:15:50.252746: step 21810, loss 0.547589.
Train: 2018-08-01T01:15:50.408962: step 21811, loss 0.562711.
Train: 2018-08-01T01:15:50.580794: step 21812, loss 0.526596.
Train: 2018-08-01T01:15:50.737008: step 21813, loss 0.544652.
Train: 2018-08-01T01:15:50.908843: step 21814, loss 0.598847.
Train: 2018-08-01T01:15:51.065056: step 21815, loss 0.436296.
Train: 2018-08-01T01:15:51.221269: step 21816, loss 0.616962.
Train: 2018-08-01T01:15:51.377486: step 21817, loss 0.4904.
Train: 2018-08-01T01:15:51.533696: step 21818, loss 0.454154.
Train: 2018-08-01T01:15:51.689881: step 21819, loss 0.526498.
Train: 2018-08-01T01:15:51.846118: step 21820, loss 0.617299.
Test: 2018-08-01T01:15:52.330385: step 21820, loss 0.547575.
Train: 2018-08-01T01:15:52.486568: step 21821, loss 0.580993.
Train: 2018-08-01T01:15:52.642782: step 21822, loss 0.617402.
Train: 2018-08-01T01:15:52.798996: step 21823, loss 0.562807.
Train: 2018-08-01T01:15:52.955208: step 21824, loss 0.617341.
Train: 2018-08-01T01:15:53.127044: step 21825, loss 0.671723.
Train: 2018-08-01T01:15:53.283256: step 21826, loss 0.689509.
Train: 2018-08-01T01:15:53.439469: step 21827, loss 0.58073.
Train: 2018-08-01T01:15:53.611305: step 21828, loss 0.652459.
Train: 2018-08-01T01:15:53.767518: step 21829, loss 0.508975.
Train: 2018-08-01T01:15:53.923756: step 21830, loss 0.598171.
Test: 2018-08-01T01:15:54.392370: step 21830, loss 0.547679.
Train: 2018-08-01T01:15:54.548610: step 21831, loss 0.615724.
Train: 2018-08-01T01:15:54.704799: step 21832, loss 0.509536.
Train: 2018-08-01T01:15:54.861012: step 21833, loss 0.456918.
Train: 2018-08-01T01:15:55.032877: step 21834, loss 0.580024.
Train: 2018-08-01T01:15:55.189086: step 21835, loss 0.492347.
Train: 2018-08-01T01:15:55.345275: step 21836, loss 0.527428.
Train: 2018-08-01T01:15:55.501518: step 21837, loss 0.667468.
Train: 2018-08-01T01:15:55.657730: step 21838, loss 0.562439.
Train: 2018-08-01T01:15:55.813914: step 21839, loss 0.597318.
Train: 2018-08-01T01:15:55.970157: step 21840, loss 0.579833.
Test: 2018-08-01T01:15:56.438798: step 21840, loss 0.547873.
Train: 2018-08-01T01:15:56.595012: step 21841, loss 0.649274.
Train: 2018-08-01T01:15:56.766841: step 21842, loss 0.527776.
Train: 2018-08-01T01:15:56.923060: step 21843, loss 0.648792.
Train: 2018-08-01T01:15:57.079243: step 21844, loss 0.665725.
Train: 2018-08-01T01:15:57.235486: step 21845, loss 0.596692.
Train: 2018-08-01T01:15:57.407292: step 21846, loss 0.613614.
Train: 2018-08-01T01:15:57.563535: step 21847, loss 0.664354.
Train: 2018-08-01T01:15:57.719750: step 21848, loss 0.545532.
Train: 2018-08-01T01:15:57.891552: step 21849, loss 0.495187.
Train: 2018-08-01T01:15:58.032175: step 21850, loss 0.495425.
Test: 2018-08-01T01:15:58.516405: step 21850, loss 0.548466.
Train: 2018-08-01T01:15:58.672656: step 21851, loss 0.52902.
Train: 2018-08-01T01:15:58.828865: step 21852, loss 0.445539.
Train: 2018-08-01T01:15:58.985046: step 21853, loss 0.595909.
Train: 2018-08-01T01:15:59.141261: step 21854, loss 0.529035.
Train: 2018-08-01T01:15:59.297474: step 21855, loss 0.529007.
Train: 2018-08-01T01:15:59.453711: step 21856, loss 0.579216.
Train: 2018-08-01T01:15:59.625521: step 21857, loss 0.629529.
Train: 2018-08-01T01:15:59.781734: step 21858, loss 0.478627.
Train: 2018-08-01T01:15:59.937973: step 21859, loss 0.545667.
Train: 2018-08-01T01:16:00.094192: step 21860, loss 0.680119.
Test: 2018-08-01T01:16:00.578453: step 21860, loss 0.548377.
Train: 2018-08-01T01:16:00.734667: step 21861, loss 0.394402.
Train: 2018-08-01T01:16:00.890881: step 21862, loss 0.59612.
Train: 2018-08-01T01:16:01.062716: step 21863, loss 0.444378.
Train: 2018-08-01T01:16:01.218898: step 21864, loss 0.613172.
Train: 2018-08-01T01:16:01.375136: step 21865, loss 0.647172.
Train: 2018-08-01T01:16:01.531355: step 21866, loss 0.596342.
Train: 2018-08-01T01:16:01.687569: step 21867, loss 0.528481.
Train: 2018-08-01T01:16:01.875025: step 21868, loss 0.681263.
Train: 2018-08-01T01:16:02.031209: step 21869, loss 0.545453.
Train: 2018-08-01T01:16:02.187452: step 21870, loss 0.647176.
Test: 2018-08-01T01:16:02.656093: step 21870, loss 0.54825.
Train: 2018-08-01T01:16:02.812306: step 21871, loss 0.545498.
Train: 2018-08-01T01:16:02.984110: step 21872, loss 0.596231.
Train: 2018-08-01T01:16:03.140354: step 21873, loss 0.461171.
Train: 2018-08-01T01:16:03.296536: step 21874, loss 0.596187.
Train: 2018-08-01T01:16:03.437162: step 21875, loss 0.579304.
Train: 2018-08-01T01:16:03.608994: step 21876, loss 0.49498.
Train: 2018-08-01T01:16:03.749586: step 21877, loss 0.444323.
Train: 2018-08-01T01:16:03.921421: step 21878, loss 0.494787.
Train: 2018-08-01T01:16:04.093250: step 21879, loss 0.51154.
Train: 2018-08-01T01:16:04.249438: step 21880, loss 0.477331.
Test: 2018-08-01T01:16:04.733718: step 21880, loss 0.548094.
Train: 2018-08-01T01:16:04.889913: step 21881, loss 0.528229.
Train: 2018-08-01T01:16:05.046128: step 21882, loss 0.562401.
Train: 2018-08-01T01:16:05.217963: step 21883, loss 0.562402.
Train: 2018-08-01T01:16:05.374175: step 21884, loss 0.666102.
Train: 2018-08-01T01:16:05.530419: step 21885, loss 0.545099.
Train: 2018-08-01T01:16:05.686633: step 21886, loss 0.545073.
Train: 2018-08-01T01:16:05.842848: step 21887, loss 0.631897.
Train: 2018-08-01T01:16:05.999028: step 21888, loss 0.63194.
Train: 2018-08-01T01:16:06.155242: step 21889, loss 0.527673.
Train: 2018-08-01T01:16:06.327077: step 21890, loss 0.701407.
Test: 2018-08-01T01:16:06.795744: step 21890, loss 0.547892.
Train: 2018-08-01T01:16:06.951955: step 21891, loss 0.597098.
Train: 2018-08-01T01:16:07.108146: step 21892, loss 0.614325.
Train: 2018-08-01T01:16:07.279978: step 21893, loss 0.562405.
Train: 2018-08-01T01:16:07.436223: step 21894, loss 0.579621.
Train: 2018-08-01T01:16:07.592405: step 21895, loss 0.545223.
Train: 2018-08-01T01:16:07.748643: step 21896, loss 0.613835.
Train: 2018-08-01T01:16:07.904863: step 21897, loss 0.545299.
Train: 2018-08-01T01:16:08.061046: step 21898, loss 0.545334.
Train: 2018-08-01T01:16:08.217295: step 21899, loss 0.477187.
Train: 2018-08-01T01:16:08.373511: step 21900, loss 0.596487.
Test: 2018-08-01T01:16:08.857733: step 21900, loss 0.548146.
Train: 2018-08-01T01:16:09.560694: step 21901, loss 0.664587.
Train: 2018-08-01T01:16:09.716909: step 21902, loss 0.545413.
Train: 2018-08-01T01:16:09.873156: step 21903, loss 0.545441.
Train: 2018-08-01T01:16:10.029365: step 21904, loss 0.579371.
Train: 2018-08-01T01:16:10.201170: step 21905, loss 0.443874.
Train: 2018-08-01T01:16:10.357414: step 21906, loss 0.460743.
Train: 2018-08-01T01:16:10.513597: step 21907, loss 0.579392.
Train: 2018-08-01T01:16:10.685463: step 21908, loss 0.647443.
Train: 2018-08-01T01:16:10.841646: step 21909, loss 0.528385.
Train: 2018-08-01T01:16:10.997888: step 21910, loss 0.562407.
Test: 2018-08-01T01:16:11.466527: step 21910, loss 0.54814.
Train: 2018-08-01T01:16:11.622737: step 21911, loss 0.545369.
Train: 2018-08-01T01:16:11.810193: step 21912, loss 0.562405.
Train: 2018-08-01T01:16:11.950791: step 21913, loss 0.545338.
Train: 2018-08-01T01:16:12.107004: step 21914, loss 0.511154.
Train: 2018-08-01T01:16:12.278808: step 21915, loss 0.596622.
Train: 2018-08-01T01:16:12.450668: step 21916, loss 0.613781.
Train: 2018-08-01T01:16:12.606856: step 21917, loss 0.613791.
Train: 2018-08-01T01:16:12.763070: step 21918, loss 0.579522.
Train: 2018-08-01T01:16:12.919314: step 21919, loss 0.579511.
Train: 2018-08-01T01:16:13.075528: step 21920, loss 0.528211.
Test: 2018-08-01T01:16:13.559758: step 21920, loss 0.548091.
Train: 2018-08-01T01:16:13.716005: step 21921, loss 0.767486.
Train: 2018-08-01T01:16:13.887833: step 21922, loss 0.613523.
Train: 2018-08-01T01:16:14.044051: step 21923, loss 0.494487.
Train: 2018-08-01T01:16:14.200263: step 21924, loss 0.562418.
Train: 2018-08-01T01:16:14.356480: step 21925, loss 0.528594.
Train: 2018-08-01T01:16:14.512685: step 21926, loss 0.680689.
Train: 2018-08-01T01:16:14.668905: step 21927, loss 0.528736.
Train: 2018-08-01T01:16:14.840738: step 21928, loss 0.612901.
Train: 2018-08-01T01:16:14.996923: step 21929, loss 0.596015.
Train: 2018-08-01T01:16:15.153135: step 21930, loss 0.445299.
Test: 2018-08-01T01:16:15.621776: step 21930, loss 0.548462.
Train: 2018-08-01T01:16:15.778019: step 21931, loss 0.545741.
Train: 2018-08-01T01:16:15.934203: step 21932, loss 0.579199.
Train: 2018-08-01T01:16:16.090453: step 21933, loss 0.662806.
Train: 2018-08-01T01:16:16.246659: step 21934, loss 0.529092.
Train: 2018-08-01T01:16:16.402873: step 21935, loss 0.545807.
Train: 2018-08-01T01:16:16.559056: step 21936, loss 0.579163.
Train: 2018-08-01T01:16:16.715269: step 21937, loss 0.529168.
Train: 2018-08-01T01:16:16.871513: step 21938, loss 0.495839.
Train: 2018-08-01T01:16:17.027696: step 21939, loss 0.612532.
Train: 2018-08-01T01:16:17.199531: step 21940, loss 0.579173.
Test: 2018-08-01T01:16:17.668202: step 21940, loss 0.548508.
Train: 2018-08-01T01:16:17.824415: step 21941, loss 0.595864.
Train: 2018-08-01T01:16:18.011871: step 21942, loss 0.562486.
Train: 2018-08-01T01:16:18.168054: step 21943, loss 0.562487.
Train: 2018-08-01T01:16:18.339889: step 21944, loss 0.67927.
Train: 2018-08-01T01:16:18.480512: step 21945, loss 0.662437.
Train: 2018-08-01T01:16:18.652316: step 21946, loss 0.479462.
Train: 2018-08-01T01:16:18.808553: step 21947, loss 0.545934.
Train: 2018-08-01T01:16:18.964743: step 21948, loss 0.56253.
Train: 2018-08-01T01:16:19.120956: step 21949, loss 0.562534.
Train: 2018-08-01T01:16:19.277170: step 21950, loss 0.579099.
Test: 2018-08-01T01:16:19.745810: step 21950, loss 0.548679.
Train: 2018-08-01T01:16:19.902054: step 21951, loss 0.479771.
Train: 2018-08-01T01:16:20.058237: step 21952, loss 0.446557.
Train: 2018-08-01T01:16:20.230072: step 21953, loss 0.579126.
Train: 2018-08-01T01:16:20.386315: step 21954, loss 0.595793.
Train: 2018-08-01T01:16:20.558119: step 21955, loss 0.44579.
Train: 2018-08-01T01:16:20.714363: step 21956, loss 0.646091.
Train: 2018-08-01T01:16:20.870571: step 21957, loss 0.629472.
Train: 2018-08-01T01:16:21.026798: step 21958, loss 0.579223.
Train: 2018-08-01T01:16:21.183004: step 21959, loss 0.595999.
Train: 2018-08-01T01:16:21.339211: step 21960, loss 0.528916.
Test: 2018-08-01T01:16:21.807826: step 21960, loss 0.548404.
Train: 2018-08-01T01:16:21.979662: step 21961, loss 0.461776.
Train: 2018-08-01T01:16:22.135874: step 21962, loss 0.46157.
Train: 2018-08-01T01:16:22.292088: step 21963, loss 0.663633.
Train: 2018-08-01T01:16:22.448302: step 21964, loss 0.629998.
Train: 2018-08-01T01:16:22.604514: step 21965, loss 0.528623.
Train: 2018-08-01T01:16:22.776350: step 21966, loss 0.545505.
Train: 2018-08-01T01:16:22.932563: step 21967, loss 0.426925.
Train: 2018-08-01T01:16:23.088777: step 21968, loss 0.528439.
Train: 2018-08-01T01:16:23.244991: step 21969, loss 0.49425.
Train: 2018-08-01T01:16:23.401204: step 21970, loss 0.528197.
Test: 2018-08-01T01:16:23.869844: step 21970, loss 0.548024.
Train: 2018-08-01T01:16:24.026087: step 21971, loss 0.5624.
Train: 2018-08-01T01:16:24.182301: step 21972, loss 0.493498.
Train: 2018-08-01T01:16:24.338515: step 21973, loss 0.580854.
Train: 2018-08-01T01:16:24.494727: step 21974, loss 0.47566.
Train: 2018-08-01T01:16:24.650910: step 21975, loss 0.649532.
Train: 2018-08-01T01:16:24.807155: step 21976, loss 0.562436.
Train: 2018-08-01T01:16:24.994610: step 21977, loss 0.562445.
Train: 2018-08-01T01:16:25.150819: step 21978, loss 0.63259.
Train: 2018-08-01T01:16:25.307038: step 21979, loss 0.720378.
Train: 2018-08-01T01:16:25.478869: step 21980, loss 0.492364.
Test: 2018-08-01T01:16:25.947513: step 21980, loss 0.547783.
Train: 2018-08-01T01:16:26.119341: step 21981, loss 0.61499.
Train: 2018-08-01T01:16:26.275556: step 21982, loss 0.527456.
Train: 2018-08-01T01:16:26.431768: step 21983, loss 0.405096.
Train: 2018-08-01T01:16:26.587987: step 21984, loss 0.562447.
Train: 2018-08-01T01:16:26.744200: step 21985, loss 0.439759.
Train: 2018-08-01T01:16:26.900414: step 21986, loss 0.562466.
Train: 2018-08-01T01:16:27.072244: step 21987, loss 0.615313.
Train: 2018-08-01T01:16:27.228433: step 21988, loss 0.562487.
Train: 2018-08-01T01:16:27.384676: step 21989, loss 0.52719.
Train: 2018-08-01T01:16:27.540890: step 21990, loss 0.544828.
Test: 2018-08-01T01:16:28.009529: step 21990, loss 0.547692.
Train: 2018-08-01T01:16:28.196987: step 21991, loss 0.633304.
Train: 2018-08-01T01:16:28.353170: step 21992, loss 0.52711.
Train: 2018-08-01T01:16:28.509407: step 21993, loss 0.509384.
Train: 2018-08-01T01:16:28.665627: step 21994, loss 0.597984.
Train: 2018-08-01T01:16:28.837455: step 21995, loss 0.598001.
Train: 2018-08-01T01:16:28.993644: step 21996, loss 0.58026.
Train: 2018-08-01T01:16:29.149858: step 21997, loss 0.615698.
Train: 2018-08-01T01:16:29.337341: step 21998, loss 0.527106.
Train: 2018-08-01T01:16:29.493551: step 21999, loss 0.633274.
Train: 2018-08-01T01:16:29.649765: step 22000, loss 0.438859.
Test: 2018-08-01T01:16:30.134035: step 22000, loss 0.547707.
Train: 2018-08-01T01:16:30.836963: step 22001, loss 0.438859.
Train: 2018-08-01T01:16:30.993206: step 22002, loss 0.456377.
Train: 2018-08-01T01:16:31.149420: step 22003, loss 0.633461.
Train: 2018-08-01T01:16:31.321254: step 22004, loss 0.633564.
Train: 2018-08-01T01:16:31.493089: step 22005, loss 0.65134.
Train: 2018-08-01T01:16:31.664925: step 22006, loss 0.722211.
Train: 2018-08-01T01:16:31.836728: step 22007, loss 0.580197.
Train: 2018-08-01T01:16:31.992972: step 22008, loss 0.527215.
Train: 2018-08-01T01:16:32.133559: step 22009, loss 0.562473.
Train: 2018-08-01T01:16:32.289779: step 22010, loss 0.61513.
Test: 2018-08-01T01:16:32.774009: step 22010, loss 0.547786.
Train: 2018-08-01T01:16:32.930255: step 22011, loss 0.685008.
Train: 2018-08-01T01:16:33.086435: step 22012, loss 0.579868.
Train: 2018-08-01T01:16:33.242679: step 22013, loss 0.51031.
Train: 2018-08-01T01:16:33.398862: step 22014, loss 0.475818.
Train: 2018-08-01T01:16:33.555075: step 22015, loss 0.579698.
Train: 2018-08-01T01:16:33.742533: step 22016, loss 0.476088.
Train: 2018-08-01T01:16:33.898745: step 22017, loss 0.57966.
Train: 2018-08-01T01:16:34.054960: step 22018, loss 0.545156.
Train: 2018-08-01T01:16:34.211196: step 22019, loss 0.527919.
Train: 2018-08-01T01:16:34.367386: step 22020, loss 0.441693.
Test: 2018-08-01T01:16:34.836057: step 22020, loss 0.54794.
Train: 2018-08-01T01:16:34.992270: step 22021, loss 0.596952.
Train: 2018-08-01T01:16:35.148483: step 22022, loss 0.475948.
Train: 2018-08-01T01:16:35.304691: step 22023, loss 0.406465.
Train: 2018-08-01T01:16:35.460880: step 22024, loss 0.562421.
Train: 2018-08-01T01:16:35.632715: step 22025, loss 0.562433.
Train: 2018-08-01T01:16:35.788927: step 22026, loss 0.57995.
Train: 2018-08-01T01:16:35.960793: step 22027, loss 0.632644.
Train: 2018-08-01T01:16:36.117000: step 22028, loss 0.5976.
Train: 2018-08-01T01:16:36.288842: step 22029, loss 0.597623.
Train: 2018-08-01T01:16:36.445054: step 22030, loss 0.720668.
Test: 2018-08-01T01:16:36.913697: step 22030, loss 0.547767.
Train: 2018-08-01T01:16:37.069878: step 22031, loss 0.422121.
Train: 2018-08-01T01:16:37.226090: step 22032, loss 0.615074.
Train: 2018-08-01T01:16:37.397927: step 22033, loss 0.544927.
Train: 2018-08-01T01:16:37.554140: step 22034, loss 0.597475.
Train: 2018-08-01T01:16:37.710353: step 22035, loss 0.492463.
Train: 2018-08-01T01:16:37.866565: step 22036, loss 0.527457.
Train: 2018-08-01T01:16:38.054023: step 22037, loss 0.509951.
Train: 2018-08-01T01:16:38.194614: step 22038, loss 0.50991.
Train: 2018-08-01T01:16:38.366485: step 22039, loss 0.615064.
Train: 2018-08-01T01:16:38.522693: step 22040, loss 0.66773.
Test: 2018-08-01T01:16:39.006948: step 22040, loss 0.547774.
Train: 2018-08-01T01:16:39.163137: step 22041, loss 0.597511.
Train: 2018-08-01T01:16:39.319350: step 22042, loss 0.544941.
Train: 2018-08-01T01:16:39.459973: step 22043, loss 0.597415.
Train: 2018-08-01T01:16:39.631777: step 22044, loss 0.632282.
Train: 2018-08-01T01:16:39.788015: step 22045, loss 0.614695.
Train: 2018-08-01T01:16:39.944236: step 22046, loss 0.510292.
Train: 2018-08-01T01:16:40.116039: step 22047, loss 0.510383.
Train: 2018-08-01T01:16:40.272283: step 22048, loss 0.56241.
Train: 2018-08-01T01:16:40.428497: step 22049, loss 0.614336.
Train: 2018-08-01T01:16:40.584710: step 22050, loss 0.648817.
Test: 2018-08-01T01:16:41.068971: step 22050, loss 0.547967.
Train: 2018-08-01T01:16:41.225186: step 22051, loss 0.57964.
Train: 2018-08-01T01:16:41.397027: step 22052, loss 0.5624.
Train: 2018-08-01T01:16:41.553233: step 22053, loss 0.459466.
Train: 2018-08-01T01:16:41.709446: step 22054, loss 0.425253.
Train: 2018-08-01T01:16:41.865661: step 22055, loss 0.510909.
Train: 2018-08-01T01:16:42.021874: step 22056, loss 0.68275.
Train: 2018-08-01T01:16:42.178057: step 22057, loss 0.579592.
Train: 2018-08-01T01:16:42.334294: step 22058, loss 0.648339.
Train: 2018-08-01T01:16:42.506104: step 22059, loss 0.613893.
Train: 2018-08-01T01:16:42.662355: step 22060, loss 0.545268.
Test: 2018-08-01T01:16:43.130988: step 22060, loss 0.548076.
Train: 2018-08-01T01:16:43.287203: step 22061, loss 0.61372.
Train: 2018-08-01T01:16:43.443385: step 22062, loss 0.596546.
Train: 2018-08-01T01:16:43.615245: step 22063, loss 0.528338.
Train: 2018-08-01T01:16:43.787085: step 22064, loss 0.477372.
Train: 2018-08-01T01:16:43.943268: step 22065, loss 0.613418.
Train: 2018-08-01T01:16:44.099512: step 22066, loss 0.545422.
Train: 2018-08-01T01:16:44.255696: step 22067, loss 0.443556.
Train: 2018-08-01T01:16:44.427562: step 22068, loss 0.596407.
Train: 2018-08-01T01:16:44.599366: step 22069, loss 0.579417.
Train: 2018-08-01T01:16:44.771237: step 22070, loss 0.477332.
Test: 2018-08-01T01:16:45.239840: step 22070, loss 0.548136.
Train: 2018-08-01T01:16:45.396084: step 22071, loss 0.545365.
Train: 2018-08-01T01:16:45.552297: step 22072, loss 0.545336.
Train: 2018-08-01T01:16:45.724115: step 22073, loss 0.528211.
Train: 2018-08-01T01:16:45.880314: step 22074, loss 0.613784.
Train: 2018-08-01T01:16:46.036528: step 22075, loss 0.545253.
Train: 2018-08-01T01:16:46.192742: step 22076, loss 0.407895.
Train: 2018-08-01T01:16:46.348985: step 22077, loss 0.631282.
Train: 2018-08-01T01:16:46.505198: step 22078, loss 0.54515.
Train: 2018-08-01T01:16:46.661382: step 22079, loss 0.57969.
Train: 2018-08-01T01:16:46.833216: step 22080, loss 0.545098.
Test: 2018-08-01T01:16:47.301856: step 22080, loss 0.547895.
Train: 2018-08-01T01:16:47.458100: step 22081, loss 0.579747.
Train: 2018-08-01T01:16:47.629935: step 22082, loss 0.545059.
Train: 2018-08-01T01:16:47.786118: step 22083, loss 0.510291.
Train: 2018-08-01T01:16:47.957989: step 22084, loss 0.545018.
Train: 2018-08-01T01:16:48.114197: step 22085, loss 0.614731.
Train: 2018-08-01T01:16:48.270404: step 22086, loss 0.492639.
Train: 2018-08-01T01:16:48.426624: step 22087, loss 0.527487.
Train: 2018-08-01T01:16:48.582807: step 22088, loss 0.59746.
Train: 2018-08-01T01:16:48.739019: step 22089, loss 0.667611.
Train: 2018-08-01T01:16:48.895263: step 22090, loss 0.457331.
Test: 2018-08-01T01:16:49.363903: step 22090, loss 0.54777.
Train: 2018-08-01T01:16:49.520087: step 22091, loss 0.544918.
Train: 2018-08-01T01:16:49.676333: step 22092, loss 0.492247.
Train: 2018-08-01T01:16:49.832514: step 22093, loss 0.597634.
Train: 2018-08-01T01:16:50.004379: step 22094, loss 0.580075.
Train: 2018-08-01T01:16:50.176183: step 22095, loss 0.439199.
Train: 2018-08-01T01:16:50.332427: step 22096, loss 0.509551.
Train: 2018-08-01T01:16:50.488640: step 22097, loss 0.580196.
Train: 2018-08-01T01:16:50.644825: step 22098, loss 0.509357.
Train: 2018-08-01T01:16:50.801038: step 22099, loss 0.598059.
Train: 2018-08-01T01:16:50.957281: step 22100, loss 0.651482.
Test: 2018-08-01T01:16:51.425921: step 22100, loss 0.547656.
Train: 2018-08-01T01:16:52.128852: step 22101, loss 0.562551.
Train: 2018-08-01T01:16:52.300712: step 22102, loss 0.562551.
Train: 2018-08-01T01:16:52.441309: step 22103, loss 0.509192.
Train: 2018-08-01T01:16:52.613147: step 22104, loss 0.54476.
Train: 2018-08-01T01:16:52.769326: step 22105, loss 0.651575.
Train: 2018-08-01T01:16:52.925572: step 22106, loss 0.562552.
Train: 2018-08-01T01:16:53.081754: step 22107, loss 0.562546.
Train: 2018-08-01T01:16:53.237967: step 22108, loss 0.562539.
Train: 2018-08-01T01:16:53.409843: step 22109, loss 0.562533.
Train: 2018-08-01T01:16:53.566015: step 22110, loss 0.527059.
Test: 2018-08-01T01:16:54.050307: step 22110, loss 0.547679.
Train: 2018-08-01T01:16:54.206490: step 22111, loss 0.562523.
Train: 2018-08-01T01:16:54.378325: step 22112, loss 0.45621.
Train: 2018-08-01T01:16:54.534538: step 22113, loss 0.615723.
Train: 2018-08-01T01:16:54.690751: step 22114, loss 0.491598.
Train: 2018-08-01T01:16:54.862611: step 22115, loss 0.615767.
Train: 2018-08-01T01:16:55.018833: step 22116, loss 0.562531.
Train: 2018-08-01T01:16:55.175038: step 22117, loss 0.651234.
Train: 2018-08-01T01:16:55.331227: step 22118, loss 0.544802.
Train: 2018-08-01T01:16:55.487440: step 22119, loss 0.474021.
Train: 2018-08-01T01:16:55.674895: step 22120, loss 0.615607.
Test: 2018-08-01T01:16:56.143566: step 22120, loss 0.547696.
Train: 2018-08-01T01:16:56.299749: step 22121, loss 0.527134.
Train: 2018-08-01T01:16:56.455994: step 22122, loss 0.615545.
Train: 2018-08-01T01:16:56.612207: step 22123, loss 0.65081.
Train: 2018-08-01T01:16:56.799632: step 22124, loss 0.632985.
Train: 2018-08-01T01:16:56.955847: step 22125, loss 0.615192.
Train: 2018-08-01T01:16:57.112084: step 22126, loss 0.474863.
Train: 2018-08-01T01:16:57.268297: step 22127, loss 0.667339.
Train: 2018-08-01T01:16:57.440108: step 22128, loss 0.475285.
Train: 2018-08-01T01:16:57.596354: step 22129, loss 0.545023.
Train: 2018-08-01T01:16:57.752535: step 22130, loss 0.52767.
Test: 2018-08-01T01:16:58.236826: step 22130, loss 0.547879.
Train: 2018-08-01T01:16:58.377388: step 22131, loss 0.579773.
Train: 2018-08-01T01:16:58.549254: step 22132, loss 0.51039.
Train: 2018-08-01T01:16:58.705437: step 22133, loss 0.562411.
Train: 2018-08-01T01:16:58.892892: step 22134, loss 0.614402.
Train: 2018-08-01T01:16:59.049137: step 22135, loss 0.614349.
Train: 2018-08-01T01:16:59.189728: step 22136, loss 0.562405.
Train: 2018-08-01T01:16:59.345942: step 22137, loss 0.579665.
Train: 2018-08-01T01:16:59.502155: step 22138, loss 0.545166.
Train: 2018-08-01T01:16:59.658369: step 22139, loss 0.579615.
Train: 2018-08-01T01:16:59.830197: step 22140, loss 0.596784.
Test: 2018-08-01T01:17:00.298845: step 22140, loss 0.548026.
Train: 2018-08-01T01:17:00.455057: step 22141, loss 0.545234.
Train: 2018-08-01T01:17:00.611240: step 22142, loss 0.596685.
Train: 2018-08-01T01:17:00.767483: step 22143, loss 0.579516.
Train: 2018-08-01T01:17:00.939288: step 22144, loss 0.562401.
Train: 2018-08-01T01:17:01.111123: step 22145, loss 0.528276.
Train: 2018-08-01T01:17:01.251716: step 22146, loss 0.562403.
Train: 2018-08-01T01:17:01.407928: step 22147, loss 0.596476.
Train: 2018-08-01T01:17:01.564143: step 22148, loss 0.579423.
Train: 2018-08-01T01:17:01.720355: step 22149, loss 0.596402.
Train: 2018-08-01T01:17:01.876568: step 22150, loss 0.579383.
Test: 2018-08-01T01:17:02.345239: step 22150, loss 0.548227.
Train: 2018-08-01T01:17:02.501422: step 22151, loss 0.528528.
Train: 2018-08-01T01:17:02.657672: step 22152, loss 0.596277.
Train: 2018-08-01T01:17:02.813879: step 22153, loss 0.630054.
Train: 2018-08-01T01:17:02.985715: step 22154, loss 0.461186.
Train: 2018-08-01T01:17:03.141925: step 22155, loss 0.528695.
Train: 2018-08-01T01:17:03.313733: step 22156, loss 0.646785.
Train: 2018-08-01T01:17:03.469976: step 22157, loss 0.596144.
Train: 2018-08-01T01:17:03.641805: step 22158, loss 0.528771.
Train: 2018-08-01T01:17:03.798025: step 22159, loss 0.528794.
Train: 2018-08-01T01:17:03.954208: step 22160, loss 0.596088.
Test: 2018-08-01T01:17:04.438498: step 22160, loss 0.548362.
Train: 2018-08-01T01:17:04.594712: step 22161, loss 0.629709.
Train: 2018-08-01T01:17:04.766547: step 22162, loss 0.562449.
Train: 2018-08-01T01:17:04.922731: step 22163, loss 0.495345.
Train: 2018-08-01T01:17:05.078976: step 22164, loss 0.495342.
Train: 2018-08-01T01:17:05.250809: step 22165, loss 0.59604.
Train: 2018-08-01T01:17:05.422646: step 22166, loss 0.596055.
Train: 2018-08-01T01:17:05.578863: step 22167, loss 0.512029.
Train: 2018-08-01T01:17:05.735071: step 22168, loss 0.495164.
Train: 2018-08-01T01:17:05.891284: step 22169, loss 0.579284.
Train: 2018-08-01T01:17:06.063113: step 22170, loss 0.56243.
Test: 2018-08-01T01:17:06.516136: step 22170, loss 0.548278.
Train: 2018-08-01T01:17:06.672321: step 22171, loss 0.545531.
Train: 2018-08-01T01:17:06.828535: step 22172, loss 0.511665.
Train: 2018-08-01T01:17:06.984747: step 22173, loss 0.613274.
Train: 2018-08-01T01:17:07.140960: step 22174, loss 0.579385.
Train: 2018-08-01T01:17:07.297205: step 22175, loss 0.579397.
Train: 2018-08-01T01:17:07.453387: step 22176, loss 0.477423.
Train: 2018-08-01T01:17:07.625222: step 22177, loss 0.494301.
Train: 2018-08-01T01:17:07.781472: step 22178, loss 0.511198.
Train: 2018-08-01T01:17:07.937680: step 22179, loss 0.596635.
Train: 2018-08-01T01:17:08.093862: step 22180, loss 0.528089.
Test: 2018-08-01T01:17:08.562534: step 22180, loss 0.547999.
Train: 2018-08-01T01:17:08.718716: step 22181, loss 0.562399.
Train: 2018-08-01T01:17:08.874965: step 22182, loss 0.493468.
Train: 2018-08-01T01:17:09.031174: step 22183, loss 0.510559.
Train: 2018-08-01T01:17:09.187392: step 22184, loss 0.649098.
Train: 2018-08-01T01:17:09.343600: step 22185, loss 0.545049.
Train: 2018-08-01T01:17:09.499815: step 22186, loss 0.614612.
Train: 2018-08-01T01:17:09.656028: step 22187, loss 0.562423.
Train: 2018-08-01T01:17:09.843453: step 22188, loss 0.562426.
Train: 2018-08-01T01:17:09.984075: step 22189, loss 0.52756.
Train: 2018-08-01T01:17:10.140258: step 22190, loss 0.475181.
Test: 2018-08-01T01:17:10.608898: step 22190, loss 0.547799.
Train: 2018-08-01T01:17:10.765112: step 22191, loss 0.56244.
Train: 2018-08-01T01:17:10.936947: step 22192, loss 0.509909.
Train: 2018-08-01T01:17:11.077540: step 22193, loss 0.615106.
Train: 2018-08-01T01:17:11.233753: step 22194, loss 0.509754.
Train: 2018-08-01T01:17:11.389965: step 22195, loss 0.580072.
Train: 2018-08-01T01:17:11.546210: step 22196, loss 0.527242.
Train: 2018-08-01T01:17:11.718044: step 22197, loss 0.668355.
Train: 2018-08-01T01:17:11.874258: step 22198, loss 0.633056.
Train: 2018-08-01T01:17:12.030441: step 22199, loss 0.456747.
Train: 2018-08-01T01:17:12.186654: step 22200, loss 0.668245.
Test: 2018-08-01T01:17:12.655325: step 22200, loss 0.547733.
Train: 2018-08-01T01:17:13.389498: step 22201, loss 0.509657.
Train: 2018-08-01T01:17:13.545711: step 22202, loss 0.615267.
Train: 2018-08-01T01:17:13.701926: step 22203, loss 0.632776.
Train: 2018-08-01T01:17:13.858168: step 22204, loss 0.527371.
Train: 2018-08-01T01:17:14.014381: step 22205, loss 0.457347.
Train: 2018-08-01T01:17:14.186186: step 22206, loss 0.492381.
Train: 2018-08-01T01:17:14.326808: step 22207, loss 0.68517.
Train: 2018-08-01T01:17:14.482992: step 22208, loss 0.527417.
Train: 2018-08-01T01:17:14.639236: step 22209, loss 0.562446.
Train: 2018-08-01T01:17:14.811039: step 22210, loss 0.544943.
Test: 2018-08-01T01:17:15.295318: step 22210, loss 0.547791.
Train: 2018-08-01T01:17:15.435923: step 22211, loss 0.57994.
Train: 2018-08-01T01:17:15.592106: step 22212, loss 0.509976.
Train: 2018-08-01T01:17:15.748320: step 22213, loss 0.562441.
Train: 2018-08-01T01:17:15.904534: step 22214, loss 0.632415.
Train: 2018-08-01T01:17:16.060747: step 22215, loss 0.510004.
Train: 2018-08-01T01:17:16.216960: step 22216, loss 0.544962.
Train: 2018-08-01T01:17:16.388822: step 22217, loss 0.597389.
Train: 2018-08-01T01:17:16.545039: step 22218, loss 0.59737.
Train: 2018-08-01T01:17:16.701252: step 22219, loss 0.510078.
Train: 2018-08-01T01:17:16.857466: step 22220, loss 0.562431.
Test: 2018-08-01T01:17:17.326106: step 22220, loss 0.547823.
Train: 2018-08-01T01:17:17.497913: step 22221, loss 0.527544.
Train: 2018-08-01T01:17:17.654148: step 22222, loss 0.544984.
Train: 2018-08-01T01:17:17.810337: step 22223, loss 0.614788.
Train: 2018-08-01T01:17:17.966581: step 22224, loss 0.544985.
Train: 2018-08-01T01:17:18.122764: step 22225, loss 0.510106.
Train: 2018-08-01T01:17:18.279009: step 22226, loss 0.597329.
Train: 2018-08-01T01:17:18.435222: step 22227, loss 0.492643.
Train: 2018-08-01T01:17:18.622647: step 22228, loss 0.527513.
Train: 2018-08-01T01:17:18.763240: step 22229, loss 0.510001.
Train: 2018-08-01T01:17:18.919453: step 22230, loss 0.509924.
Test: 2018-08-01T01:17:19.388117: step 22230, loss 0.547765.
Train: 2018-08-01T01:17:19.544331: step 22231, loss 0.615084.
Train: 2018-08-01T01:17:19.716141: step 22232, loss 0.615148.
Train: 2018-08-01T01:17:19.872354: step 22233, loss 0.615162.
Train: 2018-08-01T01:17:20.028599: step 22234, loss 0.56246.
Train: 2018-08-01T01:17:20.184812: step 22235, loss 0.667744.
Train: 2018-08-01T01:17:20.340995: step 22236, loss 0.45736.
Train: 2018-08-01T01:17:20.497208: step 22237, loss 0.527431.
Train: 2018-08-01T01:17:20.653421: step 22238, loss 0.527431.
Train: 2018-08-01T01:17:20.825286: step 22239, loss 0.597476.
Train: 2018-08-01T01:17:20.981501: step 22240, loss 0.544935.
Test: 2018-08-01T01:17:21.450109: step 22240, loss 0.547782.
Train: 2018-08-01T01:17:21.606354: step 22241, loss 0.579958.
Train: 2018-08-01T01:17:21.778194: step 22242, loss 0.649982.
Train: 2018-08-01T01:17:21.949992: step 22243, loss 0.64985.
Train: 2018-08-01T01:17:22.106206: step 22244, loss 0.527551.
Train: 2018-08-01T01:17:22.262419: step 22245, loss 0.701681.
Train: 2018-08-01T01:17:22.418633: step 22246, loss 0.493026.
Train: 2018-08-01T01:17:22.574877: step 22247, loss 0.579714.
Train: 2018-08-01T01:17:22.731090: step 22248, loss 0.562403.
Train: 2018-08-01T01:17:22.887273: step 22249, loss 0.5624.
Train: 2018-08-01T01:17:23.059134: step 22250, loss 0.562399.
Test: 2018-08-01T01:17:23.543401: step 22250, loss 0.548022.
Train: 2018-08-01T01:17:23.699614: step 22251, loss 0.459391.
Train: 2018-08-01T01:17:23.855827: step 22252, loss 0.648221.
Train: 2018-08-01T01:17:24.027632: step 22253, loss 0.613824.
Train: 2018-08-01T01:17:24.183878: step 22254, loss 0.511069.
Train: 2018-08-01T01:17:24.340089: step 22255, loss 0.579493.
Train: 2018-08-01T01:17:24.496302: step 22256, loss 0.664845.
Train: 2018-08-01T01:17:24.668130: step 22257, loss 0.613505.
Train: 2018-08-01T01:17:24.824350: step 22258, loss 0.56241.
Train: 2018-08-01T01:17:24.980563: step 22259, loss 0.647131.
Train: 2018-08-01T01:17:25.136748: step 22260, loss 0.511769.
Test: 2018-08-01T01:17:25.621033: step 22260, loss 0.548328.
Train: 2018-08-01T01:17:25.761631: step 22261, loss 0.545589.
Train: 2018-08-01T01:17:25.933436: step 22262, loss 0.680158.
Train: 2018-08-01T01:17:26.089648: step 22263, loss 0.579221.
Train: 2018-08-01T01:17:26.261514: step 22264, loss 0.412069.
Train: 2018-08-01T01:17:26.417728: step 22265, loss 0.478965.
Train: 2018-08-01T01:17:26.573946: step 22266, loss 0.579189.
Train: 2018-08-01T01:17:26.730154: step 22267, loss 0.629368.
Train: 2018-08-01T01:17:26.886367: step 22268, loss 0.529037.
Train: 2018-08-01T01:17:27.042581: step 22269, loss 0.478864.
Train: 2018-08-01T01:17:27.198795: step 22270, loss 0.562463.
Test: 2018-08-01T01:17:27.683042: step 22270, loss 0.548415.
Train: 2018-08-01T01:17:27.839269: step 22271, loss 0.663067.
Train: 2018-08-01T01:17:27.995485: step 22272, loss 0.528924.
Train: 2018-08-01T01:17:28.151665: step 22273, loss 0.562455.
Train: 2018-08-01T01:17:28.307879: step 22274, loss 0.562452.
Train: 2018-08-01T01:17:28.479715: step 22275, loss 0.59603.
Train: 2018-08-01T01:17:28.651580: step 22276, loss 0.579241.
Train: 2018-08-01T01:17:28.807792: step 22277, loss 0.629605.
Train: 2018-08-01T01:17:28.979627: step 22278, loss 0.528911.
Train: 2018-08-01T01:17:29.135810: step 22279, loss 0.595989.
Train: 2018-08-01T01:17:29.292025: step 22280, loss 0.528953.
Test: 2018-08-01T01:17:29.760663: step 22280, loss 0.548433.
Train: 2018-08-01T01:17:29.932529: step 22281, loss 0.478699.
Train: 2018-08-01T01:17:30.088713: step 22282, loss 0.595999.
Train: 2018-08-01T01:17:30.244957: step 22283, loss 0.596017.
Train: 2018-08-01T01:17:30.401170: step 22284, loss 0.49531.
Train: 2018-08-01T01:17:30.573004: step 22285, loss 0.730495.
Train: 2018-08-01T01:17:30.744833: step 22286, loss 0.629589.
Train: 2018-08-01T01:17:30.901022: step 22287, loss 0.612715.
Train: 2018-08-01T01:17:31.057265: step 22288, loss 0.42879.
Train: 2018-08-01T01:17:31.213479: step 22289, loss 0.529062.
Train: 2018-08-01T01:17:31.385284: step 22290, loss 0.612613.
Test: 2018-08-01T01:17:31.853954: step 22290, loss 0.548485.
Train: 2018-08-01T01:17:32.010167: step 22291, loss 0.52906.
Train: 2018-08-01T01:17:32.182002: step 22292, loss 0.5959.
Train: 2018-08-01T01:17:32.322594: step 22293, loss 0.629316.
Train: 2018-08-01T01:17:32.478809: step 22294, loss 0.579175.
Train: 2018-08-01T01:17:32.635021: step 22295, loss 0.562487.
Train: 2018-08-01T01:17:32.791235: step 22296, loss 0.579155.
Train: 2018-08-01T01:17:32.978684: step 22297, loss 0.695678.
Train: 2018-08-01T01:17:33.119283: step 22298, loss 0.57912.
Train: 2018-08-01T01:17:33.275497: step 22299, loss 0.512846.
Train: 2018-08-01T01:17:33.447326: step 22300, loss 0.546007.
Test: 2018-08-01T01:17:33.915994: step 22300, loss 0.548716.
Train: 2018-08-01T01:17:34.618901: step 22301, loss 0.529506.
Train: 2018-08-01T01:17:34.775150: step 22302, loss 0.612114.
Train: 2018-08-01T01:17:34.931359: step 22303, loss 0.546056.
Train: 2018-08-01T01:17:35.134430: step 22304, loss 0.480067.
Train: 2018-08-01T01:17:35.290644: step 22305, loss 0.479979.
Train: 2018-08-01T01:17:35.446863: step 22306, loss 0.612194.
Train: 2018-08-01T01:17:35.603076: step 22307, loss 0.645399.
Train: 2018-08-01T01:17:35.759290: step 22308, loss 0.678562.
Train: 2018-08-01T01:17:35.931094: step 22309, loss 0.595645.
Train: 2018-08-01T01:17:36.087338: step 22310, loss 0.49645.
Test: 2018-08-01T01:17:36.555978: step 22310, loss 0.548723.
Train: 2018-08-01T01:17:36.712161: step 22311, loss 0.562556.
Train: 2018-08-01T01:17:36.868408: step 22312, loss 0.546043.
Train: 2018-08-01T01:17:37.024619: step 22313, loss 0.579073.
Train: 2018-08-01T01:17:37.196425: step 22314, loss 0.645138.
Train: 2018-08-01T01:17:37.368257: step 22315, loss 0.645058.
Train: 2018-08-01T01:17:37.524495: step 22316, loss 0.463794.
Train: 2018-08-01T01:17:37.680716: step 22317, loss 0.595506.
Train: 2018-08-01T01:17:37.836898: step 22318, loss 0.562591.
Train: 2018-08-01T01:17:37.993141: step 22319, loss 0.562595.
Train: 2018-08-01T01:17:38.149349: step 22320, loss 0.496838.
Test: 2018-08-01T01:17:38.617964: step 22320, loss 0.548811.
Train: 2018-08-01T01:17:38.774210: step 22321, loss 0.546135.
Train: 2018-08-01T01:17:38.930423: step 22322, loss 0.628471.
Train: 2018-08-01T01:17:39.102226: step 22323, loss 0.480194.
Train: 2018-08-01T01:17:39.258439: step 22324, loss 0.694575.
Train: 2018-08-01T01:17:39.430303: step 22325, loss 0.562568.
Train: 2018-08-01T01:17:39.586489: step 22326, loss 0.59555.
Train: 2018-08-01T01:17:39.742732: step 22327, loss 0.546095.
Train: 2018-08-01T01:17:39.898946: step 22328, loss 0.480188.
Train: 2018-08-01T01:17:40.055158: step 22329, loss 0.579063.
Train: 2018-08-01T01:17:40.211341: step 22330, loss 0.446973.
Test: 2018-08-01T01:17:40.711224: step 22330, loss 0.548675.
Train: 2018-08-01T01:17:40.867468: step 22331, loss 0.579093.
Train: 2018-08-01T01:17:41.023682: step 22332, loss 0.545929.
Train: 2018-08-01T01:17:41.179866: step 22333, loss 0.595766.
Train: 2018-08-01T01:17:41.336108: step 22334, loss 0.545834.
Train: 2018-08-01T01:17:41.492322: step 22335, loss 0.462338.
Train: 2018-08-01T01:17:41.664141: step 22336, loss 0.612694.
Train: 2018-08-01T01:17:41.820341: step 22337, loss 0.545672.
Train: 2018-08-01T01:17:41.976584: step 22338, loss 0.545623.
Train: 2018-08-01T01:17:42.132766: step 22339, loss 0.511856.
Train: 2018-08-01T01:17:42.288980: step 22340, loss 0.579329.
Test: 2018-08-01T01:17:42.757620: step 22340, loss 0.548223.
Train: 2018-08-01T01:17:42.913865: step 22341, loss 0.511572.
Train: 2018-08-01T01:17:43.070047: step 22342, loss 0.494423.
Train: 2018-08-01T01:17:43.226291: step 22343, loss 0.562402.
Train: 2018-08-01T01:17:43.382475: step 22344, loss 0.562399.
Train: 2018-08-01T01:17:43.554308: step 22345, loss 0.545238.
Train: 2018-08-01T01:17:43.710552: step 22346, loss 0.476361.
Train: 2018-08-01T01:17:43.882382: step 22347, loss 0.579673.
Train: 2018-08-01T01:17:44.038602: step 22348, loss 0.510441.
Train: 2018-08-01T01:17:44.179162: step 22349, loss 0.527656.
Train: 2018-08-01T01:17:44.350997: step 22350, loss 0.562429.
Test: 2018-08-01T01:17:44.819668: step 22350, loss 0.547793.
Train: 2018-08-01T01:17:44.991497: step 22351, loss 0.614921.
Train: 2018-08-01T01:17:45.147717: step 22352, loss 0.579979.
Train: 2018-08-01T01:17:45.303929: step 22353, loss 0.52735.
Train: 2018-08-01T01:17:45.460142: step 22354, loss 0.65039.
Train: 2018-08-01T01:17:45.616325: step 22355, loss 0.509697.
Train: 2018-08-01T01:17:45.772541: step 22356, loss 0.703332.
Train: 2018-08-01T01:17:45.928782: step 22357, loss 0.386581.
Train: 2018-08-01T01:17:46.116233: step 22358, loss 0.527256.
Train: 2018-08-01T01:17:46.272422: step 22359, loss 0.650666.
Train: 2018-08-01T01:17:46.428635: step 22360, loss 0.562487.
Test: 2018-08-01T01:17:46.897275: step 22360, loss 0.547716.
Train: 2018-08-01T01:17:47.053489: step 22361, loss 0.615404.
Train: 2018-08-01T01:17:47.240976: step 22362, loss 0.439098.
Train: 2018-08-01T01:17:47.397190: step 22363, loss 0.544847.
Train: 2018-08-01T01:17:47.553373: step 22364, loss 0.52718.
Train: 2018-08-01T01:17:47.709616: step 22365, loss 0.650886.
Train: 2018-08-01T01:17:47.881421: step 22366, loss 0.474129.
Train: 2018-08-01T01:17:48.037664: step 22367, loss 0.527127.
Train: 2018-08-01T01:17:48.193849: step 22368, loss 0.456256.
Train: 2018-08-01T01:17:48.365707: step 22369, loss 0.598032.
Train: 2018-08-01T01:17:48.521927: step 22370, loss 0.49144.
Test: 2018-08-01T01:17:48.990566: step 22370, loss 0.547646.
Train: 2018-08-01T01:17:49.146780: step 22371, loss 0.526935.
Train: 2018-08-01T01:17:49.318610: step 22372, loss 0.580436.
Train: 2018-08-01T01:17:49.474828: step 22373, loss 0.544716.
Train: 2018-08-01T01:17:49.631041: step 22374, loss 0.544703.
Train: 2018-08-01T01:17:49.787249: step 22375, loss 0.634386.
Train: 2018-08-01T01:17:49.943468: step 22376, loss 0.652362.
Train: 2018-08-01T01:17:50.099682: step 22377, loss 0.437118.
Train: 2018-08-01T01:17:50.255865: step 22378, loss 0.580572.
Train: 2018-08-01T01:17:50.412108: step 22379, loss 0.490859.
Train: 2018-08-01T01:17:50.568322: step 22380, loss 0.490803.
Test: 2018-08-01T01:17:51.036931: step 22380, loss 0.547598.
Train: 2018-08-01T01:17:51.208765: step 22381, loss 0.526685.
Train: 2018-08-01T01:17:51.364979: step 22382, loss 0.490606.
Train: 2018-08-01T01:17:51.536840: step 22383, loss 0.544649.
Train: 2018-08-01T01:17:51.677437: step 22384, loss 0.580831.
Train: 2018-08-01T01:17:51.833650: step 22385, loss 0.562754.
Train: 2018-08-01T01:17:52.005485: step 22386, loss 0.617208.
Train: 2018-08-01T01:17:52.161668: step 22387, loss 0.653528.
Train: 2018-08-01T01:17:52.302291: step 22388, loss 0.544627.
Train: 2018-08-01T01:17:52.458474: step 22389, loss 0.598984.
Train: 2018-08-01T01:17:52.630335: step 22390, loss 0.508452.
Test: 2018-08-01T01:17:53.098978: step 22390, loss 0.547582.
Train: 2018-08-01T01:17:53.270783: step 22391, loss 0.526562.
Train: 2018-08-01T01:17:53.426996: step 22392, loss 0.580791.
Train: 2018-08-01T01:17:53.583211: step 22393, loss 0.454343.
Train: 2018-08-01T01:17:53.755045: step 22394, loss 0.580786.
Train: 2018-08-01T01:17:53.894606: step 22395, loss 0.616934.
Train: 2018-08-01T01:17:54.066438: step 22396, loss 0.49047.
Train: 2018-08-01T01:17:54.222655: step 22397, loss 0.653014.
Train: 2018-08-01T01:17:54.378834: step 22398, loss 0.634855.
Train: 2018-08-01T01:17:54.535048: step 22399, loss 0.634683.
Train: 2018-08-01T01:17:54.691261: step 22400, loss 0.526735.
Test: 2018-08-01T01:17:55.159902: step 22400, loss 0.547616.
Train: 2018-08-01T01:17:55.831619: step 22401, loss 0.598436.
Train: 2018-08-01T01:17:56.019076: step 22402, loss 0.562588.
Train: 2018-08-01T01:17:56.175289: step 22403, loss 0.526926.
Train: 2018-08-01T01:17:56.331533: step 22404, loss 0.526978.
Train: 2018-08-01T01:17:56.487741: step 22405, loss 0.562537.
Train: 2018-08-01T01:17:56.643963: step 22406, loss 0.651209.
Train: 2018-08-01T01:17:56.800143: step 22407, loss 0.615589.
Train: 2018-08-01T01:17:56.956356: step 22408, loss 0.544846.
Train: 2018-08-01T01:17:57.143837: step 22409, loss 0.615264.
Train: 2018-08-01T01:17:57.300056: step 22410, loss 0.45719.
Test: 2018-08-01T01:17:57.784317: step 22410, loss 0.547778.
Train: 2018-08-01T01:17:57.940500: step 22411, loss 0.597486.
Train: 2018-08-01T01:17:58.096714: step 22412, loss 0.632388.
Train: 2018-08-01T01:17:58.252960: step 22413, loss 0.579871.
Train: 2018-08-01T01:17:58.409148: step 22414, loss 0.545023.
Train: 2018-08-01T01:17:58.580975: step 22415, loss 0.649207.
Train: 2018-08-01T01:17:58.721567: step 22416, loss 0.597015.
Train: 2018-08-01T01:17:58.877811: step 22417, loss 0.545153.
Train: 2018-08-01T01:17:59.034024: step 22418, loss 0.4248.
Train: 2018-08-01T01:17:59.205831: step 22419, loss 0.63115.
Train: 2018-08-01T01:17:59.362044: step 22420, loss 0.648207.
Test: 2018-08-01T01:17:59.846335: step 22420, loss 0.548063.
Train: 2018-08-01T01:18:00.002551: step 22421, loss 0.528161.
Train: 2018-08-01T01:18:00.158755: step 22422, loss 0.664926.
Train: 2018-08-01T01:18:00.330567: step 22423, loss 0.511293.
Train: 2018-08-01T01:18:00.471158: step 22424, loss 0.528401.
Train: 2018-08-01T01:18:00.627371: step 22425, loss 0.596371.
Train: 2018-08-01T01:18:00.783617: step 22426, loss 0.511554.
Train: 2018-08-01T01:18:00.939800: step 22427, loss 0.596297.
Train: 2018-08-01T01:18:01.111663: step 22428, loss 0.528573.
Train: 2018-08-01T01:18:01.267880: step 22429, loss 0.59625.
Train: 2018-08-01T01:18:01.439683: step 22430, loss 0.511721.
Test: 2018-08-01T01:18:01.908351: step 22430, loss 0.548271.
Train: 2018-08-01T01:18:02.064565: step 22431, loss 0.528622.
Train: 2018-08-01T01:18:02.220779: step 22432, loss 0.528603.
Train: 2018-08-01T01:18:02.376961: step 22433, loss 0.596269.
Train: 2018-08-01T01:18:02.548796: step 22434, loss 0.511619.
Train: 2018-08-01T01:18:02.705034: step 22435, loss 0.613269.
Train: 2018-08-01T01:18:02.861253: step 22436, loss 0.562413.
Train: 2018-08-01T01:18:03.017470: step 22437, loss 0.59634.
Train: 2018-08-01T01:18:03.173650: step 22438, loss 0.54545.
Train: 2018-08-01T01:18:03.329893: step 22439, loss 0.630272.
Train: 2018-08-01T01:18:03.486078: step 22440, loss 0.698033.
Test: 2018-08-01T01:18:03.970369: step 22440, loss 0.548261.
Train: 2018-08-01T01:18:04.126577: step 22441, loss 0.613152.
Train: 2018-08-01T01:18:04.298417: step 22442, loss 0.613016.
Train: 2018-08-01T01:18:04.454625: step 22443, loss 0.646479.
Train: 2018-08-01T01:18:04.610844: step 22444, loss 0.595943.
Train: 2018-08-01T01:18:04.782649: step 22445, loss 0.612502.
Train: 2018-08-01T01:18:04.938862: step 22446, loss 0.529318.
Train: 2018-08-01T01:18:05.095075: step 22447, loss 0.512906.
Train: 2018-08-01T01:18:05.251319: step 22448, loss 0.628599.
Train: 2018-08-01T01:18:05.407533: step 22449, loss 0.546119.
Train: 2018-08-01T01:18:05.563740: step 22450, loss 0.579032.
Test: 2018-08-01T01:18:06.032355: step 22450, loss 0.548892.
Train: 2018-08-01T01:18:06.188568: step 22451, loss 0.628205.
Train: 2018-08-01T01:18:06.344813: step 22452, loss 0.464534.
Train: 2018-08-01T01:18:06.501026: step 22453, loss 0.546317.
Train: 2018-08-01T01:18:06.657241: step 22454, loss 0.578994.
Train: 2018-08-01T01:18:06.813453: step 22455, loss 0.530008.
Train: 2018-08-01T01:18:06.985296: step 22456, loss 0.627992.
Train: 2018-08-01T01:18:07.141472: step 22457, loss 0.611639.
Train: 2018-08-01T01:18:07.297685: step 22458, loss 0.513757.
Train: 2018-08-01T01:18:07.453922: step 22459, loss 0.546373.
Train: 2018-08-01T01:18:07.610141: step 22460, loss 0.644231.
Test: 2018-08-01T01:18:08.078751: step 22460, loss 0.549034.
Train: 2018-08-01T01:18:08.234995: step 22461, loss 0.546383.
Train: 2018-08-01T01:18:08.391212: step 22462, loss 0.595276.
Train: 2018-08-01T01:18:08.547392: step 22463, loss 0.595263.
Train: 2018-08-01T01:18:08.703636: step 22464, loss 0.578973.
Train: 2018-08-01T01:18:08.859849: step 22465, loss 0.530191.
Train: 2018-08-01T01:18:09.031653: step 22466, loss 0.497679.
Train: 2018-08-01T01:18:09.203488: step 22467, loss 0.546424.
Train: 2018-08-01T01:18:09.359702: step 22468, loss 0.530089.
Train: 2018-08-01T01:18:09.515916: step 22469, loss 0.578992.
Train: 2018-08-01T01:18:09.672128: step 22470, loss 0.61171.
Test: 2018-08-01T01:18:10.140802: step 22470, loss 0.548932.
Train: 2018-08-01T01:18:10.328255: step 22471, loss 0.54627.
Train: 2018-08-01T01:18:10.484468: step 22472, loss 0.579014.
Train: 2018-08-01T01:18:10.640676: step 22473, loss 0.562618.
Train: 2018-08-01T01:18:10.796865: step 22474, loss 0.595447.
Train: 2018-08-01T01:18:10.953109: step 22475, loss 0.579031.
Train: 2018-08-01T01:18:11.109293: step 22476, loss 0.546164.
Train: 2018-08-01T01:18:11.281127: step 22477, loss 0.595486.
Train: 2018-08-01T01:18:11.437371: step 22478, loss 0.628398.
Train: 2018-08-01T01:18:11.593584: step 22479, loss 0.562595.
Train: 2018-08-01T01:18:11.749766: step 22480, loss 0.628346.
Test: 2018-08-01T01:18:12.234058: step 22480, loss 0.548861.
Train: 2018-08-01T01:18:12.390243: step 22481, loss 0.496937.
Train: 2018-08-01T01:18:12.562076: step 22482, loss 0.464095.
Train: 2018-08-01T01:18:12.718320: step 22483, loss 0.595485.
Train: 2018-08-01T01:18:12.874504: step 22484, loss 0.579047.
Train: 2018-08-01T01:18:13.030747: step 22485, loss 0.66145.
Train: 2018-08-01T01:18:13.186966: step 22486, loss 0.496697.
Train: 2018-08-01T01:18:13.343176: step 22487, loss 0.546093.
Train: 2018-08-01T01:18:13.499360: step 22488, loss 0.513076.
Train: 2018-08-01T01:18:13.655600: step 22489, loss 0.546028.
Train: 2018-08-01T01:18:13.811814: step 22490, loss 0.529427.
Test: 2018-08-01T01:18:14.280454: step 22490, loss 0.548626.
Train: 2018-08-01T01:18:14.436638: step 22491, loss 0.67867.
Train: 2018-08-01T01:18:14.624127: step 22492, loss 0.529316.
Train: 2018-08-01T01:18:14.780308: step 22493, loss 0.612362.
Train: 2018-08-01T01:18:14.936521: step 22494, loss 0.57913.
Train: 2018-08-01T01:18:15.077144: step 22495, loss 0.562507.
Train: 2018-08-01T01:18:15.248978: step 22496, loss 0.545878.
Train: 2018-08-01T01:18:15.405192: step 22497, loss 0.429412.
Train: 2018-08-01T01:18:15.561393: step 22498, loss 0.512455.
Train: 2018-08-01T01:18:15.733247: step 22499, loss 0.595923.
Train: 2018-08-01T01:18:15.889423: step 22500, loss 0.495392.
Test: 2018-08-01T01:18:16.373713: step 22500, loss 0.548359.
Train: 2018-08-01T01:18:17.076644: step 22501, loss 0.444718.
Train: 2018-08-01T01:18:17.232858: step 22502, loss 0.545531.
Train: 2018-08-01T01:18:17.389105: step 22503, loss 0.443653.
Train: 2018-08-01T01:18:17.560905: step 22504, loss 0.477068.
Train: 2018-08-01T01:18:17.717150: step 22505, loss 0.57998.
Train: 2018-08-01T01:18:17.873368: step 22506, loss 0.562381.
Train: 2018-08-01T01:18:18.076411: step 22507, loss 0.545048.
Train: 2018-08-01T01:18:18.232656: step 22508, loss 0.614645.
Train: 2018-08-01T01:18:18.388837: step 22509, loss 0.667209.
Train: 2018-08-01T01:18:18.545075: step 22510, loss 0.667364.
Test: 2018-08-01T01:18:19.029342: step 22510, loss 0.547797.
Train: 2018-08-01T01:18:19.185525: step 22511, loss 0.492497.
Train: 2018-08-01T01:18:19.341777: step 22512, loss 0.562442.
Train: 2018-08-01T01:18:19.497953: step 22513, loss 0.614973.
Train: 2018-08-01T01:18:19.669812: step 22514, loss 0.562444.
Train: 2018-08-01T01:18:19.826025: step 22515, loss 0.492436.
Train: 2018-08-01T01:18:19.982244: step 22516, loss 0.439855.
Train: 2018-08-01T01:18:20.154087: step 22517, loss 0.562457.
Train: 2018-08-01T01:18:20.310298: step 22518, loss 0.580048.
Train: 2018-08-01T01:18:20.466507: step 22519, loss 0.509661.
Train: 2018-08-01T01:18:20.622720: step 22520, loss 0.597757.
Test: 2018-08-01T01:18:21.106951: step 22520, loss 0.547709.
Train: 2018-08-01T01:18:21.278786: step 22521, loss 0.456564.
Train: 2018-08-01T01:18:21.434998: step 22522, loss 0.52712.
Train: 2018-08-01T01:18:21.591237: step 22523, loss 0.54479.
Train: 2018-08-01T01:18:21.747456: step 22524, loss 0.580319.
Train: 2018-08-01T01:18:21.903669: step 22525, loss 0.473533.
Train: 2018-08-01T01:18:22.059853: step 22526, loss 0.455483.
Train: 2018-08-01T01:18:22.216067: step 22527, loss 0.616349.
Train: 2018-08-01T01:18:22.387901: step 22528, loss 0.544687.
Train: 2018-08-01T01:18:22.559735: step 22529, loss 0.508689.
Train: 2018-08-01T01:18:22.715949: step 22530, loss 0.52662.
Test: 2018-08-01T01:18:23.184619: step 22530, loss 0.547582.
Train: 2018-08-01T01:18:23.340831: step 22531, loss 0.418074.
Train: 2018-08-01T01:18:23.512662: step 22532, loss 0.762429.
Train: 2018-08-01T01:18:23.668850: step 22533, loss 0.526453.
Train: 2018-08-01T01:18:23.825064: step 22534, loss 0.544615.
Train: 2018-08-01T01:18:23.981277: step 22535, loss 0.599223.
Train: 2018-08-01T01:18:24.137525: step 22536, loss 0.489981.
Train: 2018-08-01T01:18:24.293735: step 22537, loss 0.471698.
Train: 2018-08-01T01:18:24.465539: step 22538, loss 0.581119.
Train: 2018-08-01T01:18:24.621753: step 22539, loss 0.508035.
Train: 2018-08-01T01:18:24.777991: step 22540, loss 0.544593.
Test: 2018-08-01T01:18:25.262260: step 22540, loss 0.547571.
Train: 2018-08-01T01:18:25.418441: step 22541, loss 0.69127.
Train: 2018-08-01T01:18:25.574655: step 22542, loss 0.489609.
Train: 2018-08-01T01:18:25.730867: step 22543, loss 0.636252.
Train: 2018-08-01T01:18:25.887081: step 22544, loss 0.526274.
Train: 2018-08-01T01:18:26.043327: step 22545, loss 0.489665.
Train: 2018-08-01T01:18:26.199533: step 22546, loss 0.58122.
Train: 2018-08-01T01:18:26.371343: step 22547, loss 0.489661.
Train: 2018-08-01T01:18:26.527587: step 22548, loss 0.526272.
Train: 2018-08-01T01:18:26.699391: step 22549, loss 0.526257.
Train: 2018-08-01T01:18:26.840014: step 22550, loss 0.67303.
Test: 2018-08-01T01:18:27.308654: step 22550, loss 0.547571.
Train: 2018-08-01T01:18:27.464867: step 22551, loss 0.489582.
Train: 2018-08-01T01:18:27.621075: step 22552, loss 0.54459.
Train: 2018-08-01T01:18:27.808506: step 22553, loss 0.507914.
Train: 2018-08-01T01:18:27.949099: step 22554, loss 0.526242.
Train: 2018-08-01T01:18:28.105312: step 22555, loss 0.654746.
Train: 2018-08-01T01:18:28.261559: step 22556, loss 0.581284.
Train: 2018-08-01T01:18:28.417768: step 22557, loss 0.63624.
Train: 2018-08-01T01:18:28.573983: step 22558, loss 0.636067.
Train: 2018-08-01T01:18:28.730195: step 22559, loss 0.599334.
Train: 2018-08-01T01:18:28.902000: step 22560, loss 0.653735.
Test: 2018-08-01T01:18:29.370640: step 22560, loss 0.547578.
Train: 2018-08-01T01:18:29.526854: step 22561, loss 0.598972.
Train: 2018-08-01T01:18:29.698690: step 22562, loss 0.508585.
Train: 2018-08-01T01:18:29.854903: step 22563, loss 0.598605.
Train: 2018-08-01T01:18:30.011116: step 22564, loss 0.544704.
Train: 2018-08-01T01:18:30.167354: step 22565, loss 0.47331.
Train: 2018-08-01T01:18:30.323573: step 22566, loss 0.616031.
Train: 2018-08-01T01:18:30.495378: step 22567, loss 0.669212.
Train: 2018-08-01T01:18:30.635969: step 22568, loss 0.580229.
Train: 2018-08-01T01:18:30.807834: step 22569, loss 0.562491.
Train: 2018-08-01T01:18:30.964048: step 22570, loss 0.492108.
Test: 2018-08-01T01:18:31.432688: step 22570, loss 0.54776.
Train: 2018-08-01T01:18:31.588901: step 22571, loss 0.474698.
Train: 2018-08-01T01:18:31.745085: step 22572, loss 0.527382.
Train: 2018-08-01T01:18:31.901299: step 22573, loss 0.49234.
Train: 2018-08-01T01:18:32.057542: step 22574, loss 0.615058.
Train: 2018-08-01T01:18:32.229384: step 22575, loss 0.693333.
Train: 2018-08-01T01:18:32.385593: step 22576, loss 0.527455.
Train: 2018-08-01T01:18:32.557424: step 22577, loss 0.597369.
Train: 2018-08-01T01:18:32.713638: step 22578, loss 0.47525.
Train: 2018-08-01T01:18:32.869820: step 22579, loss 0.492723.
Train: 2018-08-01T01:18:33.026034: step 22580, loss 0.579858.
Test: 2018-08-01T01:18:33.494705: step 22580, loss 0.547829.
Train: 2018-08-01T01:18:33.650889: step 22581, loss 0.544994.
Train: 2018-08-01T01:18:33.807102: step 22582, loss 0.544992.
Train: 2018-08-01T01:18:33.978936: step 22583, loss 0.440332.
Train: 2018-08-01T01:18:34.135149: step 22584, loss 0.597386.
Train: 2018-08-01T01:18:34.291397: step 22585, loss 0.544946.
Train: 2018-08-01T01:18:34.447576: step 22586, loss 0.632512.
Train: 2018-08-01T01:18:34.603821: step 22587, loss 0.544929.
Train: 2018-08-01T01:18:34.760004: step 22588, loss 0.544926.
Train: 2018-08-01T01:18:34.916241: step 22589, loss 0.685166.
Train: 2018-08-01T01:18:35.088053: step 22590, loss 0.49241.
Test: 2018-08-01T01:18:35.556722: step 22590, loss 0.547786.
Train: 2018-08-01T01:18:35.712936: step 22591, loss 0.49243.
Train: 2018-08-01T01:18:35.869152: step 22592, loss 0.509906.
Train: 2018-08-01T01:18:36.025362: step 22593, loss 0.562452.
Train: 2018-08-01T01:18:36.181575: step 22594, loss 0.474708.
Train: 2018-08-01T01:18:36.353406: step 22595, loss 0.632799.
Train: 2018-08-01T01:18:36.509624: step 22596, loss 0.562471.
Train: 2018-08-01T01:18:36.697074: step 22597, loss 0.615294.
Train: 2018-08-01T01:18:36.853263: step 22598, loss 0.527268.
Train: 2018-08-01T01:18:36.993886: step 22599, loss 0.580081.
Train: 2018-08-01T01:18:37.165720: step 22600, loss 0.404044.
Test: 2018-08-01T01:18:37.634359: step 22600, loss 0.547718.
Train: 2018-08-01T01:18:38.306078: step 22601, loss 0.491945.
Train: 2018-08-01T01:18:38.462292: step 22602, loss 0.580179.
Train: 2018-08-01T01:18:38.618505: step 22603, loss 0.544804.
Train: 2018-08-01T01:18:38.821583: step 22604, loss 0.615757.
Train: 2018-08-01T01:18:38.977796: step 22605, loss 0.633568.
Train: 2018-08-01T01:18:39.134012: step 22606, loss 0.438253.
Train: 2018-08-01T01:18:39.290226: step 22607, loss 0.544768.
Train: 2018-08-01T01:18:39.446435: step 22608, loss 0.598152.
Train: 2018-08-01T01:18:39.602653: step 22609, loss 0.526942.
Train: 2018-08-01T01:18:39.758833: step 22610, loss 0.544743.
Test: 2018-08-01T01:18:40.243108: step 22610, loss 0.547637.
Train: 2018-08-01T01:18:40.399307: step 22611, loss 0.651773.
Train: 2018-08-01T01:18:40.555551: step 22612, loss 0.54474.
Train: 2018-08-01T01:18:40.711765: step 22613, loss 0.562569.
Train: 2018-08-01T01:18:40.867981: step 22614, loss 0.491284.
Train: 2018-08-01T01:18:41.039808: step 22615, loss 0.633882.
Train: 2018-08-01T01:18:41.196026: step 22616, loss 0.633834.
Train: 2018-08-01T01:18:41.352235: step 22617, loss 0.704874.
Train: 2018-08-01T01:18:41.508456: step 22618, loss 0.580257.
Train: 2018-08-01T01:18:41.664638: step 22619, loss 0.615527.
Train: 2018-08-01T01:18:41.820850: step 22620, loss 0.544866.
Test: 2018-08-01T01:18:42.305142: step 22620, loss 0.547758.
Train: 2018-08-01T01:18:42.461326: step 22621, loss 0.562458.
Train: 2018-08-01T01:18:42.633159: step 22622, loss 0.579946.
Train: 2018-08-01T01:18:42.789399: step 22623, loss 0.649689.
Train: 2018-08-01T01:18:42.945587: step 22624, loss 0.562417.
Train: 2018-08-01T01:18:43.101802: step 22625, loss 0.493111.
Train: 2018-08-01T01:18:43.273660: step 22626, loss 0.614258.
Train: 2018-08-01T01:18:43.414252: step 22627, loss 0.545163.
Train: 2018-08-01T01:18:43.586086: step 22628, loss 0.562398.
Train: 2018-08-01T01:18:43.742300: step 22629, loss 0.51091.
Train: 2018-08-01T01:18:43.898513: step 22630, loss 0.562397.
Test: 2018-08-01T01:18:44.367158: step 22630, loss 0.548058.
Train: 2018-08-01T01:18:44.523343: step 22631, loss 0.511025.
Train: 2018-08-01T01:18:44.679555: step 22632, loss 0.528158.
Train: 2018-08-01T01:18:44.835799: step 22633, loss 0.511027.
Train: 2018-08-01T01:18:44.991982: step 22634, loss 0.648093.
Train: 2018-08-01T01:18:45.148227: step 22635, loss 0.545264.
Train: 2018-08-01T01:18:45.320031: step 22636, loss 0.630927.
Train: 2018-08-01T01:18:45.460647: step 22637, loss 0.459704.
Train: 2018-08-01T01:18:45.616863: step 22638, loss 0.596647.
Train: 2018-08-01T01:18:45.773081: step 22639, loss 0.562398.
Train: 2018-08-01T01:18:45.929262: step 22640, loss 0.545273.
Test: 2018-08-01T01:18:46.397903: step 22640, loss 0.548054.
Train: 2018-08-01T01:18:46.554117: step 22641, loss 0.52814.
Train: 2018-08-01T01:18:46.710330: step 22642, loss 0.63096.
Train: 2018-08-01T01:18:46.866576: step 22643, loss 0.630939.
Train: 2018-08-01T01:18:47.022757: step 22644, loss 0.562398.
Train: 2018-08-01T01:18:47.179004: step 22645, loss 0.459816.
Train: 2018-08-01T01:18:47.350843: step 22646, loss 0.545294.
Train: 2018-08-01T01:18:47.507053: step 22647, loss 0.562398.
Train: 2018-08-01T01:18:47.663267: step 22648, loss 0.562398.
Train: 2018-08-01T01:18:47.819475: step 22649, loss 0.476727.
Train: 2018-08-01T01:18:47.975683: step 22650, loss 0.631044.
Test: 2018-08-01T01:18:48.444329: step 22650, loss 0.548019.
Train: 2018-08-01T01:18:48.616135: step 22651, loss 0.562397.
Train: 2018-08-01T01:18:48.756726: step 22652, loss 0.562397.
Train: 2018-08-01T01:18:48.912969: step 22653, loss 0.528024.
Train: 2018-08-01T01:18:49.084774: step 22654, loss 0.493594.
Train: 2018-08-01T01:18:49.240987: step 22655, loss 0.562399.
Train: 2018-08-01T01:18:49.397201: step 22656, loss 0.596911.
Train: 2018-08-01T01:18:49.553414: step 22657, loss 0.562402.
Train: 2018-08-01T01:18:49.709628: step 22658, loss 0.631535.
Train: 2018-08-01T01:18:49.865841: step 22659, loss 0.666074.
Train: 2018-08-01T01:18:50.022054: step 22660, loss 0.510649.
Test: 2018-08-01T01:18:50.490727: step 22660, loss 0.547966.
Train: 2018-08-01T01:18:50.646938: step 22661, loss 0.61411.
Train: 2018-08-01T01:18:50.834389: step 22662, loss 0.545186.
Train: 2018-08-01T01:18:50.990607: step 22663, loss 0.579592.
Train: 2018-08-01T01:18:51.146821: step 22664, loss 0.493701.
Train: 2018-08-01T01:18:51.303035: step 22665, loss 0.562397.
Train: 2018-08-01T01:18:51.459218: step 22666, loss 0.493721.
Train: 2018-08-01T01:18:51.615431: step 22667, loss 0.596762.
Train: 2018-08-01T01:18:51.771644: step 22668, loss 0.648331.
Train: 2018-08-01T01:18:51.943480: step 22669, loss 0.665422.
Train: 2018-08-01T01:18:52.099693: step 22670, loss 0.596663.
Test: 2018-08-01T01:18:52.568333: step 22670, loss 0.548087.
Train: 2018-08-01T01:18:52.755823: step 22671, loss 0.562399.
Train: 2018-08-01T01:18:52.912004: step 22672, loss 0.511242.
Train: 2018-08-01T01:18:53.083873: step 22673, loss 0.64756.
Train: 2018-08-01T01:18:53.240084: step 22674, loss 0.545415.
Train: 2018-08-01T01:18:53.396265: step 22675, loss 0.54545.
Train: 2018-08-01T01:18:53.552479: step 22676, loss 0.47772.
Train: 2018-08-01T01:18:53.708691: step 22677, loss 0.443845.
Train: 2018-08-01T01:18:53.864906: step 22678, loss 0.511511.
Train: 2018-08-01T01:18:54.021118: step 22679, loss 0.596414.
Train: 2018-08-01T01:18:54.192953: step 22680, loss 0.528343.
Test: 2018-08-01T01:18:54.661623: step 22680, loss 0.548113.
Train: 2018-08-01T01:18:54.833452: step 22681, loss 0.545338.
Train: 2018-08-01T01:18:54.989641: step 22682, loss 0.511113.
Train: 2018-08-01T01:18:55.145854: step 22683, loss 0.510987.
Train: 2018-08-01T01:18:55.302068: step 22684, loss 0.510838.
Train: 2018-08-01T01:18:55.458281: step 22685, loss 0.579642.
Train: 2018-08-01T01:18:55.614494: step 22686, loss 0.61427.
Train: 2018-08-01T01:18:55.770743: step 22687, loss 0.510452.
Train: 2018-08-01T01:18:55.926952: step 22688, loss 0.597125.
Train: 2018-08-01T01:18:56.083165: step 22689, loss 0.492889.
Train: 2018-08-01T01:18:56.270591: step 22690, loss 0.597264.
Test: 2018-08-01T01:18:56.739232: step 22690, loss 0.54782.
Train: 2018-08-01T01:18:56.895445: step 22691, loss 0.4752.
Train: 2018-08-01T01:18:57.051660: step 22692, loss 0.492488.
Train: 2018-08-01T01:18:57.207872: step 22693, loss 0.509833.
Train: 2018-08-01T01:18:57.379708: step 22694, loss 0.509677.
Train: 2018-08-01T01:18:57.535950: step 22695, loss 0.544833.
Train: 2018-08-01T01:18:57.692164: step 22696, loss 0.562518.
Train: 2018-08-01T01:18:57.848377: step 22697, loss 0.509228.
Train: 2018-08-01T01:18:58.004594: step 22698, loss 0.669531.
Train: 2018-08-01T01:18:58.160804: step 22699, loss 0.544729.
Train: 2018-08-01T01:18:58.317019: step 22700, loss 0.49109.
Test: 2018-08-01T01:18:58.785657: step 22700, loss 0.547615.
Train: 2018-08-01T01:18:59.519858: step 22701, loss 0.544703.
Train: 2018-08-01T01:18:59.676046: step 22702, loss 0.526744.
Train: 2018-08-01T01:18:59.832257: step 22703, loss 0.490732.
Train: 2018-08-01T01:18:59.988504: step 22704, loss 0.562685.
Train: 2018-08-01T01:19:00.144684: step 22705, loss 0.508517.
Train: 2018-08-01T01:19:00.316518: step 22706, loss 0.526525.
Train: 2018-08-01T01:19:00.472763: step 22707, loss 0.490163.
Train: 2018-08-01T01:19:00.628986: step 22708, loss 0.508198.
Train: 2018-08-01T01:19:00.800781: step 22709, loss 0.581123.
Train: 2018-08-01T01:19:00.956994: step 22710, loss 0.489677.
Test: 2018-08-01T01:19:01.425664: step 22710, loss 0.547572.
Train: 2018-08-01T01:19:01.581878: step 22711, loss 0.599657.
Train: 2018-08-01T01:19:01.738062: step 22712, loss 0.562975.
Train: 2018-08-01T01:19:01.909895: step 22713, loss 0.728774.
Train: 2018-08-01T01:19:02.066108: step 22714, loss 0.562988.
Train: 2018-08-01T01:19:02.222352: step 22715, loss 0.544584.
Train: 2018-08-01T01:19:02.378536: step 22716, loss 0.507839.
Train: 2018-08-01T01:19:02.534779: step 22717, loss 0.544586.
Train: 2018-08-01T01:19:02.690993: step 22718, loss 0.618042.
Train: 2018-08-01T01:19:02.862836: step 22719, loss 0.489554.
Train: 2018-08-01T01:19:03.003423: step 22720, loss 0.507909.
Test: 2018-08-01T01:19:03.472060: step 22720, loss 0.547571.
Train: 2018-08-01T01:19:03.628276: step 22721, loss 0.544588.
Train: 2018-08-01T01:19:03.800079: step 22722, loss 0.544587.
Train: 2018-08-01T01:19:03.956297: step 22723, loss 0.452831.
Train: 2018-08-01T01:19:04.112538: step 22724, loss 0.507835.
Train: 2018-08-01T01:19:04.268748: step 22725, loss 0.562987.
Train: 2018-08-01T01:19:04.424962: step 22726, loss 0.563009.
Train: 2018-08-01T01:19:04.581175: step 22727, loss 0.563025.
Train: 2018-08-01T01:19:04.737392: step 22728, loss 0.618402.
Train: 2018-08-01T01:19:04.893572: step 22729, loss 0.618379.
Train: 2018-08-01T01:19:05.081029: step 22730, loss 0.636726.
Test: 2018-08-01T01:19:05.549668: step 22730, loss 0.547574.
Train: 2018-08-01T01:19:05.705882: step 22731, loss 0.654927.
Train: 2018-08-01T01:19:05.862129: step 22732, loss 0.599587.
Train: 2018-08-01T01:19:06.033960: step 22733, loss 0.599405.
Train: 2018-08-01T01:19:06.190179: step 22734, loss 0.54461.
Train: 2018-08-01T01:19:06.346395: step 22735, loss 0.599044.
Train: 2018-08-01T01:19:06.502570: step 22736, loss 0.635014.
Train: 2018-08-01T01:19:06.658819: step 22737, loss 0.526672.
Train: 2018-08-01T01:19:06.815027: step 22738, loss 0.490897.
Train: 2018-08-01T01:19:06.971240: step 22739, loss 0.526825.
Train: 2018-08-01T01:19:07.127457: step 22740, loss 0.633995.
Test: 2018-08-01T01:19:07.611692: step 22740, loss 0.547648.
Train: 2018-08-01T01:19:07.767930: step 22741, loss 0.651579.
Train: 2018-08-01T01:19:07.924143: step 22742, loss 0.580265.
Train: 2018-08-01T01:19:08.080351: step 22743, loss 0.438782.
Train: 2018-08-01T01:19:08.252161: step 22744, loss 0.580129.
Train: 2018-08-01T01:19:08.408373: step 22745, loss 0.544867.
Train: 2018-08-01T01:19:08.564587: step 22746, loss 0.580044.
Train: 2018-08-01T01:19:08.720826: step 22747, loss 0.650197.
Train: 2018-08-01T01:19:08.892635: step 22748, loss 0.544942.
Train: 2018-08-01T01:19:09.033227: step 22749, loss 0.597349.
Train: 2018-08-01T01:19:09.189440: step 22750, loss 0.632074.
Test: 2018-08-01T01:19:09.658111: step 22750, loss 0.547879.
Train: 2018-08-01T01:19:09.814325: step 22751, loss 0.562412.
Train: 2018-08-01T01:19:09.970533: step 22752, loss 0.562405.
Train: 2018-08-01T01:19:10.126755: step 22753, loss 0.579656.
Train: 2018-08-01T01:19:10.282934: step 22754, loss 0.459151.
Train: 2018-08-01T01:19:10.439148: step 22755, loss 0.562397.
Train: 2018-08-01T01:19:10.610983: step 22756, loss 0.579569.
Train: 2018-08-01T01:19:10.767226: step 22757, loss 0.579549.
Train: 2018-08-01T01:19:10.923409: step 22758, loss 0.476742.
Train: 2018-08-01T01:19:11.079623: step 22759, loss 0.59666.
Train: 2018-08-01T01:19:11.235837: step 22760, loss 0.61377.
Test: 2018-08-01T01:19:11.704506: step 22760, loss 0.548074.
Train: 2018-08-01T01:19:11.860690: step 22761, loss 0.408444.
Train: 2018-08-01T01:19:12.016905: step 22762, loss 0.613773.
Train: 2018-08-01T01:19:12.173117: step 22763, loss 0.613789.
Train: 2018-08-01T01:19:12.329331: step 22764, loss 0.682265.
Train: 2018-08-01T01:19:12.485544: step 22765, loss 0.682031.
Train: 2018-08-01T01:19:12.641757: step 22766, loss 0.664599.
Train: 2018-08-01T01:19:12.829245: step 22767, loss 0.562412.
Train: 2018-08-01T01:19:12.985460: step 22768, loss 0.579315.
Train: 2018-08-01T01:19:13.141670: step 22769, loss 0.596093.
Train: 2018-08-01T01:19:13.297879: step 22770, loss 0.57922.
Test: 2018-08-01T01:19:13.766494: step 22770, loss 0.54849.
Train: 2018-08-01T01:19:13.938329: step 22771, loss 0.562476.
Train: 2018-08-01T01:19:14.094543: step 22772, loss 0.629094.
Train: 2018-08-01T01:19:14.250756: step 22773, loss 0.529347.
Train: 2018-08-01T01:19:14.422591: step 22774, loss 0.546002.
Train: 2018-08-01T01:19:14.578834: step 22775, loss 0.595572.
Train: 2018-08-01T01:19:14.735018: step 22776, loss 0.579048.
Train: 2018-08-01T01:19:14.891232: step 22777, loss 0.595463.
Train: 2018-08-01T01:19:15.063096: step 22778, loss 0.595409.
Train: 2018-08-01T01:19:15.219280: step 22779, loss 0.595353.
Train: 2018-08-01T01:19:15.375492: step 22780, loss 0.546362.
Test: 2018-08-01T01:19:15.844163: step 22780, loss 0.549061.
Train: 2018-08-01T01:19:16.015969: step 22781, loss 0.562694.
Train: 2018-08-01T01:19:16.172180: step 22782, loss 0.627736.
Train: 2018-08-01T01:19:16.328419: step 22783, loss 0.611399.
Train: 2018-08-01T01:19:16.484640: step 22784, loss 0.578947.
Train: 2018-08-01T01:19:16.640820: step 22785, loss 0.562797.
Train: 2018-08-01T01:19:16.797035: step 22786, loss 0.578933.
Train: 2018-08-01T01:19:16.953278: step 22787, loss 0.611092.
Train: 2018-08-01T01:19:17.125083: step 22788, loss 0.578923.
Train: 2018-08-01T01:19:17.281327: step 22789, loss 0.466805.
Train: 2018-08-01T01:19:17.437509: step 22790, loss 0.546888.
Test: 2018-08-01T01:19:17.921771: step 22790, loss 0.549481.
Train: 2018-08-01T01:19:18.077984: step 22791, loss 0.578919.
Train: 2018-08-01T01:19:18.249847: step 22792, loss 0.514809.
Train: 2018-08-01T01:19:18.406033: step 22793, loss 0.627068.
Train: 2018-08-01T01:19:18.546625: step 22794, loss 0.562869.
Train: 2018-08-01T01:19:18.718460: step 22795, loss 0.594988.
Train: 2018-08-01T01:19:18.874673: step 22796, loss 0.611058.
Train: 2018-08-01T01:19:19.030886: step 22797, loss 0.562864.
Train: 2018-08-01T01:19:19.187101: step 22798, loss 0.514687.
Train: 2018-08-01T01:19:19.343315: step 22799, loss 0.562853.
Train: 2018-08-01T01:19:19.499560: step 22800, loss 0.643286.
Test: 2018-08-01T01:19:19.983788: step 22800, loss 0.54937.
Train: 2018-08-01T01:19:20.686774: step 22801, loss 0.611103.
Train: 2018-08-01T01:19:20.842988: step 22802, loss 0.56285.
Train: 2018-08-01T01:19:20.999176: step 22803, loss 0.627137.
Train: 2018-08-01T01:19:21.155389: step 22804, loss 0.498663.
Train: 2018-08-01T01:19:21.311603: step 22805, loss 0.562868.
Train: 2018-08-01T01:19:21.467816: step 22806, loss 0.466495.
Train: 2018-08-01T01:19:21.655271: step 22807, loss 0.562835.
Train: 2018-08-01T01:19:21.811515: step 22808, loss 0.659571.
Train: 2018-08-01T01:19:21.967728: step 22809, loss 0.578937.
Train: 2018-08-01T01:19:22.123911: step 22810, loss 0.578939.
Test: 2018-08-01T01:19:22.608175: step 22810, loss 0.549268.
Train: 2018-08-01T01:19:22.764388: step 22811, loss 0.498196.
Train: 2018-08-01T01:19:22.920630: step 22812, loss 0.659811.
Train: 2018-08-01T01:19:23.076839: step 22813, loss 0.562772.
Train: 2018-08-01T01:19:23.248673: step 22814, loss 0.595124.
Train: 2018-08-01T01:19:23.404863: step 22815, loss 0.546593.
Train: 2018-08-01T01:19:23.561075: step 22816, loss 0.59513.
Train: 2018-08-01T01:19:23.717328: step 22817, loss 0.498036.
Train: 2018-08-01T01:19:23.873527: step 22818, loss 0.514146.
Train: 2018-08-01T01:19:24.029751: step 22819, loss 0.514026.
Train: 2018-08-01T01:19:24.201581: step 22820, loss 0.595252.
Test: 2018-08-01T01:19:24.670220: step 22820, loss 0.549014.
Train: 2018-08-01T01:19:24.842033: step 22821, loss 0.611609.
Train: 2018-08-01T01:19:24.998272: step 22822, loss 0.546327.
Train: 2018-08-01T01:19:25.154452: step 22823, loss 0.562643.
Train: 2018-08-01T01:19:25.310695: step 22824, loss 0.529858.
Train: 2018-08-01T01:19:25.466911: step 22825, loss 0.54619.
Train: 2018-08-01T01:19:25.623126: step 22826, loss 0.611952.
Train: 2018-08-01T01:19:25.779307: step 22827, loss 0.579053.
Train: 2018-08-01T01:19:25.951173: step 22828, loss 0.612055.
Train: 2018-08-01T01:19:26.107385: step 22829, loss 0.562562.
Train: 2018-08-01T01:19:26.263598: step 22830, loss 0.579069.
Test: 2018-08-01T01:19:26.732208: step 22830, loss 0.548723.
Train: 2018-08-01T01:19:26.888421: step 22831, loss 0.430413.
Train: 2018-08-01T01:19:27.060255: step 22832, loss 0.529423.
Train: 2018-08-01T01:19:27.216507: step 22833, loss 0.512711.
Train: 2018-08-01T01:19:27.372708: step 22834, loss 0.512527.
Train: 2018-08-01T01:19:27.513306: step 22835, loss 0.612624.
Train: 2018-08-01T01:19:27.685142: step 22836, loss 0.612746.
Train: 2018-08-01T01:19:27.841324: step 22837, loss 0.562448.
Train: 2018-08-01T01:19:27.997570: step 22838, loss 0.545619.
Train: 2018-08-01T01:19:28.200644: step 22839, loss 0.495025.
Train: 2018-08-01T01:19:28.356828: step 22840, loss 0.545527.
Test: 2018-08-01T01:19:28.825498: step 22840, loss 0.548229.
Train: 2018-08-01T01:19:28.981714: step 22841, loss 0.613237.
Train: 2018-08-01T01:19:29.153540: step 22842, loss 0.54544.
Train: 2018-08-01T01:19:29.325375: step 22843, loss 0.494405.
Train: 2018-08-01T01:19:29.481566: step 22844, loss 0.460136.
Train: 2018-08-01T01:19:29.653398: step 22845, loss 0.476856.
Train: 2018-08-01T01:19:29.809612: step 22846, loss 0.545211.
Train: 2018-08-01T01:19:29.965826: step 22847, loss 0.527881.
Train: 2018-08-01T01:19:30.122072: step 22848, loss 0.562409.
Train: 2018-08-01T01:19:30.278278: step 22849, loss 0.545019.
Train: 2018-08-01T01:19:30.450088: step 22850, loss 0.66721.
Test: 2018-08-01T01:19:30.918757: step 22850, loss 0.547791.
Train: 2018-08-01T01:19:31.090594: step 22851, loss 0.544946.
Train: 2018-08-01T01:19:31.246809: step 22852, loss 0.650078.
Train: 2018-08-01T01:19:31.403017: step 22853, loss 0.509852.
Train: 2018-08-01T01:19:31.559203: step 22854, loss 0.527355.
Train: 2018-08-01T01:19:31.715416: step 22855, loss 0.439455.
Train: 2018-08-01T01:19:31.871654: step 22856, loss 0.544859.
Train: 2018-08-01T01:19:32.027867: step 22857, loss 0.580159.
Train: 2018-08-01T01:19:32.184081: step 22858, loss 0.562509.
Train: 2018-08-01T01:19:32.340300: step 22859, loss 0.633435.
Train: 2018-08-01T01:19:32.496510: step 22860, loss 0.544788.
Test: 2018-08-01T01:19:32.980776: step 22860, loss 0.547668.
Train: 2018-08-01T01:19:33.152609: step 22861, loss 0.615772.
Train: 2018-08-01T01:19:33.308793: step 22862, loss 0.6335.
Train: 2018-08-01T01:19:33.465044: step 22863, loss 0.527076.
Train: 2018-08-01T01:19:33.636842: step 22864, loss 0.491682.
Train: 2018-08-01T01:19:33.777433: step 22865, loss 0.580223.
Train: 2018-08-01T01:19:33.933646: step 22866, loss 0.509393.
Train: 2018-08-01T01:19:34.089890: step 22867, loss 0.651081.
Train: 2018-08-01T01:19:34.246074: step 22868, loss 0.509415.
Train: 2018-08-01T01:19:34.402317: step 22869, loss 0.704061.
Train: 2018-08-01T01:19:34.558531: step 22870, loss 0.491862.
Test: 2018-08-01T01:19:35.042791: step 22870, loss 0.547715.
Train: 2018-08-01T01:19:35.199008: step 22871, loss 0.544847.
Train: 2018-08-01T01:19:35.355188: step 22872, loss 0.544856.
Train: 2018-08-01T01:19:35.511402: step 22873, loss 0.632935.
Train: 2018-08-01T01:19:35.667615: step 22874, loss 0.597643.
Train: 2018-08-01T01:19:35.839451: step 22875, loss 0.580012.
Train: 2018-08-01T01:19:35.995697: step 22876, loss 0.581134.
Train: 2018-08-01T01:19:36.151908: step 22877, loss 0.475025.
Train: 2018-08-01T01:19:36.308115: step 22878, loss 0.562434.
Train: 2018-08-01T01:19:36.464335: step 22879, loss 0.684611.
Train: 2018-08-01T01:19:36.620551: step 22880, loss 0.457944.
Test: 2018-08-01T01:19:37.089158: step 22880, loss 0.547849.
Train: 2018-08-01T01:19:37.245404: step 22881, loss 0.597217.
Train: 2018-08-01T01:19:37.401615: step 22882, loss 0.614548.
Train: 2018-08-01T01:19:37.573449: step 22883, loss 0.545064.
Train: 2018-08-01T01:19:37.729666: step 22884, loss 0.545086.
Train: 2018-08-01T01:19:37.885876: step 22885, loss 0.579706.
Train: 2018-08-01T01:19:38.057681: step 22886, loss 0.476004.
Train: 2018-08-01T01:19:38.213925: step 22887, loss 0.562402.
Train: 2018-08-01T01:19:38.370108: step 22888, loss 0.545123.
Train: 2018-08-01T01:19:38.526321: step 22889, loss 0.596968.
Train: 2018-08-01T01:19:38.682565: step 22890, loss 0.510571.
Test: 2018-08-01T01:19:39.151208: step 22890, loss 0.54793.
Train: 2018-08-01T01:19:39.307415: step 22891, loss 0.614255.
Train: 2018-08-01T01:19:39.463602: step 22892, loss 0.562402.
Train: 2018-08-01T01:19:39.619848: step 22893, loss 0.683303.
Train: 2018-08-01T01:19:39.791675: step 22894, loss 0.562399.
Train: 2018-08-01T01:19:39.932242: step 22895, loss 0.527983.
Train: 2018-08-01T01:19:40.088485: step 22896, loss 0.596772.
Train: 2018-08-01T01:19:40.260325: step 22897, loss 0.510912.
Train: 2018-08-01T01:19:40.432149: step 22898, loss 0.528096.
Train: 2018-08-01T01:19:40.588368: step 22899, loss 0.476656.
Train: 2018-08-01T01:19:40.744576: step 22900, loss 0.510898.
Test: 2018-08-01T01:19:41.213222: step 22900, loss 0.547999.
Train: 2018-08-01T01:19:41.931804: step 22901, loss 0.545203.
Train: 2018-08-01T01:19:42.087988: step 22902, loss 0.61407.
Train: 2018-08-01T01:19:42.244234: step 22903, loss 0.596875.
Train: 2018-08-01T01:19:42.416036: step 22904, loss 0.596884.
Train: 2018-08-01T01:19:42.572286: step 22905, loss 0.614114.
Train: 2018-08-01T01:19:42.728496: step 22906, loss 0.510732.
Train: 2018-08-01T01:19:42.884675: step 22907, loss 0.596837.
Train: 2018-08-01T01:19:43.056510: step 22908, loss 0.52798.
Train: 2018-08-01T01:19:43.212723: step 22909, loss 0.579605.
Train: 2018-08-01T01:19:43.368936: step 22910, loss 0.579599.
Test: 2018-08-01T01:19:43.853199: step 22910, loss 0.548.
Train: 2018-08-01T01:19:44.009412: step 22911, loss 0.493628.
Train: 2018-08-01T01:19:44.165626: step 22912, loss 0.493598.
Train: 2018-08-01T01:19:44.321875: step 22913, loss 0.596844.
Train: 2018-08-01T01:19:44.478052: step 22914, loss 0.545164.
Train: 2018-08-01T01:19:44.634265: step 22915, loss 0.5279.
Train: 2018-08-01T01:19:44.790479: step 22916, loss 0.545131.
Train: 2018-08-01T01:19:44.946724: step 22917, loss 0.54511.
Train: 2018-08-01T01:19:45.118552: step 22918, loss 0.614359.
Train: 2018-08-01T01:19:45.274741: step 22919, loss 0.527754.
Train: 2018-08-01T01:19:45.430954: step 22920, loss 0.666463.
Test: 2018-08-01T01:19:45.899593: step 22920, loss 0.547895.
Train: 2018-08-01T01:19:46.055838: step 22921, loss 0.510413.
Train: 2018-08-01T01:19:46.212051: step 22922, loss 0.562409.
Train: 2018-08-01T01:19:46.368268: step 22923, loss 0.42373.
Train: 2018-08-01T01:19:46.524478: step 22924, loss 0.51031.
Train: 2018-08-01T01:19:46.680661: step 22925, loss 0.562412.
Train: 2018-08-01T01:19:46.868117: step 22926, loss 0.527781.
Train: 2018-08-01T01:19:47.024361: step 22927, loss 0.492373.
Train: 2018-08-01T01:19:47.180575: step 22928, loss 0.527293.
Train: 2018-08-01T01:19:47.336788: step 22929, loss 0.491972.
Train: 2018-08-01T01:19:47.492972: step 22930, loss 0.527146.
Test: 2018-08-01T01:19:47.961637: step 22930, loss 0.54763.
Train: 2018-08-01T01:19:48.117850: step 22931, loss 0.544141.
Train: 2018-08-01T01:19:48.289690: step 22932, loss 0.54562.
Train: 2018-08-01T01:19:48.445873: step 22933, loss 0.526356.
Train: 2018-08-01T01:19:48.602117: step 22934, loss 0.527939.
Train: 2018-08-01T01:19:48.758330: step 22935, loss 0.634964.
Train: 2018-08-01T01:19:48.914546: step 22936, loss 0.453343.
Train: 2018-08-01T01:19:49.086378: step 22937, loss 0.526231.
Train: 2018-08-01T01:19:49.242561: step 22938, loss 0.689019.
Train: 2018-08-01T01:19:49.398774: step 22939, loss 0.619073.
Train: 2018-08-01T01:19:49.555020: step 22940, loss 0.600438.
Test: 2018-08-01T01:19:50.023629: step 22940, loss 0.54757.
Train: 2018-08-01T01:19:50.195494: step 22941, loss 0.451895.
Train: 2018-08-01T01:19:50.367298: step 22942, loss 0.598584.
Train: 2018-08-01T01:19:50.523536: step 22943, loss 0.581434.
Train: 2018-08-01T01:19:50.679753: step 22944, loss 0.615948.
Train: 2018-08-01T01:19:50.835969: step 22945, loss 0.562738.
Train: 2018-08-01T01:19:51.007804: step 22946, loss 0.558557.
Train: 2018-08-01T01:19:51.163987: step 22947, loss 0.601803.
Train: 2018-08-01T01:19:51.320230: step 22948, loss 0.528256.
Train: 2018-08-01T01:19:51.476444: step 22949, loss 0.453647.
Train: 2018-08-01T01:19:51.632657: step 22950, loss 0.60212.
Test: 2018-08-01T01:19:52.101298: step 22950, loss 0.547574.
Train: 2018-08-01T01:19:52.273133: step 22951, loss 0.56247.
Train: 2018-08-01T01:19:52.444963: step 22952, loss 0.598431.
Train: 2018-08-01T01:19:52.601150: step 22953, loss 0.616627.
Train: 2018-08-01T01:19:52.757363: step 22954, loss 0.491261.
Train: 2018-08-01T01:19:52.913607: step 22955, loss 0.581366.
Train: 2018-08-01T01:19:53.085413: step 22956, loss 0.580054.
Train: 2018-08-01T01:19:53.241658: step 22957, loss 0.704363.
Train: 2018-08-01T01:19:53.397875: step 22958, loss 0.579786.
Train: 2018-08-01T01:19:53.569673: step 22959, loss 0.615485.
Train: 2018-08-01T01:19:53.725887: step 22960, loss 0.68518.
Test: 2018-08-01T01:19:54.194553: step 22960, loss 0.547862.
Train: 2018-08-01T01:19:54.350740: step 22961, loss 0.475511.
Train: 2018-08-01T01:19:54.506953: step 22962, loss 0.545108.
Train: 2018-08-01T01:19:54.663197: step 22963, loss 0.545148.
Train: 2018-08-01T01:19:54.819410: step 22964, loss 0.631287.
Train: 2018-08-01T01:19:54.991249: step 22965, loss 0.510909.
Train: 2018-08-01T01:19:55.147459: step 22966, loss 0.528149.
Train: 2018-08-01T01:19:55.303673: step 22967, loss 0.5111.
Train: 2018-08-01T01:19:55.459886: step 22968, loss 0.613678.
Train: 2018-08-01T01:19:55.616069: step 22969, loss 0.750167.
Train: 2018-08-01T01:19:55.772307: step 22970, loss 0.698459.
Test: 2018-08-01T01:19:56.256574: step 22970, loss 0.548262.
Train: 2018-08-01T01:19:56.412788: step 22971, loss 0.562408.
Train: 2018-08-01T01:19:56.568970: step 22972, loss 0.612793.
Train: 2018-08-01T01:19:56.740845: step 22973, loss 0.695116.
Train: 2018-08-01T01:19:56.897049: step 22974, loss 0.529391.
Train: 2018-08-01T01:19:57.053232: step 22975, loss 0.595135.
Train: 2018-08-01T01:19:57.209446: step 22976, loss 0.512926.
Train: 2018-08-01T01:19:57.365693: step 22977, loss 0.5645.
Train: 2018-08-01T01:19:57.521873: step 22978, loss 0.454655.
Train: 2018-08-01T01:19:57.678086: step 22979, loss 0.612746.
Train: 2018-08-01T01:19:57.849921: step 22980, loss 0.547411.
Test: 2018-08-01T01:19:58.334213: step 22980, loss 0.548904.
Train: 2018-08-01T01:19:58.490395: step 22981, loss 0.564723.
Train: 2018-08-01T01:19:58.646639: step 22982, loss 0.480828.
Train: 2018-08-01T01:19:58.802824: step 22983, loss 0.479698.
Train: 2018-08-01T01:19:58.974683: step 22984, loss 0.646648.
Train: 2018-08-01T01:19:59.130902: step 22985, loss 0.595253.
Train: 2018-08-01T01:19:59.287115: step 22986, loss 0.564553.
Train: 2018-08-01T01:19:59.443329: step 22987, loss 0.612492.
Train: 2018-08-01T01:19:59.599542: step 22988, loss 0.578164.
Train: 2018-08-01T01:19:59.755726: step 22989, loss 0.62626.
Train: 2018-08-01T01:19:59.911940: step 22990, loss 0.595939.
Test: 2018-08-01T01:20:00.380608: step 22990, loss 0.549217.
Train: 2018-08-01T01:20:00.552443: step 22991, loss 0.672668.
Train: 2018-08-01T01:20:00.708627: step 22992, loss 0.563459.
Train: 2018-08-01T01:20:00.864873: step 22993, loss 0.549694.
Train: 2018-08-01T01:20:01.021078: step 22994, loss 0.485413.
Train: 2018-08-01T01:20:01.192912: step 22995, loss 0.595261.
Train: 2018-08-01T01:20:01.349134: step 22996, loss 0.549795.
Train: 2018-08-01T01:20:01.505315: step 22997, loss 0.564723.
Train: 2018-08-01T01:20:01.661559: step 22998, loss 0.531475.
Train: 2018-08-01T01:20:01.817772: step 22999, loss 0.597471.
Train: 2018-08-01T01:20:01.989576: step 23000, loss 0.57342.
Test: 2018-08-01T01:20:02.458246: step 23000, loss 0.548109.
Train: 2018-08-01T01:20:03.161210: step 23001, loss 0.615676.
Train: 2018-08-01T01:20:03.333037: step 23002, loss 0.57637.
Train: 2018-08-01T01:20:03.489226: step 23003, loss 0.550335.
Train: 2018-08-01T01:20:03.645438: step 23004, loss 0.575658.
Train: 2018-08-01T01:20:03.801653: step 23005, loss 0.583399.
Train: 2018-08-01T01:20:03.957866: step 23006, loss 0.531577.
Train: 2018-08-01T01:20:04.114113: step 23007, loss 0.594333.
Train: 2018-08-01T01:20:04.270323: step 23008, loss 0.480843.
Train: 2018-08-01T01:20:04.426537: step 23009, loss 0.514988.
Train: 2018-08-01T01:20:04.582750: step 23010, loss 0.496197.
Test: 2018-08-01T01:20:05.051390: step 23010, loss 0.548699.
Train: 2018-08-01T01:20:05.207603: step 23011, loss 0.597411.
Train: 2018-08-01T01:20:05.363820: step 23012, loss 0.497749.
Train: 2018-08-01T01:20:05.520025: step 23013, loss 0.445412.
Train: 2018-08-01T01:20:05.676243: step 23014, loss 0.66323.
Train: 2018-08-01T01:20:05.848081: step 23015, loss 0.494167.
Train: 2018-08-01T01:20:06.004292: step 23016, loss 0.461179.
Train: 2018-08-01T01:20:06.160505: step 23017, loss 0.628284.
Train: 2018-08-01T01:20:06.316718: step 23018, loss 0.492841.
Train: 2018-08-01T01:20:06.472932: step 23019, loss 0.474993.
Train: 2018-08-01T01:20:06.644763: step 23020, loss 0.545825.
Test: 2018-08-01T01:20:07.128998: step 23020, loss 0.547668.
Train: 2018-08-01T01:20:07.285211: step 23021, loss 0.545603.
Train: 2018-08-01T01:20:07.441426: step 23022, loss 0.649785.
Train: 2018-08-01T01:20:07.613260: step 23023, loss 0.473634.
Train: 2018-08-01T01:20:07.785094: step 23024, loss 0.584369.
Train: 2018-08-01T01:20:07.925717: step 23025, loss 0.636441.
Train: 2018-08-01T01:20:08.081900: step 23026, loss 0.541429.
Train: 2018-08-01T01:20:08.253734: step 23027, loss 0.564008.
Train: 2018-08-01T01:20:08.409972: step 23028, loss 0.580304.
Train: 2018-08-01T01:20:08.566192: step 23029, loss 0.546377.
Train: 2018-08-01T01:20:08.737998: step 23030, loss 0.49104.
Test: 2018-08-01T01:20:09.206666: step 23030, loss 0.547891.
Train: 2018-08-01T01:20:09.362883: step 23031, loss 0.511189.
Train: 2018-08-01T01:20:09.519094: step 23032, loss 0.599607.
Train: 2018-08-01T01:20:09.675307: step 23033, loss 0.474334.
Train: 2018-08-01T01:20:09.847150: step 23034, loss 0.547125.
Train: 2018-08-01T01:20:10.003324: step 23035, loss 0.597733.
Train: 2018-08-01T01:20:10.159568: step 23036, loss 0.616668.
Train: 2018-08-01T01:20:10.315752: step 23037, loss 0.703647.
Train: 2018-08-01T01:20:10.471995: step 23038, loss 0.528844.
Train: 2018-08-01T01:20:10.628209: step 23039, loss 0.510241.
Train: 2018-08-01T01:20:10.784417: step 23040, loss 0.510721.
Test: 2018-08-01T01:20:11.253031: step 23040, loss 0.548053.
Train: 2018-08-01T01:20:11.409245: step 23041, loss 0.562847.
Train: 2018-08-01T01:20:11.565459: step 23042, loss 0.61459.
Train: 2018-08-01T01:20:11.721698: step 23043, loss 0.545238.
Train: 2018-08-01T01:20:11.877910: step 23044, loss 0.597157.
Train: 2018-08-01T01:20:12.034130: step 23045, loss 0.527992.
Train: 2018-08-01T01:20:12.221588: step 23046, loss 0.579836.
Train: 2018-08-01T01:20:12.377805: step 23047, loss 0.476194.
Train: 2018-08-01T01:20:12.533983: step 23048, loss 0.579842.
Train: 2018-08-01T01:20:12.690226: step 23049, loss 0.579845.
Train: 2018-08-01T01:20:12.846409: step 23050, loss 0.562392.
Test: 2018-08-01T01:20:13.330701: step 23050, loss 0.548169.
Train: 2018-08-01T01:20:13.486884: step 23051, loss 0.562114.
Train: 2018-08-01T01:20:13.643128: step 23052, loss 0.582583.
Train: 2018-08-01T01:20:13.799311: step 23053, loss 0.512668.
Train: 2018-08-01T01:20:13.955550: step 23054, loss 0.596848.
Train: 2018-08-01T01:20:14.111737: step 23055, loss 0.579802.
Train: 2018-08-01T01:20:14.283573: step 23056, loss 0.57986.
Train: 2018-08-01T01:20:14.439787: step 23057, loss 0.579846.
Train: 2018-08-01T01:20:14.596033: step 23058, loss 0.54531.
Train: 2018-08-01T01:20:14.752242: step 23059, loss 0.614427.
Train: 2018-08-01T01:20:14.908427: step 23060, loss 0.68332.
Test: 2018-08-01T01:20:15.392714: step 23060, loss 0.54815.
Train: 2018-08-01T01:20:15.548901: step 23061, loss 0.631388.
Train: 2018-08-01T01:20:15.705145: step 23062, loss 0.596908.
Train: 2018-08-01T01:20:15.861362: step 23063, loss 0.528373.
Train: 2018-08-01T01:20:16.017572: step 23064, loss 0.494372.
Train: 2018-08-01T01:20:16.173755: step 23065, loss 0.511498.
Train: 2018-08-01T01:20:16.329969: step 23066, loss 0.596608.
Train: 2018-08-01T01:20:16.501803: step 23067, loss 0.579578.
Train: 2018-08-01T01:20:16.658017: step 23068, loss 0.511632.
Train: 2018-08-01T01:20:16.814230: step 23069, loss 0.511642.
Train: 2018-08-01T01:20:16.970474: step 23070, loss 0.477634.
Test: 2018-08-01T01:20:17.439114: step 23070, loss 0.548322.
Train: 2018-08-01T01:20:17.610944: step 23071, loss 0.613625.
Train: 2018-08-01T01:20:17.751511: step 23072, loss 0.528504.
Train: 2018-08-01T01:20:17.907723: step 23073, loss 0.511404.
Train: 2018-08-01T01:20:18.095213: step 23074, loss 0.613817.
Train: 2018-08-01T01:20:18.251424: step 23075, loss 0.613864.
Train: 2018-08-01T01:20:18.407637: step 23076, loss 0.528345.
Train: 2018-08-01T01:20:18.563850: step 23077, loss 0.511203.
Train: 2018-08-01T01:20:18.735656: step 23078, loss 0.511137.
Train: 2018-08-01T01:20:18.891868: step 23079, loss 0.596889.
Train: 2018-08-01T01:20:19.048112: step 23080, loss 0.545354.
Test: 2018-08-01T01:20:19.516721: step 23080, loss 0.54813.
Train: 2018-08-01T01:20:19.672966: step 23081, loss 0.493689.
Train: 2018-08-01T01:20:19.860425: step 23082, loss 0.510794.
Train: 2018-08-01T01:20:20.016641: step 23083, loss 0.61443.
Train: 2018-08-01T01:20:20.172819: step 23084, loss 0.597192.
Train: 2018-08-01T01:20:20.329033: step 23085, loss 0.562548.
Train: 2018-08-01T01:20:20.485269: step 23086, loss 0.562548.
Train: 2018-08-01T01:20:20.641490: step 23087, loss 0.579912.
Train: 2018-08-01T01:20:20.797703: step 23088, loss 0.579916.
Train: 2018-08-01T01:20:21.000774: step 23089, loss 0.579915.
Train: 2018-08-01T01:20:21.156987: step 23090, loss 0.527807.
Test: 2018-08-01T01:20:21.625603: step 23090, loss 0.547993.
Train: 2018-08-01T01:20:21.766225: step 23091, loss 0.545169.
Train: 2018-08-01T01:20:21.953677: step 23092, loss 0.579917.
Train: 2018-08-01T01:20:22.109898: step 23093, loss 0.562537.
Train: 2018-08-01T01:20:22.266110: step 23094, loss 0.632063.
Train: 2018-08-01T01:20:22.422292: step 23095, loss 0.701441.
Train: 2018-08-01T01:20:22.578530: step 23096, loss 0.579839.
Train: 2018-08-01T01:20:22.750370: step 23097, loss 0.597054.
Train: 2018-08-01T01:20:22.906554: step 23098, loss 0.47642.
Train: 2018-08-01T01:20:23.062803: step 23099, loss 0.614086.
Train: 2018-08-01T01:20:23.219014: step 23100, loss 0.631134.
Test: 2018-08-01T01:20:23.687651: step 23100, loss 0.54818.
Train: 2018-08-01T01:20:24.406202: step 23101, loss 0.476963.
Train: 2018-08-01T01:20:24.578067: step 23102, loss 0.596678.
Train: 2018-08-01T01:20:24.734250: step 23103, loss 0.647794.
Train: 2018-08-01T01:20:24.890489: step 23104, loss 0.630558.
Train: 2018-08-01T01:20:25.046709: step 23105, loss 0.647294.
Train: 2018-08-01T01:20:25.202891: step 23106, loss 0.528759.
Train: 2018-08-01T01:20:25.374725: step 23107, loss 0.56254.
Train: 2018-08-01T01:20:25.515342: step 23108, loss 0.579334.
Train: 2018-08-01T01:20:25.687152: step 23109, loss 0.512355.
Train: 2018-08-01T01:20:25.843396: step 23110, loss 0.529156.
Test: 2018-08-01T01:20:26.312031: step 23110, loss 0.548599.
Train: 2018-08-01T01:20:26.468220: step 23111, loss 0.429037.
Train: 2018-08-01T01:20:26.624463: step 23112, loss 0.595993.
Train: 2018-08-01T01:20:26.780677: step 23113, loss 0.462228.
Train: 2018-08-01T01:20:26.952512: step 23114, loss 0.495521.
Train: 2018-08-01T01:20:27.108695: step 23115, loss 0.54573.
Train: 2018-08-01T01:20:27.264908: step 23116, loss 0.629947.
Train: 2018-08-01T01:20:27.452394: step 23117, loss 0.646941.
Train: 2018-08-01T01:20:27.608611: step 23118, loss 0.494946.
Train: 2018-08-01T01:20:27.764820: step 23119, loss 0.596339.
Train: 2018-08-01T01:20:27.921034: step 23120, loss 0.511719.
Test: 2018-08-01T01:20:28.405296: step 23120, loss 0.548303.
Train: 2018-08-01T01:20:28.577125: step 23121, loss 0.596407.
Train: 2018-08-01T01:20:28.733313: step 23122, loss 0.613403.
Train: 2018-08-01T01:20:28.889528: step 23123, loss 0.579466.
Train: 2018-08-01T01:20:29.045771: step 23124, loss 0.579464.
Train: 2018-08-01T01:20:29.201954: step 23125, loss 0.511603.
Train: 2018-08-01T01:20:29.358167: step 23126, loss 0.562493.
Train: 2018-08-01T01:20:29.514411: step 23127, loss 0.494569.
Train: 2018-08-01T01:20:29.686252: step 23128, loss 0.698523.
Train: 2018-08-01T01:20:29.842429: step 23129, loss 0.613471.
Train: 2018-08-01T01:20:29.998671: step 23130, loss 0.545517.
Test: 2018-08-01T01:20:30.467283: step 23130, loss 0.54829.
Train: 2018-08-01T01:20:30.639118: step 23131, loss 0.630329.
Train: 2018-08-01T01:20:30.795357: step 23132, loss 0.596358.
Train: 2018-08-01T01:20:30.951545: step 23133, loss 0.596299.
Train: 2018-08-01T01:20:31.107758: step 23134, loss 0.562508.
Train: 2018-08-01T01:20:31.264001: step 23135, loss 0.51204.
Train: 2018-08-01T01:20:31.420215: step 23136, loss 0.495263.
Train: 2018-08-01T01:20:31.576423: step 23137, loss 0.562518.
Train: 2018-08-01T01:20:31.732645: step 23138, loss 0.579338.
Train: 2018-08-01T01:20:31.920098: step 23139, loss 0.512054.
Train: 2018-08-01T01:20:32.076312: step 23140, loss 0.646686.
Test: 2018-08-01T01:20:32.560569: step 23140, loss 0.548424.
Train: 2018-08-01T01:20:32.716786: step 23141, loss 0.59617.
Train: 2018-08-01T01:20:32.888617: step 23142, loss 0.461631.
Train: 2018-08-01T01:20:33.044835: step 23143, loss 0.596189.
Train: 2018-08-01T01:20:33.201048: step 23144, loss 0.478344.
Train: 2018-08-01T01:20:33.357264: step 23145, loss 0.629928.
Train: 2018-08-01T01:20:33.513469: step 23146, loss 0.528746.
Train: 2018-08-01T01:20:33.669689: step 23147, loss 0.714497.
Train: 2018-08-01T01:20:33.825871: step 23148, loss 0.427462.
Train: 2018-08-01T01:20:33.997706: step 23149, loss 0.49509.
Train: 2018-08-01T01:20:34.153920: step 23150, loss 0.596455.
Test: 2018-08-01T01:20:34.638212: step 23150, loss 0.548171.
Train: 2018-08-01T01:20:34.778803: step 23151, loss 0.511261.
Train: 2018-08-01T01:20:34.950608: step 23152, loss 0.632454.
Train: 2018-08-01T01:20:35.106822: step 23153, loss 0.527111.
Train: 2018-08-01T01:20:35.263062: step 23154, loss 0.527734.
Train: 2018-08-01T01:20:35.419278: step 23155, loss 0.579594.
Train: 2018-08-01T01:20:35.575492: step 23156, loss 0.493233.
Train: 2018-08-01T01:20:35.731708: step 23157, loss 0.578576.
Train: 2018-08-01T01:20:35.887919: step 23158, loss 0.549291.
Train: 2018-08-01T01:20:36.044101: step 23159, loss 0.596582.
Train: 2018-08-01T01:20:36.200316: step 23160, loss 0.525709.
Test: 2018-08-01T01:20:36.668986: step 23160, loss 0.547747.
Train: 2018-08-01T01:20:36.825199: step 23161, loss 0.422316.
Train: 2018-08-01T01:20:36.981415: step 23162, loss 0.629882.
Train: 2018-08-01T01:20:37.137595: step 23163, loss 0.512196.
Train: 2018-08-01T01:20:37.309457: step 23164, loss 0.562397.
Train: 2018-08-01T01:20:37.465644: step 23165, loss 0.642152.
Train: 2018-08-01T01:20:37.621857: step 23166, loss 0.551212.
Train: 2018-08-01T01:20:37.793722: step 23167, loss 0.654364.
Train: 2018-08-01T01:20:37.949935: step 23168, loss 0.597882.
Train: 2018-08-01T01:20:38.106152: step 23169, loss 0.546376.
Train: 2018-08-01T01:20:38.262334: step 23170, loss 0.596791.
Test: 2018-08-01T01:20:38.731006: step 23170, loss 0.548197.
Train: 2018-08-01T01:20:38.902807: step 23171, loss 0.476676.
Train: 2018-08-01T01:20:39.059020: step 23172, loss 0.596403.
Train: 2018-08-01T01:20:39.215235: step 23173, loss 0.563004.
Train: 2018-08-01T01:20:39.371478: step 23174, loss 0.562412.
Train: 2018-08-01T01:20:39.527663: step 23175, loss 0.511342.
Train: 2018-08-01T01:20:39.683905: step 23176, loss 0.477015.
Train: 2018-08-01T01:20:39.840121: step 23177, loss 0.56249.
Train: 2018-08-01T01:20:39.996302: step 23178, loss 0.54535.
Train: 2018-08-01T01:20:40.152546: step 23179, loss 0.56249.
Train: 2018-08-01T01:20:40.324349: step 23180, loss 0.528121.
Test: 2018-08-01T01:20:40.792989: step 23180, loss 0.548079.
Train: 2018-08-01T01:20:40.949233: step 23181, loss 0.510857.
Train: 2018-08-01T01:20:41.105450: step 23182, loss 0.51075.
Train: 2018-08-01T01:20:41.261630: step 23183, loss 0.57979.
Train: 2018-08-01T01:20:41.417875: step 23184, loss 0.458536.
Train: 2018-08-01T01:20:41.574081: step 23185, loss 0.56251.
Train: 2018-08-01T01:20:41.745891: step 23186, loss 0.527655.
Train: 2018-08-01T01:20:41.902105: step 23187, loss 0.614982.
Train: 2018-08-01T01:20:42.073939: step 23188, loss 0.492471.
Train: 2018-08-01T01:20:42.230154: step 23189, loss 0.580114.
Train: 2018-08-01T01:20:42.386396: step 23190, loss 0.597757.
Test: 2018-08-01T01:20:42.855040: step 23190, loss 0.547816.
Train: 2018-08-01T01:20:43.011250: step 23191, loss 0.492093.
Train: 2018-08-01T01:20:43.167470: step 23192, loss 0.527274.
Train: 2018-08-01T01:20:43.323679: step 23193, loss 0.491829.
Train: 2018-08-01T01:20:43.479862: step 23194, loss 0.580357.
Train: 2018-08-01T01:20:43.636104: step 23195, loss 0.598189.
Train: 2018-08-01T01:20:43.792315: step 23196, loss 0.562644.
Train: 2018-08-01T01:20:43.964122: step 23197, loss 0.633941.
Train: 2018-08-01T01:20:44.120367: step 23198, loss 0.669581.
Train: 2018-08-01T01:20:44.276550: step 23199, loss 0.633818.
Train: 2018-08-01T01:20:44.432762: step 23200, loss 0.420595.
Test: 2018-08-01T01:20:44.901433: step 23200, loss 0.547755.
Train: 2018-08-01T01:20:45.635605: step 23201, loss 0.598106.
Train: 2018-08-01T01:20:45.776228: step 23202, loss 0.562606.
Train: 2018-08-01T01:20:45.948064: step 23203, loss 0.544843.
Train: 2018-08-01T01:20:46.104246: step 23204, loss 0.491571.
Train: 2018-08-01T01:20:46.260490: step 23205, loss 0.562742.
Train: 2018-08-01T01:20:46.416673: step 23206, loss 0.652459.
Train: 2018-08-01T01:20:46.572917: step 23207, loss 0.6161.
Train: 2018-08-01T01:20:46.729133: step 23208, loss 0.509626.
Train: 2018-08-01T01:20:46.885313: step 23209, loss 0.527303.
Train: 2018-08-01T01:20:47.041526: step 23210, loss 0.492096.
Test: 2018-08-01T01:20:47.510197: step 23210, loss 0.547811.
Train: 2018-08-01T01:20:47.682031: step 23211, loss 0.562567.
Train: 2018-08-01T01:20:47.838215: step 23212, loss 0.527322.
Train: 2018-08-01T01:20:47.978808: step 23213, loss 0.544943.
Train: 2018-08-01T01:20:48.150642: step 23214, loss 0.544938.
Train: 2018-08-01T01:20:48.306856: step 23215, loss 0.544932.
Train: 2018-08-01T01:20:48.463068: step 23216, loss 0.544924.
Train: 2018-08-01T01:20:48.603660: step 23217, loss 0.509549.
Train: 2018-08-01T01:20:48.759904: step 23218, loss 0.474073.
Train: 2018-08-01T01:20:48.916117: step 23219, loss 0.509386.
Train: 2018-08-01T01:20:49.072301: step 23220, loss 0.63382.
Test: 2018-08-01T01:20:49.540942: step 23220, loss 0.547739.
Train: 2018-08-01T01:20:49.697155: step 23221, loss 0.527026.
Train: 2018-08-01T01:20:49.853401: step 23222, loss 0.544828.
Train: 2018-08-01T01:20:50.009582: step 23223, loss 0.634162.
Train: 2018-08-01T01:20:50.165819: step 23224, loss 0.580561.
Train: 2018-08-01T01:20:50.322038: step 23225, loss 0.526937.
Train: 2018-08-01T01:20:50.493844: step 23226, loss 0.669953.
Train: 2018-08-01T01:20:50.650056: step 23227, loss 0.616239.
Train: 2018-08-01T01:20:50.806270: step 23228, loss 0.509189.
Train: 2018-08-01T01:20:50.962483: step 23229, loss 0.580442.
Train: 2018-08-01T01:20:51.118696: step 23230, loss 0.598181.
Test: 2018-08-01T01:20:51.587337: step 23230, loss 0.547755.
Train: 2018-08-01T01:20:51.743580: step 23231, loss 0.509382.
Train: 2018-08-01T01:20:51.899763: step 23232, loss 0.473979.
Train: 2018-08-01T01:20:52.056007: step 23233, loss 0.615783.
Train: 2018-08-01T01:20:52.212191: step 23234, loss 0.474027.
Train: 2018-08-01T01:20:52.368434: step 23235, loss 0.633484.
Train: 2018-08-01T01:20:52.524648: step 23236, loss 0.562593.
Train: 2018-08-01T01:20:52.696452: step 23237, loss 0.597983.
Train: 2018-08-01T01:20:52.852665: step 23238, loss 0.650966.
Train: 2018-08-01T01:20:53.008905: step 23239, loss 0.527287.
Train: 2018-08-01T01:20:53.165123: step 23240, loss 0.580158.
Test: 2018-08-01T01:20:53.649387: step 23240, loss 0.547821.
Train: 2018-08-01T01:20:53.868083: step 23241, loss 0.580115.
Train: 2018-08-01T01:20:54.024267: step 23242, loss 0.49236.
Train: 2018-08-01T01:20:54.180480: step 23243, loss 0.544996.
Train: 2018-08-01T01:20:54.336647: step 23244, loss 0.597548.
Train: 2018-08-01T01:20:54.492856: step 23245, loss 0.649989.
Train: 2018-08-01T01:20:54.649069: step 23246, loss 0.579959.
Train: 2018-08-01T01:20:54.805296: step 23247, loss 0.562493.
Train: 2018-08-01T01:20:54.961500: step 23248, loss 0.614626.
Train: 2018-08-01T01:20:55.117679: step 23249, loss 0.597147.
Train: 2018-08-01T01:20:55.273928: step 23250, loss 0.510617.
Test: 2018-08-01T01:20:55.742563: step 23250, loss 0.548022.
Train: 2018-08-01T01:20:55.914369: step 23251, loss 0.683229.
Train: 2018-08-01T01:20:56.070612: step 23252, loss 0.459305.
Train: 2018-08-01T01:20:56.226825: step 23253, loss 0.631123.
Train: 2018-08-01T01:20:56.383036: step 23254, loss 0.528217.
Train: 2018-08-01T01:20:56.554843: step 23255, loss 0.562464.
Train: 2018-08-01T01:20:56.711056: step 23256, loss 0.562465.
Train: 2018-08-01T01:20:56.867300: step 23257, loss 0.579511.
Train: 2018-08-01T01:20:57.070381: step 23258, loss 0.47737.
Train: 2018-08-01T01:20:57.226591: step 23259, loss 0.647559.
Train: 2018-08-01T01:20:57.382804: step 23260, loss 0.681448.
Test: 2018-08-01T01:20:57.851444: step 23260, loss 0.548283.
Train: 2018-08-01T01:20:58.023280: step 23261, loss 0.494676.
Train: 2018-08-01T01:20:58.195084: step 23262, loss 0.680954.
Train: 2018-08-01T01:20:58.351297: step 23263, loss 0.511866.
Train: 2018-08-01T01:20:58.507512: step 23264, loss 0.562497.
Train: 2018-08-01T01:20:58.663754: step 23265, loss 0.579318.
Train: 2018-08-01T01:20:58.819971: step 23266, loss 0.545725.
Train: 2018-08-01T01:20:58.976181: step 23267, loss 0.629581.
Train: 2018-08-01T01:20:59.132391: step 23268, loss 0.46213.
Train: 2018-08-01T01:20:59.319853: step 23269, loss 0.579257.
Train: 2018-08-01T01:20:59.476034: step 23270, loss 0.612696.
Test: 2018-08-01T01:20:59.929082: step 23270, loss 0.548547.
Train: 2018-08-01T01:21:00.100919: step 23271, loss 0.579241.
Train: 2018-08-01T01:21:00.257128: step 23272, loss 0.662668.
Train: 2018-08-01T01:21:00.413339: step 23273, loss 0.479309.
Train: 2018-08-01T01:21:00.569527: step 23274, loss 0.512652.
Train: 2018-08-01T01:21:00.725771: step 23275, loss 0.56256.
Train: 2018-08-01T01:21:00.897606: step 23276, loss 0.479349.
Train: 2018-08-01T01:21:01.053790: step 23277, loss 0.645882.
Train: 2018-08-01T01:21:01.210037: step 23278, loss 0.529206.
Train: 2018-08-01T01:21:01.366245: step 23279, loss 0.595908.
Train: 2018-08-01T01:21:01.538081: step 23280, loss 0.579228.
Test: 2018-08-01T01:21:02.006692: step 23280, loss 0.548562.
Train: 2018-08-01T01:21:02.178526: step 23281, loss 0.495776.
Train: 2018-08-01T01:21:02.334774: step 23282, loss 0.545821.
Train: 2018-08-01T01:21:02.506575: step 23283, loss 0.562523.
Train: 2018-08-01T01:21:02.662787: step 23284, loss 0.545762.
Train: 2018-08-01T01:21:02.819002: step 23285, loss 0.596067.
Train: 2018-08-01T01:21:02.975245: step 23286, loss 0.596094.
Train: 2018-08-01T01:21:03.131458: step 23287, loss 0.579304.
Train: 2018-08-01T01:21:03.287642: step 23288, loss 0.5625.
Train: 2018-08-01T01:21:03.459501: step 23289, loss 0.579309.
Train: 2018-08-01T01:21:03.615689: step 23290, loss 0.562498.
Test: 2018-08-01T01:21:04.084364: step 23290, loss 0.548419.
Train: 2018-08-01T01:21:04.256195: step 23291, loss 0.495247.
Train: 2018-08-01T01:21:04.412408: step 23292, loss 0.596156.
Train: 2018-08-01T01:21:04.568616: step 23293, loss 0.545649.
Train: 2018-08-01T01:21:04.724804: step 23294, loss 0.579342.
Train: 2018-08-01T01:21:04.881019: step 23295, loss 0.511889.
Train: 2018-08-01T01:21:05.037262: step 23296, loss 0.562479.
Train: 2018-08-01T01:21:05.193444: step 23297, loss 0.477941.
Train: 2018-08-01T01:21:05.349659: step 23298, loss 0.562468.
Train: 2018-08-01T01:21:05.505871: step 23299, loss 0.596426.
Train: 2018-08-01T01:21:05.662115: step 23300, loss 0.494431.
Test: 2018-08-01T01:21:06.130758: step 23300, loss 0.548181.
Train: 2018-08-01T01:21:06.864929: step 23301, loss 0.545409.
Train: 2018-08-01T01:21:07.021142: step 23302, loss 0.528281.
Train: 2018-08-01T01:21:07.177355: step 23303, loss 0.545321.
Train: 2018-08-01T01:21:07.333603: step 23304, loss 0.528104.
Train: 2018-08-01T01:21:07.489812: step 23305, loss 0.441909.
Train: 2018-08-01T01:21:07.646026: step 23306, loss 0.510583.
Train: 2018-08-01T01:21:07.802239: step 23307, loss 0.597198.
Train: 2018-08-01T01:21:07.958424: step 23308, loss 0.527626.
Train: 2018-08-01T01:21:08.114666: step 23309, loss 0.597462.
Train: 2018-08-01T01:21:08.286470: step 23310, loss 0.597564.
Test: 2018-08-01T01:21:08.770769: step 23310, loss 0.547805.
Train: 2018-08-01T01:21:08.926976: step 23311, loss 0.580074.
Train: 2018-08-01T01:21:09.098781: step 23312, loss 0.544933.
Train: 2018-08-01T01:21:09.254994: step 23313, loss 0.597745.
Train: 2018-08-01T01:21:09.411238: step 23314, loss 0.685876.
Train: 2018-08-01T01:21:09.583042: step 23315, loss 0.52732.
Train: 2018-08-01T01:21:09.739255: step 23316, loss 0.650474.
Train: 2018-08-01T01:21:09.895468: step 23317, loss 0.597629.
Train: 2018-08-01T01:21:10.051682: step 23318, loss 0.615065.
Train: 2018-08-01T01:21:10.223516: step 23319, loss 0.492584.
Train: 2018-08-01T01:21:10.364109: step 23320, loss 0.597376.
Test: 2018-08-01T01:21:10.832774: step 23320, loss 0.547889.
Train: 2018-08-01T01:21:11.004615: step 23321, loss 0.545057.
Train: 2018-08-01T01:21:11.160828: step 23322, loss 0.666796.
Train: 2018-08-01T01:21:11.332633: step 23323, loss 0.475763.
Train: 2018-08-01T01:21:11.488876: step 23324, loss 0.597085.
Train: 2018-08-01T01:21:11.660680: step 23325, loss 0.579736.
Train: 2018-08-01T01:21:11.816895: step 23326, loss 0.665961.
Train: 2018-08-01T01:21:11.957486: step 23327, loss 0.51085.
Train: 2018-08-01T01:21:12.129320: step 23328, loss 0.52812.
Train: 2018-08-01T01:21:12.285564: step 23329, loss 0.630998.
Train: 2018-08-01T01:21:12.457369: step 23330, loss 0.459844.
Test: 2018-08-01T01:21:12.926039: step 23330, loss 0.548135.
Train: 2018-08-01T01:21:13.097843: step 23331, loss 0.579537.
Train: 2018-08-01T01:21:13.254057: step 23332, loss 0.511213.
Train: 2018-08-01T01:21:13.410272: step 23333, loss 0.579526.
Train: 2018-08-01T01:21:13.582105: step 23334, loss 0.664903.
Train: 2018-08-01T01:21:13.722728: step 23335, loss 0.647695.
Train: 2018-08-01T01:21:13.878911: step 23336, loss 0.545447.
Train: 2018-08-01T01:21:14.035154: step 23337, loss 0.477604.
Train: 2018-08-01T01:21:14.191339: step 23338, loss 0.545499.
Train: 2018-08-01T01:21:14.347581: step 23339, loss 0.477684.
Train: 2018-08-01T01:21:14.503796: step 23340, loss 0.545485.
Test: 2018-08-01T01:21:14.972435: step 23340, loss 0.548226.
Train: 2018-08-01T01:21:15.144264: step 23341, loss 0.613426.
Train: 2018-08-01T01:21:15.300453: step 23342, loss 0.52846.
Train: 2018-08-01T01:21:15.456667: step 23343, loss 0.562451.
Train: 2018-08-01T01:21:15.628527: step 23344, loss 0.545426.
Train: 2018-08-01T01:21:15.800337: step 23345, loss 0.579487.
Train: 2018-08-01T01:21:15.956549: step 23346, loss 0.528346.
Train: 2018-08-01T01:21:16.112763: step 23347, loss 0.596582.
Train: 2018-08-01T01:21:16.268977: step 23348, loss 0.545368.
Train: 2018-08-01T01:21:16.409599: step 23349, loss 0.511177.
Train: 2018-08-01T01:21:16.581437: step 23350, loss 0.511106.
Test: 2018-08-01T01:21:17.050073: step 23350, loss 0.548085.
Train: 2018-08-01T01:21:17.206258: step 23351, loss 0.493861.
Train: 2018-08-01T01:21:17.378092: step 23352, loss 0.510868.
Train: 2018-08-01T01:21:17.534335: step 23353, loss 0.527955.
Train: 2018-08-01T01:21:17.690519: step 23354, loss 0.614352.
Train: 2018-08-01T01:21:17.846734: step 23355, loss 0.475761.
Train: 2018-08-01T01:21:18.018603: step 23356, loss 0.632032.
Train: 2018-08-01T01:21:18.174780: step 23357, loss 0.562468.
Train: 2018-08-01T01:21:18.331028: step 23358, loss 0.51012.
Train: 2018-08-01T01:21:18.487206: step 23359, loss 0.527508.
Train: 2018-08-01T01:21:18.643420: step 23360, loss 0.47486.
Test: 2018-08-01T01:21:19.112090: step 23360, loss 0.547787.
Train: 2018-08-01T01:21:19.268304: step 23361, loss 0.615253.
Train: 2018-08-01T01:21:19.424518: step 23362, loss 0.597755.
Train: 2018-08-01T01:21:19.596347: step 23363, loss 0.633087.
Train: 2018-08-01T01:21:19.752537: step 23364, loss 0.597814.
Train: 2018-08-01T01:21:19.908779: step 23365, loss 0.615432.
Train: 2018-08-01T01:21:20.080587: step 23366, loss 0.527291.
Train: 2018-08-01T01:21:20.221176: step 23367, loss 0.580119.
Train: 2018-08-01T01:21:20.393010: step 23368, loss 0.615272.
Train: 2018-08-01T01:21:20.549249: step 23369, loss 0.439584.
Train: 2018-08-01T01:21:20.705472: step 23370, loss 0.527378.
Test: 2018-08-01T01:21:21.174108: step 23370, loss 0.547791.
Train: 2018-08-01T01:21:21.345914: step 23371, loss 0.650358.
Train: 2018-08-01T01:21:21.502126: step 23372, loss 0.544943.
Train: 2018-08-01T01:21:21.658339: step 23373, loss 0.650236.
Train: 2018-08-01T01:21:21.814554: step 23374, loss 0.527453.
Train: 2018-08-01T01:21:21.970767: step 23375, loss 0.66747.
Train: 2018-08-01T01:21:22.126981: step 23376, loss 0.562472.
Train: 2018-08-01T01:21:22.298839: step 23377, loss 0.632122.
Train: 2018-08-01T01:21:22.455053: step 23378, loss 0.631901.
Train: 2018-08-01T01:21:22.595651: step 23379, loss 0.475959.
Train: 2018-08-01T01:21:22.767485: step 23380, loss 0.631478.
Test: 2018-08-01T01:21:23.236125: step 23380, loss 0.548029.
Train: 2018-08-01T01:21:23.423550: step 23381, loss 0.596855.
Train: 2018-08-01T01:21:23.579799: step 23382, loss 0.579592.
Train: 2018-08-01T01:21:23.736009: step 23383, loss 0.57954.
Train: 2018-08-01T01:21:23.892191: step 23384, loss 0.545392.
Train: 2018-08-01T01:21:24.048405: step 23385, loss 0.579454.
Train: 2018-08-01T01:21:24.204652: step 23386, loss 0.562451.
Train: 2018-08-01T01:21:24.360832: step 23387, loss 0.511665.
Train: 2018-08-01T01:21:24.532667: step 23388, loss 0.579371.
Train: 2018-08-01T01:21:24.688880: step 23389, loss 0.579354.
Train: 2018-08-01T01:21:24.845093: step 23390, loss 0.528736.
Test: 2018-08-01T01:21:25.313763: step 23390, loss 0.548357.
Train: 2018-08-01T01:21:25.485600: step 23391, loss 0.511905.
Train: 2018-08-01T01:21:25.641812: step 23392, loss 0.528753.
Train: 2018-08-01T01:21:25.797994: step 23393, loss 0.494986.
Train: 2018-08-01T01:21:25.954242: step 23394, loss 0.613157.
Train: 2018-08-01T01:21:26.110452: step 23395, loss 0.579371.
Train: 2018-08-01T01:21:26.266665: step 23396, loss 0.562457.
Train: 2018-08-01T01:21:26.422849: step 23397, loss 0.579386.
Train: 2018-08-01T01:21:26.594712: step 23398, loss 0.613258.
Train: 2018-08-01T01:21:26.766519: step 23399, loss 0.47782.
Train: 2018-08-01T01:21:26.922756: step 23400, loss 0.579395.
Test: 2018-08-01T01:21:27.391372: step 23400, loss 0.548257.
Train: 2018-08-01T01:21:28.203717: step 23401, loss 0.562452.
Train: 2018-08-01T01:21:28.391138: step 23402, loss 0.56245.
Train: 2018-08-01T01:21:28.578628: step 23403, loss 0.579418.
Train: 2018-08-01T01:21:28.734807: step 23404, loss 0.596396.
Train: 2018-08-01T01:21:28.906642: step 23405, loss 0.579419.
Train: 2018-08-01T01:21:29.047265: step 23406, loss 0.477629.
Train: 2018-08-01T01:21:29.219068: step 23407, loss 0.494531.
Train: 2018-08-01T01:21:29.375282: step 23408, loss 0.511415.
Train: 2018-08-01T01:21:29.531495: step 23409, loss 0.408993.
Train: 2018-08-01T01:21:29.687709: step 23410, loss 0.562435.
Test: 2018-08-01T01:21:30.156380: step 23410, loss 0.548042.
Train: 2018-08-01T01:21:30.328184: step 23411, loss 0.51087.
Train: 2018-08-01T01:21:30.484428: step 23412, loss 0.596957.
Train: 2018-08-01T01:21:30.640641: step 23413, loss 0.579759.
Train: 2018-08-01T01:21:30.796855: step 23414, loss 0.631893.
Train: 2018-08-01T01:21:30.953037: step 23415, loss 0.545069.
Train: 2018-08-01T01:21:31.140493: step 23416, loss 0.545049.
Train: 2018-08-01T01:21:31.296708: step 23417, loss 0.527592.
Train: 2018-08-01T01:21:31.452921: step 23418, loss 0.632335.
Train: 2018-08-01T01:21:31.609164: step 23419, loss 0.597426.
Train: 2018-08-01T01:21:31.765378: step 23420, loss 0.527519.
Test: 2018-08-01T01:21:32.234018: step 23420, loss 0.547834.
Train: 2018-08-01T01:21:32.390231: step 23421, loss 0.510023.
Train: 2018-08-01T01:21:32.546445: step 23422, loss 0.492473.
Train: 2018-08-01T01:21:32.702628: step 23423, loss 0.422226.
Train: 2018-08-01T01:21:32.858872: step 23424, loss 0.562505.
Train: 2018-08-01T01:21:33.015054: step 23425, loss 0.562524.
Train: 2018-08-01T01:21:33.186890: step 23426, loss 0.580231.
Train: 2018-08-01T01:21:33.343102: step 23427, loss 0.61573.
Train: 2018-08-01T01:21:33.499346: step 23428, loss 0.598048.
Train: 2018-08-01T01:21:33.655563: step 23429, loss 0.52707.
Train: 2018-08-01T01:21:33.811776: step 23430, loss 0.598091.
Test: 2018-08-01T01:21:34.280384: step 23430, loss 0.547699.
Train: 2018-08-01T01:21:34.436597: step 23431, loss 0.651373.
Train: 2018-08-01T01:21:34.592835: step 23432, loss 0.5803.
Train: 2018-08-01T01:21:34.749024: step 23433, loss 0.509411.
Train: 2018-08-01T01:21:34.920889: step 23434, loss 0.456342.
Train: 2018-08-01T01:21:35.077106: step 23435, loss 0.686534.
Train: 2018-08-01T01:21:35.233285: step 23436, loss 0.509465.
Train: 2018-08-01T01:21:35.436363: step 23437, loss 0.562538.
Train: 2018-08-01T01:21:35.592607: step 23438, loss 0.562535.
Train: 2018-08-01T01:21:35.748791: step 23439, loss 0.509528.
Train: 2018-08-01T01:21:35.905033: step 23440, loss 0.597872.
Test: 2018-08-01T01:21:36.373674: step 23440, loss 0.547739.
Train: 2018-08-01T01:21:36.545478: step 23441, loss 0.527204.
Train: 2018-08-01T01:21:36.701692: step 23442, loss 0.527204.
Train: 2018-08-01T01:21:36.857906: step 23443, loss 0.456517.
Train: 2018-08-01T01:21:37.014154: step 23444, loss 0.58024.
Train: 2018-08-01T01:21:37.170331: step 23445, loss 0.615704.
Train: 2018-08-01T01:21:37.326571: step 23446, loss 0.562553.
Train: 2018-08-01T01:21:37.482788: step 23447, loss 0.54483.
Train: 2018-08-01T01:21:37.654593: step 23448, loss 0.5271.
Train: 2018-08-01T01:21:37.810840: step 23449, loss 0.562559.
Train: 2018-08-01T01:21:37.967050: step 23450, loss 0.633542.
Test: 2018-08-01T01:21:38.435661: step 23450, loss 0.547708.
Train: 2018-08-01T01:21:38.591874: step 23451, loss 0.615757.
Train: 2018-08-01T01:21:38.763739: step 23452, loss 0.615673.
Train: 2018-08-01T01:21:38.919948: step 23453, loss 0.544859.
Train: 2018-08-01T01:21:39.076170: step 23454, loss 0.49195.
Train: 2018-08-01T01:21:39.232382: step 23455, loss 0.544885.
Train: 2018-08-01T01:21:39.388562: step 23456, loss 0.615379.
Train: 2018-08-01T01:21:39.544805: step 23457, loss 0.509702.
Train: 2018-08-01T01:21:39.716641: step 23458, loss 0.562502.
Train: 2018-08-01T01:21:39.888446: step 23459, loss 0.527331.
Train: 2018-08-01T01:21:40.044690: step 23460, loss 0.580097.
Test: 2018-08-01T01:21:40.528951: step 23460, loss 0.547779.
Train: 2018-08-01T01:21:40.685133: step 23461, loss 0.562497.
Train: 2018-08-01T01:21:40.841373: step 23462, loss 0.544925.
Train: 2018-08-01T01:21:41.013207: step 23463, loss 0.544928.
Train: 2018-08-01T01:21:41.169426: step 23464, loss 0.61519.
Train: 2018-08-01T01:21:41.325609: step 23465, loss 0.6678.
Train: 2018-08-01T01:21:41.481852: step 23466, loss 0.597505.
Train: 2018-08-01T01:21:41.638065: step 23467, loss 0.684755.
Train: 2018-08-01T01:21:41.794248: step 23468, loss 0.562453.
Train: 2018-08-01T01:21:41.950488: step 23469, loss 0.701146.
Train: 2018-08-01T01:21:42.122298: step 23470, loss 0.476192.
Test: 2018-08-01T01:21:42.590968: step 23470, loss 0.548038.
Train: 2018-08-01T01:21:42.747181: step 23471, loss 0.459303.
Train: 2018-08-01T01:21:42.903395: step 23472, loss 0.631068.
Train: 2018-08-01T01:21:43.075224: step 23473, loss 0.459744.
Train: 2018-08-01T01:21:43.231443: step 23474, loss 0.579531.
Train: 2018-08-01T01:21:43.387656: step 23475, loss 0.630765.
Train: 2018-08-01T01:21:43.543840: step 23476, loss 0.562435.
Train: 2018-08-01T01:21:43.700078: step 23477, loss 0.579461.
Train: 2018-08-01T01:21:43.856266: step 23478, loss 0.671211.
Train: 2018-08-01T01:21:44.012510: step 23479, loss 0.545504.
Train: 2018-08-01T01:21:44.168694: step 23480, loss 0.697676.
Test: 2018-08-01T01:21:44.652984: step 23480, loss 0.548375.
Train: 2018-08-01T01:21:44.809198: step 23481, loss 0.562471.
Train: 2018-08-01T01:21:44.965412: step 23482, loss 0.562488.
Train: 2018-08-01T01:21:45.137246: step 23483, loss 0.529067.
Train: 2018-08-01T01:21:45.309050: step 23484, loss 0.612558.
Train: 2018-08-01T01:21:45.449668: step 23485, loss 0.512634.
Train: 2018-08-01T01:21:45.605887: step 23486, loss 0.645581.
Train: 2018-08-01T01:21:45.762101: step 23487, loss 0.529439.
Train: 2018-08-01T01:21:45.918314: step 23488, loss 0.546045.
Train: 2018-08-01T01:21:46.074496: step 23489, loss 0.628649.
Train: 2018-08-01T01:21:46.246332: step 23490, loss 0.546123.
Test: 2018-08-01T01:21:46.714971: step 23490, loss 0.548834.
Train: 2018-08-01T01:21:46.871215: step 23491, loss 0.562618.
Train: 2018-08-01T01:21:47.027431: step 23492, loss 0.513303.
Train: 2018-08-01T01:21:47.183636: step 23493, loss 0.463991.
Train: 2018-08-01T01:21:47.339857: step 23494, loss 0.562615.
Train: 2018-08-01T01:21:47.511689: step 23495, loss 0.447178.
Train: 2018-08-01T01:21:47.652283: step 23496, loss 0.562575.
Train: 2018-08-01T01:21:47.808498: step 23497, loss 0.496188.
Train: 2018-08-01T01:21:47.980331: step 23498, loss 0.529219.
Train: 2018-08-01T01:21:48.120892: step 23499, loss 0.512344.
Train: 2018-08-01T01:21:48.292755: step 23500, loss 0.512103.
Test: 2018-08-01T01:21:48.761398: step 23500, loss 0.548332.
Train: 2018-08-01T01:21:49.479981: step 23501, loss 0.579331.
Train: 2018-08-01T01:21:49.667406: step 23502, loss 0.647141.
Train: 2018-08-01T01:21:49.807997: step 23503, loss 0.545459.
Train: 2018-08-01T01:21:49.964241: step 23504, loss 0.579457.
Train: 2018-08-01T01:21:50.120454: step 23505, loss 0.562431.
Train: 2018-08-01T01:21:50.292291: step 23506, loss 0.613692.
Train: 2018-08-01T01:21:50.432876: step 23507, loss 0.682153.
Train: 2018-08-01T01:21:50.604686: step 23508, loss 0.51116.
Train: 2018-08-01T01:21:50.760937: step 23509, loss 0.682054.
Train: 2018-08-01T01:21:50.917112: step 23510, loss 0.630675.
Test: 2018-08-01T01:21:51.401375: step 23510, loss 0.548182.
Train: 2018-08-01T01:21:51.557588: step 23511, loss 0.562434.
Train: 2018-08-01T01:21:51.729453: step 23512, loss 0.494508.
Train: 2018-08-01T01:21:51.885667: step 23513, loss 0.494575.
Train: 2018-08-01T01:21:52.041874: step 23514, loss 0.647282.
Train: 2018-08-01T01:21:52.198097: step 23515, loss 0.664146.
Train: 2018-08-01T01:21:52.369928: step 23516, loss 0.630093.
Train: 2018-08-01T01:21:52.526136: step 23517, loss 0.57932.
Train: 2018-08-01T01:21:52.682349: step 23518, loss 0.579283.
Train: 2018-08-01T01:21:52.838568: step 23519, loss 0.461907.
Train: 2018-08-01T01:21:52.994787: step 23520, loss 0.646222.
Test: 2018-08-01T01:21:53.463421: step 23520, loss 0.548508.
Train: 2018-08-01T01:21:53.635256: step 23521, loss 0.562502.
Train: 2018-08-01T01:21:53.791440: step 23522, loss 0.495782.
Train: 2018-08-01T01:21:53.947687: step 23523, loss 0.562516.
Train: 2018-08-01T01:21:54.103866: step 23524, loss 0.495848.
Train: 2018-08-01T01:21:54.260110: step 23525, loss 0.562513.
Train: 2018-08-01T01:21:54.416293: step 23526, loss 0.629275.
Train: 2018-08-01T01:21:54.572532: step 23527, loss 0.512446.
Train: 2018-08-01T01:21:54.744367: step 23528, loss 0.52911.
Train: 2018-08-01T01:21:54.900555: step 23529, loss 0.712954.
Train: 2018-08-01T01:21:55.056768: step 23530, loss 0.595904.
Test: 2018-08-01T01:21:55.525439: step 23530, loss 0.54855.
Train: 2018-08-01T01:21:55.681652: step 23531, loss 0.66257.
Train: 2018-08-01T01:21:55.837866: step 23532, loss 0.562531.
Train: 2018-08-01T01:21:55.994049: step 23533, loss 0.529356.
Train: 2018-08-01T01:21:56.150263: step 23534, loss 0.4797.
Train: 2018-08-01T01:21:56.322097: step 23535, loss 0.595701.
Train: 2018-08-01T01:21:56.478311: step 23536, loss 0.463161.
Train: 2018-08-01T01:21:56.650145: step 23537, loss 0.579137.
Train: 2018-08-01T01:21:56.806391: step 23538, loss 0.579146.
Train: 2018-08-01T01:21:56.962603: step 23539, loss 0.579153.
Train: 2018-08-01T01:21:57.118786: step 23540, loss 0.595784.
Test: 2018-08-01T01:21:57.603046: step 23540, loss 0.548609.
Train: 2018-08-01T01:21:57.759260: step 23541, loss 0.678922.
Train: 2018-08-01T01:21:57.915503: step 23542, loss 0.595747.
Train: 2018-08-01T01:21:58.071687: step 23543, loss 0.69514.
Train: 2018-08-01T01:21:58.227900: step 23544, loss 0.513032.
Train: 2018-08-01T01:21:58.384144: step 23545, loss 0.579081.
Train: 2018-08-01T01:21:58.555974: step 23546, loss 0.579065.
Train: 2018-08-01T01:21:58.712162: step 23547, loss 0.48058.
Train: 2018-08-01T01:21:58.868376: step 23548, loss 0.529834.
Train: 2018-08-01T01:21:59.024620: step 23549, loss 0.595456.
Train: 2018-08-01T01:21:59.180833: step 23550, loss 0.52983.
Test: 2018-08-01T01:21:59.649473: step 23550, loss 0.548892.
Train: 2018-08-01T01:21:59.805656: step 23551, loss 0.546222.
Train: 2018-08-01T01:21:59.977491: step 23552, loss 0.562629.
Train: 2018-08-01T01:22:00.133704: step 23553, loss 0.595506.
Train: 2018-08-01T01:22:00.289918: step 23554, loss 0.595516.
Train: 2018-08-01T01:22:00.446165: step 23555, loss 0.579066.
Train: 2018-08-01T01:22:00.602372: step 23556, loss 0.611966.
Train: 2018-08-01T01:22:00.774179: step 23557, loss 0.611939.
Train: 2018-08-01T01:22:00.930393: step 23558, loss 0.496955.
Train: 2018-08-01T01:22:01.086607: step 23559, loss 0.595473.
Train: 2018-08-01T01:22:01.258477: step 23560, loss 0.628296.
Test: 2018-08-01T01:22:01.727108: step 23560, loss 0.548916.
Train: 2018-08-01T01:22:01.883325: step 23561, loss 0.480662.
Train: 2018-08-01T01:22:02.039538: step 23562, loss 0.579045.
Train: 2018-08-01T01:22:02.195756: step 23563, loss 0.51342.
Train: 2018-08-01T01:22:02.351934: step 23564, loss 0.480507.
Train: 2018-08-01T01:22:02.523800: step 23565, loss 0.447366.
Train: 2018-08-01T01:22:02.680013: step 23566, loss 0.546046.
Train: 2018-08-01T01:22:02.851854: step 23567, loss 0.529359.
Train: 2018-08-01T01:22:03.008032: step 23568, loss 0.562517.
Train: 2018-08-01T01:22:03.148654: step 23569, loss 0.529046.
Train: 2018-08-01T01:22:03.320492: step 23570, loss 0.612844.
Test: 2018-08-01T01:22:03.789128: step 23570, loss 0.54836.
Train: 2018-08-01T01:22:03.976586: step 23571, loss 0.495107.
Train: 2018-08-01T01:22:04.132798: step 23572, loss 0.596246.
Train: 2018-08-01T01:22:04.289012: step 23573, loss 0.477705.
Train: 2018-08-01T01:22:04.445229: step 23574, loss 0.545419.
Train: 2018-08-01T01:22:04.601438: step 23575, loss 0.61364.
Train: 2018-08-01T01:22:04.757622: step 23576, loss 0.511075.
Train: 2018-08-01T01:22:04.913835: step 23577, loss 0.459419.
Train: 2018-08-01T01:22:05.085671: step 23578, loss 0.476235.
Train: 2018-08-01T01:22:05.226293: step 23579, loss 0.441183.
Train: 2018-08-01T01:22:05.382506: step 23580, loss 0.632144.
Test: 2018-08-01T01:22:05.851146: step 23580, loss 0.547812.
Train: 2018-08-01T01:22:06.007360: step 23581, loss 0.527467.
Train: 2018-08-01T01:22:06.179198: step 23582, loss 0.61521.
Train: 2018-08-01T01:22:06.351023: step 23583, loss 0.615391.
Train: 2018-08-01T01:22:06.507212: step 23584, loss 0.633173.
Train: 2018-08-01T01:22:06.663426: step 23585, loss 0.633234.
Train: 2018-08-01T01:22:06.819673: step 23586, loss 0.562522.
Train: 2018-08-01T01:22:06.975882: step 23587, loss 0.527188.
Train: 2018-08-01T01:22:07.132065: step 23588, loss 0.544853.
Train: 2018-08-01T01:22:07.288279: step 23589, loss 0.544851.
Train: 2018-08-01T01:22:07.444492: step 23590, loss 0.597874.
Test: 2018-08-01T01:22:07.928778: step 23590, loss 0.547724.
Train: 2018-08-01T01:22:08.084997: step 23591, loss 0.562521.
Train: 2018-08-01T01:22:08.241211: step 23592, loss 0.615512.
Train: 2018-08-01T01:22:08.428670: step 23593, loss 0.527221.
Train: 2018-08-01T01:22:08.584850: step 23594, loss 0.527238.
Train: 2018-08-01T01:22:08.756716: step 23595, loss 0.59777.
Train: 2018-08-01T01:22:08.912899: step 23596, loss 0.544882.
Train: 2018-08-01T01:22:09.069146: step 23597, loss 0.439219.
Train: 2018-08-01T01:22:09.225356: step 23598, loss 0.456721.
Train: 2018-08-01T01:22:09.381578: step 23599, loss 0.54485.
Train: 2018-08-01T01:22:09.553406: step 23600, loss 0.491697.
Test: 2018-08-01T01:22:10.022044: step 23600, loss 0.547687.
Train: 2018-08-01T01:22:10.709384: step 23601, loss 0.509281.
Train: 2018-08-01T01:22:10.865598: step 23602, loss 0.633839.
Train: 2018-08-01T01:22:11.021780: step 23603, loss 0.526911.
Train: 2018-08-01T01:22:11.178023: step 23604, loss 0.508983.
Train: 2018-08-01T01:22:11.334237: step 23605, loss 0.526803.
Train: 2018-08-01T01:22:11.490452: step 23606, loss 0.652471.
Train: 2018-08-01T01:22:11.662254: step 23607, loss 0.544699.
Train: 2018-08-01T01:22:11.818494: step 23608, loss 0.652642.
Train: 2018-08-01T01:22:11.990330: step 23609, loss 0.472767.
Train: 2018-08-01T01:22:12.146516: step 23610, loss 0.580677.
Test: 2018-08-01T01:22:12.615187: step 23610, loss 0.547618.
Train: 2018-08-01T01:22:12.802646: step 23611, loss 0.490711.
Train: 2018-08-01T01:22:12.958856: step 23612, loss 0.562696.
Train: 2018-08-01T01:22:13.115070: step 23613, loss 0.562703.
Train: 2018-08-01T01:22:13.271252: step 23614, loss 0.454541.
Train: 2018-08-01T01:22:13.427499: step 23615, loss 0.472446.
Train: 2018-08-01T01:22:13.583717: step 23616, loss 0.617054.
Train: 2018-08-01T01:22:13.739923: step 23617, loss 0.490283.
Train: 2018-08-01T01:22:13.927383: step 23618, loss 0.599114.
Train: 2018-08-01T01:22:14.083587: step 23619, loss 0.490106.
Train: 2018-08-01T01:22:14.239777: step 23620, loss 0.653878.
Test: 2018-08-01T01:22:14.708446: step 23620, loss 0.547591.
Train: 2018-08-01T01:22:14.880252: step 23621, loss 0.599267.
Train: 2018-08-01T01:22:15.052086: step 23622, loss 0.581041.
Train: 2018-08-01T01:22:15.192712: step 23623, loss 0.471869.
Train: 2018-08-01T01:22:15.348922: step 23624, loss 0.490046.
Train: 2018-08-01T01:22:15.520757: step 23625, loss 0.635694.
Train: 2018-08-01T01:22:15.676970: step 23626, loss 0.562839.
Train: 2018-08-01T01:22:15.833154: step 23627, loss 0.562834.
Train: 2018-08-01T01:22:15.989367: step 23628, loss 0.562826.
Train: 2018-08-01T01:22:16.161201: step 23629, loss 0.59918.
Train: 2018-08-01T01:22:16.317448: step 23630, loss 0.562801.
Test: 2018-08-01T01:22:16.786054: step 23630, loss 0.547596.
Train: 2018-08-01T01:22:16.942268: step 23631, loss 0.544646.
Train: 2018-08-01T01:22:17.114114: step 23632, loss 0.671477.
Train: 2018-08-01T01:22:17.270316: step 23633, loss 0.436224.
Train: 2018-08-01T01:22:17.426530: step 23634, loss 0.562728.
Train: 2018-08-01T01:22:17.582744: step 23635, loss 0.58076.
Train: 2018-08-01T01:22:17.723336: step 23636, loss 0.562703.
Train: 2018-08-01T01:22:17.879549: step 23637, loss 0.544689.
Train: 2018-08-01T01:22:18.035763: step 23638, loss 0.598642.
Train: 2018-08-01T01:22:18.285734: step 23639, loss 0.472883.
Train: 2018-08-01T01:22:18.441951: step 23640, loss 0.562657.
Test: 2018-08-01T01:22:18.894966: step 23640, loss 0.547629.
Train: 2018-08-01T01:22:19.051182: step 23641, loss 0.490888.
Train: 2018-08-01T01:22:19.222984: step 23642, loss 0.544708.
Train: 2018-08-01T01:22:19.379223: step 23643, loss 0.508796.
Train: 2018-08-01T01:22:19.535442: step 23644, loss 0.4189.
Train: 2018-08-01T01:22:19.707270: step 23645, loss 0.670793.
Train: 2018-08-01T01:22:19.847869: step 23646, loss 0.436504.
Train: 2018-08-01T01:22:20.019673: step 23647, loss 0.562732.
Train: 2018-08-01T01:22:20.175910: step 23648, loss 0.544657.
Train: 2018-08-01T01:22:20.332130: step 23649, loss 0.671534.
Train: 2018-08-01T01:22:20.503934: step 23650, loss 0.580899.
Test: 2018-08-01T01:22:20.972575: step 23650, loss 0.547597.
Train: 2018-08-01T01:22:21.144439: step 23651, loss 0.472181.
Train: 2018-08-01T01:22:21.300647: step 23652, loss 0.653413.
Train: 2018-08-01T01:22:21.456867: step 23653, loss 0.526538.
Train: 2018-08-01T01:22:21.628672: step 23654, loss 0.490336.
Train: 2018-08-01T01:22:21.800536: step 23655, loss 0.490316.
Train: 2018-08-01T01:22:21.956749: step 23656, loss 0.544647.
Train: 2018-08-01T01:22:22.112962: step 23657, loss 0.599091.
Train: 2018-08-01T01:22:22.269176: step 23658, loss 0.562796.
Train: 2018-08-01T01:22:22.425390: step 23659, loss 0.562797.
Train: 2018-08-01T01:22:22.597227: step 23660, loss 0.599106.
Test: 2018-08-01T01:22:23.065868: step 23660, loss 0.547594.
Train: 2018-08-01T01:22:23.222047: step 23661, loss 0.544643.
Train: 2018-08-01T01:22:23.393908: step 23662, loss 0.580911.
Train: 2018-08-01T01:22:23.550126: step 23663, loss 0.635231.
Train: 2018-08-01T01:22:23.706349: step 23664, loss 0.635072.
Train: 2018-08-01T01:22:23.862523: step 23665, loss 0.526645.
Train: 2018-08-01T01:22:24.034358: step 23666, loss 0.490708.
Train: 2018-08-01T01:22:24.190604: step 23667, loss 0.598615.
Train: 2018-08-01T01:22:24.346814: step 23668, loss 0.580594.
Train: 2018-08-01T01:22:24.502997: step 23669, loss 0.455177.
Train: 2018-08-01T01:22:24.659241: step 23670, loss 0.634232.
Test: 2018-08-01T01:22:25.143473: step 23670, loss 0.547645.
Train: 2018-08-01T01:22:25.299686: step 23671, loss 0.580489.
Train: 2018-08-01T01:22:25.455930: step 23672, loss 0.473367.
Train: 2018-08-01T01:22:25.612143: step 23673, loss 0.491243.
Train: 2018-08-01T01:22:25.768356: step 23674, loss 0.526909.
Train: 2018-08-01T01:22:25.940187: step 23675, loss 0.598314.
Train: 2018-08-01T01:22:26.096374: step 23676, loss 0.616171.
Train: 2018-08-01T01:22:26.252618: step 23677, loss 0.705336.
Train: 2018-08-01T01:22:26.408831: step 23678, loss 0.633755.
Train: 2018-08-01T01:22:26.565016: step 23679, loss 0.509337.
Train: 2018-08-01T01:22:26.721228: step 23680, loss 0.650983.
Test: 2018-08-01T01:22:27.205520: step 23680, loss 0.547738.
Train: 2018-08-01T01:22:27.361733: step 23681, loss 0.509611.
Train: 2018-08-01T01:22:27.517947: step 23682, loss 0.632829.
Train: 2018-08-01T01:22:27.674130: step 23683, loss 0.632581.
Train: 2018-08-01T01:22:27.845995: step 23684, loss 0.57991.
Train: 2018-08-01T01:22:28.002209: step 23685, loss 0.492868.
Train: 2018-08-01T01:22:28.174046: step 23686, loss 0.597124.
Train: 2018-08-01T01:22:28.330226: step 23687, loss 0.493231.
Train: 2018-08-01T01:22:28.486439: step 23688, loss 0.648767.
Train: 2018-08-01T01:22:28.642685: step 23689, loss 0.57964.
Train: 2018-08-01T01:22:28.798901: step 23690, loss 0.59677.
Test: 2018-08-01T01:22:29.267506: step 23690, loss 0.548073.
Train: 2018-08-01T01:22:29.423720: step 23691, loss 0.596672.
Train: 2018-08-01T01:22:29.579934: step 23692, loss 0.630721.
Train: 2018-08-01T01:22:29.751793: step 23693, loss 0.579436.
Train: 2018-08-01T01:22:29.908013: step 23694, loss 0.460717.
Train: 2018-08-01T01:22:30.079817: step 23695, loss 0.545513.
Train: 2018-08-01T01:22:30.236073: step 23696, loss 0.630045.
Train: 2018-08-01T01:22:30.423487: step 23697, loss 0.629912.
Train: 2018-08-01T01:22:30.579701: step 23698, loss 0.545639.
Train: 2018-08-01T01:22:30.735944: step 23699, loss 0.545686.
Train: 2018-08-01T01:22:30.892127: step 23700, loss 0.545723.
Test: 2018-08-01T01:22:31.376413: step 23700, loss 0.54847.
Train: 2018-08-01T01:22:32.126212: step 23701, loss 0.612688.
Train: 2018-08-01T01:22:32.282451: step 23702, loss 0.478964.
Train: 2018-08-01T01:22:32.438674: step 23703, loss 0.579196.
Train: 2018-08-01T01:22:32.610473: step 23704, loss 0.612583.
Train: 2018-08-01T01:22:32.766688: step 23705, loss 0.529146.
Train: 2018-08-01T01:22:32.922930: step 23706, loss 0.445791.
Train: 2018-08-01T01:22:33.079145: step 23707, loss 0.462305.
Train: 2018-08-01T01:22:33.235358: step 23708, loss 0.579226.
Train: 2018-08-01T01:22:33.391571: step 23709, loss 0.629615.
Train: 2018-08-01T01:22:33.563411: step 23710, loss 0.663312.
Test: 2018-08-01T01:22:34.032046: step 23710, loss 0.54839.
Train: 2018-08-01T01:22:34.203881: step 23711, loss 0.545657.
Train: 2018-08-01T01:22:34.360066: step 23712, loss 0.579268.
Train: 2018-08-01T01:22:34.516308: step 23713, loss 0.579267.
Train: 2018-08-01T01:22:34.703765: step 23714, loss 0.545662.
Train: 2018-08-01T01:22:34.859978: step 23715, loss 0.562463.
Train: 2018-08-01T01:22:35.016162: step 23716, loss 0.545657.
Train: 2018-08-01T01:22:35.156754: step 23717, loss 0.461588.
Train: 2018-08-01T01:22:35.312991: step 23718, loss 0.545608.
Train: 2018-08-01T01:22:35.469180: step 23719, loss 0.697464.
Train: 2018-08-01T01:22:35.625423: step 23720, loss 0.579321.
Test: 2018-08-01T01:22:36.109684: step 23720, loss 0.548317.
Train: 2018-08-01T01:22:36.265898: step 23721, loss 0.461212.
Train: 2018-08-01T01:22:36.422083: step 23722, loss 0.562441.
Train: 2018-08-01T01:22:36.578325: step 23723, loss 0.596264.
Train: 2018-08-01T01:22:36.750160: step 23724, loss 0.545511.
Train: 2018-08-01T01:22:36.906375: step 23725, loss 0.528555.
Train: 2018-08-01T01:22:37.062581: step 23726, loss 0.511548.
Train: 2018-08-01T01:22:37.234425: step 23727, loss 0.579417.
Train: 2018-08-01T01:22:37.374983: step 23728, loss 0.613475.
Train: 2018-08-01T01:22:37.546848: step 23729, loss 0.579449.
Train: 2018-08-01T01:22:37.703057: step 23730, loss 0.494277.
Test: 2018-08-01T01:22:38.171672: step 23730, loss 0.548133.
Train: 2018-08-01T01:22:38.327916: step 23731, loss 0.698882.
Train: 2018-08-01T01:22:38.484100: step 23732, loss 0.460141.
Train: 2018-08-01T01:22:38.640343: step 23733, loss 0.596537.
Train: 2018-08-01T01:22:38.796526: step 23734, loss 0.562417.
Train: 2018-08-01T01:22:38.968385: step 23735, loss 0.46.
Train: 2018-08-01T01:22:39.124605: step 23736, loss 0.59661.
Train: 2018-08-01T01:22:39.280787: step 23737, loss 0.665108.
Train: 2018-08-01T01:22:39.437000: step 23738, loss 0.596629.
Train: 2018-08-01T01:22:39.593244: step 23739, loss 0.579507.
Train: 2018-08-01T01:22:39.749427: step 23740, loss 0.47704.
Test: 2018-08-01T01:22:40.218098: step 23740, loss 0.548113.
Train: 2018-08-01T01:22:40.374312: step 23741, loss 0.562416.
Train: 2018-08-01T01:22:40.530496: step 23742, loss 0.682005.
Train: 2018-08-01T01:22:40.686708: step 23743, loss 0.494175.
Train: 2018-08-01T01:22:40.842921: step 23744, loss 0.511251.
Train: 2018-08-01T01:22:41.014781: step 23745, loss 0.52829.
Train: 2018-08-01T01:22:41.171002: step 23746, loss 0.528259.
Train: 2018-08-01T01:22:41.342835: step 23747, loss 0.579515.
Train: 2018-08-01T01:22:41.514670: step 23748, loss 0.596646.
Train: 2018-08-01T01:22:41.670883: step 23749, loss 0.511045.
Train: 2018-08-01T01:22:41.827067: step 23750, loss 0.648117.
Test: 2018-08-01T01:22:42.295741: step 23750, loss 0.548063.
Train: 2018-08-01T01:22:42.467571: step 23751, loss 0.596687.
Train: 2018-08-01T01:22:42.623785: step 23752, loss 0.630915.
Train: 2018-08-01T01:22:42.795590: step 23753, loss 0.528215.
Train: 2018-08-01T01:22:42.951828: step 23754, loss 0.511163.
Train: 2018-08-01T01:22:43.108047: step 23755, loss 0.596579.
Train: 2018-08-01T01:22:43.264260: step 23756, loss 0.596561.
Train: 2018-08-01T01:22:43.436065: step 23757, loss 0.54536.
Train: 2018-08-01T01:22:43.592309: step 23758, loss 0.511277.
Train: 2018-08-01T01:22:43.748522: step 23759, loss 0.562417.
Train: 2018-08-01T01:22:43.904734: step 23760, loss 0.511257.
Test: 2018-08-01T01:22:44.388997: step 23760, loss 0.548123.
Train: 2018-08-01T01:22:44.545180: step 23761, loss 0.545347.
Train: 2018-08-01T01:22:44.701423: step 23762, loss 0.596588.
Train: 2018-08-01T01:22:44.857631: step 23763, loss 0.545319.
Train: 2018-08-01T01:22:45.013844: step 23764, loss 0.613734.
Train: 2018-08-01T01:22:45.170057: step 23765, loss 0.511096.
Train: 2018-08-01T01:22:45.326277: step 23766, loss 0.68223.
Train: 2018-08-01T01:22:45.482484: step 23767, loss 0.528216.
Train: 2018-08-01T01:22:45.638706: step 23768, loss 0.562414.
Train: 2018-08-01T01:22:45.794886: step 23769, loss 0.699083.
Train: 2018-08-01T01:22:45.951100: step 23770, loss 0.545372.
Test: 2018-08-01T01:22:46.435391: step 23770, loss 0.548172.
Train: 2018-08-01T01:22:46.591606: step 23771, loss 0.613465.
Train: 2018-08-01T01:22:46.794677: step 23772, loss 0.511495.
Train: 2018-08-01T01:22:46.935279: step 23773, loss 0.545474.
Train: 2018-08-01T01:22:47.107080: step 23774, loss 0.56243.
Train: 2018-08-01T01:22:47.263323: step 23775, loss 0.714764.
Train: 2018-08-01T01:22:47.419506: step 23776, loss 0.562442.
Train: 2018-08-01T01:22:47.575719: step 23777, loss 0.545615.
Train: 2018-08-01T01:22:47.731933: step 23778, loss 0.444831.
Train: 2018-08-01T01:22:47.903768: step 23779, loss 0.598309.
Train: 2018-08-01T01:22:48.075633: step 23780, loss 0.612852.
Test: 2018-08-01T01:22:48.544244: step 23780, loss 0.548416.
Train: 2018-08-01T01:22:48.700480: step 23781, loss 0.596025.
Train: 2018-08-01T01:22:48.856706: step 23782, loss 0.545717.
Train: 2018-08-01T01:22:49.028534: step 23783, loss 0.579219.
Train: 2018-08-01T01:22:49.184718: step 23784, loss 0.428688.
Train: 2018-08-01T01:22:49.340931: step 23785, loss 0.595964.
Train: 2018-08-01T01:22:49.497144: step 23786, loss 0.528968.
Train: 2018-08-01T01:22:49.653358: step 23787, loss 0.663098.
Train: 2018-08-01T01:22:49.809571: step 23788, loss 0.512175.
Train: 2018-08-01T01:22:49.965785: step 23789, loss 0.679878.
Train: 2018-08-01T01:22:50.122029: step 23790, loss 0.59598.
Test: 2018-08-01T01:22:50.606290: step 23790, loss 0.548475.
Train: 2018-08-01T01:22:50.762504: step 23791, loss 0.612666.
Train: 2018-08-01T01:22:50.918720: step 23792, loss 0.562494.
Train: 2018-08-01T01:22:51.090522: step 23793, loss 0.545838.
Train: 2018-08-01T01:22:51.246760: step 23794, loss 0.545866.
Train: 2018-08-01T01:22:51.402948: step 23795, loss 0.545883.
Train: 2018-08-01T01:22:51.559196: step 23796, loss 0.662289.
Train: 2018-08-01T01:22:51.715376: step 23797, loss 0.612333.
Train: 2018-08-01T01:22:51.871615: step 23798, loss 0.645376.
Train: 2018-08-01T01:22:52.043448: step 23799, loss 0.513021.
Train: 2018-08-01T01:22:52.199673: step 23800, loss 0.645013.
Test: 2018-08-01T01:22:52.668307: step 23800, loss 0.548844.
Train: 2018-08-01T01:22:53.402510: step 23801, loss 0.52973.
Train: 2018-08-01T01:22:53.558694: step 23802, loss 0.5134.
Train: 2018-08-01T01:22:53.714938: step 23803, loss 0.611823.
Train: 2018-08-01T01:22:53.871151: step 23804, loss 0.5299.
Train: 2018-08-01T01:22:54.027364: step 23805, loss 0.529924.
Train: 2018-08-01T01:22:54.183582: step 23806, loss 0.497183.
Train: 2018-08-01T01:22:54.355408: step 23807, loss 0.464311.
Train: 2018-08-01T01:22:54.511627: step 23808, loss 0.644779.
Train: 2018-08-01T01:22:54.667839: step 23809, loss 0.529689.
Train: 2018-08-01T01:22:54.824053: step 23810, loss 0.513125.
Test: 2018-08-01T01:22:55.308318: step 23810, loss 0.548723.
Train: 2018-08-01T01:22:55.526983: step 23811, loss 0.628677.
Train: 2018-08-01T01:22:55.683197: step 23812, loss 0.562552.
Train: 2018-08-01T01:22:55.839440: step 23813, loss 0.529392.
Train: 2018-08-01T01:22:55.995653: step 23814, loss 0.545923.
Train: 2018-08-01T01:22:56.151867: step 23815, loss 0.529237.
Train: 2018-08-01T01:22:56.308084: step 23816, loss 0.529143.
Train: 2018-08-01T01:22:56.479914: step 23817, loss 0.562483.
Train: 2018-08-01T01:22:56.636098: step 23818, loss 0.596.
Train: 2018-08-01T01:22:56.792336: step 23819, loss 0.528868.
Train: 2018-08-01T01:22:56.948560: step 23820, loss 0.444617.
Test: 2018-08-01T01:22:57.432820: step 23820, loss 0.548288.
Train: 2018-08-01T01:22:57.589031: step 23821, loss 0.596228.
Train: 2018-08-01T01:22:57.745249: step 23822, loss 0.545483.
Train: 2018-08-01T01:22:57.901428: step 23823, loss 0.545427.
Train: 2018-08-01T01:22:58.073291: step 23824, loss 0.443122.
Train: 2018-08-01T01:22:58.229474: step 23825, loss 0.528183.
Train: 2018-08-01T01:22:58.385719: step 23826, loss 0.545224.
Train: 2018-08-01T01:22:58.541935: step 23827, loss 0.648697.
Train: 2018-08-01T01:22:58.698145: step 23828, loss 0.579717.
Train: 2018-08-01T01:22:58.869950: step 23829, loss 0.666416.
Train: 2018-08-01T01:22:59.026165: step 23830, loss 0.597099.
Test: 2018-08-01T01:22:59.510426: step 23830, loss 0.547907.
Train: 2018-08-01T01:22:59.651017: step 23831, loss 0.597091.
Train: 2018-08-01T01:22:59.822851: step 23832, loss 0.527776.
Train: 2018-08-01T01:22:59.994718: step 23833, loss 0.545101.
Train: 2018-08-01T01:23:00.166548: step 23834, loss 0.475819.
Train: 2018-08-01T01:23:00.322765: step 23835, loss 0.597104.
Train: 2018-08-01T01:23:00.478948: step 23836, loss 0.510374.
Train: 2018-08-01T01:23:00.635161: step 23837, loss 0.492947.
Train: 2018-08-01T01:23:00.775753: step 23838, loss 0.458011.
Train: 2018-08-01T01:23:00.947615: step 23839, loss 0.544987.
Train: 2018-08-01T01:23:01.119454: step 23840, loss 0.597474.
Test: 2018-08-01T01:23:01.588094: step 23840, loss 0.547776.
Train: 2018-08-01T01:23:01.744307: step 23841, loss 0.47474.
Train: 2018-08-01T01:23:01.900490: step 23842, loss 0.650473.
Train: 2018-08-01T01:23:02.056731: step 23843, loss 0.562493.
Train: 2018-08-01T01:23:02.212917: step 23844, loss 0.474277.
Train: 2018-08-01T01:23:02.384782: step 23845, loss 0.544833.
Train: 2018-08-01T01:23:02.540998: step 23846, loss 0.562531.
Train: 2018-08-01T01:23:02.697179: step 23847, loss 0.544794.
Train: 2018-08-01T01:23:02.853393: step 23848, loss 0.59812.
Train: 2018-08-01T01:23:03.009605: step 23849, loss 0.52697.
Train: 2018-08-01T01:23:03.165823: step 23850, loss 0.633857.
Test: 2018-08-01T01:23:03.650105: step 23850, loss 0.547655.
Train: 2018-08-01T01:23:03.806328: step 23851, loss 0.580399.
Train: 2018-08-01T01:23:03.962537: step 23852, loss 0.43786.
Train: 2018-08-01T01:23:04.118752: step 23853, loss 0.509072.
Train: 2018-08-01T01:23:04.274935: step 23854, loss 0.544735.
Train: 2018-08-01T01:23:04.431148: step 23855, loss 0.669997.
Train: 2018-08-01T01:23:04.603007: step 23856, loss 0.544722.
Train: 2018-08-01T01:23:04.743574: step 23857, loss 0.544722.
Train: 2018-08-01T01:23:04.899788: step 23858, loss 0.54472.
Train: 2018-08-01T01:23:05.056001: step 23859, loss 0.526815.
Train: 2018-08-01T01:23:05.212215: step 23860, loss 0.705934.
Test: 2018-08-01T01:23:05.680889: step 23860, loss 0.547634.
Train: 2018-08-01T01:23:05.837098: step 23861, loss 0.580501.
Train: 2018-08-01T01:23:05.993311: step 23862, loss 0.473307.
Train: 2018-08-01T01:23:06.149496: step 23863, loss 0.616141.
Train: 2018-08-01T01:23:06.305708: step 23864, loss 0.544753.
Train: 2018-08-01T01:23:06.461923: step 23865, loss 0.633811.
Train: 2018-08-01T01:23:06.618135: step 23866, loss 0.580331.
Train: 2018-08-01T01:23:06.774350: step 23867, loss 0.52706.
Train: 2018-08-01T01:23:06.930596: step 23868, loss 0.597952.
Train: 2018-08-01T01:23:07.086806: step 23869, loss 0.597871.
Train: 2018-08-01T01:23:07.242989: step 23870, loss 0.562498.
Test: 2018-08-01T01:23:07.711659: step 23870, loss 0.547746.
Train: 2018-08-01T01:23:07.883495: step 23871, loss 0.527282.
Train: 2018-08-01T01:23:08.039679: step 23872, loss 0.632773.
Train: 2018-08-01T01:23:08.195890: step 23873, loss 0.527398.
Train: 2018-08-01T01:23:08.352104: step 23874, loss 0.562455.
Train: 2018-08-01T01:23:08.523970: step 23875, loss 0.667286.
Train: 2018-08-01T01:23:08.695805: step 23876, loss 0.562436.
Train: 2018-08-01T01:23:08.836396: step 23877, loss 0.545052.
Train: 2018-08-01T01:23:09.008201: step 23878, loss 0.527747.
Train: 2018-08-01T01:23:09.164444: step 23879, loss 0.614347.
Train: 2018-08-01T01:23:09.320628: step 23880, loss 0.545142.
Test: 2018-08-01T01:23:09.789268: step 23880, loss 0.547973.
Train: 2018-08-01T01:23:09.945481: step 23881, loss 0.562412.
Train: 2018-08-01T01:23:10.101694: step 23882, loss 0.579626.
Train: 2018-08-01T01:23:10.257938: step 23883, loss 0.510848.
Train: 2018-08-01T01:23:10.429777: step 23884, loss 0.596755.
Train: 2018-08-01T01:23:10.585957: step 23885, loss 0.459491.
Train: 2018-08-01T01:23:10.742170: step 23886, loss 0.648202.
Train: 2018-08-01T01:23:10.914005: step 23887, loss 0.459546.
Train: 2018-08-01T01:23:11.054597: step 23888, loss 0.476636.
Train: 2018-08-01T01:23:11.210840: step 23889, loss 0.613962.
Train: 2018-08-01T01:23:11.367024: step 23890, loss 0.579608.
Test: 2018-08-01T01:23:11.851315: step 23890, loss 0.548.
Train: 2018-08-01T01:23:12.007499: step 23891, loss 0.527994.
Train: 2018-08-01T01:23:12.179367: step 23892, loss 0.56241.
Train: 2018-08-01T01:23:12.335547: step 23893, loss 0.66584.
Train: 2018-08-01T01:23:12.491785: step 23894, loss 0.579637.
Train: 2018-08-01T01:23:12.663629: step 23895, loss 0.47635.
Train: 2018-08-01T01:23:12.804186: step 23896, loss 0.56241.
Train: 2018-08-01T01:23:12.960400: step 23897, loss 0.614084.
Train: 2018-08-01T01:23:13.147857: step 23898, loss 0.579627.
Train: 2018-08-01T01:23:13.304104: step 23899, loss 0.545202.
Train: 2018-08-01T01:23:13.460313: step 23900, loss 0.579611.
Test: 2018-08-01T01:23:13.928957: step 23900, loss 0.548012.
Train: 2018-08-01T01:23:14.678772: step 23901, loss 0.459255.
Train: 2018-08-01T01:23:14.834961: step 23902, loss 0.596825.
Train: 2018-08-01T01:23:14.991205: step 23903, loss 0.596838.
Train: 2018-08-01T01:23:15.147418: step 23904, loss 0.510776.
Train: 2018-08-01T01:23:15.319247: step 23905, loss 0.510748.
Train: 2018-08-01T01:23:15.475464: step 23906, loss 0.562411.
Train: 2018-08-01T01:23:15.631683: step 23907, loss 0.631448.
Train: 2018-08-01T01:23:15.787896: step 23908, loss 0.527895.
Train: 2018-08-01T01:23:15.944101: step 23909, loss 0.545146.
Train: 2018-08-01T01:23:16.100291: step 23910, loss 0.596967.
Test: 2018-08-01T01:23:16.584581: step 23910, loss 0.547946.
Train: 2018-08-01T01:23:16.740801: step 23911, loss 0.648802.
Train: 2018-08-01T01:23:16.896978: step 23912, loss 0.596928.
Train: 2018-08-01T01:23:17.053226: step 23913, loss 0.56241.
Train: 2018-08-01T01:23:17.209439: step 23914, loss 0.665659.
Train: 2018-08-01T01:23:17.381270: step 23915, loss 0.528083.
Train: 2018-08-01T01:23:17.553074: step 23916, loss 0.459631.
Train: 2018-08-01T01:23:17.709318: step 23917, loss 0.562408.
Train: 2018-08-01T01:23:17.865532: step 23918, loss 0.630885.
Train: 2018-08-01T01:23:18.021715: step 23919, loss 0.562409.
Train: 2018-08-01T01:23:18.177963: step 23920, loss 0.579491.
Test: 2018-08-01T01:23:18.646599: step 23920, loss 0.548125.
Train: 2018-08-01T01:23:18.802807: step 23921, loss 0.613593.
Train: 2018-08-01T01:23:18.958995: step 23922, loss 0.562414.
Train: 2018-08-01T01:23:19.115242: step 23923, loss 0.562417.
Train: 2018-08-01T01:23:19.271422: step 23924, loss 0.494497.
Train: 2018-08-01T01:23:19.427670: step 23925, loss 0.545444.
Train: 2018-08-01T01:23:19.599495: step 23926, loss 0.494513.
Train: 2018-08-01T01:23:19.755720: step 23927, loss 0.596406.
Train: 2018-08-01T01:23:19.911928: step 23928, loss 0.477406.
Train: 2018-08-01T01:23:20.068142: step 23929, loss 0.630534.
Train: 2018-08-01T01:23:20.224324: step 23930, loss 0.460176.
Test: 2018-08-01T01:23:20.708585: step 23930, loss 0.548114.
Train: 2018-08-01T01:23:20.864799: step 23931, loss 0.511193.
Train: 2018-08-01T01:23:21.021014: step 23932, loss 0.665095.
Train: 2018-08-01T01:23:21.192878: step 23933, loss 0.562408.
Train: 2018-08-01T01:23:21.349091: step 23934, loss 0.545267.
Train: 2018-08-01T01:23:21.505305: step 23935, loss 0.562407.
Train: 2018-08-01T01:23:21.661517: step 23936, loss 0.579577.
Train: 2018-08-01T01:23:21.833348: step 23937, loss 0.459339.
Train: 2018-08-01T01:23:21.989564: step 23938, loss 0.579618.
Train: 2018-08-01T01:23:22.145749: step 23939, loss 0.56241.
Train: 2018-08-01T01:23:22.301988: step 23940, loss 0.631434.
Test: 2018-08-01T01:23:22.786254: step 23940, loss 0.547959.
Train: 2018-08-01T01:23:22.958060: step 23941, loss 0.665963.
Train: 2018-08-01T01:23:23.114273: step 23942, loss 0.596883.
Train: 2018-08-01T01:23:23.270516: step 23943, loss 0.545199.
Train: 2018-08-01T01:23:23.426700: step 23944, loss 0.47647.
Train: 2018-08-01T01:23:23.582913: step 23945, loss 0.596784.
Train: 2018-08-01T01:23:23.739159: step 23946, loss 0.545226.
Train: 2018-08-01T01:23:23.895370: step 23947, loss 0.562407.
Train: 2018-08-01T01:23:24.051553: step 23948, loss 0.579583.
Train: 2018-08-01T01:23:24.207796: step 23949, loss 0.528068.
Train: 2018-08-01T01:23:24.363979: step 23950, loss 0.510891.
Test: 2018-08-01T01:23:24.832650: step 23950, loss 0.548016.
Train: 2018-08-01T01:23:24.988834: step 23951, loss 0.493663.
Train: 2018-08-01T01:23:25.145078: step 23952, loss 0.717344.
Train: 2018-08-01T01:23:25.301295: step 23953, loss 0.527999.
Train: 2018-08-01T01:23:25.457474: step 23954, loss 0.579611.
Train: 2018-08-01T01:23:25.613688: step 23955, loss 0.614.
Train: 2018-08-01T01:23:25.769902: step 23956, loss 0.493687.
Train: 2018-08-01T01:23:25.926113: step 23957, loss 0.476504.
Train: 2018-08-01T01:23:26.082328: step 23958, loss 0.510804.
Train: 2018-08-01T01:23:26.254162: step 23959, loss 0.596872.
Train: 2018-08-01T01:23:26.410406: step 23960, loss 0.579661.
Test: 2018-08-01T01:23:26.879046: step 23960, loss 0.547955.
Train: 2018-08-01T01:23:27.035229: step 23961, loss 0.51062.
Train: 2018-08-01T01:23:27.191473: step 23962, loss 0.614274.
Train: 2018-08-01T01:23:27.363278: step 23963, loss 0.57971.
Train: 2018-08-01T01:23:27.519491: step 23964, loss 0.527817.
Train: 2018-08-01T01:23:27.675704: step 23965, loss 0.527797.
Train: 2018-08-01T01:23:27.831942: step 23966, loss 0.562418.
Train: 2018-08-01T01:23:27.988131: step 23967, loss 0.510396.
Train: 2018-08-01T01:23:28.144345: step 23968, loss 0.545057.
Train: 2018-08-01T01:23:28.300592: step 23969, loss 0.57982.
Train: 2018-08-01T01:23:28.472392: step 23970, loss 0.597253.
Test: 2018-08-01T01:23:28.941063: step 23970, loss 0.547847.
Train: 2018-08-01T01:23:29.097246: step 23971, loss 0.579851.
Train: 2018-08-01T01:23:29.253459: step 23972, loss 0.510172.
Train: 2018-08-01T01:23:29.409704: step 23973, loss 0.527568.
Train: 2018-08-01T01:23:29.581508: step 23974, loss 0.544987.
Train: 2018-08-01T01:23:29.722100: step 23975, loss 0.579918.
Train: 2018-08-01T01:23:29.893960: step 23976, loss 0.632395.
Train: 2018-08-01T01:23:30.034528: step 23977, loss 0.632373.
Train: 2018-08-01T01:23:30.221984: step 23978, loss 0.562442.
Train: 2018-08-01T01:23:30.378196: step 23979, loss 0.492682.
Train: 2018-08-01T01:23:30.534410: step 23980, loss 0.51013.
Test: 2018-08-01T01:23:31.003081: step 23980, loss 0.547831.
Train: 2018-08-01T01:23:31.159289: step 23981, loss 0.457774.
Train: 2018-08-01T01:23:31.315478: step 23982, loss 0.61487.
Train: 2018-08-01T01:23:31.471721: step 23983, loss 0.50998.
Train: 2018-08-01T01:23:31.627904: step 23984, loss 0.457371.
Train: 2018-08-01T01:23:31.815359: step 23985, loss 0.615146.
Train: 2018-08-01T01:23:31.971573: step 23986, loss 0.544891.
Train: 2018-08-01T01:23:32.112165: step 23987, loss 0.615327.
Train: 2018-08-01T01:23:32.268409: step 23988, loss 0.615364.
Train: 2018-08-01T01:23:32.440238: step 23989, loss 0.509626.
Train: 2018-08-01T01:23:32.596427: step 23990, loss 0.650632.
Test: 2018-08-01T01:23:33.065066: step 23990, loss 0.547737.
Train: 2018-08-01T01:23:33.221280: step 23991, loss 0.668163.
Train: 2018-08-01T01:23:33.377495: step 23992, loss 0.59762.
Train: 2018-08-01T01:23:33.533741: step 23993, loss 0.474815.
Train: 2018-08-01T01:23:33.689952: step 23994, loss 0.50993.
Train: 2018-08-01T01:23:33.846176: step 23995, loss 0.562451.
Train: 2018-08-01T01:23:34.018008: step 23996, loss 0.614923.
Train: 2018-08-01T01:23:34.189834: step 23997, loss 0.562444.
Train: 2018-08-01T01:23:34.346048: step 23998, loss 0.544988.
Train: 2018-08-01T01:23:34.502261: step 23999, loss 0.579873.
Train: 2018-08-01T01:23:34.674090: step 24000, loss 0.719201.
Test: 2018-08-01T01:23:35.142739: step 24000, loss 0.547881.
Train: 2018-08-01T01:23:35.908151: step 24001, loss 0.492961.
Train: 2018-08-01T01:23:36.079987: step 24002, loss 0.579755.
Train: 2018-08-01T01:23:36.236230: step 24003, loss 0.70086.
Train: 2018-08-01T01:23:36.392438: step 24004, loss 0.510663.
Train: 2018-08-01T01:23:36.548627: step 24005, loss 0.562407.
Train: 2018-08-01T01:23:36.704841: step 24006, loss 0.579578.
Train: 2018-08-01T01:23:36.861053: step 24007, loss 0.459595.
Train: 2018-08-01T01:23:37.017267: step 24008, loss 0.562406.
Train: 2018-08-01T01:23:37.189103: step 24009, loss 0.511064.
Train: 2018-08-01T01:23:37.345316: step 24010, loss 0.630871.
Test: 2018-08-01T01:23:37.813956: step 24010, loss 0.548085.
Train: 2018-08-01T01:23:37.970169: step 24011, loss 0.579511.
Train: 2018-08-01T01:23:38.126383: step 24012, loss 0.476963.
Train: 2018-08-01T01:23:38.282598: step 24013, loss 0.528219.
Train: 2018-08-01T01:23:38.438809: step 24014, loss 0.476876.
Train: 2018-08-01T01:23:38.595053: step 24015, loss 0.596676.
Train: 2018-08-01T01:23:38.751266: step 24016, loss 0.613868.
Train: 2018-08-01T01:23:38.907483: step 24017, loss 0.545245.
Train: 2018-08-01T01:23:39.063663: step 24018, loss 0.545236.
Train: 2018-08-01T01:23:39.219906: step 24019, loss 0.665495.
Train: 2018-08-01T01:23:39.391743: step 24020, loss 0.510894.
Test: 2018-08-01T01:23:39.860381: step 24020, loss 0.548027.
Train: 2018-08-01T01:23:40.016595: step 24021, loss 0.579577.
Train: 2018-08-01T01:23:40.172812: step 24022, loss 0.528069.
Train: 2018-08-01T01:23:40.344643: step 24023, loss 0.510887.
Train: 2018-08-01T01:23:40.516486: step 24024, loss 0.61397.
Train: 2018-08-01T01:23:40.672695: step 24025, loss 0.699929.
Train: 2018-08-01T01:23:40.828875: step 24026, loss 0.493752.
Train: 2018-08-01T01:23:40.985088: step 24027, loss 0.613867.
Train: 2018-08-01T01:23:41.141325: step 24028, loss 0.562406.
Train: 2018-08-01T01:23:41.297548: step 24029, loss 0.596639.
Train: 2018-08-01T01:23:41.453758: step 24030, loss 0.47694.
Test: 2018-08-01T01:23:41.922402: step 24030, loss 0.548095.
Train: 2018-08-01T01:23:42.078612: step 24031, loss 0.613681.
Train: 2018-08-01T01:23:42.250448: step 24032, loss 0.528251.
Train: 2018-08-01T01:23:42.406660: step 24033, loss 0.596556.
Train: 2018-08-01T01:23:42.562875: step 24034, loss 0.562409.
Train: 2018-08-01T01:23:42.719056: step 24035, loss 0.460085.
Train: 2018-08-01T01:23:42.875294: step 24036, loss 0.477069.
Train: 2018-08-01T01:23:43.031484: step 24037, loss 0.52821.
Train: 2018-08-01T01:23:43.187698: step 24038, loss 0.528138.
Train: 2018-08-01T01:23:43.343935: step 24039, loss 0.493715.
Train: 2018-08-01T01:23:43.500125: step 24040, loss 0.562407.
Test: 2018-08-01T01:23:43.984416: step 24040, loss 0.547951.
Train: 2018-08-01T01:23:44.140631: step 24041, loss 0.545143.
Train: 2018-08-01T01:23:44.296812: step 24042, loss 0.666272.
Train: 2018-08-01T01:23:44.453025: step 24043, loss 0.475784.
Train: 2018-08-01T01:23:44.609239: step 24044, loss 0.57978.
Train: 2018-08-01T01:23:44.765483: step 24045, loss 0.666731.
Train: 2018-08-01T01:23:44.937315: step 24046, loss 0.701503.
Train: 2018-08-01T01:23:45.093500: step 24047, loss 0.510354.
Train: 2018-08-01T01:23:45.249714: step 24048, loss 0.545079.
Train: 2018-08-01T01:23:45.405928: step 24049, loss 0.458449.
Train: 2018-08-01T01:23:45.562171: step 24050, loss 0.562418.
Test: 2018-08-01T01:23:46.030780: step 24050, loss 0.547892.
Train: 2018-08-01T01:23:46.187019: step 24051, loss 0.510374.
Train: 2018-08-01T01:23:46.358859: step 24052, loss 0.562422.
Train: 2018-08-01T01:23:46.499446: step 24053, loss 0.545041.
Train: 2018-08-01T01:23:46.671284: step 24054, loss 0.562428.
Train: 2018-08-01T01:23:46.843121: step 24055, loss 0.597264.
Train: 2018-08-01T01:23:46.999304: step 24056, loss 0.632121.
Train: 2018-08-01T01:23:47.155548: step 24057, loss 0.597254.
Train: 2018-08-01T01:23:47.311762: step 24058, loss 0.492846.
Train: 2018-08-01T01:23:47.467974: step 24059, loss 0.44067.
Train: 2018-08-01T01:23:47.624158: step 24060, loss 0.562431.
Test: 2018-08-01T01:23:48.092826: step 24060, loss 0.547833.
Train: 2018-08-01T01:23:48.264671: step 24061, loss 0.632185.
Train: 2018-08-01T01:23:48.420871: step 24062, loss 0.492674.
Train: 2018-08-01T01:23:48.577091: step 24063, loss 0.632267.
Train: 2018-08-01T01:23:48.733298: step 24064, loss 0.597352.
Train: 2018-08-01T01:23:48.905141: step 24065, loss 0.614781.
Train: 2018-08-01T01:23:49.061352: step 24066, loss 0.562433.
Train: 2018-08-01T01:23:49.217535: step 24067, loss 0.545019.
Train: 2018-08-01T01:23:49.389394: step 24068, loss 0.562427.
Train: 2018-08-01T01:23:49.545617: step 24069, loss 0.597192.
Train: 2018-08-01T01:23:49.701796: step 24070, loss 0.510328.
Test: 2018-08-01T01:23:50.170470: step 24070, loss 0.547885.
Train: 2018-08-01T01:23:50.342271: step 24071, loss 0.718636.
Train: 2018-08-01T01:23:50.498484: step 24072, loss 0.510461.
Train: 2018-08-01T01:23:50.654723: step 24073, loss 0.596997.
Train: 2018-08-01T01:23:50.795325: step 24074, loss 0.527885.
Train: 2018-08-01T01:23:50.967156: step 24075, loss 0.562407.
Train: 2018-08-01T01:23:51.123368: step 24076, loss 0.47629.
Train: 2018-08-01T01:23:51.263960: step 24077, loss 0.61408.
Train: 2018-08-01T01:23:51.435766: step 24078, loss 0.562406.
Train: 2018-08-01T01:23:51.591979: step 24079, loss 0.614022.
Train: 2018-08-01T01:23:51.748192: step 24080, loss 0.635733.
Test: 2018-08-01T01:23:52.216833: step 24080, loss 0.548041.
Train: 2018-08-01T01:23:52.373046: step 24081, loss 0.613865.
Train: 2018-08-01T01:23:52.576154: step 24082, loss 0.511066.
Train: 2018-08-01T01:23:52.732337: step 24083, loss 0.630757.
Train: 2018-08-01T01:23:52.888580: step 24084, loss 0.63061.
Train: 2018-08-01T01:23:53.044797: step 24085, loss 0.562414.
Train: 2018-08-01T01:23:53.200976: step 24086, loss 0.545459.
Train: 2018-08-01T01:23:53.357190: step 24087, loss 0.511647.
Train: 2018-08-01T01:23:53.529025: step 24088, loss 0.4948.
Train: 2018-08-01T01:23:53.685269: step 24089, loss 0.545524.
Train: 2018-08-01T01:23:53.841477: step 24090, loss 0.613151.
Test: 2018-08-01T01:23:54.310123: step 24090, loss 0.548278.
Train: 2018-08-01T01:23:54.466334: step 24091, loss 0.477932.
Train: 2018-08-01T01:23:54.622549: step 24092, loss 0.579339.
Train: 2018-08-01T01:23:54.790246: step 24093, loss 0.528588.
Train: 2018-08-01T01:23:54.946458: step 24094, loss 0.579357.
Train: 2018-08-01T01:23:55.102703: step 24095, loss 0.59631.
Train: 2018-08-01T01:23:55.258885: step 24096, loss 0.511581.
Train: 2018-08-01T01:23:55.399507: step 24097, loss 0.528498.
Train: 2018-08-01T01:23:55.571313: step 24098, loss 0.681283.
Train: 2018-08-01T01:23:55.727556: step 24099, loss 0.528469.
Train: 2018-08-01T01:23:55.883739: step 24100, loss 0.545441.
Test: 2018-08-01T01:23:56.368000: step 24100, loss 0.548196.
Train: 2018-08-01T01:23:57.055365: step 24101, loss 0.511471.
Train: 2018-08-01T01:23:57.195933: step 24102, loss 0.579412.
Train: 2018-08-01T01:23:57.352177: step 24103, loss 0.579423.
Train: 2018-08-01T01:23:57.508389: step 24104, loss 0.562412.
Train: 2018-08-01T01:23:57.664602: step 24105, loss 0.494314.
Train: 2018-08-01T01:23:57.820817: step 24106, loss 0.545364.
Train: 2018-08-01T01:23:57.977032: step 24107, loss 0.52827.
Train: 2018-08-01T01:23:58.148835: step 24108, loss 0.579502.
Train: 2018-08-01T01:23:58.320669: step 24109, loss 0.49393.
Train: 2018-08-01T01:23:58.476881: step 24110, loss 0.459485.
Test: 2018-08-01T01:23:58.945553: step 24110, loss 0.547997.
Train: 2018-08-01T01:23:59.101768: step 24111, loss 0.579611.
Train: 2018-08-01T01:23:59.273601: step 24112, loss 0.510658.
Train: 2018-08-01T01:23:59.429815: step 24113, loss 0.527812.
Train: 2018-08-01T01:23:59.585998: step 24114, loss 0.510363.
Train: 2018-08-01T01:23:59.742211: step 24115, loss 0.684292.
Train: 2018-08-01T01:23:59.898448: step 24116, loss 0.579868.
Train: 2018-08-01T01:24:00.054637: step 24117, loss 0.544985.
Train: 2018-08-01T01:24:00.210884: step 24118, loss 0.492555.
Train: 2018-08-01T01:24:00.382716: step 24119, loss 0.614959.
Train: 2018-08-01T01:24:00.538898: step 24120, loss 0.597492.
Test: 2018-08-01T01:24:01.007569: step 24120, loss 0.547781.
Train: 2018-08-01T01:24:01.179374: step 24121, loss 0.720182.
Train: 2018-08-01T01:24:01.335613: step 24122, loss 0.492461.
Train: 2018-08-01T01:24:01.491826: step 24123, loss 0.614901.
Train: 2018-08-01T01:24:01.663662: step 24124, loss 0.492589.
Train: 2018-08-01T01:24:01.819880: step 24125, loss 0.597351.
Train: 2018-08-01T01:24:01.976087: step 24126, loss 0.614762.
Train: 2018-08-01T01:24:02.132306: step 24127, loss 0.510176.
Train: 2018-08-01T01:24:02.288520: step 24128, loss 0.457989.
Train: 2018-08-01T01:24:02.460351: step 24129, loss 0.579847.
Train: 2018-08-01T01:24:02.616568: step 24130, loss 0.440475.
Test: 2018-08-01T01:24:03.100829: step 24130, loss 0.547824.
Train: 2018-08-01T01:24:03.257043: step 24131, loss 0.649695.
Train: 2018-08-01T01:24:03.413225: step 24132, loss 0.614816.
Train: 2018-08-01T01:24:03.585062: step 24133, loss 0.754431.
Train: 2018-08-01T01:24:03.741275: step 24134, loss 0.597246.
Train: 2018-08-01T01:24:03.897487: step 24135, loss 0.545059.
Train: 2018-08-01T01:24:04.053702: step 24136, loss 0.562414.
Train: 2018-08-01T01:24:04.209915: step 24137, loss 0.458712.
Train: 2018-08-01T01:24:04.366129: step 24138, loss 0.596951.
Train: 2018-08-01T01:24:04.522372: step 24139, loss 0.510649.
Train: 2018-08-01T01:24:04.694208: step 24140, loss 0.700382.
Test: 2018-08-01T01:24:05.162846: step 24140, loss 0.547992.
Train: 2018-08-01T01:24:05.319061: step 24141, loss 0.751743.
Train: 2018-08-01T01:24:05.475242: step 24142, loss 0.61383.
Train: 2018-08-01T01:24:05.631487: step 24143, loss 0.664815.
Train: 2018-08-01T01:24:05.787671: step 24144, loss 0.545436.
Train: 2018-08-01T01:24:05.943914: step 24145, loss 0.460998.
Train: 2018-08-01T01:24:06.100096: step 24146, loss 0.545578.
Train: 2018-08-01T01:24:06.256311: step 24147, loss 0.545623.
Train: 2018-08-01T01:24:06.412554: step 24148, loss 0.64643.
Train: 2018-08-01T01:24:06.568761: step 24149, loss 0.579219.
Train: 2018-08-01T01:24:06.724981: step 24150, loss 0.629329.
Test: 2018-08-01T01:24:07.209242: step 24150, loss 0.548545.
Train: 2018-08-01T01:24:07.365455: step 24151, loss 0.579161.
Train: 2018-08-01T01:24:07.521639: step 24152, loss 0.545901.
Train: 2018-08-01T01:24:07.677853: step 24153, loss 0.645426.
Train: 2018-08-01T01:24:07.834097: step 24154, loss 0.463383.
Train: 2018-08-01T01:24:07.990315: step 24155, loss 0.595582.
Train: 2018-08-01T01:24:08.146524: step 24156, loss 0.612028.
Train: 2018-08-01T01:24:08.302731: step 24157, loss 0.529693.
Train: 2018-08-01T01:24:08.458950: step 24158, loss 0.595472.
Train: 2018-08-01T01:24:08.615164: step 24159, loss 0.562619.
Train: 2018-08-01T01:24:08.771345: step 24160, loss 0.546237.
Test: 2018-08-01T01:24:09.240011: step 24160, loss 0.548917.
Train: 2018-08-01T01:24:09.396236: step 24161, loss 0.529871.
Train: 2018-08-01T01:24:09.552444: step 24162, loss 0.579018.
Train: 2018-08-01T01:24:09.708627: step 24163, loss 0.61178.
Train: 2018-08-01T01:24:09.880461: step 24164, loss 0.579014.
Train: 2018-08-01T01:24:10.036675: step 24165, loss 0.562649.
Train: 2018-08-01T01:24:10.208510: step 24166, loss 0.513592.
Train: 2018-08-01T01:24:10.364722: step 24167, loss 0.59537.
Train: 2018-08-01T01:24:10.520967: step 24168, loss 0.546287.
Train: 2018-08-01T01:24:10.677181: step 24169, loss 0.497171.
Train: 2018-08-01T01:24:10.833388: step 24170, loss 0.529848.
Test: 2018-08-01T01:24:11.302033: step 24170, loss 0.548862.
Train: 2018-08-01T01:24:11.458248: step 24171, loss 0.562613.
Train: 2018-08-01T01:24:11.630083: step 24172, loss 0.579047.
Train: 2018-08-01T01:24:11.770644: step 24173, loss 0.579058.
Train: 2018-08-01T01:24:11.926858: step 24174, loss 0.51309.
Train: 2018-08-01T01:24:12.083070: step 24175, loss 0.496456.
Train: 2018-08-01T01:24:12.239284: step 24176, loss 0.512829.
Train: 2018-08-01T01:24:12.411119: step 24177, loss 0.462785.
Train: 2018-08-01T01:24:12.567363: step 24178, loss 0.545796.
Train: 2018-08-01T01:24:12.723572: step 24179, loss 0.612742.
Train: 2018-08-01T01:24:12.879790: step 24180, loss 0.512018.
Test: 2018-08-01T01:24:13.348430: step 24180, loss 0.54831.
Train: 2018-08-01T01:24:13.520264: step 24181, loss 0.51183.
Train: 2018-08-01T01:24:13.676448: step 24182, loss 0.596287.
Train: 2018-08-01T01:24:13.817071: step 24183, loss 0.511465.
Train: 2018-08-01T01:24:13.973284: step 24184, loss 0.613529.
Train: 2018-08-01T01:24:14.129497: step 24185, loss 0.63073.
Train: 2018-08-01T01:24:14.285680: step 24186, loss 0.511093.
Train: 2018-08-01T01:24:14.441925: step 24187, loss 0.596673.
Train: 2018-08-01T01:24:14.629349: step 24188, loss 0.579559.
Train: 2018-08-01T01:24:14.785562: step 24189, loss 0.52806.
Train: 2018-08-01T01:24:14.941807: step 24190, loss 0.596788.
Test: 2018-08-01T01:24:15.426068: step 24190, loss 0.547998.
Train: 2018-08-01T01:24:15.582251: step 24191, loss 0.527996.
Train: 2018-08-01T01:24:15.754086: step 24192, loss 0.51074.
Train: 2018-08-01T01:24:15.910300: step 24193, loss 0.545158.
Train: 2018-08-01T01:24:16.066513: step 24194, loss 0.545134.
Train: 2018-08-01T01:24:16.222727: step 24195, loss 0.493201.
Train: 2018-08-01T01:24:16.378970: step 24196, loss 0.631783.
Train: 2018-08-01T01:24:16.550775: step 24197, loss 0.614505.
Train: 2018-08-01T01:24:16.706989: step 24198, loss 0.56242.
Train: 2018-08-01T01:24:16.863238: step 24199, loss 0.492925.
Train: 2018-08-01T01:24:17.019445: step 24200, loss 0.510246.
Test: 2018-08-01T01:24:17.488085: step 24200, loss 0.547842.
Train: 2018-08-01T01:24:18.222284: step 24201, loss 0.579849.
Train: 2018-08-01T01:24:18.394123: step 24202, loss 0.579874.
Train: 2018-08-01T01:24:18.534716: step 24203, loss 0.492623.
Train: 2018-08-01T01:24:18.690898: step 24204, loss 0.614881.
Train: 2018-08-01T01:24:18.847112: step 24205, loss 0.527464.
Train: 2018-08-01T01:24:19.018977: step 24206, loss 0.597466.
Train: 2018-08-01T01:24:19.175193: step 24207, loss 0.562452.
Train: 2018-08-01T01:24:19.331374: step 24208, loss 0.474854.
Train: 2018-08-01T01:24:19.487612: step 24209, loss 0.632626.
Train: 2018-08-01T01:24:19.643825: step 24210, loss 0.650189.
Test: 2018-08-01T01:24:20.112470: step 24210, loss 0.547777.
Train: 2018-08-01T01:24:20.268680: step 24211, loss 0.474806.
Train: 2018-08-01T01:24:20.424897: step 24212, loss 0.544924.
Train: 2018-08-01T01:24:20.581081: step 24213, loss 0.597536.
Train: 2018-08-01T01:24:20.737295: step 24214, loss 0.562458.
Train: 2018-08-01T01:24:20.893537: step 24215, loss 0.527395.
Train: 2018-08-01T01:24:21.049722: step 24216, loss 0.544924.
Train: 2018-08-01T01:24:21.205966: step 24217, loss 0.615073.
Train: 2018-08-01T01:24:21.362179: step 24218, loss 0.544926.
Train: 2018-08-01T01:24:21.518392: step 24219, loss 0.544929.
Train: 2018-08-01T01:24:21.674574: step 24220, loss 0.492355.
Test: 2018-08-01T01:24:22.143247: step 24220, loss 0.547773.
Train: 2018-08-01T01:24:22.299454: step 24221, loss 0.439697.
Train: 2018-08-01T01:24:22.471287: step 24222, loss 0.544896.
Train: 2018-08-01T01:24:22.627477: step 24223, loss 0.56248.
Train: 2018-08-01T01:24:22.768099: step 24224, loss 0.544854.
Train: 2018-08-01T01:24:22.924281: step 24225, loss 0.509504.
Train: 2018-08-01T01:24:23.080496: step 24226, loss 0.562516.
Train: 2018-08-01T01:24:23.236740: step 24227, loss 0.544797.
Train: 2018-08-01T01:24:23.392923: step 24228, loss 0.509257.
Train: 2018-08-01T01:24:23.549166: step 24229, loss 0.526964.
Train: 2018-08-01T01:24:23.705349: step 24230, loss 0.580414.
Test: 2018-08-01T01:24:24.189610: step 24230, loss 0.547634.
Train: 2018-08-01T01:24:24.345824: step 24231, loss 0.526866.
Train: 2018-08-01T01:24:24.502063: step 24232, loss 0.473136.
Train: 2018-08-01T01:24:24.658252: step 24233, loss 0.580575.
Train: 2018-08-01T01:24:24.814495: step 24234, loss 0.526711.
Train: 2018-08-01T01:24:24.970677: step 24235, loss 0.472638.
Train: 2018-08-01T01:24:25.126891: step 24236, loss 0.652991.
Train: 2018-08-01T01:24:25.283136: step 24237, loss 0.598882.
Train: 2018-08-01T01:24:25.439350: step 24238, loss 0.490378.
Train: 2018-08-01T01:24:25.595557: step 24239, loss 0.417869.
Train: 2018-08-01T01:24:25.767391: step 24240, loss 0.508316.
Test: 2018-08-01T01:24:26.236036: step 24240, loss 0.547576.
Train: 2018-08-01T01:24:26.392250: step 24241, loss 0.581024.
Train: 2018-08-01T01:24:26.579676: step 24242, loss 0.56285.
Train: 2018-08-01T01:24:26.720299: step 24243, loss 0.434964.
Train: 2018-08-01T01:24:26.876507: step 24244, loss 0.581243.
Train: 2018-08-01T01:24:27.032695: step 24245, loss 0.489506.
Train: 2018-08-01T01:24:27.188939: step 24246, loss 0.710256.
Train: 2018-08-01T01:24:27.345121: step 24247, loss 0.544588.
Train: 2018-08-01T01:24:27.501336: step 24248, loss 0.544587.
Train: 2018-08-01T01:24:27.673170: step 24249, loss 0.618313.
Train: 2018-08-01T01:24:27.829383: step 24250, loss 0.526163.
Test: 2018-08-01T01:24:28.298053: step 24250, loss 0.547583.
Train: 2018-08-01T01:24:28.454238: step 24251, loss 0.507746.
Train: 2018-08-01T01:24:28.610481: step 24252, loss 0.526162.
Train: 2018-08-01T01:24:28.797937: step 24253, loss 0.67362.
Train: 2018-08-01T01:24:28.938530: step 24254, loss 0.544588.
Train: 2018-08-01T01:24:29.094713: step 24255, loss 0.599786.
Train: 2018-08-01T01:24:29.250926: step 24256, loss 0.544591.
Train: 2018-08-01T01:24:29.407169: step 24257, loss 0.562944.
Train: 2018-08-01T01:24:29.563352: step 24258, loss 0.562923.
Train: 2018-08-01T01:24:29.719596: step 24259, loss 0.709332.
Train: 2018-08-01T01:24:29.875780: step 24260, loss 0.508107.
Test: 2018-08-01T01:24:30.344419: step 24260, loss 0.547575.
Train: 2018-08-01T01:24:30.500633: step 24261, loss 0.508196.
Train: 2018-08-01T01:24:30.656877: step 24262, loss 0.580981.
Train: 2018-08-01T01:24:30.828712: step 24263, loss 0.562776.
Train: 2018-08-01T01:24:31.000517: step 24264, loss 0.490286.
Train: 2018-08-01T01:24:31.141138: step 24265, loss 0.417941.
Train: 2018-08-01T01:24:31.297352: step 24266, loss 0.617083.
Train: 2018-08-01T01:24:31.453565: step 24267, loss 0.454097.
Train: 2018-08-01T01:24:31.609778: step 24268, loss 0.508385.
Train: 2018-08-01T01:24:31.765962: step 24269, loss 0.490186.
Train: 2018-08-01T01:24:31.922174: step 24270, loss 0.599159.
Test: 2018-08-01T01:24:32.390845: step 24270, loss 0.547576.
Train: 2018-08-01T01:24:32.547029: step 24271, loss 0.508219.
Train: 2018-08-01T01:24:32.703272: step 24272, loss 0.526387.
Train: 2018-08-01T01:24:32.859486: step 24273, loss 0.599358.
Train: 2018-08-01T01:24:33.015669: step 24274, loss 0.544604.
Train: 2018-08-01T01:24:33.187503: step 24275, loss 0.489767.
Train: 2018-08-01T01:24:33.343718: step 24276, loss 0.581201.
Train: 2018-08-01T01:24:33.499961: step 24277, loss 0.562912.
Train: 2018-08-01T01:24:33.656168: step 24278, loss 0.617897.
Train: 2018-08-01T01:24:33.812357: step 24279, loss 0.471316.
Train: 2018-08-01T01:24:33.968570: step 24280, loss 0.507934.
Test: 2018-08-01T01:24:34.421622: step 24280, loss 0.547576.
Train: 2018-08-01T01:24:34.593455: step 24281, loss 0.507899.
Train: 2018-08-01T01:24:34.749668: step 24282, loss 0.58133.
Train: 2018-08-01T01:24:34.905851: step 24283, loss 0.636505.
Train: 2018-08-01T01:24:35.062064: step 24284, loss 0.562967.
Train: 2018-08-01T01:24:35.218308: step 24285, loss 0.56296.
Train: 2018-08-01T01:24:35.374492: step 24286, loss 0.47116.
Train: 2018-08-01T01:24:35.530705: step 24287, loss 0.544591.
Train: 2018-08-01T01:24:35.686949: step 24288, loss 0.63643.
Train: 2018-08-01T01:24:35.843132: step 24289, loss 0.728135.
Train: 2018-08-01T01:24:35.999346: step 24290, loss 0.507985.
Test: 2018-08-01T01:24:36.483637: step 24290, loss 0.547574.
Train: 2018-08-01T01:24:36.639845: step 24291, loss 0.562873.
Train: 2018-08-01T01:24:36.796070: step 24292, loss 0.526373.
Train: 2018-08-01T01:24:36.952278: step 24293, loss 0.526405.
Train: 2018-08-01T01:24:37.108485: step 24294, loss 0.580995.
Train: 2018-08-01T01:24:37.264673: step 24295, loss 0.562788.
Train: 2018-08-01T01:24:37.420917: step 24296, loss 0.599047.
Train: 2018-08-01T01:24:37.577100: step 24297, loss 0.598959.
Train: 2018-08-01T01:24:37.733315: step 24298, loss 0.598854.
Train: 2018-08-01T01:24:37.889529: step 24299, loss 0.706871.
Train: 2018-08-01T01:24:38.045775: step 24300, loss 0.508789.
Test: 2018-08-01T01:24:38.530002: step 24300, loss 0.547625.
Train: 2018-08-01T01:24:39.311069: step 24301, loss 0.598401.
Train: 2018-08-01T01:24:39.467314: step 24302, loss 0.491234.
Train: 2018-08-01T01:24:39.607906: step 24303, loss 0.598147.
Train: 2018-08-01T01:24:39.779710: step 24304, loss 0.527038.
Train: 2018-08-01T01:24:39.935948: step 24305, loss 0.56252.
Train: 2018-08-01T01:24:40.092171: step 24306, loss 0.580186.
Train: 2018-08-01T01:24:40.248381: step 24307, loss 0.527204.
Train: 2018-08-01T01:24:40.404565: step 24308, loss 0.615338.
Train: 2018-08-01T01:24:40.560778: step 24309, loss 0.632803.
Train: 2018-08-01T01:24:40.716990: step 24310, loss 0.527386.
Test: 2018-08-01T01:24:41.201282: step 24310, loss 0.547794.
Train: 2018-08-01T01:24:41.357490: step 24311, loss 0.649939.
Train: 2018-08-01T01:24:41.498088: step 24312, loss 0.562434.
Train: 2018-08-01T01:24:41.654272: step 24313, loss 0.632018.
Train: 2018-08-01T01:24:41.810484: step 24314, loss 0.597096.
Train: 2018-08-01T01:24:41.982319: step 24315, loss 0.631529.
Train: 2018-08-01T01:24:42.138558: step 24316, loss 0.631248.
Train: 2018-08-01T01:24:42.310403: step 24317, loss 0.63094.
Train: 2018-08-01T01:24:42.466580: step 24318, loss 0.579457.
Train: 2018-08-01T01:24:42.607172: step 24319, loss 0.613332.
Train: 2018-08-01T01:24:42.779038: step 24320, loss 0.596212.
Test: 2018-08-01T01:24:43.247677: step 24320, loss 0.54837.
Train: 2018-08-01T01:24:43.403892: step 24321, loss 0.629695.
Train: 2018-08-01T01:24:43.560106: step 24322, loss 0.595927.
Train: 2018-08-01T01:24:43.731909: step 24323, loss 0.612435.
Train: 2018-08-01T01:24:43.888153: step 24324, loss 0.496299.
Train: 2018-08-01T01:24:44.044337: step 24325, loss 0.546067.
Train: 2018-08-01T01:24:44.216172: step 24326, loss 0.562593.
Train: 2018-08-01T01:24:44.372385: step 24327, loss 0.59544.
Train: 2018-08-01T01:24:44.513007: step 24328, loss 0.497163.
Train: 2018-08-01T01:24:44.669189: step 24329, loss 0.546306.
Train: 2018-08-01T01:24:44.825435: step 24330, loss 0.660675.
Test: 2018-08-01T01:24:45.294044: step 24330, loss 0.549031.
Train: 2018-08-01T01:24:45.450256: step 24331, loss 0.644203.
Train: 2018-08-01T01:24:45.606495: step 24332, loss 0.432633.
Train: 2018-08-01T01:24:45.762685: step 24333, loss 0.546467.
Train: 2018-08-01T01:24:45.918898: step 24334, loss 0.481464.
Train: 2018-08-01T01:24:46.075141: step 24335, loss 0.530164.
Train: 2018-08-01T01:24:46.231324: step 24336, loss 0.53009.
Train: 2018-08-01T01:24:46.387539: step 24337, loss 0.578998.
Train: 2018-08-01T01:24:46.543751: step 24338, loss 0.628098.
Train: 2018-08-01T01:24:46.699995: step 24339, loss 0.497126.
Train: 2018-08-01T01:24:46.856208: step 24340, loss 0.529804.
Test: 2018-08-01T01:24:47.324845: step 24340, loss 0.548829.
Train: 2018-08-01T01:24:47.512304: step 24341, loss 0.595486.
Train: 2018-08-01T01:24:47.668488: step 24342, loss 0.562584.
Train: 2018-08-01T01:24:47.824702: step 24343, loss 0.612062.
Train: 2018-08-01T01:24:47.980940: step 24344, loss 0.562562.
Train: 2018-08-01T01:24:48.121537: step 24345, loss 0.645192.
Train: 2018-08-01T01:24:48.293371: step 24346, loss 0.463407.
Train: 2018-08-01T01:24:48.449556: step 24347, loss 0.62873.
Train: 2018-08-01T01:24:48.621420: step 24348, loss 0.579095.
Train: 2018-08-01T01:24:48.777602: step 24349, loss 0.562541.
Train: 2018-08-01T01:24:48.933816: step 24350, loss 0.545978.
Test: 2018-08-01T01:24:49.402487: step 24350, loss 0.548658.
Train: 2018-08-01T01:24:49.574292: step 24351, loss 0.46311.
Train: 2018-08-01T01:24:49.730529: step 24352, loss 0.545917.
Train: 2018-08-01T01:24:49.871097: step 24353, loss 0.545869.
Train: 2018-08-01T01:24:50.042967: step 24354, loss 0.545819.
Train: 2018-08-01T01:24:50.183555: step 24355, loss 0.495637.
Train: 2018-08-01T01:24:50.355389: step 24356, loss 0.713299.
Train: 2018-08-01T01:24:50.511596: step 24357, loss 0.596003.
Train: 2018-08-01T01:24:50.683410: step 24358, loss 0.61279.
Train: 2018-08-01T01:24:50.839621: step 24359, loss 0.545685.
Train: 2018-08-01T01:24:50.980212: step 24360, loss 0.629551.
Test: 2018-08-01T01:24:51.464474: step 24360, loss 0.548428.
Train: 2018-08-01T01:24:51.605096: step 24361, loss 0.713301.
Train: 2018-08-01T01:24:51.776900: step 24362, loss 0.629342.
Train: 2018-08-01T01:24:51.933145: step 24363, loss 0.495838.
Train: 2018-08-01T01:24:52.089328: step 24364, loss 0.62904.
Train: 2018-08-01T01:24:52.229950: step 24365, loss 0.579117.
Train: 2018-08-01T01:24:52.386163: step 24366, loss 0.645308.
Train: 2018-08-01T01:24:52.557999: step 24367, loss 0.562567.
Train: 2018-08-01T01:24:52.698591: step 24368, loss 0.529676.
Train: 2018-08-01T01:24:52.870422: step 24369, loss 0.677593.
Train: 2018-08-01T01:24:53.026639: step 24370, loss 0.595389.
Test: 2018-08-01T01:24:53.495278: step 24370, loss 0.549.
Train: 2018-08-01T01:24:53.651486: step 24371, loss 0.513696.
Train: 2018-08-01T01:24:53.807706: step 24372, loss 0.448648.
Train: 2018-08-01T01:24:53.963890: step 24373, loss 0.513822.
Train: 2018-08-01T01:24:54.135753: step 24374, loss 0.644195.
Train: 2018-08-01T01:24:54.291971: step 24375, loss 0.481203.
Train: 2018-08-01T01:24:54.448175: step 24376, loss 0.562677.
Train: 2018-08-01T01:24:54.604363: step 24377, loss 0.595326.
Train: 2018-08-01T01:24:54.744985: step 24378, loss 0.513641.
Train: 2018-08-01T01:24:54.901193: step 24379, loss 0.546284.
Train: 2018-08-01T01:24:55.073004: step 24380, loss 0.595406.
Test: 2018-08-01T01:24:55.541674: step 24380, loss 0.548881.
Train: 2018-08-01T01:24:55.744751: step 24381, loss 0.52762.
Train: 2018-08-01T01:24:55.900935: step 24382, loss 0.52974.
Train: 2018-08-01T01:24:56.057179: step 24383, loss 0.595517.
Train: 2018-08-01T01:24:56.228982: step 24384, loss 0.612042.
Train: 2018-08-01T01:24:56.369575: step 24385, loss 0.562567.
Train: 2018-08-01T01:24:56.525788: step 24386, loss 0.496496.
Train: 2018-08-01T01:24:56.682001: step 24387, loss 0.529458.
Train: 2018-08-01T01:24:56.838215: step 24388, loss 0.595688.
Train: 2018-08-01T01:24:56.994428: step 24389, loss 0.545915.
Train: 2018-08-01T01:24:57.150672: step 24390, loss 0.595772.
Test: 2018-08-01T01:24:57.634934: step 24390, loss 0.548556.
Train: 2018-08-01T01:24:57.791147: step 24391, loss 0.529196.
Train: 2018-08-01T01:24:57.947361: step 24392, loss 0.545812.
Train: 2018-08-01T01:24:58.103575: step 24393, loss 0.612599.
Train: 2018-08-01T01:24:58.244166: step 24394, loss 0.562474.
Train: 2018-08-01T01:24:58.416001: step 24395, loss 0.462038.
Train: 2018-08-01T01:24:58.572215: step 24396, loss 0.461804.
Train: 2018-08-01T01:24:58.728422: step 24397, loss 0.612937.
Train: 2018-08-01T01:24:58.884636: step 24398, loss 0.444327.
Train: 2018-08-01T01:24:59.040855: step 24399, loss 0.579355.
Train: 2018-08-01T01:24:59.212659: step 24400, loss 0.545424.
Test: 2018-08-01T01:24:59.681299: step 24400, loss 0.548137.
Train: 2018-08-01T01:25:00.353018: step 24401, loss 0.545366.
Train: 2018-08-01T01:25:00.509259: step 24402, loss 0.494039.
Train: 2018-08-01T01:25:00.681066: step 24403, loss 0.493796.
Train: 2018-08-01T01:25:00.837279: step 24404, loss 0.579623.
Train: 2018-08-01T01:25:00.993492: step 24405, loss 0.52785.
Train: 2018-08-01T01:25:01.149705: step 24406, loss 0.545076.
Train: 2018-08-01T01:25:01.321540: step 24407, loss 0.59721.
Train: 2018-08-01T01:25:01.477784: step 24408, loss 0.527557.
Train: 2018-08-01T01:25:01.665244: step 24409, loss 0.579924.
Train: 2018-08-01T01:25:01.821454: step 24410, loss 0.544933.
Test: 2018-08-01T01:25:02.290064: step 24410, loss 0.547762.
Train: 2018-08-01T01:25:02.446307: step 24411, loss 0.597568.
Train: 2018-08-01T01:25:02.602490: step 24412, loss 0.615198.
Train: 2018-08-01T01:25:02.774361: step 24413, loss 0.650399.
Train: 2018-08-01T01:25:02.914947: step 24414, loss 0.544893.
Train: 2018-08-01T01:25:03.086782: step 24415, loss 0.580032.
Train: 2018-08-01T01:25:03.242993: step 24416, loss 0.597571.
Train: 2018-08-01T01:25:03.399209: step 24417, loss 0.597528.
Train: 2018-08-01T01:25:03.555418: step 24418, loss 0.527428.
Train: 2018-08-01T01:25:03.711636: step 24419, loss 0.562444.
Train: 2018-08-01T01:25:03.883476: step 24420, loss 0.544962.
Test: 2018-08-01T01:25:04.352111: step 24420, loss 0.547811.
Train: 2018-08-01T01:25:04.508324: step 24421, loss 0.475104.
Train: 2018-08-01T01:25:04.664532: step 24422, loss 0.649808.
Train: 2018-08-01T01:25:04.820752: step 24423, loss 0.579897.
Train: 2018-08-01T01:25:04.992555: step 24424, loss 0.527543.
Train: 2018-08-01T01:25:05.148804: step 24425, loss 0.527557.
Train: 2018-08-01T01:25:05.289392: step 24426, loss 0.61474.
Train: 2018-08-01T01:25:05.445574: step 24427, loss 0.492732.
Train: 2018-08-01T01:25:05.601819: step 24428, loss 0.579856.
Train: 2018-08-01T01:25:05.758032: step 24429, loss 0.579853.
Train: 2018-08-01T01:25:05.914245: step 24430, loss 0.51017.
Test: 2018-08-01T01:25:06.382857: step 24430, loss 0.547838.
Train: 2018-08-01T01:25:06.539103: step 24431, loss 0.562428.
Train: 2018-08-01T01:25:06.695313: step 24432, loss 0.597283.
Train: 2018-08-01T01:25:06.835874: step 24433, loss 0.57985.
Train: 2018-08-01T01:25:07.007708: step 24434, loss 0.614666.
Train: 2018-08-01T01:25:07.195192: step 24435, loss 0.614604.
Train: 2018-08-01T01:25:07.351409: step 24436, loss 0.545053.
Train: 2018-08-01T01:25:07.507622: step 24437, loss 0.666462.
Train: 2018-08-01T01:25:07.663835: step 24438, loss 0.510514.
Train: 2018-08-01T01:25:07.820019: step 24439, loss 0.545136.
Train: 2018-08-01T01:25:07.976233: step 24440, loss 0.596899.
Test: 2018-08-01T01:25:08.460493: step 24440, loss 0.547983.
Train: 2018-08-01T01:25:08.616732: step 24441, loss 0.459083.
Train: 2018-08-01T01:25:08.772920: step 24442, loss 0.510752.
Train: 2018-08-01T01:25:08.929134: step 24443, loss 0.665751.
Train: 2018-08-01T01:25:09.085378: step 24444, loss 0.648451.
Train: 2018-08-01T01:25:09.241591: step 24445, loss 0.528045.
Train: 2018-08-01T01:25:09.413426: step 24446, loss 0.545244.
Train: 2018-08-01T01:25:09.585261: step 24447, loss 0.699531.
Train: 2018-08-01T01:25:09.741443: step 24448, loss 0.562402.
Train: 2018-08-01T01:25:09.897658: step 24449, loss 0.733001.
Train: 2018-08-01T01:25:10.053871: step 24450, loss 0.511444.
Test: 2018-08-01T01:25:10.522511: step 24450, loss 0.548236.
Train: 2018-08-01T01:25:10.678724: step 24451, loss 0.528545.
Train: 2018-08-01T01:25:10.834937: step 24452, loss 0.528631.
Train: 2018-08-01T01:25:10.991153: step 24453, loss 0.545561.
Train: 2018-08-01T01:25:11.147394: step 24454, loss 0.528736.
Train: 2018-08-01T01:25:11.303579: step 24455, loss 0.59612.
Train: 2018-08-01T01:25:11.475444: step 24456, loss 0.579268.
Train: 2018-08-01T01:25:11.631656: step 24457, loss 0.444786.
Train: 2018-08-01T01:25:11.787873: step 24458, loss 0.562444.
Train: 2018-08-01T01:25:11.944083: step 24459, loss 0.495115.
Train: 2018-08-01T01:25:12.100291: step 24460, loss 0.495006.
Test: 2018-08-01T01:25:12.553285: step 24460, loss 0.548279.
Train: 2018-08-01T01:25:12.709499: step 24461, loss 0.545531.
Train: 2018-08-01T01:25:12.865742: step 24462, loss 0.528551.
Train: 2018-08-01T01:25:13.021956: step 24463, loss 0.545436.
Train: 2018-08-01T01:25:13.178170: step 24464, loss 0.494328.
Train: 2018-08-01T01:25:13.334382: step 24465, loss 0.630697.
Train: 2018-08-01T01:25:13.506217: step 24466, loss 0.579509.
Train: 2018-08-01T01:25:13.662401: step 24467, loss 0.579535.
Train: 2018-08-01T01:25:13.818645: step 24468, loss 0.613865.
Train: 2018-08-01T01:25:13.974858: step 24469, loss 0.510913.
Train: 2018-08-01T01:25:14.146692: step 24470, loss 0.52804.
Test: 2018-08-01T01:25:14.615333: step 24470, loss 0.547996.
Train: 2018-08-01T01:25:14.771542: step 24471, loss 0.596808.
Train: 2018-08-01T01:25:14.927730: step 24472, loss 0.614052.
Train: 2018-08-01T01:25:15.083943: step 24473, loss 0.562402.
Train: 2018-08-01T01:25:15.224535: step 24474, loss 0.44187.
Train: 2018-08-01T01:25:15.380749: step 24475, loss 0.527914.
Train: 2018-08-01T01:25:15.536992: step 24476, loss 0.562406.
Train: 2018-08-01T01:25:15.693206: step 24477, loss 0.562409.
Train: 2018-08-01T01:25:15.865040: step 24478, loss 0.701021.
Train: 2018-08-01T01:25:16.021224: step 24479, loss 0.527774.
Train: 2018-08-01T01:25:16.177461: step 24480, loss 0.527775.
Test: 2018-08-01T01:25:16.661728: step 24480, loss 0.547904.
Train: 2018-08-01T01:25:16.817942: step 24481, loss 0.631708.
Train: 2018-08-01T01:25:16.989746: step 24482, loss 0.52778.
Train: 2018-08-01T01:25:17.130338: step 24483, loss 0.579724.
Train: 2018-08-01T01:25:17.302174: step 24484, loss 0.475868.
Train: 2018-08-01T01:25:17.458416: step 24485, loss 0.735623.
Train: 2018-08-01T01:25:17.614630: step 24486, loss 0.527816.
Train: 2018-08-01T01:25:17.770815: step 24487, loss 0.631528.
Train: 2018-08-01T01:25:17.927058: step 24488, loss 0.614158.
Train: 2018-08-01T01:25:18.098892: step 24489, loss 0.527973.
Train: 2018-08-01T01:25:18.255107: step 24490, loss 0.545213.
Test: 2018-08-01T01:25:18.723745: step 24490, loss 0.548024.
Train: 2018-08-01T01:25:18.879928: step 24491, loss 0.665407.
Train: 2018-08-01T01:25:19.036173: step 24492, loss 0.562401.
Train: 2018-08-01T01:25:19.207976: step 24493, loss 0.579494.
Train: 2018-08-01T01:25:19.364190: step 24494, loss 0.630629.
Train: 2018-08-01T01:25:19.520403: step 24495, loss 0.545399.
Train: 2018-08-01T01:25:19.661026: step 24496, loss 0.681218.
Train: 2018-08-01T01:25:19.832831: step 24497, loss 0.494769.
Train: 2018-08-01T01:25:19.989056: step 24498, loss 0.596182.
Train: 2018-08-01T01:25:20.129667: step 24499, loss 0.478263.
Train: 2018-08-01T01:25:20.317117: step 24500, loss 0.528808.
Test: 2018-08-01T01:25:20.785762: step 24500, loss 0.548369.
Train: 2018-08-01T01:25:21.519965: step 24501, loss 0.629689.
Train: 2018-08-01T01:25:21.676150: step 24502, loss 0.562452.
Train: 2018-08-01T01:25:21.832393: step 24503, loss 0.62955.
Train: 2018-08-01T01:25:21.988576: step 24504, loss 0.595955.
Train: 2018-08-01T01:25:22.144819: step 24505, loss 0.662751.
Train: 2018-08-01T01:25:22.301002: step 24506, loss 0.512505.
Train: 2018-08-01T01:25:22.457215: step 24507, loss 0.512614.
Train: 2018-08-01T01:25:22.613429: step 24508, loss 0.579128.
Train: 2018-08-01T01:25:22.785265: step 24509, loss 0.462936.
Train: 2018-08-01T01:25:22.941478: step 24510, loss 0.529307.
Test: 2018-08-01T01:25:23.410119: step 24510, loss 0.548593.
Train: 2018-08-01T01:25:23.581952: step 24511, loss 0.529268.
Train: 2018-08-01T01:25:23.738166: step 24512, loss 0.529213.
Train: 2018-08-01T01:25:23.894409: step 24513, loss 0.479121.
Train: 2018-08-01T01:25:24.050624: step 24514, loss 0.495595.
Train: 2018-08-01T01:25:24.191185: step 24515, loss 0.596009.
Train: 2018-08-01T01:25:24.363020: step 24516, loss 0.562443.
Train: 2018-08-01T01:25:24.519233: step 24517, loss 0.478116.
Train: 2018-08-01T01:25:24.675447: step 24518, loss 0.562422.
Train: 2018-08-01T01:25:24.831660: step 24519, loss 0.5115.
Train: 2018-08-01T01:25:24.987904: step 24520, loss 0.630521.
Test: 2018-08-01T01:25:25.456545: step 24520, loss 0.548112.
Train: 2018-08-01T01:25:25.612752: step 24521, loss 0.494138.
Train: 2018-08-01T01:25:25.784586: step 24522, loss 0.630861.
Train: 2018-08-01T01:25:25.940801: step 24523, loss 0.5624.
Train: 2018-08-01T01:25:26.097019: step 24524, loss 0.545229.
Train: 2018-08-01T01:25:26.253203: step 24525, loss 0.648393.
Train: 2018-08-01T01:25:26.409416: step 24526, loss 0.545196.
Train: 2018-08-01T01:25:26.565660: step 24527, loss 0.527973.
Train: 2018-08-01T01:25:26.721843: step 24528, loss 0.751929.
Train: 2018-08-01T01:25:26.893677: step 24529, loss 0.493586.
Train: 2018-08-01T01:25:27.049915: step 24530, loss 0.562401.
Test: 2018-08-01T01:25:27.518555: step 24530, loss 0.548009.
Train: 2018-08-01T01:25:27.674769: step 24531, loss 0.528028.
Train: 2018-08-01T01:25:27.830958: step 24532, loss 0.528028.
Train: 2018-08-01T01:25:28.002792: step 24533, loss 0.579594.
Train: 2018-08-01T01:25:28.159006: step 24534, loss 0.596791.
Train: 2018-08-01T01:25:28.315220: step 24535, loss 0.52802.
Train: 2018-08-01T01:25:28.471463: step 24536, loss 0.68275.
Train: 2018-08-01T01:25:28.627647: step 24537, loss 0.59674.
Train: 2018-08-01T01:25:28.783859: step 24538, loss 0.510975.
Train: 2018-08-01T01:25:28.940104: step 24539, loss 0.528146.
Train: 2018-08-01T01:25:29.127559: step 24540, loss 0.613766.
Test: 2018-08-01T01:25:29.596199: step 24540, loss 0.548077.
Train: 2018-08-01T01:25:29.752383: step 24541, loss 0.596613.
Train: 2018-08-01T01:25:29.908596: step 24542, loss 0.562402.
Train: 2018-08-01T01:25:30.080432: step 24543, loss 0.630666.
Train: 2018-08-01T01:25:30.252296: step 24544, loss 0.613509.
Train: 2018-08-01T01:25:30.408504: step 24545, loss 0.647389.
Train: 2018-08-01T01:25:30.564718: step 24546, loss 0.494644.
Train: 2018-08-01T01:25:30.720936: step 24547, loss 0.613157.
Train: 2018-08-01T01:25:30.877121: step 24548, loss 0.545559.
Train: 2018-08-01T01:25:31.048953: step 24549, loss 0.596121.
Train: 2018-08-01T01:25:31.205168: step 24550, loss 0.562447.
Test: 2018-08-01T01:25:31.689459: step 24550, loss 0.548406.
Train: 2018-08-01T01:25:31.845642: step 24551, loss 0.478567.
Train: 2018-08-01T01:25:32.001856: step 24552, loss 0.629539.
Train: 2018-08-01T01:25:32.158069: step 24553, loss 0.579214.
Train: 2018-08-01T01:25:32.314319: step 24554, loss 0.512282.
Train: 2018-08-01T01:25:32.486148: step 24555, loss 0.562473.
Train: 2018-08-01T01:25:32.642330: step 24556, loss 0.612629.
Train: 2018-08-01T01:25:32.798543: step 24557, loss 0.462253.
Train: 2018-08-01T01:25:32.970379: step 24558, loss 0.61262.
Train: 2018-08-01T01:25:33.126592: step 24559, loss 0.662764.
Train: 2018-08-01T01:25:33.282836: step 24560, loss 0.579177.
Test: 2018-08-01T01:25:33.767097: step 24560, loss 0.548528.
Train: 2018-08-01T01:25:33.923282: step 24561, loss 0.56249.
Train: 2018-08-01T01:25:34.079495: step 24562, loss 0.629121.
Train: 2018-08-01T01:25:34.235738: step 24563, loss 0.479372.
Train: 2018-08-01T01:25:34.407569: step 24564, loss 0.595753.
Train: 2018-08-01T01:25:34.563757: step 24565, loss 0.545906.
Train: 2018-08-01T01:25:34.719999: step 24566, loss 0.662145.
Train: 2018-08-01T01:25:34.876207: step 24567, loss 0.562529.
Train: 2018-08-01T01:25:35.032396: step 24568, loss 0.562538.
Train: 2018-08-01T01:25:35.188640: step 24569, loss 0.463293.
Train: 2018-08-01T01:25:35.360445: step 24570, loss 0.46324.
Test: 2018-08-01T01:25:35.829116: step 24570, loss 0.548643.
Train: 2018-08-01T01:25:35.985297: step 24571, loss 0.545946.
Train: 2018-08-01T01:25:36.141512: step 24572, loss 0.612361.
Train: 2018-08-01T01:25:36.297725: step 24573, loss 0.5126.
Train: 2018-08-01T01:25:36.453968: step 24574, loss 0.512495.
Train: 2018-08-01T01:25:36.625772: step 24575, loss 0.62932.
Train: 2018-08-01T01:25:36.781987: step 24576, loss 0.579193.
Train: 2018-08-01T01:25:36.938230: step 24577, loss 0.495486.
Train: 2018-08-01T01:25:37.094444: step 24578, loss 0.512119.
Train: 2018-08-01T01:25:37.250627: step 24579, loss 0.562461.
Train: 2018-08-01T01:25:37.406865: step 24580, loss 0.579284.
Test: 2018-08-01T01:25:37.891132: step 24580, loss 0.548286.
Train: 2018-08-01T01:25:38.031695: step 24581, loss 0.494888.
Train: 2018-08-01T01:25:38.203554: step 24582, loss 0.562437.
Train: 2018-08-01T01:25:38.344151: step 24583, loss 0.630292.
Train: 2018-08-01T01:25:38.500364: step 24584, loss 0.579395.
Train: 2018-08-01T01:25:38.672169: step 24585, loss 0.596409.
Train: 2018-08-01T01:25:38.828384: step 24586, loss 0.59643.
Train: 2018-08-01T01:25:39.000217: step 24587, loss 0.596281.
Train: 2018-08-01T01:25:39.156430: step 24588, loss 0.647037.
Train: 2018-08-01T01:25:39.312644: step 24589, loss 0.578462.
Train: 2018-08-01T01:25:39.468857: step 24590, loss 0.428112.
Test: 2018-08-01T01:25:39.937528: step 24590, loss 0.54863.
Train: 2018-08-01T01:25:40.124981: step 24591, loss 0.596187.
Train: 2018-08-01T01:25:40.281197: step 24592, loss 0.564348.
Train: 2018-08-01T01:25:40.437407: step 24593, loss 0.577965.
Train: 2018-08-01T01:25:40.593624: step 24594, loss 0.528924.
Train: 2018-08-01T01:25:40.749807: step 24595, loss 0.494405.
Train: 2018-08-01T01:25:40.906023: step 24596, loss 0.64655.
Train: 2018-08-01T01:25:41.077886: step 24597, loss 0.630899.
Train: 2018-08-01T01:25:41.249690: step 24598, loss 0.630204.
Train: 2018-08-01T01:25:41.405904: step 24599, loss 0.706972.
Train: 2018-08-01T01:25:41.546520: step 24600, loss 0.599075.
Test: 2018-08-01T01:25:42.015166: step 24600, loss 0.54925.
Train: 2018-08-01T01:25:42.718126: step 24601, loss 0.486045.
Train: 2018-08-01T01:25:42.874340: step 24602, loss 0.51881.
Train: 2018-08-01T01:25:43.030524: step 24603, loss 0.532181.
Train: 2018-08-01T01:25:43.186767: step 24604, loss 0.564841.
Train: 2018-08-01T01:25:43.358597: step 24605, loss 0.595985.
Train: 2018-08-01T01:25:43.514784: step 24606, loss 0.679676.
Train: 2018-08-01T01:25:43.671029: step 24607, loss 0.613153.
Train: 2018-08-01T01:25:43.827242: step 24608, loss 0.562326.
Train: 2018-08-01T01:25:43.983425: step 24609, loss 0.629417.
Train: 2018-08-01T01:25:44.139638: step 24610, loss 0.562452.
Test: 2018-08-01T01:25:44.608309: step 24610, loss 0.548532.
Train: 2018-08-01T01:25:44.764522: step 24611, loss 0.662323.
Train: 2018-08-01T01:25:44.920737: step 24612, loss 0.612496.
Train: 2018-08-01T01:25:45.076944: step 24613, loss 0.512692.
Train: 2018-08-01T01:25:45.248789: step 24614, loss 0.645426.
Train: 2018-08-01T01:25:45.404997: step 24615, loss 0.479994.
Train: 2018-08-01T01:25:45.576832: step 24616, loss 0.562601.
Train: 2018-08-01T01:25:45.733015: step 24617, loss 0.579022.
Train: 2018-08-01T01:25:45.889260: step 24618, loss 0.496747.
Train: 2018-08-01T01:25:46.029821: step 24619, loss 0.513213.
Train: 2018-08-01T01:25:46.186065: step 24620, loss 0.463739.
Test: 2018-08-01T01:25:46.654705: step 24620, loss 0.548747.
Train: 2018-08-01T01:25:46.810919: step 24621, loss 0.513038.
Train: 2018-08-01T01:25:46.967101: step 24622, loss 0.562562.
Train: 2018-08-01T01:25:47.123316: step 24623, loss 0.545929.
Train: 2018-08-01T01:25:47.279552: step 24624, loss 0.595795.
Train: 2018-08-01T01:25:47.435766: step 24625, loss 0.629182.
Train: 2018-08-01T01:25:47.591985: step 24626, loss 0.645919.
Train: 2018-08-01T01:25:47.763825: step 24627, loss 0.529125.
Train: 2018-08-01T01:25:47.920027: step 24628, loss 0.529127.
Train: 2018-08-01T01:25:48.076247: step 24629, loss 0.478978.
Train: 2018-08-01T01:25:48.232461: step 24630, loss 0.512267.
Test: 2018-08-01T01:25:48.701100: step 24630, loss 0.54842.
Train: 2018-08-01T01:25:48.872930: step 24631, loss 0.663113.
Train: 2018-08-01T01:25:49.029149: step 24632, loss 0.545661.
Train: 2018-08-01T01:25:49.200978: step 24633, loss 0.646497.
Train: 2018-08-01T01:25:49.357197: step 24634, loss 0.512011.
Train: 2018-08-01T01:25:49.513410: step 24635, loss 0.528808.
Train: 2018-08-01T01:25:49.669624: step 24636, loss 0.511894.
Train: 2018-08-01T01:25:49.825807: step 24637, loss 0.511844.
Train: 2018-08-01T01:25:50.013294: step 24638, loss 0.545489.
Train: 2018-08-01T01:25:50.169476: step 24639, loss 0.68109.
Train: 2018-08-01T01:25:50.325721: step 24640, loss 0.613276.
Test: 2018-08-01T01:25:50.794361: step 24640, loss 0.548223.
Train: 2018-08-01T01:25:50.966165: step 24641, loss 0.596352.
Train: 2018-08-01T01:25:51.122409: step 24642, loss 0.545454.
Train: 2018-08-01T01:25:51.278616: step 24643, loss 0.494643.
Train: 2018-08-01T01:25:51.434836: step 24644, loss 0.426762.
Train: 2018-08-01T01:25:51.606670: step 24645, loss 0.579452.
Train: 2018-08-01T01:25:51.762884: step 24646, loss 0.613531.
Train: 2018-08-01T01:25:51.919066: step 24647, loss 0.562393.
Train: 2018-08-01T01:25:52.122174: step 24648, loss 0.579406.
Train: 2018-08-01T01:25:52.262737: step 24649, loss 0.511151.
Train: 2018-08-01T01:25:52.434596: step 24650, loss 0.459727.
Test: 2018-08-01T01:25:52.887621: step 24650, loss 0.548052.
Train: 2018-08-01T01:25:53.043834: step 24651, loss 0.528048.
Train: 2018-08-01T01:25:53.215637: step 24652, loss 0.527941.
Train: 2018-08-01T01:25:53.356230: step 24653, loss 0.493351.
Train: 2018-08-01T01:25:53.528064: step 24654, loss 0.649106.
Train: 2018-08-01T01:25:53.668688: step 24655, loss 0.49288.
Train: 2018-08-01T01:25:53.824895: step 24656, loss 0.527634.
Train: 2018-08-01T01:25:53.981108: step 24657, loss 0.405313.
Train: 2018-08-01T01:25:54.137333: step 24658, loss 0.597598.
Train: 2018-08-01T01:25:54.324784: step 24659, loss 0.650757.
Train: 2018-08-01T01:25:54.465376: step 24660, loss 0.562138.
Test: 2018-08-01T01:25:54.949636: step 24660, loss 0.547702.
Train: 2018-08-01T01:25:55.105820: step 24661, loss 0.544707.
Train: 2018-08-01T01:25:55.262065: step 24662, loss 0.650664.
Train: 2018-08-01T01:25:55.433868: step 24663, loss 0.509242.
Train: 2018-08-01T01:25:55.590083: step 24664, loss 0.546668.
Train: 2018-08-01T01:25:55.746328: step 24665, loss 0.508675.
Train: 2018-08-01T01:25:55.902508: step 24666, loss 0.579813.
Train: 2018-08-01T01:25:56.058722: step 24667, loss 0.562088.
Train: 2018-08-01T01:25:56.230587: step 24668, loss 0.579986.
Train: 2018-08-01T01:25:56.386801: step 24669, loss 0.491479.
Train: 2018-08-01T01:25:56.558629: step 24670, loss 0.545606.
Test: 2018-08-01T01:25:57.042867: step 24670, loss 0.547608.
Train: 2018-08-01T01:25:57.199110: step 24671, loss 0.581724.
Train: 2018-08-01T01:25:57.355324: step 24672, loss 0.527754.
Train: 2018-08-01T01:25:57.511540: step 24673, loss 0.562005.
Train: 2018-08-01T01:25:57.683373: step 24674, loss 0.491286.
Train: 2018-08-01T01:25:57.839585: step 24675, loss 0.544654.
Train: 2018-08-01T01:25:57.995799: step 24676, loss 0.455219.
Train: 2018-08-01T01:25:58.167603: step 24677, loss 0.545523.
Train: 2018-08-01T01:25:58.323816: step 24678, loss 0.599118.
Train: 2018-08-01T01:25:58.480061: step 24679, loss 0.47233.
Train: 2018-08-01T01:25:58.651866: step 24680, loss 0.436264.
Test: 2018-08-01T01:25:59.120536: step 24680, loss 0.547598.
Train: 2018-08-01T01:25:59.276718: step 24681, loss 0.600992.
Train: 2018-08-01T01:25:59.432957: step 24682, loss 0.523507.
Train: 2018-08-01T01:25:59.604797: step 24683, loss 0.599822.
Train: 2018-08-01T01:25:59.776649: step 24684, loss 0.490054.
Train: 2018-08-01T01:25:59.917222: step 24685, loss 0.526263.
Train: 2018-08-01T01:26:00.073431: step 24686, loss 0.543839.
Train: 2018-08-01T01:26:00.229651: step 24687, loss 0.508539.
Train: 2018-08-01T01:26:00.401485: step 24688, loss 0.525898.
Train: 2018-08-01T01:26:00.557700: step 24689, loss 0.525905.
Train: 2018-08-01T01:26:00.713912: step 24690, loss 0.562984.
Test: 2018-08-01T01:26:01.198175: step 24690, loss 0.547666.
Train: 2018-08-01T01:26:01.354388: step 24691, loss 0.544324.
Train: 2018-08-01T01:26:01.510601: step 24692, loss 0.511287.
Train: 2018-08-01T01:26:01.666820: step 24693, loss 0.508635.
Train: 2018-08-01T01:26:01.823022: step 24694, loss 0.545485.
Train: 2018-08-01T01:26:01.994864: step 24695, loss 0.65542.
Train: 2018-08-01T01:26:02.151046: step 24696, loss 0.470669.
Train: 2018-08-01T01:26:02.307259: step 24697, loss 0.581704.
Train: 2018-08-01T01:26:02.463503: step 24698, loss 0.656009.
Train: 2018-08-01T01:26:02.619685: step 24699, loss 0.507971.
Train: 2018-08-01T01:26:02.775930: step 24700, loss 0.507888.
Test: 2018-08-01T01:26:03.244570: step 24700, loss 0.547623.
Train: 2018-08-01T01:26:03.916277: step 24701, loss 0.61836.
Train: 2018-08-01T01:26:04.072471: step 24702, loss 0.616708.
Train: 2018-08-01T01:26:04.259963: step 24703, loss 0.598907.
Train: 2018-08-01T01:26:04.416171: step 24704, loss 0.544594.
Train: 2018-08-01T01:26:04.572384: step 24705, loss 0.616531.
Train: 2018-08-01T01:26:04.744219: step 24706, loss 0.558356.
Train: 2018-08-01T01:26:04.900432: step 24707, loss 0.575752.
Train: 2018-08-01T01:26:05.056646: step 24708, loss 0.607724.
Train: 2018-08-01T01:26:05.212830: step 24709, loss 0.570882.
Train: 2018-08-01T01:26:05.369072: step 24710, loss 0.680054.
Test: 2018-08-01T01:26:05.853333: step 24710, loss 0.552695.
Train: 2018-08-01T01:26:06.009518: step 24711, loss 0.600385.
Train: 2018-08-01T01:26:06.181351: step 24712, loss 0.512017.
Train: 2018-08-01T01:26:06.337565: step 24713, loss 0.517185.
Train: 2018-08-01T01:26:06.493779: step 24714, loss 0.554494.
Train: 2018-08-01T01:26:06.650023: step 24715, loss 0.619429.
Train: 2018-08-01T01:26:06.806236: step 24716, loss 0.592124.
Train: 2018-08-01T01:26:06.962448: step 24717, loss 0.564889.
Train: 2018-08-01T01:26:07.118633: step 24718, loss 0.56381.
Train: 2018-08-01T01:26:07.274845: step 24719, loss 0.492801.
Train: 2018-08-01T01:26:07.446682: step 24720, loss 0.528244.
Test: 2018-08-01T01:26:07.915352: step 24720, loss 0.547993.
Train: 2018-08-01T01:26:08.071534: step 24721, loss 0.546237.
Train: 2018-08-01T01:26:08.227748: step 24722, loss 0.636567.
Train: 2018-08-01T01:26:08.383962: step 24723, loss 0.564256.
Train: 2018-08-01T01:26:08.555796: step 24724, loss 0.508811.
Train: 2018-08-01T01:26:08.712009: step 24725, loss 0.472447.
Train: 2018-08-01T01:26:08.868223: step 24726, loss 0.563178.
Train: 2018-08-01T01:26:09.008845: step 24727, loss 0.526934.
Train: 2018-08-01T01:26:09.165060: step 24728, loss 0.545014.
Train: 2018-08-01T01:26:09.321272: step 24729, loss 0.490382.
Train: 2018-08-01T01:26:09.477480: step 24730, loss 0.638065.
Test: 2018-08-01T01:26:09.946126: step 24730, loss 0.548113.
Train: 2018-08-01T01:26:10.117930: step 24731, loss 0.471409.
Train: 2018-08-01T01:26:10.274174: step 24732, loss 0.582309.
Train: 2018-08-01T01:26:10.430388: step 24733, loss 0.581424.
Train: 2018-08-01T01:26:10.586601: step 24734, loss 0.654303.
Train: 2018-08-01T01:26:10.742785: step 24735, loss 0.43588.
Train: 2018-08-01T01:26:10.899022: step 24736, loss 0.581433.
Train: 2018-08-01T01:26:11.055241: step 24737, loss 0.563723.
Train: 2018-08-01T01:26:11.211424: step 24738, loss 0.490334.
Train: 2018-08-01T01:26:11.367638: step 24739, loss 0.563632.
Train: 2018-08-01T01:26:11.539472: step 24740, loss 0.581014.
Test: 2018-08-01T01:26:11.992506: step 24740, loss 0.548064.
Train: 2018-08-01T01:26:12.148705: step 24741, loss 0.508031.
Train: 2018-08-01T01:26:12.304949: step 24742, loss 0.526644.
Train: 2018-08-01T01:26:12.461156: step 24743, loss 0.638119.
Train: 2018-08-01T01:26:12.617375: step 24744, loss 0.547673.
Train: 2018-08-01T01:26:12.773589: step 24745, loss 0.526348.
Train: 2018-08-01T01:26:12.945393: step 24746, loss 0.581733.
Train: 2018-08-01T01:26:13.101636: step 24747, loss 0.654673.
Train: 2018-08-01T01:26:13.257819: step 24748, loss 0.545028.
Train: 2018-08-01T01:26:13.414032: step 24749, loss 0.63575.
Train: 2018-08-01T01:26:13.585868: step 24750, loss 0.671692.
Test: 2018-08-01T01:26:14.054539: step 24750, loss 0.548023.
Train: 2018-08-01T01:26:14.210752: step 24751, loss 0.563193.
Train: 2018-08-01T01:26:14.366966: step 24752, loss 0.50918.
Train: 2018-08-01T01:26:14.523182: step 24753, loss 0.65308.
Train: 2018-08-01T01:26:14.695013: step 24754, loss 0.598773.
Train: 2018-08-01T01:26:14.851226: step 24755, loss 0.598626.
Train: 2018-08-01T01:26:15.007411: step 24756, loss 0.509688.
Train: 2018-08-01T01:26:15.179275: step 24757, loss 0.527548.
Train: 2018-08-01T01:26:15.335488: step 24758, loss 0.545243.
Train: 2018-08-01T01:26:15.491672: step 24759, loss 0.580483.
Train: 2018-08-01T01:26:15.647916: step 24760, loss 0.49251.
Test: 2018-08-01T01:26:16.116555: step 24760, loss 0.548119.
Train: 2018-08-01T01:26:16.304012: step 24761, loss 0.562826.
Train: 2018-08-01T01:26:16.475817: step 24762, loss 0.597911.
Train: 2018-08-01T01:26:16.632059: step 24763, loss 0.562807.
Train: 2018-08-01T01:26:16.788274: step 24764, loss 0.49277.
Train: 2018-08-01T01:26:16.944456: step 24765, loss 0.615269.
Train: 2018-08-01T01:26:17.100670: step 24766, loss 0.492862.
Train: 2018-08-01T01:26:17.272504: step 24767, loss 0.527824.
Train: 2018-08-01T01:26:17.428749: step 24768, loss 0.54528.
Train: 2018-08-01T01:26:17.600583: step 24769, loss 0.545271.
Train: 2018-08-01T01:26:17.756796: step 24770, loss 0.527766.
Test: 2018-08-01T01:26:18.241058: step 24770, loss 0.548088.
Train: 2018-08-01T01:26:18.397276: step 24771, loss 0.510228.
Train: 2018-08-01T01:26:18.584722: step 24772, loss 0.580292.
Train: 2018-08-01T01:26:18.740910: step 24773, loss 0.720666.
Train: 2018-08-01T01:26:18.897124: step 24774, loss 0.650372.
Train: 2018-08-01T01:26:19.053369: step 24775, loss 0.597707.
Train: 2018-08-01T01:26:19.209582: step 24776, loss 0.545267.
Train: 2018-08-01T01:26:19.381416: step 24777, loss 0.667185.
Train: 2018-08-01T01:26:19.537600: step 24778, loss 0.597402.
Train: 2018-08-01T01:26:19.693812: step 24779, loss 0.666499.
Train: 2018-08-01T01:26:19.850057: step 24780, loss 0.562655.
Test: 2018-08-01T01:26:20.318696: step 24780, loss 0.548272.
Train: 2018-08-01T01:26:20.474910: step 24781, loss 0.528321.
Train: 2018-08-01T01:26:20.646739: step 24782, loss 0.579758.
Train: 2018-08-01T01:26:20.802928: step 24783, loss 0.511438.
Train: 2018-08-01T01:26:20.959141: step 24784, loss 0.596698.
Train: 2018-08-01T01:26:21.115355: step 24785, loss 0.664603.
Train: 2018-08-01T01:26:21.271593: step 24786, loss 0.494902.
Train: 2018-08-01T01:26:21.427812: step 24787, loss 0.579538.
Train: 2018-08-01T01:26:21.583995: step 24788, loss 0.613261.
Train: 2018-08-01T01:26:21.755830: step 24789, loss 0.596312.
Train: 2018-08-01T01:26:21.912067: step 24790, loss 0.545876.
Test: 2018-08-01T01:26:22.380713: step 24790, loss 0.548641.
Train: 2018-08-01T01:26:22.536928: step 24791, loss 0.495668.
Train: 2018-08-01T01:26:22.693135: step 24792, loss 0.562672.
Train: 2018-08-01T01:26:22.864970: step 24793, loss 0.64628.
Train: 2018-08-01T01:26:23.021188: step 24794, loss 0.612735.
Train: 2018-08-01T01:26:23.177402: step 24795, loss 0.579354.
Train: 2018-08-01T01:26:23.333616: step 24796, loss 0.629171.
Train: 2018-08-01T01:26:23.489828: step 24797, loss 0.529518.
Train: 2018-08-01T01:26:23.646043: step 24798, loss 0.529387.
Train: 2018-08-01T01:26:23.802256: step 24799, loss 0.513532.
Train: 2018-08-01T01:26:24.005339: step 24800, loss 0.6283.
Test: 2018-08-01T01:26:24.473944: step 24800, loss 0.549289.
Train: 2018-08-01T01:26:25.192524: step 24801, loss 0.612299.
Train: 2018-08-01T01:26:25.348768: step 24802, loss 0.531559.
Train: 2018-08-01T01:26:25.520574: step 24803, loss 0.466823.
Train: 2018-08-01T01:26:25.692408: step 24804, loss 0.563413.
Train: 2018-08-01T01:26:25.848659: step 24805, loss 0.579326.
Train: 2018-08-01T01:26:26.004865: step 24806, loss 0.579295.
Train: 2018-08-01T01:26:26.176669: step 24807, loss 0.579319.
Train: 2018-08-01T01:26:26.332914: step 24808, loss 0.662084.
Train: 2018-08-01T01:26:26.489097: step 24809, loss 0.579335.
Train: 2018-08-01T01:26:26.645340: step 24810, loss 0.54629.
Test: 2018-08-01T01:26:27.129599: step 24810, loss 0.548988.
Train: 2018-08-01T01:26:27.301436: step 24811, loss 0.463735.
Train: 2018-08-01T01:26:27.457649: step 24812, loss 0.529742.
Train: 2018-08-01T01:26:27.629481: step 24813, loss 0.54624.
Train: 2018-08-01T01:26:27.785667: step 24814, loss 0.612526.
Train: 2018-08-01T01:26:27.941905: step 24815, loss 0.4134.
Train: 2018-08-01T01:26:28.098125: step 24816, loss 0.496184.
Train: 2018-08-01T01:26:28.254309: step 24817, loss 0.579434.
Train: 2018-08-01T01:26:28.426142: step 24818, loss 0.612977.
Train: 2018-08-01T01:26:28.582357: step 24819, loss 0.545901.
Train: 2018-08-01T01:26:28.754221: step 24820, loss 0.613153.
Test: 2018-08-01T01:26:29.222860: step 24820, loss 0.548554.
Train: 2018-08-01T01:26:29.394666: step 24821, loss 0.579517.
Train: 2018-08-01T01:26:29.550879: step 24822, loss 0.646999.
Train: 2018-08-01T01:26:29.722713: step 24823, loss 0.663872.
Train: 2018-08-01T01:26:29.878927: step 24824, loss 0.613187.
Train: 2018-08-01T01:26:30.035171: step 24825, loss 0.478586.
Train: 2018-08-01T01:26:30.191386: step 24826, loss 0.512236.
Train: 2018-08-01T01:26:30.347597: step 24827, loss 0.629897.
Train: 2018-08-01T01:26:30.519427: step 24828, loss 0.562638.
Train: 2018-08-01T01:26:30.675617: step 24829, loss 0.613051.
Train: 2018-08-01T01:26:30.847450: step 24830, loss 0.529134.
Test: 2018-08-01T01:26:31.316090: step 24830, loss 0.548601.
Train: 2018-08-01T01:26:31.472304: step 24831, loss 0.445251.
Train: 2018-08-01T01:26:31.644139: step 24832, loss 0.56263.
Train: 2018-08-01T01:26:31.784731: step 24833, loss 0.495374.
Train: 2018-08-01T01:26:31.940944: step 24834, loss 0.528911.
Train: 2018-08-01T01:26:32.097158: step 24835, loss 0.596376.
Train: 2018-08-01T01:26:32.253371: step 24836, loss 0.647172.
Train: 2018-08-01T01:26:32.425231: step 24837, loss 0.545664.
Train: 2018-08-01T01:26:32.581451: step 24838, loss 0.579521.
Train: 2018-08-01T01:26:32.753254: step 24839, loss 0.579528.
Train: 2018-08-01T01:26:32.893877: step 24840, loss 0.579513.
Test: 2018-08-01T01:26:33.378107: step 24840, loss 0.548387.
Train: 2018-08-01T01:26:33.534322: step 24841, loss 0.630353.
Train: 2018-08-01T01:26:33.690566: step 24842, loss 0.461001.
Train: 2018-08-01T01:26:33.846748: step 24843, loss 0.579511.
Train: 2018-08-01T01:26:34.002961: step 24844, loss 0.630342.
Train: 2018-08-01T01:26:34.159206: step 24845, loss 0.57949.
Train: 2018-08-01T01:26:34.315388: step 24846, loss 0.579486.
Train: 2018-08-01T01:26:34.471632: step 24847, loss 0.664014.
Train: 2018-08-01T01:26:34.627815: step 24848, loss 0.511929.
Train: 2018-08-01T01:26:34.784030: step 24849, loss 0.596259.
Train: 2018-08-01T01:26:34.955864: step 24850, loss 0.495198.
Test: 2018-08-01T01:26:35.440156: step 24850, loss 0.548484.
Train: 2018-08-01T01:26:35.596338: step 24851, loss 0.579382.
Train: 2018-08-01T01:26:35.752551: step 24852, loss 0.528932.
Train: 2018-08-01T01:26:35.908765: step 24853, loss 0.663305.
Train: 2018-08-01T01:26:36.080600: step 24854, loss 0.546067.
Train: 2018-08-01T01:26:36.236838: step 24855, loss 0.579335.
Train: 2018-08-01T01:26:36.393052: step 24856, loss 0.562645.
Train: 2018-08-01T01:26:36.549240: step 24857, loss 0.629862.
Train: 2018-08-01T01:26:36.721075: step 24858, loss 0.545661.
Train: 2018-08-01T01:26:36.877319: step 24859, loss 0.52918.
Train: 2018-08-01T01:26:37.033502: step 24860, loss 0.5962.
Test: 2018-08-01T01:26:37.517763: step 24860, loss 0.548671.
Train: 2018-08-01T01:26:37.674003: step 24861, loss 0.512949.
Train: 2018-08-01T01:26:37.845820: step 24862, loss 0.429188.
Train: 2018-08-01T01:26:38.002050: step 24863, loss 0.612778.
Train: 2018-08-01T01:26:38.158238: step 24864, loss 0.562642.
Train: 2018-08-01T01:26:38.314482: step 24865, loss 0.579407.
Train: 2018-08-01T01:26:38.470696: step 24866, loss 0.62983.
Train: 2018-08-01T01:26:38.626904: step 24867, loss 0.512218.
Train: 2018-08-01T01:26:38.783124: step 24868, loss 0.49535.
Train: 2018-08-01T01:26:38.939307: step 24869, loss 0.562598.
Train: 2018-08-01T01:26:39.095550: step 24870, loss 0.478271.
Test: 2018-08-01T01:26:39.579811: step 24870, loss 0.54842.
Train: 2018-08-01T01:26:39.736025: step 24871, loss 0.596377.
Train: 2018-08-01T01:26:39.892209: step 24872, loss 0.562555.
Train: 2018-08-01T01:26:40.048422: step 24873, loss 0.56255.
Train: 2018-08-01T01:26:40.204635: step 24874, loss 0.596519.
Train: 2018-08-01T01:26:40.376500: step 24875, loss 0.494536.
Train: 2018-08-01T01:26:40.532714: step 24876, loss 0.511458.
Train: 2018-08-01T01:26:40.704548: step 24877, loss 0.579624.
Train: 2018-08-01T01:26:40.860731: step 24878, loss 0.596733.
Train: 2018-08-01T01:26:41.016975: step 24879, loss 0.63101.
Train: 2018-08-01T01:26:41.173188: step 24880, loss 0.511141.
Test: 2018-08-01T01:26:41.641828: step 24880, loss 0.548171.
Train: 2018-08-01T01:26:41.813633: step 24881, loss 0.631082.
Train: 2018-08-01T01:26:41.969876: step 24882, loss 0.562521.
Train: 2018-08-01T01:26:42.126089: step 24883, loss 0.545385.
Train: 2018-08-01T01:26:42.297894: step 24884, loss 0.562519.
Train: 2018-08-01T01:26:42.454107: step 24885, loss 0.579656.
Train: 2018-08-01T01:26:42.641588: step 24886, loss 0.442517.
Train: 2018-08-01T01:26:42.797777: step 24887, loss 0.545366.
Train: 2018-08-01T01:26:42.953991: step 24888, loss 0.579693.
Train: 2018-08-01T01:26:43.110204: step 24889, loss 0.579698.
Train: 2018-08-01T01:26:43.266417: step 24890, loss 0.510853.
Test: 2018-08-01T01:26:43.735088: step 24890, loss 0.548064.
Train: 2018-08-01T01:26:43.891307: step 24891, loss 0.562504.
Train: 2018-08-01T01:26:44.063136: step 24892, loss 0.545245.
Train: 2018-08-01T01:26:44.219350: step 24893, loss 0.562495.
Train: 2018-08-01T01:26:44.375559: step 24894, loss 0.475985.
Train: 2018-08-01T01:26:44.531777: step 24895, loss 0.597205.
Train: 2018-08-01T01:26:44.703617: step 24896, loss 0.562521.
Train: 2018-08-01T01:26:44.859795: step 24897, loss 0.545134.
Train: 2018-08-01T01:26:45.016032: step 24898, loss 0.597344.
Train: 2018-08-01T01:26:45.172222: step 24899, loss 0.59736.
Train: 2018-08-01T01:26:45.328434: step 24900, loss 0.510256.
Test: 2018-08-01T01:26:45.812696: step 24900, loss 0.547924.
Train: 2018-08-01T01:26:46.562520: step 24901, loss 0.579956.
Train: 2018-08-01T01:26:46.718733: step 24902, loss 0.579964.
Train: 2018-08-01T01:26:46.890597: step 24903, loss 0.597407.
Train: 2018-08-01T01:26:47.062428: step 24904, loss 0.510212.
Train: 2018-08-01T01:26:47.218618: step 24905, loss 0.545078.
Train: 2018-08-01T01:26:47.374831: step 24906, loss 0.492731.
Train: 2018-08-01T01:26:47.531075: step 24907, loss 0.527589.
Train: 2018-08-01T01:26:47.687287: step 24908, loss 0.614998.
Train: 2018-08-01T01:26:47.843470: step 24909, loss 0.632531.
Train: 2018-08-01T01:26:48.015306: step 24910, loss 0.580019.
Test: 2018-08-01T01:26:48.483975: step 24910, loss 0.547881.
Train: 2018-08-01T01:26:48.640191: step 24911, loss 0.597488.
Train: 2018-08-01T01:26:48.796373: step 24912, loss 0.562516.
Train: 2018-08-01T01:26:48.952586: step 24913, loss 0.68465.
Train: 2018-08-01T01:26:49.124422: step 24914, loss 0.405839.
Train: 2018-08-01T01:26:49.280665: step 24915, loss 0.527695.
Train: 2018-08-01T01:26:49.436873: step 24916, loss 0.492884.
Train: 2018-08-01T01:26:49.593092: step 24917, loss 0.684434.
Train: 2018-08-01T01:26:49.749275: step 24918, loss 0.423241.
Train: 2018-08-01T01:26:49.921139: step 24919, loss 0.614773.
Train: 2018-08-01T01:26:50.061731: step 24920, loss 0.527642.
Test: 2018-08-01T01:26:50.545993: step 24920, loss 0.547898.
Train: 2018-08-01T01:26:50.702206: step 24921, loss 0.492747.
Train: 2018-08-01T01:26:50.858389: step 24922, loss 0.579967.
Train: 2018-08-01T01:26:51.014602: step 24923, loss 0.54503.
Train: 2018-08-01T01:26:51.170817: step 24924, loss 0.49253.
Train: 2018-08-01T01:26:51.342653: step 24925, loss 0.650142.
Train: 2018-08-01T01:26:51.498889: step 24926, loss 0.615115.
Train: 2018-08-01T01:26:51.655109: step 24927, loss 0.650147.
Train: 2018-08-01T01:26:51.811315: step 24928, loss 0.650019.
Train: 2018-08-01T01:26:51.967506: step 24929, loss 0.527578.
Train: 2018-08-01T01:26:52.123719: step 24930, loss 0.492773.
Test: 2018-08-01T01:26:52.592357: step 24930, loss 0.547905.
Train: 2018-08-01T01:26:52.748572: step 24931, loss 0.510242.
Train: 2018-08-01T01:26:52.920406: step 24932, loss 0.458003.
Train: 2018-08-01T01:26:53.076620: step 24933, loss 0.701959.
Train: 2018-08-01T01:26:53.232834: step 24934, loss 0.579909.
Train: 2018-08-01T01:26:53.389077: step 24935, loss 0.57989.
Train: 2018-08-01T01:26:53.560881: step 24936, loss 0.527708.
Train: 2018-08-01T01:26:53.717095: step 24937, loss 0.475595.
Train: 2018-08-01T01:26:53.873335: step 24938, loss 0.56248.
Train: 2018-08-01T01:26:54.013931: step 24939, loss 0.666835.
Train: 2018-08-01T01:26:54.170145: step 24940, loss 0.492972.
Test: 2018-08-01T01:26:54.654376: step 24940, loss 0.547926.
Train: 2018-08-01T01:26:54.794998: step 24941, loss 0.562476.
Train: 2018-08-01T01:26:54.951206: step 24942, loss 0.562477.
Train: 2018-08-01T01:26:55.123040: step 24943, loss 0.597221.
Train: 2018-08-01T01:26:55.275123: step 24944, loss 0.475653.
Train: 2018-08-01T01:26:55.446958: step 24945, loss 0.59722.
Train: 2018-08-01T01:26:55.603200: step 24946, loss 0.510353.
Train: 2018-08-01T01:26:55.790626: step 24947, loss 0.597244.
Train: 2018-08-01T01:26:55.931219: step 24948, loss 0.597247.
Train: 2018-08-01T01:26:56.087432: step 24949, loss 0.684131.
Train: 2018-08-01T01:26:56.243645: step 24950, loss 0.54512.
Test: 2018-08-01T01:26:56.727937: step 24950, loss 0.547959.
Train: 2018-08-01T01:26:56.930985: step 24951, loss 0.510497.
Train: 2018-08-01T01:26:57.087198: step 24952, loss 0.545152.
Train: 2018-08-01T01:26:57.243441: step 24953, loss 0.579763.
Train: 2018-08-01T01:26:57.399655: step 24954, loss 0.458717.
Train: 2018-08-01T01:26:57.555870: step 24955, loss 0.406747.
Train: 2018-08-01T01:26:57.712083: step 24956, loss 0.597153.
Train: 2018-08-01T01:26:57.868267: step 24957, loss 0.545094.
Train: 2018-08-01T01:26:58.024503: step 24958, loss 0.57988.
Train: 2018-08-01T01:26:58.180724: step 24959, loss 0.597334.
Train: 2018-08-01T01:26:58.336935: step 24960, loss 0.510161.
Test: 2018-08-01T01:26:58.821167: step 24960, loss 0.547863.
Train: 2018-08-01T01:26:58.977408: step 24961, loss 0.614872.
Train: 2018-08-01T01:26:59.133593: step 24962, loss 0.510079.
Train: 2018-08-01T01:26:59.289837: step 24963, loss 0.562492.
Train: 2018-08-01T01:26:59.446020: step 24964, loss 0.562495.
Train: 2018-08-01T01:26:59.602264: step 24965, loss 0.615035.
Train: 2018-08-01T01:26:59.758447: step 24966, loss 0.457427.
Train: 2018-08-01T01:26:59.914685: step 24967, loss 0.580032.
Train: 2018-08-01T01:27:00.070875: step 24968, loss 0.615139.
Train: 2018-08-01T01:27:00.242710: step 24969, loss 0.667772.
Train: 2018-08-01T01:27:00.398952: step 24970, loss 0.562499.
Test: 2018-08-01T01:27:00.867592: step 24970, loss 0.547838.
Train: 2018-08-01T01:27:01.023777: step 24971, loss 0.579991.
Train: 2018-08-01T01:27:01.195638: step 24972, loss 0.475109.
Train: 2018-08-01T01:27:01.351849: step 24973, loss 0.527543.
Train: 2018-08-01T01:27:01.508068: step 24974, loss 0.527537.
Train: 2018-08-01T01:27:01.664250: step 24975, loss 0.545005.
Train: 2018-08-01T01:27:01.820464: step 24976, loss 0.475027.
Train: 2018-08-01T01:27:01.976708: step 24977, loss 0.615051.
Train: 2018-08-01T01:27:02.132891: step 24978, loss 0.562498.
Train: 2018-08-01T01:27:02.304761: step 24979, loss 0.615123.
Train: 2018-08-01T01:27:02.460940: step 24980, loss 0.492352.
Test: 2018-08-01T01:27:02.929579: step 24980, loss 0.547808.
Train: 2018-08-01T01:27:03.101439: step 24981, loss 0.580052.
Train: 2018-08-01T01:27:03.242006: step 24982, loss 0.5274.
Train: 2018-08-01T01:27:03.413868: step 24983, loss 0.487569.
Train: 2018-08-01T01:27:03.570056: step 24984, loss 0.615278.
Train: 2018-08-01T01:27:03.726293: step 24985, loss 0.650504.
Train: 2018-08-01T01:27:03.882511: step 24986, loss 0.492171.
Train: 2018-08-01T01:27:04.038696: step 24987, loss 0.615284.
Train: 2018-08-01T01:27:04.194940: step 24988, loss 0.52735.
Train: 2018-08-01T01:27:04.335531: step 24989, loss 0.439459.
Train: 2018-08-01T01:27:04.507336: step 24990, loss 0.580119.
Test: 2018-08-01T01:27:04.975974: step 24990, loss 0.547771.
Train: 2018-08-01T01:27:05.132188: step 24991, loss 0.456822.
Train: 2018-08-01T01:27:05.288432: step 24992, loss 0.456628.
Train: 2018-08-01T01:27:05.444640: step 24993, loss 0.597961.
Train: 2018-08-01T01:27:05.616453: step 24994, loss 0.615791.
Train: 2018-08-01T01:27:05.772694: step 24995, loss 0.509296.
Train: 2018-08-01T01:27:05.928877: step 24996, loss 0.704906.
Train: 2018-08-01T01:27:06.085090: step 24997, loss 0.687082.
Train: 2018-08-01T01:27:06.241304: step 24998, loss 0.615832.
Train: 2018-08-01T01:27:06.397549: step 24999, loss 0.597981.
Train: 2018-08-01T01:27:06.553731: step 25000, loss 0.491876.
Test: 2018-08-01T01:27:07.022401: step 25000, loss 0.547759.
Train: 2018-08-01T01:27:07.725362: step 25001, loss 0.509618.
Train: 2018-08-01T01:27:07.912788: step 25002, loss 0.474416.
Train: 2018-08-01T01:27:08.053411: step 25003, loss 0.527269.
Train: 2018-08-01T01:27:08.209594: step 25004, loss 0.527251.
Train: 2018-08-01T01:27:08.365808: step 25005, loss 0.580231.
Train: 2018-08-01T01:27:08.522020: step 25006, loss 0.509604.
Train: 2018-08-01T01:27:08.693886: step 25007, loss 0.456517.
Train: 2018-08-01T01:27:08.865692: step 25008, loss 0.491735.
Train: 2018-08-01T01:27:09.021903: step 25009, loss 0.633569.
Train: 2018-08-01T01:27:09.178117: step 25010, loss 0.562583.
Test: 2018-08-01T01:27:09.646785: step 25010, loss 0.547696.
Train: 2018-08-01T01:27:09.802995: step 25011, loss 0.527005.
Train: 2018-08-01T01:27:09.974825: step 25012, loss 0.598223.
Train: 2018-08-01T01:27:10.115397: step 25013, loss 0.562603.
Train: 2018-08-01T01:27:10.287232: step 25014, loss 0.473438.
Train: 2018-08-01T01:27:10.443476: step 25015, loss 0.651948.
Train: 2018-08-01T01:27:10.615281: step 25016, loss 0.544774.
Train: 2018-08-01T01:27:10.771525: step 25017, loss 0.491156.
Train: 2018-08-01T01:27:10.927738: step 25018, loss 0.598387.
Train: 2018-08-01T01:27:11.083940: step 25019, loss 0.598393.
Train: 2018-08-01T01:27:11.240134: step 25020, loss 0.652041.
Test: 2018-08-01T01:27:11.708775: step 25020, loss 0.547673.
Train: 2018-08-01T01:27:11.865018: step 25021, loss 0.687588.
Train: 2018-08-01T01:27:12.021201: step 25022, loss 0.544777.
Train: 2018-08-01T01:27:12.193060: step 25023, loss 0.54482.
Train: 2018-08-01T01:27:12.349279: step 25024, loss 0.615726.
Train: 2018-08-01T01:27:12.505500: step 25025, loss 0.562545.
Train: 2018-08-01T01:27:12.661675: step 25026, loss 0.5978.
Train: 2018-08-01T01:27:12.817890: step 25027, loss 0.562508.
Train: 2018-08-01T01:27:12.974102: step 25028, loss 0.580057.
Train: 2018-08-01T01:27:13.130347: step 25029, loss 0.579973.
Train: 2018-08-01T01:27:13.302151: step 25030, loss 0.527525.
Test: 2018-08-01T01:27:13.786442: step 25030, loss 0.547871.
Train: 2018-08-01T01:27:13.942625: step 25031, loss 0.579916.
Train: 2018-08-01T01:27:14.098840: step 25032, loss 0.562443.
Train: 2018-08-01T01:27:14.255053: step 25033, loss 0.597161.
Train: 2018-08-01T01:27:14.458130: step 25034, loss 0.614461.
Train: 2018-08-01T01:27:14.629995: step 25035, loss 0.562434.
Train: 2018-08-01T01:27:14.786179: step 25036, loss 0.493466.
Train: 2018-08-01T01:27:14.942392: step 25037, loss 0.45912.
Train: 2018-08-01T01:27:15.098630: step 25038, loss 0.579652.
Train: 2018-08-01T01:27:15.254849: step 25039, loss 0.476329.
Train: 2018-08-01T01:27:15.411062: step 25040, loss 0.57969.
Test: 2018-08-01T01:27:15.879702: step 25040, loss 0.547994.
Train: 2018-08-01T01:27:16.035916: step 25041, loss 0.596912.
Train: 2018-08-01T01:27:16.192098: step 25042, loss 0.614206.
Train: 2018-08-01T01:27:16.363933: step 25043, loss 0.562434.
Train: 2018-08-01T01:27:16.520149: step 25044, loss 0.562453.
Train: 2018-08-01T01:27:16.691981: step 25045, loss 0.562427.
Train: 2018-08-01T01:27:16.848195: step 25046, loss 0.545212.
Train: 2018-08-01T01:27:17.004409: step 25047, loss 0.510793.
Train: 2018-08-01T01:27:17.160647: step 25048, loss 0.493544.
Train: 2018-08-01T01:27:17.316866: step 25049, loss 0.527946.
Train: 2018-08-01T01:27:17.473079: step 25050, loss 0.545171.
Test: 2018-08-01T01:27:17.941720: step 25050, loss 0.547955.
Train: 2018-08-01T01:27:18.097933: step 25051, loss 0.631628.
Train: 2018-08-01T01:27:18.269767: step 25052, loss 0.545147.
Train: 2018-08-01T01:27:18.425950: step 25053, loss 0.527798.
Train: 2018-08-01T01:27:18.582165: step 25054, loss 0.614467.
Train: 2018-08-01T01:27:18.785241: step 25055, loss 0.475746.
Train: 2018-08-01T01:27:18.941479: step 25056, loss 0.527701.
Train: 2018-08-01T01:27:19.097699: step 25057, loss 0.57982.
Train: 2018-08-01T01:27:19.253881: step 25058, loss 0.545039.
Train: 2018-08-01T01:27:19.410119: step 25059, loss 0.492747.
Train: 2018-08-01T01:27:19.581930: step 25060, loss 0.68468.
Test: 2018-08-01T01:27:20.050602: step 25060, loss 0.547843.
Train: 2018-08-01T01:27:20.222429: step 25061, loss 0.545.
Train: 2018-08-01T01:27:20.378619: step 25062, loss 0.510058.
Train: 2018-08-01T01:27:20.534832: step 25063, loss 0.475057.
Train: 2018-08-01T01:27:20.691046: step 25064, loss 0.667615.
Train: 2018-08-01T01:27:20.847290: step 25065, loss 0.474892.
Train: 2018-08-01T01:27:21.019118: step 25066, loss 0.56247.
Train: 2018-08-01T01:27:21.175306: step 25067, loss 0.457155.
Train: 2018-08-01T01:27:21.331550: step 25068, loss 0.580077.
Train: 2018-08-01T01:27:21.487764: step 25069, loss 0.580129.
Train: 2018-08-01T01:27:21.643978: step 25070, loss 0.509585.
Test: 2018-08-01T01:27:22.128240: step 25070, loss 0.547732.
Train: 2018-08-01T01:27:22.284422: step 25071, loss 0.527206.
Train: 2018-08-01T01:27:22.440636: step 25072, loss 0.597936.
Train: 2018-08-01T01:27:22.596849: step 25073, loss 0.633458.
Train: 2018-08-01T01:27:22.753063: step 25074, loss 0.491666.
Train: 2018-08-01T01:27:22.909306: step 25075, loss 0.580306.
Train: 2018-08-01T01:27:23.065489: step 25076, loss 0.651262.
Train: 2018-08-01T01:27:23.252970: step 25077, loss 0.598038.
Train: 2018-08-01T01:27:23.393568: step 25078, loss 0.562535.
Train: 2018-08-01T01:27:23.565404: step 25079, loss 0.615591.
Train: 2018-08-01T01:27:23.721610: step 25080, loss 0.527196.
Test: 2018-08-01T01:27:24.190258: step 25080, loss 0.547746.
Train: 2018-08-01T01:27:24.362060: step 25081, loss 0.562515.
Train: 2018-08-01T01:27:24.533926: step 25082, loss 0.59774.
Train: 2018-08-01T01:27:24.690110: step 25083, loss 0.668037.
Train: 2018-08-01T01:27:24.846353: step 25084, loss 0.667723.
Train: 2018-08-01T01:27:25.002537: step 25085, loss 0.63236.
Train: 2018-08-01T01:27:25.174402: step 25086, loss 0.527651.
Train: 2018-08-01T01:27:25.330584: step 25087, loss 0.597123.
Train: 2018-08-01T01:27:25.486798: step 25088, loss 0.59699.
Train: 2018-08-01T01:27:25.643011: step 25089, loss 0.717354.
Train: 2018-08-01T01:27:25.799256: step 25090, loss 0.442569.
Test: 2018-08-01T01:27:26.267894: step 25090, loss 0.548136.
Train: 2018-08-01T01:27:26.439725: step 25091, loss 0.613633.
Train: 2018-08-01T01:27:26.595912: step 25092, loss 0.579449.
Train: 2018-08-01T01:27:26.752126: step 25093, loss 0.56245.
Train: 2018-08-01T01:27:26.923961: step 25094, loss 0.477956.
Train: 2018-08-01T01:27:27.080205: step 25095, loss 0.579327.
Train: 2018-08-01T01:27:27.236389: step 25096, loss 0.528776.
Train: 2018-08-01T01:27:27.377012: step 25097, loss 0.545639.
Train: 2018-08-01T01:27:27.548816: step 25098, loss 0.495202.
Train: 2018-08-01T01:27:27.705028: step 25099, loss 0.629759.
Train: 2018-08-01T01:27:27.861241: step 25100, loss 0.49521.
Test: 2018-08-01T01:27:28.329911: step 25100, loss 0.54838.
Train: 2018-08-01T01:27:29.048494: step 25101, loss 0.562467.
Train: 2018-08-01T01:27:29.204707: step 25102, loss 0.5793.
Train: 2018-08-01T01:27:29.360921: step 25103, loss 0.5793.
Train: 2018-08-01T01:27:29.532750: step 25104, loss 0.5793.
Train: 2018-08-01T01:27:29.688939: step 25105, loss 0.629811.
Train: 2018-08-01T01:27:29.860804: step 25106, loss 0.478358.
Train: 2018-08-01T01:27:30.017017: step 25107, loss 0.478328.
Train: 2018-08-01T01:27:30.173231: step 25108, loss 0.444497.
Train: 2018-08-01T01:27:30.329438: step 25109, loss 0.646948.
Train: 2018-08-01T01:27:30.485656: step 25110, loss 0.545518.
Test: 2018-08-01T01:27:30.954267: step 25110, loss 0.548243.
Train: 2018-08-01T01:27:31.110510: step 25111, loss 0.545486.
Train: 2018-08-01T01:27:31.282317: step 25112, loss 0.494506.
Train: 2018-08-01T01:27:31.454150: step 25113, loss 0.732663.
Train: 2018-08-01T01:27:31.594743: step 25114, loss 0.545405.
Train: 2018-08-01T01:27:31.766606: step 25115, loss 0.596488.
Train: 2018-08-01T01:27:31.922790: step 25116, loss 0.545403.
Train: 2018-08-01T01:27:32.094624: step 25117, loss 0.630544.
Train: 2018-08-01T01:27:32.250838: step 25118, loss 0.545414.
Train: 2018-08-01T01:27:32.407082: step 25119, loss 0.477386.
Train: 2018-08-01T01:27:32.547669: step 25120, loss 0.579451.
Test: 2018-08-01T01:27:33.031905: step 25120, loss 0.548169.
Train: 2018-08-01T01:27:33.188150: step 25121, loss 0.596485.
Train: 2018-08-01T01:27:33.344332: step 25122, loss 0.579457.
Train: 2018-08-01T01:27:33.500575: step 25123, loss 0.528379.
Train: 2018-08-01T01:27:33.656797: step 25124, loss 0.647576.
Train: 2018-08-01T01:27:33.813003: step 25125, loss 0.494366.
Train: 2018-08-01T01:27:33.969212: step 25126, loss 0.630503.
Train: 2018-08-01T01:27:34.141021: step 25127, loss 0.613451.
Train: 2018-08-01T01:27:34.297266: step 25128, loss 0.562433.
Train: 2018-08-01T01:27:34.453447: step 25129, loss 0.613338.
Train: 2018-08-01T01:27:34.609691: step 25130, loss 0.562439.
Test: 2018-08-01T01:27:35.093952: step 25130, loss 0.548278.
Train: 2018-08-01T01:27:35.250179: step 25131, loss 0.460943.
Train: 2018-08-01T01:27:35.406349: step 25132, loss 0.579361.
Train: 2018-08-01T01:27:35.562563: step 25133, loss 0.477863.
Train: 2018-08-01T01:27:35.718806: step 25134, loss 0.511642.
Train: 2018-08-01T01:27:35.875015: step 25135, loss 0.748994.
Train: 2018-08-01T01:27:36.046849: step 25136, loss 0.545493.
Train: 2018-08-01T01:27:36.203062: step 25137, loss 0.562439.
Train: 2018-08-01T01:27:36.374903: step 25138, loss 0.528585.
Train: 2018-08-01T01:27:36.515495: step 25139, loss 0.494727.
Train: 2018-08-01T01:27:36.671715: step 25140, loss 0.545494.
Test: 2018-08-01T01:27:37.140348: step 25140, loss 0.548231.
Train: 2018-08-01T01:27:37.312152: step 25141, loss 0.562435.
Train: 2018-08-01T01:27:37.483989: step 25142, loss 0.528473.
Train: 2018-08-01T01:27:37.640201: step 25143, loss 0.528423.
Train: 2018-08-01T01:27:37.780793: step 25144, loss 0.477269.
Train: 2018-08-01T01:27:37.937007: step 25145, loss 0.579498.
Train: 2018-08-01T01:27:38.108842: step 25146, loss 0.613756.
Train: 2018-08-01T01:27:38.249464: step 25147, loss 0.579553.
Train: 2018-08-01T01:27:38.421300: step 25148, loss 0.528119.
Train: 2018-08-01T01:27:38.593139: step 25149, loss 0.545248.
Train: 2018-08-01T01:27:38.749348: step 25150, loss 0.45925.
Test: 2018-08-01T01:27:39.217986: step 25150, loss 0.547987.
Train: 2018-08-01T01:27:39.389822: step 25151, loss 0.596897.
Train: 2018-08-01T01:27:39.546037: step 25152, loss 0.579692.
Train: 2018-08-01T01:27:39.717870: step 25153, loss 0.51055.
Train: 2018-08-01T01:27:39.874054: step 25154, loss 0.47581.
Train: 2018-08-01T01:27:40.045889: step 25155, loss 0.579807.
Train: 2018-08-01T01:27:40.202127: step 25156, loss 0.545034.
Train: 2018-08-01T01:27:40.358316: step 25157, loss 0.597341.
Train: 2018-08-01T01:27:40.514553: step 25158, loss 0.544987.
Train: 2018-08-01T01:27:40.670743: step 25159, loss 0.667431.
Train: 2018-08-01T01:27:40.842578: step 25160, loss 0.614948.
Test: 2018-08-01T01:27:41.311247: step 25160, loss 0.547819.
Train: 2018-08-01T01:27:41.467455: step 25161, loss 0.527492.
Train: 2018-08-01T01:27:41.639296: step 25162, loss 0.544979.
Train: 2018-08-01T01:27:41.811100: step 25163, loss 0.440112.
Train: 2018-08-01T01:27:41.967337: step 25164, loss 0.544962.
Train: 2018-08-01T01:27:42.123556: step 25165, loss 0.474844.
Train: 2018-08-01T01:27:42.279770: step 25166, loss 0.580045.
Train: 2018-08-01T01:27:42.420333: step 25167, loss 0.492119.
Train: 2018-08-01T01:27:42.592198: step 25168, loss 0.597773.
Train: 2018-08-01T01:27:42.748380: step 25169, loss 0.650822.
Train: 2018-08-01T01:27:42.920215: step 25170, loss 0.544851.
Test: 2018-08-01T01:27:43.388885: step 25170, loss 0.54772.
Train: 2018-08-01T01:27:43.545100: step 25171, loss 0.633216.
Train: 2018-08-01T01:27:43.701312: step 25172, loss 0.597844.
Train: 2018-08-01T01:27:43.857526: step 25173, loss 0.615451.
Train: 2018-08-01T01:27:44.029331: step 25174, loss 0.509641.
Train: 2018-08-01T01:27:44.185543: step 25175, loss 0.544889.
Train: 2018-08-01T01:27:44.341756: step 25176, loss 0.580082.
Train: 2018-08-01T01:27:44.482349: step 25177, loss 0.597641.
Train: 2018-08-01T01:27:44.638595: step 25178, loss 0.615143.
Train: 2018-08-01T01:27:44.794777: step 25179, loss 0.562468.
Train: 2018-08-01T01:27:44.950990: step 25180, loss 0.667422.
Test: 2018-08-01T01:27:45.435282: step 25180, loss 0.547841.
Train: 2018-08-01T01:27:45.591494: step 25181, loss 0.545005.
Train: 2018-08-01T01:27:45.747707: step 25182, loss 0.527635.
Train: 2018-08-01T01:27:45.903922: step 25183, loss 0.492948.
Train: 2018-08-01T01:27:46.060136: step 25184, loss 0.510358.
Train: 2018-08-01T01:27:46.216320: step 25185, loss 0.735985.
Train: 2018-08-01T01:27:46.372563: step 25186, loss 0.545109.
Train: 2018-08-01T01:27:46.528775: step 25187, loss 0.475997.
Train: 2018-08-01T01:27:46.684957: step 25188, loss 0.545147.
Train: 2018-08-01T01:27:46.841172: step 25189, loss 0.579689.
Train: 2018-08-01T01:27:46.997385: step 25190, loss 0.614195.
Test: 2018-08-01T01:27:47.481647: step 25190, loss 0.547983.
Train: 2018-08-01T01:27:47.637861: step 25191, loss 0.545179.
Train: 2018-08-01T01:27:47.794105: step 25192, loss 0.614088.
Train: 2018-08-01T01:27:47.950318: step 25193, loss 0.545218.
Train: 2018-08-01T01:27:48.106531: step 25194, loss 0.442143.
Train: 2018-08-01T01:27:48.262744: step 25195, loss 0.545228.
Train: 2018-08-01T01:27:48.434585: step 25196, loss 0.579617.
Train: 2018-08-01T01:27:48.590795: step 25197, loss 0.527998.
Train: 2018-08-01T01:27:48.746975: step 25198, loss 0.545193.
Train: 2018-08-01T01:27:48.903188: step 25199, loss 0.493468.
Train: 2018-08-01T01:27:49.059402: step 25200, loss 0.631486.
Test: 2018-08-01T01:27:49.512452: step 25200, loss 0.547955.
Train: 2018-08-01T01:27:50.184164: step 25201, loss 0.527871.
Train: 2018-08-01T01:27:50.340353: step 25202, loss 0.631593.
Train: 2018-08-01T01:27:50.496596: step 25203, loss 0.631586.
Train: 2018-08-01T01:27:50.684053: step 25204, loss 0.493313.
Train: 2018-08-01T01:27:50.840235: step 25205, loss 0.47603.
Train: 2018-08-01T01:27:50.996448: step 25206, loss 0.666194.
Train: 2018-08-01T01:27:51.152662: step 25207, loss 0.527846.
Train: 2018-08-01T01:27:51.308875: step 25208, loss 0.648883.
Train: 2018-08-01T01:27:51.465088: step 25209, loss 0.527873.
Train: 2018-08-01T01:27:51.636951: step 25210, loss 0.545152.
Test: 2018-08-01T01:27:52.121185: step 25210, loss 0.547964.
Train: 2018-08-01T01:27:52.277429: step 25211, loss 0.493366.
Train: 2018-08-01T01:27:52.433643: step 25212, loss 0.545143.
Train: 2018-08-01T01:27:52.589825: step 25213, loss 0.631562.
Train: 2018-08-01T01:27:52.761660: step 25214, loss 0.579708.
Train: 2018-08-01T01:27:52.933526: step 25215, loss 0.596983.
Train: 2018-08-01T01:27:53.089741: step 25216, loss 0.63146.
Train: 2018-08-01T01:27:53.245953: step 25217, loss 0.493485.
Train: 2018-08-01T01:27:53.402166: step 25218, loss 0.614093.
Train: 2018-08-01T01:27:53.558373: step 25219, loss 0.562421.
Train: 2018-08-01T01:27:53.714593: step 25220, loss 0.579601.
Test: 2018-08-01T01:27:54.198824: step 25220, loss 0.548041.
Train: 2018-08-01T01:27:54.355068: step 25221, loss 0.47659.
Train: 2018-08-01T01:27:54.511281: step 25222, loss 0.579579.
Train: 2018-08-01T01:27:54.667495: step 25223, loss 0.596735.
Train: 2018-08-01T01:27:54.823679: step 25224, loss 0.528114.
Train: 2018-08-01T01:27:54.995539: step 25225, loss 0.648154.
Train: 2018-08-01T01:27:55.151725: step 25226, loss 0.648051.
Train: 2018-08-01T01:27:55.307964: step 25227, loss 0.596599.
Train: 2018-08-01T01:27:55.464152: step 25228, loss 0.426005.
Train: 2018-08-01T01:27:55.620365: step 25229, loss 0.579463.
Train: 2018-08-01T01:27:55.776604: step 25230, loss 0.528348.
Test: 2018-08-01T01:27:56.260871: step 25230, loss 0.548154.
Train: 2018-08-01T01:27:56.417086: step 25231, loss 0.596489.
Train: 2018-08-01T01:27:56.573298: step 25232, loss 0.579447.
Train: 2018-08-01T01:27:56.729512: step 25233, loss 0.596456.
Train: 2018-08-01T01:27:56.885695: step 25234, loss 0.562423.
Train: 2018-08-01T01:27:57.041910: step 25235, loss 0.596401.
Train: 2018-08-01T01:27:57.244985: step 25236, loss 0.579398.
Train: 2018-08-01T01:27:57.401224: step 25237, loss 0.579379.
Train: 2018-08-01T01:27:57.557445: step 25238, loss 0.477796.
Train: 2018-08-01T01:27:57.713657: step 25239, loss 0.562433.
Train: 2018-08-01T01:27:57.869838: step 25240, loss 0.528578.
Test: 2018-08-01T01:27:58.338480: step 25240, loss 0.548251.
Train: 2018-08-01T01:27:58.510314: step 25241, loss 0.46082.
Train: 2018-08-01T01:27:58.666527: step 25242, loss 0.596356.
Train: 2018-08-01T01:27:58.822771: step 25243, loss 0.579409.
Train: 2018-08-01T01:27:58.978979: step 25244, loss 0.579422.
Train: 2018-08-01T01:27:59.135198: step 25245, loss 0.528401.
Train: 2018-08-01T01:27:59.275790: step 25246, loss 0.579447.
Train: 2018-08-01T01:27:59.463241: step 25247, loss 0.562418.
Train: 2018-08-01T01:27:59.619454: step 25248, loss 0.579465.
Train: 2018-08-01T01:27:59.775643: step 25249, loss 0.562416.
Train: 2018-08-01T01:27:59.916235: step 25250, loss 0.511229.
Test: 2018-08-01T01:28:00.384874: step 25250, loss 0.548113.
Train: 2018-08-01T01:28:00.556710: step 25251, loss 0.630732.
Train: 2018-08-01T01:28:00.712923: step 25252, loss 0.596574.
Train: 2018-08-01T01:28:00.869136: step 25253, loss 0.459972.
Train: 2018-08-01T01:28:01.025351: step 25254, loss 0.545326.
Train: 2018-08-01T01:28:01.181563: step 25255, loss 0.596629.
Train: 2018-08-01T01:28:01.337807: step 25256, loss 0.528176.
Train: 2018-08-01T01:28:01.509611: step 25257, loss 0.511012.
Train: 2018-08-01T01:28:01.665825: step 25258, loss 0.545252.
Train: 2018-08-01T01:28:01.822070: step 25259, loss 0.596789.
Train: 2018-08-01T01:28:01.978282: step 25260, loss 0.579614.
Test: 2018-08-01T01:28:02.462545: step 25260, loss 0.547999.
Train: 2018-08-01T01:28:02.618758: step 25261, loss 0.527986.
Train: 2018-08-01T01:28:02.806214: step 25262, loss 0.562414.
Train: 2018-08-01T01:28:02.962427: step 25263, loss 0.545169.
Train: 2018-08-01T01:28:03.118610: step 25264, loss 0.648728.
Train: 2018-08-01T01:28:03.274854: step 25265, loss 0.562412.
Train: 2018-08-01T01:28:03.431068: step 25266, loss 0.458879.
Train: 2018-08-01T01:28:03.587251: step 25267, loss 0.527866.
Train: 2018-08-01T01:28:03.774718: step 25268, loss 0.666211.
Train: 2018-08-01T01:28:03.930919: step 25269, loss 0.527822.
Train: 2018-08-01T01:28:04.087134: step 25270, loss 0.700854.
Test: 2018-08-01T01:28:04.555805: step 25270, loss 0.547947.
Train: 2018-08-01T01:28:04.711987: step 25271, loss 0.527856.
Train: 2018-08-01T01:28:04.883821: step 25272, loss 0.596946.
Train: 2018-08-01T01:28:05.024445: step 25273, loss 0.545169.
Train: 2018-08-01T01:28:05.196249: step 25274, loss 0.545184.
Train: 2018-08-01T01:28:05.352461: step 25275, loss 0.527972.
Train: 2018-08-01T01:28:05.508706: step 25276, loss 0.614067.
Train: 2018-08-01T01:28:05.664888: step 25277, loss 0.476396.
Train: 2018-08-01T01:28:05.821102: step 25278, loss 0.579623.
Train: 2018-08-01T01:28:05.992937: step 25279, loss 0.5452.
Train: 2018-08-01T01:28:06.149175: step 25280, loss 0.579629.
Test: 2018-08-01T01:28:06.617820: step 25280, loss 0.547994.
Train: 2018-08-01T01:28:06.774035: step 25281, loss 0.47632.
Train: 2018-08-01T01:28:06.930249: step 25282, loss 0.596884.
Train: 2018-08-01T01:28:07.102091: step 25283, loss 0.61415.
Train: 2018-08-01T01:28:07.258266: step 25284, loss 0.525631.
Train: 2018-08-01T01:28:07.414504: step 25285, loss 0.614162.
Train: 2018-08-01T01:28:07.570723: step 25286, loss 0.596897.
Train: 2018-08-01T01:28:07.726906: step 25287, loss 0.510727.
Train: 2018-08-01T01:28:07.883119: step 25288, loss 0.510729.
Train: 2018-08-01T01:28:08.039333: step 25289, loss 0.407282.
Train: 2018-08-01T01:28:08.211168: step 25290, loss 0.648806.
Test: 2018-08-01T01:28:08.695428: step 25290, loss 0.547934.
Train: 2018-08-01T01:28:08.851672: step 25291, loss 0.597012.
Train: 2018-08-01T01:28:09.007886: step 25292, loss 0.562418.
Train: 2018-08-01T01:28:09.164100: step 25293, loss 0.527795.
Train: 2018-08-01T01:28:09.351550: step 25294, loss 0.631729.
Train: 2018-08-01T01:28:09.507739: step 25295, loss 0.579746.
Train: 2018-08-01T01:28:09.663983: step 25296, loss 0.597054.
Train: 2018-08-01T01:28:09.820195: step 25297, loss 0.579721.
Train: 2018-08-01T01:28:09.976403: step 25298, loss 0.527842.
Train: 2018-08-01T01:28:10.132623: step 25299, loss 0.527856.
Train: 2018-08-01T01:28:10.288838: step 25300, loss 0.631532.
Test: 2018-08-01T01:28:10.757476: step 25300, loss 0.547958.
Train: 2018-08-01T01:28:11.476065: step 25301, loss 0.57968.
Train: 2018-08-01T01:28:11.616650: step 25302, loss 0.527921.
Train: 2018-08-01T01:28:11.772858: step 25303, loss 0.510697.
Train: 2018-08-01T01:28:11.929047: step 25304, loss 0.562412.
Train: 2018-08-01T01:28:12.100882: step 25305, loss 0.596901.
Train: 2018-08-01T01:28:12.257127: step 25306, loss 0.596889.
Train: 2018-08-01T01:28:12.413345: step 25307, loss 0.682991.
Train: 2018-08-01T01:28:12.585174: step 25308, loss 0.648354.
Train: 2018-08-01T01:28:12.741388: step 25309, loss 0.510998.
Train: 2018-08-01T01:28:12.897600: step 25310, loss 0.528207.
Test: 2018-08-01T01:28:13.366240: step 25310, loss 0.548111.
Train: 2018-08-01T01:28:13.522423: step 25311, loss 0.699032.
Train: 2018-08-01T01:28:13.678638: step 25312, loss 0.596469.
Train: 2018-08-01T01:28:13.850502: step 25313, loss 0.59637.
Train: 2018-08-01T01:28:14.006685: step 25314, loss 0.66395.
Train: 2018-08-01T01:28:14.162898: step 25315, loss 0.562445.
Train: 2018-08-01T01:28:14.319142: step 25316, loss 0.495311.
Train: 2018-08-01T01:28:14.475325: step 25317, loss 0.545726.
Train: 2018-08-01T01:28:14.631539: step 25318, loss 0.595917.
Train: 2018-08-01T01:28:14.787752: step 25319, loss 0.69595.
Train: 2018-08-01T01:28:14.943996: step 25320, loss 0.579142.
Test: 2018-08-01T01:28:15.428258: step 25320, loss 0.548669.
Train: 2018-08-01T01:28:15.584472: step 25321, loss 0.595679.
Train: 2018-08-01T01:28:15.740685: step 25322, loss 0.546056.
Train: 2018-08-01T01:28:15.912514: step 25323, loss 0.44731.
Train: 2018-08-01T01:28:16.068728: step 25324, loss 0.513229.
Train: 2018-08-01T01:28:16.224949: step 25325, loss 0.513222.
Train: 2018-08-01T01:28:16.381154: step 25326, loss 0.546117.
Train: 2018-08-01T01:28:16.537374: step 25327, loss 0.628547.
Train: 2018-08-01T01:28:16.709207: step 25328, loss 0.480098.
Train: 2018-08-01T01:28:16.881047: step 25329, loss 0.562566.
Train: 2018-08-01T01:28:17.052848: step 25330, loss 0.59564.
Test: 2018-08-01T01:28:17.537108: step 25330, loss 0.548682.
Train: 2018-08-01T01:28:17.693347: step 25331, loss 0.529431.
Train: 2018-08-01T01:28:17.849566: step 25332, loss 0.61228.
Train: 2018-08-01T01:28:18.021371: step 25333, loss 0.512755.
Train: 2018-08-01T01:28:18.177584: step 25334, loss 0.612366.
Train: 2018-08-01T01:28:18.333797: step 25335, loss 0.612395.
Train: 2018-08-01T01:28:18.490010: step 25336, loss 0.496012.
Train: 2018-08-01T01:28:18.708709: step 25337, loss 0.512583.
Train: 2018-08-01T01:28:18.864922: step 25338, loss 0.662519.
Train: 2018-08-01T01:28:19.021137: step 25339, loss 0.595846.
Train: 2018-08-01T01:28:19.193007: step 25340, loss 0.512484.
Test: 2018-08-01T01:28:19.677263: step 25340, loss 0.548526.
Train: 2018-08-01T01:28:19.833446: step 25341, loss 0.445724.
Train: 2018-08-01T01:28:19.974068: step 25342, loss 0.646071.
Train: 2018-08-01T01:28:20.130281: step 25343, loss 0.595943.
Train: 2018-08-01T01:28:20.317707: step 25344, loss 0.562475.
Train: 2018-08-01T01:28:20.458330: step 25345, loss 0.512225.
Train: 2018-08-01T01:28:20.614543: step 25346, loss 0.495393.
Train: 2018-08-01T01:28:20.770726: step 25347, loss 0.59606.
Train: 2018-08-01T01:28:20.926940: step 25348, loss 0.5288.
Train: 2018-08-01T01:28:21.083178: step 25349, loss 0.714133.
Train: 2018-08-01T01:28:21.239398: step 25350, loss 0.528746.
Test: 2018-08-01T01:28:21.723628: step 25350, loss 0.548332.
Train: 2018-08-01T01:28:21.879877: step 25351, loss 0.495035.
Train: 2018-08-01T01:28:22.036086: step 25352, loss 0.613051.
Train: 2018-08-01T01:28:22.192269: step 25353, loss 0.545561.
Train: 2018-08-01T01:28:22.348512: step 25354, loss 0.663758.
Train: 2018-08-01T01:28:22.520317: step 25355, loss 0.511813.
Train: 2018-08-01T01:28:22.676561: step 25356, loss 0.545562.
Train: 2018-08-01T01:28:22.832773: step 25357, loss 0.511792.
Train: 2018-08-01T01:28:22.988958: step 25358, loss 0.613127.
Train: 2018-08-01T01:28:23.145201: step 25359, loss 0.54553.
Train: 2018-08-01T01:28:23.301383: step 25360, loss 0.511698.
Test: 2018-08-01T01:28:23.770054: step 25360, loss 0.54825.
Train: 2018-08-01T01:28:23.926237: step 25361, loss 0.613218.
Train: 2018-08-01T01:28:24.082481: step 25362, loss 0.579363.
Train: 2018-08-01T01:28:24.238665: step 25363, loss 0.613247.
Train: 2018-08-01T01:28:24.394877: step 25364, loss 0.630159.
Train: 2018-08-01T01:28:24.551091: step 25365, loss 0.613169.
Train: 2018-08-01T01:28:24.722926: step 25366, loss 0.629973.
Train: 2018-08-01T01:28:24.863545: step 25367, loss 0.5456.
Train: 2018-08-01T01:28:25.019762: step 25368, loss 0.528826.
Train: 2018-08-01T01:28:25.175976: step 25369, loss 0.646427.
Train: 2018-08-01T01:28:25.332190: step 25370, loss 0.562468.
Test: 2018-08-01T01:28:25.800829: step 25370, loss 0.54847.
Train: 2018-08-01T01:28:25.957012: step 25371, loss 0.629391.
Train: 2018-08-01T01:28:26.113256: step 25372, loss 0.595867.
Train: 2018-08-01T01:28:26.269469: step 25373, loss 0.479282.
Train: 2018-08-01T01:28:26.441304: step 25374, loss 0.562516.
Train: 2018-08-01T01:28:26.597517: step 25375, loss 0.512688.
Train: 2018-08-01T01:28:26.769349: step 25376, loss 0.562519.
Train: 2018-08-01T01:28:26.925534: step 25377, loss 0.545898.
Train: 2018-08-01T01:28:27.081778: step 25378, loss 0.645655.
Train: 2018-08-01T01:28:27.237998: step 25379, loss 0.529311.
Train: 2018-08-01T01:28:27.394176: step 25380, loss 0.529323.
Test: 2018-08-01T01:28:27.847195: step 25380, loss 0.548614.
Train: 2018-08-01T01:28:28.019060: step 25381, loss 0.529305.
Train: 2018-08-01T01:28:28.159652: step 25382, loss 0.545892.
Train: 2018-08-01T01:28:28.331456: step 25383, loss 0.529224.
Train: 2018-08-01T01:28:28.487699: step 25384, loss 0.512515.
Train: 2018-08-01T01:28:28.643882: step 25385, loss 0.562491.
Train: 2018-08-01T01:28:28.784476: step 25386, loss 0.61269.
Train: 2018-08-01T01:28:28.940690: step 25387, loss 0.579227.
Train: 2018-08-01T01:28:29.112548: step 25388, loss 0.612788.
Train: 2018-08-01T01:28:29.268767: step 25389, loss 0.478568.
Train: 2018-08-01T01:28:29.424981: step 25390, loss 0.579259.
Test: 2018-08-01T01:28:29.909243: step 25390, loss 0.548366.
Train: 2018-08-01T01:28:30.065426: step 25391, loss 0.51199.
Train: 2018-08-01T01:28:30.221668: step 25392, loss 0.596141.
Train: 2018-08-01T01:28:30.393472: step 25393, loss 0.64678.
Train: 2018-08-01T01:28:30.549687: step 25394, loss 0.545573.
Train: 2018-08-01T01:28:30.705931: step 25395, loss 0.511826.
Train: 2018-08-01T01:28:30.862112: step 25396, loss 0.494888.
Train: 2018-08-01T01:28:31.018356: step 25397, loss 0.61318.
Train: 2018-08-01T01:28:31.205783: step 25398, loss 0.562428.
Train: 2018-08-01T01:28:31.346375: step 25399, loss 0.545477.
Train: 2018-08-01T01:28:31.518210: step 25400, loss 0.528489.
Test: 2018-08-01T01:28:31.986880: step 25400, loss 0.548191.
Train: 2018-08-01T01:28:32.705431: step 25401, loss 0.613386.
Train: 2018-08-01T01:28:32.861645: step 25402, loss 0.613417.
Train: 2018-08-01T01:28:33.017858: step 25403, loss 0.528416.
Train: 2018-08-01T01:28:33.174072: step 25404, loss 0.528401.
Train: 2018-08-01T01:28:33.330316: step 25405, loss 0.596456.
Train: 2018-08-01T01:28:33.502144: step 25406, loss 0.562412.
Train: 2018-08-01T01:28:33.658365: step 25407, loss 0.511313.
Train: 2018-08-01T01:28:33.814590: step 25408, loss 0.545359.
Train: 2018-08-01T01:28:33.955139: step 25409, loss 0.511189.
Train: 2018-08-01T01:28:34.127004: step 25410, loss 0.596631.
Test: 2018-08-01T01:28:34.595643: step 25410, loss 0.548056.
Train: 2018-08-01T01:28:34.751827: step 25411, loss 0.442448.
Train: 2018-08-01T01:28:34.908041: step 25412, loss 0.562554.
Train: 2018-08-01T01:28:35.064279: step 25413, loss 0.475822.
Train: 2018-08-01T01:28:35.220467: step 25414, loss 0.528259.
Train: 2018-08-01T01:28:35.376706: step 25415, loss 0.474282.
Train: 2018-08-01T01:28:35.532934: step 25416, loss 0.721605.
Train: 2018-08-01T01:28:35.704729: step 25417, loss 0.543007.
Train: 2018-08-01T01:28:35.860973: step 25418, loss 0.493607.
Train: 2018-08-01T01:28:36.017188: step 25419, loss 0.618289.
Train: 2018-08-01T01:28:36.173395: step 25420, loss 0.526915.
Test: 2018-08-01T01:28:36.642041: step 25420, loss 0.547675.
Train: 2018-08-01T01:28:36.813869: step 25421, loss 0.471957.
Train: 2018-08-01T01:28:36.970088: step 25422, loss 0.52827.
Train: 2018-08-01T01:28:37.126302: step 25423, loss 0.51019.
Train: 2018-08-01T01:28:37.282516: step 25424, loss 0.472746.
Train: 2018-08-01T01:28:37.438729: step 25425, loss 0.600671.
Train: 2018-08-01T01:28:37.594941: step 25426, loss 0.599017.
Train: 2018-08-01T01:28:37.766748: step 25427, loss 0.581307.
Train: 2018-08-01T01:28:37.922985: step 25428, loss 0.473611.
Train: 2018-08-01T01:28:38.079204: step 25429, loss 0.4556.
Train: 2018-08-01T01:28:38.235387: step 25430, loss 0.634283.
Test: 2018-08-01T01:28:38.688435: step 25430, loss 0.547619.
Train: 2018-08-01T01:28:38.860240: step 25431, loss 0.725062.
Train: 2018-08-01T01:28:39.016455: step 25432, loss 0.473231.
Train: 2018-08-01T01:28:39.172698: step 25433, loss 0.473076.
Train: 2018-08-01T01:28:39.328905: step 25434, loss 0.491069.
Train: 2018-08-01T01:28:39.485095: step 25435, loss 0.670144.
Train: 2018-08-01T01:28:39.641338: step 25436, loss 0.473032.
Train: 2018-08-01T01:28:39.797522: step 25437, loss 0.634345.
Train: 2018-08-01T01:28:39.969356: step 25438, loss 0.652286.
Train: 2018-08-01T01:28:40.125568: step 25439, loss 0.580539.
Train: 2018-08-01T01:28:40.281782: step 25440, loss 0.491059.
Test: 2018-08-01T01:28:40.766044: step 25440, loss 0.547637.
Train: 2018-08-01T01:28:40.922289: step 25441, loss 0.669877.
Train: 2018-08-01T01:28:41.094100: step 25442, loss 0.544749.
Train: 2018-08-01T01:28:41.234685: step 25443, loss 0.544756.
Train: 2018-08-01T01:28:41.406543: step 25444, loss 0.526953.
Train: 2018-08-01T01:28:41.547142: step 25445, loss 0.562538.
Train: 2018-08-01T01:28:41.718946: step 25446, loss 0.598115.
Train: 2018-08-01T01:28:41.890806: step 25447, loss 0.544796.
Train: 2018-08-01T01:28:42.047030: step 25448, loss 0.615703.
Train: 2018-08-01T01:28:42.203239: step 25449, loss 0.527076.
Train: 2018-08-01T01:28:42.359451: step 25450, loss 0.597741.
Test: 2018-08-01T01:28:42.828061: step 25450, loss 0.547727.
Train: 2018-08-01T01:28:42.984304: step 25451, loss 0.597756.
Train: 2018-08-01T01:28:43.140489: step 25452, loss 0.474126.
Train: 2018-08-01T01:28:43.312353: step 25453, loss 0.492663.
Train: 2018-08-01T01:28:43.468561: step 25454, loss 0.509231.
Train: 2018-08-01T01:28:43.624776: step 25455, loss 0.527688.
Train: 2018-08-01T01:28:43.780994: step 25456, loss 0.527931.
Train: 2018-08-01T01:28:43.937201: step 25457, loss 0.615443.
Train: 2018-08-01T01:28:44.093420: step 25458, loss 0.474447.
Train: 2018-08-01T01:28:44.249639: step 25459, loss 0.562551.
Train: 2018-08-01T01:28:44.421439: step 25460, loss 0.562491.
Test: 2018-08-01T01:28:44.890108: step 25460, loss 0.547673.
Train: 2018-08-01T01:28:45.046323: step 25461, loss 0.473449.
Train: 2018-08-01T01:28:45.202506: step 25462, loss 0.491118.
Train: 2018-08-01T01:28:45.358719: step 25463, loss 0.527194.
Train: 2018-08-01T01:28:45.514970: step 25464, loss 0.544599.
Train: 2018-08-01T01:28:45.686797: step 25465, loss 0.635256.
Train: 2018-08-01T01:28:45.843004: step 25466, loss 0.490924.
Train: 2018-08-01T01:28:45.999224: step 25467, loss 0.508681.
Train: 2018-08-01T01:28:46.155439: step 25468, loss 0.527179.
Train: 2018-08-01T01:28:46.311651: step 25469, loss 0.525845.
Train: 2018-08-01T01:28:46.467864: step 25470, loss 0.435508.
Test: 2018-08-01T01:28:46.936504: step 25470, loss 0.547588.
Train: 2018-08-01T01:28:47.092713: step 25471, loss 0.489617.
Train: 2018-08-01T01:28:47.264522: step 25472, loss 0.54547.
Train: 2018-08-01T01:28:47.420761: step 25473, loss 0.637334.
Train: 2018-08-01T01:28:47.576949: step 25474, loss 0.582208.
Train: 2018-08-01T01:28:47.764433: step 25475, loss 0.45196.
Train: 2018-08-01T01:28:47.920620: step 25476, loss 0.61665.
Train: 2018-08-01T01:28:48.061240: step 25477, loss 0.507293.
Train: 2018-08-01T01:28:48.217453: step 25478, loss 0.58323.
Train: 2018-08-01T01:28:48.373638: step 25479, loss 0.543761.
Train: 2018-08-01T01:28:48.529882: step 25480, loss 0.619535.
Test: 2018-08-01T01:28:49.014143: step 25480, loss 0.547622.
Train: 2018-08-01T01:28:49.170357: step 25481, loss 0.63748.
Train: 2018-08-01T01:28:49.326570: step 25482, loss 0.526644.
Train: 2018-08-01T01:28:49.482783: step 25483, loss 0.618349.
Train: 2018-08-01T01:28:49.638991: step 25484, loss 0.434508.
Train: 2018-08-01T01:28:49.795181: step 25485, loss 0.654849.
Train: 2018-08-01T01:28:49.967047: step 25486, loss 0.563291.
Train: 2018-08-01T01:28:50.107636: step 25487, loss 0.562653.
Train: 2018-08-01T01:28:50.263821: step 25488, loss 0.526007.
Train: 2018-08-01T01:28:50.420064: step 25489, loss 0.508225.
Train: 2018-08-01T01:28:50.576280: step 25490, loss 0.599187.
Test: 2018-08-01T01:28:51.044918: step 25490, loss 0.547586.
Train: 2018-08-01T01:28:51.216722: step 25491, loss 0.526516.
Train: 2018-08-01T01:28:51.372935: step 25492, loss 0.580931.
Train: 2018-08-01T01:28:51.529180: step 25493, loss 0.617297.
Train: 2018-08-01T01:28:51.685393: step 25494, loss 0.635273.
Train: 2018-08-01T01:28:51.841606: step 25495, loss 0.635035.
Train: 2018-08-01T01:28:51.997816: step 25496, loss 0.652694.
Train: 2018-08-01T01:28:52.169661: step 25497, loss 0.454986.
Train: 2018-08-01T01:28:52.310215: step 25498, loss 0.508858.
Train: 2018-08-01T01:28:52.482081: step 25499, loss 0.562646.
Train: 2018-08-01T01:28:52.638294: step 25500, loss 0.54469.
Test: 2018-08-01T01:28:53.106934: step 25500, loss 0.547659.
Train: 2018-08-01T01:28:53.825516: step 25501, loss 0.580372.
Train: 2018-08-01T01:28:53.966108: step 25502, loss 0.526985.
Train: 2018-08-01T01:28:54.122321: step 25503, loss 0.544725.
Train: 2018-08-01T01:28:54.294126: step 25504, loss 0.562504.
Train: 2018-08-01T01:28:54.450365: step 25505, loss 0.580312.
Train: 2018-08-01T01:28:54.622174: step 25506, loss 0.59796.
Train: 2018-08-01T01:28:54.778419: step 25507, loss 0.562468.
Train: 2018-08-01T01:28:54.934631: step 25508, loss 0.54492.
Train: 2018-08-01T01:28:55.090814: step 25509, loss 0.491899.
Train: 2018-08-01T01:28:55.247028: step 25510, loss 0.650605.
Test: 2018-08-01T01:28:55.731320: step 25510, loss 0.547739.
Train: 2018-08-01T01:28:55.887503: step 25511, loss 0.491986.
Train: 2018-08-01T01:28:56.043716: step 25512, loss 0.668093.
Train: 2018-08-01T01:28:56.199961: step 25513, loss 0.580081.
Train: 2018-08-01T01:28:56.371795: step 25514, loss 0.457297.
Train: 2018-08-01T01:28:56.528010: step 25515, loss 0.562705.
Train: 2018-08-01T01:28:56.684192: step 25516, loss 0.545006.
Train: 2018-08-01T01:28:56.840435: step 25517, loss 0.527431.
Train: 2018-08-01T01:28:56.996650: step 25518, loss 0.562529.
Train: 2018-08-01T01:28:57.168452: step 25519, loss 0.527302.
Train: 2018-08-01T01:28:57.324696: step 25520, loss 0.562463.
Test: 2018-08-01T01:28:57.808957: step 25520, loss 0.547782.
Train: 2018-08-01T01:28:57.980793: step 25521, loss 0.580008.
Train: 2018-08-01T01:28:58.137007: step 25522, loss 0.544882.
Train: 2018-08-01T01:28:58.308835: step 25523, loss 0.457118.
Train: 2018-08-01T01:28:58.465054: step 25524, loss 0.562373.
Train: 2018-08-01T01:28:58.636887: step 25525, loss 0.597552.
Train: 2018-08-01T01:28:58.777477: step 25526, loss 0.615255.
Train: 2018-08-01T01:28:58.933689: step 25527, loss 0.544902.
Train: 2018-08-01T01:28:59.089908: step 25528, loss 0.527356.
Train: 2018-08-01T01:28:59.246091: step 25529, loss 0.650357.
Train: 2018-08-01T01:28:59.402304: step 25530, loss 0.580165.
Test: 2018-08-01T01:28:59.886597: step 25530, loss 0.547758.
Train: 2018-08-01T01:29:00.042811: step 25531, loss 0.632544.
Train: 2018-08-01T01:29:00.199023: step 25532, loss 0.562342.
Train: 2018-08-01T01:29:00.355237: step 25533, loss 0.509822.
Train: 2018-08-01T01:29:00.511421: step 25534, loss 0.544648.
Train: 2018-08-01T01:29:00.667664: step 25535, loss 0.562447.
Train: 2018-08-01T01:29:00.839468: step 25536, loss 0.579257.
Train: 2018-08-01T01:29:00.980091: step 25537, loss 0.527742.
Train: 2018-08-01T01:29:01.151927: step 25538, loss 0.632675.
Train: 2018-08-01T01:29:01.308138: step 25539, loss 0.632078.
Train: 2018-08-01T01:29:01.464359: step 25540, loss 0.510261.
Test: 2018-08-01T01:29:01.932962: step 25540, loss 0.547831.
Train: 2018-08-01T01:29:02.089206: step 25541, loss 0.492586.
Train: 2018-08-01T01:29:02.245388: step 25542, loss 0.597822.
Train: 2018-08-01T01:29:02.386012: step 25543, loss 0.597739.
Train: 2018-08-01T01:29:02.557846: step 25544, loss 0.631482.
Train: 2018-08-01T01:29:02.714029: step 25545, loss 0.631837.
Train: 2018-08-01T01:29:02.870242: step 25546, loss 0.458661.
Train: 2018-08-01T01:29:03.026456: step 25547, loss 0.544976.
Train: 2018-08-01T01:29:03.182670: step 25548, loss 0.598742.
Train: 2018-08-01T01:29:03.354535: step 25549, loss 0.493962.
Train: 2018-08-01T01:29:03.510744: step 25550, loss 0.683286.
Test: 2018-08-01T01:29:03.979389: step 25550, loss 0.548037.
Train: 2018-08-01T01:29:04.151194: step 25551, loss 0.631044.
Train: 2018-08-01T01:29:04.307432: step 25552, loss 0.579199.
Train: 2018-08-01T01:29:04.463619: step 25553, loss 0.545438.
Train: 2018-08-01T01:29:04.619834: step 25554, loss 0.494328.
Train: 2018-08-01T01:29:04.776047: step 25555, loss 0.562492.
Train: 2018-08-01T01:29:04.947881: step 25556, loss 0.511438.
Train: 2018-08-01T01:29:05.104123: step 25557, loss 0.528439.
Train: 2018-08-01T01:29:05.275961: step 25558, loss 0.579401.
Train: 2018-08-01T01:29:05.432173: step 25559, loss 0.545413.
Train: 2018-08-01T01:29:05.588386: step 25560, loss 0.579408.
Test: 2018-08-01T01:29:06.057026: step 25560, loss 0.548131.
Train: 2018-08-01T01:29:06.228850: step 25561, loss 0.562726.
Train: 2018-08-01T01:29:06.385045: step 25562, loss 0.613507.
Train: 2018-08-01T01:29:06.541258: step 25563, loss 0.562455.
Train: 2018-08-01T01:29:06.697502: step 25564, loss 0.579393.
Train: 2018-08-01T01:29:06.853685: step 25565, loss 0.528449.
Train: 2018-08-01T01:29:07.025519: step 25566, loss 0.613382.
Train: 2018-08-01T01:29:07.181764: step 25567, loss 0.52847.
Train: 2018-08-01T01:29:07.337947: step 25568, loss 0.596373.
Train: 2018-08-01T01:29:07.494191: step 25569, loss 0.613324.
Train: 2018-08-01T01:29:07.650405: step 25570, loss 0.477686.
Test: 2018-08-01T01:29:08.119043: step 25570, loss 0.548234.
Train: 2018-08-01T01:29:08.275227: step 25571, loss 0.630232.
Train: 2018-08-01T01:29:08.447063: step 25572, loss 0.56243.
Train: 2018-08-01T01:29:08.603275: step 25573, loss 0.528573.
Train: 2018-08-01T01:29:08.759520: step 25574, loss 0.613219.
Train: 2018-08-01T01:29:08.915733: step 25575, loss 0.647022.
Train: 2018-08-01T01:29:09.071946: step 25576, loss 0.629999.
Train: 2018-08-01T01:29:09.228159: step 25577, loss 0.613002.
Train: 2018-08-01T01:29:09.384343: step 25578, loss 0.579267.
Train: 2018-08-01T01:29:09.571828: step 25579, loss 0.478664.
Train: 2018-08-01T01:29:09.728012: step 25580, loss 0.595965.
Test: 2018-08-01T01:29:10.196652: step 25580, loss 0.548488.
Train: 2018-08-01T01:29:10.352895: step 25581, loss 0.629363.
Train: 2018-08-01T01:29:10.509103: step 25582, loss 0.462398.
Train: 2018-08-01T01:29:10.680938: step 25583, loss 0.645883.
Train: 2018-08-01T01:29:10.821505: step 25584, loss 0.479254.
Train: 2018-08-01T01:29:10.993371: step 25585, loss 0.544754.
Train: 2018-08-01T01:29:11.149586: step 25586, loss 0.445938.
Train: 2018-08-01T01:29:11.305798: step 25587, loss 0.612552.
Train: 2018-08-01T01:29:11.462011: step 25588, loss 0.51239.
Train: 2018-08-01T01:29:11.618225: step 25589, loss 0.545755.
Train: 2018-08-01T01:29:11.790060: step 25590, loss 0.562474.
Test: 2018-08-01T01:29:12.258669: step 25590, loss 0.548408.
Train: 2018-08-01T01:29:12.414913: step 25591, loss 0.545678.
Train: 2018-08-01T01:29:12.571126: step 25592, loss 0.528821.
Train: 2018-08-01T01:29:12.727345: step 25593, loss 0.545595.
Train: 2018-08-01T01:29:12.899181: step 25594, loss 0.562441.
Train: 2018-08-01T01:29:13.071010: step 25595, loss 0.494737.
Train: 2018-08-01T01:29:13.227224: step 25596, loss 0.579396.
Train: 2018-08-01T01:29:13.383430: step 25597, loss 0.613445.
Train: 2018-08-01T01:29:13.524022: step 25598, loss 0.562419.
Train: 2018-08-01T01:29:13.695863: step 25599, loss 0.630629.
Train: 2018-08-01T01:29:13.852076: step 25600, loss 0.477127.
Test: 2018-08-01T01:29:14.305089: step 25600, loss 0.548111.
Train: 2018-08-01T01:29:15.054889: step 25601, loss 0.494091.
Train: 2018-08-01T01:29:15.195511: step 25602, loss 0.63088.
Train: 2018-08-01T01:29:15.367341: step 25603, loss 0.699487.
Train: 2018-08-01T01:29:15.523529: step 25604, loss 0.613775.
Train: 2018-08-01T01:29:15.679743: step 25605, loss 0.494022.
Train: 2018-08-01T01:29:15.835956: step 25606, loss 0.545322.
Train: 2018-08-01T01:29:15.992170: step 25607, loss 0.476961.
Train: 2018-08-01T01:29:16.148384: step 25608, loss 0.562413.
Train: 2018-08-01T01:29:16.304621: step 25609, loss 0.476796.
Train: 2018-08-01T01:29:16.476432: step 25610, loss 0.562411.
Test: 2018-08-01T01:29:16.945101: step 25610, loss 0.548021.
Train: 2018-08-01T01:29:17.101315: step 25611, loss 0.579597.
Train: 2018-08-01T01:29:17.273120: step 25612, loss 0.596827.
Train: 2018-08-01T01:29:17.413737: step 25613, loss 0.510751.
Train: 2018-08-01T01:29:17.585571: step 25614, loss 0.579657.
Train: 2018-08-01T01:29:17.741790: step 25615, loss 0.579674.
Train: 2018-08-01T01:29:17.897974: step 25616, loss 0.458797.
Train: 2018-08-01T01:29:18.054188: step 25617, loss 0.597021.
Train: 2018-08-01T01:29:18.210431: step 25618, loss 0.649028.
Train: 2018-08-01T01:29:18.382266: step 25619, loss 0.475815.
Train: 2018-08-01T01:29:18.538479: step 25620, loss 0.47573.
Test: 2018-08-01T01:29:19.007089: step 25620, loss 0.547881.
Train: 2018-08-01T01:29:19.178949: step 25621, loss 0.597172.
Train: 2018-08-01T01:29:19.319546: step 25622, loss 0.59722.
Train: 2018-08-01T01:29:19.491350: step 25623, loss 0.562434.
Train: 2018-08-01T01:29:19.647564: step 25624, loss 0.527603.
Train: 2018-08-01T01:29:19.803808: step 25625, loss 0.579871.
Train: 2018-08-01T01:29:19.960022: step 25626, loss 0.614767.
Train: 2018-08-01T01:29:20.116204: step 25627, loss 0.667073.
Train: 2018-08-01T01:29:20.272445: step 25628, loss 0.562435.
Train: 2018-08-01T01:29:20.428661: step 25629, loss 0.614599.
Train: 2018-08-01T01:29:20.600496: step 25630, loss 0.614494.
Test: 2018-08-01T01:29:21.084759: step 25630, loss 0.547919.
Train: 2018-08-01T01:29:21.240971: step 25631, loss 0.700941.
Train: 2018-08-01T01:29:21.412776: step 25632, loss 0.631406.
Train: 2018-08-01T01:29:21.569014: step 25633, loss 0.528062.
Train: 2018-08-01T01:29:21.740849: step 25634, loss 0.545296.
Train: 2018-08-01T01:29:21.897069: step 25635, loss 0.545349.
Train: 2018-08-01T01:29:22.053281: step 25636, loss 0.511353.
Train: 2018-08-01T01:29:22.209494: step 25637, loss 0.545423.
Train: 2018-08-01T01:29:22.365678: step 25638, loss 0.596372.
Train: 2018-08-01T01:29:22.521922: step 25639, loss 0.579376.
Train: 2018-08-01T01:29:22.678134: step 25640, loss 0.579355.
Test: 2018-08-01T01:29:23.146773: step 25640, loss 0.54828.
Train: 2018-08-01T01:29:23.318609: step 25641, loss 0.545532.
Train: 2018-08-01T01:29:23.474793: step 25642, loss 0.46114.
Train: 2018-08-01T01:29:23.631036: step 25643, loss 0.613102.
Train: 2018-08-01T01:29:23.787245: step 25644, loss 0.478015.
Train: 2018-08-01T01:29:23.943433: step 25645, loss 0.444139.
Train: 2018-08-01T01:29:24.115292: step 25646, loss 0.630181.
Train: 2018-08-01T01:29:24.271518: step 25647, loss 0.579383.
Train: 2018-08-01T01:29:24.427725: step 25648, loss 0.477534.
Train: 2018-08-01T01:29:24.583938: step 25649, loss 0.545405.
Train: 2018-08-01T01:29:24.740152: step 25650, loss 0.698773.
Test: 2018-08-01T01:29:25.208791: step 25650, loss 0.548137.
Train: 2018-08-01T01:29:25.364999: step 25651, loss 0.443083.
Train: 2018-08-01T01:29:25.521220: step 25652, loss 0.613633.
Train: 2018-08-01T01:29:25.677401: step 25653, loss 0.562409.
Train: 2018-08-01T01:29:25.833646: step 25654, loss 0.613713.
Train: 2018-08-01T01:29:25.989859: step 25655, loss 0.545306.
Train: 2018-08-01T01:29:26.161694: step 25656, loss 0.528194.
Train: 2018-08-01T01:29:26.317907: step 25657, loss 0.493933.
Train: 2018-08-01T01:29:26.474121: step 25658, loss 0.648125.
Train: 2018-08-01T01:29:26.630303: step 25659, loss 0.528111.
Train: 2018-08-01T01:29:26.786548: step 25660, loss 0.579566.
Test: 2018-08-01T01:29:27.255158: step 25660, loss 0.548032.
Train: 2018-08-01T01:29:27.426992: step 25661, loss 0.579572.
Train: 2018-08-01T01:29:27.583230: step 25662, loss 0.562406.
Train: 2018-08-01T01:29:27.739419: step 25663, loss 0.562406.
Train: 2018-08-01T01:29:27.895632: step 25664, loss 0.596749.
Train: 2018-08-01T01:29:28.051846: step 25665, loss 0.562406.
Train: 2018-08-01T01:29:28.208095: step 25666, loss 0.665367.
Train: 2018-08-01T01:29:28.364303: step 25667, loss 0.665207.
Train: 2018-08-01T01:29:28.536107: step 25668, loss 0.511145.
Train: 2018-08-01T01:29:28.692351: step 25669, loss 0.545352.
Train: 2018-08-01T01:29:28.848534: step 25670, loss 0.613514.
Test: 2018-08-01T01:29:29.332827: step 25670, loss 0.548177.
Train: 2018-08-01T01:29:29.489045: step 25671, loss 0.494405.
Train: 2018-08-01T01:29:29.645254: step 25672, loss 0.545427.
Train: 2018-08-01T01:29:29.801467: step 25673, loss 0.59638.
Train: 2018-08-01T01:29:29.957680: step 25674, loss 0.579387.
Train: 2018-08-01T01:29:30.113893: step 25675, loss 0.596325.
Train: 2018-08-01T01:29:30.285729: step 25676, loss 0.562425.
Train: 2018-08-01T01:29:30.441912: step 25677, loss 0.731557.
Train: 2018-08-01T01:29:30.598149: step 25678, loss 0.613021.
Train: 2018-08-01T01:29:30.754339: step 25679, loss 0.461631.
Train: 2018-08-01T01:29:30.926173: step 25680, loss 0.545686.
Test: 2018-08-01T01:29:31.394844: step 25680, loss 0.548438.
Train: 2018-08-01T01:29:31.551051: step 25681, loss 0.612731.
Train: 2018-08-01T01:29:31.722860: step 25682, loss 0.529025.
Train: 2018-08-01T01:29:31.879112: step 25683, loss 0.529065.
Train: 2018-08-01T01:29:32.035312: step 25684, loss 0.478975.
Train: 2018-08-01T01:29:32.191531: step 25685, loss 0.595911.
Train: 2018-08-01T01:29:32.347745: step 25686, loss 0.579199.
Train: 2018-08-01T01:29:32.503959: step 25687, loss 0.428684.
Train: 2018-08-01T01:29:32.675763: step 25688, loss 0.612738.
Train: 2018-08-01T01:29:32.831977: step 25689, loss 0.495352.
Train: 2018-08-01T01:29:32.972570: step 25690, loss 0.612883.
Test: 2018-08-01T01:29:33.456830: step 25690, loss 0.548352.
Train: 2018-08-01T01:29:33.613044: step 25691, loss 0.528784.
Train: 2018-08-01T01:29:33.784904: step 25692, loss 0.663584.
Train: 2018-08-01T01:29:33.941092: step 25693, loss 0.562438.
Train: 2018-08-01T01:29:34.097306: step 25694, loss 0.629892.
Train: 2018-08-01T01:29:34.253549: step 25695, loss 0.629851.
Train: 2018-08-01T01:29:34.409731: step 25696, loss 0.562446.
Train: 2018-08-01T01:29:34.565976: step 25697, loss 0.512023.
Train: 2018-08-01T01:29:34.722159: step 25698, loss 0.444832.
Train: 2018-08-01T01:29:34.893994: step 25699, loss 0.478328.
Train: 2018-08-01T01:29:35.050243: step 25700, loss 0.444405.
Test: 2018-08-01T01:29:35.534493: step 25700, loss 0.548255.
Train: 2018-08-01T01:29:36.268703: step 25701, loss 0.545503.
Train: 2018-08-01T01:29:36.424885: step 25702, loss 0.562416.
Train: 2018-08-01T01:29:36.581123: step 25703, loss 0.681648.
Train: 2018-08-01T01:29:36.737336: step 25704, loss 0.613578.
Train: 2018-08-01T01:29:36.893557: step 25705, loss 0.425873.
Train: 2018-08-01T01:29:37.065384: step 25706, loss 0.5453.
Train: 2018-08-01T01:29:37.237195: step 25707, loss 0.562404.
Train: 2018-08-01T01:29:37.393440: step 25708, loss 0.528049.
Train: 2018-08-01T01:29:37.549647: step 25709, loss 0.54519.
Train: 2018-08-01T01:29:37.721486: step 25710, loss 0.510647.
Test: 2018-08-01T01:29:38.190095: step 25710, loss 0.547926.
Train: 2018-08-01T01:29:38.346335: step 25711, loss 0.579709.
Train: 2018-08-01T01:29:38.502523: step 25712, loss 0.57975.
Train: 2018-08-01T01:29:38.658764: step 25713, loss 0.70132.
Train: 2018-08-01T01:29:38.814951: step 25714, loss 0.545061.
Train: 2018-08-01T01:29:38.971190: step 25715, loss 0.579777.
Train: 2018-08-01T01:29:39.143026: step 25716, loss 0.475652.
Train: 2018-08-01T01:29:39.314833: step 25717, loss 0.527687.
Train: 2018-08-01T01:29:39.471077: step 25718, loss 0.510267.
Train: 2018-08-01T01:29:39.642914: step 25719, loss 0.492779.
Train: 2018-08-01T01:29:39.799125: step 25720, loss 0.649689.
Test: 2018-08-01T01:29:40.267762: step 25720, loss 0.547814.
Train: 2018-08-01T01:29:40.439570: step 25721, loss 0.544974.
Train: 2018-08-01T01:29:40.595783: step 25722, loss 0.544961.
Train: 2018-08-01T01:29:40.751996: step 25723, loss 0.492447.
Train: 2018-08-01T01:29:40.908210: step 25724, loss 0.579986.
Train: 2018-08-01T01:29:41.080045: step 25725, loss 0.650221.
Train: 2018-08-01T01:29:41.236259: step 25726, loss 0.527359.
Train: 2018-08-01T01:29:41.392484: step 25727, loss 0.527347.
Train: 2018-08-01T01:29:41.548715: step 25728, loss 0.562469.
Train: 2018-08-01T01:29:41.704899: step 25729, loss 0.49215.
Train: 2018-08-01T01:29:41.861112: step 25730, loss 0.562479.
Test: 2018-08-01T01:29:42.345404: step 25730, loss 0.54773.
Train: 2018-08-01T01:29:42.501587: step 25731, loss 0.615349.
Train: 2018-08-01T01:29:42.657826: step 25732, loss 0.562487.
Train: 2018-08-01T01:29:42.814045: step 25733, loss 0.650632.
Train: 2018-08-01T01:29:42.970228: step 25734, loss 0.492035.
Train: 2018-08-01T01:29:43.126441: step 25735, loss 0.509652.
Train: 2018-08-01T01:29:43.282678: step 25736, loss 0.527249.
Train: 2018-08-01T01:29:43.438903: step 25737, loss 0.685904.
Train: 2018-08-01T01:29:43.641976: step 25738, loss 0.509636.
Train: 2018-08-01T01:29:43.798189: step 25739, loss 0.562482.
Train: 2018-08-01T01:29:43.954402: step 25740, loss 0.597695.
Test: 2018-08-01T01:29:44.423012: step 25740, loss 0.547742.
Train: 2018-08-01T01:29:44.579256: step 25741, loss 0.597665.
Train: 2018-08-01T01:29:44.751060: step 25742, loss 0.632767.
Train: 2018-08-01T01:29:44.907305: step 25743, loss 0.492296.
Train: 2018-08-01T01:29:45.063517: step 25744, loss 0.63255.
Train: 2018-08-01T01:29:45.235322: step 25745, loss 0.614926.
Train: 2018-08-01T01:29:45.391567: step 25746, loss 0.527529.
Train: 2018-08-01T01:29:45.547773: step 25747, loss 0.52758.
Train: 2018-08-01T01:29:45.688371: step 25748, loss 0.527616.
Train: 2018-08-01T01:29:45.860201: step 25749, loss 0.632.
Train: 2018-08-01T01:29:46.016389: step 25750, loss 0.545051.
Test: 2018-08-01T01:29:46.485028: step 25750, loss 0.547889.
Train: 2018-08-01T01:29:46.656888: step 25751, loss 0.458322.
Train: 2018-08-01T01:29:46.797456: step 25752, loss 0.493006.
Train: 2018-08-01T01:29:46.984912: step 25753, loss 0.52768.
Train: 2018-08-01T01:29:47.141125: step 25754, loss 0.597208.
Train: 2018-08-01T01:29:47.297339: step 25755, loss 0.492809.
Train: 2018-08-01T01:29:47.453583: step 25756, loss 0.510144.
Train: 2018-08-01T01:29:47.609796: step 25757, loss 0.527515.
Train: 2018-08-01T01:29:47.781600: step 25758, loss 0.59744.
Train: 2018-08-01T01:29:47.922223: step 25759, loss 0.615015.
Train: 2018-08-01T01:29:48.109684: step 25760, loss 0.509865.
Test: 2018-08-01T01:29:48.578319: step 25760, loss 0.547766.
Train: 2018-08-01T01:29:48.734533: step 25761, loss 0.650204.
Train: 2018-08-01T01:29:48.890747: step 25762, loss 0.632643.
Train: 2018-08-01T01:29:49.062576: step 25763, loss 0.457288.
Train: 2018-08-01T01:29:49.234385: step 25764, loss 0.650118.
Train: 2018-08-01T01:29:49.390630: step 25765, loss 0.492383.
Train: 2018-08-01T01:29:49.531222: step 25766, loss 0.650037.
Train: 2018-08-01T01:29:49.687405: step 25767, loss 0.52745.
Train: 2018-08-01T01:29:49.843643: step 25768, loss 0.614904.
Train: 2018-08-01T01:29:50.015453: step 25769, loss 0.562438.
Train: 2018-08-01T01:29:50.171695: step 25770, loss 0.492654.
Test: 2018-08-01T01:29:50.640305: step 25770, loss 0.547828.
Train: 2018-08-01T01:29:50.796550: step 25771, loss 0.597313.
Train: 2018-08-01T01:29:50.952763: step 25772, loss 0.597286.
Train: 2018-08-01T01:29:51.108947: step 25773, loss 0.457972.
Train: 2018-08-01T01:29:51.265192: step 25774, loss 0.510188.
Train: 2018-08-01T01:29:51.436994: step 25775, loss 0.492723.
Train: 2018-08-01T01:29:51.577586: step 25776, loss 0.597341.
Train: 2018-08-01T01:29:51.733830: step 25777, loss 0.457629.
Train: 2018-08-01T01:29:51.890014: step 25778, loss 0.509938.
Train: 2018-08-01T01:29:52.061849: step 25779, loss 0.562459.
Train: 2018-08-01T01:29:52.218062: step 25780, loss 0.703114.
Test: 2018-08-01T01:29:52.686732: step 25780, loss 0.547747.
Train: 2018-08-01T01:29:52.842915: step 25781, loss 0.562471.
Train: 2018-08-01T01:29:52.999158: step 25782, loss 0.474553.
Train: 2018-08-01T01:29:53.155373: step 25783, loss 0.439268.
Train: 2018-08-01T01:29:53.311586: step 25784, loss 0.668339.
Train: 2018-08-01T01:29:53.467771: step 25785, loss 0.650767.
Train: 2018-08-01T01:29:53.639603: step 25786, loss 0.615432.
Train: 2018-08-01T01:29:53.795818: step 25787, loss 0.491977.
Train: 2018-08-01T01:29:53.952061: step 25788, loss 0.685846.
Train: 2018-08-01T01:29:54.108245: step 25789, loss 0.439324.
Train: 2018-08-01T01:29:54.280078: step 25790, loss 0.492114.
Test: 2018-08-01T01:29:54.748718: step 25790, loss 0.547738.
Train: 2018-08-01T01:29:54.904932: step 25791, loss 0.650477.
Train: 2018-08-01T01:29:55.076767: step 25792, loss 0.597653.
Train: 2018-08-01T01:29:55.233005: step 25793, loss 0.597613.
Train: 2018-08-01T01:29:55.389195: step 25794, loss 0.597558.
Train: 2018-08-01T01:29:55.545437: step 25795, loss 0.422298.
Train: 2018-08-01T01:29:55.701621: step 25796, loss 0.527411.
Train: 2018-08-01T01:29:55.869349: step 25797, loss 0.562454.
Train: 2018-08-01T01:29:56.025592: step 25798, loss 0.509857.
Train: 2018-08-01T01:29:56.181775: step 25799, loss 0.562459.
Train: 2018-08-01T01:29:56.337989: step 25800, loss 0.580022.
Test: 2018-08-01T01:29:56.806628: step 25800, loss 0.547756.
Train: 2018-08-01T01:29:57.587725: step 25801, loss 0.597596.
Train: 2018-08-01T01:29:57.743910: step 25802, loss 0.509776.
Train: 2018-08-01T01:29:57.915774: step 25803, loss 0.632745.
Train: 2018-08-01T01:29:58.071982: step 25804, loss 0.597585.
Train: 2018-08-01T01:29:58.228172: step 25805, loss 0.457193.
Train: 2018-08-01T01:29:58.400035: step 25806, loss 0.50981.
Train: 2018-08-01T01:29:58.556227: step 25807, loss 0.5449.
Train: 2018-08-01T01:29:58.712466: step 25808, loss 0.509728.
Train: 2018-08-01T01:29:58.868645: step 25809, loss 0.632895.
Train: 2018-08-01T01:29:59.040480: step 25810, loss 0.58009.
Test: 2018-08-01T01:29:59.509145: step 25810, loss 0.547733.
Train: 2018-08-01T01:29:59.665359: step 25811, loss 0.685755.
Train: 2018-08-01T01:29:59.837170: step 25812, loss 0.615225.
Train: 2018-08-01T01:29:59.993413: step 25813, loss 0.615108.
Train: 2018-08-01T01:30:00.165217: step 25814, loss 0.579953.
Train: 2018-08-01T01:30:00.321461: step 25815, loss 0.527513.
Train: 2018-08-01T01:30:00.477674: step 25816, loss 0.614714.
Train: 2018-08-01T01:30:00.633887: step 25817, loss 0.492873.
Train: 2018-08-01T01:30:00.790103: step 25818, loss 0.52769.
Train: 2018-08-01T01:30:00.946314: step 25819, loss 0.579764.
Train: 2018-08-01T01:30:01.102530: step 25820, loss 0.614407.
Test: 2018-08-01T01:30:01.571137: step 25820, loss 0.547918.
Train: 2018-08-01T01:30:01.742972: step 25821, loss 0.648933.
Train: 2018-08-01T01:30:01.899216: step 25822, loss 0.717765.
Train: 2018-08-01T01:30:02.055431: step 25823, loss 0.562401.
Train: 2018-08-01T01:30:02.211644: step 25824, loss 0.511018.
Train: 2018-08-01T01:30:02.383472: step 25825, loss 0.528241.
Train: 2018-08-01T01:30:02.539691: step 25826, loss 0.44308.
Train: 2018-08-01T01:30:02.695899: step 25827, loss 0.562406.
Train: 2018-08-01T01:30:02.852112: step 25828, loss 0.596478.
Train: 2018-08-01T01:30:03.008326: step 25829, loss 0.528357.
Train: 2018-08-01T01:30:03.164514: step 25830, loss 0.460272.
Test: 2018-08-01T01:30:03.633185: step 25830, loss 0.548134.
Train: 2018-08-01T01:30:03.789399: step 25831, loss 0.528321.
Train: 2018-08-01T01:30:03.945582: step 25832, loss 0.630673.
Train: 2018-08-01T01:30:04.101795: step 25833, loss 0.596555.
Train: 2018-08-01T01:30:04.258039: step 25834, loss 0.613633.
Train: 2018-08-01T01:30:04.414254: step 25835, loss 0.716006.
Train: 2018-08-01T01:30:04.586057: step 25836, loss 0.664563.
Train: 2018-08-01T01:30:04.742271: step 25837, loss 0.59635.
Train: 2018-08-01T01:30:04.898515: step 25838, loss 0.579333.
Train: 2018-08-01T01:30:05.054698: step 25839, loss 0.495021.
Train: 2018-08-01T01:30:05.210911: step 25840, loss 0.49517.
Test: 2018-08-01T01:30:05.695202: step 25840, loss 0.548378.
Train: 2018-08-01T01:30:05.867037: step 25841, loss 0.579251.
Train: 2018-08-01T01:30:06.023251: step 25842, loss 0.596023.
Train: 2018-08-01T01:30:06.179466: step 25843, loss 0.629514.
Train: 2018-08-01T01:30:06.335678: step 25844, loss 0.445355.
Train: 2018-08-01T01:30:06.491890: step 25845, loss 0.595926.
Train: 2018-08-01T01:30:06.663721: step 25846, loss 0.579193.
Train: 2018-08-01T01:30:06.819908: step 25847, loss 0.545769.
Train: 2018-08-01T01:30:06.976152: step 25848, loss 0.545775.
Train: 2018-08-01T01:30:07.132336: step 25849, loss 0.595888.
Train: 2018-08-01T01:30:07.288548: step 25850, loss 0.545781.
Test: 2018-08-01T01:30:07.772835: step 25850, loss 0.548497.
Train: 2018-08-01T01:30:07.913403: step 25851, loss 0.495682.
Train: 2018-08-01T01:30:08.069616: step 25852, loss 0.478898.
Train: 2018-08-01T01:30:08.210239: step 25853, loss 0.579213.
Train: 2018-08-01T01:30:08.382044: step 25854, loss 0.562456.
Train: 2018-08-01T01:30:08.538286: step 25855, loss 0.512041.
Train: 2018-08-01T01:30:08.694495: step 25856, loss 0.562439.
Train: 2018-08-01T01:30:08.866304: step 25857, loss 0.562432.
Train: 2018-08-01T01:30:09.022548: step 25858, loss 0.511726.
Train: 2018-08-01T01:30:09.178756: step 25859, loss 0.697925.
Train: 2018-08-01T01:30:09.334975: step 25860, loss 0.545472.
Test: 2018-08-01T01:30:09.819236: step 25860, loss 0.548218.
Train: 2018-08-01T01:30:09.991042: step 25861, loss 0.64719.
Train: 2018-08-01T01:30:10.147254: step 25862, loss 0.494631.
Train: 2018-08-01T01:30:10.303500: step 25863, loss 0.528508.
Train: 2018-08-01T01:30:10.459681: step 25864, loss 0.49454.
Train: 2018-08-01T01:30:10.631542: step 25865, loss 0.56241.
Train: 2018-08-01T01:30:10.787762: step 25866, loss 0.59645.
Train: 2018-08-01T01:30:10.943977: step 25867, loss 0.647594.
Train: 2018-08-01T01:30:11.115779: step 25868, loss 0.528336.
Train: 2018-08-01T01:30:11.271991: step 25869, loss 0.545365.
Train: 2018-08-01T01:30:11.428236: step 25870, loss 0.647643.
Test: 2018-08-01T01:30:11.881254: step 25870, loss 0.548138.
Train: 2018-08-01T01:30:12.053058: step 25871, loss 0.613517.
Train: 2018-08-01T01:30:12.209271: step 25872, loss 0.545389.
Train: 2018-08-01T01:30:12.365515: step 25873, loss 0.545405.
Train: 2018-08-01T01:30:12.537350: step 25874, loss 0.494427.
Train: 2018-08-01T01:30:12.693533: step 25875, loss 0.562409.
Train: 2018-08-01T01:30:12.849776: step 25876, loss 0.596428.
Train: 2018-08-01T01:30:12.990369: step 25877, loss 0.630445.
Train: 2018-08-01T01:30:13.146553: step 25878, loss 0.56241.
Train: 2018-08-01T01:30:13.318387: step 25879, loss 0.579394.
Train: 2018-08-01T01:30:13.474601: step 25880, loss 0.443637.
Test: 2018-08-01T01:30:13.943271: step 25880, loss 0.548192.
Train: 2018-08-01T01:30:14.099485: step 25881, loss 0.613354.
Train: 2018-08-01T01:30:14.271319: step 25882, loss 0.596375.
Train: 2018-08-01T01:30:14.443123: step 25883, loss 0.511483.
Train: 2018-08-01T01:30:14.599362: step 25884, loss 0.477499.
Train: 2018-08-01T01:30:14.755576: step 25885, loss 0.579415.
Train: 2018-08-01T01:30:14.911788: step 25886, loss 0.598726.
Train: 2018-08-01T01:30:15.068009: step 25887, loss 0.596474.
Train: 2018-08-01T01:30:15.224193: step 25888, loss 0.596477.
Train: 2018-08-01T01:30:15.380406: step 25889, loss 0.528345.
Train: 2018-08-01T01:30:15.552240: step 25890, loss 0.613504.
Test: 2018-08-01T01:30:16.036500: step 25890, loss 0.54815.
Train: 2018-08-01T01:30:16.192738: step 25891, loss 0.528357.
Train: 2018-08-01T01:30:16.348958: step 25892, loss 0.613481.
Train: 2018-08-01T01:30:16.536385: step 25893, loss 0.596437.
Train: 2018-08-01T01:30:16.692596: step 25894, loss 0.562409.
Train: 2018-08-01T01:30:16.848810: step 25895, loss 0.562411.
Train: 2018-08-01T01:30:17.005026: step 25896, loss 0.562412.
Train: 2018-08-01T01:30:17.161267: step 25897, loss 0.596339.
Train: 2018-08-01T01:30:17.317452: step 25898, loss 0.528524.
Train: 2018-08-01T01:30:17.489285: step 25899, loss 0.647116.
Train: 2018-08-01T01:30:17.645499: step 25900, loss 0.545505.
Test: 2018-08-01T01:30:18.129790: step 25900, loss 0.548273.
Train: 2018-08-01T01:30:18.832746: step 25901, loss 0.613123.
Train: 2018-08-01T01:30:19.004586: step 25902, loss 0.613053.
Train: 2018-08-01T01:30:19.160801: step 25903, loss 0.596121.
Train: 2018-08-01T01:30:19.316982: step 25904, loss 0.646475.
Train: 2018-08-01T01:30:19.473220: step 25905, loss 0.545705.
Train: 2018-08-01T01:30:19.629440: step 25906, loss 0.512324.
Train: 2018-08-01T01:30:19.785624: step 25907, loss 0.71272.
Train: 2018-08-01T01:30:19.957482: step 25908, loss 0.629065.
Train: 2018-08-01T01:30:20.113700: step 25909, loss 0.463044.
Train: 2018-08-01T01:30:20.269915: step 25910, loss 0.397044.
Test: 2018-08-01T01:30:20.738554: step 25910, loss 0.54867.
Train: 2018-08-01T01:30:20.910385: step 25911, loss 0.512858.
Train: 2018-08-01T01:30:21.066573: step 25912, loss 0.529365.
Train: 2018-08-01T01:30:21.222816: step 25913, loss 0.579124.
Train: 2018-08-01T01:30:21.379000: step 25914, loss 0.562505.
Train: 2018-08-01T01:30:21.535213: step 25915, loss 0.495879.
Train: 2018-08-01T01:30:21.691457: step 25916, loss 0.462341.
Train: 2018-08-01T01:30:21.847670: step 25917, loss 0.57921.
Train: 2018-08-01T01:30:22.003853: step 25918, loss 0.545658.
Train: 2018-08-01T01:30:22.175689: step 25919, loss 0.528759.
Train: 2018-08-01T01:30:22.331927: step 25920, loss 0.579316.
Test: 2018-08-01T01:30:22.816163: step 25920, loss 0.54824.
Train: 2018-08-01T01:30:22.972376: step 25921, loss 0.545486.
Train: 2018-08-01T01:30:23.128589: step 25922, loss 0.681235.
Train: 2018-08-01T01:30:23.284833: step 25923, loss 0.46048.
Train: 2018-08-01T01:30:23.441016: step 25924, loss 0.477294.
Train: 2018-08-01T01:30:23.597229: step 25925, loss 0.630688.
Train: 2018-08-01T01:30:23.753467: step 25926, loss 0.699212.
Train: 2018-08-01T01:30:23.909687: step 25927, loss 0.6308.
Train: 2018-08-01T01:30:24.065900: step 25928, loss 0.613655.
Train: 2018-08-01T01:30:24.237706: step 25929, loss 0.681823.
Train: 2018-08-01T01:30:24.393949: step 25930, loss 0.57942.
Test: 2018-08-01T01:30:24.862588: step 25930, loss 0.548204.
Train: 2018-08-01T01:30:25.018802: step 25931, loss 0.613317.
Train: 2018-08-01T01:30:25.190638: step 25932, loss 0.460918.
Train: 2018-08-01T01:30:25.346856: step 25933, loss 0.444171.
Train: 2018-08-01T01:30:25.503064: step 25934, loss 0.545527.
Train: 2018-08-01T01:30:25.659279: step 25935, loss 0.680766.
Train: 2018-08-01T01:30:25.815491: step 25936, loss 0.545537.
Train: 2018-08-01T01:30:25.956053: step 25937, loss 0.579307.
Train: 2018-08-01T01:30:26.112267: step 25938, loss 0.680492.
Train: 2018-08-01T01:30:26.268509: step 25939, loss 0.57927.
Train: 2018-08-01T01:30:26.440315: step 25940, loss 0.629632.
Test: 2018-08-01T01:30:26.908953: step 25940, loss 0.548435.
Train: 2018-08-01T01:30:27.080795: step 25941, loss 0.629468.
Train: 2018-08-01T01:30:27.237033: step 25942, loss 0.529083.
Train: 2018-08-01T01:30:27.393218: step 25943, loss 0.579153.
Train: 2018-08-01T01:30:27.565084: step 25944, loss 0.479403.
Train: 2018-08-01T01:30:27.721295: step 25945, loss 0.529302.
Train: 2018-08-01T01:30:27.877507: step 25946, loss 0.446301.
Train: 2018-08-01T01:30:28.033721: step 25947, loss 0.496009.
Train: 2018-08-01T01:30:28.189905: step 25948, loss 0.545833.
Train: 2018-08-01T01:30:28.346118: step 25949, loss 0.595876.
Train: 2018-08-01T01:30:28.502361: step 25950, loss 0.52902.
Test: 2018-08-01T01:30:28.970972: step 25950, loss 0.548427.
Train: 2018-08-01T01:30:29.142806: step 25951, loss 0.579218.
Train: 2018-08-01T01:30:29.299020: step 25952, loss 0.579238.
Train: 2018-08-01T01:30:29.455258: step 25953, loss 0.680102.
Train: 2018-08-01T01:30:29.611477: step 25954, loss 0.512035.
Train: 2018-08-01T01:30:29.783281: step 25955, loss 0.663317.
Train: 2018-08-01T01:30:29.939494: step 25956, loss 0.512052.
Train: 2018-08-01T01:30:30.095709: step 25957, loss 0.545649.
Train: 2018-08-01T01:30:30.267543: step 25958, loss 0.57925.
Train: 2018-08-01T01:30:30.423756: step 25959, loss 0.562447.
Train: 2018-08-01T01:30:30.580000: step 25960, loss 0.528833.
Test: 2018-08-01T01:30:31.048641: step 25960, loss 0.548361.
Train: 2018-08-01T01:30:31.204854: step 25961, loss 0.495177.
Train: 2018-08-01T01:30:31.361067: step 25962, loss 0.461393.
Train: 2018-08-01T01:30:31.532871: step 25963, loss 0.511773.
Train: 2018-08-01T01:30:31.689110: step 25964, loss 0.528546.
Train: 2018-08-01T01:30:31.860956: step 25965, loss 0.647356.
Train: 2018-08-01T01:30:32.017134: step 25966, loss 0.511345.
Train: 2018-08-01T01:30:32.173347: step 25967, loss 0.647698.
Train: 2018-08-01T01:30:32.313969: step 25968, loss 0.511171.
Train: 2018-08-01T01:30:32.470183: step 25969, loss 0.545296.
Train: 2018-08-01T01:30:32.642017: step 25970, loss 0.57953.
Test: 2018-08-01T01:30:33.126249: step 25970, loss 0.548036.
Train: 2018-08-01T01:30:33.282494: step 25971, loss 0.493789.
Train: 2018-08-01T01:30:33.438705: step 25972, loss 0.47647.
Train: 2018-08-01T01:30:33.594919: step 25973, loss 0.614102.
Train: 2018-08-01T01:30:33.751103: step 25974, loss 0.614201.
Train: 2018-08-01T01:30:33.907348: step 25975, loss 0.389566.
Train: 2018-08-01T01:30:34.079151: step 25976, loss 0.527741.
Train: 2018-08-01T01:30:34.235394: step 25977, loss 0.579807.
Train: 2018-08-01T01:30:34.391608: step 25978, loss 0.544996.
Train: 2018-08-01T01:30:34.547791: step 25979, loss 0.597383.
Train: 2018-08-01T01:30:34.704034: step 25980, loss 0.527439.
Test: 2018-08-01T01:30:35.172683: step 25980, loss 0.547769.
Train: 2018-08-01T01:30:35.328858: step 25981, loss 0.562453.
Train: 2018-08-01T01:30:35.485102: step 25982, loss 0.580026.
Train: 2018-08-01T01:30:35.641315: step 25983, loss 0.562469.
Train: 2018-08-01T01:30:35.797530: step 25984, loss 0.544872.
Train: 2018-08-01T01:30:35.953711: step 25985, loss 0.66821.
Train: 2018-08-01T01:30:36.094328: step 25986, loss 0.615325.
Train: 2018-08-01T01:30:36.266164: step 25987, loss 0.509679.
Train: 2018-08-01T01:30:36.422384: step 25988, loss 0.562471.
Train: 2018-08-01T01:30:36.578596: step 25989, loss 0.474543.
Train: 2018-08-01T01:30:36.734809: step 25990, loss 0.580068.
Test: 2018-08-01T01:30:37.203450: step 25990, loss 0.547735.
Train: 2018-08-01T01:30:37.390876: step 25991, loss 0.544873.
Train: 2018-08-01T01:30:37.547089: step 25992, loss 0.615297.
Train: 2018-08-01T01:30:37.703301: step 25993, loss 0.703284.
Train: 2018-08-01T01:30:37.859515: step 25994, loss 0.580029.
Train: 2018-08-01T01:30:38.015760: step 25995, loss 0.474801.
Train: 2018-08-01T01:30:38.187564: step 25996, loss 0.579962.
Train: 2018-08-01T01:30:38.343777: step 25997, loss 0.49246.
Train: 2018-08-01T01:30:38.499990: step 25998, loss 0.579934.
Train: 2018-08-01T01:30:38.656234: step 25999, loss 0.579924.
Train: 2018-08-01T01:30:38.812448: step 26000, loss 0.562437.
Test: 2018-08-01T01:30:39.281056: step 26000, loss 0.547812.
Train: 2018-08-01T01:30:40.015291: step 26001, loss 0.457662.
Train: 2018-08-01T01:30:40.171505: step 26002, loss 0.562437.
Train: 2018-08-01T01:30:40.327717: step 26003, loss 0.562439.
Train: 2018-08-01T01:30:40.483901: step 26004, loss 0.492488.
Train: 2018-08-01T01:30:40.640144: step 26005, loss 0.562445.
Train: 2018-08-01T01:30:40.796359: step 26006, loss 0.632547.
Train: 2018-08-01T01:30:40.952566: step 26007, loss 0.597498.
Train: 2018-08-01T01:30:41.108755: step 26008, loss 0.527416.
Train: 2018-08-01T01:30:41.264968: step 26009, loss 0.61499.
Train: 2018-08-01T01:30:41.421182: step 26010, loss 0.649951.
Test: 2018-08-01T01:30:41.905472: step 26010, loss 0.547806.
Train: 2018-08-01T01:30:42.046067: step 26011, loss 0.492552.
Train: 2018-08-01T01:30:42.202279: step 26012, loss 0.684632.
Train: 2018-08-01T01:30:42.358462: step 26013, loss 0.562425.
Train: 2018-08-01T01:30:42.514706: step 26014, loss 0.527651.
Train: 2018-08-01T01:30:42.670888: step 26015, loss 0.545055.
Train: 2018-08-01T01:30:42.842723: step 26016, loss 0.614428.
Train: 2018-08-01T01:30:42.998937: step 26017, loss 0.648958.
Train: 2018-08-01T01:30:43.139528: step 26018, loss 0.562403.
Train: 2018-08-01T01:30:43.295742: step 26019, loss 0.596852.
Train: 2018-08-01T01:30:43.451956: step 26020, loss 0.648311.
Test: 2018-08-01T01:30:43.936252: step 26020, loss 0.548058.
Train: 2018-08-01T01:30:44.092431: step 26021, loss 0.545273.
Train: 2018-08-01T01:30:44.248645: step 26022, loss 0.562401.
Train: 2018-08-01T01:30:44.404858: step 26023, loss 0.528333.
Train: 2018-08-01T01:30:44.561070: step 26024, loss 0.528398.
Train: 2018-08-01T01:30:44.717309: step 26025, loss 0.664315.
Train: 2018-08-01T01:30:44.873529: step 26026, loss 0.54547.
Train: 2018-08-01T01:30:45.060954: step 26027, loss 0.613163.
Train: 2018-08-01T01:30:45.217197: step 26028, loss 0.579304.
Train: 2018-08-01T01:30:45.373410: step 26029, loss 0.596115.
Train: 2018-08-01T01:30:45.529594: step 26030, loss 0.596046.
Test: 2018-08-01T01:30:45.998264: step 26030, loss 0.548427.
Train: 2018-08-01T01:30:46.170093: step 26031, loss 0.512187.
Train: 2018-08-01T01:30:46.310660: step 26032, loss 0.512272.
Train: 2018-08-01T01:30:46.466905: step 26033, loss 0.529031.
Train: 2018-08-01T01:30:46.638739: step 26034, loss 0.478879.
Train: 2018-08-01T01:30:46.794954: step 26035, loss 0.512258.
Train: 2018-08-01T01:30:46.951166: step 26036, loss 0.47864.
Train: 2018-08-01T01:30:47.107350: step 26037, loss 0.629674.
Train: 2018-08-01T01:30:47.263563: step 26038, loss 0.562438.
Train: 2018-08-01T01:30:47.419808: step 26039, loss 0.478146.
Train: 2018-08-01T01:30:47.575990: step 26040, loss 0.680709.
Test: 2018-08-01T01:30:48.044662: step 26040, loss 0.548261.
Train: 2018-08-01T01:30:48.200874: step 26041, loss 0.545511.
Train: 2018-08-01T01:30:48.372679: step 26042, loss 0.545493.
Train: 2018-08-01T01:30:48.513308: step 26043, loss 0.511586.
Train: 2018-08-01T01:30:48.685136: step 26044, loss 0.545441.
Train: 2018-08-01T01:30:48.841349: step 26045, loss 0.51141.
Train: 2018-08-01T01:30:48.981941: step 26046, loss 0.57944.
Train: 2018-08-01T01:30:49.153746: step 26047, loss 0.460003.
Train: 2018-08-01T01:30:49.309988: step 26048, loss 0.442593.
Train: 2018-08-01T01:30:49.481794: step 26049, loss 0.545214.
Train: 2018-08-01T01:30:49.638008: step 26050, loss 0.510654.
Test: 2018-08-01T01:30:50.122269: step 26050, loss 0.547906.
Train: 2018-08-01T01:30:50.278515: step 26051, loss 0.579727.
Train: 2018-08-01T01:30:50.434726: step 26052, loss 0.579793.
Train: 2018-08-01T01:30:50.606561: step 26053, loss 0.562425.
Train: 2018-08-01T01:30:50.778365: step 26054, loss 0.61484.
Train: 2018-08-01T01:30:50.934578: step 26055, loss 0.649918.
Train: 2018-08-01T01:30:51.075201: step 26056, loss 0.527442.
Train: 2018-08-01T01:30:51.247006: step 26057, loss 0.667518.
Train: 2018-08-01T01:30:51.403248: step 26058, loss 0.492444.
Train: 2018-08-01T01:30:51.559433: step 26059, loss 0.474933.
Train: 2018-08-01T01:30:51.715645: step 26060, loss 0.527407.
Test: 2018-08-01T01:30:52.199906: step 26060, loss 0.547764.
Train: 2018-08-01T01:30:52.340499: step 26061, loss 0.439647.
Train: 2018-08-01T01:30:52.496743: step 26062, loss 0.456937.
Train: 2018-08-01T01:30:52.652927: step 26063, loss 0.491894.
Train: 2018-08-01T01:30:52.824791: step 26064, loss 0.615666.
Train: 2018-08-01T01:30:52.996625: step 26065, loss 0.633597.
Train: 2018-08-01T01:30:53.152809: step 26066, loss 0.687097.
Train: 2018-08-01T01:30:53.309022: step 26067, loss 0.615922.
Train: 2018-08-01T01:30:53.465236: step 26068, loss 0.598097.
Train: 2018-08-01T01:30:53.621449: step 26069, loss 0.509269.
Train: 2018-08-01T01:30:53.793285: step 26070, loss 0.49155.
Test: 2018-08-01T01:30:54.246333: step 26070, loss 0.547669.
Train: 2018-08-01T01:30:54.418169: step 26071, loss 0.491538.
Train: 2018-08-01T01:30:54.574381: step 26072, loss 0.580303.
Train: 2018-08-01T01:30:54.730564: step 26073, loss 0.580316.
Train: 2018-08-01T01:30:54.902437: step 26074, loss 0.455889.
Train: 2018-08-01T01:30:55.058612: step 26075, loss 0.509161.
Train: 2018-08-01T01:30:55.199234: step 26076, loss 0.526915.
Train: 2018-08-01T01:30:55.355448: step 26077, loss 0.526869.
Train: 2018-08-01T01:30:55.511632: step 26078, loss 0.580495.
Train: 2018-08-01T01:30:55.667845: step 26079, loss 0.616366.
Train: 2018-08-01T01:30:55.824058: step 26080, loss 0.526772.
Test: 2018-08-01T01:30:56.308350: step 26080, loss 0.547609.
Train: 2018-08-01T01:30:56.464564: step 26081, loss 0.634387.
Train: 2018-08-01T01:30:56.620778: step 26082, loss 0.634368.
Train: 2018-08-01T01:30:56.776986: step 26083, loss 0.544702.
Train: 2018-08-01T01:30:56.933204: step 26084, loss 0.616302.
Train: 2018-08-01T01:30:57.105008: step 26085, loss 0.598333.
Train: 2018-08-01T01:30:57.245600: step 26086, loss 0.616084.
Train: 2018-08-01T01:30:57.401813: step 26087, loss 0.491378.
Train: 2018-08-01T01:30:57.558058: step 26088, loss 0.527005.
Train: 2018-08-01T01:30:57.714271: step 26089, loss 0.527033.
Train: 2018-08-01T01:30:57.870479: step 26090, loss 0.598004.
Test: 2018-08-01T01:30:58.339094: step 26090, loss 0.547681.
Train: 2018-08-01T01:30:58.542171: step 26091, loss 0.580239.
Train: 2018-08-01T01:30:58.698415: step 26092, loss 0.509415.
Train: 2018-08-01T01:30:58.854624: step 26093, loss 0.580194.
Train: 2018-08-01T01:30:59.010836: step 26094, loss 0.597847.
Train: 2018-08-01T01:30:59.182677: step 26095, loss 0.597796.
Train: 2018-08-01T01:30:59.370129: step 26096, loss 0.491983.
Train: 2018-08-01T01:30:59.541969: step 26097, loss 0.562477.
Train: 2018-08-01T01:30:59.682560: step 26098, loss 0.580074.
Train: 2018-08-01T01:30:59.854395: step 26099, loss 0.509713.
Train: 2018-08-01T01:30:59.994987: step 26100, loss 0.580047.
Test: 2018-08-01T01:31:00.479248: step 26100, loss 0.547749.
Train: 2018-08-01T01:31:01.244691: step 26101, loss 0.597607.
Train: 2018-08-01T01:31:01.432153: step 26102, loss 0.667791.
Train: 2018-08-01T01:31:01.619606: step 26103, loss 0.562448.
Train: 2018-08-01T01:31:01.775790: step 26104, loss 0.527471.
Train: 2018-08-01T01:31:01.932004: step 26105, loss 0.562433.
Train: 2018-08-01T01:31:02.088247: step 26106, loss 0.527555.
Train: 2018-08-01T01:31:02.244460: step 26107, loss 0.492737.
Train: 2018-08-01T01:31:02.416290: step 26108, loss 0.510157.
Train: 2018-08-01T01:31:02.572479: step 26109, loss 0.527561.
Train: 2018-08-01T01:31:02.713094: step 26110, loss 0.544981.
Test: 2018-08-01T01:31:03.197361: step 26110, loss 0.547808.
Train: 2018-08-01T01:31:03.353545: step 26111, loss 0.579901.
Train: 2018-08-01T01:31:03.509789: step 26112, loss 0.510005.
Train: 2018-08-01T01:31:03.681618: step 26113, loss 0.579939.
Train: 2018-08-01T01:31:03.837807: step 26114, loss 0.544935.
Train: 2018-08-01T01:31:03.978400: step 26115, loss 0.5274.
Train: 2018-08-01T01:31:04.150266: step 26116, loss 0.562455.
Train: 2018-08-01T01:31:04.290825: step 26117, loss 0.702943.
Train: 2018-08-01T01:31:04.462660: step 26118, loss 0.615091.
Train: 2018-08-01T01:31:04.618904: step 26119, loss 0.527408.
Train: 2018-08-01T01:31:04.775121: step 26120, loss 0.579947.
Test: 2018-08-01T01:31:05.259378: step 26120, loss 0.547798.
Train: 2018-08-01T01:31:05.415594: step 26121, loss 0.614889.
Train: 2018-08-01T01:31:05.571807: step 26122, loss 0.544977.
Train: 2018-08-01T01:31:05.728019: step 26123, loss 0.597288.
Train: 2018-08-01T01:31:05.884202: step 26124, loss 0.492814.
Train: 2018-08-01T01:31:06.040416: step 26125, loss 0.562418.
Train: 2018-08-01T01:31:06.196629: step 26126, loss 0.527662.
Train: 2018-08-01T01:31:06.352844: step 26127, loss 0.614534.
Train: 2018-08-01T01:31:06.509087: step 26128, loss 0.562413.
Train: 2018-08-01T01:31:06.665302: step 26129, loss 0.631785.
Train: 2018-08-01T01:31:06.837135: step 26130, loss 0.493143.
Test: 2018-08-01T01:31:07.305774: step 26130, loss 0.547915.
Train: 2018-08-01T01:31:07.461958: step 26131, loss 0.614321.
Train: 2018-08-01T01:31:07.618172: step 26132, loss 0.54512.
Train: 2018-08-01T01:31:07.774385: step 26133, loss 0.562402.
Train: 2018-08-01T01:31:07.930599: step 26134, loss 0.51064.
Train: 2018-08-01T01:31:08.102433: step 26135, loss 0.527898.
Train: 2018-08-01T01:31:08.258673: step 26136, loss 0.648682.
Train: 2018-08-01T01:31:08.414859: step 26137, loss 0.493432.
Train: 2018-08-01T01:31:08.571073: step 26138, loss 0.476183.
Train: 2018-08-01T01:31:08.727286: step 26139, loss 0.579665.
Train: 2018-08-01T01:31:08.883530: step 26140, loss 0.493299.
Test: 2018-08-01T01:31:09.352170: step 26140, loss 0.547917.
Train: 2018-08-01T01:31:09.523975: step 26141, loss 0.579708.
Train: 2018-08-01T01:31:09.664567: step 26142, loss 0.614372.
Train: 2018-08-01T01:31:09.820811: step 26143, loss 0.527753.
Train: 2018-08-01T01:31:09.977024: step 26144, loss 0.441031.
Train: 2018-08-01T01:31:10.133238: step 26145, loss 0.597167.
Train: 2018-08-01T01:31:10.305042: step 26146, loss 0.54502.
Train: 2018-08-01T01:31:10.461286: step 26147, loss 0.457875.
Train: 2018-08-01T01:31:10.617468: step 26148, loss 0.544967.
Train: 2018-08-01T01:31:10.773712: step 26149, loss 0.509916.
Train: 2018-08-01T01:31:10.929897: step 26150, loss 0.544902.
Test: 2018-08-01T01:31:11.398566: step 26150, loss 0.547734.
Train: 2018-08-01T01:31:11.554780: step 26151, loss 0.456861.
Train: 2018-08-01T01:31:11.726616: step 26152, loss 0.580158.
Train: 2018-08-01T01:31:11.882828: step 26153, loss 0.544803.
Train: 2018-08-01T01:31:12.039011: step 26154, loss 0.544777.
Train: 2018-08-01T01:31:12.195251: step 26155, loss 0.544753.
Train: 2018-08-01T01:31:12.351474: step 26156, loss 0.491197.
Train: 2018-08-01T01:31:12.523272: step 26157, loss 0.705769.
Train: 2018-08-01T01:31:12.679517: step 26158, loss 0.652161.
Train: 2018-08-01T01:31:12.835700: step 26159, loss 0.544707.
Train: 2018-08-01T01:31:12.991937: step 26160, loss 0.544709.
Test: 2018-08-01T01:31:13.460583: step 26160, loss 0.547621.
Train: 2018-08-01T01:31:13.632418: step 26161, loss 0.562605.
Train: 2018-08-01T01:31:13.788626: step 26162, loss 0.562602.
Train: 2018-08-01T01:31:13.944845: step 26163, loss 0.616249.
Train: 2018-08-01T01:31:14.101058: step 26164, loss 0.598319.
Train: 2018-08-01T01:31:14.257272: step 26165, loss 0.562575.
Train: 2018-08-01T01:31:14.413481: step 26166, loss 0.598192.
Train: 2018-08-01T01:31:14.569693: step 26167, loss 0.491415.
Train: 2018-08-01T01:31:14.757149: step 26168, loss 0.56254.
Train: 2018-08-01T01:31:14.913370: step 26169, loss 0.598036.
Train: 2018-08-01T01:31:15.069551: step 26170, loss 0.633437.
Test: 2018-08-01T01:31:15.538223: step 26170, loss 0.547692.
Train: 2018-08-01T01:31:15.710056: step 26171, loss 0.597891.
Train: 2018-08-01T01:31:15.866241: step 26172, loss 0.650743.
Train: 2018-08-01T01:31:16.022483: step 26173, loss 0.580064.
Train: 2018-08-01T01:31:16.178666: step 26174, loss 0.527378.
Train: 2018-08-01T01:31:16.334882: step 26175, loss 0.597427.
Train: 2018-08-01T01:31:16.491093: step 26176, loss 0.510093.
Train: 2018-08-01T01:31:16.647339: step 26177, loss 0.510186.
Train: 2018-08-01T01:31:16.819170: step 26178, loss 0.579811.
Train: 2018-08-01T01:31:16.975385: step 26179, loss 0.684008.
Train: 2018-08-01T01:31:17.115978: step 26180, loss 0.545083.
Test: 2018-08-01T01:31:17.600209: step 26180, loss 0.547928.
Train: 2018-08-01T01:31:17.756423: step 26181, loss 0.510543.
Train: 2018-08-01T01:31:17.912675: step 26182, loss 0.614192.
Train: 2018-08-01T01:31:18.068885: step 26183, loss 0.751939.
Train: 2018-08-01T01:31:18.225092: step 26184, loss 0.476587.
Train: 2018-08-01T01:31:18.381278: step 26185, loss 0.54528.
Train: 2018-08-01T01:31:18.537523: step 26186, loss 0.596564.
Train: 2018-08-01T01:31:18.678081: step 26187, loss 0.544223.
Train: 2018-08-01T01:31:18.834325: step 26188, loss 0.460333.
Train: 2018-08-01T01:31:19.006130: step 26189, loss 0.562406.
Train: 2018-08-01T01:31:19.177964: step 26190, loss 0.596408.
Test: 2018-08-01T01:31:19.646605: step 26190, loss 0.548181.
Train: 2018-08-01T01:31:19.802848: step 26191, loss 0.562408.
Train: 2018-08-01T01:31:19.959062: step 26192, loss 0.460531.
Train: 2018-08-01T01:31:20.115245: step 26193, loss 0.528422.
Train: 2018-08-01T01:31:20.287079: step 26194, loss 0.613443.
Train: 2018-08-01T01:31:20.443323: step 26195, loss 0.545385.
Train: 2018-08-01T01:31:20.599507: step 26196, loss 0.494282.
Train: 2018-08-01T01:31:20.755750: step 26197, loss 0.647674.
Train: 2018-08-01T01:31:20.911933: step 26198, loss 0.545343.
Train: 2018-08-01T01:31:21.068174: step 26199, loss 0.681863.
Train: 2018-08-01T01:31:21.240008: step 26200, loss 0.49421.
Test: 2018-08-01T01:31:21.693030: step 26200, loss 0.548128.
Train: 2018-08-01T01:31:22.411582: step 26201, loss 0.596495.
Train: 2018-08-01T01:31:22.567796: step 26202, loss 0.647593.
Train: 2018-08-01T01:31:22.724008: step 26203, loss 0.579418.
Train: 2018-08-01T01:31:22.880253: step 26204, loss 0.681318.
Train: 2018-08-01T01:31:23.036469: step 26205, loss 0.545476.
Train: 2018-08-01T01:31:23.192680: step 26206, loss 0.646925.
Train: 2018-08-01T01:31:23.348887: step 26207, loss 0.528737.
Train: 2018-08-01T01:31:23.520698: step 26208, loss 0.612872.
Train: 2018-08-01T01:31:23.676935: step 26209, loss 0.64628.
Train: 2018-08-01T01:31:23.833155: step 26210, loss 0.579183.
Test: 2018-08-01T01:31:24.301764: step 26210, loss 0.548549.
Train: 2018-08-01T01:31:24.458008: step 26211, loss 0.595803.
Train: 2018-08-01T01:31:24.645466: step 26212, loss 0.379921.
Train: 2018-08-01T01:31:24.801678: step 26213, loss 0.612296.
Train: 2018-08-01T01:31:24.957891: step 26214, loss 0.496225.
Train: 2018-08-01T01:31:25.114104: step 26215, loss 0.446487.
Train: 2018-08-01T01:31:25.270288: step 26216, loss 0.562515.
Train: 2018-08-01T01:31:25.426501: step 26217, loss 0.678924.
Train: 2018-08-01T01:31:25.582739: step 26218, loss 0.495977.
Train: 2018-08-01T01:31:25.754550: step 26219, loss 0.495906.
Train: 2018-08-01T01:31:25.910763: step 26220, loss 0.479097.
Test: 2018-08-01T01:31:26.363811: step 26220, loss 0.548465.
Train: 2018-08-01T01:31:26.520025: step 26221, loss 0.595917.
Train: 2018-08-01T01:31:26.676239: step 26222, loss 0.545699.
Train: 2018-08-01T01:31:26.863690: step 26223, loss 0.663224.
Train: 2018-08-01T01:31:27.004295: step 26224, loss 0.61287.
Train: 2018-08-01T01:31:27.160471: step 26225, loss 0.646496.
Train: 2018-08-01T01:31:27.316684: step 26226, loss 0.579243.
Train: 2018-08-01T01:31:27.472927: step 26227, loss 0.579231.
Train: 2018-08-01T01:31:27.644765: step 26228, loss 0.612742.
Train: 2018-08-01T01:31:27.800975: step 26229, loss 0.512256.
Train: 2018-08-01T01:31:27.972804: step 26230, loss 0.545743.
Test: 2018-08-01T01:31:28.457071: step 26230, loss 0.548469.
Train: 2018-08-01T01:31:28.597634: step 26231, loss 0.612633.
Train: 2018-08-01T01:31:28.753877: step 26232, loss 0.595889.
Train: 2018-08-01T01:31:28.925682: step 26233, loss 0.529105.
Train: 2018-08-01T01:31:29.097516: step 26234, loss 0.479083.
Train: 2018-08-01T01:31:29.238110: step 26235, loss 0.612557.
Train: 2018-08-01T01:31:29.409975: step 26236, loss 0.61256.
Train: 2018-08-01T01:31:29.550566: step 26237, loss 0.595853.
Train: 2018-08-01T01:31:29.706773: step 26238, loss 0.562488.
Train: 2018-08-01T01:31:29.862992: step 26239, loss 0.679119.
Train: 2018-08-01T01:31:30.019202: step 26240, loss 0.645645.
Test: 2018-08-01T01:31:30.503437: step 26240, loss 0.54864.
Train: 2018-08-01T01:31:30.659651: step 26241, loss 0.51278.
Train: 2018-08-01T01:31:30.815863: step 26242, loss 0.595643.
Train: 2018-08-01T01:31:30.972102: step 26243, loss 0.562554.
Train: 2018-08-01T01:31:31.128291: step 26244, loss 0.546073.
Train: 2018-08-01T01:31:31.300151: step 26245, loss 0.463727.
Train: 2018-08-01T01:31:31.456338: step 26246, loss 0.546092.
Train: 2018-08-01T01:31:31.612553: step 26247, loss 0.612045.
Train: 2018-08-01T01:31:31.784419: step 26248, loss 0.612048.
Train: 2018-08-01T01:31:31.940615: step 26249, loss 0.579057.
Train: 2018-08-01T01:31:32.096814: step 26250, loss 0.612007.
Test: 2018-08-01T01:31:32.565453: step 26250, loss 0.548801.
Train: 2018-08-01T01:31:32.721668: step 26251, loss 0.546124.
Train: 2018-08-01T01:31:32.877912: step 26252, loss 0.513237.
Train: 2018-08-01T01:31:33.034127: step 26253, loss 0.661318.
Train: 2018-08-01T01:31:33.190338: step 26254, loss 0.496839.
Train: 2018-08-01T01:31:33.362179: step 26255, loss 0.529713.
Train: 2018-08-01T01:31:33.502773: step 26256, loss 0.546137.
Train: 2018-08-01T01:31:33.658980: step 26257, loss 0.546113.
Train: 2018-08-01T01:31:33.815193: step 26258, loss 0.546084.
Train: 2018-08-01T01:31:33.987027: step 26259, loss 0.595579.
Train: 2018-08-01T01:31:34.143242: step 26260, loss 0.546026.
Test: 2018-08-01T01:31:34.627504: step 26260, loss 0.548689.
Train: 2018-08-01T01:31:34.783685: step 26261, loss 0.529454.
Train: 2018-08-01T01:31:34.939928: step 26262, loss 0.47968.
Train: 2018-08-01T01:31:35.096112: step 26263, loss 0.512673.
Train: 2018-08-01T01:31:35.252350: step 26264, loss 0.5125.
Train: 2018-08-01T01:31:35.408571: step 26265, loss 0.595913.
Train: 2018-08-01T01:31:35.564777: step 26266, loss 0.512153.
Train: 2018-08-01T01:31:35.720966: step 26267, loss 0.579261.
Train: 2018-08-01T01:31:35.877209: step 26268, loss 0.545564.
Train: 2018-08-01T01:31:36.033392: step 26269, loss 0.596243.
Train: 2018-08-01T01:31:36.189605: step 26270, loss 0.57936.
Test: 2018-08-01T01:31:36.658278: step 26270, loss 0.548197.
Train: 2018-08-01T01:31:36.814460: step 26271, loss 0.494517.
Train: 2018-08-01T01:31:36.970673: step 26272, loss 0.545392.
Train: 2018-08-01T01:31:37.126887: step 26273, loss 0.545348.
Train: 2018-08-01T01:31:37.283131: step 26274, loss 0.528214.
Train: 2018-08-01T01:31:37.439314: step 26275, loss 0.51099.
Train: 2018-08-01T01:31:37.595557: step 26276, loss 0.545212.
Train: 2018-08-01T01:31:37.767361: step 26277, loss 0.527924.
Train: 2018-08-01T01:31:37.923605: step 26278, loss 0.545105.
Train: 2018-08-01T01:31:38.079818: step 26279, loss 0.649299.
Train: 2018-08-01T01:31:38.236031: step 26280, loss 0.579709.
Test: 2018-08-01T01:31:38.704672: step 26280, loss 0.54785.
Train: 2018-08-01T01:31:38.876504: step 26281, loss 0.54489.
Train: 2018-08-01T01:31:39.032722: step 26282, loss 0.544811.
Train: 2018-08-01T01:31:39.188928: step 26283, loss 0.440155.
Train: 2018-08-01T01:31:39.345146: step 26284, loss 0.668377.
Train: 2018-08-01T01:31:39.485739: step 26285, loss 0.562124.
Train: 2018-08-01T01:31:39.641955: step 26286, loss 0.580034.
Train: 2018-08-01T01:31:39.798166: step 26287, loss 0.597397.
Train: 2018-08-01T01:31:39.985592: step 26288, loss 0.580388.
Train: 2018-08-01T01:31:40.126223: step 26289, loss 0.509646.
Train: 2018-08-01T01:31:40.282398: step 26290, loss 0.686256.
Test: 2018-08-01T01:31:40.751067: step 26290, loss 0.547752.
Train: 2018-08-01T01:31:40.907283: step 26291, loss 0.509553.
Train: 2018-08-01T01:31:41.079116: step 26292, loss 0.544532.
Train: 2018-08-01T01:31:41.235335: step 26293, loss 0.579803.
Train: 2018-08-01T01:31:41.391544: step 26294, loss 0.54511.
Train: 2018-08-01T01:31:41.547726: step 26295, loss 0.562405.
Train: 2018-08-01T01:31:41.703939: step 26296, loss 0.510099.
Train: 2018-08-01T01:31:41.860152: step 26297, loss 0.492716.
Train: 2018-08-01T01:31:42.016367: step 26298, loss 0.562693.
Train: 2018-08-01T01:31:42.188201: step 26299, loss 0.492356.
Train: 2018-08-01T01:31:42.344439: step 26300, loss 0.439403.
Test: 2018-08-01T01:31:42.813055: step 26300, loss 0.547724.
Train: 2018-08-01T01:31:43.547288: step 26301, loss 0.561698.
Train: 2018-08-01T01:31:43.703501: step 26302, loss 0.526248.
Train: 2018-08-01T01:31:43.875330: step 26303, loss 0.493272.
Train: 2018-08-01T01:31:44.031551: step 26304, loss 0.580937.
Train: 2018-08-01T01:31:44.187732: step 26305, loss 0.67007.
Train: 2018-08-01T01:31:44.343946: step 26306, loss 0.562897.
Train: 2018-08-01T01:31:44.500159: step 26307, loss 0.583111.
Train: 2018-08-01T01:31:44.656405: step 26308, loss 0.582215.
Train: 2018-08-01T01:31:44.812586: step 26309, loss 0.508596.
Train: 2018-08-01T01:31:44.984452: step 26310, loss 0.527488.
Test: 2018-08-01T01:31:45.453061: step 26310, loss 0.547654.
Train: 2018-08-01T01:31:45.609275: step 26311, loss 0.597911.
Train: 2018-08-01T01:31:45.765488: step 26312, loss 0.580106.
Train: 2018-08-01T01:31:45.921701: step 26313, loss 0.562514.
Train: 2018-08-01T01:31:46.077945: step 26314, loss 0.544811.
Train: 2018-08-01T01:31:46.249789: step 26315, loss 0.615618.
Train: 2018-08-01T01:31:46.405996: step 26316, loss 0.527127.
Train: 2018-08-01T01:31:46.577822: step 26317, loss 0.562501.
Train: 2018-08-01T01:31:46.718421: step 26318, loss 0.562498.
Train: 2018-08-01T01:31:46.874628: step 26319, loss 0.544834.
Train: 2018-08-01T01:31:47.030849: step 26320, loss 0.615453.
Test: 2018-08-01T01:31:47.515108: step 26320, loss 0.547717.
Train: 2018-08-01T01:31:47.718186: step 26321, loss 0.650665.
Train: 2018-08-01T01:31:47.874394: step 26322, loss 0.580073.
Train: 2018-08-01T01:31:48.030582: step 26323, loss 0.457076.
Train: 2018-08-01T01:31:48.186797: step 26324, loss 0.544905.
Train: 2018-08-01T01:31:48.343042: step 26325, loss 0.667713.
Train: 2018-08-01T01:31:48.499253: step 26326, loss 0.579958.
Train: 2018-08-01T01:31:48.655436: step 26327, loss 0.527476.
Train: 2018-08-01T01:31:48.827271: step 26328, loss 0.614806.
Train: 2018-08-01T01:31:48.983484: step 26329, loss 0.492721.
Train: 2018-08-01T01:31:49.139698: step 26330, loss 0.475367.
Test: 2018-08-01T01:31:49.608367: step 26330, loss 0.54784.
Train: 2018-08-01T01:31:49.764582: step 26331, loss 0.527593.
Train: 2018-08-01T01:31:49.952008: step 26332, loss 0.545.
Train: 2018-08-01T01:31:50.092630: step 26333, loss 0.614737.
Train: 2018-08-01T01:31:50.264469: step 26334, loss 0.562427.
Train: 2018-08-01T01:31:50.420678: step 26335, loss 0.457824.
Train: 2018-08-01T01:31:50.576886: step 26336, loss 0.597338.
Train: 2018-08-01T01:31:50.733075: step 26337, loss 0.597359.
Train: 2018-08-01T01:31:50.904910: step 26338, loss 0.562433.
Train: 2018-08-01T01:31:51.061124: step 26339, loss 0.614821.
Train: 2018-08-01T01:31:51.217367: step 26340, loss 0.562431.
Test: 2018-08-01T01:31:51.701629: step 26340, loss 0.547825.
Train: 2018-08-01T01:31:51.857812: step 26341, loss 0.52755.
Train: 2018-08-01T01:31:52.029647: step 26342, loss 0.562427.
Train: 2018-08-01T01:31:52.185884: step 26343, loss 0.614717.
Train: 2018-08-01T01:31:52.342109: step 26344, loss 0.579838.
Train: 2018-08-01T01:31:52.498317: step 26345, loss 0.579816.
Train: 2018-08-01T01:31:52.654532: step 26346, loss 0.527665.
Train: 2018-08-01T01:31:52.810744: step 26347, loss 0.64923.
Train: 2018-08-01T01:31:52.966962: step 26348, loss 0.614411.
Train: 2018-08-01T01:31:53.138761: step 26349, loss 0.579701.
Train: 2018-08-01T01:31:53.279386: step 26350, loss 0.545144.
Test: 2018-08-01T01:31:53.747994: step 26350, loss 0.547974.
Train: 2018-08-01T01:31:53.904239: step 26351, loss 0.51072.
Train: 2018-08-01T01:31:54.076072: step 26352, loss 0.52798.
Train: 2018-08-01T01:31:54.232256: step 26353, loss 0.527996.
Train: 2018-08-01T01:31:54.388469: step 26354, loss 0.596799.
Train: 2018-08-01T01:31:54.544682: step 26355, loss 0.545205.
Train: 2018-08-01T01:31:54.716518: step 26356, loss 0.596776.
Train: 2018-08-01T01:31:54.872730: step 26357, loss 0.579576.
Train: 2018-08-01T01:31:55.028945: step 26358, loss 0.373577.
Train: 2018-08-01T01:31:55.169561: step 26359, loss 0.528011.
Train: 2018-08-01T01:31:55.341370: step 26360, loss 0.545174.
Test: 2018-08-01T01:31:55.810013: step 26360, loss 0.54795.
Train: 2018-08-01T01:31:55.981870: step 26361, loss 0.545143.
Train: 2018-08-01T01:31:56.138060: step 26362, loss 0.527823.
Train: 2018-08-01T01:31:56.309893: step 26363, loss 0.562408.
Train: 2018-08-01T01:31:56.481729: step 26364, loss 0.510336.
Train: 2018-08-01T01:31:56.637972: step 26365, loss 0.56242.
Train: 2018-08-01T01:31:56.794186: step 26366, loss 0.440396.
Train: 2018-08-01T01:31:56.950399: step 26367, loss 0.597417.
Train: 2018-08-01T01:31:57.106616: step 26368, loss 0.667634.
Train: 2018-08-01T01:31:57.262820: step 26369, loss 0.615092.
Train: 2018-08-01T01:31:57.434630: step 26370, loss 0.59755.
Test: 2018-08-01T01:31:57.903302: step 26370, loss 0.547766.
Train: 2018-08-01T01:31:58.059515: step 26371, loss 0.492292.
Train: 2018-08-01T01:31:58.215729: step 26372, loss 0.544908.
Train: 2018-08-01T01:31:58.387535: step 26373, loss 0.685355.
Train: 2018-08-01T01:31:58.528157: step 26374, loss 0.562453.
Train: 2018-08-01T01:31:58.715605: step 26375, loss 0.474844.
Train: 2018-08-01T01:31:58.856203: step 26376, loss 0.544926.
Train: 2018-08-01T01:31:59.012418: step 26377, loss 0.544924.
Train: 2018-08-01T01:31:59.168630: step 26378, loss 0.579983.
Train: 2018-08-01T01:31:59.324844: step 26379, loss 0.544919.
Train: 2018-08-01T01:31:59.496678: step 26380, loss 0.597524.
Test: 2018-08-01T01:31:59.965288: step 26380, loss 0.547771.
Train: 2018-08-01T01:32:00.121531: step 26381, loss 0.492328.
Train: 2018-08-01T01:32:00.277715: step 26382, loss 0.579993.
Train: 2018-08-01T01:32:00.433929: step 26383, loss 0.52737.
Train: 2018-08-01T01:32:00.590142: step 26384, loss 0.562457.
Train: 2018-08-01T01:32:00.746356: step 26385, loss 0.492226.
Train: 2018-08-01T01:32:00.918226: step 26386, loss 0.580043.
Train: 2018-08-01T01:32:01.074428: step 26387, loss 0.615242.
Train: 2018-08-01T01:32:01.230647: step 26388, loss 0.58006.
Train: 2018-08-01T01:32:01.386830: step 26389, loss 0.509712.
Train: 2018-08-01T01:32:01.543045: step 26390, loss 0.492109.
Test: 2018-08-01T01:32:02.011714: step 26390, loss 0.547731.
Train: 2018-08-01T01:32:02.167930: step 26391, loss 0.597691.
Train: 2018-08-01T01:32:02.339731: step 26392, loss 0.685786.
Train: 2018-08-01T01:32:02.495975: step 26393, loss 0.544875.
Train: 2018-08-01T01:32:02.652191: step 26394, loss 0.615206.
Train: 2018-08-01T01:32:02.808373: step 26395, loss 0.544904.
Train: 2018-08-01T01:32:02.964611: step 26396, loss 0.579985.
Train: 2018-08-01T01:32:03.136451: step 26397, loss 0.509916.
Train: 2018-08-01T01:32:03.292664: step 26398, loss 0.667433.
Train: 2018-08-01T01:32:03.448847: step 26399, loss 0.492571.
Train: 2018-08-01T01:32:03.605091: step 26400, loss 0.61478.
Test: 2018-08-01T01:32:04.089347: step 26400, loss 0.547834.
Train: 2018-08-01T01:32:04.807928: step 26401, loss 0.527577.
Train: 2018-08-01T01:32:04.979769: step 26402, loss 0.527607.
Train: 2018-08-01T01:32:05.135953: step 26403, loss 0.579818.
Train: 2018-08-01T01:32:05.307788: step 26404, loss 0.527645.
Train: 2018-08-01T01:32:05.479652: step 26405, loss 0.649328.
Train: 2018-08-01T01:32:05.635836: step 26406, loss 0.510334.
Train: 2018-08-01T01:32:05.792048: step 26407, loss 0.527712.
Train: 2018-08-01T01:32:05.948292: step 26408, loss 0.579758.
Train: 2018-08-01T01:32:06.104475: step 26409, loss 0.631775.
Train: 2018-08-01T01:32:06.276343: step 26410, loss 0.510446.
Test: 2018-08-01T01:32:06.744950: step 26410, loss 0.547909.
Train: 2018-08-01T01:32:06.901170: step 26411, loss 0.614343.
Train: 2018-08-01T01:32:07.057407: step 26412, loss 0.527817.
Train: 2018-08-01T01:32:07.213590: step 26413, loss 0.596971.
Train: 2018-08-01T01:32:07.385427: step 26414, loss 0.683273.
Train: 2018-08-01T01:32:07.557261: step 26415, loss 0.579626.
Train: 2018-08-01T01:32:07.713474: step 26416, loss 0.613957.
Train: 2018-08-01T01:32:07.869717: step 26417, loss 0.579536.
Train: 2018-08-01T01:32:08.025932: step 26418, loss 0.545306.
Train: 2018-08-01T01:32:08.182114: step 26419, loss 0.613567.
Train: 2018-08-01T01:32:08.338352: step 26420, loss 0.460342.
Test: 2018-08-01T01:32:08.806997: step 26420, loss 0.548178.
Train: 2018-08-01T01:32:08.978818: step 26421, loss 0.562408.
Train: 2018-08-01T01:32:09.119425: step 26422, loss 0.545433.
Train: 2018-08-01T01:32:09.275640: step 26423, loss 0.494543.
Train: 2018-08-01T01:32:09.431851: step 26424, loss 0.545437.
Train: 2018-08-01T01:32:09.603686: step 26425, loss 0.596374.
Train: 2018-08-01T01:32:09.759902: step 26426, loss 0.698286.
Train: 2018-08-01T01:32:09.931729: step 26427, loss 0.57937.
Train: 2018-08-01T01:32:10.087942: step 26428, loss 0.562417.
Train: 2018-08-01T01:32:10.244131: step 26429, loss 0.444075.
Train: 2018-08-01T01:32:10.400376: step 26430, loss 0.56242.
Test: 2018-08-01T01:32:10.869015: step 26430, loss 0.548254.
Train: 2018-08-01T01:32:11.025197: step 26431, loss 0.613168.
Train: 2018-08-01T01:32:11.181412: step 26432, loss 0.596241.
Train: 2018-08-01T01:32:11.337649: step 26433, loss 0.511728.
Train: 2018-08-01T01:32:11.493838: step 26434, loss 0.63002.
Train: 2018-08-01T01:32:11.650083: step 26435, loss 0.596198.
Train: 2018-08-01T01:32:11.837508: step 26436, loss 0.545561.
Train: 2018-08-01T01:32:11.993721: step 26437, loss 0.596145.
Train: 2018-08-01T01:32:12.134346: step 26438, loss 0.596114.
Train: 2018-08-01T01:32:12.306149: step 26439, loss 0.680163.
Train: 2018-08-01T01:32:12.462392: step 26440, loss 0.461814.
Test: 2018-08-01T01:32:12.946624: step 26440, loss 0.548427.
Train: 2018-08-01T01:32:13.102861: step 26441, loss 0.512189.
Train: 2018-08-01T01:32:13.274672: step 26442, loss 0.528953.
Train: 2018-08-01T01:32:13.415294: step 26443, loss 0.612735.
Train: 2018-08-01T01:32:13.587098: step 26444, loss 0.495443.
Train: 2018-08-01T01:32:13.743343: step 26445, loss 0.612753.
Train: 2018-08-01T01:32:13.899525: step 26446, loss 0.512158.
Train: 2018-08-01T01:32:14.087017: step 26447, loss 0.528895.
Train: 2018-08-01T01:32:14.243225: step 26448, loss 0.680033.
Train: 2018-08-01T01:32:14.399432: step 26449, loss 0.495284.
Train: 2018-08-01T01:32:14.555652: step 26450, loss 0.579247.
Test: 2018-08-01T01:32:15.024293: step 26450, loss 0.548371.
Train: 2018-08-01T01:32:15.180505: step 26451, loss 0.545638.
Train: 2018-08-01T01:32:15.352334: step 26452, loss 0.562442.
Train: 2018-08-01T01:32:15.508523: step 26453, loss 0.47831.
Train: 2018-08-01T01:32:15.664767: step 26454, loss 0.680408.
Train: 2018-08-01T01:32:15.820980: step 26455, loss 0.562432.
Train: 2018-08-01T01:32:15.977193: step 26456, loss 0.511865.
Train: 2018-08-01T01:32:16.148999: step 26457, loss 0.545561.
Train: 2018-08-01T01:32:16.320857: step 26458, loss 0.494887.
Train: 2018-08-01T01:32:16.477077: step 26459, loss 0.528591.
Train: 2018-08-01T01:32:16.633294: step 26460, loss 0.596312.
Test: 2018-08-01T01:32:17.117521: step 26460, loss 0.548197.
Train: 2018-08-01T01:32:17.289357: step 26461, loss 0.647277.
Train: 2018-08-01T01:32:17.445602: step 26462, loss 0.494498.
Train: 2018-08-01T01:32:17.601814: step 26463, loss 0.54541.
Train: 2018-08-01T01:32:17.757996: step 26464, loss 0.664513.
Train: 2018-08-01T01:32:17.914210: step 26465, loss 0.562405.
Train: 2018-08-01T01:32:18.070424: step 26466, loss 0.545391.
Train: 2018-08-01T01:32:18.226636: step 26467, loss 0.630471.
Train: 2018-08-01T01:32:18.398471: step 26468, loss 0.528396.
Train: 2018-08-01T01:32:18.539094: step 26469, loss 0.562406.
Train: 2018-08-01T01:32:18.695277: step 26470, loss 0.613405.
Test: 2018-08-01T01:32:19.179569: step 26470, loss 0.548183.
Train: 2018-08-01T01:32:19.335777: step 26471, loss 0.511447.
Train: 2018-08-01T01:32:19.554481: step 26472, loss 0.61337.
Train: 2018-08-01T01:32:19.710663: step 26473, loss 0.528455.
Train: 2018-08-01T01:32:19.866909: step 26474, loss 0.630312.
Train: 2018-08-01T01:32:20.038743: step 26475, loss 0.511531.
Train: 2018-08-01T01:32:20.194926: step 26476, loss 0.613285.
Train: 2018-08-01T01:32:20.351169: step 26477, loss 0.545469.
Train: 2018-08-01T01:32:20.507383: step 26478, loss 0.494662.
Train: 2018-08-01T01:32:20.679218: step 26479, loss 0.511573.
Train: 2018-08-01T01:32:20.835432: step 26480, loss 0.426679.
Test: 2018-08-01T01:32:21.319692: step 26480, loss 0.548158.
Train: 2018-08-01T01:32:21.475908: step 26481, loss 0.630459.
Train: 2018-08-01T01:32:21.632134: step 26482, loss 0.596485.
Train: 2018-08-01T01:32:21.803960: step 26483, loss 0.545341.
Train: 2018-08-01T01:32:21.960168: step 26484, loss 0.562399.
Train: 2018-08-01T01:32:22.116351: step 26485, loss 0.511101.
Train: 2018-08-01T01:32:22.288185: step 26486, loss 0.493889.
Train: 2018-08-01T01:32:22.428777: step 26487, loss 0.49373.
Train: 2018-08-01T01:32:22.584991: step 26488, loss 0.617492.
Train: 2018-08-01T01:32:22.772472: step 26489, loss 0.5624.
Train: 2018-08-01T01:32:22.928660: step 26490, loss 0.579683.
Test: 2018-08-01T01:32:23.397333: step 26490, loss 0.547916.
Train: 2018-08-01T01:32:23.553545: step 26491, loss 0.631617.
Train: 2018-08-01T01:32:23.709758: step 26492, loss 0.51048.
Train: 2018-08-01T01:32:23.881563: step 26493, loss 0.683676.
Train: 2018-08-01T01:32:24.037801: step 26494, loss 0.666279.
Train: 2018-08-01T01:32:24.193990: step 26495, loss 0.596961.
Train: 2018-08-01T01:32:24.350234: step 26496, loss 0.527915.
Train: 2018-08-01T01:32:24.506417: step 26497, loss 0.459104.
Train: 2018-08-01T01:32:24.678282: step 26498, loss 0.614039.
Train: 2018-08-01T01:32:24.834489: step 26499, loss 0.562398.
Train: 2018-08-01T01:32:24.990680: step 26500, loss 0.596775.
Test: 2018-08-01T01:32:25.459348: step 26500, loss 0.548019.
Train: 2018-08-01T01:32:26.256036: step 26501, loss 0.528056.
Train: 2018-08-01T01:32:26.443495: step 26502, loss 0.476588.
Train: 2018-08-01T01:32:26.615327: step 26503, loss 0.613912.
Train: 2018-08-01T01:32:26.771543: step 26504, loss 0.562397.
Train: 2018-08-01T01:32:26.927754: step 26505, loss 0.562397.
Train: 2018-08-01T01:32:27.083969: step 26506, loss 0.545231.
Train: 2018-08-01T01:32:27.255772: step 26507, loss 0.631071.
Train: 2018-08-01T01:32:27.411985: step 26508, loss 0.631021.
Train: 2018-08-01T01:32:27.568199: step 26509, loss 0.665178.
Train: 2018-08-01T01:32:27.724412: step 26510, loss 0.511143.
Test: 2018-08-01T01:32:28.193082: step 26510, loss 0.548119.
Train: 2018-08-01T01:32:28.364888: step 26511, loss 0.494177.
Train: 2018-08-01T01:32:28.521102: step 26512, loss 0.494225.
Train: 2018-08-01T01:32:28.677315: step 26513, loss 0.511256.
Train: 2018-08-01T01:32:28.817936: step 26514, loss 0.511209.
Train: 2018-08-01T01:32:28.989776: step 26515, loss 0.767459.
Train: 2018-08-01T01:32:29.145986: step 26516, loss 0.5624.
Train: 2018-08-01T01:32:29.302199: step 26517, loss 0.596499.
Train: 2018-08-01T01:32:29.474033: step 26518, loss 0.613479.
Train: 2018-08-01T01:32:29.630218: step 26519, loss 0.545414.
Train: 2018-08-01T01:32:29.786429: step 26520, loss 0.545442.
Test: 2018-08-01T01:32:30.255100: step 26520, loss 0.548219.
Train: 2018-08-01T01:32:30.426937: step 26521, loss 0.443758.
Train: 2018-08-01T01:32:30.598763: step 26522, loss 0.51153.
Train: 2018-08-01T01:32:30.754986: step 26523, loss 0.494487.
Train: 2018-08-01T01:32:30.911196: step 26524, loss 0.44331.
Train: 2018-08-01T01:32:31.067380: step 26525, loss 0.767225.
Train: 2018-08-01T01:32:31.239214: step 26526, loss 0.425796.
Train: 2018-08-01T01:32:31.395453: step 26527, loss 0.579508.
Train: 2018-08-01T01:32:31.567264: step 26528, loss 0.63095.
Train: 2018-08-01T01:32:31.723476: step 26529, loss 0.442353.
Train: 2018-08-01T01:32:31.895335: step 26530, loss 0.545213.
Test: 2018-08-01T01:32:32.363981: step 26530, loss 0.54798.
Train: 2018-08-01T01:32:32.520164: step 26531, loss 0.596836.
Train: 2018-08-01T01:32:32.692000: step 26532, loss 0.5624.
Train: 2018-08-01T01:32:32.848213: step 26533, loss 0.527873.
Train: 2018-08-01T01:32:33.004458: step 26534, loss 0.614274.
Train: 2018-08-01T01:32:33.160641: step 26535, loss 0.5278.
Train: 2018-08-01T01:32:33.316853: step 26536, loss 0.458484.
Train: 2018-08-01T01:32:33.473066: step 26537, loss 0.597128.
Train: 2018-08-01T01:32:33.629280: step 26538, loss 0.5798.
Train: 2018-08-01T01:32:33.816761: step 26539, loss 0.545018.
Train: 2018-08-01T01:32:33.972950: step 26540, loss 0.440467.
Test: 2018-08-01T01:32:34.441588: step 26540, loss 0.547809.
Train: 2018-08-01T01:32:34.597803: step 26541, loss 0.544969.
Train: 2018-08-01T01:32:34.754041: step 26542, loss 0.527433.
Train: 2018-08-01T01:32:34.925887: step 26543, loss 0.527359.
Train: 2018-08-01T01:32:35.082064: step 26544, loss 0.56247.
Train: 2018-08-01T01:32:35.238277: step 26545, loss 0.597748.
Train: 2018-08-01T01:32:35.394515: step 26546, loss 0.491858.
Train: 2018-08-01T01:32:35.550704: step 26547, loss 0.580204.
Train: 2018-08-01T01:32:35.706919: step 26548, loss 0.597968.
Train: 2018-08-01T01:32:35.863162: step 26549, loss 0.527045.
Train: 2018-08-01T01:32:36.034967: step 26550, loss 0.544775.
Test: 2018-08-01T01:32:36.503636: step 26550, loss 0.547656.
Train: 2018-08-01T01:32:36.675465: step 26551, loss 0.544764.
Train: 2018-08-01T01:32:36.831686: step 26552, loss 0.598161.
Train: 2018-08-01T01:32:36.987898: step 26553, loss 0.598184.
Train: 2018-08-01T01:32:37.175325: step 26554, loss 0.473504.
Train: 2018-08-01T01:32:37.331568: step 26555, loss 0.580395.
Train: 2018-08-01T01:32:37.487752: step 26556, loss 0.616079.
Train: 2018-08-01T01:32:37.643964: step 26557, loss 0.598232.
Train: 2018-08-01T01:32:37.800177: step 26558, loss 0.544746.
Train: 2018-08-01T01:32:37.956391: step 26559, loss 0.544751.
Train: 2018-08-01T01:32:38.143873: step 26560, loss 0.615954.
Test: 2018-08-01T01:32:38.612517: step 26560, loss 0.547656.
Train: 2018-08-01T01:32:38.768702: step 26561, loss 0.651449.
Train: 2018-08-01T01:32:38.924946: step 26562, loss 0.491554.
Train: 2018-08-01T01:32:39.081159: step 26563, loss 0.50935.
Train: 2018-08-01T01:32:39.252964: step 26564, loss 0.562515.
Train: 2018-08-01T01:32:39.409176: step 26565, loss 0.491694.
Train: 2018-08-01T01:32:39.565390: step 26566, loss 0.562513.
Train: 2018-08-01T01:32:39.721636: step 26567, loss 0.580224.
Train: 2018-08-01T01:32:39.877848: step 26568, loss 0.615634.
Train: 2018-08-01T01:32:40.034029: step 26569, loss 0.59789.
Train: 2018-08-01T01:32:40.190273: step 26570, loss 0.527158.
Test: 2018-08-01T01:32:40.658914: step 26570, loss 0.547708.
Train: 2018-08-01T01:32:40.815096: step 26571, loss 0.527181.
Train: 2018-08-01T01:32:40.971336: step 26572, loss 0.633083.
Train: 2018-08-01T01:32:41.127549: step 26573, loss 0.47435.
Train: 2018-08-01T01:32:41.283767: step 26574, loss 0.597726.
Train: 2018-08-01T01:32:41.455572: step 26575, loss 0.632923.
Train: 2018-08-01T01:32:41.596195: step 26576, loss 0.562467.
Train: 2018-08-01T01:32:41.768031: step 26577, loss 0.474652.
Train: 2018-08-01T01:32:41.924242: step 26578, loss 0.544901.
Train: 2018-08-01T01:32:42.064840: step 26579, loss 0.49224.
Train: 2018-08-01T01:32:42.221043: step 26580, loss 0.492198.
Test: 2018-08-01T01:32:42.705280: step 26580, loss 0.547739.
Train: 2018-08-01T01:32:42.861524: step 26581, loss 0.544879.
Train: 2018-08-01T01:32:43.017707: step 26582, loss 0.580089.
Train: 2018-08-01T01:32:43.158329: step 26583, loss 0.509594.
Train: 2018-08-01T01:32:43.330135: step 26584, loss 0.597798.
Train: 2018-08-01T01:32:43.470755: step 26585, loss 0.509496.
Train: 2018-08-01T01:32:43.658206: step 26586, loss 0.580193.
Train: 2018-08-01T01:32:43.798798: step 26587, loss 0.509403.
Train: 2018-08-01T01:32:43.970639: step 26588, loss 0.580244.
Train: 2018-08-01T01:32:44.126851: step 26589, loss 0.527048.
Train: 2018-08-01T01:32:44.283059: step 26590, loss 0.491503.
Test: 2018-08-01T01:32:44.767295: step 26590, loss 0.547654.
Train: 2018-08-01T01:32:44.939162: step 26591, loss 0.562549.
Train: 2018-08-01T01:32:45.095345: step 26592, loss 0.633813.
Train: 2018-08-01T01:32:45.251558: step 26593, loss 0.633841.
Train: 2018-08-01T01:32:45.407775: step 26594, loss 0.580368.
Train: 2018-08-01T01:32:45.548395: step 26595, loss 0.615933.
Train: 2018-08-01T01:32:45.720199: step 26596, loss 0.420398.
Train: 2018-08-01T01:32:45.907655: step 26597, loss 0.509227.
Train: 2018-08-01T01:32:46.063898: step 26598, loss 0.598115.
Train: 2018-08-01T01:32:46.220112: step 26599, loss 0.562548.
Train: 2018-08-01T01:32:46.376327: step 26600, loss 0.562548.
Test: 2018-08-01T01:32:46.844967: step 26600, loss 0.547654.
Train: 2018-08-01T01:32:47.563547: step 26601, loss 0.491406.
Train: 2018-08-01T01:32:47.719760: step 26602, loss 0.562553.
Train: 2018-08-01T01:32:47.875974: step 26603, loss 0.509141.
Train: 2018-08-01T01:32:48.047803: step 26604, loss 0.580388.
Train: 2018-08-01T01:32:48.219613: step 26605, loss 0.526907.
Train: 2018-08-01T01:32:48.360236: step 26606, loss 0.59827.
Train: 2018-08-01T01:32:48.516418: step 26607, loss 0.56258.
Train: 2018-08-01T01:32:48.672632: step 26608, loss 0.491177.
Train: 2018-08-01T01:32:48.844491: step 26609, loss 0.580452.
Train: 2018-08-01T01:32:49.000679: step 26610, loss 0.508977.
Test: 2018-08-01T01:32:49.469350: step 26610, loss 0.547622.
Train: 2018-08-01T01:32:49.625564: step 26611, loss 0.5626.
Train: 2018-08-01T01:32:49.781748: step 26612, loss 0.687891.
Train: 2018-08-01T01:32:49.953612: step 26613, loss 0.598358.
Train: 2018-08-01T01:32:50.109797: step 26614, loss 0.580439.
Train: 2018-08-01T01:32:50.297251: step 26615, loss 0.562569.
Train: 2018-08-01T01:32:50.437843: step 26616, loss 0.651564.
Train: 2018-08-01T01:32:50.594090: step 26617, loss 0.757871.
Train: 2018-08-01T01:32:50.750272: step 26618, loss 0.491791.
Train: 2018-08-01T01:32:50.906515: step 26619, loss 0.668184.
Train: 2018-08-01T01:32:51.062698: step 26620, loss 0.562453.
Test: 2018-08-01T01:32:51.546989: step 26620, loss 0.547804.
Train: 2018-08-01T01:32:51.703203: step 26621, loss 0.562434.
Train: 2018-08-01T01:32:51.859387: step 26622, loss 0.562421.
Train: 2018-08-01T01:32:52.015599: step 26623, loss 0.545061.
Train: 2018-08-01T01:32:52.171843: step 26624, loss 0.527804.
Train: 2018-08-01T01:32:52.328051: step 26625, loss 0.49335.
Train: 2018-08-01T01:32:52.499885: step 26626, loss 0.665858.
Train: 2018-08-01T01:32:52.656099: step 26627, loss 0.562397.
Train: 2018-08-01T01:32:52.812287: step 26628, loss 0.579565.
Train: 2018-08-01T01:32:52.968532: step 26629, loss 0.493869.
Train: 2018-08-01T01:32:53.124714: step 26630, loss 0.511054.
Test: 2018-08-01T01:32:53.608976: step 26630, loss 0.54807.
Train: 2018-08-01T01:32:53.749598: step 26631, loss 0.613725.
Train: 2018-08-01T01:32:53.905812: step 26632, loss 0.61368.
Train: 2018-08-01T01:32:54.077647: step 26633, loss 0.716028.
Train: 2018-08-01T01:32:54.233830: step 26634, loss 0.545388.
Train: 2018-08-01T01:32:54.390043: step 26635, loss 0.56241.
Train: 2018-08-01T01:32:54.561879: step 26636, loss 0.49469.
Train: 2018-08-01T01:32:54.718122: step 26637, loss 0.613153.
Train: 2018-08-01T01:32:54.874305: step 26638, loss 0.545543.
Train: 2018-08-01T01:32:55.030518: step 26639, loss 0.579291.
Train: 2018-08-01T01:32:55.186731: step 26640, loss 0.612951.
Test: 2018-08-01T01:32:55.655403: step 26640, loss 0.548368.
Train: 2018-08-01T01:32:55.827237: step 26641, loss 0.579252.
Train: 2018-08-01T01:32:55.983419: step 26642, loss 0.612789.
Train: 2018-08-01T01:32:56.139665: step 26643, loss 0.612691.
Train: 2018-08-01T01:32:56.306895: step 26644, loss 0.562477.
Train: 2018-08-01T01:32:56.447487: step 26645, loss 0.579154.
Train: 2018-08-01T01:32:56.619324: step 26646, loss 0.545876.
Train: 2018-08-01T01:32:56.775533: step 26647, loss 0.579117.
Train: 2018-08-01T01:32:56.931744: step 26648, loss 0.562527.
Train: 2018-08-01T01:32:57.087933: step 26649, loss 0.612197.
Train: 2018-08-01T01:32:57.244178: step 26650, loss 0.496454.
Test: 2018-08-01T01:32:57.712815: step 26650, loss 0.548727.
Train: 2018-08-01T01:32:57.884622: step 26651, loss 0.661643.
Train: 2018-08-01T01:32:58.040834: step 26652, loss 0.562571.
Train: 2018-08-01T01:32:58.197047: step 26653, loss 0.546121.
Train: 2018-08-01T01:32:58.353260: step 26654, loss 0.546146.
Train: 2018-08-01T01:32:58.509474: step 26655, loss 0.529723.
Train: 2018-08-01T01:32:58.665718: step 26656, loss 0.595473.
Train: 2018-08-01T01:32:58.821902: step 26657, loss 0.628336.
Train: 2018-08-01T01:32:59.009389: step 26658, loss 0.595445.
Train: 2018-08-01T01:32:59.165596: step 26659, loss 0.611816.
Train: 2018-08-01T01:32:59.306193: step 26660, loss 0.546262.
Test: 2018-08-01T01:32:59.790454: step 26660, loss 0.548951.
Train: 2018-08-01T01:33:00.009147: step 26661, loss 0.497228.
Train: 2018-08-01T01:33:00.180994: step 26662, loss 0.54629.
Train: 2018-08-01T01:33:00.337196: step 26663, loss 0.529918.
Train: 2018-08-01T01:33:00.493417: step 26664, loss 0.529878.
Train: 2018-08-01T01:33:00.665220: step 26665, loss 0.415017.
Train: 2018-08-01T01:33:00.821464: step 26666, loss 0.579042.
Train: 2018-08-01T01:33:00.977674: step 26667, loss 0.546057.
Train: 2018-08-01T01:33:01.133862: step 26668, loss 0.678408.
Train: 2018-08-01T01:33:01.305695: step 26669, loss 0.595675.
Train: 2018-08-01T01:33:01.446286: step 26670, loss 0.628867.
Test: 2018-08-01T01:33:01.930578: step 26670, loss 0.548635.
Train: 2018-08-01T01:33:02.086786: step 26671, loss 0.479599.
Train: 2018-08-01T01:33:02.242977: step 26672, loss 0.612324.
Train: 2018-08-01T01:33:02.414810: step 26673, loss 0.579122.
Train: 2018-08-01T01:33:02.571053: step 26674, loss 0.52928.
Train: 2018-08-01T01:33:02.711646: step 26675, loss 0.579132.
Train: 2018-08-01T01:33:02.867861: step 26676, loss 0.562501.
Train: 2018-08-01T01:33:03.024072: step 26677, loss 0.529203.
Train: 2018-08-01T01:33:03.180286: step 26678, loss 0.629149.
Train: 2018-08-01T01:33:03.336470: step 26679, loss 0.612491.
Train: 2018-08-01T01:33:03.492715: step 26680, loss 0.612473.
Test: 2018-08-01T01:33:03.976974: step 26680, loss 0.54856.
Train: 2018-08-01T01:33:04.133187: step 26681, loss 0.645721.
Train: 2018-08-01T01:33:04.305022: step 26682, loss 0.612352.
Train: 2018-08-01T01:33:04.461205: step 26683, loss 0.512797.
Train: 2018-08-01T01:33:04.617451: step 26684, loss 0.463202.
Train: 2018-08-01T01:33:04.773632: step 26685, loss 0.496293.
Train: 2018-08-01T01:33:04.929876: step 26686, loss 0.545944.
Train: 2018-08-01T01:33:05.086083: step 26687, loss 0.595722.
Train: 2018-08-01T01:33:05.242305: step 26688, loss 0.595747.
Train: 2018-08-01T01:33:05.398510: step 26689, loss 0.495994.
Train: 2018-08-01T01:33:05.554724: step 26690, loss 0.495892.
Test: 2018-08-01T01:33:06.023370: step 26690, loss 0.548507.
Train: 2018-08-01T01:33:06.179554: step 26691, loss 0.562481.
Train: 2018-08-01T01:33:06.335797: step 26692, loss 0.512303.
Train: 2018-08-01T01:33:06.492012: step 26693, loss 0.612752.
Train: 2018-08-01T01:33:06.679468: step 26694, loss 0.579241.
Train: 2018-08-01T01:33:06.835680: step 26695, loss 0.629713.
Train: 2018-08-01T01:33:07.007484: step 26696, loss 0.612916.
Train: 2018-08-01T01:33:07.163728: step 26697, loss 0.596085.
Train: 2018-08-01T01:33:07.319936: step 26698, loss 0.69695.
Train: 2018-08-01T01:33:07.476155: step 26699, loss 0.562452.
Train: 2018-08-01T01:33:07.647989: step 26700, loss 0.528969.
Test: 2018-08-01T01:33:08.116599: step 26700, loss 0.548462.
Train: 2018-08-01T01:33:08.835181: step 26701, loss 0.495564.
Train: 2018-08-01T01:33:08.991427: step 26702, loss 0.579193.
Train: 2018-08-01T01:33:09.147639: step 26703, loss 0.462154.
Train: 2018-08-01T01:33:09.303852: step 26704, loss 0.528987.
Train: 2018-08-01T01:33:09.460035: step 26705, loss 0.512165.
Train: 2018-08-01T01:33:09.616249: step 26706, loss 0.612842.
Train: 2018-08-01T01:33:09.788084: step 26707, loss 0.495159.
Train: 2018-08-01T01:33:09.959919: step 26708, loss 0.579287.
Train: 2018-08-01T01:33:10.116132: step 26709, loss 0.596192.
Train: 2018-08-01T01:33:10.272345: step 26710, loss 0.511713.
Test: 2018-08-01T01:33:10.740984: step 26710, loss 0.548238.
Train: 2018-08-01T01:33:10.897223: step 26711, loss 0.664006.
Train: 2018-08-01T01:33:11.069064: step 26712, loss 0.562415.
Train: 2018-08-01T01:33:11.225247: step 26713, loss 0.528531.
Train: 2018-08-01T01:33:11.381460: step 26714, loss 0.647181.
Train: 2018-08-01T01:33:11.537674: step 26715, loss 0.562413.
Train: 2018-08-01T01:33:11.693887: step 26716, loss 0.596299.
Train: 2018-08-01T01:33:11.850100: step 26717, loss 0.545485.
Train: 2018-08-01T01:33:11.990693: step 26718, loss 0.545492.
Train: 2018-08-01T01:33:12.162528: step 26719, loss 0.596265.
Train: 2018-08-01T01:33:12.318740: step 26720, loss 0.697749.
Test: 2018-08-01T01:33:12.787411: step 26720, loss 0.54829.
Train: 2018-08-01T01:33:12.943625: step 26721, loss 0.629951.
Train: 2018-08-01T01:33:13.099838: step 26722, loss 0.596108.
Train: 2018-08-01T01:33:13.271668: step 26723, loss 0.512082.
Train: 2018-08-01T01:33:13.427886: step 26724, loss 0.495424.
Train: 2018-08-01T01:33:13.584100: step 26725, loss 0.512222.
Train: 2018-08-01T01:33:13.740316: step 26726, loss 0.528965.
Train: 2018-08-01T01:33:13.896526: step 26727, loss 0.528943.
Train: 2018-08-01T01:33:14.052740: step 26728, loss 0.596002.
Train: 2018-08-01T01:33:14.208923: step 26729, loss 0.629584.
Train: 2018-08-01T01:33:14.380757: step 26730, loss 0.512117.
Test: 2018-08-01T01:33:14.849427: step 26730, loss 0.548393.
Train: 2018-08-01T01:33:15.005641: step 26731, loss 0.545664.
Train: 2018-08-01T01:33:15.161826: step 26732, loss 0.512056.
Train: 2018-08-01T01:33:15.318068: step 26733, loss 0.596078.
Train: 2018-08-01T01:33:15.474284: step 26734, loss 0.444612.
Train: 2018-08-01T01:33:15.646110: step 26735, loss 0.596169.
Train: 2018-08-01T01:33:15.802300: step 26736, loss 0.579321.
Train: 2018-08-01T01:33:15.958544: step 26737, loss 0.562418.
Train: 2018-08-01T01:33:16.114727: step 26738, loss 0.477706.
Train: 2018-08-01T01:33:16.270970: step 26739, loss 0.52845.
Train: 2018-08-01T01:33:16.427184: step 26740, loss 0.681547.
Test: 2018-08-01T01:33:16.895824: step 26740, loss 0.548139.
Train: 2018-08-01T01:33:17.052038: step 26741, loss 0.477238.
Train: 2018-08-01T01:33:17.208220: step 26742, loss 0.477088.
Train: 2018-08-01T01:33:17.364466: step 26743, loss 0.630826.
Train: 2018-08-01T01:33:17.520683: step 26744, loss 0.510997.
Train: 2018-08-01T01:33:17.692507: step 26745, loss 0.459391.
Train: 2018-08-01T01:33:17.848728: step 26746, loss 0.545178.
Train: 2018-08-01T01:33:18.004940: step 26747, loss 0.596943.
Train: 2018-08-01T01:33:18.161122: step 26748, loss 0.527787.
Train: 2018-08-01T01:33:18.317360: step 26749, loss 0.458311.
Train: 2018-08-01T01:33:18.473550: step 26750, loss 0.527604.
Test: 2018-08-01T01:33:18.942189: step 26750, loss 0.547807.
Train: 2018-08-01T01:33:19.098428: step 26751, loss 0.632301.
Train: 2018-08-01T01:33:19.254644: step 26752, loss 0.509929.
Train: 2018-08-01T01:33:19.410860: step 26753, loss 0.562455.
Train: 2018-08-01T01:33:19.567044: step 26754, loss 0.527294.
Train: 2018-08-01T01:33:19.723257: step 26755, loss 0.544854.
Train: 2018-08-01T01:33:19.895092: step 26756, loss 0.544829.
Train: 2018-08-01T01:33:20.051305: step 26757, loss 0.61562.
Train: 2018-08-01T01:33:20.207518: step 26758, loss 0.651142.
Train: 2018-08-01T01:33:20.363764: step 26759, loss 0.580243.
Train: 2018-08-01T01:33:20.535567: step 26760, loss 0.562517.
Test: 2018-08-01T01:33:21.004236: step 26760, loss 0.547683.
Train: 2018-08-01T01:33:21.160450: step 26761, loss 0.527091.
Train: 2018-08-01T01:33:21.316633: step 26762, loss 0.686489.
Train: 2018-08-01T01:33:21.472877: step 26763, loss 0.562502.
Train: 2018-08-01T01:33:21.644681: step 26764, loss 0.527177.
Train: 2018-08-01T01:33:21.785304: step 26765, loss 0.456644.
Train: 2018-08-01T01:33:21.941517: step 26766, loss 0.703647.
Train: 2018-08-01T01:33:22.128943: step 26767, loss 0.580097.
Train: 2018-08-01T01:33:22.285157: step 26768, loss 0.527287.
Train: 2018-08-01T01:33:22.425749: step 26769, loss 0.544891.
Train: 2018-08-01T01:33:22.581986: step 26770, loss 0.597569.
Test: 2018-08-01T01:33:23.066224: step 26770, loss 0.547768.
Train: 2018-08-01T01:33:23.222437: step 26771, loss 0.579985.
Train: 2018-08-01T01:33:23.378650: step 26772, loss 0.720032.
Train: 2018-08-01T01:33:23.534863: step 26773, loss 0.56243.
Train: 2018-08-01T01:33:23.691108: step 26774, loss 0.527612.
Train: 2018-08-01T01:33:23.847321: step 26775, loss 0.545048.
Train: 2018-08-01T01:33:24.003504: step 26776, loss 0.597074.
Train: 2018-08-01T01:33:24.159754: step 26777, loss 0.562404.
Train: 2018-08-01T01:33:24.331582: step 26778, loss 0.631452.
Train: 2018-08-01T01:33:24.487798: step 26779, loss 0.424653.
Train: 2018-08-01T01:33:24.644010: step 26780, loss 0.476364.
Test: 2018-08-01T01:33:25.112652: step 26780, loss 0.547983.
Train: 2018-08-01T01:33:25.268865: step 26781, loss 0.476327.
Train: 2018-08-01T01:33:25.456314: step 26782, loss 0.493444.
Train: 2018-08-01T01:33:25.596882: step 26783, loss 0.614226.
Train: 2018-08-01T01:33:25.753125: step 26784, loss 0.458625.
Train: 2018-08-01T01:33:25.909339: step 26785, loss 0.579746.
Train: 2018-08-01T01:33:26.065522: step 26786, loss 0.562414.
Train: 2018-08-01T01:33:26.221765: step 26787, loss 0.545021.
Train: 2018-08-01T01:33:26.377950: step 26788, loss 0.457863.
Train: 2018-08-01T01:33:26.549783: step 26789, loss 0.562435.
Train: 2018-08-01T01:33:26.721642: step 26790, loss 0.57996.
Test: 2018-08-01T01:33:27.190288: step 26790, loss 0.547761.
Train: 2018-08-01T01:33:27.330850: step 26791, loss 0.544908.
Train: 2018-08-01T01:33:27.502710: step 26792, loss 0.615201.
Train: 2018-08-01T01:33:27.658929: step 26793, loss 0.580065.
Train: 2018-08-01T01:33:27.815111: step 26794, loss 0.703318.
Train: 2018-08-01T01:33:27.971325: step 26795, loss 0.509712.
Train: 2018-08-01T01:33:28.127569: step 26796, loss 0.65034.
Train: 2018-08-01T01:33:28.283752: step 26797, loss 0.650195.
Train: 2018-08-01T01:33:28.439966: step 26798, loss 0.667469.
Train: 2018-08-01T01:33:28.596180: step 26799, loss 0.492657.
Train: 2018-08-01T01:33:28.768038: step 26800, loss 0.632021.
Test: 2018-08-01T01:33:29.236686: step 26800, loss 0.547884.
Train: 2018-08-01T01:33:29.923993: step 26801, loss 0.579758.
Train: 2018-08-01T01:33:30.080206: step 26802, loss 0.5797.
Train: 2018-08-01T01:33:30.252065: step 26803, loss 0.648627.
Train: 2018-08-01T01:33:30.392633: step 26804, loss 0.562396.
Train: 2018-08-01T01:33:30.548846: step 26805, loss 0.579521.
Train: 2018-08-01T01:33:30.705090: step 26806, loss 0.579469.
Train: 2018-08-01T01:33:30.876895: step 26807, loss 0.494338.
Train: 2018-08-01T01:33:31.033134: step 26808, loss 0.528441.
Train: 2018-08-01T01:33:31.189321: step 26809, loss 0.579372.
Train: 2018-08-01T01:33:31.345534: step 26810, loss 0.49466.
Test: 2018-08-01T01:33:31.814205: step 26810, loss 0.548236.
Train: 2018-08-01T01:33:32.001667: step 26811, loss 0.647081.
Train: 2018-08-01T01:33:32.157875: step 26812, loss 0.663884.
Train: 2018-08-01T01:33:32.329680: step 26813, loss 0.528689.
Train: 2018-08-01T01:33:32.485893: step 26814, loss 0.612957.
Train: 2018-08-01T01:33:32.642106: step 26815, loss 0.512029.
Train: 2018-08-01T01:33:32.798319: step 26816, loss 0.596018.
Train: 2018-08-01T01:33:32.954561: step 26817, loss 0.4619.
Train: 2018-08-01T01:33:33.126367: step 26818, loss 0.562457.
Train: 2018-08-01T01:33:33.282581: step 26819, loss 0.629503.
Train: 2018-08-01T01:33:33.454415: step 26820, loss 0.478712.
Test: 2018-08-01T01:33:33.923086: step 26820, loss 0.548425.
Train: 2018-08-01T01:33:34.094918: step 26821, loss 0.579216.
Train: 2018-08-01T01:33:34.251135: step 26822, loss 0.545693.
Train: 2018-08-01T01:33:34.407348: step 26823, loss 0.646315.
Train: 2018-08-01T01:33:34.563531: step 26824, loss 0.528928.
Train: 2018-08-01T01:33:34.719777: step 26825, loss 0.545691.
Train: 2018-08-01T01:33:34.875988: step 26826, loss 0.478607.
Train: 2018-08-01T01:33:35.032202: step 26827, loss 0.596034.
Train: 2018-08-01T01:33:35.204008: step 26828, loss 0.612868.
Train: 2018-08-01T01:33:35.360252: step 26829, loss 0.596066.
Train: 2018-08-01T01:33:35.516433: step 26830, loss 0.562443.
Test: 2018-08-01T01:33:35.985073: step 26830, loss 0.548369.
Train: 2018-08-01T01:33:36.141287: step 26831, loss 0.51202.
Train: 2018-08-01T01:33:36.313123: step 26832, loss 0.629713.
Train: 2018-08-01T01:33:36.469365: step 26833, loss 0.528813.
Train: 2018-08-01T01:33:36.625579: step 26834, loss 0.629714.
Train: 2018-08-01T01:33:36.781786: step 26835, loss 0.495207.
Train: 2018-08-01T01:33:36.938007: step 26836, loss 0.545625.
Train: 2018-08-01T01:33:37.094188: step 26837, loss 0.596092.
Train: 2018-08-01T01:33:37.266023: step 26838, loss 0.545607.
Train: 2018-08-01T01:33:37.422238: step 26839, loss 0.697136.
Train: 2018-08-01T01:33:37.562860: step 26840, loss 0.528808.
Test: 2018-08-01T01:33:38.031468: step 26840, loss 0.548371.
Train: 2018-08-01T01:33:38.187684: step 26841, loss 0.545638.
Train: 2018-08-01T01:33:38.343926: step 26842, loss 0.495244.
Train: 2018-08-01T01:33:38.500135: step 26843, loss 0.68012.
Train: 2018-08-01T01:33:38.671974: step 26844, loss 0.428074.
Train: 2018-08-01T01:33:38.828187: step 26845, loss 0.545629.
Train: 2018-08-01T01:33:38.984403: step 26846, loss 0.562437.
Train: 2018-08-01T01:33:39.140616: step 26847, loss 0.511879.
Train: 2018-08-01T01:33:39.296797: step 26848, loss 0.511788.
Train: 2018-08-01T01:33:39.453011: step 26849, loss 0.697748.
Train: 2018-08-01T01:33:39.624846: step 26850, loss 0.528575.
Test: 2018-08-01T01:33:40.109108: step 26850, loss 0.548235.
Train: 2018-08-01T01:33:40.265351: step 26851, loss 0.596283.
Train: 2018-08-01T01:33:40.421535: step 26852, loss 0.562415.
Train: 2018-08-01T01:33:40.577778: step 26853, loss 0.562414.
Train: 2018-08-01T01:33:40.749619: step 26854, loss 0.392931.
Train: 2018-08-01T01:33:40.905821: step 26855, loss 0.613374.
Train: 2018-08-01T01:33:41.062040: step 26856, loss 0.596435.
Train: 2018-08-01T01:33:41.233844: step 26857, loss 0.494273.
Train: 2018-08-01T01:33:41.390064: step 26858, loss 0.528275.
Train: 2018-08-01T01:33:41.546302: step 26859, loss 0.579494.
Train: 2018-08-01T01:33:41.702523: step 26860, loss 0.596645.
Test: 2018-08-01T01:33:42.186776: step 26860, loss 0.548042.
Train: 2018-08-01T01:33:42.342992: step 26861, loss 0.579538.
Train: 2018-08-01T01:33:42.499172: step 26862, loss 0.528087.
Train: 2018-08-01T01:33:42.655417: step 26863, loss 0.596742.
Train: 2018-08-01T01:33:42.827246: step 26864, loss 0.493668.
Train: 2018-08-01T01:33:42.983459: step 26865, loss 0.614011.
Train: 2018-08-01T01:33:43.139674: step 26866, loss 0.631254.
Train: 2018-08-01T01:33:43.295861: step 26867, loss 0.527981.
Train: 2018-08-01T01:33:43.452074: step 26868, loss 0.493558.
Train: 2018-08-01T01:33:43.608288: step 26869, loss 0.6313.
Train: 2018-08-01T01:33:43.764532: step 26870, loss 0.562398.
Test: 2018-08-01T01:33:44.233174: step 26870, loss 0.547974.
Train: 2018-08-01T01:33:44.389356: step 26871, loss 0.648521.
Train: 2018-08-01T01:33:44.561215: step 26872, loss 0.545191.
Train: 2018-08-01T01:33:44.717404: step 26873, loss 0.596782.
Train: 2018-08-01T01:33:44.858029: step 26874, loss 0.562396.
Train: 2018-08-01T01:33:45.029860: step 26875, loss 0.562396.
Train: 2018-08-01T01:33:45.201704: step 26876, loss 0.476694.
Train: 2018-08-01T01:33:45.357912: step 26877, loss 0.528107.
Train: 2018-08-01T01:33:45.514121: step 26878, loss 0.613862.
Train: 2018-08-01T01:33:45.670305: step 26879, loss 0.476626.
Train: 2018-08-01T01:33:45.826519: step 26880, loss 0.545225.
Test: 2018-08-01T01:33:46.295189: step 26880, loss 0.548002.
Train: 2018-08-01T01:33:46.467027: step 26881, loss 0.476447.
Train: 2018-08-01T01:33:46.623207: step 26882, loss 0.596847.
Train: 2018-08-01T01:33:46.779420: step 26883, loss 0.527902.
Train: 2018-08-01T01:33:46.951255: step 26884, loss 0.63151.
Train: 2018-08-01T01:33:47.107501: step 26885, loss 0.683419.
Train: 2018-08-01T01:33:47.294950: step 26886, loss 0.596946.
Train: 2018-08-01T01:33:47.451140: step 26887, loss 0.527898.
Train: 2018-08-01T01:33:47.607353: step 26888, loss 0.493445.
Train: 2018-08-01T01:33:47.763592: step 26889, loss 0.424469.
Train: 2018-08-01T01:33:47.919779: step 26890, loss 0.596946.
Test: 2018-08-01T01:33:48.404070: step 26890, loss 0.547923.
Train: 2018-08-01T01:33:48.560283: step 26891, loss 0.579696.
Train: 2018-08-01T01:33:48.716467: step 26892, loss 0.441256.
Train: 2018-08-01T01:33:48.872680: step 26893, loss 0.631788.
Train: 2018-08-01T01:33:49.044516: step 26894, loss 0.614503.
Train: 2018-08-01T01:33:49.200730: step 26895, loss 0.406088.
Train: 2018-08-01T01:33:49.356975: step 26896, loss 0.492795.
Train: 2018-08-01T01:33:49.528777: step 26897, loss 0.579883.
Train: 2018-08-01T01:33:49.684991: step 26898, loss 0.632401.
Train: 2018-08-01T01:33:49.841203: step 26899, loss 0.562444.
Train: 2018-08-01T01:33:49.997417: step 26900, loss 0.579973.
Test: 2018-08-01T01:33:50.497333: step 26900, loss 0.547768.
Train: 2018-08-01T01:33:51.184670: step 26901, loss 0.492312.
Train: 2018-08-01T01:33:51.340883: step 26902, loss 0.527344.
Train: 2018-08-01T01:33:51.497096: step 26903, loss 0.615213.
Train: 2018-08-01T01:33:51.668932: step 26904, loss 0.544875.
Train: 2018-08-01T01:33:51.825145: step 26905, loss 0.509654.
Train: 2018-08-01T01:33:51.996950: step 26906, loss 0.527226.
Train: 2018-08-01T01:33:52.153163: step 26907, loss 0.509534.
Train: 2018-08-01T01:33:52.309400: step 26908, loss 0.615556.
Train: 2018-08-01T01:33:52.465589: step 26909, loss 0.597909.
Train: 2018-08-01T01:33:52.621833: step 26910, loss 0.668746.
Test: 2018-08-01T01:33:53.106064: step 26910, loss 0.547692.
Train: 2018-08-01T01:33:53.262278: step 26911, loss 0.527128.
Train: 2018-08-01T01:33:53.418521: step 26912, loss 0.5625.
Train: 2018-08-01T01:33:53.574706: step 26913, loss 0.580164.
Train: 2018-08-01T01:33:53.730950: step 26914, loss 0.509531.
Train: 2018-08-01T01:33:53.902753: step 26915, loss 0.562489.
Train: 2018-08-01T01:33:54.058996: step 26916, loss 0.597777.
Train: 2018-08-01T01:33:54.215212: step 26917, loss 0.527218.
Train: 2018-08-01T01:33:54.371423: step 26918, loss 0.597735.
Train: 2018-08-01T01:33:54.527606: step 26919, loss 0.474409.
Train: 2018-08-01T01:33:54.699471: step 26920, loss 0.474388.
Test: 2018-08-01T01:33:55.183736: step 26920, loss 0.547715.
Train: 2018-08-01T01:33:55.339946: step 26921, loss 0.562485.
Train: 2018-08-01T01:33:55.496166: step 26922, loss 0.544836.
Train: 2018-08-01T01:33:55.652373: step 26923, loss 0.544825.
Train: 2018-08-01T01:33:55.808587: step 26924, loss 0.633276.
Train: 2018-08-01T01:33:55.964802: step 26925, loss 0.52712.
Train: 2018-08-01T01:33:56.121016: step 26926, loss 0.597907.
Train: 2018-08-01T01:33:56.277227: step 26927, loss 0.474026.
Train: 2018-08-01T01:33:56.449062: step 26928, loss 0.544804.
Train: 2018-08-01T01:33:56.605245: step 26929, loss 0.72204.
Train: 2018-08-01T01:33:56.761483: step 26930, loss 0.456289.
Test: 2018-08-01T01:33:57.230131: step 26930, loss 0.547685.
Train: 2018-08-01T01:33:57.386313: step 26931, loss 0.544806.
Train: 2018-08-01T01:33:57.542526: step 26932, loss 0.580221.
Train: 2018-08-01T01:33:57.714360: step 26933, loss 0.651042.
Train: 2018-08-01T01:33:57.870574: step 26934, loss 0.633242.
Train: 2018-08-01T01:33:58.011167: step 26935, loss 0.438941.
Train: 2018-08-01T01:33:58.183001: step 26936, loss 0.491918.
Train: 2018-08-01T01:33:58.339213: step 26937, loss 0.509545.
Train: 2018-08-01T01:33:58.495464: step 26938, loss 0.580157.
Train: 2018-08-01T01:33:58.651671: step 26939, loss 0.527155.
Train: 2018-08-01T01:33:58.807855: step 26940, loss 0.527134.
Test: 2018-08-01T01:33:59.292146: step 26940, loss 0.547687.
Train: 2018-08-01T01:33:59.448329: step 26941, loss 0.56251.
Train: 2018-08-01T01:33:59.604543: step 26942, loss 0.527083.
Train: 2018-08-01T01:33:59.760757: step 26943, loss 0.509319.
Train: 2018-08-01T01:33:59.916969: step 26944, loss 0.562536.
Train: 2018-08-01T01:34:00.073183: step 26945, loss 0.544763.
Train: 2018-08-01T01:34:00.229429: step 26946, loss 0.562556.
Train: 2018-08-01T01:34:00.385635: step 26947, loss 0.526922.
Train: 2018-08-01T01:34:00.541824: step 26948, loss 0.669632.
Train: 2018-08-01T01:34:00.698067: step 26949, loss 0.616088.
Train: 2018-08-01T01:34:00.854281: step 26950, loss 0.473456.
Test: 2018-08-01T01:34:01.322920: step 26950, loss 0.547641.
Train: 2018-08-01T01:34:01.494725: step 26951, loss 0.544743.
Train: 2018-08-01T01:34:01.650938: step 26952, loss 0.598219.
Train: 2018-08-01T01:34:01.807153: step 26953, loss 0.509106.
Train: 2018-08-01T01:34:01.963365: step 26954, loss 0.45563.
Train: 2018-08-01T01:34:02.119579: step 26955, loss 0.509042.
Train: 2018-08-01T01:34:02.275792: step 26956, loss 0.580467.
Train: 2018-08-01T01:34:02.432036: step 26957, loss 0.455234.
Train: 2018-08-01T01:34:02.603840: step 26958, loss 0.52676.
Train: 2018-08-01T01:34:02.744462: step 26959, loss 0.472787.
Train: 2018-08-01T01:34:02.916298: step 26960, loss 0.544659.
Test: 2018-08-01T01:34:03.384907: step 26960, loss 0.547582.
Train: 2018-08-01T01:34:03.541151: step 26961, loss 0.580785.
Train: 2018-08-01T01:34:03.712980: step 26962, loss 0.508418.
Train: 2018-08-01T01:34:03.869193: step 26963, loss 0.490177.
Train: 2018-08-01T01:34:04.025383: step 26964, loss 0.508217.
Train: 2018-08-01T01:34:04.181626: step 26965, loss 0.617595.
Train: 2018-08-01T01:34:04.353463: step 26966, loss 0.581158.
Train: 2018-08-01T01:34:04.509675: step 26967, loss 0.489679.
Train: 2018-08-01T01:34:04.665889: step 26968, loss 0.526252.
Train: 2018-08-01T01:34:04.837693: step 26969, loss 0.709904.
Train: 2018-08-01T01:34:04.993906: step 26970, loss 0.801711.
Test: 2018-08-01T01:34:05.462545: step 26970, loss 0.547569.
Train: 2018-08-01T01:34:05.618758: step 26971, loss 0.562905.
Train: 2018-08-01T01:34:05.775003: step 26972, loss 0.526333.
Train: 2018-08-01T01:34:05.962461: step 26973, loss 0.599277.
Train: 2018-08-01T01:34:06.118666: step 26974, loss 0.58097.
Train: 2018-08-01T01:34:06.274856: step 26975, loss 0.544627.
Train: 2018-08-01T01:34:06.431068: step 26976, loss 0.526552.
Train: 2018-08-01T01:34:06.587312: step 26977, loss 0.526596.
Train: 2018-08-01T01:34:06.743526: step 26978, loss 0.508602.
Train: 2018-08-01T01:34:06.915369: step 26979, loss 0.490624.
Train: 2018-08-01T01:34:07.071544: step 26980, loss 0.598697.
Test: 2018-08-01T01:34:07.555805: step 26980, loss 0.547594.
Train: 2018-08-01T01:34:07.712052: step 26981, loss 0.544667.
Train: 2018-08-01T01:34:07.868233: step 26982, loss 0.508684.
Train: 2018-08-01T01:34:08.024447: step 26983, loss 0.508682.
Train: 2018-08-01T01:34:08.196286: step 26984, loss 0.670687.
Train: 2018-08-01T01:34:08.352494: step 26985, loss 0.47272.
Train: 2018-08-01T01:34:08.508708: step 26986, loss 0.58065.
Train: 2018-08-01T01:34:08.664920: step 26987, loss 0.616614.
Train: 2018-08-01T01:34:08.821166: step 26988, loss 0.544679.
Train: 2018-08-01T01:34:08.977348: step 26989, loss 0.526729.
Train: 2018-08-01T01:34:09.164805: step 26990, loss 0.59853.
Test: 2018-08-01T01:34:09.633445: step 26990, loss 0.547609.
Train: 2018-08-01T01:34:09.789687: step 26991, loss 0.508829.
Train: 2018-08-01T01:34:09.945901: step 26992, loss 0.6164.
Train: 2018-08-01T01:34:10.102084: step 26993, loss 0.670061.
Train: 2018-08-01T01:34:10.258297: step 26994, loss 0.526852.
Train: 2018-08-01T01:34:10.414510: step 26995, loss 0.616088.
Train: 2018-08-01T01:34:10.570725: step 26996, loss 0.633747.
Train: 2018-08-01T01:34:10.726970: step 26997, loss 0.686754.
Train: 2018-08-01T01:34:10.883151: step 26998, loss 0.509478.
Train: 2018-08-01T01:34:11.039364: step 26999, loss 0.59771.
Train: 2018-08-01T01:34:11.211230: step 27000, loss 0.650244.
Test: 2018-08-01T01:34:11.664243: step 27000, loss 0.547796.
Train: 2018-08-01T01:34:12.367179: step 27001, loss 0.527467.
Train: 2018-08-01T01:34:12.554635: step 27002, loss 0.614703.
Train: 2018-08-01T01:34:12.710878: step 27003, loss 0.562412.
Train: 2018-08-01T01:34:12.867092: step 27004, loss 0.614314.
Train: 2018-08-01T01:34:13.023299: step 27005, loss 0.441722.
Train: 2018-08-01T01:34:13.179519: step 27006, loss 0.527983.
Train: 2018-08-01T01:34:13.335701: step 27007, loss 0.493658.
Train: 2018-08-01T01:34:13.491916: step 27008, loss 0.545218.
Train: 2018-08-01T01:34:13.663780: step 27009, loss 0.631103.
Train: 2018-08-01T01:34:13.835584: step 27010, loss 0.562396.
Test: 2018-08-01T01:34:14.304255: step 27010, loss 0.548038.
Train: 2018-08-01T01:34:14.476060: step 27011, loss 0.510957.
Train: 2018-08-01T01:34:14.632276: step 27012, loss 0.596684.
Train: 2018-08-01T01:34:14.804138: step 27013, loss 0.630936.
Train: 2018-08-01T01:34:14.944726: step 27014, loss 0.562397.
Train: 2018-08-01T01:34:15.100946: step 27015, loss 0.562398.
Train: 2018-08-01T01:34:15.257128: step 27016, loss 0.459952.
Train: 2018-08-01T01:34:15.413370: step 27017, loss 0.596558.
Train: 2018-08-01T01:34:15.585208: step 27018, loss 0.613633.
Train: 2018-08-01T01:34:15.757037: step 27019, loss 0.528267.
Train: 2018-08-01T01:34:15.928881: step 27020, loss 0.528275.
Test: 2018-08-01T01:34:16.381893: step 27020, loss 0.548108.
Train: 2018-08-01T01:34:16.538107: step 27021, loss 0.528266.
Train: 2018-08-01T01:34:16.709912: step 27022, loss 0.528243.
Train: 2018-08-01T01:34:16.866126: step 27023, loss 0.613682.
Train: 2018-08-01T01:34:17.022369: step 27024, loss 0.476898.
Train: 2018-08-01T01:34:17.178552: step 27025, loss 0.511029.
Train: 2018-08-01T01:34:17.334790: step 27026, loss 0.596703.
Train: 2018-08-01T01:34:17.491010: step 27027, loss 0.476523.
Train: 2018-08-01T01:34:17.662838: step 27028, loss 0.545186.
Train: 2018-08-01T01:34:17.819061: step 27029, loss 0.510657.
Train: 2018-08-01T01:34:17.975242: step 27030, loss 0.579694.
Test: 2018-08-01T01:34:18.459532: step 27030, loss 0.547899.
Train: 2018-08-01T01:34:18.615715: step 27031, loss 0.527755.
Train: 2018-08-01T01:34:18.771929: step 27032, loss 0.649232.
Train: 2018-08-01T01:34:18.928172: step 27033, loss 0.545035.
Train: 2018-08-01T01:34:19.100002: step 27034, loss 0.545021.
Train: 2018-08-01T01:34:19.256214: step 27035, loss 0.510175.
Train: 2018-08-01T01:34:19.412435: step 27036, loss 0.597312.
Train: 2018-08-01T01:34:19.615511: step 27037, loss 0.597347.
Train: 2018-08-01T01:34:19.771728: step 27038, loss 0.527503.
Train: 2018-08-01T01:34:19.912317: step 27039, loss 0.492527.
Train: 2018-08-01T01:34:20.084122: step 27040, loss 0.632447.
Test: 2018-08-01T01:34:20.552761: step 27040, loss 0.547782.
Train: 2018-08-01T01:34:20.709005: step 27041, loss 0.579951.
Train: 2018-08-01T01:34:20.865220: step 27042, loss 0.544934.
Train: 2018-08-01T01:34:21.021433: step 27043, loss 0.614985.
Train: 2018-08-01T01:34:21.177645: step 27044, loss 0.509927.
Train: 2018-08-01T01:34:21.365072: step 27045, loss 0.562443.
Train: 2018-08-01T01:34:21.505693: step 27046, loss 0.562443.
Train: 2018-08-01T01:34:21.661902: step 27047, loss 0.527425.
Train: 2018-08-01T01:34:21.818121: step 27048, loss 0.597476.
Train: 2018-08-01T01:34:21.989956: step 27049, loss 0.667522.
Train: 2018-08-01T01:34:22.146169: step 27050, loss 0.492485.
Test: 2018-08-01T01:34:22.630431: step 27050, loss 0.547799.
Train: 2018-08-01T01:34:22.786644: step 27051, loss 0.579915.
Train: 2018-08-01T01:34:22.958449: step 27052, loss 0.632301.
Train: 2018-08-01T01:34:23.114662: step 27053, loss 0.544986.
Train: 2018-08-01T01:34:23.270875: step 27054, loss 0.579842.
Train: 2018-08-01T01:34:23.427090: step 27055, loss 0.510228.
Train: 2018-08-01T01:34:23.598948: step 27056, loss 0.579802.
Train: 2018-08-01T01:34:23.739540: step 27057, loss 0.52767.
Train: 2018-08-01T01:34:23.895730: step 27058, loss 0.527681.
Train: 2018-08-01T01:34:24.067588: step 27059, loss 0.492944.
Train: 2018-08-01T01:34:24.223776: step 27060, loss 0.423357.
Test: 2018-08-01T01:34:24.692448: step 27060, loss 0.547833.
Train: 2018-08-01T01:34:24.848631: step 27061, loss 0.649542.
Train: 2018-08-01T01:34:25.004874: step 27062, loss 0.527542.
Train: 2018-08-01T01:34:25.161087: step 27063, loss 0.562433.
Train: 2018-08-01T01:34:25.317301: step 27064, loss 0.632381.
Train: 2018-08-01T01:34:25.473517: step 27065, loss 0.632393.
Train: 2018-08-01T01:34:25.645319: step 27066, loss 0.579911.
Train: 2018-08-01T01:34:25.801563: step 27067, loss 0.562431.
Train: 2018-08-01T01:34:25.957746: step 27068, loss 0.562428.
Train: 2018-08-01T01:34:26.113990: step 27069, loss 0.597285.
Train: 2018-08-01T01:34:26.270203: step 27070, loss 0.614647.
Test: 2018-08-01T01:34:26.738813: step 27070, loss 0.547863.
Train: 2018-08-01T01:34:26.895027: step 27071, loss 0.562414.
Train: 2018-08-01T01:34:27.051240: step 27072, loss 0.597139.
Train: 2018-08-01T01:34:27.207454: step 27073, loss 0.666316.
Train: 2018-08-01T01:34:27.363666: step 27074, loss 0.596934.
Train: 2018-08-01T01:34:27.519881: step 27075, loss 0.424696.
Train: 2018-08-01T01:34:27.691745: step 27076, loss 0.613975.
Train: 2018-08-01T01:34:27.847929: step 27077, loss 0.49374.
Train: 2018-08-01T01:34:28.004166: step 27078, loss 0.596701.
Train: 2018-08-01T01:34:28.160385: step 27079, loss 0.579531.
Train: 2018-08-01T01:34:28.316599: step 27080, loss 0.562397.
Test: 2018-08-01T01:34:28.785239: step 27080, loss 0.54808.
Train: 2018-08-01T01:34:28.941423: step 27081, loss 0.579496.
Train: 2018-08-01T01:34:29.097668: step 27082, loss 0.545319.
Train: 2018-08-01T01:34:29.253879: step 27083, loss 0.528268.
Train: 2018-08-01T01:34:29.410064: step 27084, loss 0.664768.
Train: 2018-08-01T01:34:29.566306: step 27085, loss 0.562402.
Train: 2018-08-01T01:34:29.722523: step 27086, loss 0.647472.
Train: 2018-08-01T01:34:29.878733: step 27087, loss 0.545433.
Train: 2018-08-01T01:34:30.066185: step 27088, loss 0.545468.
Train: 2018-08-01T01:34:30.222405: step 27089, loss 0.630109.
Train: 2018-08-01T01:34:30.378586: step 27090, loss 0.562424.
Test: 2018-08-01T01:34:30.847258: step 27090, loss 0.548314.
Train: 2018-08-01T01:34:31.003470: step 27091, loss 0.562431.
Train: 2018-08-01T01:34:31.175274: step 27092, loss 0.629766.
Train: 2018-08-01T01:34:31.315866: step 27093, loss 0.612832.
Train: 2018-08-01T01:34:31.472080: step 27094, loss 0.512204.
Train: 2018-08-01T01:34:31.628324: step 27095, loss 0.545743.
Train: 2018-08-01T01:34:31.800154: step 27096, loss 0.579183.
Train: 2018-08-01T01:34:31.940750: step 27097, loss 0.629225.
Train: 2018-08-01T01:34:32.112555: step 27098, loss 0.562494.
Train: 2018-08-01T01:34:32.284389: step 27099, loss 0.529248.
Train: 2018-08-01T01:34:32.440603: step 27100, loss 0.61235.
Test: 2018-08-01T01:34:32.893622: step 27100, loss 0.548629.
Train: 2018-08-01T01:34:33.596615: step 27101, loss 0.71183.
Train: 2018-08-01T01:34:33.752826: step 27102, loss 0.628699.
Train: 2018-08-01T01:34:33.909010: step 27103, loss 0.562574.
Train: 2018-08-01T01:34:34.065224: step 27104, loss 0.464032.
Train: 2018-08-01T01:34:34.221468: step 27105, loss 0.579021.
Train: 2018-08-01T01:34:34.393271: step 27106, loss 0.579012.
Train: 2018-08-01T01:34:34.533862: step 27107, loss 0.644458.
Train: 2018-08-01T01:34:34.690076: step 27108, loss 0.627978.
Train: 2018-08-01T01:34:34.846322: step 27109, loss 0.692976.
Train: 2018-08-01T01:34:35.002503: step 27110, loss 0.562737.
Test: 2018-08-01T01:34:35.486796: step 27110, loss 0.549244.
Train: 2018-08-01T01:34:35.643008: step 27111, loss 0.562779.
Train: 2018-08-01T01:34:35.799216: step 27112, loss 0.530584.
Train: 2018-08-01T01:34:35.955404: step 27113, loss 0.562844.
Train: 2018-08-01T01:34:36.111644: step 27114, loss 0.578924.
Train: 2018-08-01T01:34:36.267831: step 27115, loss 0.514789.
Train: 2018-08-01T01:34:36.439666: step 27116, loss 0.498795.
Train: 2018-08-01T01:34:36.595880: step 27117, loss 0.530815.
Train: 2018-08-01T01:34:36.752094: step 27118, loss 0.466537.
Train: 2018-08-01T01:34:36.908337: step 27119, loss 0.627223.
Train: 2018-08-01T01:34:37.064551: step 27120, loss 0.514438.
Test: 2018-08-01T01:34:37.533190: step 27120, loss 0.549247.
Train: 2018-08-01T01:34:37.704996: step 27121, loss 0.530457.
Train: 2018-08-01T01:34:37.861240: step 27122, loss 0.497923.
Train: 2018-08-01T01:34:38.017452: step 27123, loss 0.578969.
Train: 2018-08-01T01:34:38.173667: step 27124, loss 0.611611.
Train: 2018-08-01T01:34:38.329881: step 27125, loss 0.56265.
Train: 2018-08-01T01:34:38.486062: step 27126, loss 0.579012.
Train: 2018-08-01T01:34:38.657927: step 27127, loss 0.595439.
Train: 2018-08-01T01:34:38.829732: step 27128, loss 0.628343.
Train: 2018-08-01T01:34:38.985945: step 27129, loss 0.595481.
Train: 2018-08-01T01:34:39.142159: step 27130, loss 0.644819.
Test: 2018-08-01T01:34:39.610799: step 27130, loss 0.548842.
Train: 2018-08-01T01:34:39.767012: step 27131, loss 0.562601.
Train: 2018-08-01T01:34:39.938847: step 27132, loss 0.464091.
Train: 2018-08-01T01:34:40.095061: step 27133, loss 0.464001.
Train: 2018-08-01T01:34:40.251275: step 27134, loss 0.496704.
Train: 2018-08-01T01:34:40.407517: step 27135, loss 0.546037.
Train: 2018-08-01T01:34:40.563731: step 27136, loss 0.645363.
Train: 2018-08-01T01:34:40.719939: step 27137, loss 0.579113.
Train: 2018-08-01T01:34:40.891750: step 27138, loss 0.512657.
Train: 2018-08-01T01:34:41.063584: step 27139, loss 0.662397.
Train: 2018-08-01T01:34:41.219836: step 27140, loss 0.579151.
Test: 2018-08-01T01:34:41.704088: step 27140, loss 0.548533.
Train: 2018-08-01T01:34:41.860272: step 27141, loss 0.629154.
Train: 2018-08-01T01:34:42.016518: step 27142, loss 0.579151.
Train: 2018-08-01T01:34:42.188322: step 27143, loss 0.529195.
Train: 2018-08-01T01:34:42.344533: step 27144, loss 0.529193.
Train: 2018-08-01T01:34:42.500778: step 27145, loss 0.495851.
Train: 2018-08-01T01:34:42.672581: step 27146, loss 0.545798.
Train: 2018-08-01T01:34:42.828825: step 27147, loss 0.562473.
Train: 2018-08-01T01:34:42.985040: step 27148, loss 0.528992.
Train: 2018-08-01T01:34:43.141258: step 27149, loss 0.545688.
Train: 2018-08-01T01:34:43.297466: step 27150, loss 0.629645.
Test: 2018-08-01T01:34:43.781727: step 27150, loss 0.54836.
Train: 2018-08-01T01:34:43.937911: step 27151, loss 0.461546.
Train: 2018-08-01T01:34:44.094156: step 27152, loss 0.528726.
Train: 2018-08-01T01:34:44.265986: step 27153, loss 0.646892.
Train: 2018-08-01T01:34:44.406552: step 27154, loss 0.562419.
Train: 2018-08-01T01:34:44.578410: step 27155, loss 0.579348.
Train: 2018-08-01T01:34:44.734630: step 27156, loss 0.579359.
Train: 2018-08-01T01:34:44.890812: step 27157, loss 0.647189.
Train: 2018-08-01T01:34:45.047056: step 27158, loss 0.477681.
Train: 2018-08-01T01:34:45.203240: step 27159, loss 0.630239.
Train: 2018-08-01T01:34:45.390695: step 27160, loss 0.613269.
Test: 2018-08-01T01:34:45.859365: step 27160, loss 0.548231.
Train: 2018-08-01T01:34:46.015579: step 27161, loss 0.562414.
Train: 2018-08-01T01:34:46.171792: step 27162, loss 0.613194.
Train: 2018-08-01T01:34:46.328009: step 27163, loss 0.646945.
Train: 2018-08-01T01:34:46.515463: step 27164, loss 0.545559.
Train: 2018-08-01T01:34:46.671675: step 27165, loss 0.596115.
Train: 2018-08-01T01:34:46.827892: step 27166, loss 0.612868.
Train: 2018-08-01T01:34:46.984107: step 27167, loss 0.579224.
Train: 2018-08-01T01:34:47.140316: step 27168, loss 0.562465.
Train: 2018-08-01T01:34:47.296535: step 27169, loss 0.445573.
Train: 2018-08-01T01:34:47.452746: step 27170, loss 0.629269.
Test: 2018-08-01T01:34:47.937004: step 27170, loss 0.548513.
Train: 2018-08-01T01:34:48.093220: step 27171, loss 0.47907.
Train: 2018-08-01T01:34:48.249400: step 27172, loss 0.529105.
Train: 2018-08-01T01:34:48.405644: step 27173, loss 0.562476.
Train: 2018-08-01T01:34:48.561829: step 27174, loss 0.579186.
Train: 2018-08-01T01:34:48.749284: step 27175, loss 0.629366.
Train: 2018-08-01T01:34:48.905530: step 27176, loss 0.51231.
Train: 2018-08-01T01:34:49.061712: step 27177, loss 0.478828.
Train: 2018-08-01T01:34:49.217956: step 27178, loss 0.545704.
Train: 2018-08-01T01:34:49.374168: step 27179, loss 0.579233.
Train: 2018-08-01T01:34:49.530382: step 27180, loss 0.612861.
Test: 2018-08-01T01:34:50.014642: step 27180, loss 0.548358.
Train: 2018-08-01T01:34:50.170856: step 27181, loss 0.545624.
Train: 2018-08-01T01:34:50.327039: step 27182, loss 0.511944.
Train: 2018-08-01T01:34:50.483252: step 27183, loss 0.478152.
Train: 2018-08-01T01:34:50.639466: step 27184, loss 0.545525.
Train: 2018-08-01T01:34:50.795690: step 27185, loss 0.5116.
Train: 2018-08-01T01:34:50.967552: step 27186, loss 0.630354.
Train: 2018-08-01T01:34:51.123729: step 27187, loss 0.511354.
Train: 2018-08-01T01:34:51.279966: step 27188, loss 0.630618.
Train: 2018-08-01T01:34:51.436180: step 27189, loss 0.562398.
Train: 2018-08-01T01:34:51.592400: step 27190, loss 0.476933.
Test: 2018-08-01T01:34:52.076662: step 27190, loss 0.548054.
Train: 2018-08-01T01:34:52.232873: step 27191, loss 0.630906.
Train: 2018-08-01T01:34:52.389056: step 27192, loss 0.545251.
Train: 2018-08-01T01:34:52.545300: step 27193, loss 0.407927.
Train: 2018-08-01T01:34:52.701514: step 27194, loss 0.527972.
Train: 2018-08-01T01:34:52.857697: step 27195, loss 0.545136.
Train: 2018-08-01T01:34:53.029568: step 27196, loss 0.527778.
Train: 2018-08-01T01:34:53.185775: step 27197, loss 0.597142.
Train: 2018-08-01T01:34:53.341959: step 27198, loss 0.597226.
Train: 2018-08-01T01:34:53.498202: step 27199, loss 0.544994.
Train: 2018-08-01T01:34:53.654410: step 27200, loss 0.597345.
Test: 2018-08-01T01:34:54.123060: step 27200, loss 0.547802.
Train: 2018-08-01T01:34:54.825987: step 27201, loss 0.562434.
Train: 2018-08-01T01:34:54.982200: step 27202, loss 0.649873.
Train: 2018-08-01T01:34:55.138414: step 27203, loss 0.562436.
Train: 2018-08-01T01:34:55.310248: step 27204, loss 0.579908.
Train: 2018-08-01T01:34:55.466485: step 27205, loss 0.544969.
Train: 2018-08-01T01:34:55.622710: step 27206, loss 0.562438.
Train: 2018-08-01T01:34:55.778912: step 27207, loss 0.614776.
Train: 2018-08-01T01:34:55.935132: step 27208, loss 0.614719.
Train: 2018-08-01T01:34:56.091347: step 27209, loss 0.545016.
Train: 2018-08-01T01:34:56.247558: step 27210, loss 0.649323.
Test: 2018-08-01T01:34:56.731819: step 27210, loss 0.547887.
Train: 2018-08-01T01:34:56.888027: step 27211, loss 0.683811.
Train: 2018-08-01T01:34:57.044216: step 27212, loss 0.631533.
Train: 2018-08-01T01:34:57.200463: step 27213, loss 0.631252.
Train: 2018-08-01T01:34:57.356643: step 27214, loss 0.562397.
Train: 2018-08-01T01:34:57.544099: step 27215, loss 0.494129.
Train: 2018-08-01T01:34:57.684693: step 27216, loss 0.494323.
Train: 2018-08-01T01:34:57.840906: step 27217, loss 0.494438.
Train: 2018-08-01T01:34:57.997118: step 27218, loss 0.545426.
Train: 2018-08-01T01:34:58.168952: step 27219, loss 0.596363.
Train: 2018-08-01T01:34:58.325197: step 27220, loss 0.579377.
Test: 2018-08-01T01:34:58.793837: step 27220, loss 0.548218.
Train: 2018-08-01T01:34:58.950050: step 27221, loss 0.596318.
Train: 2018-08-01T01:34:59.106233: step 27222, loss 0.613218.
Train: 2018-08-01T01:34:59.262446: step 27223, loss 0.494794.
Train: 2018-08-01T01:34:59.418662: step 27224, loss 0.427241.
Train: 2018-08-01T01:34:59.590521: step 27225, loss 0.477824.
Train: 2018-08-01T01:34:59.746733: step 27226, loss 0.613284.
Train: 2018-08-01T01:34:59.902952: step 27227, loss 0.511467.
Train: 2018-08-01T01:35:00.059167: step 27228, loss 0.664487.
Train: 2018-08-01T01:35:00.215381: step 27229, loss 0.494317.
Train: 2018-08-01T01:35:00.387184: step 27230, loss 0.613534.
Test: 2018-08-01T01:35:00.855823: step 27230, loss 0.548121.
Train: 2018-08-01T01:35:01.074553: step 27231, loss 0.528294.
Train: 2018-08-01T01:35:01.230737: step 27232, loss 0.613609.
Train: 2018-08-01T01:35:01.386951: step 27233, loss 0.494106.
Train: 2018-08-01T01:35:01.558785: step 27234, loss 0.57949.
Train: 2018-08-01T01:35:01.714997: step 27235, loss 0.511085.
Train: 2018-08-01T01:35:01.886857: step 27236, loss 0.699413.
Train: 2018-08-01T01:35:02.043046: step 27237, loss 0.511042.
Train: 2018-08-01T01:35:02.199260: step 27238, loss 0.459666.
Train: 2018-08-01T01:35:02.355473: step 27239, loss 0.562397.
Train: 2018-08-01T01:35:02.511687: step 27240, loss 0.52806.
Test: 2018-08-01T01:35:02.980356: step 27240, loss 0.547998.
Train: 2018-08-01T01:35:03.136571: step 27241, loss 0.613986.
Train: 2018-08-01T01:35:03.292752: step 27242, loss 0.596817.
Train: 2018-08-01T01:35:03.449000: step 27243, loss 0.545184.
Train: 2018-08-01T01:35:03.605212: step 27244, loss 0.562399.
Train: 2018-08-01T01:35:03.777047: step 27245, loss 0.665772.
Train: 2018-08-01T01:35:03.933228: step 27246, loss 0.631251.
Train: 2018-08-01T01:35:04.105063: step 27247, loss 0.596767.
Train: 2018-08-01T01:35:04.261276: step 27248, loss 0.665307.
Train: 2018-08-01T01:35:04.417489: step 27249, loss 0.579498.
Train: 2018-08-01T01:35:04.589357: step 27250, loss 0.613554.
Test: 2018-08-01T01:35:05.057990: step 27250, loss 0.548175.
Train: 2018-08-01T01:35:05.214211: step 27251, loss 0.392449.
Train: 2018-08-01T01:35:05.370416: step 27252, loss 0.596373.
Train: 2018-08-01T01:35:05.526606: step 27253, loss 0.562411.
Train: 2018-08-01T01:35:05.682819: step 27254, loss 0.545466.
Train: 2018-08-01T01:35:05.839032: step 27255, loss 0.52854.
Train: 2018-08-01T01:35:05.995275: step 27256, loss 0.443864.
Train: 2018-08-01T01:35:06.151459: step 27257, loss 0.562411.
Train: 2018-08-01T01:35:06.338940: step 27258, loss 0.528443.
Train: 2018-08-01T01:35:06.495128: step 27259, loss 0.528384.
Train: 2018-08-01T01:35:06.651341: step 27260, loss 0.545358.
Test: 2018-08-01T01:35:07.120012: step 27260, loss 0.548099.
Train: 2018-08-01T01:35:07.291842: step 27261, loss 0.69901.
Train: 2018-08-01T01:35:07.448030: step 27262, loss 0.511165.
Train: 2018-08-01T01:35:07.619875: step 27263, loss 0.579488.
Train: 2018-08-01T01:35:07.776081: step 27264, loss 0.528202.
Train: 2018-08-01T01:35:07.916701: step 27265, loss 0.545285.
Train: 2018-08-01T01:35:08.088529: step 27266, loss 0.562397.
Train: 2018-08-01T01:35:08.229097: step 27267, loss 0.682401.
Train: 2018-08-01T01:35:08.416584: step 27268, loss 0.511001.
Train: 2018-08-01T01:35:08.572799: step 27269, loss 0.545264.
Train: 2018-08-01T01:35:08.729011: step 27270, loss 0.54526.
Test: 2018-08-01T01:35:09.197650: step 27270, loss 0.548041.
Train: 2018-08-01T01:35:09.353833: step 27271, loss 0.476679.
Train: 2018-08-01T01:35:09.525668: step 27272, loss 0.510892.
Train: 2018-08-01T01:35:09.681912: step 27273, loss 0.6312.
Train: 2018-08-01T01:35:09.838128: step 27274, loss 0.596829.
Train: 2018-08-01T01:35:09.994339: step 27275, loss 0.441844.
Train: 2018-08-01T01:35:10.150552: step 27276, loss 0.545147.
Train: 2018-08-01T01:35:10.306761: step 27277, loss 0.579685.
Train: 2018-08-01T01:35:10.462982: step 27278, loss 0.597018.
Train: 2018-08-01T01:35:10.634785: step 27279, loss 0.631689.
Train: 2018-08-01T01:35:10.791022: step 27280, loss 0.614361.
Test: 2018-08-01T01:35:11.259637: step 27280, loss 0.547914.
Train: 2018-08-01T01:35:11.415852: step 27281, loss 0.648929.
Train: 2018-08-01T01:35:11.572095: step 27282, loss 0.579676.
Train: 2018-08-01T01:35:11.743935: step 27283, loss 0.476182.
Train: 2018-08-01T01:35:11.900143: step 27284, loss 0.527932.
Train: 2018-08-01T01:35:12.056351: step 27285, loss 0.596859.
Train: 2018-08-01T01:35:12.212541: step 27286, loss 0.562398.
Train: 2018-08-01T01:35:12.368783: step 27287, loss 0.631246.
Train: 2018-08-01T01:35:12.524991: step 27288, loss 0.596776.
Train: 2018-08-01T01:35:12.681181: step 27289, loss 0.528071.
Train: 2018-08-01T01:35:12.853045: step 27290, loss 0.562396.
Test: 2018-08-01T01:35:13.337275: step 27290, loss 0.548053.
Train: 2018-08-01T01:35:13.493520: step 27291, loss 0.511009.
Train: 2018-08-01T01:35:13.649702: step 27292, loss 0.562396.
Train: 2018-08-01T01:35:13.805948: step 27293, loss 0.545273.
Train: 2018-08-01T01:35:13.977750: step 27294, loss 0.511025.
Train: 2018-08-01T01:35:14.133964: step 27295, loss 0.630939.
Train: 2018-08-01T01:35:14.290178: step 27296, loss 0.476736.
Train: 2018-08-01T01:35:14.446391: step 27297, loss 0.579543.
Train: 2018-08-01T01:35:14.602604: step 27298, loss 0.579552.
Train: 2018-08-01T01:35:14.774439: step 27299, loss 0.613881.
Train: 2018-08-01T01:35:14.930653: step 27300, loss 0.493774.
Test: 2018-08-01T01:35:15.399323: step 27300, loss 0.548023.
Train: 2018-08-01T01:35:16.102290: step 27301, loss 0.528067.
Train: 2018-08-01T01:35:16.258467: step 27302, loss 0.545217.
Train: 2018-08-01T01:35:16.414711: step 27303, loss 0.5452.
Train: 2018-08-01T01:35:16.570895: step 27304, loss 0.527966.
Train: 2018-08-01T01:35:16.727107: step 27305, loss 0.545159.
Train: 2018-08-01T01:35:16.883351: step 27306, loss 0.545136.
Train: 2018-08-01T01:35:17.039534: step 27307, loss 0.562403.
Train: 2018-08-01T01:35:17.227021: step 27308, loss 0.579719.
Train: 2018-08-01T01:35:17.383237: step 27309, loss 0.614397.
Train: 2018-08-01T01:35:17.539448: step 27310, loss 0.475739.
Test: 2018-08-01T01:35:18.023709: step 27310, loss 0.547878.
Train: 2018-08-01T01:35:18.179922: step 27311, loss 0.527702.
Train: 2018-08-01T01:35:18.351727: step 27312, loss 0.545035.
Train: 2018-08-01T01:35:18.507940: step 27313, loss 0.545014.
Train: 2018-08-01T01:35:18.664153: step 27314, loss 0.492697.
Train: 2018-08-01T01:35:18.820367: step 27315, loss 0.562433.
Train: 2018-08-01T01:35:18.976611: step 27316, loss 0.579943.
Train: 2018-08-01T01:35:19.132793: step 27317, loss 0.527394.
Train: 2018-08-01T01:35:19.289038: step 27318, loss 0.597568.
Train: 2018-08-01T01:35:19.476493: step 27319, loss 0.6679.
Train: 2018-08-01T01:35:19.632702: step 27320, loss 0.632723.
Test: 2018-08-01T01:35:20.101349: step 27320, loss 0.547762.
Train: 2018-08-01T01:35:20.257560: step 27321, loss 0.579997.
Train: 2018-08-01T01:35:20.413796: step 27322, loss 0.457331.
Train: 2018-08-01T01:35:20.585579: step 27323, loss 0.579963.
Train: 2018-08-01T01:35:20.741817: step 27324, loss 0.492396.
Train: 2018-08-01T01:35:20.898007: step 27325, loss 0.439805.
Train: 2018-08-01T01:35:21.054219: step 27326, loss 0.5098.
Train: 2018-08-01T01:35:21.210466: step 27327, loss 0.544877.
Train: 2018-08-01T01:35:21.366646: step 27328, loss 0.632987.
Train: 2018-08-01T01:35:21.538514: step 27329, loss 0.509554.
Train: 2018-08-01T01:35:21.694727: step 27330, loss 0.562496.
Test: 2018-08-01T01:35:22.163364: step 27330, loss 0.547691.
Train: 2018-08-01T01:35:22.319581: step 27331, loss 0.597886.
Train: 2018-08-01T01:35:22.475761: step 27332, loss 0.58021.
Train: 2018-08-01T01:35:22.647596: step 27333, loss 0.580216.
Train: 2018-08-01T01:35:22.788189: step 27334, loss 0.597918.
Train: 2018-08-01T01:35:22.960054: step 27335, loss 0.633282.
Train: 2018-08-01T01:35:23.116267: step 27336, loss 0.491819.
Train: 2018-08-01T01:35:23.272449: step 27337, loss 0.580152.
Train: 2018-08-01T01:35:23.428663: step 27338, loss 0.403669.
Train: 2018-08-01T01:35:23.584876: step 27339, loss 0.562495.
Train: 2018-08-01T01:35:23.741091: step 27340, loss 0.527138.
Test: 2018-08-01T01:35:24.209730: step 27340, loss 0.547686.
Train: 2018-08-01T01:35:24.365974: step 27341, loss 0.615613.
Train: 2018-08-01T01:35:24.522187: step 27342, loss 0.50939.
Train: 2018-08-01T01:35:24.678399: step 27343, loss 0.491631.
Train: 2018-08-01T01:35:24.850206: step 27344, loss 0.598024.
Train: 2018-08-01T01:35:25.022067: step 27345, loss 0.580297.
Train: 2018-08-01T01:35:25.178254: step 27346, loss 0.527.
Train: 2018-08-01T01:35:25.334467: step 27347, loss 0.68702.
Train: 2018-08-01T01:35:25.490681: step 27348, loss 0.651369.
Train: 2018-08-01T01:35:25.646924: step 27349, loss 0.562522.
Train: 2018-08-01T01:35:25.803108: step 27350, loss 0.527108.
Test: 2018-08-01T01:35:26.287399: step 27350, loss 0.547697.
Train: 2018-08-01T01:35:26.443612: step 27351, loss 0.544822.
Train: 2018-08-01T01:35:26.599826: step 27352, loss 0.544833.
Train: 2018-08-01T01:35:26.756039: step 27353, loss 0.491911.
Train: 2018-08-01T01:35:26.912221: step 27354, loss 0.544842.
Train: 2018-08-01T01:35:27.068437: step 27355, loss 0.562487.
Train: 2018-08-01T01:35:27.224679: step 27356, loss 0.527194.
Train: 2018-08-01T01:35:27.380892: step 27357, loss 0.580143.
Train: 2018-08-01T01:35:27.537106: step 27358, loss 0.597799.
Train: 2018-08-01T01:35:27.693322: step 27359, loss 0.474255.
Train: 2018-08-01T01:35:27.849502: step 27360, loss 0.491867.
Test: 2018-08-01T01:35:28.318173: step 27360, loss 0.547696.
Train: 2018-08-01T01:35:28.474356: step 27361, loss 0.633211.
Train: 2018-08-01T01:35:28.630601: step 27362, loss 0.580183.
Train: 2018-08-01T01:35:28.786813: step 27363, loss 0.63322.
Train: 2018-08-01T01:35:28.943026: step 27364, loss 0.650806.
Train: 2018-08-01T01:35:29.099211: step 27365, loss 0.580108.
Train: 2018-08-01T01:35:29.271045: step 27366, loss 0.544877.
Train: 2018-08-01T01:35:29.411667: step 27367, loss 0.492217.
Train: 2018-08-01T01:35:29.567883: step 27368, loss 0.544908.
Train: 2018-08-01T01:35:29.724063: step 27369, loss 0.579987.
Train: 2018-08-01T01:35:29.880276: step 27370, loss 0.509881.
Test: 2018-08-01T01:35:30.348948: step 27370, loss 0.547776.
Train: 2018-08-01T01:35:30.520782: step 27371, loss 0.562446.
Train: 2018-08-01T01:35:30.676996: step 27372, loss 0.509897.
Train: 2018-08-01T01:35:30.833203: step 27373, loss 0.562447.
Train: 2018-08-01T01:35:30.989392: step 27374, loss 0.54492.
Train: 2018-08-01T01:35:31.145606: step 27375, loss 0.597521.
Train: 2018-08-01T01:35:31.301820: step 27376, loss 0.527383.
Train: 2018-08-01T01:35:31.473653: step 27377, loss 0.562451.
Train: 2018-08-01T01:35:31.629867: step 27378, loss 0.544911.
Train: 2018-08-01T01:35:31.786080: step 27379, loss 0.580001.
Train: 2018-08-01T01:35:31.942293: step 27380, loss 0.492267.
Test: 2018-08-01T01:35:32.410965: step 27380, loss 0.547753.
Train: 2018-08-01T01:35:32.582770: step 27381, loss 0.597579.
Train: 2018-08-01T01:35:32.754629: step 27382, loss 0.544895.
Train: 2018-08-01T01:35:32.895227: step 27383, loss 0.632742.
Train: 2018-08-01T01:35:33.051410: step 27384, loss 0.597577.
Train: 2018-08-01T01:35:33.223244: step 27385, loss 0.597537.
Train: 2018-08-01T01:35:33.363867: step 27386, loss 0.509892.
Train: 2018-08-01T01:35:33.520081: step 27387, loss 0.597454.
Train: 2018-08-01T01:35:33.707507: step 27388, loss 0.509977.
Train: 2018-08-01T01:35:33.848098: step 27389, loss 0.509997.
Train: 2018-08-01T01:35:34.004336: step 27390, loss 0.509987.
Test: 2018-08-01T01:35:34.488572: step 27390, loss 0.547789.
Train: 2018-08-01T01:35:34.644817: step 27391, loss 0.487788.
Train: 2018-08-01T01:35:34.832243: step 27392, loss 0.544924.
Train: 2018-08-01T01:35:34.988481: step 27393, loss 0.615104.
Train: 2018-08-01T01:35:35.144670: step 27394, loss 0.738073.
Train: 2018-08-01T01:35:35.300913: step 27395, loss 0.492312.
Train: 2018-08-01T01:35:35.457128: step 27396, loss 0.457303.
Train: 2018-08-01T01:35:35.613341: step 27397, loss 0.56245.
Train: 2018-08-01T01:35:35.785176: step 27398, loss 0.597542.
Train: 2018-08-01T01:35:35.941359: step 27399, loss 0.667717.
Train: 2018-08-01T01:35:36.097601: step 27400, loss 0.544926.
Test: 2018-08-01T01:35:36.581865: step 27400, loss 0.547785.
Train: 2018-08-01T01:35:37.300439: step 27401, loss 0.649956.
Train: 2018-08-01T01:35:37.456628: step 27402, loss 0.597367.
Train: 2018-08-01T01:35:37.612841: step 27403, loss 0.527569.
Train: 2018-08-01T01:35:37.769055: step 27404, loss 0.475428.
Train: 2018-08-01T01:35:37.940920: step 27405, loss 0.66675.
Train: 2018-08-01T01:35:38.112724: step 27406, loss 0.510336.
Train: 2018-08-01T01:35:38.268963: step 27407, loss 0.510385.
Train: 2018-08-01T01:35:38.425181: step 27408, loss 0.614416.
Train: 2018-08-01T01:35:38.581365: step 27409, loss 0.527766.
Train: 2018-08-01T01:35:38.737608: step 27410, loss 0.579718.
Test: 2018-08-01T01:35:39.206217: step 27410, loss 0.547915.
Train: 2018-08-01T01:35:39.362462: step 27411, loss 0.597007.
Train: 2018-08-01T01:35:39.518676: step 27412, loss 0.614254.
Train: 2018-08-01T01:35:39.690481: step 27413, loss 0.6832.
Train: 2018-08-01T01:35:39.846693: step 27414, loss 0.596811.
Train: 2018-08-01T01:35:40.002937: step 27415, loss 0.47662.
Train: 2018-08-01T01:35:40.190393: step 27416, loss 0.493891.
Train: 2018-08-01T01:35:40.346607: step 27417, loss 0.579511.
Train: 2018-08-01T01:35:40.518442: step 27418, loss 0.528195.
Train: 2018-08-01T01:35:40.674625: step 27419, loss 0.562397.
Train: 2018-08-01T01:35:40.815216: step 27420, loss 0.528214.
Test: 2018-08-01T01:35:41.299508: step 27420, loss 0.548082.
Train: 2018-08-01T01:35:41.455692: step 27421, loss 0.476922.
Train: 2018-08-01T01:35:41.611935: step 27422, loss 0.54528.
Train: 2018-08-01T01:35:41.768152: step 27423, loss 0.579535.
Train: 2018-08-01T01:35:41.924362: step 27424, loss 0.579552.
Train: 2018-08-01T01:35:42.080545: step 27425, loss 0.51089.
Train: 2018-08-01T01:35:42.236759: step 27426, loss 0.596776.
Train: 2018-08-01T01:35:42.393005: step 27427, loss 0.527992.
Train: 2018-08-01T01:35:42.549210: step 27428, loss 0.614057.
Train: 2018-08-01T01:35:42.705432: step 27429, loss 0.545172.
Train: 2018-08-01T01:35:42.861612: step 27430, loss 0.596864.
Test: 2018-08-01T01:35:43.345904: step 27430, loss 0.547967.
Train: 2018-08-01T01:35:43.517722: step 27431, loss 0.476233.
Train: 2018-08-01T01:35:43.673952: step 27432, loss 0.510647.
Train: 2018-08-01T01:35:43.830135: step 27433, loss 0.562401.
Train: 2018-08-01T01:35:43.986379: step 27434, loss 0.614306.
Train: 2018-08-01T01:35:44.142593: step 27435, loss 0.614337.
Train: 2018-08-01T01:35:44.298806: step 27436, loss 0.562404.
Train: 2018-08-01T01:35:44.455027: step 27437, loss 0.475875.
Train: 2018-08-01T01:35:44.611216: step 27438, loss 0.649013.
Train: 2018-08-01T01:35:44.767417: step 27439, loss 0.458506.
Train: 2018-08-01T01:35:44.923659: step 27440, loss 0.562408.
Test: 2018-08-01T01:35:45.392300: step 27440, loss 0.547882.
Train: 2018-08-01T01:35:45.564106: step 27441, loss 0.475667.
Train: 2018-08-01T01:35:45.720319: step 27442, loss 0.492896.
Train: 2018-08-01T01:35:45.876532: step 27443, loss 0.545001.
Train: 2018-08-01T01:35:46.032775: step 27444, loss 0.667203.
Train: 2018-08-01T01:35:46.188990: step 27445, loss 0.57991.
Train: 2018-08-01T01:35:46.345202: step 27446, loss 0.544953.
Train: 2018-08-01T01:35:46.501415: step 27447, loss 0.667401.
Train: 2018-08-01T01:35:46.657600: step 27448, loss 0.509996.
Train: 2018-08-01T01:35:46.829458: step 27449, loss 0.52748.
Train: 2018-08-01T01:35:46.970055: step 27450, loss 0.579918.
Test: 2018-08-01T01:35:47.454319: step 27450, loss 0.547798.
Train: 2018-08-01T01:35:47.610502: step 27451, loss 0.544955.
Train: 2018-08-01T01:35:47.766744: step 27452, loss 0.527471.
Train: 2018-08-01T01:35:47.922953: step 27453, loss 0.562438.
Train: 2018-08-01T01:35:48.079141: step 27454, loss 0.614932.
Train: 2018-08-01T01:35:48.235385: step 27455, loss 0.492473.
Train: 2018-08-01T01:35:48.391598: step 27456, loss 0.59744.
Train: 2018-08-01T01:35:48.547810: step 27457, loss 0.632435.
Train: 2018-08-01T01:35:48.704026: step 27458, loss 0.614883.
Train: 2018-08-01T01:35:48.860241: step 27459, loss 0.475151.
Train: 2018-08-01T01:35:49.063286: step 27460, loss 0.544979.
Test: 2018-08-01T01:35:49.516303: step 27460, loss 0.547818.
Train: 2018-08-01T01:35:49.672548: step 27461, loss 0.510089.
Train: 2018-08-01T01:35:49.828731: step 27462, loss 0.4228.
Train: 2018-08-01T01:35:49.984974: step 27463, loss 0.492483.
Train: 2018-08-01T01:35:50.156778: step 27464, loss 0.422181.
Train: 2018-08-01T01:35:50.297372: step 27465, loss 0.527267.
Train: 2018-08-01T01:35:50.453585: step 27466, loss 0.544827.
Train: 2018-08-01T01:35:50.609829: step 27467, loss 0.61572.
Train: 2018-08-01T01:35:50.766041: step 27468, loss 0.491435.
Train: 2018-08-01T01:35:50.937879: step 27469, loss 0.580398.
Train: 2018-08-01T01:35:51.094090: step 27470, loss 0.491105.
Test: 2018-08-01T01:35:51.562730: step 27470, loss 0.547611.
Train: 2018-08-01T01:35:51.718914: step 27471, loss 0.526775.
Train: 2018-08-01T01:35:51.875127: step 27472, loss 0.562649.
Train: 2018-08-01T01:35:52.031370: step 27473, loss 0.490615.
Train: 2018-08-01T01:35:52.187583: step 27474, loss 0.454312.
Train: 2018-08-01T01:35:52.359388: step 27475, loss 0.617151.
Train: 2018-08-01T01:35:52.515632: step 27476, loss 0.544614.
Train: 2018-08-01T01:35:52.671845: step 27477, loss 0.489952.
Train: 2018-08-01T01:35:52.828061: step 27478, loss 0.52633.
Train: 2018-08-01T01:35:52.984266: step 27479, loss 0.50796.
Train: 2018-08-01T01:35:53.140479: step 27480, loss 0.526218.
Test: 2018-08-01T01:35:53.624747: step 27480, loss 0.547576.
Train: 2018-08-01T01:35:53.780963: step 27481, loss 0.544581.
Train: 2018-08-01T01:35:53.937174: step 27482, loss 0.526118.
Train: 2018-08-01T01:35:54.093357: step 27483, loss 0.507567.
Train: 2018-08-01T01:35:54.249570: step 27484, loss 0.60024.
Train: 2018-08-01T01:35:54.405784: step 27485, loss 0.525998.
Train: 2018-08-01T01:35:54.577618: step 27486, loss 0.674899.
Train: 2018-08-01T01:35:54.733832: step 27487, loss 0.488729.
Train: 2018-08-01T01:35:54.890076: step 27488, loss 0.600482.
Train: 2018-08-01T01:35:55.046295: step 27489, loss 0.544587.
Train: 2018-08-01T01:35:55.202504: step 27490, loss 0.544587.
Test: 2018-08-01T01:35:55.686764: step 27490, loss 0.547617.
Train: 2018-08-01T01:35:55.842949: step 27491, loss 0.544587.
Train: 2018-08-01T01:35:55.999160: step 27492, loss 0.525956.
Train: 2018-08-01T01:35:56.155404: step 27493, loss 0.56322.
Train: 2018-08-01T01:35:56.311587: step 27494, loss 0.47006.
Train: 2018-08-01T01:35:56.467801: step 27495, loss 0.581877.
Train: 2018-08-01T01:35:56.639636: step 27496, loss 0.563236.
Train: 2018-08-01T01:35:56.791284: step 27497, loss 0.637824.
Train: 2018-08-01T01:35:56.947493: step 27498, loss 0.619097.
Train: 2018-08-01T01:35:57.103708: step 27499, loss 0.581774.
Train: 2018-08-01T01:35:57.259889: step 27500, loss 0.581698.
Test: 2018-08-01T01:35:57.728558: step 27500, loss 0.547591.
Train: 2018-08-01T01:35:58.431520: step 27501, loss 0.489026.
Train: 2018-08-01T01:35:58.587702: step 27502, loss 0.563071.
Train: 2018-08-01T01:35:58.743947: step 27503, loss 0.544579.
Train: 2018-08-01T01:35:58.915788: step 27504, loss 0.581462.
Train: 2018-08-01T01:35:59.071994: step 27505, loss 0.470931.
Train: 2018-08-01T01:35:59.228178: step 27506, loss 0.544582.
Train: 2018-08-01T01:35:59.384391: step 27507, loss 0.63654.
Train: 2018-08-01T01:35:59.540605: step 27508, loss 0.562949.
Train: 2018-08-01T01:35:59.696817: step 27509, loss 0.599599.
Train: 2018-08-01T01:35:59.868683: step 27510, loss 0.599497.
Test: 2018-08-01T01:36:00.337322: step 27510, loss 0.547567.
Train: 2018-08-01T01:36:00.493536: step 27511, loss 0.47156.
Train: 2018-08-01T01:36:00.665372: step 27512, loss 0.599312.
Train: 2018-08-01T01:36:00.821585: step 27513, loss 0.435373.
Train: 2018-08-01T01:36:00.977769: step 27514, loss 0.599212.
Train: 2018-08-01T01:36:01.149602: step 27515, loss 0.471868.
Train: 2018-08-01T01:36:01.305846: step 27516, loss 0.599177.
Train: 2018-08-01T01:36:01.462029: step 27517, loss 0.599154.
Train: 2018-08-01T01:36:01.618274: step 27518, loss 0.508292.
Train: 2018-08-01T01:36:01.774482: step 27519, loss 0.65355.
Train: 2018-08-01T01:36:01.930670: step 27520, loss 0.544627.
Test: 2018-08-01T01:36:02.399340: step 27520, loss 0.547577.
Train: 2018-08-01T01:36:02.555554: step 27521, loss 0.544633.
Train: 2018-08-01T01:36:02.711738: step 27522, loss 0.562722.
Train: 2018-08-01T01:36:02.883571: step 27523, loss 0.436278.
Train: 2018-08-01T01:36:03.039816: step 27524, loss 0.508514.
Train: 2018-08-01T01:36:03.196029: step 27525, loss 0.544641.
Train: 2018-08-01T01:36:03.367863: step 27526, loss 0.526548.
Train: 2018-08-01T01:36:03.524072: step 27527, loss 0.653262.
Train: 2018-08-01T01:36:03.680292: step 27528, loss 0.598929.
Train: 2018-08-01T01:36:03.836503: step 27529, loss 0.526558.
Train: 2018-08-01T01:36:03.992717: step 27530, loss 0.598859.
Test: 2018-08-01T01:36:04.461357: step 27530, loss 0.547584.
Train: 2018-08-01T01:36:04.617540: step 27531, loss 0.526595.
Train: 2018-08-01T01:36:04.773785: step 27532, loss 0.580735.
Train: 2018-08-01T01:36:04.929998: step 27533, loss 0.616756.
Train: 2018-08-01T01:36:05.086211: step 27534, loss 0.634648.
Train: 2018-08-01T01:36:05.242424: step 27535, loss 0.526731.
Train: 2018-08-01T01:36:05.398633: step 27536, loss 0.473018.
Train: 2018-08-01T01:36:05.570466: step 27537, loss 0.544704.
Train: 2018-08-01T01:36:05.726686: step 27538, loss 0.526813.
Train: 2018-08-01T01:36:05.882899: step 27539, loss 0.508929.
Train: 2018-08-01T01:36:06.039084: step 27540, loss 0.687873.
Test: 2018-08-01T01:36:06.523384: step 27540, loss 0.547625.
Train: 2018-08-01T01:36:06.679588: step 27541, loss 0.544719.
Train: 2018-08-01T01:36:06.851422: step 27542, loss 0.61614.
Train: 2018-08-01T01:36:07.007605: step 27543, loss 0.598211.
Train: 2018-08-01T01:36:07.163850: step 27544, loss 0.633693.
Train: 2018-08-01T01:36:07.320033: step 27545, loss 0.651211.
Train: 2018-08-01T01:36:07.476276: step 27546, loss 0.509478.
Train: 2018-08-01T01:36:07.648080: step 27547, loss 0.615355.
Train: 2018-08-01T01:36:07.804294: step 27548, loss 0.667878.
Train: 2018-08-01T01:36:07.976130: step 27549, loss 0.56244.
Train: 2018-08-01T01:36:08.132344: step 27550, loss 0.475275.
Test: 2018-08-01T01:36:08.601012: step 27550, loss 0.547856.
Train: 2018-08-01T01:36:08.757195: step 27551, loss 0.562416.
Train: 2018-08-01T01:36:08.897787: step 27552, loss 0.597106.
Train: 2018-08-01T01:36:09.054032: step 27553, loss 0.527793.
Train: 2018-08-01T01:36:09.225835: step 27554, loss 0.545127.
Train: 2018-08-01T01:36:09.382079: step 27555, loss 0.648641.
Train: 2018-08-01T01:36:09.538294: step 27556, loss 0.527982.
Train: 2018-08-01T01:36:09.678886: step 27557, loss 0.562396.
Train: 2018-08-01T01:36:09.850726: step 27558, loss 0.699597.
Train: 2018-08-01T01:36:10.006933: step 27559, loss 0.59659.
Train: 2018-08-01T01:36:10.147495: step 27560, loss 0.528318.
Test: 2018-08-01T01:36:10.631787: step 27560, loss 0.54817.
Train: 2018-08-01T01:36:10.788002: step 27561, loss 0.613403.
Train: 2018-08-01T01:36:10.959835: step 27562, loss 0.545461.
Train: 2018-08-01T01:36:11.116018: step 27563, loss 0.511684.
Train: 2018-08-01T01:36:11.272232: step 27564, loss 0.562423.
Train: 2018-08-01T01:36:11.428477: step 27565, loss 0.478093.
Train: 2018-08-01T01:36:11.584690: step 27566, loss 0.528693.
Train: 2018-08-01T01:36:11.740902: step 27567, loss 0.562426.
Train: 2018-08-01T01:36:11.897116: step 27568, loss 0.494885.
Train: 2018-08-01T01:36:12.053323: step 27569, loss 0.646958.
Train: 2018-08-01T01:36:12.209543: step 27570, loss 0.663885.
Test: 2018-08-01T01:36:12.693803: step 27570, loss 0.548277.
Train: 2018-08-01T01:36:12.850017: step 27571, loss 0.579315.
Train: 2018-08-01T01:36:13.006225: step 27572, loss 0.562427.
Train: 2018-08-01T01:36:13.162414: step 27573, loss 0.646712.
Train: 2018-08-01T01:36:13.318627: step 27574, loss 0.427847.
Train: 2018-08-01T01:36:13.474841: step 27575, loss 0.545613.
Train: 2018-08-01T01:36:13.631054: step 27576, loss 0.528776.
Train: 2018-08-01T01:36:13.787268: step 27577, loss 0.59612.
Train: 2018-08-01T01:36:13.943482: step 27578, loss 0.495037.
Train: 2018-08-01T01:36:14.099696: step 27579, loss 0.528689.
Train: 2018-08-01T01:36:14.255909: step 27580, loss 0.545526.
Test: 2018-08-01T01:36:14.740170: step 27580, loss 0.548245.
Train: 2018-08-01T01:36:14.896413: step 27581, loss 0.57934.
Train: 2018-08-01T01:36:15.052596: step 27582, loss 0.579359.
Train: 2018-08-01T01:36:15.208841: step 27583, loss 0.528484.
Train: 2018-08-01T01:36:15.380670: step 27584, loss 0.562407.
Train: 2018-08-01T01:36:15.536890: step 27585, loss 0.59642.
Train: 2018-08-01T01:36:15.693107: step 27586, loss 0.562403.
Train: 2018-08-01T01:36:15.849317: step 27587, loss 0.54537.
Train: 2018-08-01T01:36:16.005500: step 27588, loss 0.528308.
Train: 2018-08-01T01:36:16.161711: step 27589, loss 0.545332.
Train: 2018-08-01T01:36:16.317926: step 27590, loss 0.630754.
Test: 2018-08-01T01:36:16.786596: step 27590, loss 0.548082.
Train: 2018-08-01T01:36:16.942780: step 27591, loss 0.613682.
Train: 2018-08-01T01:36:17.114614: step 27592, loss 0.579487.
Train: 2018-08-01T01:36:17.270858: step 27593, loss 0.528237.
Train: 2018-08-01T01:36:17.427072: step 27594, loss 0.613639.
Train: 2018-08-01T01:36:17.614521: step 27595, loss 0.459982.
Train: 2018-08-01T01:36:17.755118: step 27596, loss 0.596562.
Train: 2018-08-01T01:36:17.926948: step 27597, loss 0.562398.
Train: 2018-08-01T01:36:18.083168: step 27598, loss 0.545308.
Train: 2018-08-01T01:36:18.239350: step 27599, loss 0.613688.
Train: 2018-08-01T01:36:18.395563: step 27600, loss 0.528211.
Test: 2018-08-01T01:36:18.864234: step 27600, loss 0.548081.
Train: 2018-08-01T01:36:19.629681: step 27601, loss 0.562397.
Train: 2018-08-01T01:36:19.817137: step 27602, loss 0.630797.
Train: 2018-08-01T01:36:19.973355: step 27603, loss 0.579486.
Train: 2018-08-01T01:36:20.129563: step 27604, loss 0.647773.
Train: 2018-08-01T01:36:20.285745: step 27605, loss 0.562401.
Train: 2018-08-01T01:36:20.441984: step 27606, loss 0.545386.
Train: 2018-08-01T01:36:20.598198: step 27607, loss 0.545408.
Train: 2018-08-01T01:36:20.770007: step 27608, loss 0.511459.
Train: 2018-08-01T01:36:20.926249: step 27609, loss 0.528444.
Train: 2018-08-01T01:36:21.082465: step 27610, loss 0.596383.
Test: 2018-08-01T01:36:21.566728: step 27610, loss 0.548182.
Train: 2018-08-01T01:36:21.722940: step 27611, loss 0.545419.
Train: 2018-08-01T01:36:21.894746: step 27612, loss 0.562406.
Train: 2018-08-01T01:36:22.050957: step 27613, loss 0.5794.
Train: 2018-08-01T01:36:22.207196: step 27614, loss 0.5794.
Train: 2018-08-01T01:36:22.363409: step 27615, loss 0.562406.
Train: 2018-08-01T01:36:22.519599: step 27616, loss 0.579395.
Train: 2018-08-01T01:36:22.675842: step 27617, loss 0.545424.
Train: 2018-08-01T01:36:22.832061: step 27618, loss 0.562407.
Train: 2018-08-01T01:36:23.003859: step 27619, loss 0.562407.
Train: 2018-08-01T01:36:23.144482: step 27620, loss 0.57939.
Test: 2018-08-01T01:36:23.628713: step 27620, loss 0.548189.
Train: 2018-08-01T01:36:23.784958: step 27621, loss 0.562408.
Train: 2018-08-01T01:36:23.941170: step 27622, loss 0.630319.
Train: 2018-08-01T01:36:24.113005: step 27623, loss 0.56241.
Train: 2018-08-01T01:36:24.269219: step 27624, loss 0.494622.
Train: 2018-08-01T01:36:24.425433: step 27625, loss 0.562412.
Train: 2018-08-01T01:36:24.581640: step 27626, loss 0.579365.
Train: 2018-08-01T01:36:24.737859: step 27627, loss 0.511552.
Train: 2018-08-01T01:36:24.894076: step 27628, loss 0.647233.
Train: 2018-08-01T01:36:25.050255: step 27629, loss 0.51154.
Train: 2018-08-01T01:36:25.222090: step 27630, loss 0.596334.
Test: 2018-08-01T01:36:25.690760: step 27630, loss 0.548209.
Train: 2018-08-01T01:36:25.862595: step 27631, loss 0.596329.
Train: 2018-08-01T01:36:26.003157: step 27632, loss 0.630212.
Train: 2018-08-01T01:36:26.159402: step 27633, loss 0.596271.
Train: 2018-08-01T01:36:26.346826: step 27634, loss 0.52862.
Train: 2018-08-01T01:36:26.487449: step 27635, loss 0.54554.
Train: 2018-08-01T01:36:26.659285: step 27636, loss 0.545552.
Train: 2018-08-01T01:36:26.815503: step 27637, loss 0.579297.
Train: 2018-08-01T01:36:26.971712: step 27638, loss 0.545566.
Train: 2018-08-01T01:36:27.127924: step 27639, loss 0.596151.
Train: 2018-08-01T01:36:27.284139: step 27640, loss 0.562431.
Test: 2018-08-01T01:36:27.768369: step 27640, loss 0.548326.
Train: 2018-08-01T01:36:27.924613: step 27641, loss 0.545586.
Train: 2018-08-01T01:36:28.080826: step 27642, loss 0.511897.
Train: 2018-08-01T01:36:28.237008: step 27643, loss 0.444436.
Train: 2018-08-01T01:36:28.393222: step 27644, loss 0.596208.
Train: 2018-08-01T01:36:28.565057: step 27645, loss 0.528579.
Train: 2018-08-01T01:36:28.721270: step 27646, loss 0.562412.
Train: 2018-08-01T01:36:28.877484: step 27647, loss 0.511466.
Train: 2018-08-01T01:36:29.033697: step 27648, loss 0.545385.
Train: 2018-08-01T01:36:29.189911: step 27649, loss 0.443002.
Train: 2018-08-01T01:36:29.346154: step 27650, loss 0.579514.
Test: 2018-08-01T01:36:29.814795: step 27650, loss 0.548019.
Train: 2018-08-01T01:36:29.970977: step 27651, loss 0.596733.
Train: 2018-08-01T01:36:30.127191: step 27652, loss 0.631225.
Train: 2018-08-01T01:36:30.283406: step 27653, loss 0.631304.
Train: 2018-08-01T01:36:30.455264: step 27654, loss 0.562398.
Train: 2018-08-01T01:36:30.611453: step 27655, loss 0.665786.
Train: 2018-08-01T01:36:30.783287: step 27656, loss 0.562397.
Train: 2018-08-01T01:36:30.939501: step 27657, loss 0.493627.
Train: 2018-08-01T01:36:31.111336: step 27658, loss 0.717108.
Train: 2018-08-01T01:36:31.267580: step 27659, loss 0.665326.
Train: 2018-08-01T01:36:31.423787: step 27660, loss 0.562397.
Test: 2018-08-01T01:36:31.892433: step 27660, loss 0.54812.
Train: 2018-08-01T01:36:32.048616: step 27661, loss 0.545347.
Train: 2018-08-01T01:36:32.204854: step 27662, loss 0.54539.
Train: 2018-08-01T01:36:32.361068: step 27663, loss 0.528444.
Train: 2018-08-01T01:36:32.532878: step 27664, loss 0.477603.
Train: 2018-08-01T01:36:32.673471: step 27665, loss 0.528486.
Train: 2018-08-01T01:36:32.876550: step 27666, loss 0.579381.
Train: 2018-08-01T01:36:33.017139: step 27667, loss 0.698209.
Train: 2018-08-01T01:36:33.173352: step 27668, loss 0.579374.
Train: 2018-08-01T01:36:33.329566: step 27669, loss 0.57934.
Train: 2018-08-01T01:36:33.485810: step 27670, loss 0.562426.
Test: 2018-08-01T01:36:33.970053: step 27670, loss 0.548292.
Train: 2018-08-01T01:36:34.126279: step 27671, loss 0.528656.
Train: 2018-08-01T01:36:34.282492: step 27672, loss 0.663767.
Train: 2018-08-01T01:36:34.438706: step 27673, loss 0.545586.
Train: 2018-08-01T01:36:34.594925: step 27674, loss 0.478383.
Train: 2018-08-01T01:36:34.751109: step 27675, loss 0.646487.
Train: 2018-08-01T01:36:34.907353: step 27676, loss 0.663188.
Train: 2018-08-01T01:36:35.063562: step 27677, loss 0.595951.
Train: 2018-08-01T01:36:35.219784: step 27678, loss 0.645991.
Train: 2018-08-01T01:36:35.375993: step 27679, loss 0.562495.
Train: 2018-08-01T01:36:35.532200: step 27680, loss 0.545914.
Test: 2018-08-01T01:36:36.016467: step 27680, loss 0.548661.
Train: 2018-08-01T01:36:36.188302: step 27681, loss 0.529404.
Train: 2018-08-01T01:36:36.344485: step 27682, loss 0.579083.
Train: 2018-08-01T01:36:36.500698: step 27683, loss 0.54604.
Train: 2018-08-01T01:36:36.656912: step 27684, loss 0.480069.
Train: 2018-08-01T01:36:36.828746: step 27685, loss 0.612075.
Train: 2018-08-01T01:36:36.984985: step 27686, loss 0.579064.
Train: 2018-08-01T01:36:37.141174: step 27687, loss 0.612052.
Train: 2018-08-01T01:36:37.313033: step 27688, loss 0.52961.
Train: 2018-08-01T01:36:37.469252: step 27689, loss 0.546097.
Train: 2018-08-01T01:36:37.625466: step 27690, loss 0.579054.
Test: 2018-08-01T01:36:38.094105: step 27690, loss 0.548772.
Train: 2018-08-01T01:36:38.250313: step 27691, loss 0.562573.
Train: 2018-08-01T01:36:38.422125: step 27692, loss 0.597738.
Train: 2018-08-01T01:36:38.593989: step 27693, loss 0.562574.
Train: 2018-08-01T01:36:38.750173: step 27694, loss 0.579054.
Train: 2018-08-01T01:36:38.906385: step 27695, loss 0.480197.
Train: 2018-08-01T01:36:39.062600: step 27696, loss 0.562567.
Train: 2018-08-01T01:36:39.218812: step 27697, loss 0.513023.
Train: 2018-08-01T01:36:39.375050: step 27698, loss 0.628707.
Train: 2018-08-01T01:36:39.546861: step 27699, loss 0.545984.
Train: 2018-08-01T01:36:39.703104: step 27700, loss 0.595672.
Test: 2018-08-01T01:36:40.171746: step 27700, loss 0.548641.
Train: 2018-08-01T01:36:40.905917: step 27701, loss 0.529363.
Train: 2018-08-01T01:36:41.062163: step 27702, loss 0.496121.
Train: 2018-08-01T01:36:41.218344: step 27703, loss 0.562504.
Train: 2018-08-01T01:36:41.374557: step 27704, loss 0.662467.
Train: 2018-08-01T01:36:41.530795: step 27705, loss 0.512481.
Train: 2018-08-01T01:36:41.702605: step 27706, loss 0.562482.
Train: 2018-08-01T01:36:41.858849: step 27707, loss 0.595888.
Train: 2018-08-01T01:36:42.015033: step 27708, loss 0.629339.
Train: 2018-08-01T01:36:42.171277: step 27709, loss 0.595898.
Train: 2018-08-01T01:36:42.327489: step 27710, loss 0.529073.
Test: 2018-08-01T01:36:42.811751: step 27710, loss 0.548491.
Train: 2018-08-01T01:36:42.967934: step 27711, loss 0.545775.
Train: 2018-08-01T01:36:43.124148: step 27712, loss 0.478942.
Train: 2018-08-01T01:36:43.280361: step 27713, loss 0.679583.
Train: 2018-08-01T01:36:43.436575: step 27714, loss 0.495557.
Train: 2018-08-01T01:36:43.592788: step 27715, loss 0.528982.
Train: 2018-08-01T01:36:43.749033: step 27716, loss 0.562457.
Train: 2018-08-01T01:36:43.920860: step 27717, loss 0.528889.
Train: 2018-08-01T01:36:44.077049: step 27718, loss 0.59606.
Train: 2018-08-01T01:36:44.233293: step 27719, loss 0.612914.
Train: 2018-08-01T01:36:44.389477: step 27720, loss 0.545608.
Test: 2018-08-01T01:36:44.873774: step 27720, loss 0.548335.
Train: 2018-08-01T01:36:45.045604: step 27721, loss 0.612954.
Train: 2018-08-01T01:36:45.201816: step 27722, loss 0.545599.
Train: 2018-08-01T01:36:45.358030: step 27723, loss 0.511913.
Train: 2018-08-01T01:36:45.514213: step 27724, loss 0.629854.
Train: 2018-08-01T01:36:45.670451: step 27725, loss 0.511868.
Train: 2018-08-01T01:36:45.826671: step 27726, loss 0.579296.
Train: 2018-08-01T01:36:45.998476: step 27727, loss 0.494934.
Train: 2018-08-01T01:36:46.154689: step 27728, loss 0.49484.
Train: 2018-08-01T01:36:46.310932: step 27729, loss 0.562417.
Train: 2018-08-01T01:36:46.467145: step 27730, loss 0.715092.
Test: 2018-08-01T01:36:46.935786: step 27730, loss 0.548209.
Train: 2018-08-01T01:36:47.091969: step 27731, loss 0.52849.
Train: 2018-08-01T01:36:47.263834: step 27732, loss 0.528479.
Train: 2018-08-01T01:36:47.420018: step 27733, loss 0.494496.
Train: 2018-08-01T01:36:47.591852: step 27734, loss 0.630426.
Train: 2018-08-01T01:36:47.748096: step 27735, loss 0.613448.
Train: 2018-08-01T01:36:47.904315: step 27736, loss 0.579417.
Train: 2018-08-01T01:36:48.060523: step 27737, loss 0.511385.
Train: 2018-08-01T01:36:48.216705: step 27738, loss 0.562405.
Train: 2018-08-01T01:36:48.388540: step 27739, loss 0.409223.
Train: 2018-08-01T01:36:48.544784: step 27740, loss 0.59652.
Test: 2018-08-01T01:36:49.013393: step 27740, loss 0.548089.
Train: 2018-08-01T01:36:49.185230: step 27741, loss 0.579487.
Train: 2018-08-01T01:36:49.341467: step 27742, loss 0.545287.
Train: 2018-08-01T01:36:49.497655: step 27743, loss 0.6138.
Train: 2018-08-01T01:36:49.653900: step 27744, loss 0.596686.
Train: 2018-08-01T01:36:49.810083: step 27745, loss 0.528104.
Train: 2018-08-01T01:36:49.966326: step 27746, loss 0.528086.
Train: 2018-08-01T01:36:50.122509: step 27747, loss 0.613911.
Train: 2018-08-01T01:36:50.278723: step 27748, loss 0.528048.
Train: 2018-08-01T01:36:50.450557: step 27749, loss 0.545213.
Train: 2018-08-01T01:36:50.606771: step 27750, loss 0.613989.
Test: 2018-08-01T01:36:51.075411: step 27750, loss 0.547997.
Train: 2018-08-01T01:36:51.231650: step 27751, loss 0.613989.
Train: 2018-08-01T01:36:51.387868: step 27752, loss 0.579583.
Train: 2018-08-01T01:36:51.559708: step 27753, loss 0.545225.
Train: 2018-08-01T01:36:51.700264: step 27754, loss 0.613887.
Train: 2018-08-01T01:36:51.872135: step 27755, loss 0.699552.
Train: 2018-08-01T01:36:52.012722: step 27756, loss 0.47691.
Train: 2018-08-01T01:36:52.168905: step 27757, loss 0.630696.
Train: 2018-08-01T01:36:52.325149: step 27758, loss 0.562402.
Train: 2018-08-01T01:36:52.496953: step 27759, loss 0.579412.
Train: 2018-08-01T01:36:52.653167: step 27760, loss 0.732159.
Test: 2018-08-01T01:36:53.121807: step 27760, loss 0.54826.
Train: 2018-08-01T01:36:53.278020: step 27761, loss 0.477871.
Train: 2018-08-01T01:36:53.434264: step 27762, loss 0.579299.
Train: 2018-08-01T01:36:53.590478: step 27763, loss 0.562437.
Train: 2018-08-01T01:36:53.777934: step 27764, loss 0.64644.
Train: 2018-08-01T01:36:53.934117: step 27765, loss 0.679718.
Train: 2018-08-01T01:36:54.090330: step 27766, loss 0.5458.
Train: 2018-08-01T01:36:54.246544: step 27767, loss 0.529249.
Train: 2018-08-01T01:36:54.402788: step 27768, loss 0.463003.
Train: 2018-08-01T01:36:54.574591: step 27769, loss 0.529382.
Train: 2018-08-01T01:36:54.730807: step 27770, loss 0.512819.
Test: 2018-08-01T01:36:55.199475: step 27770, loss 0.548641.
Train: 2018-08-01T01:36:55.371280: step 27771, loss 0.612266.
Train: 2018-08-01T01:36:55.527525: step 27772, loss 0.446465.
Train: 2018-08-01T01:36:55.683737: step 27773, loss 0.46287.
Train: 2018-08-01T01:36:55.839951: step 27774, loss 0.595804.
Train: 2018-08-01T01:36:56.011755: step 27775, loss 0.529095.
Train: 2018-08-01T01:36:56.167968: step 27776, loss 0.528995.
Train: 2018-08-01T01:36:56.324181: step 27777, loss 0.512106.
Train: 2018-08-01T01:36:56.480395: step 27778, loss 0.579272.
Train: 2018-08-01T01:36:56.636609: step 27779, loss 0.545544.
Train: 2018-08-01T01:36:56.792853: step 27780, loss 0.562417.
Test: 2018-08-01T01:36:57.261492: step 27780, loss 0.5482.
Train: 2018-08-01T01:36:57.433327: step 27781, loss 0.54544.
Train: 2018-08-01T01:36:57.589541: step 27782, loss 0.596428.
Train: 2018-08-01T01:36:57.745724: step 27783, loss 0.460148.
Train: 2018-08-01T01:36:57.901962: step 27784, loss 0.579491.
Train: 2018-08-01T01:36:58.073801: step 27785, loss 0.562397.
Train: 2018-08-01T01:36:58.230015: step 27786, loss 0.579568.
Train: 2018-08-01T01:36:58.386237: step 27787, loss 0.510792.
Train: 2018-08-01T01:36:58.542443: step 27788, loss 0.510679.
Train: 2018-08-01T01:36:58.714277: step 27789, loss 0.631543.
Train: 2018-08-01T01:36:58.870491: step 27790, loss 0.614337.
Test: 2018-08-01T01:36:59.339131: step 27790, loss 0.547902.
Train: 2018-08-01T01:36:59.495314: step 27791, loss 0.649016.
Train: 2018-08-01T01:36:59.651527: step 27792, loss 0.545093.
Train: 2018-08-01T01:36:59.807765: step 27793, loss 0.527788.
Train: 2018-08-01T01:36:59.963990: step 27794, loss 0.527783.
Train: 2018-08-01T01:37:00.120198: step 27795, loss 0.597049.
Train: 2018-08-01T01:37:00.292005: step 27796, loss 0.59705.
Train: 2018-08-01T01:37:00.432625: step 27797, loss 0.57972.
Train: 2018-08-01T01:37:00.588809: step 27798, loss 0.510493.
Train: 2018-08-01T01:37:00.745021: step 27799, loss 0.51049.
Train: 2018-08-01T01:37:00.901266: step 27800, loss 0.54509.
Test: 2018-08-01T01:37:01.385497: step 27800, loss 0.547896.
Train: 2018-08-01T01:37:02.088488: step 27801, loss 0.614399.
Train: 2018-08-01T01:37:02.244701: step 27802, loss 0.510415.
Train: 2018-08-01T01:37:02.400916: step 27803, loss 0.527725.
Train: 2018-08-01T01:37:02.572743: step 27804, loss 0.61449.
Train: 2018-08-01T01:37:02.728956: step 27805, loss 0.631865.
Train: 2018-08-01T01:37:02.885177: step 27806, loss 0.510358.
Train: 2018-08-01T01:37:03.041383: step 27807, loss 0.683865.
Train: 2018-08-01T01:37:03.197602: step 27808, loss 0.597055.
Train: 2018-08-01T01:37:03.353787: step 27809, loss 0.510527.
Train: 2018-08-01T01:37:03.525661: step 27810, loss 0.562402.
Test: 2018-08-01T01:37:03.994260: step 27810, loss 0.547949.
Train: 2018-08-01T01:37:04.166097: step 27811, loss 0.665944.
Train: 2018-08-01T01:37:04.322309: step 27812, loss 0.493518.
Train: 2018-08-01T01:37:04.478523: step 27813, loss 0.459191.
Train: 2018-08-01T01:37:04.650358: step 27814, loss 0.476368.
Train: 2018-08-01T01:37:04.806571: step 27815, loss 0.579627.
Train: 2018-08-01T01:37:04.962814: step 27816, loss 0.545154.
Train: 2018-08-01T01:37:05.118997: step 27817, loss 0.527873.
Train: 2018-08-01T01:37:05.275242: step 27818, loss 0.545115.
Train: 2018-08-01T01:37:05.447055: step 27819, loss 0.597029.
Train: 2018-08-01T01:37:05.587638: step 27820, loss 0.493102.
Test: 2018-08-01T01:37:06.087553: step 27820, loss 0.547879.
Train: 2018-08-01T01:37:06.243764: step 27821, loss 0.649178.
Train: 2018-08-01T01:37:06.399979: step 27822, loss 0.631847.
Train: 2018-08-01T01:37:06.556160: step 27823, loss 0.666501.
Train: 2018-08-01T01:37:06.712374: step 27824, loss 0.579722.
Train: 2018-08-01T01:37:06.884209: step 27825, loss 0.631535.
Train: 2018-08-01T01:37:07.040453: step 27826, loss 0.579637.
Train: 2018-08-01T01:37:07.196636: step 27827, loss 0.631173.
Train: 2018-08-01T01:37:07.352880: step 27828, loss 0.545257.
Train: 2018-08-01T01:37:07.524685: step 27829, loss 0.562398.
Train: 2018-08-01T01:37:07.680927: step 27830, loss 0.460084.
Test: 2018-08-01T01:37:08.149569: step 27830, loss 0.548134.
Train: 2018-08-01T01:37:08.305781: step 27831, loss 0.596479.
Train: 2018-08-01T01:37:08.477616: step 27832, loss 0.494329.
Train: 2018-08-01T01:37:08.633830: step 27833, loss 0.681515.
Train: 2018-08-01T01:37:08.790044: step 27834, loss 0.647347.
Train: 2018-08-01T01:37:08.930630: step 27835, loss 0.579358.
Train: 2018-08-01T01:37:09.118085: step 27836, loss 0.477905.
Train: 2018-08-01T01:37:09.274275: step 27837, loss 0.748155.
Train: 2018-08-01T01:37:09.446139: step 27838, loss 0.612923.
Train: 2018-08-01T01:37:09.602353: step 27839, loss 0.478615.
Train: 2018-08-01T01:37:09.774158: step 27840, loss 0.595931.
Test: 2018-08-01T01:37:10.242827: step 27840, loss 0.548498.
Train: 2018-08-01T01:37:10.399011: step 27841, loss 0.495698.
Train: 2018-08-01T01:37:10.570846: step 27842, loss 0.612516.
Train: 2018-08-01T01:37:10.727060: step 27843, loss 0.612448.
Train: 2018-08-01T01:37:10.867681: step 27844, loss 0.579126.
Train: 2018-08-01T01:37:11.039485: step 27845, loss 0.496175.
Train: 2018-08-01T01:37:11.211321: step 27846, loss 0.595676.
Train: 2018-08-01T01:37:11.367533: step 27847, loss 0.496303.
Train: 2018-08-01T01:37:11.523779: step 27848, loss 0.562534.
Train: 2018-08-01T01:37:11.679991: step 27849, loss 0.479722.
Train: 2018-08-01T01:37:11.836205: step 27850, loss 0.612277.
Test: 2018-08-01T01:37:12.320462: step 27850, loss 0.54862.
Train: 2018-08-01T01:37:12.476650: step 27851, loss 0.595709.
Train: 2018-08-01T01:37:12.632863: step 27852, loss 0.579116.
Train: 2018-08-01T01:37:12.789107: step 27853, loss 0.645524.
Train: 2018-08-01T01:37:12.945320: step 27854, loss 0.645455.
Train: 2018-08-01T01:37:13.101533: step 27855, loss 0.595648.
Train: 2018-08-01T01:37:13.257746: step 27856, loss 0.579074.
Train: 2018-08-01T01:37:13.429577: step 27857, loss 0.48011.
Train: 2018-08-01T01:37:13.585795: step 27858, loss 0.562571.
Train: 2018-08-01T01:37:13.741978: step 27859, loss 0.529619.
Train: 2018-08-01T01:37:13.898191: step 27860, loss 0.77684.
Test: 2018-08-01T01:37:14.382483: step 27860, loss 0.548828.
Train: 2018-08-01T01:37:14.538704: step 27861, loss 0.628357.
Train: 2018-08-01T01:37:14.710531: step 27862, loss 0.513452.
Train: 2018-08-01T01:37:14.866739: step 27863, loss 0.562643.
Train: 2018-08-01T01:37:15.022959: step 27864, loss 0.660652.
Train: 2018-08-01T01:37:15.179141: step 27865, loss 0.595265.
Train: 2018-08-01T01:37:15.335386: step 27866, loss 0.578963.
Train: 2018-08-01T01:37:15.507220: step 27867, loss 0.497931.
Train: 2018-08-01T01:37:15.679025: step 27868, loss 0.595133.
Train: 2018-08-01T01:37:15.835239: step 27869, loss 0.514289.
Train: 2018-08-01T01:37:15.991487: step 27870, loss 0.627413.
Test: 2018-08-01T01:37:16.475743: step 27870, loss 0.549281.
Train: 2018-08-01T01:37:16.631957: step 27871, loss 0.546657.
Train: 2018-08-01T01:37:16.819382: step 27872, loss 0.707989.
Train: 2018-08-01T01:37:16.959974: step 27873, loss 0.659398.
Train: 2018-08-01T01:37:17.116188: step 27874, loss 0.498715.
Train: 2018-08-01T01:37:17.272401: step 27875, loss 0.546895.
Train: 2018-08-01T01:37:17.428616: step 27876, loss 0.546933.
Train: 2018-08-01T01:37:17.584853: step 27877, loss 0.610876.
Train: 2018-08-01T01:37:17.756698: step 27878, loss 0.594876.
Train: 2018-08-01T01:37:17.928497: step 27879, loss 0.515138.
Train: 2018-08-01T01:37:18.100364: step 27880, loss 0.562972.
Test: 2018-08-01T01:37:18.553381: step 27880, loss 0.549622.
Train: 2018-08-01T01:37:18.725199: step 27881, loss 0.531089.
Train: 2018-08-01T01:37:18.881436: step 27882, loss 0.515104.
Train: 2018-08-01T01:37:19.053264: step 27883, loss 0.515007.
Train: 2018-08-01T01:37:19.209449: step 27884, loss 0.594931.
Train: 2018-08-01T01:37:19.365661: step 27885, loss 0.578921.
Train: 2018-08-01T01:37:19.537527: step 27886, loss 0.578925.
Train: 2018-08-01T01:37:19.693710: step 27887, loss 0.530658.
Train: 2018-08-01T01:37:19.849955: step 27888, loss 0.611174.
Train: 2018-08-01T01:37:20.021769: step 27889, loss 0.498238.
Train: 2018-08-01T01:37:20.177996: step 27890, loss 0.401022.
Test: 2018-08-01T01:37:20.662263: step 27890, loss 0.549114.
Train: 2018-08-01T01:37:20.818471: step 27891, loss 0.562718.
Train: 2018-08-01T01:37:20.974659: step 27892, loss 0.546361.
Train: 2018-08-01T01:37:21.130873: step 27893, loss 0.628139.
Train: 2018-08-01T01:37:21.287122: step 27894, loss 0.513333.
Train: 2018-08-01T01:37:21.443301: step 27895, loss 0.644967.
Train: 2018-08-01T01:37:21.599538: step 27896, loss 0.513021.
Train: 2018-08-01T01:37:21.755726: step 27897, loss 0.463209.
Train: 2018-08-01T01:37:21.911940: step 27898, loss 0.579125.
Train: 2018-08-01T01:37:22.083775: step 27899, loss 0.612497.
Train: 2018-08-01T01:37:22.255610: step 27900, loss 0.612599.
Test: 2018-08-01T01:37:22.724279: step 27900, loss 0.548452.
Train: 2018-08-01T01:37:23.442832: step 27901, loss 0.579198.
Train: 2018-08-01T01:37:23.599045: step 27902, loss 0.512197.
Train: 2018-08-01T01:37:23.755289: step 27903, loss 0.478529.
Train: 2018-08-01T01:37:23.911471: step 27904, loss 0.495115.
Train: 2018-08-01T01:37:24.067716: step 27905, loss 0.51176.
Train: 2018-08-01T01:37:24.239550: step 27906, loss 0.613265.
Train: 2018-08-01T01:37:24.395734: step 27907, loss 0.596401.
Train: 2018-08-01T01:37:24.551983: step 27908, loss 0.528336.
Train: 2018-08-01T01:37:24.708190: step 27909, loss 0.562398.
Train: 2018-08-01T01:37:24.864398: step 27910, loss 0.596611.
Test: 2018-08-01T01:37:25.333044: step 27910, loss 0.54805.
Train: 2018-08-01T01:37:25.489258: step 27911, loss 0.493867.
Train: 2018-08-01T01:37:25.661062: step 27912, loss 0.476549.
Train: 2018-08-01T01:37:25.817305: step 27913, loss 0.424631.
Train: 2018-08-01T01:37:25.989140: step 27914, loss 0.579699.
Train: 2018-08-01T01:37:26.129732: step 27915, loss 0.562411.
Train: 2018-08-01T01:37:26.285947: step 27916, loss 0.492757.
Train: 2018-08-01T01:37:26.442129: step 27917, loss 0.562436.
Train: 2018-08-01T01:37:26.629612: step 27918, loss 0.544913.
Train: 2018-08-01T01:37:26.785830: step 27919, loss 0.650433.
Train: 2018-08-01T01:37:26.942042: step 27920, loss 0.527234.
Test: 2018-08-01T01:37:27.410676: step 27920, loss 0.547707.
Train: 2018-08-01T01:37:27.566866: step 27921, loss 0.5978.
Train: 2018-08-01T01:37:27.738714: step 27922, loss 0.509472.
Train: 2018-08-01T01:37:27.894913: step 27923, loss 0.704139.
Train: 2018-08-01T01:37:28.051127: step 27924, loss 0.456318.
Train: 2018-08-01T01:37:28.207340: step 27925, loss 0.633369.
Train: 2018-08-01T01:37:28.363554: step 27926, loss 0.52709.
Train: 2018-08-01T01:37:28.519798: step 27927, loss 0.562515.
Train: 2018-08-01T01:37:28.675981: step 27928, loss 0.580233.
Train: 2018-08-01T01:37:28.879058: step 27929, loss 0.527087.
Train: 2018-08-01T01:37:29.035271: step 27930, loss 0.562515.
Test: 2018-08-01T01:37:29.503911: step 27930, loss 0.54768.
Train: 2018-08-01T01:37:29.660125: step 27931, loss 0.438497.
Train: 2018-08-01T01:37:29.816338: step 27932, loss 0.527043.
Train: 2018-08-01T01:37:29.988199: step 27933, loss 0.527.
Train: 2018-08-01T01:37:30.144418: step 27934, loss 0.580353.
Train: 2018-08-01T01:37:30.300600: step 27935, loss 0.437811.
Train: 2018-08-01T01:37:30.456814: step 27936, loss 0.580453.
Train: 2018-08-01T01:37:30.613028: step 27937, loss 0.526808.
Train: 2018-08-01T01:37:30.769241: step 27938, loss 0.598495.
Train: 2018-08-01T01:37:30.925484: step 27939, loss 0.634467.
Train: 2018-08-01T01:37:31.097325: step 27940, loss 0.508761.
Test: 2018-08-01T01:37:31.565959: step 27940, loss 0.547599.
Train: 2018-08-01T01:37:31.722142: step 27941, loss 0.472789.
Train: 2018-08-01T01:37:31.878356: step 27942, loss 0.526668.
Train: 2018-08-01T01:37:32.034600: step 27943, loss 0.490574.
Train: 2018-08-01T01:37:32.206436: step 27944, loss 0.580776.
Train: 2018-08-01T01:37:32.362618: step 27945, loss 0.544636.
Train: 2018-08-01T01:37:32.518832: step 27946, loss 0.635229.
Train: 2018-08-01T01:37:32.690667: step 27947, loss 0.544627.
Train: 2018-08-01T01:37:32.846909: step 27948, loss 0.526491.
Train: 2018-08-01T01:37:33.018715: step 27949, loss 0.490189.
Train: 2018-08-01T01:37:33.174929: step 27950, loss 0.599115.
Test: 2018-08-01T01:37:33.643599: step 27950, loss 0.54757.
Train: 2018-08-01T01:37:33.799811: step 27951, loss 0.617316.
Train: 2018-08-01T01:37:33.971616: step 27952, loss 0.490106.
Train: 2018-08-01T01:37:34.127860: step 27953, loss 0.635499.
Train: 2018-08-01T01:37:34.284043: step 27954, loss 0.562783.
Train: 2018-08-01T01:37:34.455909: step 27955, loss 0.562773.
Train: 2018-08-01T01:37:34.612121: step 27956, loss 0.508346.
Train: 2018-08-01T01:37:34.768341: step 27957, loss 0.544625.
Train: 2018-08-01T01:37:34.924547: step 27958, loss 0.725937.
Train: 2018-08-01T01:37:35.065134: step 27959, loss 0.617008.
Train: 2018-08-01T01:37:35.236970: step 27960, loss 0.562696.
Test: 2018-08-01T01:37:35.705614: step 27960, loss 0.547594.
Train: 2018-08-01T01:37:35.877450: step 27961, loss 0.544667.
Train: 2018-08-01T01:37:36.033664: step 27962, loss 0.65244.
Train: 2018-08-01T01:37:36.189876: step 27963, loss 0.544705.
Train: 2018-08-01T01:37:36.346059: step 27964, loss 0.616145.
Train: 2018-08-01T01:37:36.517896: step 27965, loss 0.58035.
Train: 2018-08-01T01:37:36.674108: step 27966, loss 0.598008.
Train: 2018-08-01T01:37:36.830352: step 27967, loss 0.527138.
Train: 2018-08-01T01:37:36.986559: step 27968, loss 0.474317.
Train: 2018-08-01T01:37:37.142749: step 27969, loss 0.544866.
Train: 2018-08-01T01:37:37.298991: step 27970, loss 0.474539.
Test: 2018-08-01T01:37:37.767633: step 27970, loss 0.547741.
Train: 2018-08-01T01:37:37.923845: step 27971, loss 0.580048.
Train: 2018-08-01T01:37:38.080059: step 27972, loss 0.474581.
Train: 2018-08-01T01:37:38.236273: step 27973, loss 0.562466.
Train: 2018-08-01T01:37:38.408108: step 27974, loss 0.544873.
Train: 2018-08-01T01:37:38.564290: step 27975, loss 0.597685.
Train: 2018-08-01T01:37:38.720504: step 27976, loss 0.615293.
Train: 2018-08-01T01:37:38.876718: step 27977, loss 0.615254.
Train: 2018-08-01T01:37:39.032962: step 27978, loss 0.632751.
Train: 2018-08-01T01:37:39.189174: step 27979, loss 0.457233.
Train: 2018-08-01T01:37:39.361009: step 27980, loss 0.562447.
Test: 2018-08-01T01:37:39.814027: step 27980, loss 0.547779.
Train: 2018-08-01T01:37:39.970211: step 27981, loss 0.59747.
Train: 2018-08-01T01:37:40.126455: step 27982, loss 0.52745.
Train: 2018-08-01T01:37:40.282663: step 27983, loss 0.57992.
Train: 2018-08-01T01:37:40.438882: step 27984, loss 0.492553.
Train: 2018-08-01T01:37:40.595095: step 27985, loss 0.51002.
Train: 2018-08-01T01:37:40.751309: step 27986, loss 0.5974.
Train: 2018-08-01T01:37:40.923113: step 27987, loss 0.527468.
Train: 2018-08-01T01:37:41.079326: step 27988, loss 0.457486.
Train: 2018-08-01T01:37:41.235570: step 27989, loss 0.439805.
Train: 2018-08-01T01:37:41.391753: step 27990, loss 0.580031.
Test: 2018-08-01T01:37:41.860392: step 27990, loss 0.547728.
Train: 2018-08-01T01:37:42.047879: step 27991, loss 0.474424.
Train: 2018-08-01T01:37:42.204095: step 27992, loss 0.597819.
Train: 2018-08-01T01:37:42.360276: step 27993, loss 0.600273.
Train: 2018-08-01T01:37:42.532110: step 27994, loss 0.544792.
Train: 2018-08-01T01:37:42.688354: step 27995, loss 0.562531.
Train: 2018-08-01T01:37:42.844568: step 27996, loss 0.633637.
Train: 2018-08-01T01:37:43.000780: step 27997, loss 0.491435.
Train: 2018-08-01T01:37:43.172586: step 27998, loss 0.562549.
Train: 2018-08-01T01:37:43.328824: step 27999, loss 0.615967.
Train: 2018-08-01T01:37:43.485013: step 28000, loss 0.473544.
Test: 2018-08-01T01:37:43.953653: step 28000, loss 0.547642.
Train: 2018-08-01T01:37:44.625401: step 28001, loss 0.491295.
Train: 2018-08-01T01:37:44.797205: step 28002, loss 0.52689.
Train: 2018-08-01T01:37:44.953420: step 28003, loss 0.526847.
Train: 2018-08-01T01:37:45.109663: step 28004, loss 0.526802.
Train: 2018-08-01T01:37:45.281467: step 28005, loss 0.580563.
Train: 2018-08-01T01:37:45.437681: step 28006, loss 0.562642.
Train: 2018-08-01T01:37:45.593894: step 28007, loss 0.544674.
Train: 2018-08-01T01:37:45.750138: step 28008, loss 0.562666.
Train: 2018-08-01T01:37:45.906347: step 28009, loss 0.544661.
Train: 2018-08-01T01:37:46.062534: step 28010, loss 0.580713.
Test: 2018-08-01T01:37:46.531205: step 28010, loss 0.547587.
Train: 2018-08-01T01:37:46.687388: step 28011, loss 0.544654.
Train: 2018-08-01T01:37:46.843602: step 28012, loss 0.508566.
Train: 2018-08-01T01:37:46.999845: step 28013, loss 0.562705.
Train: 2018-08-01T01:37:47.156059: step 28014, loss 0.598852.
Train: 2018-08-01T01:37:47.327893: step 28015, loss 0.562713.
Train: 2018-08-01T01:37:47.499728: step 28016, loss 0.598847.
Train: 2018-08-01T01:37:47.655943: step 28017, loss 0.472424.
Train: 2018-08-01T01:37:47.812125: step 28018, loss 0.472402.
Train: 2018-08-01T01:37:47.968338: step 28019, loss 0.562721.
Train: 2018-08-01T01:37:48.124582: step 28020, loss 0.635121.
Test: 2018-08-01T01:37:48.608813: step 28020, loss 0.547578.
Train: 2018-08-01T01:37:48.765026: step 28021, loss 0.617012.
Train: 2018-08-01T01:37:48.905650: step 28022, loss 0.580796.
Train: 2018-08-01T01:37:49.077483: step 28023, loss 0.634932.
Train: 2018-08-01T01:37:49.233697: step 28024, loss 0.490596.
Train: 2018-08-01T01:37:49.389880: step 28025, loss 0.580668.
Train: 2018-08-01T01:37:49.530503: step 28026, loss 0.436815.
Train: 2018-08-01T01:37:49.702307: step 28027, loss 0.562653.
Train: 2018-08-01T01:37:49.858520: step 28028, loss 0.65254.
Train: 2018-08-01T01:37:50.014759: step 28029, loss 0.544683.
Train: 2018-08-01T01:37:50.170972: step 28030, loss 0.67026.
Test: 2018-08-01T01:37:50.639618: step 28030, loss 0.547617.
Train: 2018-08-01T01:37:50.811423: step 28031, loss 0.598402.
Train: 2018-08-01T01:37:50.967671: step 28032, loss 0.598287.
Train: 2018-08-01T01:37:51.123874: step 28033, loss 0.509146.
Train: 2018-08-01T01:37:51.280094: step 28034, loss 0.509237.
Train: 2018-08-01T01:37:51.436306: step 28035, loss 0.491552.
Train: 2018-08-01T01:37:51.592520: step 28036, loss 0.651204.
Train: 2018-08-01T01:37:51.748703: step 28037, loss 0.456257.
Train: 2018-08-01T01:37:51.936183: step 28038, loss 0.615627.
Train: 2018-08-01T01:37:52.092372: step 28039, loss 0.527125.
Train: 2018-08-01T01:37:52.248616: step 28040, loss 0.597862.
Test: 2018-08-01T01:37:52.717225: step 28040, loss 0.547702.
Train: 2018-08-01T01:37:52.873440: step 28041, loss 0.597823.
Train: 2018-08-01T01:37:53.045274: step 28042, loss 0.491921.
Train: 2018-08-01T01:37:53.201487: step 28043, loss 0.43905.
Train: 2018-08-01T01:37:53.357700: step 28044, loss 0.703691.
Train: 2018-08-01T01:37:53.513945: step 28045, loss 0.562483.
Train: 2018-08-01T01:37:53.670128: step 28046, loss 0.562478.
Train: 2018-08-01T01:37:53.826372: step 28047, loss 0.703316.
Train: 2018-08-01T01:37:53.982555: step 28048, loss 0.667829.
Train: 2018-08-01T01:37:54.154389: step 28049, loss 0.632439.
Train: 2018-08-01T01:37:54.310602: step 28050, loss 0.527567.
Test: 2018-08-01T01:37:54.779243: step 28050, loss 0.547867.
Train: 2018-08-01T01:37:54.951108: step 28051, loss 0.510301.
Train: 2018-08-01T01:37:55.107308: step 28052, loss 0.475763.
Train: 2018-08-01T01:37:55.263536: step 28053, loss 0.63164.
Train: 2018-08-01T01:37:55.419719: step 28054, loss 0.596953.
Train: 2018-08-01T01:37:55.575931: step 28055, loss 0.562398.
Train: 2018-08-01T01:37:55.732175: step 28056, loss 0.545191.
Train: 2018-08-01T01:37:55.888390: step 28057, loss 0.579574.
Train: 2018-08-01T01:37:56.060194: step 28058, loss 0.579546.
Train: 2018-08-01T01:37:56.216406: step 28059, loss 0.579518.
Train: 2018-08-01T01:37:56.372651: step 28060, loss 0.613675.
Test: 2018-08-01T01:37:56.856911: step 28060, loss 0.548117.
Train: 2018-08-01T01:37:57.013096: step 28061, loss 0.545344.
Train: 2018-08-01T01:37:57.169338: step 28062, loss 0.477272.
Train: 2018-08-01T01:37:57.341168: step 28063, loss 0.494331.
Train: 2018-08-01T01:37:57.481766: step 28064, loss 0.681582.
Train: 2018-08-01T01:37:57.637980: step 28065, loss 0.528389.
Train: 2018-08-01T01:37:57.794187: step 28066, loss 0.511408.
Train: 2018-08-01T01:37:57.950406: step 28067, loss 0.494394.
Train: 2018-08-01T01:37:58.122240: step 28068, loss 0.545382.
Train: 2018-08-01T01:37:58.262802: step 28069, loss 0.579442.
Train: 2018-08-01T01:37:58.434668: step 28070, loss 0.579456.
Test: 2018-08-01T01:37:58.903308: step 28070, loss 0.548107.
Train: 2018-08-01T01:37:59.075113: step 28071, loss 0.579465.
Train: 2018-08-01T01:37:59.231355: step 28072, loss 0.664832.
Train: 2018-08-01T01:37:59.387539: step 28073, loss 0.545343.
Train: 2018-08-01T01:37:59.559404: step 28074, loss 0.443085.
Train: 2018-08-01T01:37:59.715617: step 28075, loss 0.562399.
Train: 2018-08-01T01:37:59.871825: step 28076, loss 0.59655.
Train: 2018-08-01T01:38:00.028016: step 28077, loss 0.545316.
Train: 2018-08-01T01:38:00.184228: step 28078, loss 0.545306.
Train: 2018-08-01T01:38:00.356092: step 28079, loss 0.613708.
Train: 2018-08-01T01:38:00.496685: step 28080, loss 0.528188.
Test: 2018-08-01T01:38:00.980916: step 28080, loss 0.548067.
Train: 2018-08-01T01:38:01.137161: step 28081, loss 0.511061.
Train: 2018-08-01T01:38:01.293343: step 28082, loss 0.545266.
Train: 2018-08-01T01:38:01.449587: step 28083, loss 0.562395.
Train: 2018-08-01T01:38:01.605771: step 28084, loss 0.476557.
Train: 2018-08-01T01:38:01.793225: step 28085, loss 0.545194.
Train: 2018-08-01T01:38:01.949464: step 28086, loss 0.631344.
Train: 2018-08-01T01:38:02.105682: step 28087, loss 0.458883.
Train: 2018-08-01T01:38:02.261865: step 28088, loss 0.545113.
Train: 2018-08-01T01:38:02.418109: step 28089, loss 0.61438.
Train: 2018-08-01T01:38:02.574323: step 28090, loss 0.562409.
Test: 2018-08-01T01:38:03.042963: step 28090, loss 0.547872.
Train: 2018-08-01T01:38:03.199147: step 28091, loss 0.475593.
Train: 2018-08-01T01:38:03.355385: step 28092, loss 0.632009.
Train: 2018-08-01T01:38:03.511574: step 28093, loss 0.632074.
Train: 2018-08-01T01:38:03.667817: step 28094, loss 0.719127.
Train: 2018-08-01T01:38:03.839623: step 28095, loss 0.597168.
Train: 2018-08-01T01:38:04.011487: step 28096, loss 0.562408.
Train: 2018-08-01T01:38:04.152049: step 28097, loss 0.545101.
Train: 2018-08-01T01:38:04.323883: step 28098, loss 0.562401.
Train: 2018-08-01T01:38:04.480129: step 28099, loss 0.527905.
Train: 2018-08-01T01:38:04.636335: step 28100, loss 0.527937.
Test: 2018-08-01T01:38:05.104980: step 28100, loss 0.547976.
Train: 2018-08-01T01:38:05.823532: step 28101, loss 0.476286.
Train: 2018-08-01T01:38:05.979746: step 28102, loss 0.545165.
Train: 2018-08-01T01:38:06.151580: step 28103, loss 0.562398.
Train: 2018-08-01T01:38:06.292203: step 28104, loss 0.648688.
Train: 2018-08-01T01:38:06.448417: step 28105, loss 0.527899.
Train: 2018-08-01T01:38:06.604629: step 28106, loss 0.562399.
Train: 2018-08-01T01:38:06.760813: step 28107, loss 0.5279.
Train: 2018-08-01T01:38:06.932647: step 28108, loss 0.545143.
Train: 2018-08-01T01:38:07.088885: step 28109, loss 0.5624.
Train: 2018-08-01T01:38:07.245105: step 28110, loss 0.562401.
Test: 2018-08-01T01:38:07.713746: step 28110, loss 0.547931.
Train: 2018-08-01T01:38:07.869952: step 28111, loss 0.579681.
Train: 2018-08-01T01:38:08.041763: step 28112, loss 0.631531.
Train: 2018-08-01T01:38:08.182384: step 28113, loss 0.57967.
Train: 2018-08-01T01:38:08.354189: step 28114, loss 0.562399.
Train: 2018-08-01T01:38:08.510434: step 28115, loss 0.527919.
Train: 2018-08-01T01:38:08.666649: step 28116, loss 0.476229.
Train: 2018-08-01T01:38:08.822829: step 28117, loss 0.648632.
Train: 2018-08-01T01:38:08.979044: step 28118, loss 0.614117.
Train: 2018-08-01T01:38:09.150877: step 28119, loss 0.51073.
Train: 2018-08-01T01:38:09.307121: step 28120, loss 0.614049.
Test: 2018-08-01T01:38:09.760146: step 28120, loss 0.547992.
Train: 2018-08-01T01:38:09.916354: step 28121, loss 0.510791.
Train: 2018-08-01T01:38:10.072563: step 28122, loss 0.493602.
Train: 2018-08-01T01:38:10.244372: step 28123, loss 0.527976.
Train: 2018-08-01T01:38:10.400618: step 28124, loss 0.54517.
Train: 2018-08-01T01:38:10.572421: step 28125, loss 0.476163.
Train: 2018-08-01T01:38:10.728633: step 28126, loss 0.596967.
Train: 2018-08-01T01:38:10.884878: step 28127, loss 0.579711.
Train: 2018-08-01T01:38:11.056712: step 28128, loss 0.545082.
Train: 2018-08-01T01:38:11.212925: step 28129, loss 0.649127.
Train: 2018-08-01T01:38:11.369138: step 28130, loss 0.597093.
Test: 2018-08-01T01:38:11.853370: step 28130, loss 0.547893.
Train: 2018-08-01T01:38:12.009615: step 28131, loss 0.649071.
Train: 2018-08-01T01:38:12.165797: step 28132, loss 0.493181.
Train: 2018-08-01T01:38:12.322010: step 28133, loss 0.562403.
Train: 2018-08-01T01:38:12.478254: step 28134, loss 0.596974.
Train: 2018-08-01T01:38:12.634475: step 28135, loss 0.5624.
Train: 2018-08-01T01:38:12.806272: step 28136, loss 0.493381.
Train: 2018-08-01T01:38:12.962485: step 28137, loss 0.510633.
Train: 2018-08-01T01:38:13.118729: step 28138, loss 0.666002.
Train: 2018-08-01T01:38:13.259290: step 28139, loss 0.527889.
Train: 2018-08-01T01:38:13.431126: step 28140, loss 0.476142.
Test: 2018-08-01T01:38:13.899765: step 28140, loss 0.547942.
Train: 2018-08-01T01:38:14.055979: step 28141, loss 0.5624.
Train: 2018-08-01T01:38:14.212223: step 28142, loss 0.648796.
Train: 2018-08-01T01:38:14.368436: step 28143, loss 0.614217.
Train: 2018-08-01T01:38:14.524619: step 28144, loss 0.545145.
Train: 2018-08-01T01:38:14.680863: step 28145, loss 0.683092.
Train: 2018-08-01T01:38:14.837047: step 28146, loss 0.596806.
Train: 2018-08-01T01:38:15.008881: step 28147, loss 0.528067.
Train: 2018-08-01T01:38:15.165124: step 28148, loss 0.648069.
Train: 2018-08-01T01:38:15.321307: step 28149, loss 0.476947.
Train: 2018-08-01T01:38:15.477522: step 28150, loss 0.630672.
Test: 2018-08-01T01:38:15.946187: step 28150, loss 0.548137.
Train: 2018-08-01T01:38:16.102399: step 28151, loss 0.528332.
Train: 2018-08-01T01:38:16.258619: step 28152, loss 0.52838.
Train: 2018-08-01T01:38:16.414802: step 28153, loss 0.681396.
Train: 2018-08-01T01:38:16.571015: step 28154, loss 0.545448.
Train: 2018-08-01T01:38:16.727228: step 28155, loss 0.613214.
Train: 2018-08-01T01:38:16.883441: step 28156, loss 0.613112.
Train: 2018-08-01T01:38:17.055311: step 28157, loss 0.478161.
Train: 2018-08-01T01:38:17.211520: step 28158, loss 0.461428.
Train: 2018-08-01T01:38:17.367703: step 28159, loss 0.478235.
Train: 2018-08-01T01:38:17.539539: step 28160, loss 0.528701.
Test: 2018-08-01T01:38:18.008209: step 28160, loss 0.548276.
Train: 2018-08-01T01:38:18.195666: step 28161, loss 0.528636.
Train: 2018-08-01T01:38:18.351878: step 28162, loss 0.545488.
Train: 2018-08-01T01:38:18.508093: step 28163, loss 0.528483.
Train: 2018-08-01T01:38:18.664305: step 28164, loss 0.630418.
Train: 2018-08-01T01:38:18.836135: step 28165, loss 0.562402.
Train: 2018-08-01T01:38:18.992353: step 28166, loss 0.63058.
Train: 2018-08-01T01:38:19.148568: step 28167, loss 0.511255.
Train: 2018-08-01T01:38:19.304750: step 28168, loss 0.442958.
Train: 2018-08-01T01:38:19.460988: step 28169, loss 0.665007.
Train: 2018-08-01T01:38:19.617177: step 28170, loss 0.630856.
Test: 2018-08-01T01:38:20.085847: step 28170, loss 0.548066.
Train: 2018-08-01T01:38:20.242061: step 28171, loss 0.647958.
Train: 2018-08-01T01:38:20.476381: step 28172, loss 0.613673.
Train: 2018-08-01T01:38:20.632595: step 28173, loss 0.477084.
Train: 2018-08-01T01:38:20.788807: step 28174, loss 0.579455.
Train: 2018-08-01T01:38:20.944991: step 28175, loss 0.49422.
Train: 2018-08-01T01:38:21.101235: step 28176, loss 0.528299.
Train: 2018-08-01T01:38:21.257417: step 28177, loss 0.579462.
Train: 2018-08-01T01:38:21.413630: step 28178, loss 0.545327.
Train: 2018-08-01T01:38:21.585466: step 28179, loss 0.545315.
Train: 2018-08-01T01:38:21.741679: step 28180, loss 0.511109.
Test: 2018-08-01T01:38:22.210350: step 28180, loss 0.54806.
Train: 2018-08-01T01:38:22.366564: step 28181, loss 0.562396.
Train: 2018-08-01T01:38:22.538399: step 28182, loss 0.493832.
Train: 2018-08-01T01:38:22.710226: step 28183, loss 0.562396.
Train: 2018-08-01T01:38:22.866446: step 28184, loss 0.562396.
Train: 2018-08-01T01:38:23.022660: step 28185, loss 0.57963.
Train: 2018-08-01T01:38:23.178873: step 28186, loss 0.545146.
Train: 2018-08-01T01:38:23.335086: step 28187, loss 0.562401.
Train: 2018-08-01T01:38:23.491300: step 28188, loss 0.75264.
Train: 2018-08-01T01:38:23.647486: step 28189, loss 0.42423.
Train: 2018-08-01T01:38:23.803697: step 28190, loss 0.545122.
Test: 2018-08-01T01:38:24.287988: step 28190, loss 0.547924.
Train: 2018-08-01T01:38:24.444172: step 28191, loss 0.614272.
Train: 2018-08-01T01:38:24.600415: step 28192, loss 0.527826.
Train: 2018-08-01T01:38:24.772220: step 28193, loss 0.527815.
Train: 2018-08-01T01:38:24.928465: step 28194, loss 0.61432.
Train: 2018-08-01T01:38:25.069055: step 28195, loss 0.527795.
Train: 2018-08-01T01:38:25.240891: step 28196, loss 0.475852.
Train: 2018-08-01T01:38:25.397073: step 28197, loss 0.493072.
Train: 2018-08-01T01:38:25.553286: step 28198, loss 0.527675.
Train: 2018-08-01T01:38:25.709501: step 28199, loss 0.492791.
Train: 2018-08-01T01:38:25.881335: step 28200, loss 0.544974.
Test: 2018-08-01T01:38:26.349977: step 28200, loss 0.547786.
Train: 2018-08-01T01:38:27.084214: step 28201, loss 0.509937.
Train: 2018-08-01T01:38:27.240391: step 28202, loss 0.562455.
Train: 2018-08-01T01:38:27.380984: step 28203, loss 0.632863.
Train: 2018-08-01T01:38:27.552849: step 28204, loss 0.509609.
Train: 2018-08-01T01:38:27.709062: step 28205, loss 0.615456.
Train: 2018-08-01T01:38:27.865245: step 28206, loss 0.544825.
Train: 2018-08-01T01:38:28.021485: step 28207, loss 0.509436.
Train: 2018-08-01T01:38:28.208945: step 28208, loss 0.491658.
Train: 2018-08-01T01:38:28.365129: step 28209, loss 0.580279.
Train: 2018-08-01T01:38:28.521342: step 28210, loss 0.562542.
Test: 2018-08-01T01:38:28.989981: step 28210, loss 0.547649.
Train: 2018-08-01T01:38:29.146220: step 28211, loss 0.437965.
Train: 2018-08-01T01:38:29.302408: step 28212, loss 0.509049.
Train: 2018-08-01T01:38:29.458622: step 28213, loss 0.50893.
Train: 2018-08-01T01:38:29.630488: step 28214, loss 0.508803.
Train: 2018-08-01T01:38:29.786670: step 28215, loss 0.598663.
Train: 2018-08-01T01:38:29.942884: step 28216, loss 0.670929.
Train: 2018-08-01T01:38:30.099122: step 28217, loss 0.526597.
Train: 2018-08-01T01:38:30.270933: step 28218, loss 0.616915.
Train: 2018-08-01T01:38:30.427145: step 28219, loss 0.472369.
Train: 2018-08-01T01:38:30.583389: step 28220, loss 0.526553.
Test: 2018-08-01T01:38:31.052030: step 28220, loss 0.547577.
Train: 2018-08-01T01:38:31.192621: step 28221, loss 0.562737.
Train: 2018-08-01T01:38:31.364426: step 28222, loss 0.490269.
Train: 2018-08-01T01:38:31.520671: step 28223, loss 0.562767.
Train: 2018-08-01T01:38:31.692504: step 28224, loss 0.562782.
Train: 2018-08-01T01:38:31.848718: step 28225, loss 0.635517.
Train: 2018-08-01T01:38:32.004900: step 28226, loss 0.50826.
Train: 2018-08-01T01:38:32.161145: step 28227, loss 0.599159.
Train: 2018-08-01T01:38:32.332979: step 28228, loss 0.653673.
Train: 2018-08-01T01:38:32.520404: step 28229, loss 0.599071.
Train: 2018-08-01T01:38:32.676649: step 28230, loss 0.544629.
Test: 2018-08-01T01:38:33.160884: step 28230, loss 0.547579.
Train: 2018-08-01T01:38:33.317124: step 28231, loss 0.67125.
Train: 2018-08-01T01:38:33.473306: step 28232, loss 0.670912.
Train: 2018-08-01T01:38:33.660763: step 28233, loss 0.634514.
Train: 2018-08-01T01:38:33.817006: step 28234, loss 0.616262.
Train: 2018-08-01T01:38:33.973215: step 28235, loss 0.509146.
Train: 2018-08-01T01:38:34.129440: step 28236, loss 0.686676.
Train: 2018-08-01T01:38:34.285617: step 28237, loss 0.633084.
Train: 2018-08-01T01:38:34.441860: step 28238, loss 0.492237.
Train: 2018-08-01T01:38:34.613694: step 28239, loss 0.52747.
Train: 2018-08-01T01:38:34.785500: step 28240, loss 0.579848.
Test: 2018-08-01T01:38:35.238549: step 28240, loss 0.547868.
Train: 2018-08-01T01:38:35.394763: step 28241, loss 0.562413.
Train: 2018-08-01T01:38:35.550976: step 28242, loss 0.545088.
Train: 2018-08-01T01:38:35.722782: step 28243, loss 0.545127.
Train: 2018-08-01T01:38:35.878993: step 28244, loss 0.596875.
Train: 2018-08-01T01:38:36.035237: step 28245, loss 0.527998.
Train: 2018-08-01T01:38:36.191451: step 28246, loss 0.596736.
Train: 2018-08-01T01:38:36.363280: step 28247, loss 0.510983.
Train: 2018-08-01T01:38:36.519494: step 28248, loss 0.459684.
Train: 2018-08-01T01:38:36.675712: step 28249, loss 0.459653.
Train: 2018-08-01T01:38:36.847554: step 28250, loss 0.528095.
Test: 2018-08-01T01:38:37.316187: step 28250, loss 0.548008.
Train: 2018-08-01T01:38:37.472400: step 28251, loss 0.510851.
Train: 2018-08-01T01:38:37.628615: step 28252, loss 0.631278.
Train: 2018-08-01T01:38:37.784828: step 28253, loss 0.579639.
Train: 2018-08-01T01:38:37.972253: step 28254, loss 0.545144.
Train: 2018-08-01T01:38:38.128467: step 28255, loss 0.579672.
Train: 2018-08-01T01:38:38.284680: step 28256, loss 0.596965.
Train: 2018-08-01T01:38:38.425302: step 28257, loss 0.527834.
Train: 2018-08-01T01:38:38.597106: step 28258, loss 0.683452.
Train: 2018-08-01T01:38:38.737729: step 28259, loss 0.59695.
Train: 2018-08-01T01:38:38.893944: step 28260, loss 0.562399.
Test: 2018-08-01T01:38:39.362553: step 28260, loss 0.54797.
Train: 2018-08-01T01:38:39.518797: step 28261, loss 0.545168.
Train: 2018-08-01T01:38:39.675010: step 28262, loss 0.596823.
Train: 2018-08-01T01:38:39.846844: step 28263, loss 0.49363.
Train: 2018-08-01T01:38:40.003028: step 28264, loss 0.613954.
Train: 2018-08-01T01:38:40.159267: step 28265, loss 0.562395.
Train: 2018-08-01T01:38:40.315480: step 28266, loss 0.579552.
Train: 2018-08-01T01:38:40.471699: step 28267, loss 0.562396.
Train: 2018-08-01T01:38:40.627883: step 28268, loss 0.630896.
Train: 2018-08-01T01:38:40.784094: step 28269, loss 0.647883.
Train: 2018-08-01T01:38:40.940308: step 28270, loss 0.477128.
Test: 2018-08-01T01:38:41.408979: step 28270, loss 0.548137.
Train: 2018-08-01T01:38:41.565195: step 28271, loss 0.545367.
Train: 2018-08-01T01:38:41.721406: step 28272, loss 0.613462.
Train: 2018-08-01T01:38:41.893241: step 28273, loss 0.596398.
Train: 2018-08-01T01:38:42.065045: step 28274, loss 0.477566.
Train: 2018-08-01T01:38:42.221258: step 28275, loss 0.579372.
Train: 2018-08-01T01:38:42.393093: step 28276, loss 0.613272.
Train: 2018-08-01T01:38:42.533715: step 28277, loss 0.477738.
Train: 2018-08-01T01:38:42.689929: step 28278, loss 0.596289.
Train: 2018-08-01T01:38:42.846142: step 28279, loss 0.545482.
Train: 2018-08-01T01:38:43.017946: step 28280, loss 0.511615.
Test: 2018-08-01T01:38:43.486619: step 28280, loss 0.548223.
Train: 2018-08-01T01:38:43.642832: step 28281, loss 0.562413.
Train: 2018-08-01T01:38:43.814671: step 28282, loss 0.562411.
Train: 2018-08-01T01:38:43.970849: step 28283, loss 0.545442.
Train: 2018-08-01T01:38:44.142684: step 28284, loss 0.562407.
Train: 2018-08-01T01:38:44.283306: step 28285, loss 0.579399.
Train: 2018-08-01T01:38:44.455148: step 28286, loss 0.647415.
Train: 2018-08-01T01:38:44.626944: step 28287, loss 0.732323.
Train: 2018-08-01T01:38:44.767568: step 28288, loss 0.579359.
Train: 2018-08-01T01:38:44.923780: step 28289, loss 0.461003.
Train: 2018-08-01T01:38:45.079965: step 28290, loss 0.562424.
Test: 2018-08-01T01:38:45.548634: step 28290, loss 0.548298.
Train: 2018-08-01T01:38:45.736085: step 28291, loss 0.59617.
Train: 2018-08-01T01:38:45.892298: step 28292, loss 0.579284.
Train: 2018-08-01T01:38:46.048486: step 28293, loss 0.528772.
Train: 2018-08-01T01:38:46.204702: step 28294, loss 0.562439.
Train: 2018-08-01T01:38:46.360945: step 28295, loss 0.612883.
Train: 2018-08-01T01:38:46.532749: step 28296, loss 0.528852.
Train: 2018-08-01T01:38:46.688994: step 28297, loss 0.696765.
Train: 2018-08-01T01:38:46.845176: step 28298, loss 0.545703.
Train: 2018-08-01T01:38:47.017010: step 28299, loss 0.64611.
Train: 2018-08-01T01:38:47.173223: step 28300, loss 0.629232.
Test: 2018-08-01T01:38:47.657515: step 28300, loss 0.548567.
Train: 2018-08-01T01:38:48.376098: step 28301, loss 0.562499.
Train: 2018-08-01T01:38:48.532280: step 28302, loss 0.496138.
Train: 2018-08-01T01:38:48.688525: step 28303, loss 0.479668.
Train: 2018-08-01T01:38:48.844707: step 28304, loss 0.645383.
Train: 2018-08-01T01:38:49.016542: step 28305, loss 0.628751.
Train: 2018-08-01T01:38:49.172755: step 28306, loss 0.612126.
Train: 2018-08-01T01:38:49.328999: step 28307, loss 0.546076.
Train: 2018-08-01T01:38:49.485212: step 28308, loss 0.480255.
Train: 2018-08-01T01:38:49.657047: step 28309, loss 0.447347.
Train: 2018-08-01T01:38:49.813231: step 28310, loss 0.61203.
Test: 2018-08-01T01:38:50.281901: step 28310, loss 0.548745.
Train: 2018-08-01T01:38:50.438085: step 28311, loss 0.529562.
Train: 2018-08-01T01:38:50.594298: step 28312, loss 0.496467.
Train: 2018-08-01T01:38:50.750511: step 28313, loss 0.62876.
Train: 2018-08-01T01:38:50.906724: step 28314, loss 0.678553.
Train: 2018-08-01T01:38:51.062938: step 28315, loss 0.545961.
Train: 2018-08-01T01:38:51.250426: step 28316, loss 0.678503.
Train: 2018-08-01T01:38:51.406638: step 28317, loss 0.562541.
Train: 2018-08-01T01:38:51.562851: step 28318, loss 0.562551.
Train: 2018-08-01T01:38:51.719035: step 28319, loss 0.480027.
Train: 2018-08-01T01:38:51.875248: step 28320, loss 0.463487.
Test: 2018-08-01T01:38:52.343912: step 28320, loss 0.548693.
Train: 2018-08-01T01:38:52.500101: step 28321, loss 0.628701.
Train: 2018-08-01T01:38:52.656345: step 28322, loss 0.562537.
Train: 2018-08-01T01:38:52.812558: step 28323, loss 0.612227.
Train: 2018-08-01T01:38:52.968742: step 28324, loss 0.612233.
Train: 2018-08-01T01:38:53.124954: step 28325, loss 0.595655.
Train: 2018-08-01T01:38:53.296790: step 28326, loss 0.52944.
Train: 2018-08-01T01:38:53.437412: step 28327, loss 0.645276.
Train: 2018-08-01T01:38:53.609247: step 28328, loss 0.49643.
Train: 2018-08-01T01:38:53.765431: step 28329, loss 0.579077.
Train: 2018-08-01T01:38:53.921645: step 28330, loss 0.562548.
Test: 2018-08-01T01:38:54.405935: step 28330, loss 0.548708.
Train: 2018-08-01T01:38:54.562119: step 28331, loss 0.562548.
Train: 2018-08-01T01:38:54.718332: step 28332, loss 0.595607.
Train: 2018-08-01T01:38:54.874571: step 28333, loss 0.595602.
Train: 2018-08-01T01:38:55.030758: step 28334, loss 0.579071.
Train: 2018-08-01T01:38:55.187002: step 28335, loss 0.546051.
Train: 2018-08-01T01:38:55.343186: step 28336, loss 0.463534.
Train: 2018-08-01T01:38:55.515051: step 28337, loss 0.512975.
Train: 2018-08-01T01:38:55.671264: step 28338, loss 0.579091.
Train: 2018-08-01T01:38:55.827448: step 28339, loss 0.579105.
Train: 2018-08-01T01:38:55.983691: step 28340, loss 0.479495.
Test: 2018-08-01T01:38:56.452331: step 28340, loss 0.548561.
Train: 2018-08-01T01:38:56.624136: step 28341, loss 0.545855.
Train: 2018-08-01T01:38:56.780349: step 28342, loss 0.462383.
Train: 2018-08-01T01:38:56.920941: step 28343, loss 0.545719.
Train: 2018-08-01T01:38:57.092806: step 28344, loss 0.512042.
Train: 2018-08-01T01:38:57.244408: step 28345, loss 0.680482.
Train: 2018-08-01T01:38:57.400623: step 28346, loss 0.528625.
Train: 2018-08-01T01:38:57.556805: step 28347, loss 0.545478.
Train: 2018-08-01T01:38:57.728640: step 28348, loss 0.511485.
Train: 2018-08-01T01:38:57.884852: step 28349, loss 0.511342.
Train: 2018-08-01T01:38:58.041067: step 28350, loss 0.579471.
Test: 2018-08-01T01:38:58.525328: step 28350, loss 0.548063.
Train: 2018-08-01T01:38:58.681572: step 28351, loss 0.579513.
Train: 2018-08-01T01:38:58.868997: step 28352, loss 0.631006.
Train: 2018-08-01T01:38:59.009624: step 28353, loss 0.596737.
Train: 2018-08-01T01:38:59.181426: step 28354, loss 0.682652.
Train: 2018-08-01T01:38:59.368910: step 28355, loss 0.682529.
Train: 2018-08-01T01:38:59.525119: step 28356, loss 0.562396.
Train: 2018-08-01T01:38:59.696953: step 28357, loss 0.528229.
Train: 2018-08-01T01:38:59.853168: step 28358, loss 0.528283.
Train: 2018-08-01T01:39:00.009395: step 28359, loss 0.528315.
Train: 2018-08-01T01:39:00.181221: step 28360, loss 0.528329.
Test: 2018-08-01T01:39:00.649861: step 28360, loss 0.548134.
Train: 2018-08-01T01:39:00.806074: step 28361, loss 0.49425.
Train: 2018-08-01T01:39:00.977904: step 28362, loss 0.630616.
Train: 2018-08-01T01:39:01.118471: step 28363, loss 0.681781.
Train: 2018-08-01T01:39:01.274715: step 28364, loss 0.613491.
Train: 2018-08-01T01:39:01.430933: step 28365, loss 0.562405.
Train: 2018-08-01T01:39:01.602762: step 28366, loss 0.596346.
Train: 2018-08-01T01:39:01.758981: step 28367, loss 0.562414.
Train: 2018-08-01T01:39:01.915160: step 28368, loss 0.545513.
Train: 2018-08-01T01:39:02.087030: step 28369, loss 0.596194.
Train: 2018-08-01T01:39:02.227616: step 28370, loss 0.511853.
Test: 2018-08-01T01:39:02.711878: step 28370, loss 0.548325.
Train: 2018-08-01T01:39:02.914955: step 28371, loss 0.478196.
Train: 2018-08-01T01:39:03.071138: step 28372, loss 0.596142.
Train: 2018-08-01T01:39:03.258595: step 28373, loss 0.511859.
Train: 2018-08-01T01:39:03.414840: step 28374, loss 0.646776.
Train: 2018-08-01T01:39:03.571046: step 28375, loss 0.714203.
Train: 2018-08-01T01:39:03.727265: step 28376, loss 0.54561.
Train: 2018-08-01T01:39:03.883483: step 28377, loss 0.596041.
Train: 2018-08-01T01:39:04.039692: step 28378, loss 0.478624.
Train: 2018-08-01T01:39:04.211529: step 28379, loss 0.662996.
Train: 2018-08-01T01:39:04.383365: step 28380, loss 0.54574.
Test: 2018-08-01T01:39:04.851972: step 28380, loss 0.548485.
Train: 2018-08-01T01:39:04.992593: step 28381, loss 0.646002.
Train: 2018-08-01T01:39:05.148808: step 28382, loss 0.629165.
Train: 2018-08-01T01:39:05.304991: step 28383, loss 0.612376.
Train: 2018-08-01T01:39:05.492471: step 28384, loss 0.545954.
Train: 2018-08-01T01:39:05.648692: step 28385, loss 0.512947.
Train: 2018-08-01T01:39:05.804903: step 28386, loss 0.579067.
Train: 2018-08-01T01:39:05.961117: step 28387, loss 0.710947.
Train: 2018-08-01T01:39:06.117330: step 28388, loss 0.562597.
Train: 2018-08-01T01:39:06.273514: step 28389, loss 0.628187.
Train: 2018-08-01T01:39:06.429766: step 28390, loss 0.578994.
Test: 2018-08-01T01:39:06.898398: step 28390, loss 0.549044.
Train: 2018-08-01T01:39:07.054611: step 28391, loss 0.578977.
Train: 2018-08-01T01:39:07.226446: step 28392, loss 0.578963.
Train: 2018-08-01T01:39:07.382663: step 28393, loss 0.562747.
Train: 2018-08-01T01:39:07.538873: step 28394, loss 0.546602.
Train: 2018-08-01T01:39:07.710708: step 28395, loss 0.562792.
Train: 2018-08-01T01:39:07.882512: step 28396, loss 0.611188.
Train: 2018-08-01T01:39:08.038760: step 28397, loss 0.530625.
Train: 2018-08-01T01:39:08.194940: step 28398, loss 0.562838.
Train: 2018-08-01T01:39:08.351152: step 28399, loss 0.498521.
Train: 2018-08-01T01:39:08.507400: step 28400, loss 0.546746.
Test: 2018-08-01T01:39:08.976035: step 28400, loss 0.549336.
Train: 2018-08-01T01:39:09.678997: step 28401, loss 0.578931.
Train: 2018-08-01T01:39:09.850801: step 28402, loss 0.546692.
Train: 2018-08-01T01:39:10.007014: step 28403, loss 0.562798.
Train: 2018-08-01T01:39:10.163253: step 28404, loss 0.546623.
Train: 2018-08-01T01:39:10.335064: step 28405, loss 0.611313.
Train: 2018-08-01T01:39:10.491306: step 28406, loss 0.514162.
Train: 2018-08-01T01:39:10.647520: step 28407, loss 0.676294.
Train: 2018-08-01T01:39:10.803733: step 28408, loss 0.660074.
Train: 2018-08-01T01:39:10.991159: step 28409, loss 0.530337.
Train: 2018-08-01T01:39:11.131752: step 28410, loss 0.65994.
Test: 2018-08-01T01:39:11.616012: step 28410, loss 0.549228.
Train: 2018-08-01T01:39:11.772227: step 28411, loss 0.546598.
Train: 2018-08-01T01:39:11.944061: step 28412, loss 0.611254.
Train: 2018-08-01T01:39:12.100275: step 28413, loss 0.546668.
Train: 2018-08-01T01:39:12.256512: step 28414, loss 0.627293.
Train: 2018-08-01T01:39:12.412731: step 28415, loss 0.595025.
Train: 2018-08-01T01:39:12.568939: step 28416, loss 0.627135.
Train: 2018-08-01T01:39:12.725159: step 28417, loss 0.594955.
Train: 2018-08-01T01:39:12.881342: step 28418, loss 0.498916.
Train: 2018-08-01T01:39:13.037586: step 28419, loss 0.658844.
Train: 2018-08-01T01:39:13.193793: step 28420, loss 0.562958.
Test: 2018-08-01T01:39:13.662438: step 28420, loss 0.549641.
Train: 2018-08-01T01:39:13.818623: step 28421, loss 0.54705.
Train: 2018-08-01T01:39:13.990487: step 28422, loss 0.626657.
Train: 2018-08-01T01:39:14.146711: step 28423, loss 0.515347.
Train: 2018-08-01T01:39:14.302884: step 28424, loss 0.547143.
Train: 2018-08-01T01:39:14.459096: step 28425, loss 0.515375.
Train: 2018-08-01T01:39:14.615335: step 28426, loss 0.467619.
Train: 2018-08-01T01:39:14.771524: step 28427, loss 0.610787.
Train: 2018-08-01T01:39:14.927738: step 28428, loss 0.531018.
Train: 2018-08-01T01:39:15.083951: step 28429, loss 0.594916.
Train: 2018-08-01T01:39:15.255786: step 28430, loss 0.562891.
Test: 2018-08-01T01:39:15.724455: step 28430, loss 0.54942.
Train: 2018-08-01T01:39:15.880673: step 28431, loss 0.450469.
Train: 2018-08-01T01:39:16.036883: step 28432, loss 0.482268.
Train: 2018-08-01T01:39:16.193096: step 28433, loss 0.562766.
Train: 2018-08-01T01:39:16.364900: step 28434, loss 0.497735.
Train: 2018-08-01T01:39:16.505493: step 28435, loss 0.481059.
Train: 2018-08-01T01:39:16.661706: step 28436, loss 0.579021.
Train: 2018-08-01T01:39:16.817950: step 28437, loss 0.447149.
Train: 2018-08-01T01:39:16.974163: step 28438, loss 0.579107.
Train: 2018-08-01T01:39:17.130347: step 28439, loss 0.562486.
Train: 2018-08-01T01:39:17.286559: step 28440, loss 0.61271.
Test: 2018-08-01T01:39:17.770851: step 28440, loss 0.548364.
Train: 2018-08-01T01:39:17.927049: step 28441, loss 0.42795.
Train: 2018-08-01T01:39:18.083248: step 28442, loss 0.545525.
Train: 2018-08-01T01:39:18.239491: step 28443, loss 0.477524.
Train: 2018-08-01T01:39:18.395705: step 28444, loss 0.494128.
Train: 2018-08-01T01:39:18.567546: step 28445, loss 0.562395.
Train: 2018-08-01T01:39:18.723724: step 28446, loss 0.510645.
Train: 2018-08-01T01:39:18.879970: step 28447, loss 0.545068.
Train: 2018-08-01T01:39:19.036181: step 28448, loss 0.475307.
Train: 2018-08-01T01:39:19.192365: step 28449, loss 0.57996.
Train: 2018-08-01T01:39:19.348577: step 28450, loss 0.527281.
Test: 2018-08-01T01:39:19.832839: step 28450, loss 0.5477.
Train: 2018-08-01T01:39:19.989082: step 28451, loss 0.580166.
Train: 2018-08-01T01:39:20.145295: step 28452, loss 0.509321.
Train: 2018-08-01T01:39:20.301509: step 28453, loss 0.491351.
Train: 2018-08-01T01:39:20.457693: step 28454, loss 0.634085.
Train: 2018-08-01T01:39:20.613936: step 28455, loss 0.634309.
Train: 2018-08-01T01:39:20.785766: step 28456, loss 0.598535.
Train: 2018-08-01T01:39:20.941954: step 28457, loss 0.508748.
Train: 2018-08-01T01:39:21.098167: step 28458, loss 0.598634.
Train: 2018-08-01T01:39:21.254420: step 28459, loss 0.544667.
Train: 2018-08-01T01:39:21.410624: step 28460, loss 0.70675.
Test: 2018-08-01T01:39:21.879268: step 28460, loss 0.547596.
Train: 2018-08-01T01:39:22.019826: step 28461, loss 0.454729.
Train: 2018-08-01T01:39:22.191661: step 28462, loss 0.634613.
Train: 2018-08-01T01:39:22.347875: step 28463, loss 0.544677.
Train: 2018-08-01T01:39:22.504088: step 28464, loss 0.490807.
Train: 2018-08-01T01:39:22.660301: step 28465, loss 0.401014.
Train: 2018-08-01T01:39:22.832161: step 28466, loss 0.490704.
Train: 2018-08-01T01:39:23.003971: step 28467, loss 0.616769.
Train: 2018-08-01T01:39:23.160184: step 28468, loss 0.508548.
Train: 2018-08-01T01:39:23.316428: step 28469, loss 0.580798.
Train: 2018-08-01T01:39:23.472642: step 28470, loss 0.544634.
Test: 2018-08-01T01:39:23.956903: step 28470, loss 0.547575.
Train: 2018-08-01T01:39:24.128742: step 28471, loss 0.526513.
Train: 2018-08-01T01:39:24.284920: step 28472, loss 0.508348.
Train: 2018-08-01T01:39:24.456755: step 28473, loss 0.580947.
Train: 2018-08-01T01:39:24.612999: step 28474, loss 0.617347.
Train: 2018-08-01T01:39:24.769182: step 28475, loss 0.508239.
Train: 2018-08-01T01:39:24.925427: step 28476, loss 0.635594.
Train: 2018-08-01T01:39:25.097273: step 28477, loss 0.5628.
Train: 2018-08-01T01:39:25.269096: step 28478, loss 0.580972.
Train: 2018-08-01T01:39:25.425279: step 28479, loss 0.562781.
Train: 2018-08-01T01:39:25.581523: step 28480, loss 0.490179.
Test: 2018-08-01T01:39:26.050131: step 28480, loss 0.547572.
Train: 2018-08-01T01:39:26.206346: step 28481, loss 0.544622.
Train: 2018-08-01T01:39:26.362559: step 28482, loss 0.59905.
Train: 2018-08-01T01:39:26.518772: step 28483, loss 0.490233.
Train: 2018-08-01T01:39:26.674986: step 28484, loss 0.580889.
Train: 2018-08-01T01:39:26.831230: step 28485, loss 0.580881.
Train: 2018-08-01T01:39:27.003069: step 28486, loss 0.598978.
Train: 2018-08-01T01:39:27.159278: step 28487, loss 0.562732.
Train: 2018-08-01T01:39:27.315462: step 28488, loss 0.59887.
Train: 2018-08-01T01:39:27.471675: step 28489, loss 0.490504.
Train: 2018-08-01T01:39:27.627889: step 28490, loss 0.562689.
Test: 2018-08-01T01:39:28.096528: step 28490, loss 0.547589.
Train: 2018-08-01T01:39:28.252743: step 28491, loss 0.616743.
Train: 2018-08-01T01:39:28.440224: step 28492, loss 0.670633.
Train: 2018-08-01T01:39:28.580791: step 28493, loss 0.652371.
Train: 2018-08-01T01:39:28.737003: step 28494, loss 0.526828.
Train: 2018-08-01T01:39:28.908838: step 28495, loss 0.491237.
Train: 2018-08-01T01:39:29.065082: step 28496, loss 0.669351.
Train: 2018-08-01T01:39:29.221265: step 28497, loss 0.59802.
Train: 2018-08-01T01:39:29.377512: step 28498, loss 0.544815.
Train: 2018-08-01T01:39:29.533723: step 28499, loss 0.562484.
Train: 2018-08-01T01:39:29.689905: step 28500, loss 0.527281.
Test: 2018-08-01T01:39:30.174196: step 28500, loss 0.547754.
Train: 2018-08-01T01:39:30.877128: step 28501, loss 0.580016.
Train: 2018-08-01T01:39:31.033341: step 28502, loss 0.597491.
Train: 2018-08-01T01:39:31.189554: step 28503, loss 0.544955.
Train: 2018-08-01T01:39:31.345799: step 28504, loss 0.544981.
Train: 2018-08-01T01:39:31.502005: step 28505, loss 0.562422.
Train: 2018-08-01T01:39:31.673816: step 28506, loss 0.545024.
Train: 2018-08-01T01:39:31.830029: step 28507, loss 0.440805.
Train: 2018-08-01T01:39:32.001898: step 28508, loss 0.45814.
Train: 2018-08-01T01:39:32.158077: step 28509, loss 0.527607.
Train: 2018-08-01T01:39:32.314291: step 28510, loss 0.544989.
Test: 2018-08-01T01:39:32.782931: step 28510, loss 0.547805.
Train: 2018-08-01T01:39:32.939174: step 28511, loss 0.544965.
Train: 2018-08-01T01:39:33.095359: step 28512, loss 0.63243.
Train: 2018-08-01T01:39:33.267218: step 28513, loss 0.527424.
Train: 2018-08-01T01:39:33.439027: step 28514, loss 0.579974.
Train: 2018-08-01T01:39:33.595271: step 28515, loss 0.492304.
Train: 2018-08-01T01:39:33.751488: step 28516, loss 0.580017.
Train: 2018-08-01T01:39:33.923290: step 28517, loss 0.527311.
Train: 2018-08-01T01:39:34.079502: step 28518, loss 0.509681.
Train: 2018-08-01T01:39:34.235716: step 28519, loss 0.527231.
Train: 2018-08-01T01:39:34.407550: step 28520, loss 0.421248.
Test: 2018-08-01T01:39:34.876191: step 28520, loss 0.547682.
Train: 2018-08-01T01:39:35.048025: step 28521, loss 0.562513.
Train: 2018-08-01T01:39:35.188619: step 28522, loss 0.527015.
Train: 2018-08-01T01:39:35.360453: step 28523, loss 0.491322.
Train: 2018-08-01T01:39:35.501045: step 28524, loss 0.687649.
Train: 2018-08-01T01:39:35.672910: step 28525, loss 0.49104.
Train: 2018-08-01T01:39:35.829092: step 28526, loss 0.598468.
Train: 2018-08-01T01:39:35.985305: step 28527, loss 0.490851.
Train: 2018-08-01T01:39:36.157141: step 28528, loss 0.68849.
Train: 2018-08-01T01:39:36.313385: step 28529, loss 0.526697.
Train: 2018-08-01T01:39:36.469567: step 28530, loss 0.562656.
Test: 2018-08-01T01:39:36.938207: step 28530, loss 0.547596.
Train: 2018-08-01T01:39:37.094422: step 28531, loss 0.580644.
Train: 2018-08-01T01:39:37.250669: step 28532, loss 0.472741.
Train: 2018-08-01T01:39:37.406878: step 28533, loss 0.490681.
Train: 2018-08-01T01:39:37.563092: step 28534, loss 0.508621.
Train: 2018-08-01T01:39:37.719275: step 28535, loss 0.544649.
Train: 2018-08-01T01:39:37.875488: step 28536, loss 0.490409.
Train: 2018-08-01T01:39:38.031732: step 28537, loss 0.472172.
Train: 2018-08-01T01:39:38.187946: step 28538, loss 0.635434.
Train: 2018-08-01T01:39:38.391017: step 28539, loss 0.562801.
Train: 2018-08-01T01:39:38.547239: step 28540, loss 0.562818.
Test: 2018-08-01T01:39:39.015876: step 28540, loss 0.547568.
Train: 2018-08-01T01:39:39.172090: step 28541, loss 0.617514.
Train: 2018-08-01T01:39:39.343928: step 28542, loss 0.617517.
Train: 2018-08-01T01:39:39.515729: step 28543, loss 0.617468.
Train: 2018-08-01T01:39:39.671943: step 28544, loss 0.617371.
Train: 2018-08-01T01:39:39.828186: step 28545, loss 0.472006.
Train: 2018-08-01T01:39:39.984400: step 28546, loss 0.472081.
Train: 2018-08-01T01:39:40.140614: step 28547, loss 0.580895.
Train: 2018-08-01T01:39:40.296796: step 28548, loss 0.544626.
Train: 2018-08-01T01:39:40.484279: step 28549, loss 0.598999.
Train: 2018-08-01T01:39:40.640466: step 28550, loss 0.653287.
Test: 2018-08-01T01:39:41.109137: step 28550, loss 0.54758.
Train: 2018-08-01T01:39:41.265320: step 28551, loss 0.526565.
Train: 2018-08-01T01:39:41.421563: step 28552, loss 0.544649.
Train: 2018-08-01T01:39:41.593367: step 28553, loss 0.490572.
Train: 2018-08-01T01:39:41.749581: step 28554, loss 0.5807.
Train: 2018-08-01T01:39:41.905795: step 28555, loss 0.544663.
Train: 2018-08-01T01:39:42.062008: step 28556, loss 0.598659.
Train: 2018-08-01T01:39:42.218253: step 28557, loss 0.72446.
Train: 2018-08-01T01:39:42.374469: step 28558, loss 0.598475.
Train: 2018-08-01T01:39:42.530678: step 28559, loss 0.651946.
Train: 2018-08-01T01:39:42.686898: step 28560, loss 0.68716.
Test: 2018-08-01T01:39:43.171154: step 28560, loss 0.547682.
Train: 2018-08-01T01:39:43.327366: step 28561, loss 0.473959.
Train: 2018-08-01T01:39:43.483551: step 28562, loss 0.597779.
Train: 2018-08-01T01:39:43.639794: step 28563, loss 0.421828.
Train: 2018-08-01T01:39:43.811598: step 28564, loss 0.580001.
Train: 2018-08-01T01:39:43.967812: step 28565, loss 0.597471.
Train: 2018-08-01T01:39:44.124026: step 28566, loss 0.47506.
Train: 2018-08-01T01:39:44.280239: step 28567, loss 0.56243.
Train: 2018-08-01T01:39:44.436452: step 28568, loss 0.562426.
Train: 2018-08-01T01:39:44.608287: step 28569, loss 0.562423.
Train: 2018-08-01T01:39:44.764499: step 28570, loss 0.5276.
Test: 2018-08-01T01:39:45.248762: step 28570, loss 0.547846.
Train: 2018-08-01T01:39:45.389384: step 28571, loss 0.527613.
Train: 2018-08-01T01:39:45.545599: step 28572, loss 0.527612.
Train: 2018-08-01T01:39:45.701781: step 28573, loss 0.56242.
Train: 2018-08-01T01:39:45.857994: step 28574, loss 0.545006.
Train: 2018-08-01T01:39:46.045451: step 28575, loss 0.614692.
Train: 2018-08-01T01:39:46.201665: step 28576, loss 0.527584.
Train: 2018-08-01T01:39:46.357878: step 28577, loss 0.614685.
Train: 2018-08-01T01:39:46.514090: step 28578, loss 0.597244.
Train: 2018-08-01T01:39:46.670305: step 28579, loss 0.475441.
Train: 2018-08-01T01:39:46.826517: step 28580, loss 0.54502.
Test: 2018-08-01T01:39:47.295158: step 28580, loss 0.547845.
Train: 2018-08-01T01:39:47.451401: step 28581, loss 0.545015.
Train: 2018-08-01T01:39:47.607618: step 28582, loss 0.632064.
Train: 2018-08-01T01:39:47.779449: step 28583, loss 0.492808.
Train: 2018-08-01T01:39:47.935633: step 28584, loss 0.545011.
Train: 2018-08-01T01:39:48.091846: step 28585, loss 0.614675.
Train: 2018-08-01T01:39:48.263705: step 28586, loss 0.510179.
Train: 2018-08-01T01:39:48.419925: step 28587, loss 0.52758.
Train: 2018-08-01T01:39:48.591759: step 28588, loss 0.544991.
Train: 2018-08-01T01:39:48.747942: step 28589, loss 0.562428.
Train: 2018-08-01T01:39:48.904184: step 28590, loss 0.56243.
Test: 2018-08-01T01:39:49.388447: step 28590, loss 0.547804.
Train: 2018-08-01T01:39:49.544631: step 28591, loss 0.544963.
Train: 2018-08-01T01:39:49.700845: step 28592, loss 0.527473.
Train: 2018-08-01T01:39:49.841467: step 28593, loss 0.632432.
Train: 2018-08-01T01:39:49.997684: step 28594, loss 0.56244.
Train: 2018-08-01T01:39:50.169514: step 28595, loss 0.581103.
Train: 2018-08-01T01:39:50.325724: step 28596, loss 0.527457.
Train: 2018-08-01T01:39:50.497557: step 28597, loss 0.509963.
Train: 2018-08-01T01:39:50.653776: step 28598, loss 0.597446.
Train: 2018-08-01T01:39:50.809960: step 28599, loss 0.544937.
Train: 2018-08-01T01:39:50.966174: step 28600, loss 0.474901.
Test: 2018-08-01T01:39:51.434841: step 28600, loss 0.54777.
Train: 2018-08-01T01:39:52.153394: step 28601, loss 0.544919.
Train: 2018-08-01T01:39:52.309608: step 28602, loss 0.580005.
Train: 2018-08-01T01:39:52.465852: step 28603, loss 0.562459.
Train: 2018-08-01T01:39:52.622059: step 28604, loss 0.474577.
Train: 2018-08-01T01:39:52.778249: step 28605, loss 0.615287.
Train: 2018-08-01T01:39:52.934493: step 28606, loss 0.685801.
Train: 2018-08-01T01:39:53.090706: step 28607, loss 0.562471.
Train: 2018-08-01T01:39:53.246928: step 28608, loss 0.580054.
Train: 2018-08-01T01:39:53.418754: step 28609, loss 0.457043.
Train: 2018-08-01T01:39:53.574969: step 28610, loss 0.650331.
Test: 2018-08-01T01:39:54.043578: step 28610, loss 0.547754.
Train: 2018-08-01T01:39:54.199822: step 28611, loss 0.562457.
Train: 2018-08-01T01:39:54.371659: step 28612, loss 0.544909.
Train: 2018-08-01T01:39:54.527869: step 28613, loss 0.49232.
Train: 2018-08-01T01:39:54.684083: step 28614, loss 0.544914.
Train: 2018-08-01T01:39:54.871543: step 28615, loss 0.667702.
Train: 2018-08-01T01:39:55.012131: step 28616, loss 0.527399.
Train: 2018-08-01T01:39:55.183966: step 28617, loss 0.404815.
Train: 2018-08-01T01:39:55.340179: step 28618, loss 0.579988.
Train: 2018-08-01T01:39:55.496362: step 28619, loss 0.509795.
Train: 2018-08-01T01:39:55.652605: step 28620, loss 0.615196.
Test: 2018-08-01T01:39:56.136867: step 28620, loss 0.547739.
Train: 2018-08-01T01:39:56.293052: step 28621, loss 0.527292.
Train: 2018-08-01T01:39:56.449264: step 28622, loss 0.527267.
Train: 2018-08-01T01:39:56.605502: step 28623, loss 0.491992.
Train: 2018-08-01T01:39:56.761691: step 28624, loss 0.544837.
Train: 2018-08-01T01:39:56.917946: step 28625, loss 0.597865.
Train: 2018-08-01T01:39:57.074148: step 28626, loss 0.580208.
Train: 2018-08-01T01:39:57.230360: step 28627, loss 0.597936.
Train: 2018-08-01T01:39:57.386569: step 28628, loss 0.527088.
Train: 2018-08-01T01:39:57.542759: step 28629, loss 0.473918.
Train: 2018-08-01T01:39:57.698971: step 28630, loss 0.598011.
Test: 2018-08-01T01:39:58.167641: step 28630, loss 0.547665.
Train: 2018-08-01T01:39:58.339477: step 28631, loss 0.456007.
Train: 2018-08-01T01:39:58.495660: step 28632, loss 0.580331.
Train: 2018-08-01T01:39:58.651904: step 28633, loss 0.615977.
Train: 2018-08-01T01:39:58.808087: step 28634, loss 0.526932.
Train: 2018-08-01T01:39:58.964300: step 28635, loss 0.509088.
Train: 2018-08-01T01:39:59.120514: step 28636, loss 0.616115.
Train: 2018-08-01T01:39:59.276751: step 28637, loss 0.616133.
Train: 2018-08-01T01:39:59.432941: step 28638, loss 0.651789.
Train: 2018-08-01T01:39:59.589153: step 28639, loss 0.562561.
Train: 2018-08-01T01:39:59.745367: step 28640, loss 0.52697.
Test: 2018-08-01T01:40:00.214033: step 28640, loss 0.547658.
Train: 2018-08-01T01:40:00.370255: step 28641, loss 0.526998.
Train: 2018-08-01T01:40:00.526435: step 28642, loss 0.633572.
Train: 2018-08-01T01:40:00.698268: step 28643, loss 0.491589.
Train: 2018-08-01T01:40:00.854483: step 28644, loss 0.597963.
Train: 2018-08-01T01:40:01.010696: step 28645, loss 0.615623.
Train: 2018-08-01T01:40:01.166939: step 28646, loss 0.650876.
Train: 2018-08-01T01:40:01.338774: step 28647, loss 0.509591.
Train: 2018-08-01T01:40:01.494957: step 28648, loss 0.509675.
Train: 2018-08-01T01:40:01.635549: step 28649, loss 0.544884.
Train: 2018-08-01T01:40:01.807384: step 28650, loss 0.562459.
Test: 2018-08-01T01:40:02.276054: step 28650, loss 0.547758.
Train: 2018-08-01T01:40:02.432238: step 28651, loss 0.49225.
Train: 2018-08-01T01:40:02.588452: step 28652, loss 0.597559.
Train: 2018-08-01T01:40:02.744689: step 28653, loss 0.457186.
Train: 2018-08-01T01:40:02.900908: step 28654, loss 0.492224.
Train: 2018-08-01T01:40:03.057121: step 28655, loss 0.527297.
Train: 2018-08-01T01:40:03.213335: step 28656, loss 0.562475.
Train: 2018-08-01T01:40:03.369519: step 28657, loss 0.668318.
Train: 2018-08-01T01:40:03.541378: step 28658, loss 0.562484.
Train: 2018-08-01T01:40:03.697568: step 28659, loss 0.562483.
Train: 2018-08-01T01:40:03.853781: step 28660, loss 0.59775.
Test: 2018-08-01T01:40:04.322419: step 28660, loss 0.547722.
Train: 2018-08-01T01:40:04.494289: step 28661, loss 0.580101.
Train: 2018-08-01T01:40:04.666125: step 28662, loss 0.58008.
Train: 2018-08-01T01:40:04.822327: step 28663, loss 0.527289.
Train: 2018-08-01T01:40:04.978517: step 28664, loss 0.527306.
Train: 2018-08-01T01:40:05.134754: step 28665, loss 0.650338.
Train: 2018-08-01T01:40:05.290944: step 28666, loss 0.580008.
Train: 2018-08-01T01:40:05.447187: step 28667, loss 0.579976.
Train: 2018-08-01T01:40:05.603400: step 28668, loss 0.492438.
Train: 2018-08-01T01:40:05.790862: step 28669, loss 0.527458.
Train: 2018-08-01T01:40:05.947064: step 28670, loss 0.527464.
Test: 2018-08-01T01:40:06.415710: step 28670, loss 0.547792.
Train: 2018-08-01T01:40:06.571923: step 28671, loss 0.702358.
Train: 2018-08-01T01:40:06.743753: step 28672, loss 0.632283.
Train: 2018-08-01T01:40:06.931184: step 28673, loss 0.510153.
Train: 2018-08-01T01:40:07.071777: step 28674, loss 0.61461.
Train: 2018-08-01T01:40:07.227990: step 28675, loss 0.49296.
Train: 2018-08-01T01:40:07.384203: step 28676, loss 0.527717.
Train: 2018-08-01T01:40:07.540416: step 28677, loss 0.458385.
Train: 2018-08-01T01:40:07.696660: step 28678, loss 0.597111.
Train: 2018-08-01T01:40:07.852844: step 28679, loss 0.63183.
Train: 2018-08-01T01:40:08.024678: step 28680, loss 0.458346.
Test: 2018-08-01T01:40:08.493352: step 28680, loss 0.547878.
Train: 2018-08-01T01:40:08.649562: step 28681, loss 0.579765.
Train: 2018-08-01T01:40:08.805746: step 28682, loss 0.492968.
Train: 2018-08-01T01:40:08.961961: step 28683, loss 0.492894.
Train: 2018-08-01T01:40:09.133794: step 28684, loss 0.56242.
Train: 2018-08-01T01:40:09.290037: step 28685, loss 0.632182.
Train: 2018-08-01T01:40:09.446250: step 28686, loss 0.54498.
Train: 2018-08-01T01:40:09.602467: step 28687, loss 0.492592.
Train: 2018-08-01T01:40:09.774268: step 28688, loss 0.57992.
Train: 2018-08-01T01:40:09.914892: step 28689, loss 0.54494.
Train: 2018-08-01T01:40:10.086727: step 28690, loss 0.527409.
Test: 2018-08-01T01:40:10.555366: step 28690, loss 0.547763.
Train: 2018-08-01T01:40:10.727170: step 28691, loss 0.50983.
Train: 2018-08-01T01:40:10.883414: step 28692, loss 0.439466.
Train: 2018-08-01T01:40:11.039598: step 28693, loss 0.615344.
Train: 2018-08-01T01:40:11.211432: step 28694, loss 0.597803.
Train: 2018-08-01T01:40:11.367680: step 28695, loss 0.527143.
Train: 2018-08-01T01:40:11.508268: step 28696, loss 0.544806.
Train: 2018-08-01T01:40:11.664481: step 28697, loss 0.42069.
Train: 2018-08-01T01:40:11.820695: step 28698, loss 0.704774.
Train: 2018-08-01T01:40:11.976910: step 28699, loss 0.56255.
Train: 2018-08-01T01:40:12.133090: step 28700, loss 0.598164.
Test: 2018-08-01T01:40:12.601732: step 28700, loss 0.547646.
Train: 2018-08-01T01:40:13.335965: step 28701, loss 0.562556.
Train: 2018-08-01T01:40:13.523421: step 28702, loss 0.509143.
Train: 2018-08-01T01:40:13.679629: step 28703, loss 0.562559.
Train: 2018-08-01T01:40:13.835817: step 28704, loss 0.562562.
Train: 2018-08-01T01:40:13.992064: step 28705, loss 0.5091.
Train: 2018-08-01T01:40:14.148274: step 28706, loss 0.56257.
Train: 2018-08-01T01:40:14.304482: step 28707, loss 0.687469.
Train: 2018-08-01T01:40:14.460704: step 28708, loss 0.526919.
Train: 2018-08-01T01:40:14.632505: step 28709, loss 0.580369.
Train: 2018-08-01T01:40:14.788744: step 28710, loss 0.509167.
Test: 2018-08-01T01:40:15.257389: step 28710, loss 0.547652.
Train: 2018-08-01T01:40:15.413603: step 28711, loss 0.598126.
Train: 2018-08-01T01:40:15.569788: step 28712, loss 0.562541.
Train: 2018-08-01T01:40:15.741621: step 28713, loss 0.580296.
Train: 2018-08-01T01:40:15.897835: step 28714, loss 0.65124.
Train: 2018-08-01T01:40:16.054072: step 28715, loss 0.491684.
Train: 2018-08-01T01:40:16.210292: step 28716, loss 0.527129.
Train: 2018-08-01T01:40:16.366509: step 28717, loss 0.456446.
Train: 2018-08-01T01:40:16.522712: step 28718, loss 0.580187.
Train: 2018-08-01T01:40:16.678903: step 28719, loss 0.562504.
Train: 2018-08-01T01:40:16.850766: step 28720, loss 0.562504.
Test: 2018-08-01T01:40:17.335028: step 28720, loss 0.54769.
Train: 2018-08-01T01:40:17.491246: step 28721, loss 0.49174.
Train: 2018-08-01T01:40:17.647456: step 28722, loss 0.509397.
Train: 2018-08-01T01:40:17.819293: step 28723, loss 0.562519.
Train: 2018-08-01T01:40:17.975506: step 28724, loss 0.52704.
Train: 2018-08-01T01:40:18.131716: step 28725, loss 0.580302.
Train: 2018-08-01T01:40:18.287936: step 28726, loss 0.509206.
Train: 2018-08-01T01:40:18.444113: step 28727, loss 0.562554.
Train: 2018-08-01T01:40:18.615982: step 28728, loss 0.580381.
Train: 2018-08-01T01:40:18.772163: step 28729, loss 0.49125.
Train: 2018-08-01T01:40:18.944012: step 28730, loss 0.616135.
Test: 2018-08-01T01:40:19.412681: step 28730, loss 0.547629.
Train: 2018-08-01T01:40:19.553230: step 28731, loss 0.562583.
Train: 2018-08-01T01:40:19.725063: step 28732, loss 0.508995.
Train: 2018-08-01T01:40:19.881277: step 28733, loss 0.491087.
Train: 2018-08-01T01:40:20.053113: step 28734, loss 0.544706.
Train: 2018-08-01T01:40:20.209356: step 28735, loss 0.544696.
Train: 2018-08-01T01:40:20.365573: step 28736, loss 0.544686.
Train: 2018-08-01T01:40:20.568617: step 28737, loss 0.652493.
Train: 2018-08-01T01:40:20.724829: step 28738, loss 0.52671.
Train: 2018-08-01T01:40:20.896694: step 28739, loss 0.490758.
Train: 2018-08-01T01:40:21.052877: step 28740, loss 0.454725.
Test: 2018-08-01T01:40:21.521548: step 28740, loss 0.547589.
Train: 2018-08-01T01:40:21.677730: step 28741, loss 0.562681.
Train: 2018-08-01T01:40:21.849596: step 28742, loss 0.580752.
Train: 2018-08-01T01:40:22.005804: step 28743, loss 0.490429.
Train: 2018-08-01T01:40:22.161993: step 28744, loss 0.68944.
Train: 2018-08-01T01:40:22.333861: step 28745, loss 0.653229.
Train: 2018-08-01T01:40:22.490065: step 28746, loss 0.562718.
Train: 2018-08-01T01:40:22.646254: step 28747, loss 0.47243.
Train: 2018-08-01T01:40:22.802468: step 28748, loss 0.526599.
Train: 2018-08-01T01:40:22.958681: step 28749, loss 0.689054.
Train: 2018-08-01T01:40:23.114928: step 28750, loss 0.634774.
Test: 2018-08-01T01:40:23.599187: step 28750, loss 0.547597.
Train: 2018-08-01T01:40:23.755401: step 28751, loss 0.544673.
Train: 2018-08-01T01:40:23.911583: step 28752, loss 0.61647.
Train: 2018-08-01T01:40:24.067797: step 28753, loss 0.580506.
Train: 2018-08-01T01:40:24.224010: step 28754, loss 0.598287.
Train: 2018-08-01T01:40:24.380224: step 28755, loss 0.544752.
Train: 2018-08-01T01:40:24.552094: step 28756, loss 0.651323.
Train: 2018-08-01T01:40:24.708304: step 28757, loss 0.597904.
Train: 2018-08-01T01:40:24.864509: step 28758, loss 0.580119.
Train: 2018-08-01T01:40:25.020699: step 28759, loss 0.615185.
Train: 2018-08-01T01:40:25.176942: step 28760, loss 0.562442.
Test: 2018-08-01T01:40:25.645552: step 28760, loss 0.547819.
Train: 2018-08-01T01:40:25.801795: step 28761, loss 0.475201.
Train: 2018-08-01T01:40:25.958004: step 28762, loss 0.632049.
Train: 2018-08-01T01:40:26.129814: step 28763, loss 0.597127.
Train: 2018-08-01T01:40:26.286057: step 28764, loss 0.545098.
Train: 2018-08-01T01:40:26.442265: step 28765, loss 0.510615.
Train: 2018-08-01T01:40:26.629696: step 28766, loss 0.562398.
Train: 2018-08-01T01:40:26.785909: step 28767, loss 0.579603.
Train: 2018-08-01T01:40:26.942124: step 28768, loss 0.579575.
Train: 2018-08-01T01:40:27.098369: step 28769, loss 0.630998.
Train: 2018-08-01T01:40:27.254580: step 28770, loss 0.528175.
Test: 2018-08-01T01:40:27.723232: step 28770, loss 0.548094.
Train: 2018-08-01T01:40:27.879434: step 28771, loss 0.630725.
Train: 2018-08-01T01:40:28.035647: step 28772, loss 0.528317.
Train: 2018-08-01T01:40:28.191831: step 28773, loss 0.54539.
Train: 2018-08-01T01:40:28.348074: step 28774, loss 0.545415.
Train: 2018-08-01T01:40:28.504287: step 28775, loss 0.59636.
Train: 2018-08-01T01:40:28.660501: step 28776, loss 0.613277.
Train: 2018-08-01T01:40:28.816723: step 28777, loss 0.477785.
Train: 2018-08-01T01:40:28.972922: step 28778, loss 0.647012.
Train: 2018-08-01T01:40:29.129141: step 28779, loss 0.494842.
Train: 2018-08-01T01:40:29.285357: step 28780, loss 0.545534.
Test: 2018-08-01T01:40:29.753965: step 28780, loss 0.548282.
Train: 2018-08-01T01:40:29.925826: step 28781, loss 0.511761.
Train: 2018-08-01T01:40:30.082043: step 28782, loss 0.562421.
Train: 2018-08-01T01:40:30.238226: step 28783, loss 0.528602.
Train: 2018-08-01T01:40:30.394464: step 28784, loss 0.596267.
Train: 2018-08-01T01:40:30.566274: step 28785, loss 0.511611.
Train: 2018-08-01T01:40:30.722518: step 28786, loss 0.579365.
Train: 2018-08-01T01:40:30.878732: step 28787, loss 0.54544.
Train: 2018-08-01T01:40:31.081813: step 28788, loss 0.579393.
Train: 2018-08-01T01:40:31.237993: step 28789, loss 0.545407.
Train: 2018-08-01T01:40:31.394236: step 28790, loss 0.647472.
Test: 2018-08-01T01:40:31.862880: step 28790, loss 0.54816.
Train: 2018-08-01T01:40:32.019089: step 28791, loss 0.562404.
Train: 2018-08-01T01:40:32.190894: step 28792, loss 0.511385.
Train: 2018-08-01T01:40:32.347132: step 28793, loss 0.511359.
Train: 2018-08-01T01:40:32.503356: step 28794, loss 0.409098.
Train: 2018-08-01T01:40:32.659534: step 28795, loss 0.562397.
Train: 2018-08-01T01:40:32.831369: step 28796, loss 0.630914.
Train: 2018-08-01T01:40:32.971962: step 28797, loss 0.442304.
Train: 2018-08-01T01:40:33.143796: step 28798, loss 0.665628.
Train: 2018-08-01T01:40:33.315631: step 28799, loss 0.562397.
Train: 2018-08-01T01:40:33.471844: step 28800, loss 0.596893.
Test: 2018-08-01T01:40:33.940514: step 28800, loss 0.547948.
Train: 2018-08-01T01:40:34.674687: step 28801, loss 0.63143.
Train: 2018-08-01T01:40:34.830931: step 28802, loss 0.510642.
Train: 2018-08-01T01:40:34.987148: step 28803, loss 0.407079.
Train: 2018-08-01T01:40:35.158949: step 28804, loss 0.596994.
Train: 2018-08-01T01:40:35.315188: step 28805, loss 0.683657.
Train: 2018-08-01T01:40:35.502618: step 28806, loss 0.683639.
Train: 2018-08-01T01:40:35.658856: step 28807, loss 0.458656.
Train: 2018-08-01T01:40:35.815045: step 28808, loss 0.596976.
Train: 2018-08-01T01:40:35.971289: step 28809, loss 0.579677.
Train: 2018-08-01T01:40:36.127503: step 28810, loss 0.579662.
Test: 2018-08-01T01:40:36.611768: step 28810, loss 0.547957.
Train: 2018-08-01T01:40:36.767947: step 28811, loss 0.562398.
Train: 2018-08-01T01:40:36.908540: step 28812, loss 0.596859.
Train: 2018-08-01T01:40:37.064784: step 28813, loss 0.631235.
Train: 2018-08-01T01:40:37.220996: step 28814, loss 0.579571.
Train: 2018-08-01T01:40:37.392826: step 28815, loss 0.442402.
Train: 2018-08-01T01:40:37.549044: step 28816, loss 0.510982.
Train: 2018-08-01T01:40:37.705227: step 28817, loss 0.4767.
Train: 2018-08-01T01:40:37.861466: step 28818, loss 0.528019.
Train: 2018-08-01T01:40:38.017654: step 28819, loss 0.528006.
Train: 2018-08-01T01:40:38.173893: step 28820, loss 0.545021.
Test: 2018-08-01T01:40:38.642510: step 28820, loss 0.547853.
Train: 2018-08-01T01:40:38.814344: step 28821, loss 0.666843.
Train: 2018-08-01T01:40:38.970590: step 28822, loss 0.579318.
Train: 2018-08-01T01:40:39.126771: step 28823, loss 0.509994.
Train: 2018-08-01T01:40:39.283014: step 28824, loss 0.631232.
Train: 2018-08-01T01:40:39.454818: step 28825, loss 0.509594.
Train: 2018-08-01T01:40:39.611065: step 28826, loss 0.580351.
Train: 2018-08-01T01:40:39.767247: step 28827, loss 0.581958.
Train: 2018-08-01T01:40:39.923458: step 28828, loss 0.492583.
Train: 2018-08-01T01:40:40.079702: step 28829, loss 0.546966.
Train: 2018-08-01T01:40:40.235910: step 28830, loss 0.632059.
Test: 2018-08-01T01:40:40.704555: step 28830, loss 0.547794.
Train: 2018-08-01T01:40:40.860739: step 28831, loss 0.528451.
Train: 2018-08-01T01:40:41.032604: step 28832, loss 0.579863.
Train: 2018-08-01T01:40:41.188787: step 28833, loss 0.683818.
Train: 2018-08-01T01:40:41.345026: step 28834, loss 0.614226.
Train: 2018-08-01T01:40:41.516865: step 28835, loss 0.562364.
Train: 2018-08-01T01:40:41.673073: step 28836, loss 0.562399.
Train: 2018-08-01T01:40:41.829292: step 28837, loss 0.545239.
Train: 2018-08-01T01:40:41.985476: step 28838, loss 0.613816.
Train: 2018-08-01T01:40:42.141713: step 28839, loss 0.699248.
Train: 2018-08-01T01:40:42.297932: step 28840, loss 0.511263.
Test: 2018-08-01T01:40:42.782194: step 28840, loss 0.548169.
Train: 2018-08-01T01:40:42.938377: step 28841, loss 0.545403.
Train: 2018-08-01T01:40:43.110212: step 28842, loss 0.477547.
Train: 2018-08-01T01:40:43.250829: step 28843, loss 0.579378.
Train: 2018-08-01T01:40:43.407047: step 28844, loss 0.579367.
Train: 2018-08-01T01:40:43.563231: step 28845, loss 0.630158.
Train: 2018-08-01T01:40:43.719477: step 28846, loss 0.528609.
Train: 2018-08-01T01:40:43.875658: step 28847, loss 0.59621.
Train: 2018-08-01T01:40:44.031902: step 28848, loss 0.596171.
Train: 2018-08-01T01:40:44.203736: step 28849, loss 0.545594.
Train: 2018-08-01T01:40:44.359919: step 28850, loss 0.596093.
Test: 2018-08-01T01:40:44.828590: step 28850, loss 0.548378.
Train: 2018-08-01T01:40:44.984807: step 28851, loss 0.528844.
Train: 2018-08-01T01:40:45.141017: step 28852, loss 0.512083.
Train: 2018-08-01T01:40:45.312851: step 28853, loss 0.596032.
Train: 2018-08-01T01:40:45.469065: step 28854, loss 0.562453.
Train: 2018-08-01T01:40:45.625248: step 28855, loss 0.612795.
Train: 2018-08-01T01:40:45.781461: step 28856, loss 0.49539.
Train: 2018-08-01T01:40:45.937676: step 28857, loss 0.562456.
Train: 2018-08-01T01:40:46.093921: step 28858, loss 0.612779.
Train: 2018-08-01T01:40:46.250126: step 28859, loss 0.629533.
Train: 2018-08-01T01:40:46.421937: step 28860, loss 0.495452.
Test: 2018-08-01T01:40:46.890607: step 28860, loss 0.54843.
Train: 2018-08-01T01:40:47.046821: step 28861, loss 0.528913.
Train: 2018-08-01T01:40:47.203033: step 28862, loss 0.495109.
Train: 2018-08-01T01:40:47.359251: step 28863, loss 0.545245.
Train: 2018-08-01T01:40:47.531053: step 28864, loss 0.579609.
Train: 2018-08-01T01:40:47.687266: step 28865, loss 0.66635.
Train: 2018-08-01T01:40:47.843509: step 28866, loss 0.493301.
Train: 2018-08-01T01:40:47.999693: step 28867, loss 0.495138.
Train: 2018-08-01T01:40:48.155935: step 28868, loss 0.595356.
Train: 2018-08-01T01:40:48.312149: step 28869, loss 0.545601.
Train: 2018-08-01T01:40:48.468362: step 28870, loss 0.58006.
Test: 2018-08-01T01:40:48.937002: step 28870, loss 0.547921.
Train: 2018-08-01T01:40:49.093185: step 28871, loss 0.577542.
Train: 2018-08-01T01:40:49.249400: step 28872, loss 0.720458.
Train: 2018-08-01T01:40:49.405612: step 28873, loss 0.546394.
Train: 2018-08-01T01:40:49.561827: step 28874, loss 0.579052.
Train: 2018-08-01T01:40:49.733685: step 28875, loss 0.579839.
Train: 2018-08-01T01:40:49.889899: step 28876, loss 0.562689.
Train: 2018-08-01T01:40:50.061739: step 28877, loss 0.595555.
Train: 2018-08-01T01:40:50.217953: step 28878, loss 0.515442.
Train: 2018-08-01T01:40:50.374135: step 28879, loss 0.531145.
Train: 2018-08-01T01:40:50.530380: step 28880, loss 0.562432.
Test: 2018-08-01T01:40:50.999020: step 28880, loss 0.548466.
Train: 2018-08-01T01:40:51.170854: step 28881, loss 0.595923.
Train: 2018-08-01T01:40:51.327070: step 28882, loss 0.595895.
Train: 2018-08-01T01:40:51.483285: step 28883, loss 0.562754.
Train: 2018-08-01T01:40:51.639464: step 28884, loss 0.613339.
Train: 2018-08-01T01:40:51.811330: step 28885, loss 0.528669.
Train: 2018-08-01T01:40:51.967512: step 28886, loss 0.628558.
Train: 2018-08-01T01:40:52.123757: step 28887, loss 0.611835.
Train: 2018-08-01T01:40:52.279970: step 28888, loss 0.546628.
Train: 2018-08-01T01:40:52.436189: step 28889, loss 0.614168.
Train: 2018-08-01T01:40:52.608022: step 28890, loss 0.517394.
Test: 2018-08-01T01:40:53.076652: step 28890, loss 0.548528.
Train: 2018-08-01T01:40:53.232876: step 28891, loss 0.563403.
Train: 2018-08-01T01:40:53.389055: step 28892, loss 0.679816.
Train: 2018-08-01T01:40:53.545269: step 28893, loss 0.678422.
Train: 2018-08-01T01:40:53.701516: step 28894, loss 0.5627.
Train: 2018-08-01T01:40:53.857719: step 28895, loss 0.513473.
Train: 2018-08-01T01:40:54.013910: step 28896, loss 0.580367.
Train: 2018-08-01T01:40:54.170154: step 28897, loss 0.480958.
Train: 2018-08-01T01:40:54.341958: step 28898, loss 0.562918.
Train: 2018-08-01T01:40:54.482548: step 28899, loss 0.5465.
Train: 2018-08-01T01:40:54.654383: step 28900, loss 0.629065.
Test: 2018-08-01T01:40:55.123025: step 28900, loss 0.549075.
Train: 2018-08-01T01:40:55.826015: step 28901, loss 0.611783.
Train: 2018-08-01T01:40:55.982232: step 28902, loss 0.546424.
Train: 2018-08-01T01:40:56.138439: step 28903, loss 0.579243.
Train: 2018-08-01T01:40:56.310271: step 28904, loss 0.595553.
Train: 2018-08-01T01:40:56.482080: step 28905, loss 0.546653.
Train: 2018-08-01T01:40:56.638324: step 28906, loss 0.513966.
Train: 2018-08-01T01:40:56.794507: step 28907, loss 0.465255.
Train: 2018-08-01T01:40:56.950752: step 28908, loss 0.562651.
Train: 2018-08-01T01:40:57.106969: step 28909, loss 0.579117.
Train: 2018-08-01T01:40:57.278800: step 28910, loss 0.562616.
Test: 2018-08-01T01:40:57.747439: step 28910, loss 0.549016.
Train: 2018-08-01T01:40:57.919244: step 28911, loss 0.51368.
Train: 2018-08-01T01:40:58.075481: step 28912, loss 0.578817.
Train: 2018-08-01T01:40:58.231696: step 28913, loss 0.546143.
Train: 2018-08-01T01:40:58.434782: step 28914, loss 0.614929.
Train: 2018-08-01T01:40:58.590961: step 28915, loss 0.615699.
Train: 2018-08-01T01:40:58.747200: step 28916, loss 0.621674.
Train: 2018-08-01T01:40:58.887767: step 28917, loss 0.664855.
Train: 2018-08-01T01:40:59.059602: step 28918, loss 0.47928.
Train: 2018-08-01T01:40:59.200227: step 28919, loss 0.613364.
Train: 2018-08-01T01:40:59.372029: step 28920, loss 0.595807.
Test: 2018-08-01T01:40:59.840699: step 28920, loss 0.549187.
Train: 2018-08-01T01:40:59.996913: step 28921, loss 0.612348.
Train: 2018-08-01T01:41:00.153127: step 28922, loss 0.49729.
Train: 2018-08-01T01:41:00.309309: step 28923, loss 0.513758.
Train: 2018-08-01T01:41:00.465523: step 28924, loss 0.44806.
Train: 2018-08-01T01:41:00.637382: step 28925, loss 0.59591.
Train: 2018-08-01T01:41:00.793570: step 28926, loss 0.579505.
Train: 2018-08-01T01:41:00.949784: step 28927, loss 0.579515.
Train: 2018-08-01T01:41:01.105999: step 28928, loss 0.579525.
Train: 2018-08-01T01:41:01.262241: step 28929, loss 0.562994.
Train: 2018-08-01T01:41:01.418426: step 28930, loss 0.529893.
Test: 2018-08-01T01:41:01.902695: step 28930, loss 0.549093.
Train: 2018-08-01T01:41:02.058899: step 28931, loss 0.56297.
Train: 2018-08-01T01:41:02.230769: step 28932, loss 0.479989.
Train: 2018-08-01T01:41:02.371327: step 28933, loss 0.562932.
Train: 2018-08-01T01:41:02.543192: step 28934, loss 0.579578.
Train: 2018-08-01T01:41:02.699376: step 28935, loss 0.646385.
Train: 2018-08-01T01:41:02.871209: step 28936, loss 0.62973.
Train: 2018-08-01T01:41:03.011832: step 28937, loss 0.562859.
Train: 2018-08-01T01:41:03.183637: step 28938, loss 0.495969.
Train: 2018-08-01T01:41:03.339874: step 28939, loss 0.730774.
Train: 2018-08-01T01:41:03.496099: step 28940, loss 0.496122.
Test: 2018-08-01T01:41:03.964734: step 28940, loss 0.548847.
Train: 2018-08-01T01:41:04.183432: step 28941, loss 0.546139.
Train: 2018-08-01T01:41:04.339649: step 28942, loss 0.529447.
Train: 2018-08-01T01:41:04.480242: step 28943, loss 0.429245.
Train: 2018-08-01T01:41:04.636451: step 28944, loss 0.596301.
Train: 2018-08-01T01:41:04.808273: step 28945, loss 0.562794.
Train: 2018-08-01T01:41:04.964503: step 28946, loss 0.646746.
Train: 2018-08-01T01:41:05.120719: step 28947, loss 0.562744.
Train: 2018-08-01T01:41:05.261305: step 28948, loss 0.59661.
Train: 2018-08-01T01:41:05.433109: step 28949, loss 0.579568.
Train: 2018-08-01T01:41:05.589322: step 28950, loss 0.613218.
Test: 2018-08-01T01:41:06.057962: step 28950, loss 0.548741.
Train: 2018-08-01T01:41:06.214211: step 28951, loss 0.512559.
Train: 2018-08-01T01:41:06.370390: step 28952, loss 0.512458.
Train: 2018-08-01T01:41:06.526604: step 28953, loss 0.61322.
Train: 2018-08-01T01:41:06.698438: step 28954, loss 0.545997.
Train: 2018-08-01T01:41:06.854651: step 28955, loss 0.529174.
Train: 2018-08-01T01:41:07.010902: step 28956, loss 0.562789.
Train: 2018-08-01T01:41:07.182730: step 28957, loss 0.613299.
Train: 2018-08-01T01:41:07.338914: step 28958, loss 0.529204.
Train: 2018-08-01T01:41:07.495127: step 28959, loss 0.52908.
Train: 2018-08-01T01:41:07.651365: step 28960, loss 0.630235.
Test: 2018-08-01T01:41:08.120010: step 28960, loss 0.548623.
Train: 2018-08-01T01:41:08.307436: step 28961, loss 0.461525.
Train: 2018-08-01T01:41:08.448053: step 28962, loss 0.528947.
Train: 2018-08-01T01:41:08.604242: step 28963, loss 0.630423.
Train: 2018-08-01T01:41:08.776107: step 28964, loss 0.57965.
Train: 2018-08-01T01:41:08.916670: step 28965, loss 0.596595.
Train: 2018-08-01T01:41:09.088503: step 28966, loss 0.596588.
Train: 2018-08-01T01:41:09.244747: step 28967, loss 0.461038.
Train: 2018-08-01T01:41:09.432174: step 28968, loss 0.596591.
Train: 2018-08-01T01:41:09.588417: step 28969, loss 0.528729.
Train: 2018-08-01T01:41:09.744600: step 28970, loss 0.613602.
Test: 2018-08-01T01:41:10.228895: step 28970, loss 0.54842.
Train: 2018-08-01T01:41:10.400729: step 28971, loss 0.562644.
Train: 2018-08-01T01:41:10.572532: step 28972, loss 0.443702.
Train: 2018-08-01T01:41:10.728745: step 28973, loss 0.494544.
Train: 2018-08-01T01:41:10.900580: step 28974, loss 0.579675.
Train: 2018-08-01T01:41:11.041196: step 28975, loss 0.562604.
Train: 2018-08-01T01:41:11.197415: step 28976, loss 0.511218.
Train: 2018-08-01T01:41:11.353632: step 28977, loss 0.49393.
Train: 2018-08-01T01:41:11.525433: step 28978, loss 0.579801.
Train: 2018-08-01T01:41:11.681677: step 28979, loss 0.597067.
Train: 2018-08-01T01:41:11.837860: step 28980, loss 0.459196.
Test: 2018-08-01T01:41:12.306530: step 28980, loss 0.548079.
Train: 2018-08-01T01:41:12.462738: step 28981, loss 0.579971.
Train: 2018-08-01T01:41:12.634549: step 28982, loss 0.527855.
Train: 2018-08-01T01:41:12.775172: step 28983, loss 0.510353.
Train: 2018-08-01T01:41:12.931354: step 28984, loss 0.510218.
Train: 2018-08-01T01:41:13.087598: step 28985, loss 0.5451.
Train: 2018-08-01T01:41:13.243782: step 28986, loss 0.527496.
Train: 2018-08-01T01:41:13.399994: step 28987, loss 0.633112.
Train: 2018-08-01T01:41:13.556238: step 28988, loss 0.492057.
Train: 2018-08-01T01:41:13.712472: step 28989, loss 0.509597.
Train: 2018-08-01T01:41:13.868671: step 28990, loss 0.509469.
Test: 2018-08-01T01:41:14.337305: step 28990, loss 0.547807.
Train: 2018-08-01T01:41:14.493519: step 28991, loss 0.562653.
Train: 2018-08-01T01:41:14.665353: step 28992, loss 0.545096.
Train: 2018-08-01T01:41:14.821538: step 28993, loss 0.598723.
Train: 2018-08-01T01:41:14.993403: step 28994, loss 0.616461.
Train: 2018-08-01T01:41:15.149583: step 28995, loss 0.5269.
Train: 2018-08-01T01:41:15.305797: step 28996, loss 0.598655.
Train: 2018-08-01T01:41:15.462041: step 28997, loss 0.508913.
Train: 2018-08-01T01:41:15.618255: step 28998, loss 0.580646.
Train: 2018-08-01T01:41:15.774468: step 28999, loss 0.544707.
Train: 2018-08-01T01:41:15.946298: step 29000, loss 0.56261.
Test: 2018-08-01T01:41:16.430534: step 29000, loss 0.547757.
Train: 2018-08-01T01:41:17.133496: step 29001, loss 0.634532.
Train: 2018-08-01T01:41:17.289708: step 29002, loss 0.633845.
Train: 2018-08-01T01:41:17.445922: step 29003, loss 0.633221.
Train: 2018-08-01T01:41:17.617787: step 29004, loss 0.544611.
Train: 2018-08-01T01:41:17.774000: step 29005, loss 0.519006.
Train: 2018-08-01T01:41:17.914595: step 29006, loss 0.575746.
Train: 2018-08-01T01:41:18.086397: step 29007, loss 0.655851.
Train: 2018-08-01T01:41:18.242641: step 29008, loss 0.564518.
Train: 2018-08-01T01:41:18.398823: step 29009, loss 0.701177.
Train: 2018-08-01T01:41:18.555037: step 29010, loss 0.511811.
Test: 2018-08-01T01:41:19.023707: step 29010, loss 0.548182.
Train: 2018-08-01T01:41:19.195512: step 29011, loss 0.52831.
Train: 2018-08-01T01:41:19.336104: step 29012, loss 0.493423.
Train: 2018-08-01T01:41:19.492317: step 29013, loss 0.54743.
Train: 2018-08-01T01:41:19.664183: step 29014, loss 0.527944.
Train: 2018-08-01T01:41:19.820365: step 29015, loss 0.58097.
Train: 2018-08-01T01:41:19.976613: step 29016, loss 0.527833.
Train: 2018-08-01T01:41:20.132822: step 29017, loss 0.633205.
Train: 2018-08-01T01:41:20.289037: step 29018, loss 0.580375.
Train: 2018-08-01T01:41:20.445249: step 29019, loss 0.633186.
Train: 2018-08-01T01:41:20.617084: step 29020, loss 0.492408.
Test: 2018-08-01T01:41:21.085724: step 29020, loss 0.548035.
Train: 2018-08-01T01:41:21.257528: step 29021, loss 0.580508.
Train: 2018-08-01T01:41:21.413744: step 29022, loss 0.439806.
Train: 2018-08-01T01:41:21.569955: step 29023, loss 0.527721.
Train: 2018-08-01T01:41:21.726194: step 29024, loss 0.562707.
Train: 2018-08-01T01:41:21.882413: step 29025, loss 0.492275.
Train: 2018-08-01T01:41:22.038627: step 29026, loss 0.439388.
Train: 2018-08-01T01:41:22.194839: step 29027, loss 0.633493.
Train: 2018-08-01T01:41:22.351057: step 29028, loss 0.562797.
Train: 2018-08-01T01:41:22.522882: step 29029, loss 0.669258.
Train: 2018-08-01T01:41:22.679072: step 29030, loss 0.598149.
Test: 2018-08-01T01:41:23.147741: step 29030, loss 0.547991.
Train: 2018-08-01T01:41:23.303955: step 29031, loss 0.509727.
Train: 2018-08-01T01:41:23.460138: step 29032, loss 0.686542.
Train: 2018-08-01T01:41:23.616352: step 29033, loss 0.598233.
Train: 2018-08-01T01:41:23.772596: step 29034, loss 0.492393.
Train: 2018-08-01T01:41:23.928809: step 29035, loss 0.562757.
Train: 2018-08-01T01:41:24.100613: step 29036, loss 0.580328.
Train: 2018-08-01T01:41:24.256826: step 29037, loss 0.562739.
Train: 2018-08-01T01:41:24.413070: step 29038, loss 0.510114.
Train: 2018-08-01T01:41:24.569254: step 29039, loss 0.615319.
Train: 2018-08-01T01:41:24.741118: step 29040, loss 0.510179.
Test: 2018-08-01T01:41:25.209758: step 29040, loss 0.548052.
Train: 2018-08-01T01:41:25.381564: step 29041, loss 0.650237.
Train: 2018-08-01T01:41:25.537807: step 29042, loss 0.510262.
Train: 2018-08-01T01:41:25.693991: step 29043, loss 0.545227.
Train: 2018-08-01T01:41:25.881446: step 29044, loss 0.562688.
Train: 2018-08-01T01:41:26.037690: step 29045, loss 0.684822.
Train: 2018-08-01T01:41:26.193903: step 29046, loss 0.527842.
Train: 2018-08-01T01:41:26.350120: step 29047, loss 0.545272.
Train: 2018-08-01T01:41:26.506324: step 29048, loss 0.562655.
Train: 2018-08-01T01:41:26.662543: step 29049, loss 0.545295.
Train: 2018-08-01T01:41:26.834349: step 29050, loss 0.649343.
Test: 2018-08-01T01:41:27.303021: step 29050, loss 0.548139.
Train: 2018-08-01T01:41:27.459234: step 29051, loss 0.579944.
Train: 2018-08-01T01:41:27.615440: step 29052, loss 0.597184.
Train: 2018-08-01T01:41:27.771628: step 29053, loss 0.579863.
Train: 2018-08-01T01:41:27.943464: step 29054, loss 0.493792.
Train: 2018-08-01T01:41:28.099711: step 29055, loss 0.528236.
Train: 2018-08-01T01:41:28.255921: step 29056, loss 0.596966.
Train: 2018-08-01T01:41:28.412103: step 29057, loss 0.545442.
Train: 2018-08-01T01:41:28.568316: step 29058, loss 0.528296.
Train: 2018-08-01T01:41:28.724565: step 29059, loss 0.545447.
Train: 2018-08-01T01:41:28.896389: step 29060, loss 0.631206.
Test: 2018-08-01T01:41:29.365035: step 29060, loss 0.54824.
Train: 2018-08-01T01:41:29.521249: step 29061, loss 0.66543.
Train: 2018-08-01T01:41:29.677432: step 29062, loss 0.631014.
Train: 2018-08-01T01:41:29.849291: step 29063, loss 0.647895.
Train: 2018-08-01T01:41:30.005481: step 29064, loss 0.562592.
Train: 2018-08-01T01:41:30.177346: step 29065, loss 0.545647.
Train: 2018-08-01T01:41:30.333559: step 29066, loss 0.461157.
Train: 2018-08-01T01:41:30.489741: step 29067, loss 0.410576.
Train: 2018-08-01T01:41:30.645986: step 29068, loss 0.528773.
Train: 2018-08-01T01:41:30.802199: step 29069, loss 0.528714.
Train: 2018-08-01T01:41:30.958412: step 29070, loss 0.562581.
Test: 2018-08-01T01:41:31.427053: step 29070, loss 0.548342.
Train: 2018-08-01T01:41:31.583235: step 29071, loss 0.528581.
Train: 2018-08-01T01:41:31.739449: step 29072, loss 0.596629.
Train: 2018-08-01T01:41:31.911315: step 29073, loss 0.681939.
Train: 2018-08-01T01:41:32.067499: step 29074, loss 0.59666.
Train: 2018-08-01T01:41:32.223745: step 29075, loss 0.511448.
Train: 2018-08-01T01:41:32.411192: step 29076, loss 0.494402.
Train: 2018-08-01T01:41:32.567406: step 29077, loss 0.511389.
Train: 2018-08-01T01:41:32.739246: step 29078, loss 0.579633.
Train: 2018-08-01T01:41:32.895450: step 29079, loss 0.562549.
Train: 2018-08-01T01:41:33.051641: step 29080, loss 0.47695.
Test: 2018-08-01T01:41:33.520315: step 29080, loss 0.548179.
Train: 2018-08-01T01:41:33.692118: step 29081, loss 0.579697.
Train: 2018-08-01T01:41:33.848330: step 29082, loss 0.528179.
Train: 2018-08-01T01:41:34.004543: step 29083, loss 0.510901.
Train: 2018-08-01T01:41:34.160757: step 29084, loss 0.510782.
Train: 2018-08-01T01:41:34.316971: step 29085, loss 0.510645.
Train: 2018-08-01T01:41:34.473218: step 29086, loss 0.579901.
Train: 2018-08-01T01:41:34.645049: step 29087, loss 0.527764.
Train: 2018-08-01T01:41:34.801263: step 29088, loss 0.527681.
Train: 2018-08-01T01:41:34.973101: step 29089, loss 0.527595.
Train: 2018-08-01T01:41:35.129281: step 29090, loss 0.545046.
Test: 2018-08-01T01:41:35.597923: step 29090, loss 0.547872.
Train: 2018-08-01T01:41:35.769785: step 29091, loss 0.527428.
Train: 2018-08-01T01:41:35.925968: step 29092, loss 0.597876.
Train: 2018-08-01T01:41:36.082212: step 29093, loss 0.633292.
Train: 2018-08-01T01:41:36.238395: step 29094, loss 0.597992.
Train: 2018-08-01T01:41:36.394639: step 29095, loss 0.651064.
Train: 2018-08-01T01:41:36.550852: step 29096, loss 0.527276.
Train: 2018-08-01T01:41:36.707038: step 29097, loss 0.509632.
Train: 2018-08-01T01:41:36.878872: step 29098, loss 0.63328.
Train: 2018-08-01T01:41:37.035109: step 29099, loss 0.47435.
Train: 2018-08-01T01:41:37.191328: step 29100, loss 0.544955.
Test: 2018-08-01T01:41:37.675589: step 29100, loss 0.547823.
Train: 2018-08-01T01:41:38.378544: step 29101, loss 0.580276.
Train: 2018-08-01T01:41:38.534763: step 29102, loss 0.54495.
Train: 2018-08-01T01:41:38.706600: step 29103, loss 0.562613.
Train: 2018-08-01T01:41:38.862812: step 29104, loss 0.562613.
Train: 2018-08-01T01:41:39.050237: step 29105, loss 0.633277.
Train: 2018-08-01T01:41:39.206484: step 29106, loss 0.580254.
Train: 2018-08-01T01:41:39.347077: step 29107, loss 0.597855.
Train: 2018-08-01T01:41:39.503286: step 29108, loss 0.492174.
Train: 2018-08-01T01:41:39.675121: step 29109, loss 0.615357.
Train: 2018-08-01T01:41:39.831338: step 29110, loss 0.509861.
Test: 2018-08-01T01:41:40.299974: step 29110, loss 0.547863.
Train: 2018-08-01T01:41:40.456183: step 29111, loss 0.422084.
Train: 2018-08-01T01:41:40.628023: step 29112, loss 0.685633.
Train: 2018-08-01T01:41:40.784206: step 29113, loss 0.544998.
Train: 2018-08-01T01:41:40.940419: step 29114, loss 0.474741.
Train: 2018-08-01T01:41:41.096662: step 29115, loss 0.650453.
Train: 2018-08-01T01:41:41.268467: step 29116, loss 0.5977.
Train: 2018-08-01T01:41:41.424680: step 29117, loss 0.545006.
Train: 2018-08-01T01:41:41.580928: step 29118, loss 0.667789.
Train: 2018-08-01T01:41:41.737138: step 29119, loss 0.632563.
Train: 2018-08-01T01:41:41.893351: step 29120, loss 0.56253.
Test: 2018-08-01T01:41:42.377584: step 29120, loss 0.547936.
Train: 2018-08-01T01:41:42.518205: step 29121, loss 0.527688.
Train: 2018-08-01T01:41:42.690040: step 29122, loss 0.562513.
Train: 2018-08-01T01:41:42.846257: step 29123, loss 0.614573.
Train: 2018-08-01T01:41:43.002468: step 29124, loss 0.770309.
Train: 2018-08-01T01:41:43.174273: step 29125, loss 0.562492.
Train: 2018-08-01T01:41:43.346132: step 29126, loss 0.54532.
Train: 2018-08-01T01:41:43.502319: step 29127, loss 0.494054.
Train: 2018-08-01T01:41:43.658534: step 29128, loss 0.596628.
Train: 2018-08-01T01:41:43.814777: step 29129, loss 0.528438.
Train: 2018-08-01T01:41:43.970960: step 29130, loss 0.749452.
Test: 2018-08-01T01:41:44.439633: step 29130, loss 0.548331.
Train: 2018-08-01T01:41:44.595848: step 29131, loss 0.613237.
Train: 2018-08-01T01:41:44.752028: step 29132, loss 0.528951.
Train: 2018-08-01T01:41:44.923861: step 29133, loss 0.545511.
Train: 2018-08-01T01:41:45.064455: step 29134, loss 0.579179.
Train: 2018-08-01T01:41:45.220702: step 29135, loss 0.645836.
Train: 2018-08-01T01:41:45.376912: step 29136, loss 0.563335.
Train: 2018-08-01T01:41:45.548716: step 29137, loss 0.546416.
Train: 2018-08-01T01:41:45.704961: step 29138, loss 0.711241.
Train: 2018-08-01T01:41:45.861168: step 29139, loss 0.594987.
Train: 2018-08-01T01:41:46.017357: step 29140, loss 0.57829.
Test: 2018-08-01T01:41:46.486026: step 29140, loss 0.549405.
Train: 2018-08-01T01:41:46.657866: step 29141, loss 0.593995.
Train: 2018-08-01T01:41:46.814076: step 29142, loss 0.480686.
Train: 2018-08-01T01:41:46.970292: step 29143, loss 0.500476.
Train: 2018-08-01T01:41:47.126495: step 29144, loss 0.486913.
Train: 2018-08-01T01:41:47.282709: step 29145, loss 0.612148.
Train: 2018-08-01T01:41:47.438929: step 29146, loss 0.562682.
Train: 2018-08-01T01:41:47.595145: step 29147, loss 0.515689.
Train: 2018-08-01T01:41:47.766977: step 29148, loss 0.547091.
Train: 2018-08-01T01:41:47.923184: step 29149, loss 0.514768.
Train: 2018-08-01T01:41:48.079374: step 29150, loss 0.62839.
Test: 2018-08-01T01:41:48.548013: step 29150, loss 0.548921.
Train: 2018-08-01T01:41:48.704227: step 29151, loss 0.51329.
Train: 2018-08-01T01:41:48.876085: step 29152, loss 0.562646.
Train: 2018-08-01T01:41:49.032310: step 29153, loss 0.513141.
Train: 2018-08-01T01:41:49.188514: step 29154, loss 0.579174.
Train: 2018-08-01T01:41:49.344727: step 29155, loss 0.59578.
Train: 2018-08-01T01:41:49.500945: step 29156, loss 0.595822.
Train: 2018-08-01T01:41:49.657164: step 29157, loss 0.612491.
Train: 2018-08-01T01:41:49.813374: step 29158, loss 0.529269.
Train: 2018-08-01T01:41:50.000828: step 29159, loss 0.529232.
Train: 2018-08-01T01:41:50.157044: step 29160, loss 0.56255.
Test: 2018-08-01T01:41:50.625682: step 29160, loss 0.548552.
Train: 2018-08-01T01:41:50.781895: step 29161, loss 0.51242.
Train: 2018-08-01T01:41:50.938078: step 29162, loss 0.529054.
Train: 2018-08-01T01:41:51.109914: step 29163, loss 0.461865.
Train: 2018-08-01T01:41:51.266127: step 29164, loss 0.545672.
Train: 2018-08-01T01:41:51.422370: step 29165, loss 0.528717.
Train: 2018-08-01T01:41:51.594209: step 29166, loss 0.647203.
Train: 2018-08-01T01:41:51.750389: step 29167, loss 0.51154.
Train: 2018-08-01T01:41:51.906633: step 29168, loss 0.528427.
Train: 2018-08-01T01:41:52.078436: step 29169, loss 0.630732.
Train: 2018-08-01T01:41:52.234650: step 29170, loss 0.528276.
Test: 2018-08-01T01:41:52.718946: step 29170, loss 0.548121.
Train: 2018-08-01T01:41:52.875125: step 29171, loss 0.528211.
Train: 2018-08-01T01:41:53.031368: step 29172, loss 0.510977.
Train: 2018-08-01T01:41:53.187553: step 29173, loss 0.510848.
Train: 2018-08-01T01:41:53.343765: step 29174, loss 0.527956.
Train: 2018-08-01T01:41:53.500009: step 29175, loss 0.475939.
Train: 2018-08-01T01:41:53.656230: step 29176, loss 0.545107.
Train: 2018-08-01T01:41:53.812436: step 29177, loss 0.614783.
Train: 2018-08-01T01:41:53.968653: step 29178, loss 0.492598.
Train: 2018-08-01T01:41:54.124862: step 29179, loss 0.492401.
Train: 2018-08-01T01:41:54.296704: step 29180, loss 0.615295.
Test: 2018-08-01T01:41:54.765337: step 29180, loss 0.547779.
Train: 2018-08-01T01:41:54.921521: step 29181, loss 0.633068.
Train: 2018-08-01T01:41:55.077767: step 29182, loss 0.580205.
Train: 2018-08-01T01:41:55.233978: step 29183, loss 0.562557.
Train: 2018-08-01T01:41:55.390163: step 29184, loss 0.562561.
Train: 2018-08-01T01:41:55.546410: step 29185, loss 0.527184.
Train: 2018-08-01T01:41:55.702613: step 29186, loss 0.544865.
Train: 2018-08-01T01:41:55.858801: step 29187, loss 0.598017.
Train: 2018-08-01T01:41:56.015014: step 29188, loss 0.438502.
Train: 2018-08-01T01:41:56.171259: step 29189, loss 0.50933.
Train: 2018-08-01T01:41:56.327474: step 29190, loss 0.52703.
Test: 2018-08-01T01:41:56.796081: step 29190, loss 0.547697.
Train: 2018-08-01T01:41:56.952320: step 29191, loss 0.544799.
Train: 2018-08-01T01:41:57.108508: step 29192, loss 0.580501.
Train: 2018-08-01T01:41:57.264722: step 29193, loss 0.616312.
Train: 2018-08-01T01:41:57.436581: step 29194, loss 0.723743.
Train: 2018-08-01T01:41:57.604285: step 29195, loss 0.634129.
Train: 2018-08-01T01:41:57.744911: step 29196, loss 0.616109.
Train: 2018-08-01T01:41:57.901120: step 29197, loss 0.657095.
Train: 2018-08-01T01:41:58.057333: step 29198, loss 0.474303.
Train: 2018-08-01T01:41:58.213546: step 29199, loss 0.562269.
Train: 2018-08-01T01:41:58.369731: step 29200, loss 0.509882.
Test: 2018-08-01T01:41:58.838400: step 29200, loss 0.547917.
Train: 2018-08-01T01:41:59.510118: step 29201, loss 0.614096.
Train: 2018-08-01T01:41:59.681953: step 29202, loss 0.460129.
Train: 2018-08-01T01:41:59.853790: step 29203, loss 0.528866.
Train: 2018-08-01T01:42:00.010004: step 29204, loss 0.526801.
Train: 2018-08-01T01:42:00.166215: step 29205, loss 0.580032.
Train: 2018-08-01T01:42:00.322397: step 29206, loss 0.580286.
Train: 2018-08-01T01:42:00.478644: step 29207, loss 0.667374.
Train: 2018-08-01T01:42:00.650446: step 29208, loss 0.423189.
Train: 2018-08-01T01:42:00.806686: step 29209, loss 0.580061.
Train: 2018-08-01T01:42:00.978494: step 29210, loss 0.580018.
Test: 2018-08-01T01:42:01.462786: step 29210, loss 0.547864.
Train: 2018-08-01T01:42:01.618999: step 29211, loss 0.492614.
Train: 2018-08-01T01:42:01.775212: step 29212, loss 0.475021.
Train: 2018-08-01T01:42:01.931428: step 29213, loss 0.544908.
Train: 2018-08-01T01:42:02.103230: step 29214, loss 0.58012.
Train: 2018-08-01T01:42:02.259474: step 29215, loss 0.615437.
Train: 2018-08-01T01:42:02.415657: step 29216, loss 0.633184.
Train: 2018-08-01T01:42:02.571901: step 29217, loss 0.492005.
Train: 2018-08-01T01:42:02.728114: step 29218, loss 0.492011.
Train: 2018-08-01T01:42:02.884298: step 29219, loss 0.544942.
Train: 2018-08-01T01:42:03.040547: step 29220, loss 0.597802.
Test: 2018-08-01T01:42:03.509181: step 29220, loss 0.547758.
Train: 2018-08-01T01:42:03.665364: step 29221, loss 0.527215.
Train: 2018-08-01T01:42:03.821614: step 29222, loss 0.580172.
Train: 2018-08-01T01:42:03.977821: step 29223, loss 0.544951.
Train: 2018-08-01T01:42:04.149627: step 29224, loss 0.651211.
Train: 2018-08-01T01:42:04.321491: step 29225, loss 0.580244.
Train: 2018-08-01T01:42:04.477699: step 29226, loss 0.668534.
Train: 2018-08-01T01:42:04.633922: step 29227, loss 0.439183.
Train: 2018-08-01T01:42:04.805723: step 29228, loss 0.685777.
Train: 2018-08-01T01:42:04.961936: step 29229, loss 0.509814.
Train: 2018-08-01T01:42:05.118179: step 29230, loss 0.667785.
Test: 2018-08-01T01:42:05.602410: step 29230, loss 0.547842.
Train: 2018-08-01T01:42:05.758624: step 29231, loss 0.58.
Train: 2018-08-01T01:42:05.914837: step 29232, loss 0.527571.
Train: 2018-08-01T01:42:06.071081: step 29233, loss 0.475354.
Train: 2018-08-01T01:42:06.227295: step 29234, loss 0.545063.
Train: 2018-08-01T01:42:06.399124: step 29235, loss 0.579878.
Train: 2018-08-01T01:42:06.555340: step 29236, loss 0.562471.
Train: 2018-08-01T01:42:06.711556: step 29237, loss 0.562469.
Train: 2018-08-01T01:42:06.867739: step 29238, loss 0.562466.
Train: 2018-08-01T01:42:07.023983: step 29239, loss 0.597186.
Train: 2018-08-01T01:42:07.180167: step 29240, loss 0.614492.
Test: 2018-08-01T01:42:07.648837: step 29240, loss 0.547956.
Train: 2018-08-01T01:42:07.805020: step 29241, loss 0.631724.
Train: 2018-08-01T01:42:07.961233: step 29242, loss 0.527897.
Train: 2018-08-01T01:42:08.117477: step 29243, loss 0.579699.
Train: 2018-08-01T01:42:08.273662: step 29244, loss 0.562447.
Train: 2018-08-01T01:42:08.429904: step 29245, loss 0.528059.
Train: 2018-08-01T01:42:08.601734: step 29246, loss 0.562445.
Train: 2018-08-01T01:42:08.757923: step 29247, loss 0.63109.
Train: 2018-08-01T01:42:08.914136: step 29248, loss 0.528178.
Train: 2018-08-01T01:42:09.070382: step 29249, loss 0.442639.
Train: 2018-08-01T01:42:09.226592: step 29250, loss 0.476822.
Test: 2018-08-01T01:42:09.695233: step 29250, loss 0.548081.
Train: 2018-08-01T01:42:09.851448: step 29251, loss 0.562443.
Train: 2018-08-01T01:42:10.023250: step 29252, loss 0.476566.
Train: 2018-08-01T01:42:10.179495: step 29253, loss 0.700165.
Train: 2018-08-01T01:42:10.335707: step 29254, loss 0.545222.
Train: 2018-08-01T01:42:10.491921: step 29255, loss 0.700292.
Train: 2018-08-01T01:42:10.648104: step 29256, loss 0.596863.
Train: 2018-08-01T01:42:10.819939: step 29257, loss 0.562441.
Train: 2018-08-01T01:42:10.976153: step 29258, loss 0.613922.
Train: 2018-08-01T01:42:11.132391: step 29259, loss 0.511056.
Train: 2018-08-01T01:42:11.304227: step 29260, loss 0.54533.
Test: 2018-08-01T01:42:11.772871: step 29260, loss 0.548123.
Train: 2018-08-01T01:42:11.960309: step 29261, loss 0.408561.
Train: 2018-08-01T01:42:12.116540: step 29262, loss 0.54532.
Train: 2018-08-01T01:42:12.272749: step 29263, loss 0.511011.
Train: 2018-08-01T01:42:12.428968: step 29264, loss 0.493741.
Train: 2018-08-01T01:42:12.585181: step 29265, loss 0.49357.
Train: 2018-08-01T01:42:12.741399: step 29266, loss 0.545172.
Train: 2018-08-01T01:42:12.897579: step 29267, loss 0.562448.
Train: 2018-08-01T01:42:13.069437: step 29268, loss 0.40615.
Train: 2018-08-01T01:42:13.225656: step 29269, loss 0.527588.
Train: 2018-08-01T01:42:13.366248: step 29270, loss 0.615021.
Test: 2018-08-01T01:42:13.850509: step 29270, loss 0.547791.
Train: 2018-08-01T01:42:14.006693: step 29271, loss 0.580065.
Train: 2018-08-01T01:42:14.178528: step 29272, loss 0.474474.
Train: 2018-08-01T01:42:14.334771: step 29273, loss 0.580198.
Train: 2018-08-01T01:42:14.475363: step 29274, loss 0.686511.
Train: 2018-08-01T01:42:14.647199: step 29275, loss 0.562557.
Train: 2018-08-01T01:42:14.803406: step 29276, loss 0.61576.
Train: 2018-08-01T01:42:14.959595: step 29277, loss 0.65121.
Train: 2018-08-01T01:42:15.131466: step 29278, loss 0.544843.
Train: 2018-08-01T01:42:15.287642: step 29279, loss 0.544853.
Train: 2018-08-01T01:42:15.443857: step 29280, loss 0.527185.
Test: 2018-08-01T01:42:15.912497: step 29280, loss 0.547738.
Train: 2018-08-01T01:42:16.068711: step 29281, loss 0.544865.
Train: 2018-08-01T01:42:16.224926: step 29282, loss 0.633193.
Train: 2018-08-01T01:42:16.381137: step 29283, loss 0.597816.
Train: 2018-08-01T01:42:16.537350: step 29284, loss 0.562515.
Train: 2018-08-01T01:42:16.709215: step 29285, loss 0.527316.
Train: 2018-08-01T01:42:16.865398: step 29286, loss 0.58008.
Train: 2018-08-01T01:42:17.021613: step 29287, loss 0.580054.
Train: 2018-08-01T01:42:17.177855: step 29288, loss 0.54495.
Train: 2018-08-01T01:42:17.349695: step 29289, loss 0.615042.
Train: 2018-08-01T01:42:17.490282: step 29290, loss 0.422537.
Test: 2018-08-01T01:42:17.974543: step 29290, loss 0.547825.
Train: 2018-08-01T01:42:18.130757: step 29291, loss 0.597466.
Train: 2018-08-01T01:42:18.286971: step 29292, loss 0.492513.
Train: 2018-08-01T01:42:18.458776: step 29293, loss 0.49248.
Train: 2018-08-01T01:42:18.599401: step 29294, loss 0.685126.
Train: 2018-08-01T01:42:18.755605: step 29295, loss 0.562479.
Train: 2018-08-01T01:42:18.927415: step 29296, loss 0.632503.
Train: 2018-08-01T01:42:19.068008: step 29297, loss 0.579956.
Train: 2018-08-01T01:42:19.224221: step 29298, loss 0.719606.
Train: 2018-08-01T01:42:19.396056: step 29299, loss 0.545049.
Train: 2018-08-01T01:42:19.567921: step 29300, loss 0.649236.
Test: 2018-08-01T01:42:20.036561: step 29300, loss 0.547953.
Train: 2018-08-01T01:42:20.755112: step 29301, loss 0.527842.
Train: 2018-08-01T01:42:20.926947: step 29302, loss 0.458934.
Train: 2018-08-01T01:42:21.083192: step 29303, loss 0.562431.
Train: 2018-08-01T01:42:21.239399: step 29304, loss 0.493596.
Train: 2018-08-01T01:42:21.395612: step 29305, loss 0.631251.
Train: 2018-08-01T01:42:21.551802: step 29306, loss 0.545242.
Train: 2018-08-01T01:42:21.739258: step 29307, loss 0.510903.
Train: 2018-08-01T01:42:21.895500: step 29308, loss 0.596779.
Train: 2018-08-01T01:42:22.051714: step 29309, loss 0.631098.
Train: 2018-08-01T01:42:22.207897: step 29310, loss 0.493844.
Test: 2018-08-01T01:42:22.692192: step 29310, loss 0.548074.
Train: 2018-08-01T01:42:22.863994: step 29311, loss 0.511004.
Train: 2018-08-01T01:42:23.020240: step 29312, loss 0.648169.
Train: 2018-08-01T01:42:23.176420: step 29313, loss 0.545292.
Train: 2018-08-01T01:42:23.332634: step 29314, loss 0.52817.
Train: 2018-08-01T01:42:23.488877: step 29315, loss 0.613817.
Train: 2018-08-01T01:42:23.645090: step 29316, loss 0.476828.
Train: 2018-08-01T01:42:23.801305: step 29317, loss 0.630944.
Train: 2018-08-01T01:42:23.973142: step 29318, loss 0.545304.
Train: 2018-08-01T01:42:24.129358: step 29319, loss 0.59667.
Train: 2018-08-01T01:42:24.285537: step 29320, loss 0.562427.
Test: 2018-08-01T01:42:24.754175: step 29320, loss 0.548104.
Train: 2018-08-01T01:42:24.910420: step 29321, loss 0.562428.
Train: 2018-08-01T01:42:25.082249: step 29322, loss 0.69921.
Train: 2018-08-01T01:42:25.238438: step 29323, loss 0.613619.
Train: 2018-08-01T01:42:25.394682: step 29324, loss 0.630517.
Train: 2018-08-01T01:42:25.550864: step 29325, loss 0.56244.
Train: 2018-08-01T01:42:25.707109: step 29326, loss 0.494754.
Train: 2018-08-01T01:42:25.863293: step 29327, loss 0.494865.
Train: 2018-08-01T01:42:26.035150: step 29328, loss 0.562453.
Train: 2018-08-01T01:42:26.222581: step 29329, loss 0.629979.
Train: 2018-08-01T01:42:26.378825: step 29330, loss 0.44443.
Test: 2018-08-01T01:42:26.847435: step 29330, loss 0.548331.
Train: 2018-08-01T01:42:27.003649: step 29331, loss 0.629934.
Train: 2018-08-01T01:42:27.175525: step 29332, loss 0.596184.
Train: 2018-08-01T01:42:27.331727: step 29333, loss 0.613014.
Train: 2018-08-01T01:42:27.503562: step 29334, loss 0.461485.
Train: 2018-08-01T01:42:27.659776: step 29335, loss 0.663468.
Train: 2018-08-01T01:42:27.815989: step 29336, loss 0.562469.
Train: 2018-08-01T01:42:27.972205: step 29337, loss 0.495265.
Train: 2018-08-01T01:42:28.128419: step 29338, loss 0.562472.
Train: 2018-08-01T01:42:28.284631: step 29339, loss 0.545664.
Train: 2018-08-01T01:42:28.456434: step 29340, loss 0.512026.
Test: 2018-08-01T01:42:28.925107: step 29340, loss 0.548369.
Train: 2018-08-01T01:42:29.081318: step 29341, loss 0.612963.
Train: 2018-08-01T01:42:29.237502: step 29342, loss 0.62982.
Train: 2018-08-01T01:42:29.393716: step 29343, loss 0.478306.
Train: 2018-08-01T01:42:29.549964: step 29344, loss 0.562461.
Train: 2018-08-01T01:42:29.706166: step 29345, loss 0.596169.
Train: 2018-08-01T01:42:29.877976: step 29346, loss 0.629896.
Train: 2018-08-01T01:42:30.034190: step 29347, loss 0.596159.
Train: 2018-08-01T01:42:30.190434: step 29348, loss 0.562463.
Train: 2018-08-01T01:42:30.346647: step 29349, loss 0.612932.
Train: 2018-08-01T01:42:30.502866: step 29350, loss 0.596073.
Test: 2018-08-01T01:42:30.987126: step 29350, loss 0.548432.
Train: 2018-08-01T01:42:31.143336: step 29351, loss 0.495379.
Train: 2018-08-01T01:42:31.299549: step 29352, loss 0.528946.
Train: 2018-08-01T01:42:31.455762: step 29353, loss 0.562481.
Train: 2018-08-01T01:42:31.627567: step 29354, loss 0.528936.
Train: 2018-08-01T01:42:31.783810: step 29355, loss 0.445001.
Train: 2018-08-01T01:42:31.939994: step 29356, loss 0.478376.
Train: 2018-08-01T01:42:32.096232: step 29357, loss 0.596192.
Train: 2018-08-01T01:42:32.252444: step 29358, loss 0.562446.
Train: 2018-08-01T01:42:32.408664: step 29359, loss 0.613275.
Train: 2018-08-01T01:42:32.580499: step 29360, loss 0.5285.
Test: 2018-08-01T01:42:33.064760: step 29360, loss 0.5482.
Train: 2018-08-01T01:42:33.220976: step 29361, loss 0.562432.
Train: 2018-08-01T01:42:33.377156: step 29362, loss 0.545407.
Train: 2018-08-01T01:42:33.549018: step 29363, loss 0.664717.
Train: 2018-08-01T01:42:33.705235: step 29364, loss 0.528323.
Train: 2018-08-01T01:42:33.892661: step 29365, loss 0.596548.
Train: 2018-08-01T01:42:34.033253: step 29366, loss 0.46004.
Train: 2018-08-01T01:42:34.189468: step 29367, loss 0.511159.
Train: 2018-08-01T01:42:34.345679: step 29368, loss 0.613783.
Train: 2018-08-01T01:42:34.517515: step 29369, loss 0.57956.
Train: 2018-08-01T01:42:34.673759: step 29370, loss 0.442355.
Test: 2018-08-01T01:42:35.142401: step 29370, loss 0.548027.
Train: 2018-08-01T01:42:35.298613: step 29371, loss 0.510853.
Train: 2018-08-01T01:42:35.454825: step 29372, loss 0.527956.
Train: 2018-08-01T01:42:35.611039: step 29373, loss 0.527866.
Train: 2018-08-01T01:42:35.782843: step 29374, loss 0.562432.
Train: 2018-08-01T01:42:35.923466: step 29375, loss 0.562438.
Train: 2018-08-01T01:42:36.110927: step 29376, loss 0.649502.
Train: 2018-08-01T01:42:36.267136: step 29377, loss 0.492739.
Train: 2018-08-01T01:42:36.423349: step 29378, loss 0.57991.
Train: 2018-08-01T01:42:36.579532: step 29379, loss 0.579935.
Train: 2018-08-01T01:42:36.735747: step 29380, loss 0.649915.
Test: 2018-08-01T01:42:37.220025: step 29380, loss 0.54782.
Train: 2018-08-01T01:42:37.376245: step 29381, loss 0.544976.
Train: 2018-08-01T01:42:37.532464: step 29382, loss 0.56246.
Train: 2018-08-01T01:42:37.688647: step 29383, loss 0.527503.
Train: 2018-08-01T01:42:37.844861: step 29384, loss 0.527497.
Train: 2018-08-01T01:42:38.001105: step 29385, loss 0.527481.
Train: 2018-08-01T01:42:38.172933: step 29386, loss 0.667498.
Train: 2018-08-01T01:42:38.329123: step 29387, loss 0.457488.
Train: 2018-08-01T01:42:38.485360: step 29388, loss 0.562466.
Train: 2018-08-01T01:42:38.641579: step 29389, loss 0.527433.
Train: 2018-08-01T01:42:38.797793: step 29390, loss 0.422206.
Test: 2018-08-01T01:42:39.266404: step 29390, loss 0.547769.
Train: 2018-08-01T01:42:39.438238: step 29391, loss 0.562486.
Train: 2018-08-01T01:42:39.594452: step 29392, loss 0.580109.
Train: 2018-08-01T01:42:39.750694: step 29393, loss 0.456674.
Train: 2018-08-01T01:42:39.906878: step 29394, loss 0.527157.
Train: 2018-08-01T01:42:40.047500: step 29395, loss 0.509352.
Train: 2018-08-01T01:42:40.219337: step 29396, loss 0.509222.
Train: 2018-08-01T01:42:40.375519: step 29397, loss 0.65178.
Train: 2018-08-01T01:42:40.531732: step 29398, loss 0.526877.
Train: 2018-08-01T01:42:40.687982: step 29399, loss 0.526831.
Train: 2018-08-01T01:42:40.859810: step 29400, loss 0.508849.
Test: 2018-08-01T01:42:41.328420: step 29400, loss 0.547622.
Train: 2018-08-01T01:42:42.031381: step 29401, loss 0.616588.
Train: 2018-08-01T01:42:42.187624: step 29402, loss 0.544691.
Train: 2018-08-01T01:42:42.343807: step 29403, loss 0.616746.
Train: 2018-08-01T01:42:42.500054: step 29404, loss 0.616769.
Train: 2018-08-01T01:42:42.671892: step 29405, loss 0.526669.
Train: 2018-08-01T01:42:42.828069: step 29406, loss 0.562696.
Train: 2018-08-01T01:42:42.984281: step 29407, loss 0.634725.
Train: 2018-08-01T01:42:43.140526: step 29408, loss 0.56268.
Train: 2018-08-01T01:42:43.296739: step 29409, loss 0.544701.
Train: 2018-08-01T01:42:43.452952: step 29410, loss 0.598555.
Test: 2018-08-01T01:42:43.921562: step 29410, loss 0.547632.
Train: 2018-08-01T01:42:44.077777: step 29411, loss 0.59849.
Train: 2018-08-01T01:42:44.249610: step 29412, loss 0.526839.
Train: 2018-08-01T01:42:44.405854: step 29413, loss 0.491136.
Train: 2018-08-01T01:42:44.562068: step 29414, loss 0.651906.
Train: 2018-08-01T01:42:44.718284: step 29415, loss 0.740914.
Train: 2018-08-01T01:42:44.890086: step 29416, loss 0.491482.
Train: 2018-08-01T01:42:45.061921: step 29417, loss 0.68662.
Train: 2018-08-01T01:42:45.218164: step 29418, loss 0.544854.
Train: 2018-08-01T01:42:45.358756: step 29419, loss 0.509686.
Train: 2018-08-01T01:42:45.530562: step 29420, loss 0.544919.
Test: 2018-08-01T01:42:45.999202: step 29420, loss 0.547793.
Train: 2018-08-01T01:42:46.155445: step 29421, loss 0.667619.
Train: 2018-08-01T01:42:46.311664: step 29422, loss 0.527513.
Train: 2018-08-01T01:42:46.467874: step 29423, loss 0.545017.
Train: 2018-08-01T01:42:46.639675: step 29424, loss 0.475475.
Train: 2018-08-01T01:42:46.795920: step 29425, loss 0.562435.
Train: 2018-08-01T01:42:46.952134: step 29426, loss 0.579797.
Train: 2018-08-01T01:42:47.123962: step 29427, loss 0.545083.
Train: 2018-08-01T01:42:47.280181: step 29428, loss 0.562428.
Train: 2018-08-01T01:42:47.436395: step 29429, loss 0.718349.
Train: 2018-08-01T01:42:47.592579: step 29430, loss 0.54514.
Test: 2018-08-01T01:42:48.061245: step 29430, loss 0.547977.
Train: 2018-08-01T01:42:48.233088: step 29431, loss 0.45894.
Train: 2018-08-01T01:42:48.389297: step 29432, loss 0.596891.
Train: 2018-08-01T01:42:48.561101: step 29433, loss 0.527979.
Train: 2018-08-01T01:42:48.717315: step 29434, loss 0.562417.
Train: 2018-08-01T01:42:48.873527: step 29435, loss 0.545213.
Train: 2018-08-01T01:42:49.045363: step 29436, loss 0.545216.
Train: 2018-08-01T01:42:49.201619: step 29437, loss 0.528014.
Train: 2018-08-01T01:42:49.373441: step 29438, loss 0.527999.
Train: 2018-08-01T01:42:49.514033: step 29439, loss 0.596862.
Train: 2018-08-01T01:42:49.670247: step 29440, loss 0.579645.
Test: 2018-08-01T01:42:50.154509: step 29440, loss 0.54799.
Train: 2018-08-01T01:42:50.326313: step 29441, loss 0.493503.
Train: 2018-08-01T01:42:50.482556: step 29442, loss 0.476201.
Train: 2018-08-01T01:42:50.638769: step 29443, loss 0.59697.
Train: 2018-08-01T01:42:50.794983: step 29444, loss 0.545127.
Train: 2018-08-01T01:42:50.951196: step 29445, loss 0.579742.
Train: 2018-08-01T01:42:51.107405: step 29446, loss 0.562427.
Train: 2018-08-01T01:42:51.263594: step 29447, loss 0.51039.
Train: 2018-08-01T01:42:51.419808: step 29448, loss 0.597169.
Train: 2018-08-01T01:42:51.576056: step 29449, loss 0.562434.
Train: 2018-08-01T01:42:51.747854: step 29450, loss 0.597219.
Test: 2018-08-01T01:42:52.216495: step 29450, loss 0.547871.
Train: 2018-08-01T01:42:52.372708: step 29451, loss 0.492863.
Train: 2018-08-01T01:42:52.528922: step 29452, loss 0.475397.
Train: 2018-08-01T01:42:52.685165: step 29453, loss 0.545006.
Train: 2018-08-01T01:42:52.856995: step 29454, loss 0.527511.
Train: 2018-08-01T01:42:53.013213: step 29455, loss 0.544956.
Train: 2018-08-01T01:42:53.169397: step 29456, loss 0.580008.
Train: 2018-08-01T01:42:53.325611: step 29457, loss 0.650294.
Train: 2018-08-01T01:42:53.481824: step 29458, loss 0.562479.
Train: 2018-08-01T01:42:53.638037: step 29459, loss 0.667894.
Train: 2018-08-01T01:42:53.794281: step 29460, loss 0.580021.
Test: 2018-08-01T01:42:54.262920: step 29460, loss 0.547791.
Train: 2018-08-01T01:42:54.419135: step 29461, loss 0.544941.
Train: 2018-08-01T01:42:54.575348: step 29462, loss 0.649991.
Train: 2018-08-01T01:42:54.747153: step 29463, loss 0.649803.
Train: 2018-08-01T01:42:54.903397: step 29464, loss 0.492764.
Train: 2018-08-01T01:42:55.075201: step 29465, loss 0.562434.
Train: 2018-08-01T01:42:55.231414: step 29466, loss 0.510358.
Train: 2018-08-01T01:42:55.403279: step 29467, loss 0.458382.
Train: 2018-08-01T01:42:55.559487: step 29468, loss 0.631816.
Train: 2018-08-01T01:42:55.700084: step 29469, loss 0.562426.
Train: 2018-08-01T01:42:55.871889: step 29470, loss 0.579754.
Test: 2018-08-01T01:42:56.340559: step 29470, loss 0.547922.
Train: 2018-08-01T01:42:56.496743: step 29471, loss 0.527789.
Train: 2018-08-01T01:42:56.668602: step 29472, loss 0.614362.
Train: 2018-08-01T01:42:56.824816: step 29473, loss 0.47593.
Train: 2018-08-01T01:42:56.996626: step 29474, loss 0.510514.
Train: 2018-08-01T01:42:57.152873: step 29475, loss 0.614373.
Train: 2018-08-01T01:42:57.309083: step 29476, loss 0.614378.
Train: 2018-08-01T01:42:57.465297: step 29477, loss 0.631655.
Train: 2018-08-01T01:42:57.621509: step 29478, loss 0.631558.
Train: 2018-08-01T01:42:57.762102: step 29479, loss 0.545168.
Train: 2018-08-01T01:42:57.918315: step 29480, loss 0.614072.
Test: 2018-08-01T01:42:58.386924: step 29480, loss 0.548025.
Train: 2018-08-01T01:42:58.543140: step 29481, loss 0.545232.
Train: 2018-08-01T01:42:58.715003: step 29482, loss 0.613868.
Train: 2018-08-01T01:42:58.871217: step 29483, loss 0.579527.
Train: 2018-08-01T01:42:59.027431: step 29484, loss 0.528263.
Train: 2018-08-01T01:42:59.214889: step 29485, loss 0.647665.
Train: 2018-08-01T01:42:59.371100: step 29486, loss 0.715493.
Train: 2018-08-01T01:42:59.527314: step 29487, loss 0.57937.
Train: 2018-08-01T01:42:59.683527: step 29488, loss 0.54557.
Train: 2018-08-01T01:42:59.839740: step 29489, loss 0.596094.
Train: 2018-08-01T01:42:59.995954: step 29490, loss 0.512183.
Test: 2018-08-01T01:43:00.464595: step 29490, loss 0.548479.
Train: 2018-08-01T01:43:00.620807: step 29491, loss 0.595935.
Train: 2018-08-01T01:43:00.776991: step 29492, loss 0.595868.
Train: 2018-08-01T01:43:00.933203: step 29493, loss 0.612443.
Train: 2018-08-01T01:43:01.089418: step 29494, loss 0.496152.
Train: 2018-08-01T01:43:01.261253: step 29495, loss 0.529408.
Train: 2018-08-01T01:43:01.417465: step 29496, loss 0.529445.
Train: 2018-08-01T01:43:01.573679: step 29497, loss 0.529456.
Train: 2018-08-01T01:43:01.729923: step 29498, loss 0.633184.
Train: 2018-08-01T01:43:01.886137: step 29499, loss 0.628737.
Train: 2018-08-01T01:43:02.042320: step 29500, loss 0.463425.
Test: 2018-08-01T01:43:02.510989: step 29500, loss 0.548724.
Train: 2018-08-01T01:43:03.245162: step 29501, loss 0.51298.
Train: 2018-08-01T01:43:03.401375: step 29502, loss 0.64528.
Train: 2018-08-01T01:43:03.588856: step 29503, loss 0.62873.
Train: 2018-08-01T01:43:03.729454: step 29504, loss 0.562564.
Train: 2018-08-01T01:43:03.885638: step 29505, loss 0.57909.
Train: 2018-08-01T01:43:04.041852: step 29506, loss 0.513055.
Train: 2018-08-01T01:43:04.198094: step 29507, loss 0.480029.
Train: 2018-08-01T01:43:04.354308: step 29508, loss 0.595625.
Train: 2018-08-01T01:43:04.510523: step 29509, loss 0.562556.
Train: 2018-08-01T01:43:04.682361: step 29510, loss 0.430073.
Test: 2018-08-01T01:43:05.166586: step 29510, loss 0.548627.
Train: 2018-08-01T01:43:05.369667: step 29511, loss 0.51272.
Train: 2018-08-01T01:43:05.525910: step 29512, loss 0.562509.
Train: 2018-08-01T01:43:05.697714: step 29513, loss 0.579194.
Train: 2018-08-01T01:43:05.838306: step 29514, loss 0.629452.
Train: 2018-08-01T01:43:05.994519: step 29515, loss 0.495402.
Train: 2018-08-01T01:43:06.150762: step 29516, loss 0.512049.
Train: 2018-08-01T01:43:06.306945: step 29517, loss 0.511903.
Train: 2018-08-01T01:43:06.463159: step 29518, loss 0.579337.
Train: 2018-08-01T01:43:06.619372: step 29519, loss 0.579373.
Train: 2018-08-01T01:43:06.791207: step 29520, loss 0.613366.
Test: 2018-08-01T01:43:07.259877: step 29520, loss 0.548182.
Train: 2018-08-01T01:43:07.416091: step 29521, loss 0.579424.
Train: 2018-08-01T01:43:07.572305: step 29522, loss 0.511357.
Train: 2018-08-01T01:43:07.728487: step 29523, loss 0.511275.
Train: 2018-08-01T01:43:07.884701: step 29524, loss 0.61366.
Train: 2018-08-01T01:43:08.040914: step 29525, loss 0.494.
Train: 2018-08-01T01:43:08.197129: step 29526, loss 0.493865.
Train: 2018-08-01T01:43:08.368992: step 29527, loss 0.596774.
Train: 2018-08-01T01:43:08.525206: step 29528, loss 0.493556.
Train: 2018-08-01T01:43:08.681390: step 29529, loss 0.527899.
Train: 2018-08-01T01:43:08.853225: step 29530, loss 0.493201.
Test: 2018-08-01T01:43:09.321894: step 29530, loss 0.547889.
Train: 2018-08-01T01:43:09.493701: step 29531, loss 0.545066.
Train: 2018-08-01T01:43:09.649912: step 29532, loss 0.545022.
Train: 2018-08-01T01:43:09.806125: step 29533, loss 0.614842.
Train: 2018-08-01T01:43:09.962364: step 29534, loss 0.562456.
Train: 2018-08-01T01:43:10.134175: step 29535, loss 0.597522.
Train: 2018-08-01T01:43:10.290418: step 29536, loss 0.544922.
Train: 2018-08-01T01:43:10.446631: step 29537, loss 0.527341.
Train: 2018-08-01T01:43:10.602845: step 29538, loss 0.562483.
Train: 2018-08-01T01:43:10.759052: step 29539, loss 0.509658.
Train: 2018-08-01T01:43:10.915265: step 29540, loss 0.456672.
Test: 2018-08-01T01:43:11.383881: step 29540, loss 0.547709.
Train: 2018-08-01T01:43:11.540096: step 29541, loss 0.52715.
Train: 2018-08-01T01:43:11.711930: step 29542, loss 0.686644.
Train: 2018-08-01T01:43:11.868142: step 29543, loss 0.509309.
Train: 2018-08-01T01:43:12.024388: step 29544, loss 0.527018.
Train: 2018-08-01T01:43:12.180570: step 29545, loss 0.509185.
Train: 2018-08-01T01:43:12.368026: step 29546, loss 0.598232.
Train: 2018-08-01T01:43:12.524270: step 29547, loss 0.562591.
Train: 2018-08-01T01:43:12.680454: step 29548, loss 0.544738.
Train: 2018-08-01T01:43:12.836699: step 29549, loss 0.455339.
Train: 2018-08-01T01:43:13.008534: step 29550, loss 0.437238.
Test: 2018-08-01T01:43:13.477142: step 29550, loss 0.547615.
Train: 2018-08-01T01:43:13.649006: step 29551, loss 0.580627.
Train: 2018-08-01T01:43:13.805219: step 29552, loss 0.670748.
Train: 2018-08-01T01:43:13.961402: step 29553, loss 0.490598.
Train: 2018-08-01T01:43:14.117647: step 29554, loss 0.598813.
Train: 2018-08-01T01:43:14.273860: step 29555, loss 0.472408.
Train: 2018-08-01T01:43:14.445691: step 29556, loss 0.562741.
Train: 2018-08-01T01:43:14.586281: step 29557, loss 0.580869.
Train: 2018-08-01T01:43:14.742501: step 29558, loss 0.526515.
Train: 2018-08-01T01:43:14.898683: step 29559, loss 0.562779.
Train: 2018-08-01T01:43:15.054897: step 29560, loss 0.580944.
Test: 2018-08-01T01:43:15.539160: step 29560, loss 0.547585.
Train: 2018-08-01T01:43:15.695402: step 29561, loss 0.544632.
Train: 2018-08-01T01:43:15.851616: step 29562, loss 0.526466.
Train: 2018-08-01T01:43:16.007829: step 29563, loss 0.471931.
Train: 2018-08-01T01:43:16.164013: step 29564, loss 0.653813.
Train: 2018-08-01T01:43:16.320226: step 29565, loss 0.508227.
Train: 2018-08-01T01:43:16.492061: step 29566, loss 0.544622.
Train: 2018-08-01T01:43:16.648299: step 29567, loss 0.489975.
Train: 2018-08-01T01:43:16.804487: step 29568, loss 0.581084.
Train: 2018-08-01T01:43:16.960731: step 29569, loss 0.562859.
Train: 2018-08-01T01:43:17.116944: step 29570, loss 0.599366.
Test: 2018-08-01T01:43:17.585554: step 29570, loss 0.547581.
Train: 2018-08-01T01:43:17.757390: step 29571, loss 0.508121.
Train: 2018-08-01T01:43:17.913628: step 29572, loss 0.471611.
Train: 2018-08-01T01:43:18.069815: step 29573, loss 0.471533.
Train: 2018-08-01T01:43:18.226059: step 29574, loss 0.508003.
Train: 2018-08-01T01:43:18.382243: step 29575, loss 0.507925.
Train: 2018-08-01T01:43:18.538487: step 29576, loss 0.471084.
Train: 2018-08-01T01:43:18.694694: step 29577, loss 0.618312.
Train: 2018-08-01T01:43:18.866505: step 29578, loss 0.599977.
Train: 2018-08-01T01:43:19.022718: step 29579, loss 0.544592.
Train: 2018-08-01T01:43:19.178956: step 29580, loss 0.581583.
Test: 2018-08-01T01:43:19.647601: step 29580, loss 0.547601.
Train: 2018-08-01T01:43:19.803785: step 29581, loss 0.563095.
Train: 2018-08-01T01:43:19.975619: step 29582, loss 0.729644.
Train: 2018-08-01T01:43:20.131863: step 29583, loss 0.65542.
Train: 2018-08-01T01:43:20.288076: step 29584, loss 0.636689.
Train: 2018-08-01T01:43:20.444285: step 29585, loss 0.471182.
Train: 2018-08-01T01:43:20.600473: step 29586, loss 0.581225.
Train: 2018-08-01T01:43:20.756686: step 29587, loss 0.526345.
Train: 2018-08-01T01:43:20.912930: step 29588, loss 0.508162.
Train: 2018-08-01T01:43:21.100356: step 29589, loss 0.52642.
Train: 2018-08-01T01:43:21.256570: step 29590, loss 0.562809.
Test: 2018-08-01T01:43:21.740831: step 29590, loss 0.547584.
Train: 2018-08-01T01:43:21.897045: step 29591, loss 0.508303.
Train: 2018-08-01T01:43:22.053289: step 29592, loss 0.599095.
Train: 2018-08-01T01:43:22.225122: step 29593, loss 0.544637.
Train: 2018-08-01T01:43:22.381337: step 29594, loss 0.689601.
Train: 2018-08-01T01:43:22.537520: step 29595, loss 0.49042.
Train: 2018-08-01T01:43:22.693764: step 29596, loss 0.598817.
Train: 2018-08-01T01:43:22.849971: step 29597, loss 0.616747.
Train: 2018-08-01T01:43:23.006160: step 29598, loss 0.544688.
Train: 2018-08-01T01:43:23.162400: step 29599, loss 0.616456.
Train: 2018-08-01T01:43:23.334209: step 29600, loss 0.616289.
Test: 2018-08-01T01:43:23.802878: step 29600, loss 0.547649.
Train: 2018-08-01T01:43:24.490217: step 29601, loss 0.616094.
Train: 2018-08-01T01:43:24.646431: step 29602, loss 0.580328.
Train: 2018-08-01T01:43:24.802645: step 29603, loss 0.615665.
Train: 2018-08-01T01:43:24.958858: step 29604, loss 0.650726.
Train: 2018-08-01T01:43:25.115071: step 29605, loss 0.421951.
Train: 2018-08-01T01:43:25.271279: step 29606, loss 0.527417.
Train: 2018-08-01T01:43:25.458712: step 29607, loss 0.492501.
Train: 2018-08-01T01:43:25.614925: step 29608, loss 0.667268.
Train: 2018-08-01T01:43:25.755550: step 29609, loss 0.632168.
Train: 2018-08-01T01:43:25.927352: step 29610, loss 0.545044.
Test: 2018-08-01T01:43:26.411643: step 29610, loss 0.547899.
Train: 2018-08-01T01:43:26.583478: step 29611, loss 0.614448.
Train: 2018-08-01T01:43:26.739691: step 29612, loss 0.683473.
Train: 2018-08-01T01:43:26.895904: step 29613, loss 0.665758.
Train: 2018-08-01T01:43:27.067740: step 29614, loss 0.545267.
Train: 2018-08-01T01:43:27.223922: step 29615, loss 0.579479.
Train: 2018-08-01T01:43:27.380135: step 29616, loss 0.596418.
Train: 2018-08-01T01:43:27.536349: step 29617, loss 0.494699.
Train: 2018-08-01T01:43:27.708217: step 29618, loss 0.562436.
Train: 2018-08-01T01:43:27.864427: step 29619, loss 0.612979.
Train: 2018-08-01T01:43:28.036262: step 29620, loss 0.562457.
Test: 2018-08-01T01:43:28.504902: step 29620, loss 0.548438.
Train: 2018-08-01T01:43:28.676738: step 29621, loss 0.595983.
Train: 2018-08-01T01:43:28.832950: step 29622, loss 0.59591.
Train: 2018-08-01T01:43:28.989136: step 29623, loss 0.67918.
Train: 2018-08-01T01:43:29.145347: step 29624, loss 0.645547.
Train: 2018-08-01T01:43:29.301591: step 29625, loss 0.694799.
Train: 2018-08-01T01:43:29.457774: step 29626, loss 0.43112.
Train: 2018-08-01T01:43:29.614017: step 29627, loss 0.513492.
Train: 2018-08-01T01:43:29.801474: step 29628, loss 0.644398.
Train: 2018-08-01T01:43:29.942065: step 29629, loss 0.611592.
Train: 2018-08-01T01:43:30.113901: step 29630, loss 0.562727.
Test: 2018-08-01T01:43:30.582541: step 29630, loss 0.549188.
Train: 2018-08-01T01:43:30.738754: step 29631, loss 0.595169.
Train: 2018-08-01T01:43:30.926211: step 29632, loss 0.6436.
Train: 2018-08-01T01:43:31.082424: step 29633, loss 0.546728.
Train: 2018-08-01T01:43:31.238631: step 29634, loss 0.530741.
Train: 2018-08-01T01:43:31.394821: step 29635, loss 0.498748.
Train: 2018-08-01T01:43:31.551034: step 29636, loss 0.627018.
Train: 2018-08-01T01:43:31.707272: step 29637, loss 0.466851.
Train: 2018-08-01T01:43:31.879081: step 29638, loss 0.498831.
Train: 2018-08-01T01:43:32.050947: step 29639, loss 0.514752.
Train: 2018-08-01T01:43:32.191508: step 29640, loss 0.59502.
Test: 2018-08-01T01:43:32.660148: step 29640, loss 0.549341.
Train: 2018-08-01T01:43:32.831984: step 29641, loss 0.530611.
Train: 2018-08-01T01:43:32.988228: step 29642, loss 0.643537.
Train: 2018-08-01T01:43:33.160033: step 29643, loss 0.611282.
Train: 2018-08-01T01:43:33.316270: step 29644, loss 0.53044.
Train: 2018-08-01T01:43:33.472489: step 29645, loss 0.546582.
Train: 2018-08-01T01:43:33.644294: step 29646, loss 0.514125.
Train: 2018-08-01T01:43:33.800507: step 29647, loss 0.595216.
Train: 2018-08-01T01:43:33.956751: step 29648, loss 0.676587.
Train: 2018-08-01T01:43:34.128556: step 29649, loss 0.64405.
Train: 2018-08-01T01:43:34.284768: step 29650, loss 0.611479.
Test: 2018-08-01T01:43:34.753439: step 29650, loss 0.549151.
Train: 2018-08-01T01:43:34.925245: step 29651, loss 0.546512.
Train: 2018-08-01T01:43:35.081456: step 29652, loss 0.660041.
Train: 2018-08-01T01:43:35.253323: step 29653, loss 0.692242.
Train: 2018-08-01T01:43:35.409530: step 29654, loss 0.643462.
Train: 2018-08-01T01:43:35.565719: step 29655, loss 0.482544.
Train: 2018-08-01T01:43:35.721933: step 29656, loss 0.482759.
Train: 2018-08-01T01:43:35.878149: step 29657, loss 0.466811.
Train: 2018-08-01T01:43:36.034360: step 29658, loss 0.675116.
Train: 2018-08-01T01:43:36.190572: step 29659, loss 0.610972.
Train: 2018-08-01T01:43:36.346822: step 29660, loss 0.658957.
Test: 2018-08-01T01:43:36.815425: step 29660, loss 0.549576.
Train: 2018-08-01T01:43:36.971670: step 29661, loss 0.499058.
Train: 2018-08-01T01:43:37.127883: step 29662, loss 0.531039.
Train: 2018-08-01T01:43:37.284091: step 29663, loss 0.642771.
Train: 2018-08-01T01:43:37.440311: step 29664, loss 0.642712.
Train: 2018-08-01T01:43:37.596523: step 29665, loss 0.70628.
Train: 2018-08-01T01:43:37.752707: step 29666, loss 0.578921.
Train: 2018-08-01T01:43:37.908950: step 29667, loss 0.594741.
Train: 2018-08-01T01:43:38.065164: step 29668, loss 0.626242.
Train: 2018-08-01T01:43:38.221348: step 29669, loss 0.516054.
Train: 2018-08-01T01:43:38.377560: step 29670, loss 0.641683.
Test: 2018-08-01T01:43:38.846230: step 29670, loss 0.550201.
Train: 2018-08-01T01:43:39.002444: step 29671, loss 0.657159.
Train: 2018-08-01T01:43:39.158658: step 29672, loss 0.625718.
Train: 2018-08-01T01:43:39.314866: step 29673, loss 0.594489.
Train: 2018-08-01T01:43:39.471057: step 29674, loss 0.532678.
Train: 2018-08-01T01:43:39.627269: step 29675, loss 0.594426.
Train: 2018-08-01T01:43:39.783481: step 29676, loss 0.578983.
Train: 2018-08-01T01:43:39.939695: step 29677, loss 0.609677.
Train: 2018-08-01T01:43:40.111529: step 29678, loss 0.548534.
Train: 2018-08-01T01:43:40.267773: step 29679, loss 0.517898.
Train: 2018-08-01T01:43:40.423986: step 29680, loss 0.548517.
Test: 2018-08-01T01:43:40.892636: step 29680, loss 0.550931.
Train: 2018-08-01T01:43:41.033218: step 29681, loss 0.579046.
Train: 2018-08-01T01:43:41.189402: step 29682, loss 0.487168.
Train: 2018-08-01T01:43:41.345645: step 29683, loss 0.640413.
Train: 2018-08-01T01:43:41.501829: step 29684, loss 0.532967.
Train: 2018-08-01T01:43:41.658072: step 29685, loss 0.625166.
Train: 2018-08-01T01:43:41.829911: step 29686, loss 0.563628.
Train: 2018-08-01T01:43:41.986120: step 29687, loss 0.532788.
Train: 2018-08-01T01:43:42.142328: step 29688, loss 0.563569.
Train: 2018-08-01T01:43:42.298517: step 29689, loss 0.470744.
Train: 2018-08-01T01:43:42.454755: step 29690, loss 0.594495.
Test: 2018-08-01T01:43:42.923370: step 29690, loss 0.550375.
Train: 2018-08-01T01:43:43.079616: step 29691, loss 0.438918.
Train: 2018-08-01T01:43:43.235828: step 29692, loss 0.532048.
Train: 2018-08-01T01:43:43.392047: step 29693, loss 0.578936.
Train: 2018-08-01T01:43:43.548254: step 29694, loss 0.673611.
Train: 2018-08-01T01:43:43.720083: step 29695, loss 0.578925.
Train: 2018-08-01T01:43:43.876303: step 29696, loss 0.531345.
Train: 2018-08-01T01:43:44.032523: step 29697, loss 0.467593.
Train: 2018-08-01T01:43:44.188730: step 29698, loss 0.674743.
Train: 2018-08-01T01:43:44.344913: step 29699, loss 0.546917.
Train: 2018-08-01T01:43:44.501127: step 29700, loss 0.578934.
Test: 2018-08-01T01:43:44.969796: step 29700, loss 0.549391.
Train: 2018-08-01T01:43:45.672758: step 29701, loss 0.627184.
Train: 2018-08-01T01:43:45.828940: step 29702, loss 0.514533.
Train: 2018-08-01T01:43:45.985153: step 29703, loss 0.546679.
Train: 2018-08-01T01:43:46.141369: step 29704, loss 0.530445.
Train: 2018-08-01T01:43:46.313238: step 29705, loss 0.643813.
Train: 2018-08-01T01:43:46.469446: step 29706, loss 0.562738.
Train: 2018-08-01T01:43:46.641281: step 29707, loss 0.562721.
Train: 2018-08-01T01:43:46.797466: step 29708, loss 0.448746.
Train: 2018-08-01T01:43:46.953710: step 29709, loss 0.546346.
Train: 2018-08-01T01:43:47.109921: step 29710, loss 0.513512.
Test: 2018-08-01T01:43:47.578555: step 29710, loss 0.548848.
Train: 2018-08-01T01:43:47.750365: step 29711, loss 0.628345.
Train: 2018-08-01T01:43:47.906609: step 29712, loss 0.546115.
Train: 2018-08-01T01:43:48.062822: step 29713, loss 0.546054.
Train: 2018-08-01T01:43:48.219040: step 29714, loss 0.579103.
Train: 2018-08-01T01:43:48.390877: step 29715, loss 0.562531.
Train: 2018-08-01T01:43:48.547078: step 29716, loss 0.462766.
Train: 2018-08-01T01:43:48.718919: step 29717, loss 0.462426.
Train: 2018-08-01T01:43:48.875104: step 29718, loss 0.528974.
Train: 2018-08-01T01:43:49.031346: step 29719, loss 0.495169.
Train: 2018-08-01T01:43:49.187528: step 29720, loss 0.697634.
Test: 2018-08-01T01:43:49.656200: step 29720, loss 0.548236.
Train: 2018-08-01T01:43:49.812416: step 29721, loss 0.596313.
Train: 2018-08-01T01:43:49.968626: step 29722, loss 0.562419.
Train: 2018-08-01T01:43:50.124839: step 29723, loss 0.613437.
Train: 2018-08-01T01:43:50.281053: step 29724, loss 0.596462.
Train: 2018-08-01T01:43:50.437266: step 29725, loss 0.630544.
Train: 2018-08-01T01:43:50.624692: step 29726, loss 0.647546.
Train: 2018-08-01T01:43:50.780938: step 29727, loss 0.494402.
Train: 2018-08-01T01:43:50.937149: step 29728, loss 0.511425.
Train: 2018-08-01T01:43:51.093363: step 29729, loss 0.562416.
Train: 2018-08-01T01:43:51.249546: step 29730, loss 0.647457.
Test: 2018-08-01T01:43:51.733817: step 29730, loss 0.548184.
Train: 2018-08-01T01:43:51.874430: step 29731, loss 0.630401.
Train: 2018-08-01T01:43:52.046235: step 29732, loss 0.579391.
Train: 2018-08-01T01:43:52.202473: step 29733, loss 0.528533.
Train: 2018-08-01T01:43:52.358691: step 29734, loss 0.613217.
Train: 2018-08-01T01:43:52.514905: step 29735, loss 0.562431.
Train: 2018-08-01T01:43:52.671117: step 29736, loss 0.66375.
Train: 2018-08-01T01:43:52.842923: step 29737, loss 0.562443.
Train: 2018-08-01T01:43:52.999137: step 29738, loss 0.528832.
Train: 2018-08-01T01:43:53.155380: step 29739, loss 0.461732.
Train: 2018-08-01T01:43:53.311563: step 29740, loss 0.528877.
Test: 2018-08-01T01:43:53.764612: step 29740, loss 0.548387.
Train: 2018-08-01T01:43:53.936448: step 29741, loss 0.596056.
Train: 2018-08-01T01:43:54.108282: step 29742, loss 0.495244.
Train: 2018-08-01T01:43:54.264501: step 29743, loss 0.52881.
Train: 2018-08-01T01:43:54.420709: step 29744, loss 0.528757.
Train: 2018-08-01T01:43:54.592541: step 29745, loss 0.511818.
Train: 2018-08-01T01:43:54.748752: step 29746, loss 0.579342.
Train: 2018-08-01T01:43:54.904972: step 29747, loss 0.579368.
Train: 2018-08-01T01:43:55.076811: step 29748, loss 0.56242.
Train: 2018-08-01T01:43:55.248641: step 29749, loss 0.477499.
Train: 2018-08-01T01:43:55.404823: step 29750, loss 0.545381.
Test: 2018-08-01T01:43:55.873493: step 29750, loss 0.548118.
Train: 2018-08-01T01:43:56.045323: step 29751, loss 0.613618.
Train: 2018-08-01T01:43:56.201544: step 29752, loss 0.511103.
Train: 2018-08-01T01:43:56.357725: step 29753, loss 0.579471.
Train: 2018-08-01T01:43:56.513968: step 29754, loss 0.648491.
Train: 2018-08-01T01:43:56.670182: step 29755, loss 0.632197.
Train: 2018-08-01T01:43:56.841987: step 29756, loss 0.510895.
Train: 2018-08-01T01:43:56.998230: step 29757, loss 0.4766.
Train: 2018-08-01T01:43:57.154415: step 29758, loss 0.596783.
Train: 2018-08-01T01:43:57.310651: step 29759, loss 0.493681.
Train: 2018-08-01T01:43:57.466875: step 29760, loss 0.493587.
Test: 2018-08-01T01:43:57.935510: step 29760, loss 0.547974.
Train: 2018-08-01T01:43:58.091729: step 29761, loss 0.579652.
Train: 2018-08-01T01:43:58.247908: step 29762, loss 0.579682.
Train: 2018-08-01T01:43:58.419767: step 29763, loss 0.510544.
Train: 2018-08-01T01:43:58.575986: step 29764, loss 0.527778.
Train: 2018-08-01T01:43:58.732199: step 29765, loss 0.579777.
Train: 2018-08-01T01:43:58.888406: step 29766, loss 0.49291.
Train: 2018-08-01T01:43:59.044596: step 29767, loss 0.562434.
Train: 2018-08-01T01:43:59.200840: step 29768, loss 0.492645.
Train: 2018-08-01T01:43:59.357024: step 29769, loss 0.492485.
Train: 2018-08-01T01:43:59.528882: step 29770, loss 0.58001.
Test: 2018-08-01T01:43:59.997527: step 29770, loss 0.547753.
Train: 2018-08-01T01:44:00.153741: step 29771, loss 0.509722.
Train: 2018-08-01T01:44:00.309955: step 29772, loss 0.527229.
Train: 2018-08-01T01:44:00.481760: step 29773, loss 0.580196.
Train: 2018-08-01T01:44:00.638003: step 29774, loss 0.580251.
Train: 2018-08-01T01:44:00.778595: step 29775, loss 0.473792.
Train: 2018-08-01T01:44:00.950429: step 29776, loss 0.54477.
Train: 2018-08-01T01:44:01.106643: step 29777, loss 0.562584.
Train: 2018-08-01T01:44:01.262826: step 29778, loss 0.526865.
Train: 2018-08-01T01:44:01.419064: step 29779, loss 0.616338.
Train: 2018-08-01T01:44:01.590876: step 29780, loss 0.562634.
Test: 2018-08-01T01:44:02.059544: step 29780, loss 0.54762.
Train: 2018-08-01T01:44:02.215753: step 29781, loss 0.616467.
Train: 2018-08-01T01:44:02.371941: step 29782, loss 0.616472.
Train: 2018-08-01T01:44:02.528156: step 29783, loss 0.5985.
Train: 2018-08-01T01:44:02.700022: step 29784, loss 0.473069.
Train: 2018-08-01T01:44:02.856204: step 29785, loss 0.526806.
Train: 2018-08-01T01:44:03.012417: step 29786, loss 0.526801.
Train: 2018-08-01T01:44:03.168629: step 29787, loss 0.508868.
Train: 2018-08-01T01:44:03.340489: step 29788, loss 0.401204.
Train: 2018-08-01T01:44:03.496710: step 29789, loss 0.472758.
Train: 2018-08-01T01:44:03.637301: step 29790, loss 0.52663.
Test: 2018-08-01T01:44:04.121557: step 29790, loss 0.547591.
Train: 2018-08-01T01:44:04.277776: step 29791, loss 0.580834.
Train: 2018-08-01T01:44:04.433989: step 29792, loss 0.599045.
Train: 2018-08-01T01:44:04.590202: step 29793, loss 0.61729.
Train: 2018-08-01T01:44:04.746385: step 29794, loss 0.562805.
Train: 2018-08-01T01:44:04.918220: step 29795, loss 0.490065.
Train: 2018-08-01T01:44:05.058842: step 29796, loss 0.471796.
Train: 2018-08-01T01:44:05.215051: step 29797, loss 0.654046.
Train: 2018-08-01T01:44:05.371239: step 29798, loss 0.581107.
Train: 2018-08-01T01:44:05.527483: step 29799, loss 0.504466.
Train: 2018-08-01T01:44:05.683696: step 29800, loss 0.599384.
Test: 2018-08-01T01:44:06.152336: step 29800, loss 0.54758.
Train: 2018-08-01T01:44:06.839675: step 29801, loss 0.654147.
Train: 2018-08-01T01:44:07.011481: step 29802, loss 0.526381.
Train: 2018-08-01T01:44:07.167693: step 29803, loss 0.544618.
Train: 2018-08-01T01:44:07.323906: step 29804, loss 0.581029.
Train: 2018-08-01T01:44:07.480150: step 29805, loss 0.453696.
Train: 2018-08-01T01:44:07.636334: step 29806, loss 0.65375.
Train: 2018-08-01T01:44:07.792547: step 29807, loss 0.52646.
Train: 2018-08-01T01:44:07.948760: step 29808, loss 0.562787.
Train: 2018-08-01T01:44:08.104974: step 29809, loss 0.50835.
Train: 2018-08-01T01:44:08.261187: step 29810, loss 0.635323.
Test: 2018-08-01T01:44:08.745479: step 29810, loss 0.547587.
Train: 2018-08-01T01:44:08.901663: step 29811, loss 0.635223.
Train: 2018-08-01T01:44:09.057906: step 29812, loss 0.580812.
Train: 2018-08-01T01:44:09.229744: step 29813, loss 0.508579.
Train: 2018-08-01T01:44:09.370333: step 29814, loss 0.634751.
Train: 2018-08-01T01:44:09.526515: step 29815, loss 0.580638.
Train: 2018-08-01T01:44:09.698350: step 29816, loss 0.544704.
Train: 2018-08-01T01:44:09.854564: step 29817, loss 0.562616.
Train: 2018-08-01T01:44:10.010778: step 29818, loss 0.491148.
Train: 2018-08-01T01:44:10.166991: step 29819, loss 0.651804.
Train: 2018-08-01T01:44:10.338826: step 29820, loss 0.562568.
Test: 2018-08-01T01:44:10.807497: step 29820, loss 0.547669.
Train: 2018-08-01T01:44:10.963704: step 29821, loss 0.562551.
Train: 2018-08-01T01:44:11.119923: step 29822, loss 0.544797.
Train: 2018-08-01T01:44:11.276131: step 29823, loss 0.562524.
Train: 2018-08-01T01:44:11.463588: step 29824, loss 0.597882.
Train: 2018-08-01T01:44:11.619806: step 29825, loss 0.633107.
Train: 2018-08-01T01:44:11.775989: step 29826, loss 0.52727.
Train: 2018-08-01T01:44:11.932245: step 29827, loss 0.404322.
Train: 2018-08-01T01:44:12.088446: step 29828, loss 0.580045.
Train: 2018-08-01T01:44:12.244660: step 29829, loss 0.597606.
Train: 2018-08-01T01:44:12.400843: step 29830, loss 0.492246.
Test: 2018-08-01T01:44:12.869513: step 29830, loss 0.547765.
Train: 2018-08-01T01:44:13.025727: step 29831, loss 0.615139.
Train: 2018-08-01T01:44:13.181910: step 29832, loss 0.597559.
Train: 2018-08-01T01:44:13.322503: step 29833, loss 0.54493.
Train: 2018-08-01T01:44:13.494337: step 29834, loss 0.632524.
Train: 2018-08-01T01:44:13.650551: step 29835, loss 0.527469.
Train: 2018-08-01T01:44:13.806764: step 29836, loss 0.597388.
Train: 2018-08-01T01:44:13.963007: step 29837, loss 0.544991.
Train: 2018-08-01T01:44:14.119215: step 29838, loss 0.649576.
Train: 2018-08-01T01:44:14.275434: step 29839, loss 0.614605.
Train: 2018-08-01T01:44:14.431618: step 29840, loss 0.666513.
Test: 2018-08-01T01:44:14.915908: step 29840, loss 0.547936.
Train: 2018-08-01T01:44:15.072127: step 29841, loss 0.64885.
Train: 2018-08-01T01:44:15.228336: step 29842, loss 0.545193.
Train: 2018-08-01T01:44:15.384550: step 29843, loss 0.648163.
Train: 2018-08-01T01:44:15.540763: step 29844, loss 0.477023.
Train: 2018-08-01T01:44:15.696977: step 29845, loss 0.528355.
Train: 2018-08-01T01:44:15.868811: step 29846, loss 0.562416.
Train: 2018-08-01T01:44:16.024993: step 29847, loss 0.443702.
Train: 2018-08-01T01:44:16.181207: step 29848, loss 0.596334.
Train: 2018-08-01T01:44:16.337451: step 29849, loss 0.528529.
Train: 2018-08-01T01:44:16.493665: step 29850, loss 0.511585.
Test: 2018-08-01T01:44:16.962305: step 29850, loss 0.548222.
Train: 2018-08-01T01:44:17.118518: step 29851, loss 0.630246.
Train: 2018-08-01T01:44:17.274733: step 29852, loss 0.579373.
Train: 2018-08-01T01:44:17.430916: step 29853, loss 0.528533.
Train: 2018-08-01T01:44:17.587129: step 29854, loss 0.528529.
Train: 2018-08-01T01:44:17.743373: step 29855, loss 0.52851.
Train: 2018-08-01T01:44:17.899580: step 29856, loss 0.494532.
Train: 2018-08-01T01:44:18.071420: step 29857, loss 0.545414.
Train: 2018-08-01T01:44:18.227628: step 29858, loss 0.494287.
Train: 2018-08-01T01:44:18.383817: step 29859, loss 0.596554.
Train: 2018-08-01T01:44:18.540060: step 29860, loss 0.476887.
Test: 2018-08-01T01:44:19.008701: step 29860, loss 0.548044.
Train: 2018-08-01T01:44:19.180531: step 29861, loss 0.579555.
Train: 2018-08-01T01:44:19.352341: step 29862, loss 0.493656.
Train: 2018-08-01T01:44:19.539823: step 29863, loss 0.493466.
Train: 2018-08-01T01:44:19.696011: step 29864, loss 0.527826.
Train: 2018-08-01T01:44:19.867847: step 29865, loss 0.458311.
Train: 2018-08-01T01:44:20.024060: step 29866, loss 0.597283.
Train: 2018-08-01T01:44:20.211523: step 29867, loss 0.632379.
Train: 2018-08-01T01:44:20.383349: step 29868, loss 0.685101.
Train: 2018-08-01T01:44:20.539563: step 29869, loss 0.562458.
Train: 2018-08-01T01:44:20.711397: step 29870, loss 0.544925.
Test: 2018-08-01T01:44:21.180066: step 29870, loss 0.547772.
Train: 2018-08-01T01:44:21.351903: step 29871, loss 0.580003.
Train: 2018-08-01T01:44:21.554974: step 29872, loss 0.474743.
Train: 2018-08-01T01:44:21.711187: step 29873, loss 0.667844.
Train: 2018-08-01T01:44:21.867406: step 29874, loss 0.509794.
Train: 2018-08-01T01:44:22.023620: step 29875, loss 0.474659.
Train: 2018-08-01T01:44:22.195455: step 29876, loss 0.580057.
Train: 2018-08-01T01:44:22.351670: step 29877, loss 0.562479.
Train: 2018-08-01T01:44:22.523497: step 29878, loss 0.527266.
Train: 2018-08-01T01:44:22.679724: step 29879, loss 0.562488.
Train: 2018-08-01T01:44:22.835924: step 29880, loss 0.703597.
Test: 2018-08-01T01:44:23.304540: step 29880, loss 0.547732.
Train: 2018-08-01T01:44:23.460753: step 29881, loss 0.668207.
Train: 2018-08-01T01:44:23.632588: step 29882, loss 0.580055.
Train: 2018-08-01T01:44:23.788832: step 29883, loss 0.492295.
Train: 2018-08-01T01:44:23.945039: step 29884, loss 0.632531.
Train: 2018-08-01T01:44:24.101264: step 29885, loss 0.527478.
Train: 2018-08-01T01:44:24.273088: step 29886, loss 0.492607.
Train: 2018-08-01T01:44:24.413685: step 29887, loss 0.579885.
Train: 2018-08-01T01:44:24.585490: step 29888, loss 0.61474.
Train: 2018-08-01T01:44:24.757325: step 29889, loss 0.510193.
Train: 2018-08-01T01:44:24.897947: step 29890, loss 0.579828.
Test: 2018-08-01T01:44:25.366588: step 29890, loss 0.547865.
Train: 2018-08-01T01:44:25.538422: step 29891, loss 0.52765.
Train: 2018-08-01T01:44:25.694606: step 29892, loss 0.527662.
Train: 2018-08-01T01:44:25.850819: step 29893, loss 0.562423.
Train: 2018-08-01T01:44:26.007062: step 29894, loss 0.631953.
Train: 2018-08-01T01:44:26.163270: step 29895, loss 0.597156.
Train: 2018-08-01T01:44:26.335081: step 29896, loss 0.527725.
Train: 2018-08-01T01:44:26.475702: step 29897, loss 0.510413.
Train: 2018-08-01T01:44:26.647508: step 29898, loss 0.44108.
Train: 2018-08-01T01:44:26.803721: step 29899, loss 0.510347.
Train: 2018-08-01T01:44:26.959964: step 29900, loss 0.510257.
Test: 2018-08-01T01:44:27.444194: step 29900, loss 0.547838.
Train: 2018-08-01T01:44:28.100321: step 29901, loss 0.562432.
Train: 2018-08-01T01:44:28.256505: step 29902, loss 0.510053.
Train: 2018-08-01T01:44:28.412748: step 29903, loss 0.649963.
Train: 2018-08-01T01:44:28.584583: step 29904, loss 0.615015.
Train: 2018-08-01T01:44:28.740791: step 29905, loss 0.527407.
Train: 2018-08-01T01:44:28.897010: step 29906, loss 0.52739.
Train: 2018-08-01T01:44:29.068848: step 29907, loss 0.562463.
Train: 2018-08-01T01:44:29.225030: step 29908, loss 0.509781.
Train: 2018-08-01T01:44:29.381242: step 29909, loss 0.580056.
Train: 2018-08-01T01:44:29.537455: step 29910, loss 0.580074.
Test: 2018-08-01T01:44:30.006121: step 29910, loss 0.547739.
Train: 2018-08-01T01:44:30.177931: step 29911, loss 0.580085.
Train: 2018-08-01T01:44:30.334168: step 29912, loss 0.597695.
Train: 2018-08-01T01:44:30.490387: step 29913, loss 0.650481.
Train: 2018-08-01T01:44:30.646601: step 29914, loss 0.544895.
Train: 2018-08-01T01:44:30.802813: step 29915, loss 0.562464.
Train: 2018-08-01T01:44:30.959021: step 29916, loss 0.544922.
Train: 2018-08-01T01:44:31.115241: step 29917, loss 0.579976.
Train: 2018-08-01T01:44:31.287070: step 29918, loss 0.632465.
Train: 2018-08-01T01:44:31.443285: step 29919, loss 0.492551.
Train: 2018-08-01T01:44:31.599473: step 29920, loss 0.562438.
Test: 2018-08-01T01:44:32.068143: step 29920, loss 0.547828.
Train: 2018-08-01T01:44:32.239949: step 29921, loss 0.457772.
Train: 2018-08-01T01:44:32.411782: step 29922, loss 0.632245.
Train: 2018-08-01T01:44:32.568025: step 29923, loss 0.475215.
Train: 2018-08-01T01:44:32.724241: step 29924, loss 0.6148.
Train: 2018-08-01T01:44:32.880455: step 29925, loss 0.562437.
Train: 2018-08-01T01:44:33.036635: step 29926, loss 0.63223.
Train: 2018-08-01T01:44:33.192881: step 29927, loss 0.475279.
Train: 2018-08-01T01:44:33.364713: step 29928, loss 0.579864.
Train: 2018-08-01T01:44:33.536543: step 29929, loss 0.597288.
Train: 2018-08-01T01:44:33.692732: step 29930, loss 0.457925.
Test: 2018-08-01T01:44:34.161402: step 29930, loss 0.547837.
Train: 2018-08-01T01:44:34.333232: step 29931, loss 0.562431.
Train: 2018-08-01T01:44:34.505042: step 29932, loss 0.510121.
Train: 2018-08-01T01:44:34.661255: step 29933, loss 0.492615.
Train: 2018-08-01T01:44:34.817469: step 29934, loss 0.492502.
Train: 2018-08-01T01:44:34.973707: step 29935, loss 0.562455.
Train: 2018-08-01T01:44:35.129925: step 29936, loss 0.474659.
Train: 2018-08-01T01:44:35.286139: step 29937, loss 0.597702.
Train: 2018-08-01T01:44:35.442353: step 29938, loss 0.562494.
Train: 2018-08-01T01:44:35.614193: step 29939, loss 0.509478.
Train: 2018-08-01T01:44:35.770370: step 29940, loss 0.420818.
Test: 2018-08-01T01:44:36.223419: step 29940, loss 0.547665.
Train: 2018-08-01T01:44:36.379633: step 29941, loss 0.491455.
Train: 2018-08-01T01:44:36.535816: step 29942, loss 0.651782.
Train: 2018-08-01T01:44:36.692030: step 29943, loss 0.598364.
Train: 2018-08-01T01:44:36.848243: step 29944, loss 0.562618.
Train: 2018-08-01T01:44:37.004457: step 29945, loss 0.598492.
Train: 2018-08-01T01:44:37.160701: step 29946, loss 0.526755.
Train: 2018-08-01T01:44:37.316914: step 29947, loss 0.616515.
Train: 2018-08-01T01:44:37.473127: step 29948, loss 0.580603.
Train: 2018-08-01T01:44:37.629335: step 29949, loss 0.562643.
Train: 2018-08-01T01:44:37.785555: step 29950, loss 0.562639.
Test: 2018-08-01T01:44:38.254194: step 29950, loss 0.547615.
Train: 2018-08-01T01:44:38.410402: step 29951, loss 0.598506.
Train: 2018-08-01T01:44:38.582252: step 29952, loss 0.598462.
Train: 2018-08-01T01:44:38.738459: step 29953, loss 0.526822.
Train: 2018-08-01T01:44:38.941536: step 29954, loss 0.544723.
Train: 2018-08-01T01:44:39.097747: step 29955, loss 0.437547.
Train: 2018-08-01T01:44:39.253954: step 29956, loss 0.616224.
Train: 2018-08-01T01:44:39.394521: step 29957, loss 0.616214.
Train: 2018-08-01T01:44:39.550735: step 29958, loss 0.56259.
Train: 2018-08-01T01:44:39.722571: step 29959, loss 0.598263.
Train: 2018-08-01T01:44:39.878814: step 29960, loss 0.580387.
Test: 2018-08-01T01:44:40.347453: step 29960, loss 0.547658.
Train: 2018-08-01T01:44:40.503669: step 29961, loss 0.633722.
Train: 2018-08-01T01:44:40.659881: step 29962, loss 0.598041.
Train: 2018-08-01T01:44:40.816089: step 29963, loss 0.580225.
Train: 2018-08-01T01:44:40.972307: step 29964, loss 0.509515.
Train: 2018-08-01T01:44:41.159733: step 29965, loss 0.65064.
Train: 2018-08-01T01:44:41.315977: step 29966, loss 0.509724.
Train: 2018-08-01T01:44:41.472190: step 29967, loss 0.650209.
Train: 2018-08-01T01:44:41.628404: step 29968, loss 0.492445.
Train: 2018-08-01T01:44:41.800238: step 29969, loss 0.57991.
Train: 2018-08-01T01:44:41.940800: step 29970, loss 0.579871.
Test: 2018-08-01T01:44:42.425093: step 29970, loss 0.547851.
Train: 2018-08-01T01:44:42.581275: step 29971, loss 0.68426.
Train: 2018-08-01T01:44:42.737513: step 29972, loss 0.666512.
Train: 2018-08-01T01:44:42.893733: step 29973, loss 0.562408.
Train: 2018-08-01T01:44:43.049946: step 29974, loss 0.545192.
Train: 2018-08-01T01:44:43.206166: step 29975, loss 0.545246.
Train: 2018-08-01T01:44:43.393622: step 29976, loss 0.596623.
Train: 2018-08-01T01:44:43.549837: step 29977, loss 0.545344.
Train: 2018-08-01T01:44:43.706047: step 29978, loss 0.681559.
Train: 2018-08-01T01:44:43.862226: step 29979, loss 0.596338.
Train: 2018-08-01T01:44:44.018463: step 29980, loss 0.630025.
Test: 2018-08-01T01:44:44.487079: step 29980, loss 0.54835.
Train: 2018-08-01T01:44:44.643322: step 29981, loss 0.562443.
Train: 2018-08-01T01:44:44.799537: step 29982, loss 0.528922.
Train: 2018-08-01T01:44:44.955720: step 29983, loss 0.52903.
Train: 2018-08-01T01:44:45.111932: step 29984, loss 0.595864.
Train: 2018-08-01T01:44:45.268145: step 29985, loss 0.529195.
Train: 2018-08-01T01:44:45.424384: step 29986, loss 0.56251.
Train: 2018-08-01T01:44:45.580574: step 29987, loss 0.54591.
Train: 2018-08-01T01:44:45.752408: step 29988, loss 0.595715.
Train: 2018-08-01T01:44:45.908651: step 29989, loss 0.57911.
Train: 2018-08-01T01:44:46.064865: step 29990, loss 0.479737.
Test: 2018-08-01T01:44:46.533515: step 29990, loss 0.548667.
Train: 2018-08-01T01:44:46.705345: step 29991, loss 0.562538.
Train: 2018-08-01T01:44:46.861548: step 29992, loss 0.661953.
Train: 2018-08-01T01:44:47.017768: step 29993, loss 0.711531.
Train: 2018-08-01T01:44:47.173980: step 29994, loss 0.529544.
Train: 2018-08-01T01:44:47.330193: step 29995, loss 0.463708.
Train: 2018-08-01T01:44:47.486377: step 29996, loss 0.612005.
Train: 2018-08-01T01:44:47.658213: step 29997, loss 0.611973.
Train: 2018-08-01T01:44:47.798805: step 29998, loss 0.529719.
Train: 2018-08-01T01:44:47.955018: step 29999, loss 0.529742.
Train: 2018-08-01T01:44:48.111231: step 30000, loss 0.579038.
Test: 2018-08-01T01:44:48.579900: step 30000, loss 0.548845.
Train: 2018-08-01T01:44:49.360937: step 30001, loss 0.480446.
Train: 2018-08-01T01:44:49.517181: step 30002, loss 0.6284.
Train: 2018-08-01T01:44:49.673395: step 30003, loss 0.463854.
Train: 2018-08-01T01:44:49.845200: step 30004, loss 0.710935.
Train: 2018-08-01T01:44:49.985823: step 30005, loss 0.480184.
Train: 2018-08-01T01:44:50.142005: step 30006, loss 0.447113.
Train: 2018-08-01T01:44:50.298219: step 30007, loss 0.546017.
Train: 2018-08-01T01:44:50.454431: step 30008, loss 0.562532.
Train: 2018-08-01T01:44:50.610644: step 30009, loss 0.57913.
Train: 2018-08-01T01:44:50.766883: step 30010, loss 0.662393.
Test: 2018-08-01T01:44:51.251150: step 30010, loss 0.548548.
Train: 2018-08-01T01:44:51.407333: step 30011, loss 0.529181.
Train: 2018-08-01T01:44:51.563547: step 30012, loss 0.512464.
Train: 2018-08-01T01:44:51.719796: step 30013, loss 0.629295.
Train: 2018-08-01T01:44:51.875974: step 30014, loss 0.579192.
Train: 2018-08-01T01:44:52.047810: step 30015, loss 0.512303.
Train: 2018-08-01T01:44:52.204023: step 30016, loss 0.562468.
Train: 2018-08-01T01:44:52.360236: step 30017, loss 0.528938.
Train: 2018-08-01T01:44:52.516479: step 30018, loss 0.461734.
Train: 2018-08-01T01:44:52.672692: step 30019, loss 0.528779.
Train: 2018-08-01T01:44:52.828876: step 30020, loss 0.579311.
Test: 2018-08-01T01:44:53.297546: step 30020, loss 0.548253.
Train: 2018-08-01T01:44:53.453729: step 30021, loss 0.545502.
Train: 2018-08-01T01:44:53.625564: step 30022, loss 0.528491.
Train: 2018-08-01T01:44:53.781808: step 30023, loss 0.477374.
Train: 2018-08-01T01:44:53.938021: step 30024, loss 0.494142.
Train: 2018-08-01T01:44:54.078613: step 30025, loss 0.49387.
Train: 2018-08-01T01:44:54.281691: step 30026, loss 0.562402.
Train: 2018-08-01T01:44:54.437875: step 30027, loss 0.562407.
Train: 2018-08-01T01:44:54.594087: step 30028, loss 0.475736.
Train: 2018-08-01T01:44:54.765953: step 30029, loss 0.614647.
Train: 2018-08-01T01:44:54.922165: step 30030, loss 0.475135.
Test: 2018-08-01T01:44:55.390805: step 30030, loss 0.547778.
Train: 2018-08-01T01:44:55.547020: step 30031, loss 0.492353.
Train: 2018-08-01T01:44:55.703233: step 30032, loss 0.597669.
Train: 2018-08-01T01:44:55.859446: step 30033, loss 0.668414.
Train: 2018-08-01T01:44:56.015659: step 30034, loss 0.438742.
Train: 2018-08-01T01:44:56.187500: step 30035, loss 0.49161.
Train: 2018-08-01T01:44:56.343720: step 30036, loss 0.633694.
Train: 2018-08-01T01:44:56.515544: step 30037, loss 0.580389.
Train: 2018-08-01T01:44:56.671750: step 30038, loss 0.580429.
Train: 2018-08-01T01:44:56.827939: step 30039, loss 0.491137.
Train: 2018-08-01T01:44:56.984153: step 30040, loss 0.634177.
Test: 2018-08-01T01:44:57.452829: step 30040, loss 0.547622.
Train: 2018-08-01T01:44:57.624652: step 30041, loss 0.598416.
Train: 2018-08-01T01:44:57.796487: step 30042, loss 0.616314.
Train: 2018-08-01T01:44:57.952706: step 30043, loss 0.669928.
Train: 2018-08-01T01:44:58.104278: step 30044, loss 0.61614.
Train: 2018-08-01T01:44:58.260493: step 30045, loss 0.58037.
Train: 2018-08-01T01:44:58.416705: step 30046, loss 0.544779.
Train: 2018-08-01T01:44:58.604162: step 30047, loss 0.491634.
Train: 2018-08-01T01:44:58.760400: step 30048, loss 0.527114.
Train: 2018-08-01T01:44:58.916619: step 30049, loss 0.544823.
Train: 2018-08-01T01:44:59.072802: step 30050, loss 0.491805.
Test: 2018-08-01T01:44:59.525846: step 30050, loss 0.547702.
Train: 2018-08-01T01:44:59.697656: step 30051, loss 0.527149.
Train: 2018-08-01T01:44:59.838248: step 30052, loss 0.580195.
Train: 2018-08-01T01:44:59.994491: step 30053, loss 0.562509.
Train: 2018-08-01T01:45:00.166321: step 30054, loss 0.615579.
Train: 2018-08-01T01:45:00.338130: step 30055, loss 0.615541.
Train: 2018-08-01T01:45:00.494344: step 30056, loss 0.491872.
Train: 2018-08-01T01:45:00.650559: step 30057, loss 0.597792.
Train: 2018-08-01T01:45:00.806771: step 30058, loss 0.509586.
Train: 2018-08-01T01:45:00.963017: step 30059, loss 0.668266.
Train: 2018-08-01T01:45:01.119223: step 30060, loss 0.544874.
Test: 2018-08-01T01:45:01.603458: step 30060, loss 0.547747.
Train: 2018-08-01T01:45:01.759673: step 30061, loss 0.439396.
Train: 2018-08-01T01:45:01.947159: step 30062, loss 0.597645.
Train: 2018-08-01T01:45:02.087720: step 30063, loss 0.580053.
Train: 2018-08-01T01:45:02.243934: step 30064, loss 0.52732.
Train: 2018-08-01T01:45:02.400178: step 30065, loss 0.580039.
Train: 2018-08-01T01:45:02.572007: step 30066, loss 0.580031.
Train: 2018-08-01T01:45:02.728196: step 30067, loss 0.422015.
Train: 2018-08-01T01:45:02.884410: step 30068, loss 0.527319.
Train: 2018-08-01T01:45:03.056243: step 30069, loss 0.492088.
Train: 2018-08-01T01:45:03.212458: step 30070, loss 0.580117.
Test: 2018-08-01T01:45:03.681113: step 30070, loss 0.547712.
Train: 2018-08-01T01:45:03.837344: step 30071, loss 0.580151.
Train: 2018-08-01T01:45:04.009179: step 30072, loss 0.456465.
Train: 2018-08-01T01:45:04.181005: step 30073, loss 0.50939.
Train: 2018-08-01T01:45:04.337226: step 30074, loss 0.615788.
Train: 2018-08-01T01:45:04.493438: step 30075, loss 0.63365.
Train: 2018-08-01T01:45:04.649645: step 30076, loss 0.580333.
Train: 2018-08-01T01:45:04.805834: step 30077, loss 0.633683.
Train: 2018-08-01T01:45:04.962080: step 30078, loss 0.562543.
Train: 2018-08-01T01:45:05.133886: step 30079, loss 0.59804.
Train: 2018-08-01T01:45:05.290132: step 30080, loss 0.651172.
Test: 2018-08-01T01:45:05.774388: step 30080, loss 0.547696.
Train: 2018-08-01T01:45:05.977459: step 30081, loss 0.420995.
Train: 2018-08-01T01:45:06.133679: step 30082, loss 0.615547.
Train: 2018-08-01T01:45:06.336752: step 30083, loss 0.527177.
Train: 2018-08-01T01:45:06.492940: step 30084, loss 0.597789.
Train: 2018-08-01T01:45:06.649154: step 30085, loss 0.474343.
Train: 2018-08-01T01:45:06.805365: step 30086, loss 0.562485.
Train: 2018-08-01T01:45:06.961604: step 30087, loss 0.632986.
Train: 2018-08-01T01:45:07.133439: step 30088, loss 0.3864.
Train: 2018-08-01T01:45:07.289652: step 30089, loss 0.509605.
Train: 2018-08-01T01:45:07.461488: step 30090, loss 0.633106.
Test: 2018-08-01T01:45:07.930103: step 30090, loss 0.547709.
Train: 2018-08-01T01:45:08.086348: step 30091, loss 0.580159.
Train: 2018-08-01T01:45:08.258151: step 30092, loss 0.597825.
Train: 2018-08-01T01:45:08.414397: step 30093, loss 0.562496.
Train: 2018-08-01T01:45:08.586224: step 30094, loss 0.597792.
Train: 2018-08-01T01:45:08.742443: step 30095, loss 0.633026.
Train: 2018-08-01T01:45:08.898625: step 30096, loss 0.597688.
Train: 2018-08-01T01:45:09.054867: step 30097, loss 0.615179.
Train: 2018-08-01T01:45:09.226704: step 30098, loss 0.579981.
Train: 2018-08-01T01:45:09.382888: step 30099, loss 0.66735.
Train: 2018-08-01T01:45:09.554724: step 30100, loss 0.636769.
Test: 2018-08-01T01:45:10.023363: step 30100, loss 0.547884.
